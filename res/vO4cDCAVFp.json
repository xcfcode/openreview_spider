{"notes": [{"id": "vO4cDCAVFp", "original": "qZwjAawqvF", "number": 20, "cdate": 1582750156172, "ddate": null, "tcdate": 1582750156172, "tmdate": 1587925113230, "tddate": null, "forum": "vO4cDCAVFp", "replyto": null, "invitation": "ICLR.cc/2020/Workshop/DeepDiffEq/-/Blind_Submission", "content": {"keywords": ["Neural ODEs", "Curriculum Learning", "Progressive Growing", "Time Series"], "authors": ["Hammad A. Ayyubi", "Yi Yao", "Ajay Divakaran"], "title": "Progressive Growing of Neural ODEs", "pdf": "/pdf/14cc0209f5a012e7909128210ebaadcc5c0182dd.pdf", "TL;DR": "Progressively growing Neural ODE network and data complexity to learn complex time-series.", "abstract": "Neural Ordinary Differential Equations (NODEs) have proven to be a powerful modeling tool for approximating (interpolation) and forecasting (extrapolation) irregularly sampled time series data. However, their performance degrades substantially when applied to real-world data, especially long-term data with complex behaviors (e.g., long-term trend across years, mid-term seasonality across months, and short-term local variation across days). To address the modeling of such complex data with different behaviors at different frequencies (time spans), we propose a novel progressive learning paradigm of NODEs for long-term time series forecasting. Specifically, following the principle of curriculum learning, we gradually increase the complexity of data and network capacity as training progresses. Our experiments with both synthetic data and real traffic data (PeMS Bay Area traffic data) show that our training methodology consistently improves the performance of vanilla NODEs by over 64%.", "authorids": ["hayyubi@eng.ucsd.edu", "yi.yao@sri.com", "ajay.divakaran@sri.com"], "paperhash": "ayyubi|progressive_growing_of_neural_odes", "_bibtex": "@inproceedings{\nayyubi2020progressive,\ntitle={Progressive Growing of Neural {\\{}ODE{\\}}s},\nauthor={Hammad A. Ayyubi and Yi Yao and Ajay Divakaran},\nbooktitle={ICLR 2020 Workshop on Integration of Deep Neural Models and Differential Equations},\nyear={2020},\nurl={https://openreview.net/forum?id=vO4cDCAVFp}\n}"}, "signatures": ["ICLR.cc/2020/Workshop/DeepDiffEq"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Workshop/DeepDiffEq"], "details": {"replyCount": 1, "writable": false, "overwriting": [], "revisions": false, "tags": [], "invitation": {"reply": {"readers": {"values-regex": ".*"}, "writers": {"values": ["ICLR.cc/2020/Workshop/DeepDiffEq"]}, "signatures": {"values": ["ICLR.cc/2020/Workshop/DeepDiffEq"]}, "content": {"authors": {"values": ["Anonymous"]}, "authorids": {"values-regex": ".*"}}}, "signatures": ["ICLR.cc/2020/Workshop/DeepDiffEq"], "readers": ["everyone"], "writers": ["ICLR.cc/2020/Workshop/DeepDiffEq"], "invitees": ["~"], "tcdate": 1582750147213, "tmdate": 1587924718420, "id": "ICLR.cc/2020/Workshop/DeepDiffEq/-/Blind_Submission"}}, "tauthor": "OpenReview.net"}, {"id": "f7V9gHN0Z", "original": null, "number": 1, "cdate": 1582774741574, "ddate": null, "tcdate": 1582774741574, "tmdate": 1582774741574, "tddate": null, "forum": "vO4cDCAVFp", "replyto": "vO4cDCAVFp", "invitation": "ICLR.cc/2020/Workshop/DeepDiffEq/Paper20/-/Decision", "content": {"decision": "Accept (Poster)", "title": "Paper Decision"}, "signatures": ["ICLR.cc/2020/Workshop/DeepDiffEq/Program_Chairs"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Workshop/DeepDiffEq/Program_Chairs"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"keywords": ["Neural ODEs", "Curriculum Learning", "Progressive Growing", "Time Series"], "authors": ["Hammad A. Ayyubi", "Yi Yao", "Ajay Divakaran"], "title": "Progressive Growing of Neural ODEs", "pdf": "/pdf/14cc0209f5a012e7909128210ebaadcc5c0182dd.pdf", "TL;DR": "Progressively growing Neural ODE network and data complexity to learn complex time-series.", "abstract": "Neural Ordinary Differential Equations (NODEs) have proven to be a powerful modeling tool for approximating (interpolation) and forecasting (extrapolation) irregularly sampled time series data. However, their performance degrades substantially when applied to real-world data, especially long-term data with complex behaviors (e.g., long-term trend across years, mid-term seasonality across months, and short-term local variation across days). To address the modeling of such complex data with different behaviors at different frequencies (time spans), we propose a novel progressive learning paradigm of NODEs for long-term time series forecasting. Specifically, following the principle of curriculum learning, we gradually increase the complexity of data and network capacity as training progresses. Our experiments with both synthetic data and real traffic data (PeMS Bay Area traffic data) show that our training methodology consistently improves the performance of vanilla NODEs by over 64%.", "authorids": ["hayyubi@eng.ucsd.edu", "yi.yao@sri.com", "ajay.divakaran@sri.com"], "paperhash": "ayyubi|progressive_growing_of_neural_odes", "_bibtex": "@inproceedings{\nayyubi2020progressive,\ntitle={Progressive Growing of Neural {\\{}ODE{\\}}s},\nauthor={Hammad A. Ayyubi and Yi Yao and Ajay Divakaran},\nbooktitle={ICLR 2020 Workshop on Integration of Deep Neural Models and Differential Equations},\nyear={2020},\nurl={https://openreview.net/forum?id=vO4cDCAVFp}\n}"}, "tags": [], "invitation": {"reply": {"writers": {"values": ["ICLR.cc/2020/Workshop/DeepDiffEq/Program_Chairs"], "description": "How your identity will be displayed."}, "signatures": {"values": ["ICLR.cc/2020/Workshop/DeepDiffEq/Program_Chairs"], "description": "How your identity will be displayed."}, "content": {"title": {"order": 1, "required": true, "value": "Paper Decision"}, "decision": {"order": 2, "required": true, "value-radio": ["Accept (Oral)", "Accept (Poster)", "Reject"], "description": "Decision"}, "comment": {"order": 3, "required": false, "value-regex": "[\\S\\s]{0,5000}", "description": ""}}, "forum": "vO4cDCAVFp", "replyto": "vO4cDCAVFp", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}}, "cdate": 1582156800000, "expdate": 1589155200000, "duedate": 1588291200000, "multiReply": false, "readers": ["everyone"], "invitees": ["ICLR.cc/2020/Workshop/DeepDiffEq/Program_Chairs"], "tcdate": 1582771074389, "tmdate": 1587925023492, "super": "ICLR.cc/2020/Workshop/DeepDiffEq/-/Decision", "signatures": ["ICLR.cc/2020/Workshop/DeepDiffEq"], "writers": ["ICLR.cc/2020/Workshop/DeepDiffEq"], "id": "ICLR.cc/2020/Workshop/DeepDiffEq/Paper20/-/Decision"}}}], "count": 2}