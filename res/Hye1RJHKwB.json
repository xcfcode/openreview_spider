{"notes": [{"id": "Hye1RJHKwB", "original": "HJloHI1Kvr", "number": 2009, "cdate": 1569439686884, "ddate": null, "tcdate": 1569439686884, "tmdate": 1583912040831, "tddate": null, "forum": "Hye1RJHKwB", "replyto": null, "invitation": "ICLR.cc/2020/Conference/-/Blind_Submission", "content": {"authorids": ["d.stoller@qmul.ac.uk", "sewert@spotify.com", "s.e.dixon@qmul.ac.uk"], "title": "Training Generative Adversarial Networks from Incomplete Observations using Factorised Discriminators", "authors": ["Daniel Stoller", "Sebastian Ewert", "Simon Dixon"], "pdf": "/pdf/dd2f617b749f8375bb46bfd434be0338b70e4cd5.pdf", "TL;DR": "We decompose the discriminator in a GAN in a principled way so that each component can be independently trained on different parts of the input. The resulting \"FactorGAN\" can be used for semi-supervised learning and in missing data scenarios.", "abstract": "Generative adversarial networks (GANs) have shown great success in applications such as image generation and inpainting.\nHowever, they typically require large datasets, which are often not available, especially in the context of prediction tasks such as image segmentation that require labels. Therefore, methods such as the CycleGAN use more easily available unlabelled data, but do not offer a way to leverage additional labelled data for improved performance. To address this shortcoming, we show how to factorise the joint data distribution into a set of lower-dimensional distributions along with their dependencies. This allows splitting the discriminator in a GAN into multiple \"sub-discriminators\" that can be independently trained from incomplete observations. Their outputs can be combined to estimate the density ratio between the joint real and the generator distribution, which enables training generators as in the original GAN framework. We apply our method to image generation, image segmentation and audio source separation, and obtain improved performance over a standard GAN when additional incomplete training examples are available. For the Cityscapes segmentation task in particular, our method also improves accuracy by an absolute 14.9% over CycleGAN while using only 25 additional paired examples.", "code": "https://www.dropbox.com/s/gtc7m7pc4n2yt05/source.zip?dl=1", "keywords": ["Adversarial Learning", "Semi-supervised Learning", "Image generation", "Image segmentation", "Missing Data"], "paperhash": "stoller|training_generative_adversarial_networks_from_incomplete_observations_using_factorised_discriminators", "_bibtex": "@inproceedings{\nStoller2020Training,\ntitle={Training Generative Adversarial Networks from Incomplete Observations using Factorised Discriminators},\nauthor={Daniel Stoller and Sebastian Ewert and Simon Dixon},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=Hye1RJHKwB}\n}", "full_presentation_video": "", "original_pdf": "/attachment/858be1a64692ebfcc0ee8131c227274b3ba8b89c.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "signatures": ["ICLR.cc/2020/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference"], "details": {"replyCount": 7, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"reply": {"readers": {"values-regex": ".*"}, "writers": {"values": ["ICLR.cc/2020/Conference"]}, "signatures": {"values": ["ICLR.cc/2020/Conference"]}, "content": {"spotlight_video": {"value-regex": ".*"}, "full_presentation_video": {"value-regex": ".*"}, "original_pdf": {"required": false, "description": "Upload a PDF file that ends with .pdf", "value-regex": ".*"}, "appendix": {"value-regex": ".*"}, "authorids": {"values-regex": ".*"}, "poster": {"value-regex": ".*"}, "authors": {"values": ["Anonymous"]}, "slides": {"value-regex": ".*"}}}, "final": [], "signatures": ["ICLR.cc/2020/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference"], "noninvitees": [], "tcdate": 1569271260237, "tmdate": 1593459412141, "id": "ICLR.cc/2020/Conference/-/Blind_Submission"}}, "tauthor": "ICLR.cc/2020/Conference"}, {"id": "l6hr25do6z", "original": null, "number": 1, "cdate": 1576798738141, "ddate": null, "tcdate": 1576798738141, "tmdate": 1576800898214, "tddate": null, "forum": "Hye1RJHKwB", "replyto": "Hye1RJHKwB", "invitation": "ICLR.cc/2020/Conference/Paper2009/-/Decision", "content": {"decision": "Accept (Poster)", "comment": "All three reviewers appreciate the new method (FactorGAN) for training generative networks from incomplete observations. At the same time, the quality of the experimental results can still be improved. On balance, the paper will make a good poster.", "title": "Paper Decision"}, "signatures": ["ICLR.cc/2020/Conference/Program_Chairs"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Program_Chairs"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["d.stoller@qmul.ac.uk", "sewert@spotify.com", "s.e.dixon@qmul.ac.uk"], "title": "Training Generative Adversarial Networks from Incomplete Observations using Factorised Discriminators", "authors": ["Daniel Stoller", "Sebastian Ewert", "Simon Dixon"], "pdf": "/pdf/dd2f617b749f8375bb46bfd434be0338b70e4cd5.pdf", "TL;DR": "We decompose the discriminator in a GAN in a principled way so that each component can be independently trained on different parts of the input. The resulting \"FactorGAN\" can be used for semi-supervised learning and in missing data scenarios.", "abstract": "Generative adversarial networks (GANs) have shown great success in applications such as image generation and inpainting.\nHowever, they typically require large datasets, which are often not available, especially in the context of prediction tasks such as image segmentation that require labels. Therefore, methods such as the CycleGAN use more easily available unlabelled data, but do not offer a way to leverage additional labelled data for improved performance. To address this shortcoming, we show how to factorise the joint data distribution into a set of lower-dimensional distributions along with their dependencies. This allows splitting the discriminator in a GAN into multiple \"sub-discriminators\" that can be independently trained from incomplete observations. Their outputs can be combined to estimate the density ratio between the joint real and the generator distribution, which enables training generators as in the original GAN framework. We apply our method to image generation, image segmentation and audio source separation, and obtain improved performance over a standard GAN when additional incomplete training examples are available. For the Cityscapes segmentation task in particular, our method also improves accuracy by an absolute 14.9% over CycleGAN while using only 25 additional paired examples.", "code": "https://www.dropbox.com/s/gtc7m7pc4n2yt05/source.zip?dl=1", "keywords": ["Adversarial Learning", "Semi-supervised Learning", "Image generation", "Image segmentation", "Missing Data"], "paperhash": "stoller|training_generative_adversarial_networks_from_incomplete_observations_using_factorised_discriminators", "_bibtex": "@inproceedings{\nStoller2020Training,\ntitle={Training Generative Adversarial Networks from Incomplete Observations using Factorised Discriminators},\nauthor={Daniel Stoller and Sebastian Ewert and Simon Dixon},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=Hye1RJHKwB}\n}", "full_presentation_video": "", "original_pdf": "/attachment/858be1a64692ebfcc0ee8131c227274b3ba8b89c.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "tags": [], "invitation": {"reply": {"writers": {"description": "How your identity will be displayed.", "values-regex": ["ICLR.cc/2020/Conference/Program_Chairs"]}, "signatures": {"values": ["ICLR.cc/2020/Conference/Program_Chairs"], "description": "How your identity will be displayed."}, "content": {"decision": {"value-radio": ["Accept (Spotlight)", "Accept (Talk)", "Accept (Poster)", "Reject"], "description": "Decision", "required": true, "order": 2}, "title": {"value": "Paper Decision", "required": true, "order": 1}, "comment": {"value-regex": "[\\S\\s]{0,5000}", "description": "", "required": false, "order": 3}}, "forum": "Hye1RJHKwB", "replyto": "Hye1RJHKwB", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}}, "expdate": 1576854540000, "duedate": 1576853940000, "multiReply": false, "readers": ["everyone"], "invitees": ["ICLR.cc/2020/Conference/Program_Chairs"], "tcdate": 1576795716626, "tmdate": 1576800266814, "super": "ICLR.cc/2020/Conference/-/Decision", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper2009/-/Decision"}}}, {"id": "rkxZuQfJcH", "original": null, "number": 1, "cdate": 1571918697112, "ddate": null, "tcdate": 1571918697112, "tmdate": 1574470809516, "tddate": null, "forum": "Hye1RJHKwB", "replyto": "Hye1RJHKwB", "invitation": "ICLR.cc/2020/Conference/Paper2009/-/Official_Review", "content": {"experience_assessment": "I have read many papers in this area.", "rating": "6: Weak Accept", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "title": "Official Blind Review #2", "review": "The authors present FactorGANs, which handle missing data scenarios by constructing conditional marginal estimates from ratios of joint and marginal distributions, estimated with GANs. FactorGANs are applied to the problem of semi-supervised (paired+unpaired) translation and demonstrate good performance.\n\nStrengths:\n-Nice formulation, which I believe is novel. Well written, good initial results.\n\nLimitations:\n-The most serious limitation of the paper is that the technique is not compared with any other semi-supervised methods, such as the Augmented CycleGAN. Because of this it is not clear how the technique compares with SOTA, and so the significance of the paper is not clear.\n-The approach scales linearly with the number of marginals, which may limit its applicability to more general imputation tasks.\n-The title is the same as an the arxiv paper title, and so the double-blind requirement is trivially violated.\n\nOverall:\n\nA nice formulation, but weak experimental investigations (no comparisons to SOTA semi-supervised translation) make the significance of the paper unclear. This makes it a borderline paper. I strongly encourage the authors to update their experiments accordingly.\n\nPost Response:\n\nThank you to the authors for the detailed response and additional experimentation. I have updated my rating. It is a nice formulation, and the experimental validation of the technique has been strengthened. The additional experiments (i.e. comparing to the augmented cyclegan) that the authors are following through on will further improve the paper, making it a clear accept.\n", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory."}, "signatures": ["ICLR.cc/2020/Conference/Paper2009/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper2009/AnonReviewer2"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["d.stoller@qmul.ac.uk", "sewert@spotify.com", "s.e.dixon@qmul.ac.uk"], "title": "Training Generative Adversarial Networks from Incomplete Observations using Factorised Discriminators", "authors": ["Daniel Stoller", "Sebastian Ewert", "Simon Dixon"], "pdf": "/pdf/dd2f617b749f8375bb46bfd434be0338b70e4cd5.pdf", "TL;DR": "We decompose the discriminator in a GAN in a principled way so that each component can be independently trained on different parts of the input. The resulting \"FactorGAN\" can be used for semi-supervised learning and in missing data scenarios.", "abstract": "Generative adversarial networks (GANs) have shown great success in applications such as image generation and inpainting.\nHowever, they typically require large datasets, which are often not available, especially in the context of prediction tasks such as image segmentation that require labels. Therefore, methods such as the CycleGAN use more easily available unlabelled data, but do not offer a way to leverage additional labelled data for improved performance. To address this shortcoming, we show how to factorise the joint data distribution into a set of lower-dimensional distributions along with their dependencies. This allows splitting the discriminator in a GAN into multiple \"sub-discriminators\" that can be independently trained from incomplete observations. Their outputs can be combined to estimate the density ratio between the joint real and the generator distribution, which enables training generators as in the original GAN framework. We apply our method to image generation, image segmentation and audio source separation, and obtain improved performance over a standard GAN when additional incomplete training examples are available. For the Cityscapes segmentation task in particular, our method also improves accuracy by an absolute 14.9% over CycleGAN while using only 25 additional paired examples.", "code": "https://www.dropbox.com/s/gtc7m7pc4n2yt05/source.zip?dl=1", "keywords": ["Adversarial Learning", "Semi-supervised Learning", "Image generation", "Image segmentation", "Missing Data"], "paperhash": "stoller|training_generative_adversarial_networks_from_incomplete_observations_using_factorised_discriminators", "_bibtex": "@inproceedings{\nStoller2020Training,\ntitle={Training Generative Adversarial Networks from Incomplete Observations using Factorised Discriminators},\nauthor={Daniel Stoller and Sebastian Ewert and Simon Dixon},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=Hye1RJHKwB}\n}", "full_presentation_video": "", "original_pdf": "/attachment/858be1a64692ebfcc0ee8131c227274b3ba8b89c.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "Hye1RJHKwB", "replyto": "Hye1RJHKwB", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper2009/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper2009/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1575643160010, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper2009/Reviewers"], "noninvitees": [], "tcdate": 1570237729078, "tmdate": 1575643160024, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper2009/-/Official_Review"}}}, {"id": "rklgOOV9jr", "original": null, "number": 3, "cdate": 1573697639982, "ddate": null, "tcdate": 1573697639982, "tmdate": 1573697639982, "tddate": null, "forum": "Hye1RJHKwB", "replyto": "rkxZuQfJcH", "invitation": "ICLR.cc/2020/Conference/Paper2009/-/Official_Comment", "content": {"title": "Author response", "comment": "Thank you for your feedback on this paper. We hope to clarify some details with the following and thus respond to your questions.\n\n\"The most serious limitation of the paper is that the technique is not compared with any other semi-supervised methods, such as the Augmented CycleGAN. Because of this it is not clear how the technique compares with SOTA, and so the significance of the paper is not clear.\"\n\nOur main contribution is a theoretical foundation for GAN training applicable to generation in a missing data scenario as well as general prediction tasks, and not only limited to image segmentation. While a comparison to SOTA methods for certain sub-tasks (such as image segmentation) could indeed be interesting, our aim was not to claim SOTA for any of these sub-tasks, but to demonstrate that our technique can be applied in a range of possible application scenarios and deliver results in line with our theory (e.g. that performance should increase with more paired samples as the p-dependency discriminator can better estimate its density ratio). \n\nWe agree that applying our technique to more tasks and introducing more complex network architectures to reach better performance is certainly worthwhile - given the range of application scenarios we consider and the space constraints for the paper, however, we feel that we have to point to future work in this context.\n\nHowever, to account for your concerns given the space constraints, we ran additional experiments using the CycleGAN on the image segmentation task (as mentioned also in the response to AnonReviewer4). We used the same network architectures and training setup as the GAN and FactorGAN (so that the standard GAN loss is used alongside spetral normalization). This ensures a fair comparison to GAN and FactorGAN. We included the results in an updated version of the paper, so please refer to the paper for more details. In short, CycleGAN is outperformed by FactorGAN in this setting, even when FactorGAN is only given 25 paired samples, and so FactorGAN is able to model the input-output dependencies more accurately.\n\nWe also trained the Augmented CycleGAN by minimally adapting their code [1] to our Cityscapes setting. The only changes were increasing the input resolution from 64x64 to 128x128, and adding one more layer in the discriminator networks due to the higher input resolution. However, the model did not converge, so we are unable to add these results as another baseline.\nComparison to commonly used missing data imputation methods is also difficult due to the higher number of variables to impute (3 color channels * 128 pixels * 128 pixels per image). We attempted to run missForest [2] but it was too memory-intensive for this reason.\n\nWe are currently experimenting with reimplementing the Augmented CycleGAN from scratch, and will update you if we have additional results to share.\n\n\"The title is the same as an the arxiv paper title, and so the double-blind requirement is trivially violated.\"\n\nPlease note that we are fully compliant with the ICLR 2020 submission requirements: We fully anonymised both paper and code, and submission on arXiv is explicitly allowed. Citing the call for papers, it says: \"However, papers that cite previous related work by the authors and papers that have appeared on non-peered reviewed websites (like arXiv) or that have been presented at workshops (i.e., venues that do not have a publication proceedings) do not violate the policy. The policy is enforced during the whole reviewing process period. Submission of the paper to archival repositories such as arXiv are allowed.\"\n\n[1] Augmented CycleGAN official codebase. https://github.com/aalmah/augmented_cyclegan\n[2] missForest as implemented in missingPy (https://pypi.org/project/missingpy/)"}, "signatures": ["ICLR.cc/2020/Conference/Paper2009/Authors"], "readers": ["everyone", "ICLR.cc/2020/Conference/Paper2009/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper2009/Reviewers"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper2009/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["d.stoller@qmul.ac.uk", "sewert@spotify.com", "s.e.dixon@qmul.ac.uk"], "title": "Training Generative Adversarial Networks from Incomplete Observations using Factorised Discriminators", "authors": ["Daniel Stoller", "Sebastian Ewert", "Simon Dixon"], "pdf": "/pdf/dd2f617b749f8375bb46bfd434be0338b70e4cd5.pdf", "TL;DR": "We decompose the discriminator in a GAN in a principled way so that each component can be independently trained on different parts of the input. The resulting \"FactorGAN\" can be used for semi-supervised learning and in missing data scenarios.", "abstract": "Generative adversarial networks (GANs) have shown great success in applications such as image generation and inpainting.\nHowever, they typically require large datasets, which are often not available, especially in the context of prediction tasks such as image segmentation that require labels. Therefore, methods such as the CycleGAN use more easily available unlabelled data, but do not offer a way to leverage additional labelled data for improved performance. To address this shortcoming, we show how to factorise the joint data distribution into a set of lower-dimensional distributions along with their dependencies. This allows splitting the discriminator in a GAN into multiple \"sub-discriminators\" that can be independently trained from incomplete observations. Their outputs can be combined to estimate the density ratio between the joint real and the generator distribution, which enables training generators as in the original GAN framework. We apply our method to image generation, image segmentation and audio source separation, and obtain improved performance over a standard GAN when additional incomplete training examples are available. For the Cityscapes segmentation task in particular, our method also improves accuracy by an absolute 14.9% over CycleGAN while using only 25 additional paired examples.", "code": "https://www.dropbox.com/s/gtc7m7pc4n2yt05/source.zip?dl=1", "keywords": ["Adversarial Learning", "Semi-supervised Learning", "Image generation", "Image segmentation", "Missing Data"], "paperhash": "stoller|training_generative_adversarial_networks_from_incomplete_observations_using_factorised_discriminators", "_bibtex": "@inproceedings{\nStoller2020Training,\ntitle={Training Generative Adversarial Networks from Incomplete Observations using Factorised Discriminators},\nauthor={Daniel Stoller and Sebastian Ewert and Simon Dixon},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=Hye1RJHKwB}\n}", "full_presentation_video": "", "original_pdf": "/attachment/858be1a64692ebfcc0ee8131c227274b3ba8b89c.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "Hye1RJHKwB", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper2009/Authors", "ICLR.cc/2020/Conference/Paper2009/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper2009/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper2009/Reviewers", "ICLR.cc/2020/Conference/Paper2009/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper2009/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper2009/Authors|ICLR.cc/2020/Conference/Paper2009/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504147649, "tmdate": 1576860558611, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper2009/Authors", "ICLR.cc/2020/Conference/Paper2009/Reviewers", "ICLR.cc/2020/Conference/Paper2009/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper2009/-/Official_Comment"}}}, {"id": "r1lnE_4qjS", "original": null, "number": 2, "cdate": 1573697588171, "ddate": null, "tcdate": 1573697588171, "tmdate": 1573697588171, "tddate": null, "forum": "Hye1RJHKwB", "replyto": "SygA0eq1qr", "invitation": "ICLR.cc/2020/Conference/Paper2009/-/Official_Comment", "content": {"title": "Author response", "comment": "We would like to thank you for your thoughtful review and are delighted about your positive assessment of the paper.\n\n\"For the paired MNIST experiment I found it hard to assess the qualitative results visually and am always concerned about the ad-hoc nature of Inception Distances - I find it difficult to attribute weight to them quantitatively since they are usually being used to assess things where they might suffer from a common error (e.g. they are both based on NNs).\"\n\nWe agree that the evaluation metric is not necessarily optimal. Since GAN evaluation is still an unsolved problem however, we believe providing Inception distances along with visual examples is a reasonable choice given the lack of clearly superior alternatives.\n\n\"I appreciated having error bars on some of the plots to help assess significance - would it not be possible to put error bars on all plots?\"\n\nWe included error bars wherever possible, as we agree they are quite helpful to assess significance. Unfortunately, we are not able to add them to the other plots due to the high computational requirements of training each model in each configuration (multiple days of training on a single GPU), combined with the considerable number of different configurations.\n\n\"Also, I'm not fully on board with the dependency metric in (5) but then the authors also point out the same concerns. \"\n\nWe agree that the metric is not without flaws. However, we believe that including the metric provides useful information and thus decided to keep it in the paper.\n\nFinally, we agree that training stability is an important aspect in our setting, since we rely on the discriminators being good estimators of the respective density ratios.\nWhile we did not observe them in the experiments we included in the paper, we did notice that regularisation of the discriminators (here in the form of spectral normalisation) is important to ensure stability. Without such regularisation, the p-dependency discriminator can become very confident in its predictions, leading to large gradients to the generator that can prevent successful training. While we can not add further experiments easily due to the paper's space constraints, we included a short summary of this issue with a focus on how it could be resolved by extending our theoretical framework to inherently more stable GAN formulations into the conclusion section of the paper.\n\nAbout your note on independent marginals, it is correct that the model in this setting is more constrained than the general variant we propose. However there are some use-cases, such as independent component analysis, where an input has to be separated into components that do not exhibit dependencies between each other. This setting would be tackled in our framework by feeding the input to the generator, and viewing each output component as its own marginal, so that the q-dependency discriminator will ensure that the marginal outputs are independent."}, "signatures": ["ICLR.cc/2020/Conference/Paper2009/Authors"], "readers": ["everyone", "ICLR.cc/2020/Conference/Paper2009/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper2009/Reviewers"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper2009/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["d.stoller@qmul.ac.uk", "sewert@spotify.com", "s.e.dixon@qmul.ac.uk"], "title": "Training Generative Adversarial Networks from Incomplete Observations using Factorised Discriminators", "authors": ["Daniel Stoller", "Sebastian Ewert", "Simon Dixon"], "pdf": "/pdf/dd2f617b749f8375bb46bfd434be0338b70e4cd5.pdf", "TL;DR": "We decompose the discriminator in a GAN in a principled way so that each component can be independently trained on different parts of the input. The resulting \"FactorGAN\" can be used for semi-supervised learning and in missing data scenarios.", "abstract": "Generative adversarial networks (GANs) have shown great success in applications such as image generation and inpainting.\nHowever, they typically require large datasets, which are often not available, especially in the context of prediction tasks such as image segmentation that require labels. Therefore, methods such as the CycleGAN use more easily available unlabelled data, but do not offer a way to leverage additional labelled data for improved performance. To address this shortcoming, we show how to factorise the joint data distribution into a set of lower-dimensional distributions along with their dependencies. This allows splitting the discriminator in a GAN into multiple \"sub-discriminators\" that can be independently trained from incomplete observations. Their outputs can be combined to estimate the density ratio between the joint real and the generator distribution, which enables training generators as in the original GAN framework. We apply our method to image generation, image segmentation and audio source separation, and obtain improved performance over a standard GAN when additional incomplete training examples are available. For the Cityscapes segmentation task in particular, our method also improves accuracy by an absolute 14.9% over CycleGAN while using only 25 additional paired examples.", "code": "https://www.dropbox.com/s/gtc7m7pc4n2yt05/source.zip?dl=1", "keywords": ["Adversarial Learning", "Semi-supervised Learning", "Image generation", "Image segmentation", "Missing Data"], "paperhash": "stoller|training_generative_adversarial_networks_from_incomplete_observations_using_factorised_discriminators", "_bibtex": "@inproceedings{\nStoller2020Training,\ntitle={Training Generative Adversarial Networks from Incomplete Observations using Factorised Discriminators},\nauthor={Daniel Stoller and Sebastian Ewert and Simon Dixon},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=Hye1RJHKwB}\n}", "full_presentation_video": "", "original_pdf": "/attachment/858be1a64692ebfcc0ee8131c227274b3ba8b89c.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "Hye1RJHKwB", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper2009/Authors", "ICLR.cc/2020/Conference/Paper2009/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper2009/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper2009/Reviewers", "ICLR.cc/2020/Conference/Paper2009/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper2009/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper2009/Authors|ICLR.cc/2020/Conference/Paper2009/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504147649, "tmdate": 1576860558611, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper2009/Authors", "ICLR.cc/2020/Conference/Paper2009/Reviewers", "ICLR.cc/2020/Conference/Paper2009/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper2009/-/Official_Comment"}}}, {"id": "HkxJkw45sS", "original": null, "number": 1, "cdate": 1573697239173, "ddate": null, "tcdate": 1573697239173, "tmdate": 1573697239173, "tddate": null, "forum": "Hye1RJHKwB", "replyto": "Ske4xC31ir", "invitation": "ICLR.cc/2020/Conference/Paper2009/-/Official_Comment", "content": {"title": "Author response", "comment": "Thanks for your generally positive review and your useful feedback. We would like to respond to the questions raised in the following.\n\n\"It is not clear to me to what extent does the proposed model outperform the regular CycleGAN on a large amount of paired training samples due to architectural changes (including spectral normalization).\"\n\nWe ran additional experiments for the CycleGAN on the image segmentation task, using the same network architectures and training setup as the GAN and FactorGAN (so that the standard GAN loss is used alongside spectral normalization). We included the results in an updated version of the paper, so please refer to the paper for more details. In short, CycleGAN is outperformed by FactorGAN in this setting, even when FactorGAN is only given 25 paired samples, and so FactorGAN is able to model the input-output dependencies more accurately. Do note however that CycleGAN treats all samples as unpaired and instead relies on its cycle consistency assumption to model the input-output dependencies.\n\n\"Also, it would be nice if the comparison was carried out with a newer, possibly SotA models for unpaired image-to-image translation (MUNIT, FUNIT, BicycleGAN).\"\n\nWe agree that further scaling our proposed factorisation technique to more recently proposed models would be interesting. However, we believe that our main contribution is a theoretical foundation for both generation in the presence of missing data as well as general prediction tasks. It is not limited to image segmentation, and not based on a particular network architecture for the generator and discriminators, shown by the use of different networks in the paper. Therefore, we believe our experiments sufficiently support our main contribution, as they demonstrate the validity of the factorisation approach in different scenarios.\n\n\"Moreover, there are some simple modifications that can be made to a standard CycleGAN/Pix2pix training pipeline that would facilitate the small number of annotations (for example, see \"Learning image-to-image translation using paired and unpaired training samples\").\"\n\nWe agree that methods such as the CycleGAN can be adapted to the same problem setting. However, many of these simple adaptations (Augmented CycleGAN, the method described in the 'Learning image-to-image translation' paper) involve adding more loss terms to the objective in an ad-hoc manner which makes it difficult to characterise optimal solutions of the overall optimisation objective. It also results in more hyper-parameters required for balancing the different loss terms. Additionally, the tasks for the discriminators can overlap \u2013 for example in the 'Learning image-to-image translation' paper, where one discriminator models the marginal generator output while another the conditional generator output. In contrast, our factorisation elegantly partitions the joint modeling task and assigns it to multiple discriminators without functional overlaps. Furthermore, as we show in the paper, we can keep the standard GAN loss where equilibrium is reached when the generator and data distribution are the same.\nTo add to this, the paper you mentioned is not only restricted to deterministic generators, but also uses a cycle consistency loss that relies on the assumption that the mapping between the domains is deterministic and bijective. Since this is not the case for many problems (including the Cityscapes segmentation task), the perfect reconstruction encouraged by the cycle consistency loss is not possible. This has detrimental effects on the resulting model, as shown for the CycleGAN learning to embed extra information in its outputs to circumvent the information loss when mapping from one domain to the other that would normally make perfect reconstruction impossible. [1]\nRegardless, we included the mentioned paper in the related work section.\n\n[1] \"CycleGAN, a Master of Steganography\", Casey Chu, Presentation at the Machine Deception Session, NeurIPS 2017"}, "signatures": ["ICLR.cc/2020/Conference/Paper2009/Authors"], "readers": ["everyone", "ICLR.cc/2020/Conference/Paper2009/Reviewers", "ICLR.cc/2020/Conference/Paper2009/Reviewers/Submitted"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper2009/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["d.stoller@qmul.ac.uk", "sewert@spotify.com", "s.e.dixon@qmul.ac.uk"], "title": "Training Generative Adversarial Networks from Incomplete Observations using Factorised Discriminators", "authors": ["Daniel Stoller", "Sebastian Ewert", "Simon Dixon"], "pdf": "/pdf/dd2f617b749f8375bb46bfd434be0338b70e4cd5.pdf", "TL;DR": "We decompose the discriminator in a GAN in a principled way so that each component can be independently trained on different parts of the input. The resulting \"FactorGAN\" can be used for semi-supervised learning and in missing data scenarios.", "abstract": "Generative adversarial networks (GANs) have shown great success in applications such as image generation and inpainting.\nHowever, they typically require large datasets, which are often not available, especially in the context of prediction tasks such as image segmentation that require labels. Therefore, methods such as the CycleGAN use more easily available unlabelled data, but do not offer a way to leverage additional labelled data for improved performance. To address this shortcoming, we show how to factorise the joint data distribution into a set of lower-dimensional distributions along with their dependencies. This allows splitting the discriminator in a GAN into multiple \"sub-discriminators\" that can be independently trained from incomplete observations. Their outputs can be combined to estimate the density ratio between the joint real and the generator distribution, which enables training generators as in the original GAN framework. We apply our method to image generation, image segmentation and audio source separation, and obtain improved performance over a standard GAN when additional incomplete training examples are available. For the Cityscapes segmentation task in particular, our method also improves accuracy by an absolute 14.9% over CycleGAN while using only 25 additional paired examples.", "code": "https://www.dropbox.com/s/gtc7m7pc4n2yt05/source.zip?dl=1", "keywords": ["Adversarial Learning", "Semi-supervised Learning", "Image generation", "Image segmentation", "Missing Data"], "paperhash": "stoller|training_generative_adversarial_networks_from_incomplete_observations_using_factorised_discriminators", "_bibtex": "@inproceedings{\nStoller2020Training,\ntitle={Training Generative Adversarial Networks from Incomplete Observations using Factorised Discriminators},\nauthor={Daniel Stoller and Sebastian Ewert and Simon Dixon},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=Hye1RJHKwB}\n}", "full_presentation_video": "", "original_pdf": "/attachment/858be1a64692ebfcc0ee8131c227274b3ba8b89c.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "Hye1RJHKwB", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper2009/Authors", "ICLR.cc/2020/Conference/Paper2009/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper2009/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper2009/Reviewers", "ICLR.cc/2020/Conference/Paper2009/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper2009/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper2009/Authors|ICLR.cc/2020/Conference/Paper2009/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504147649, "tmdate": 1576860558611, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper2009/Authors", "ICLR.cc/2020/Conference/Paper2009/Reviewers", "ICLR.cc/2020/Conference/Paper2009/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper2009/-/Official_Comment"}}}, {"id": "Ske4xC31ir", "original": null, "number": 3, "cdate": 1573010923734, "ddate": null, "tcdate": 1573010923734, "tmdate": 1573010923734, "tddate": null, "forum": "Hye1RJHKwB", "replyto": "Hye1RJHKwB", "invitation": "ICLR.cc/2020/Conference/Paper2009/-/Official_Review", "content": {"experience_assessment": "I have published one or two papers in this area.", "rating": "6: Weak Accept", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "title": "Official Blind Review #4", "review": "The paper is tackling the problem of training generative adversarial networks with incomplete data points. The problem appears to be important for semi-supervised training of image to image translation models, where we may have a lot of observations in both domains, but a little annotated correspondences between the domains.\n\nThe solution proposed by the authors involves an observation that discriminator in GANs is estimating the density ratio between real and fake distributions. This ratio can then be decomposed into a product of marginal density ratios, with two additional multipliers, corresponding to density ratios between a joint real/fake distribution and a product of its marginals. The authors then use discriminators to approximate all the ratios, which allows them to facilitate semi-supervised training.\n\nMy decision is \"weak accept\".\n\nIt is not clear to me to what extent does the proposed model outperform the regular CycleGAN on a large amount of paired training samples due to architectural changes (including spectral normalization).\n\nAlso, it would be nice if the comparison was carried out with a newer, possibly SotA models for unpaired image-to-image translation (MUNIT, FUNIT, BicycleGAN).\n\nMoreover, there are some simple modifications that can be made to a standard CycleGAN/Pix2pix training pipeline that would facilitate the small number of annotations (for example, see \"Learning image-to-image translation using paired and unpaired training samples\").\n\nIt is hard to evaluate the comparative performance of the method without the comparisons mentioned above.", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory."}, "signatures": ["ICLR.cc/2020/Conference/Paper2009/AnonReviewer4"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper2009/AnonReviewer4"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["d.stoller@qmul.ac.uk", "sewert@spotify.com", "s.e.dixon@qmul.ac.uk"], "title": "Training Generative Adversarial Networks from Incomplete Observations using Factorised Discriminators", "authors": ["Daniel Stoller", "Sebastian Ewert", "Simon Dixon"], "pdf": "/pdf/dd2f617b749f8375bb46bfd434be0338b70e4cd5.pdf", "TL;DR": "We decompose the discriminator in a GAN in a principled way so that each component can be independently trained on different parts of the input. The resulting \"FactorGAN\" can be used for semi-supervised learning and in missing data scenarios.", "abstract": "Generative adversarial networks (GANs) have shown great success in applications such as image generation and inpainting.\nHowever, they typically require large datasets, which are often not available, especially in the context of prediction tasks such as image segmentation that require labels. Therefore, methods such as the CycleGAN use more easily available unlabelled data, but do not offer a way to leverage additional labelled data for improved performance. To address this shortcoming, we show how to factorise the joint data distribution into a set of lower-dimensional distributions along with their dependencies. This allows splitting the discriminator in a GAN into multiple \"sub-discriminators\" that can be independently trained from incomplete observations. Their outputs can be combined to estimate the density ratio between the joint real and the generator distribution, which enables training generators as in the original GAN framework. We apply our method to image generation, image segmentation and audio source separation, and obtain improved performance over a standard GAN when additional incomplete training examples are available. For the Cityscapes segmentation task in particular, our method also improves accuracy by an absolute 14.9% over CycleGAN while using only 25 additional paired examples.", "code": "https://www.dropbox.com/s/gtc7m7pc4n2yt05/source.zip?dl=1", "keywords": ["Adversarial Learning", "Semi-supervised Learning", "Image generation", "Image segmentation", "Missing Data"], "paperhash": "stoller|training_generative_adversarial_networks_from_incomplete_observations_using_factorised_discriminators", "_bibtex": "@inproceedings{\nStoller2020Training,\ntitle={Training Generative Adversarial Networks from Incomplete Observations using Factorised Discriminators},\nauthor={Daniel Stoller and Sebastian Ewert and Simon Dixon},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=Hye1RJHKwB}\n}", "full_presentation_video": "", "original_pdf": "/attachment/858be1a64692ebfcc0ee8131c227274b3ba8b89c.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "Hye1RJHKwB", "replyto": "Hye1RJHKwB", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper2009/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper2009/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1575643160010, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper2009/Reviewers"], "noninvitees": [], "tcdate": 1570237729078, "tmdate": 1575643160024, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper2009/-/Official_Review"}}}, {"id": "SygA0eq1qr", "original": null, "number": 2, "cdate": 1571950805743, "ddate": null, "tcdate": 1571950805743, "tmdate": 1572972394966, "tddate": null, "forum": "Hye1RJHKwB", "replyto": "Hye1RJHKwB", "invitation": "ICLR.cc/2020/Conference/Paper2009/-/Official_Review", "content": {"experience_assessment": "I have read many papers in this area.", "rating": "8: Accept", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #3", "review_assessment:_checking_correctness_of_derivations_and_theory": "I carefully checked the derivations and theory.", "review": "I found this paper very easy and clear to follow - the authors present, what I believe to be an elegant, approach to training a GAN in the presence of missing data or where many marginal samples might be available but very few complete (e.g. paired) samples. The approach proceeds by identifying that the joint distributions (true and approximate) can be factored so as to yield a number of different density ratios which can then be estimated by specific discriminators; in particular, these include the appropriate marginal density ratios and then corresponding overall correction factors. As a caveat to the review I should point out that while I am familiar with GANs, they are not my main area of expertise so this should be taken into consideration - apologies if there is literature I have missed.\n\n\nExperiments: The authors provide a number of illustrative experiments that demonstrate the efficacy of the approach across a number of tasks. There are many differing GAN models but due to the nature of the problem I don't have a big issue with the majority of the comparisons being against a standard GAN since the tasks are suitably designed. For the paired MNIST experiment I found it hard to assess the qualitative results visually and am always concerned about the ad-hoc nature of Inception Distances - I find it difficult to attribute weight to them quantitatively since they are usually being used to assess things where they might suffer from a common error (e.g. they are both based on NNs). Also, I'm not fully on board with the dependency metric in (5) but then the authors also point out the same concerns. The other experiments I found more convincing.\n\nI appreciated having error bars on some of the plots to help assess significance - would it not be possible to put error bars on all plots?\n\nI found the additional extensions presented in the appendix to be interesting ideas as well and would be interested to see how the approach works with other GAN objectives as mentioned for future work.\n\nI am mostly very positive about this work - my main concern is really common to most GANs - all the analysis relies on the premise that the discriminators can be setup as good estimators for the density ratios. We know that this is not always the case since everything comes from samples and if the capacities of each of the discriminators are not set appropriately then I would expect problems to occur - has this been explored by the authors? It would be no detriment to the work to include failure examples where the authors purposefully make use of inappropriate architectures for some of the discriminators to check for this? For example, there will be large imbalances in the number of training samples used for the different discriminators - how does this affect stability?\n\n\nOther notes:\n\n- Whilst I understand the point about independent marginals in 2.4 I'm not sure I see the motivation as clearly since it seems that the model is much more useful when there is dependent information but maybe there's a use-case I'm not thinking of?"}, "signatures": ["ICLR.cc/2020/Conference/Paper2009/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper2009/AnonReviewer3"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["d.stoller@qmul.ac.uk", "sewert@spotify.com", "s.e.dixon@qmul.ac.uk"], "title": "Training Generative Adversarial Networks from Incomplete Observations using Factorised Discriminators", "authors": ["Daniel Stoller", "Sebastian Ewert", "Simon Dixon"], "pdf": "/pdf/dd2f617b749f8375bb46bfd434be0338b70e4cd5.pdf", "TL;DR": "We decompose the discriminator in a GAN in a principled way so that each component can be independently trained on different parts of the input. The resulting \"FactorGAN\" can be used for semi-supervised learning and in missing data scenarios.", "abstract": "Generative adversarial networks (GANs) have shown great success in applications such as image generation and inpainting.\nHowever, they typically require large datasets, which are often not available, especially in the context of prediction tasks such as image segmentation that require labels. Therefore, methods such as the CycleGAN use more easily available unlabelled data, but do not offer a way to leverage additional labelled data for improved performance. To address this shortcoming, we show how to factorise the joint data distribution into a set of lower-dimensional distributions along with their dependencies. This allows splitting the discriminator in a GAN into multiple \"sub-discriminators\" that can be independently trained from incomplete observations. Their outputs can be combined to estimate the density ratio between the joint real and the generator distribution, which enables training generators as in the original GAN framework. We apply our method to image generation, image segmentation and audio source separation, and obtain improved performance over a standard GAN when additional incomplete training examples are available. For the Cityscapes segmentation task in particular, our method also improves accuracy by an absolute 14.9% over CycleGAN while using only 25 additional paired examples.", "code": "https://www.dropbox.com/s/gtc7m7pc4n2yt05/source.zip?dl=1", "keywords": ["Adversarial Learning", "Semi-supervised Learning", "Image generation", "Image segmentation", "Missing Data"], "paperhash": "stoller|training_generative_adversarial_networks_from_incomplete_observations_using_factorised_discriminators", "_bibtex": "@inproceedings{\nStoller2020Training,\ntitle={Training Generative Adversarial Networks from Incomplete Observations using Factorised Discriminators},\nauthor={Daniel Stoller and Sebastian Ewert and Simon Dixon},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=Hye1RJHKwB}\n}", "full_presentation_video": "", "original_pdf": "/attachment/858be1a64692ebfcc0ee8131c227274b3ba8b89c.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "Hye1RJHKwB", "replyto": "Hye1RJHKwB", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper2009/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper2009/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1575643160010, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper2009/Reviewers"], "noninvitees": [], "tcdate": 1570237729078, "tmdate": 1575643160024, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper2009/-/Official_Review"}}}], "count": 8}