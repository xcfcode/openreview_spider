{"notes": [{"id": "Hkl4EANFDH", "original": "SJlN0mUOvS", "number": 1071, "cdate": 1569439275795, "ddate": null, "tcdate": 1569439275795, "tmdate": 1577168291943, "tddate": null, "forum": "Hkl4EANFDH", "replyto": null, "invitation": "ICLR.cc/2020/Conference/-/Blind_Submission", "content": {"authorids": ["pmichel1@cs.cmu.edu", "esalesky@gmail.com", "gneubig@cs.cmu.edu"], "title": "Regularizing Trajectories to Mitigate Catastrophic Forgetting", "authors": ["Paul Michel", "Elisabeth Salesky", "Graham Neubig"], "pdf": "/pdf/b1019731271f19d64c06ef1e0917679d2ec2cba4.pdf", "TL;DR": "Regularizing the optimization trajectory with the Fisher information of old tasks reduces catastrophic forgetting greatly", "abstract": "Regularization-based continual learning approaches generally prevent catastrophic forgetting by augmenting the training loss with an auxiliary objective. However in most practical optimization scenarios with noisy data and/or gradients, it is possible that stochastic gradient descent can inadvertently change critical parameters.\nIn this paper, we argue for the importance of regularizing optimization trajectories directly. We derive a new co-natural gradient update rule for continual learning whereby the new task gradients are preconditioned with the empirical Fisher information of previously learnt tasks. We show that using the co-natural gradient systematically reduces forgetting in continual learning. Moreover, it helps combat overfitting when learning a new task in a low resource scenario.", "keywords": ["Continual Learning", "Regularization", "Adaptation", "Natural Gradient"], "paperhash": "michel|regularizing_trajectories_to_mitigate_catastrophic_forgetting", "original_pdf": "/attachment/9dc9d5286f63fc63503eef46323e1605e0d7735f.pdf", "_bibtex": "@misc{\nmichel2020regularizing,\ntitle={Regularizing Trajectories to Mitigate Catastrophic Forgetting},\nauthor={Paul Michel and Elisabeth Salesky and Graham Neubig},\nyear={2020},\nurl={https://openreview.net/forum?id=Hkl4EANFDH}\n}"}, "signatures": ["ICLR.cc/2020/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference"], "details": {"replyCount": 10, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"reply": {"readers": {"values-regex": ".*"}, "writers": {"values": ["ICLR.cc/2020/Conference"]}, "signatures": {"values": ["ICLR.cc/2020/Conference"]}, "content": {"spotlight_video": {"value-regex": ".*"}, "full_presentation_video": {"value-regex": ".*"}, "original_pdf": {"required": false, "description": "Upload a PDF file that ends with .pdf", "value-regex": ".*"}, "appendix": {"value-regex": ".*"}, "authorids": {"values-regex": ".*"}, "poster": {"value-regex": ".*"}, "authors": {"values": ["Anonymous"]}, "slides": {"value-regex": ".*"}}}, "final": [], "signatures": ["ICLR.cc/2020/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference"], "noninvitees": [], "tcdate": 1569271260237, "tmdate": 1593459412141, "id": "ICLR.cc/2020/Conference/-/Blind_Submission"}}, "tauthor": "OpenReview.net"}, {"id": "QScSo_rdNA", "original": null, "number": 1, "cdate": 1576798713807, "ddate": null, "tcdate": 1576798713807, "tmdate": 1576800922674, "tddate": null, "forum": "Hkl4EANFDH", "replyto": "Hkl4EANFDH", "invitation": "ICLR.cc/2020/Conference/Paper1071/-/Decision", "content": {"decision": "Reject", "comment": "The submission proposes a 'co-natural' gradient update rule to precondition the optimization trajectory using a Fisher information estimate acquired from previous experience. This results in reduced sensitivity and forgetting when new tasks are learned. \n\nThe reviews were mixed on this paper, and unfortunately not all reviewers had enough expertise in the field. After reading the paper carefully, I believe that the paper has significance and relevance to the field of continual learning, however it will benefit from more careful positioning with respect to other work as well as more empirical support. The application to the low-data-regime is interesting and could be expanded and refined in a future submission. \n\nThe recommendation is for rejection.", "title": "Paper Decision"}, "signatures": ["ICLR.cc/2020/Conference/Program_Chairs"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Program_Chairs"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["pmichel1@cs.cmu.edu", "esalesky@gmail.com", "gneubig@cs.cmu.edu"], "title": "Regularizing Trajectories to Mitigate Catastrophic Forgetting", "authors": ["Paul Michel", "Elisabeth Salesky", "Graham Neubig"], "pdf": "/pdf/b1019731271f19d64c06ef1e0917679d2ec2cba4.pdf", "TL;DR": "Regularizing the optimization trajectory with the Fisher information of old tasks reduces catastrophic forgetting greatly", "abstract": "Regularization-based continual learning approaches generally prevent catastrophic forgetting by augmenting the training loss with an auxiliary objective. However in most practical optimization scenarios with noisy data and/or gradients, it is possible that stochastic gradient descent can inadvertently change critical parameters.\nIn this paper, we argue for the importance of regularizing optimization trajectories directly. We derive a new co-natural gradient update rule for continual learning whereby the new task gradients are preconditioned with the empirical Fisher information of previously learnt tasks. We show that using the co-natural gradient systematically reduces forgetting in continual learning. Moreover, it helps combat overfitting when learning a new task in a low resource scenario.", "keywords": ["Continual Learning", "Regularization", "Adaptation", "Natural Gradient"], "paperhash": "michel|regularizing_trajectories_to_mitigate_catastrophic_forgetting", "original_pdf": "/attachment/9dc9d5286f63fc63503eef46323e1605e0d7735f.pdf", "_bibtex": "@misc{\nmichel2020regularizing,\ntitle={Regularizing Trajectories to Mitigate Catastrophic Forgetting},\nauthor={Paul Michel and Elisabeth Salesky and Graham Neubig},\nyear={2020},\nurl={https://openreview.net/forum?id=Hkl4EANFDH}\n}"}, "tags": [], "invitation": {"reply": {"writers": {"description": "How your identity will be displayed.", "values-regex": ["ICLR.cc/2020/Conference/Program_Chairs"]}, "signatures": {"values": ["ICLR.cc/2020/Conference/Program_Chairs"], "description": "How your identity will be displayed."}, "content": {"decision": {"value-radio": ["Accept (Spotlight)", "Accept (Talk)", "Accept (Poster)", "Reject"], "description": "Decision", "required": true, "order": 2}, "title": {"value": "Paper Decision", "required": true, "order": 1}, "comment": {"value-regex": "[\\S\\s]{0,5000}", "description": "", "required": false, "order": 3}}, "forum": "Hkl4EANFDH", "replyto": "Hkl4EANFDH", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}}, "expdate": 1576854540000, "duedate": 1576853940000, "multiReply": false, "readers": ["everyone"], "invitees": ["ICLR.cc/2020/Conference/Program_Chairs"], "tcdate": 1576795721665, "tmdate": 1576800272801, "super": "ICLR.cc/2020/Conference/-/Decision", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper1071/-/Decision"}}}, {"id": "BJx1bKaTFH", "original": null, "number": 3, "cdate": 1571834103367, "ddate": null, "tcdate": 1571834103367, "tmdate": 1574420326223, "tddate": null, "forum": "Hkl4EANFDH", "replyto": "Hkl4EANFDH", "invitation": "ICLR.cc/2020/Conference/Paper1071/-/Official_Review", "content": {"experience_assessment": "I have published one or two papers in this area.", "rating": "6: Weak Accept", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "title": "Official Blind Review #3", "review": "This paper amends the gradient update rule for continual learning using a natural-gradient-style formulation in order to regularise the trajectory during learning to forget previous task(s) less. They show experiments where this 'co-natural gradient' update rule improves some baselines. They also provide experiments showing the benefits of this update rule for low-resource finetuning settings.\n\nAlthough the idea seems reasonable and interesting, I feel like this paper needs work both in the theory and experiments. Figure 1 is a nice visualisation of the key take-away point of the paper.\n\nTheory: the authors take the natural-gradient updates from batch learning and just modify it so that the KL term is now for the previous task(s) instead of the current one. Although this may seem reasonable, I would appreciate some analysis as to what this implies or means.\n\nExperiments: \n- Split CIFAR from Chaudhry et al. (2018b) uses 10 tasks, why does this paper use 20 tasks? \n- Previous works usually find that for EWC, large values of the \\lambda hyperparameter provide best results. This corresponds to lower forgetting of previous tasks. The hyperparameter range in Appendix A.2.3 is only over small values of \\lambda (by orders of magnitude). \n- Why do the authors only allow 1 epoch per task for Split CIFAR? This probably results in early stopping: the new tasks are not able to reach their new optimal points (with or without regularised trajectories). This seems to go against the intuition provided by Figure 1, where the authors are showing that changing the trajectory results in a better local minimum being found. \nIn fact, by adding another regularisation term, it is unsurprising that co-natural gradient updates have less forgetting, as the extra regularisation term probably means the trained parameters are even closer to the previous parameters.\n\n-------------------\nEDIT: Score changed to 'Weak Accept' following discussion with the authors.", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory."}, "signatures": ["ICLR.cc/2020/Conference/Paper1071/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1071/AnonReviewer3"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["pmichel1@cs.cmu.edu", "esalesky@gmail.com", "gneubig@cs.cmu.edu"], "title": "Regularizing Trajectories to Mitigate Catastrophic Forgetting", "authors": ["Paul Michel", "Elisabeth Salesky", "Graham Neubig"], "pdf": "/pdf/b1019731271f19d64c06ef1e0917679d2ec2cba4.pdf", "TL;DR": "Regularizing the optimization trajectory with the Fisher information of old tasks reduces catastrophic forgetting greatly", "abstract": "Regularization-based continual learning approaches generally prevent catastrophic forgetting by augmenting the training loss with an auxiliary objective. However in most practical optimization scenarios with noisy data and/or gradients, it is possible that stochastic gradient descent can inadvertently change critical parameters.\nIn this paper, we argue for the importance of regularizing optimization trajectories directly. We derive a new co-natural gradient update rule for continual learning whereby the new task gradients are preconditioned with the empirical Fisher information of previously learnt tasks. We show that using the co-natural gradient systematically reduces forgetting in continual learning. Moreover, it helps combat overfitting when learning a new task in a low resource scenario.", "keywords": ["Continual Learning", "Regularization", "Adaptation", "Natural Gradient"], "paperhash": "michel|regularizing_trajectories_to_mitigate_catastrophic_forgetting", "original_pdf": "/attachment/9dc9d5286f63fc63503eef46323e1605e0d7735f.pdf", "_bibtex": "@misc{\nmichel2020regularizing,\ntitle={Regularizing Trajectories to Mitigate Catastrophic Forgetting},\nauthor={Paul Michel and Elisabeth Salesky and Graham Neubig},\nyear={2020},\nurl={https://openreview.net/forum?id=Hkl4EANFDH}\n}"}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "Hkl4EANFDH", "replyto": "Hkl4EANFDH", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper1071/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper1071/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1575508060321, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper1071/Reviewers"], "noninvitees": [], "tcdate": 1570237742785, "tmdate": 1575508060335, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper1071/-/Official_Review"}}}, {"id": "ryxtooH2jS", "original": null, "number": 9, "cdate": 1573833632894, "ddate": null, "tcdate": 1573833632894, "tmdate": 1573833632894, "tddate": null, "forum": "Hkl4EANFDH", "replyto": "B1lrIXGooB", "invitation": "ICLR.cc/2020/Conference/Paper1071/-/Official_Comment", "content": {"title": "Response to Reviewer #3", "comment": "Many thanks to the reviewer for taking the time to read and respond to our rebuttal. Here is our response to the concerns listed above.\n\n> Re theory: I would have liked to see some analysis, if possible, about adding this specific KL term to the Lagrangian. I only say this because the idea seems very similar to previous natural-gradient literature, and therefore there might be something you can say / derive theoretically. I understand the intuitive explanation for adding this term. Of course, it may not be possible to say anything more theoretically.\n\nAs far as we understand it, the reviewer is asking for some sort of convergence guarantees or Fisher efficiency results in the vein of Amari et al. (1998) (\"Natural Gradient Works Efficiently in Learning\"). We have no such result as of now. The strongest guarantee we can give is that in the case of a fixed, positive definite Fisher, the co-natural gradient is guaranteed to converge in the convex case (since we are merely preconditioning with a fixed matrix).\n\n> Re experiments: Thank you for clarifying about EWC, and apologies for missing the 20 task definition of split CIFAR in Chaudhry et al. (2018b). My concerns about 1 epoch still remain, however. A-GEM is designed for the setting where data is only visited once (1 epoch), whereas EWC (as well as many other methods) are designed for the case where there can be multiple epochs per task. See Appendix F in their paper where they show EWC performing better as the number of epochs is increased.\n>\n> I do not actually see any reason why the co-natural gradient update should do worse if trained for many more epochs. My intuition tells me that it could/should reach a better optimal solution ('better' = for continual learning). But my concern is that 1 epoch is not enough to let it reach a local minimum, therefore reducing the conclusions that can be drawn from the experiment. That being said, I am aware this does not impact your other results. How many epochs do you use for the new results on Split MiniImageNet?\n\nWe understand the reviewer's point with respect to convergence and the number of epochs (and we agree that the co-natural gradient is not expected to be \"worse\" if trained for longer --- barring the problem of the validity of our assumption on a static Fisher --- we simply meant to emphasize that regularizing the trajectory directly is likely to help at any stage of the optimization process).\n\nIndeed, both our Omniglot and MiniImageNet experiments are run for more epochs (Omniglot for 2500 steps: ~=150-250 epochs depending on the alphabet and MiniImageNet for 500 steps, ~= 5.5 epochs per tasks). We take this as evidence that the co-natural gradient helps both when the model has converged (MiniImageNet, Omniglot) or not (CIFAR).\n\n> Re re-normalizing the co-natural gradient norm: I am struggling to understand why this is important. Does the method essentially fail without this, even if you increase alpha? I would have hoped that the form of the update (without re-normalizing) was good enough itself. I would have expected that if some parameter updates were too large (because they have little to no effect on the KL divergence), then increasing alpha would ensure the update size is still of reasonable magnitude.\n\nYes, we found this to be important for the co-natural gradient to succeed. The main reason is as follow: the reviewer is correct that increasing the damping coefficient should in principle keep \"almost-zero\" parameters of the Fisher under control. However, higher alpha is also confounded with a \"smoothing\" effect on the Fisher: the ratio between any two diagonal elements becomes closer to 1 as alpha increases. This smooths over the relative importance of different parameters. Thus, higher alpha leads to better behaved update but to lesser regularization. On the other hand, re-normalizing decouples damping (control of the amount of regularization <=> the relative learning rate of any two parameter) and update size (now entirely controlled by the learning rate and the norm of the original gradient).\n\nPerhaps a more elegant solution would have been to solve the Lagrangian on a hypersphere of fixed radius (=the desired norm $\\Vert \\nabla L_T \\Vert$). This can be shown to yield an update of the form $\\delta^*\\propto -[F+\\eta(\\nabla L_T)I]^{-1}\\nabla L_T$ where importantly the damping coefficient $\\eta(\\nabla L)$ is a function of the gradient $\\nabla L_T$. As far as we know there is no closed form solution for $\\eta$, and finding it iteratively would add a non-negligible computational overhead, hence our decision to use the renormalization approach.\n"}, "signatures": ["ICLR.cc/2020/Conference/Paper1071/Authors"], "readers": ["everyone", "ICLR.cc/2020/Conference/Paper1071/Reviewers", "ICLR.cc/2020/Conference/Paper1071/Area_Chairs"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1071/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["pmichel1@cs.cmu.edu", "esalesky@gmail.com", "gneubig@cs.cmu.edu"], "title": "Regularizing Trajectories to Mitigate Catastrophic Forgetting", "authors": ["Paul Michel", "Elisabeth Salesky", "Graham Neubig"], "pdf": "/pdf/b1019731271f19d64c06ef1e0917679d2ec2cba4.pdf", "TL;DR": "Regularizing the optimization trajectory with the Fisher information of old tasks reduces catastrophic forgetting greatly", "abstract": "Regularization-based continual learning approaches generally prevent catastrophic forgetting by augmenting the training loss with an auxiliary objective. However in most practical optimization scenarios with noisy data and/or gradients, it is possible that stochastic gradient descent can inadvertently change critical parameters.\nIn this paper, we argue for the importance of regularizing optimization trajectories directly. We derive a new co-natural gradient update rule for continual learning whereby the new task gradients are preconditioned with the empirical Fisher information of previously learnt tasks. We show that using the co-natural gradient systematically reduces forgetting in continual learning. Moreover, it helps combat overfitting when learning a new task in a low resource scenario.", "keywords": ["Continual Learning", "Regularization", "Adaptation", "Natural Gradient"], "paperhash": "michel|regularizing_trajectories_to_mitigate_catastrophic_forgetting", "original_pdf": "/attachment/9dc9d5286f63fc63503eef46323e1605e0d7735f.pdf", "_bibtex": "@misc{\nmichel2020regularizing,\ntitle={Regularizing Trajectories to Mitigate Catastrophic Forgetting},\nauthor={Paul Michel and Elisabeth Salesky and Graham Neubig},\nyear={2020},\nurl={https://openreview.net/forum?id=Hkl4EANFDH}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "Hkl4EANFDH", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper1071/Authors", "ICLR.cc/2020/Conference/Paper1071/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper1071/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper1071/Reviewers", "ICLR.cc/2020/Conference/Paper1071/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper1071/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper1071/Authors|ICLR.cc/2020/Conference/Paper1071/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504161706, "tmdate": 1576860530486, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper1071/Authors", "ICLR.cc/2020/Conference/Paper1071/Reviewers", "ICLR.cc/2020/Conference/Paper1071/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper1071/-/Official_Comment"}}}, {"id": "B1lrIXGooB", "original": null, "number": 8, "cdate": 1573753677394, "ddate": null, "tcdate": 1573753677394, "tmdate": 1573753677394, "tddate": null, "forum": "Hkl4EANFDH", "replyto": "B1gs04aIiS", "invitation": "ICLR.cc/2020/Conference/Paper1071/-/Official_Comment", "content": {"title": "Response to authors", "comment": "Many thanks for your response. You have cleared up some questions I had. I still wonder about a few things.\n\nRe theory: I would have liked to see some analysis, if possible, about adding this specific KL term to the Lagrangian. I only say this because the idea seems very similar to previous natural-gradient literature, and therefore there might be something you can say / derive theoretically. I understand the intuitive explanation for adding this term. Of course, it may not be possible to say anything more theoretically.\n\nRe experiments: Thank you for clarifying about EWC, and apologies for missing the 20 task definition of split CIFAR in Chaudhry et al. (2018b). My concerns about 1 epoch still remain, however. A-GEM is designed for the setting where data is only visited once (1 epoch), whereas EWC (as well as many other methods) are designed for the case where there can be multiple epochs per task. See Appendix F in their paper where they show EWC performing better as the number of epochs is increased.\n\nI do not actually see any reason why the co-natural gradient update should do worse if trained for many more epochs. My intuition tells me that it could/should reach a better optimal solution ('better' = for continual learning). But my concern is that 1 epoch is not enough to let it reach a local minimum, therefore reducing the conclusions that can be drawn from the experiment. That being said, I am aware this does not impact your other results. How many epochs do you use for the new results on Split MiniImageNet?\n\nRe re-normalising the co-natural gradient norm: I am struggling to understand why this is important. Does the method essentially fail without this, even if you increase alpha? I would have hoped that the form of the update (without renormalising) was good enough itself. I would have expected that if some parameter updates were too large (because they have little to no effect on the KL divergence), then increasing alpha would ensure the update size is still of reasonable magnitude."}, "signatures": ["ICLR.cc/2020/Conference/Paper1071/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1071/AnonReviewer3", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["pmichel1@cs.cmu.edu", "esalesky@gmail.com", "gneubig@cs.cmu.edu"], "title": "Regularizing Trajectories to Mitigate Catastrophic Forgetting", "authors": ["Paul Michel", "Elisabeth Salesky", "Graham Neubig"], "pdf": "/pdf/b1019731271f19d64c06ef1e0917679d2ec2cba4.pdf", "TL;DR": "Regularizing the optimization trajectory with the Fisher information of old tasks reduces catastrophic forgetting greatly", "abstract": "Regularization-based continual learning approaches generally prevent catastrophic forgetting by augmenting the training loss with an auxiliary objective. However in most practical optimization scenarios with noisy data and/or gradients, it is possible that stochastic gradient descent can inadvertently change critical parameters.\nIn this paper, we argue for the importance of regularizing optimization trajectories directly. We derive a new co-natural gradient update rule for continual learning whereby the new task gradients are preconditioned with the empirical Fisher information of previously learnt tasks. We show that using the co-natural gradient systematically reduces forgetting in continual learning. Moreover, it helps combat overfitting when learning a new task in a low resource scenario.", "keywords": ["Continual Learning", "Regularization", "Adaptation", "Natural Gradient"], "paperhash": "michel|regularizing_trajectories_to_mitigate_catastrophic_forgetting", "original_pdf": "/attachment/9dc9d5286f63fc63503eef46323e1605e0d7735f.pdf", "_bibtex": "@misc{\nmichel2020regularizing,\ntitle={Regularizing Trajectories to Mitigate Catastrophic Forgetting},\nauthor={Paul Michel and Elisabeth Salesky and Graham Neubig},\nyear={2020},\nurl={https://openreview.net/forum?id=Hkl4EANFDH}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "Hkl4EANFDH", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper1071/Authors", "ICLR.cc/2020/Conference/Paper1071/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper1071/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper1071/Reviewers", "ICLR.cc/2020/Conference/Paper1071/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper1071/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper1071/Authors|ICLR.cc/2020/Conference/Paper1071/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504161706, "tmdate": 1576860530486, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper1071/Authors", "ICLR.cc/2020/Conference/Paper1071/Reviewers", "ICLR.cc/2020/Conference/Paper1071/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper1071/-/Official_Comment"}}}, {"id": "HygoSO6Lor", "original": null, "number": 3, "cdate": 1573472323307, "ddate": null, "tcdate": 1573472323307, "tmdate": 1573476771841, "tddate": null, "forum": "Hkl4EANFDH", "replyto": "Hyxd4ffhFr", "invitation": "ICLR.cc/2020/Conference/Paper1071/-/Official_Comment", "content": {"title": "Response to Reviewer #2", "comment": "We thank the reviewer for their comments. See our top-level comment for a summary of the main points and updates to the paper. We respond to specific points in the review below:\n\n> [Model] After surveying previous work, I am not sure if the paper is really novel: \n> First of all, adding KL-based constrains to alleviate model forgetting has already been widely explored in prior arts, as the authors also acknowledged in the paper. The proposed regularizer has a close relationship with the EWC, especially with the EWC++. \n\nFirst, let us state that the relationship and differences with EWC are clearly stated in the paper (section 4.1): \u201cit is a natural baseline for us to compare to in that it also consists in a Fisher-based penalty --- although in the loss function instead of the optimization dynamics\u201d.\n\nRegarding EWC+++, we would like to apologize for an omission in the paper that likely led to confusion. In our EWC experiments, we use the same rolling Fisher described in section 3.4. This makes our EWC implementation equivalent to the online-EWC introduced by Schwartz et al. (2018). The paper was updated to reflect this. Now as we understand it from Chaudhry et al. (2018a), EWC++ differs from EWC in two ways:\n- Use of only one, rolling Fisher for computing the l2 penalty (which is what we, and online-EWC also do)\n- Compute the Fisher for a task in an online. This is justified by the setting in Chaudhry et al. (2018a) where the model can only see the data once. However, we place no such restriction in our experiments, and as such it is strictly better to compute the Fisher for a given task after training on this task has finished, which we and online-EWC do.\n\n>EWC++ encourages the KL-divergence between two distributions learned at successive tasks to be minimized, while the authors proposed to regularize the KL-divergence between two nearby updates, which leads to the well-known natural gradient descent.\n\nOur method does not just regularize the KL between two nearby update like the natural gradient. We quote the end of section 3.3 to highlight the difference:\n\n\u201cThere is a however a crucial difference, both in execution and purpose: where the natural gradient uses knowledge of the curvature of the KL divergence of $\\mathcal{D}_T$ to \\emph{speed-up} convergence, our proposed method leverages the curvature of the KL divergence on $\\mathcal{D}_S$ to \\emph{slow-down} divergence from $p^S_{\\theta_S}$.\u201d\n\nIn particular the KL is taken between distributions over the past tasks which is not the case for the natural gradient.\n\n> The authors [...] proposed to use a static Fisher estimated at the previous task for fast approximation. However, the approximation makes the algorithm not a natural gradient descent approach, nor a valid KL-regularized optimization problem.\n\nWhile this is certainly true, this approximation is shared with the large majority of previous work using the Fisher for continual learning, including EWC (Kirkpatrick et al., 2017) EWC++ (Chaudhry et al, 2018a) and online-EWC (Schwartz et al., 2018).\n\n> The theoretical implications of the static Fisher approximation are not discussed in the paper.\n\nWe clarify this in our revised version: this approximation is only valid insofar as we are staying close to the original parameters. As per our experimental results, this approximation still leads to good results empirically. Finally we would like to reiterate that this approximation is found in related work as well (EWC, EWC++, online-EWC...).\n\n> [Experiments] The authors may consider comparing with EWC++, which is a closely related baseline. \n\nSee our comment above, our EWC baseline actually uses the rolling Fisher described in sec. 3.4, thus making it equivalent to the \u201conline-EWC\u201d described in Schwartz et al. (2018). Apologies for the omission, this is clarified in the text now.\n\n> Still, it would be much better to see how it can help more state-of-the-art methods like LwM, LwF, etc, and especially on a few more challenging datasets.\n\nWe would argue that LwF (2016) is not a state of the art approach, in fact Schwartz et al. (2018) show that it is inferior to online-EWC (one of our baselines). We thank the reviewer for bringing up LwM to our attention. While it seems like this approach was mostly intended for class incremental learning, a slightly different problem that the one considered in our experiments, we have updated our submission to cite it. Last but not least we emphasize that our ER baseline from Chaudhry et al. (2019) is a very recent approach, shown to be SOTA compared to a variety of other methods.\n\nRegarding more challenging datasets, we have added results for MiniImageNet to the paper, with similar results. While we are limited by the time alloted to author discussion, we are open to suggestions from the reviewer. We also refer to section 5, where we perform experiments on more realistic settings (MiniImageNet -> CUB and machine translation experiments).\n\nEDIT: fixed title to \"Reviewer #2\""}, "signatures": ["ICLR.cc/2020/Conference/Paper1071/Authors"], "readers": ["everyone", "ICLR.cc/2020/Conference/Paper1071/Reviewers", "ICLR.cc/2020/Conference/Paper1071/Area_Chairs"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1071/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["pmichel1@cs.cmu.edu", "esalesky@gmail.com", "gneubig@cs.cmu.edu"], "title": "Regularizing Trajectories to Mitigate Catastrophic Forgetting", "authors": ["Paul Michel", "Elisabeth Salesky", "Graham Neubig"], "pdf": "/pdf/b1019731271f19d64c06ef1e0917679d2ec2cba4.pdf", "TL;DR": "Regularizing the optimization trajectory with the Fisher information of old tasks reduces catastrophic forgetting greatly", "abstract": "Regularization-based continual learning approaches generally prevent catastrophic forgetting by augmenting the training loss with an auxiliary objective. However in most practical optimization scenarios with noisy data and/or gradients, it is possible that stochastic gradient descent can inadvertently change critical parameters.\nIn this paper, we argue for the importance of regularizing optimization trajectories directly. We derive a new co-natural gradient update rule for continual learning whereby the new task gradients are preconditioned with the empirical Fisher information of previously learnt tasks. We show that using the co-natural gradient systematically reduces forgetting in continual learning. Moreover, it helps combat overfitting when learning a new task in a low resource scenario.", "keywords": ["Continual Learning", "Regularization", "Adaptation", "Natural Gradient"], "paperhash": "michel|regularizing_trajectories_to_mitigate_catastrophic_forgetting", "original_pdf": "/attachment/9dc9d5286f63fc63503eef46323e1605e0d7735f.pdf", "_bibtex": "@misc{\nmichel2020regularizing,\ntitle={Regularizing Trajectories to Mitigate Catastrophic Forgetting},\nauthor={Paul Michel and Elisabeth Salesky and Graham Neubig},\nyear={2020},\nurl={https://openreview.net/forum?id=Hkl4EANFDH}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "Hkl4EANFDH", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper1071/Authors", "ICLR.cc/2020/Conference/Paper1071/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper1071/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper1071/Reviewers", "ICLR.cc/2020/Conference/Paper1071/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper1071/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper1071/Authors|ICLR.cc/2020/Conference/Paper1071/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504161706, "tmdate": 1576860530486, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper1071/Authors", "ICLR.cc/2020/Conference/Paper1071/Reviewers", "ICLR.cc/2020/Conference/Paper1071/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper1071/-/Official_Comment"}}}, {"id": "rye67npUoS", "original": null, "number": 4, "cdate": 1573473316595, "ddate": null, "tcdate": 1573473316595, "tmdate": 1573473316595, "tddate": null, "forum": "Hkl4EANFDH", "replyto": "Hkl4EANFDH", "invitation": "ICLR.cc/2020/Conference/Paper1071/-/Official_Comment", "content": {"title": "Paper updates", "comment": "We thank all reviewers for their valuable feedback. We have responded to most comments individually. The paper has been updated to include:\n\n- A clarification that our EWC baseline coincides with online EWC (Schwarz et al. 2018): We keep only one rolling Fisher for EWC, which we update at the end of each task's training. We believe that this addresses most comments regarding a stronger EWC baseline.\n- Clarify that we renormalize the Fisher so that the average diagonal element has magnitude ~= 1. This explains our choice of hyper-parameters for EWC.\n- Additional continual learning experiments on MiniImageNet: this is to provide experiments on a more challenging dataset. We observe similar conclusions as on Split CIFAR and Omniglot\n- Clarification on when the static Fisher approximation is expected to hold, and a note on its ubiquity in the related literature\n"}, "signatures": ["ICLR.cc/2020/Conference/Paper1071/Authors"], "readers": ["everyone", "ICLR.cc/2020/Conference/Paper1071/Reviewers", "ICLR.cc/2020/Conference/Paper1071/Area_Chairs"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1071/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["pmichel1@cs.cmu.edu", "esalesky@gmail.com", "gneubig@cs.cmu.edu"], "title": "Regularizing Trajectories to Mitigate Catastrophic Forgetting", "authors": ["Paul Michel", "Elisabeth Salesky", "Graham Neubig"], "pdf": "/pdf/b1019731271f19d64c06ef1e0917679d2ec2cba4.pdf", "TL;DR": "Regularizing the optimization trajectory with the Fisher information of old tasks reduces catastrophic forgetting greatly", "abstract": "Regularization-based continual learning approaches generally prevent catastrophic forgetting by augmenting the training loss with an auxiliary objective. However in most practical optimization scenarios with noisy data and/or gradients, it is possible that stochastic gradient descent can inadvertently change critical parameters.\nIn this paper, we argue for the importance of regularizing optimization trajectories directly. We derive a new co-natural gradient update rule for continual learning whereby the new task gradients are preconditioned with the empirical Fisher information of previously learnt tasks. We show that using the co-natural gradient systematically reduces forgetting in continual learning. Moreover, it helps combat overfitting when learning a new task in a low resource scenario.", "keywords": ["Continual Learning", "Regularization", "Adaptation", "Natural Gradient"], "paperhash": "michel|regularizing_trajectories_to_mitigate_catastrophic_forgetting", "original_pdf": "/attachment/9dc9d5286f63fc63503eef46323e1605e0d7735f.pdf", "_bibtex": "@misc{\nmichel2020regularizing,\ntitle={Regularizing Trajectories to Mitigate Catastrophic Forgetting},\nauthor={Paul Michel and Elisabeth Salesky and Graham Neubig},\nyear={2020},\nurl={https://openreview.net/forum?id=Hkl4EANFDH}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "Hkl4EANFDH", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper1071/Authors", "ICLR.cc/2020/Conference/Paper1071/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper1071/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper1071/Reviewers", "ICLR.cc/2020/Conference/Paper1071/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper1071/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper1071/Authors|ICLR.cc/2020/Conference/Paper1071/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504161706, "tmdate": 1576860530486, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper1071/Authors", "ICLR.cc/2020/Conference/Paper1071/Reviewers", "ICLR.cc/2020/Conference/Paper1071/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper1071/-/Official_Comment"}}}, {"id": "HJe47LaIiH", "original": null, "number": 2, "cdate": 1573471771857, "ddate": null, "tcdate": 1573471771857, "tmdate": 1573471771857, "tddate": null, "forum": "Hkl4EANFDH", "replyto": "rkeTDi2TYB", "invitation": "ICLR.cc/2020/Conference/Paper1071/-/Official_Comment", "content": {"title": "Response to Reviewer #1", "comment": "We thank the reviewer for their comments. See our top-level comment for a summary of the main points and updates to the paper. We respond to specific points in the review below:\n\n> I think that the performance of finetuning + co-gradient is too natural, and not much meaningful.\n\nWe are not entirely sure of what the reviewer means with this statement. Surely it is natural that a method designed to reduce catastrophic forgetting indeed improves performance in continual learning. We respectfully but firmly disagree with the reviewer that the fact that the proposed approach is simple or natural means that it is \u201cnot much meaningful\u201d. In our opinion the simplicity of the proposed approach is a strength, not a weakness.\n\n\n> And the tradeoff between accuracy and forgetting for baselines is hard to compare on table 1 since the tradeoff depends on the hyperparameters.\n\nWe argue (we think, in line with Chaudhry et. al (2018b) and follow-up work) that comparing these results with different sets of hyper-parameters chosen with grid-search makes for a *better* comparison. Indeed, we are comparing the best set of hyper-parameters (as chosen by our validation procedure) for each method. For a more exhaustive exploration of the trade-off for EWC and co-natural fine-tuning (albeit in a slightly different setting), we refer to Section 5\n\n> And it is required to apply on heterogeneous datasets to evaluate the performance when problems are really different. (like MNIST->CIFAR100->Omniglot->Imagenet, and so on). In the paper, the experiments are performed on very similar problems (split a single dataset).\n\nFirst and foremost, most recent continual learning work uses the datasets that we used or even less realistic datasets (permuted MNIST...). The reason we do this is that this is an easy way to get 1. Many tasks (so we can test for long term forgetting) and 2. Tasks that are of similar difficulty (the impact of task ordering is limited).\nWith only 4 tasks (MNIST->CIFAR100->Omniglot->Imagenet) we encounter other issues: too few tasks to perform grid search on a subset of tasks, curriculum effect (learning Imagenet and then MNIST vs MNIST then imagenet), different data size, etc\u2026 overall we believe that this is a valid criticism but it is more addressed to the current literature on CL than this paper specifically.\n\nFinally note that, albeit in a different setting, Section 5 provides examples of adapting to different, more heterogeneous datasets.\n\n>Also, it would be great to show an illustration like figure 1, on real dataset, like split CIFAR.\n\nWe are not entirely sure what the reviewer has in mind. Given that in that case the dimension of the parameter space is of the order of the millions, such a representation (projected in 2d) is unlikely to be meaningful. We are open to suggestions.\n"}, "signatures": ["ICLR.cc/2020/Conference/Paper1071/Authors"], "readers": ["everyone", "ICLR.cc/2020/Conference/Paper1071/Reviewers", "ICLR.cc/2020/Conference/Paper1071/Area_Chairs"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1071/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["pmichel1@cs.cmu.edu", "esalesky@gmail.com", "gneubig@cs.cmu.edu"], "title": "Regularizing Trajectories to Mitigate Catastrophic Forgetting", "authors": ["Paul Michel", "Elisabeth Salesky", "Graham Neubig"], "pdf": "/pdf/b1019731271f19d64c06ef1e0917679d2ec2cba4.pdf", "TL;DR": "Regularizing the optimization trajectory with the Fisher information of old tasks reduces catastrophic forgetting greatly", "abstract": "Regularization-based continual learning approaches generally prevent catastrophic forgetting by augmenting the training loss with an auxiliary objective. However in most practical optimization scenarios with noisy data and/or gradients, it is possible that stochastic gradient descent can inadvertently change critical parameters.\nIn this paper, we argue for the importance of regularizing optimization trajectories directly. We derive a new co-natural gradient update rule for continual learning whereby the new task gradients are preconditioned with the empirical Fisher information of previously learnt tasks. We show that using the co-natural gradient systematically reduces forgetting in continual learning. Moreover, it helps combat overfitting when learning a new task in a low resource scenario.", "keywords": ["Continual Learning", "Regularization", "Adaptation", "Natural Gradient"], "paperhash": "michel|regularizing_trajectories_to_mitigate_catastrophic_forgetting", "original_pdf": "/attachment/9dc9d5286f63fc63503eef46323e1605e0d7735f.pdf", "_bibtex": "@misc{\nmichel2020regularizing,\ntitle={Regularizing Trajectories to Mitigate Catastrophic Forgetting},\nauthor={Paul Michel and Elisabeth Salesky and Graham Neubig},\nyear={2020},\nurl={https://openreview.net/forum?id=Hkl4EANFDH}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "Hkl4EANFDH", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper1071/Authors", "ICLR.cc/2020/Conference/Paper1071/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper1071/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper1071/Reviewers", "ICLR.cc/2020/Conference/Paper1071/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper1071/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper1071/Authors|ICLR.cc/2020/Conference/Paper1071/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504161706, "tmdate": 1576860530486, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper1071/Authors", "ICLR.cc/2020/Conference/Paper1071/Reviewers", "ICLR.cc/2020/Conference/Paper1071/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper1071/-/Official_Comment"}}}, {"id": "B1gs04aIiS", "original": null, "number": 1, "cdate": 1573471443214, "ddate": null, "tcdate": 1573471443214, "tmdate": 1573471443214, "tddate": null, "forum": "Hkl4EANFDH", "replyto": "BJx1bKaTFH", "invitation": "ICLR.cc/2020/Conference/Paper1071/-/Official_Comment", "content": {"title": "Response to Reviewer #3", "comment": "We thank the reviewer for their comments. See our top-level comment for a summary of the main points and updates to the paper. We respond to specific points in the review below:\n\n> Theory: the authors take the natural-gradient updates from batch learning and just modify it so that the KL term is now for the previous task(s) instead of the current one. Although this may seem reasonable, I would appreciate some analysis as to what this implies or means.\n\nAs made explicit in Section 3.2 of the paper:\n\n\u201c In a continual learning setting [...], the quantity we are most interested in preserving is the probability distribution that \u03b8 models on the source task S [...]. Therefore, a  more natural distance between \u03b8 and \u03b8+\u03b4 is the Kullback-Leibler divergence\u201d\n\nApplying a KL penalty in the Lagrangian from equation (2) will encourage the updates to be selected to as to preserve the distribution induced by the model on past tasks (and as a proxy, its performance). Let us know if there is anything more we can add to clarify what this implies or mean.\n\n>Experiments:\n>  - Split CIFAR from Chaudhry et al. (2018b) uses 10 tasks, why does this paper use 20 tasks?\n\nQuoting Chaudhry et al. (2018b): \u201cSplit CIFAR (Zenke et al., 2017) consists of splitting the original CIFAR-100 dataset (Krizhevsky & Hinton, 2009) into 20 disjoint subsets [...]\u201d. See https://arxiv.org/pdf/1812.00420.pdf\n\n>  - Previous works usually find that for EWC, large values of the \\lambda hyperparameter provide best results. This corresponds to lower forgetting of previous tasks. The hyperparameter range in Appendix A.2.3 is only over small values of \\lambda (by orders of magnitude).\n\nIn all our experiments, we renormalize the fisher so that it sums up to #params. This is to make the average value of the diagonal elements independent of the size of the model, easing hyper-parameter selection across models. In particular this means that the average magnitude of our fisher weights is much higher. As a consequence, we can get away with ranges of EWC regularization that are much smaller than what is usual in the literature. This was omitted in the original version, and we have amended the paper to make it clear (Appendix A.2.2). That being said, we have run additional experiments with EWC regularization values 10 and 50 for split CIFAR and found that grid search never prefers these values over the ones in {5, 1, 0.5}.\n\n> - Why do the authors only allow 1 epoch per task for Split CIFAR? This probably results in early stopping: the new tasks are not able to reach their new optimal points (with or without regularised trajectories). This seems to go against the intuition provided by Figure 1, where the authors are showing that changing the trajectory results in a better local minimum being found. \n\nWe follow Chaudhry et al (2018b). Note that the batch size is relatively small (10), so we are performing as many updates than as if we were training for 3 epochs with batch size 32. Moreover is not at odds with the intuition in figure 1: especially if optimization does not converge, following the trajectory that hurts previously learnt tasks the least is advantageous. This can be seen in Figure 1 by the fact that the co-natural trajectory tends to follow a path where the loss on T1 increases much more slowly.\n\n> In fact, by adding another regularisation term, it is unsurprising that co-natural gradient updates have less forgetting, as the extra regularisation term probably means the trained parameters are even closer to the previous parameters.\n\nWhile the reviewer is correct that the positive effect of adding the co-natural gradient is not unexpected, we feel like their statement is dismissive of the three following points:\n - The co-natural gradient leads to lower forgetting than the two other approaches on its own. Thus, it is not just any regularization term, rather it is the one that leads to the least forgetting.\n - The co-natural gradient alone is still competitive or even better (see Omniglot) than the other methods, in terms of average accuracy.\n - The co-natural gradient requires strictly less resources than EWC (need the Fisher and the previous parameters) or ER (need access to data from previous tasks). We only require the Fisher\n\nFinally, let us note that the co-natural gradient does not explicitly encourage parameters to stay close to the original parameters (like EWC does). In fact, as mentioned in section 3.3, we re-normalize the co-natural gradient to the same norm as the standard gradient: the co-natural gradient does not change the magnitude of the updates, rather their direction.\n"}, "signatures": ["ICLR.cc/2020/Conference/Paper1071/Authors"], "readers": ["everyone", "ICLR.cc/2020/Conference/Paper1071/Reviewers", "ICLR.cc/2020/Conference/Paper1071/Area_Chairs"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1071/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["pmichel1@cs.cmu.edu", "esalesky@gmail.com", "gneubig@cs.cmu.edu"], "title": "Regularizing Trajectories to Mitigate Catastrophic Forgetting", "authors": ["Paul Michel", "Elisabeth Salesky", "Graham Neubig"], "pdf": "/pdf/b1019731271f19d64c06ef1e0917679d2ec2cba4.pdf", "TL;DR": "Regularizing the optimization trajectory with the Fisher information of old tasks reduces catastrophic forgetting greatly", "abstract": "Regularization-based continual learning approaches generally prevent catastrophic forgetting by augmenting the training loss with an auxiliary objective. However in most practical optimization scenarios with noisy data and/or gradients, it is possible that stochastic gradient descent can inadvertently change critical parameters.\nIn this paper, we argue for the importance of regularizing optimization trajectories directly. We derive a new co-natural gradient update rule for continual learning whereby the new task gradients are preconditioned with the empirical Fisher information of previously learnt tasks. We show that using the co-natural gradient systematically reduces forgetting in continual learning. Moreover, it helps combat overfitting when learning a new task in a low resource scenario.", "keywords": ["Continual Learning", "Regularization", "Adaptation", "Natural Gradient"], "paperhash": "michel|regularizing_trajectories_to_mitigate_catastrophic_forgetting", "original_pdf": "/attachment/9dc9d5286f63fc63503eef46323e1605e0d7735f.pdf", "_bibtex": "@misc{\nmichel2020regularizing,\ntitle={Regularizing Trajectories to Mitigate Catastrophic Forgetting},\nauthor={Paul Michel and Elisabeth Salesky and Graham Neubig},\nyear={2020},\nurl={https://openreview.net/forum?id=Hkl4EANFDH}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "Hkl4EANFDH", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper1071/Authors", "ICLR.cc/2020/Conference/Paper1071/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper1071/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper1071/Reviewers", "ICLR.cc/2020/Conference/Paper1071/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper1071/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper1071/Authors|ICLR.cc/2020/Conference/Paper1071/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504161706, "tmdate": 1576860530486, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper1071/Authors", "ICLR.cc/2020/Conference/Paper1071/Reviewers", "ICLR.cc/2020/Conference/Paper1071/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper1071/-/Official_Comment"}}}, {"id": "Hyxd4ffhFr", "original": null, "number": 1, "cdate": 1571721776033, "ddate": null, "tcdate": 1571721776033, "tmdate": 1572972516476, "tddate": null, "forum": "Hkl4EANFDH", "replyto": "Hkl4EANFDH", "invitation": "ICLR.cc/2020/Conference/Paper1071/-/Official_Review", "content": {"experience_assessment": "I have read many papers in this area.", "rating": "1: Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #2", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "The paper puts forward a new regularization based continual learning method that explicitly regularizes the optimization trajectory by constraining in the distribution space. The paper is well written, and preliminary empirical results are promising. \n \n[Model]\n After surveying previous work, I am not sure if the paper is really novel: \n\nFirst of all, adding KL-based constrains to alleviate model forgetting has already been widely explored in prior arts, as the authors also acknowledged in the paper. The proposed regularizer has a close relationship with the EWC, especially with the EWC++. EWC++ encourages the KL-divergence between two distributions learned at successive tasks to be minimized, while the authors proposed to regularize the KL-divergence between two nearby updates, which leads to the well-known natural gradient descent.\n\nNatural gradient updates require to calculate the Fisher based on the current curvature, which is computationally expensive in practice. The authors further proposed to use a static Fisher estimated at the previous task for fast approximation. However, the approximation makes the algorithm not a natural gradient descent approach, nor a valid KL-regularized optimization problem. The theoretical implications of the static Fisher approximation are not discussed in the paper.\n \n[Experiments]\nThe authors may consider comparing with EWC++, which is a closely related baseline. \nThe experiment results have shown that the co-nature gradient method help from time to time. Understandably, the co-nature gradient-based optimization has the add-on benefit for any continual learning tasks. Still, it would be much better to see how it can help more state-of-the-art methods like LwM, LwF, etc, and especially on a few more challenging datasets.\n\n"}, "signatures": ["ICLR.cc/2020/Conference/Paper1071/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1071/AnonReviewer2"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["pmichel1@cs.cmu.edu", "esalesky@gmail.com", "gneubig@cs.cmu.edu"], "title": "Regularizing Trajectories to Mitigate Catastrophic Forgetting", "authors": ["Paul Michel", "Elisabeth Salesky", "Graham Neubig"], "pdf": "/pdf/b1019731271f19d64c06ef1e0917679d2ec2cba4.pdf", "TL;DR": "Regularizing the optimization trajectory with the Fisher information of old tasks reduces catastrophic forgetting greatly", "abstract": "Regularization-based continual learning approaches generally prevent catastrophic forgetting by augmenting the training loss with an auxiliary objective. However in most practical optimization scenarios with noisy data and/or gradients, it is possible that stochastic gradient descent can inadvertently change critical parameters.\nIn this paper, we argue for the importance of regularizing optimization trajectories directly. We derive a new co-natural gradient update rule for continual learning whereby the new task gradients are preconditioned with the empirical Fisher information of previously learnt tasks. We show that using the co-natural gradient systematically reduces forgetting in continual learning. Moreover, it helps combat overfitting when learning a new task in a low resource scenario.", "keywords": ["Continual Learning", "Regularization", "Adaptation", "Natural Gradient"], "paperhash": "michel|regularizing_trajectories_to_mitigate_catastrophic_forgetting", "original_pdf": "/attachment/9dc9d5286f63fc63503eef46323e1605e0d7735f.pdf", "_bibtex": "@misc{\nmichel2020regularizing,\ntitle={Regularizing Trajectories to Mitigate Catastrophic Forgetting},\nauthor={Paul Michel and Elisabeth Salesky and Graham Neubig},\nyear={2020},\nurl={https://openreview.net/forum?id=Hkl4EANFDH}\n}"}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "Hkl4EANFDH", "replyto": "Hkl4EANFDH", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper1071/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper1071/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1575508060321, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper1071/Reviewers"], "noninvitees": [], "tcdate": 1570237742785, "tmdate": 1575508060335, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper1071/-/Official_Review"}}}, {"id": "rkeTDi2TYB", "original": null, "number": 2, "cdate": 1571830629115, "ddate": null, "tcdate": 1571830629115, "tmdate": 1572972516381, "tddate": null, "forum": "Hkl4EANFDH", "replyto": "Hkl4EANFDH", "invitation": "ICLR.cc/2020/Conference/Paper1071/-/Official_Review", "content": {"experience_assessment": "I have published one or two papers in this area.", "rating": "3: Weak Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #1", "review_assessment:_checking_correctness_of_derivations_and_theory": "I carefully checked the derivations and theory.", "review": "The paper proposed a novel regularization methods for continual learning. The authors introduce co-natural gradients, which is an incremental development of natural gradient methods, note that co-natural gradients use Fisher information to regularize the trajectory of the gradients which will be optimal on both tasks.\n\nThe method can be applied on existing regularization-based continual learning approach such as EWC, or ER. And with co-natural gradients, the model can perform better on continual learning problem.\n\nI think that the performance of finetuning + co-gradient is too natural, and not much meaningful. And the tradeoff between accuracy and forgetting for baselines is hard to compare on table 1 since the tradeoff depends on the hyperparameters. \n\nAnd it is required to apply on heterogeneous datasets to evaluate the performance when problems are really different. (like MNIST->CIFAR100->Omniglot->Imagenet, and so on). In the paper, the experiments are performed on very similar problems (split a single dataset).\n\nAlso, it would be great to show an illustration like figure 1, on real dataset, like split CIFAR.\n\n"}, "signatures": ["ICLR.cc/2020/Conference/Paper1071/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1071/AnonReviewer1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["pmichel1@cs.cmu.edu", "esalesky@gmail.com", "gneubig@cs.cmu.edu"], "title": "Regularizing Trajectories to Mitigate Catastrophic Forgetting", "authors": ["Paul Michel", "Elisabeth Salesky", "Graham Neubig"], "pdf": "/pdf/b1019731271f19d64c06ef1e0917679d2ec2cba4.pdf", "TL;DR": "Regularizing the optimization trajectory with the Fisher information of old tasks reduces catastrophic forgetting greatly", "abstract": "Regularization-based continual learning approaches generally prevent catastrophic forgetting by augmenting the training loss with an auxiliary objective. However in most practical optimization scenarios with noisy data and/or gradients, it is possible that stochastic gradient descent can inadvertently change critical parameters.\nIn this paper, we argue for the importance of regularizing optimization trajectories directly. We derive a new co-natural gradient update rule for continual learning whereby the new task gradients are preconditioned with the empirical Fisher information of previously learnt tasks. We show that using the co-natural gradient systematically reduces forgetting in continual learning. Moreover, it helps combat overfitting when learning a new task in a low resource scenario.", "keywords": ["Continual Learning", "Regularization", "Adaptation", "Natural Gradient"], "paperhash": "michel|regularizing_trajectories_to_mitigate_catastrophic_forgetting", "original_pdf": "/attachment/9dc9d5286f63fc63503eef46323e1605e0d7735f.pdf", "_bibtex": "@misc{\nmichel2020regularizing,\ntitle={Regularizing Trajectories to Mitigate Catastrophic Forgetting},\nauthor={Paul Michel and Elisabeth Salesky and Graham Neubig},\nyear={2020},\nurl={https://openreview.net/forum?id=Hkl4EANFDH}\n}"}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "Hkl4EANFDH", "replyto": "Hkl4EANFDH", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper1071/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper1071/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1575508060321, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper1071/Reviewers"], "noninvitees": [], "tcdate": 1570237742785, "tmdate": 1575508060335, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper1071/-/Official_Review"}}}], "count": 11}