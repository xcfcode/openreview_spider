{"notes": [{"id": "rkgt0REKwS", "original": "r1elcY5uDS", "number": 1438, "cdate": 1569439440788, "ddate": null, "tcdate": 1569439440788, "tmdate": 1583912044704, "tddate": null, "forum": "rkgt0REKwS", "replyto": null, "invitation": "ICLR.cc/2020/Conference/-/Blind_Submission", "content": {"title": "Curriculum Loss: Robust Learning and Generalization  against Label Corruption", "authors": ["Yueming Lyu", "Ivor W. Tsang"], "authorids": ["lv_yueming@outlook.com", "ivor.tsang@uts.edu.au"], "keywords": ["Curriculum Learning", "deep learning"], "TL;DR": "A novel loss bridges curriculum learning and robust learning", "abstract": "Deep neural networks (DNNs) have great expressive power, which can even memorize samples with wrong labels. It is vitally important to reiterate robustness and generalization in DNNs against label corruption. To this end, this paper studies the 0-1 loss, which has a monotonic relationship between empirical adversary (reweighted) risk (Hu et al. 2018). Although the 0-1 loss is robust to outliers, it is also difficult to optimize.   To efficiently optimize the 0-1 loss while keeping its robust properties, we propose a very simple and efficient loss, i.e. curriculum loss (CL). Our CL  is a tighter upper bound of the 0-1 loss compared with conventional summation based surrogate losses.  Moreover, CL can adaptively select samples for stagewise training. As a result, our loss can be deemed as a novel perspective of curriculum sample selection strategy, which bridges a connection between curriculum learning and robust learning.     Experimental results on noisy MNIST, CIFAR10 and CIFAR100 dataset validate the robustness of the proposed loss.", "pdf": "/pdf/800966a39eedb870f2172779e97ac57edbff69e5.pdf", "paperhash": "lyu|curriculum_loss_robust_learning_and_generalization_against_label_corruption", "_bibtex": "@inproceedings{\nLyu2020Curriculum,\ntitle={Curriculum Loss: Robust Learning and Generalization  against Label Corruption},\nauthor={Yueming Lyu and Ivor W. Tsang},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=rkgt0REKwS}\n}", "full_presentation_video": "", "original_pdf": "/attachment/8f92c68c81714ce3ea0423465464268d22752db5.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "signatures": ["ICLR.cc/2020/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference"], "details": {"replyCount": 8, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"reply": {"readers": {"values-regex": ".*"}, "writers": {"values": ["ICLR.cc/2020/Conference"]}, "signatures": {"values": ["ICLR.cc/2020/Conference"]}, "content": {"spotlight_video": {"value-regex": ".*"}, "full_presentation_video": {"value-regex": ".*"}, "original_pdf": {"required": false, "description": "Upload a PDF file that ends with .pdf", "value-regex": ".*"}, "appendix": {"value-regex": ".*"}, "authorids": {"values-regex": ".*"}, "poster": {"value-regex": ".*"}, "authors": {"values": ["Anonymous"]}, "slides": {"value-regex": ".*"}}}, "final": [], "signatures": ["ICLR.cc/2020/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference"], "noninvitees": [], "tcdate": 1569271260237, "tmdate": 1593459412141, "id": "ICLR.cc/2020/Conference/-/Blind_Submission"}}, "tauthor": "ICLR.cc/2020/Conference"}, {"id": "Skg2CS-Q3S", "original": null, "number": 7, "cdate": 1574274516014, "ddate": null, "tcdate": 1574274516014, "tmdate": 1577101297720, "tddate": null, "forum": "rkgt0REKwS", "replyto": "rJezxPnojH", "invitation": "ICLR.cc/2020/Conference/Paper1438/-/Official_Comment", "content": {"title": "On the motivation", "comment": "Thank you for the clarification! I would like to clarify that in my previous review about motivation, I  did not misunderstand the motivation but I want to emphasize that the message of Theorem 1 basically says that \n\nthe minimizer of the clean distribution is identical to that of the worst-case distribution around that clean distribution (which refers to the f-divergence ball).\n\nAnd I acknowledged that the authors wanted to interpret as \n\nthe minimizer of the corrupted distribution is identical to that of the worst-case \"clean\" distribution around that corrupted distribution.\n\nMy concern is that if what the author suggested is true, although it is free from noise assumption, it sounds like the minimizer of the corrupted risk w.r.t. 0-1 loss is identical to the worst-case clean distribution with arbitrary delta (which determines the size of the f-divergence ball). This sounds highly pessimistic if I did not misunderstand this part. Could you please clarify this part?\n\nRegarding the key finding of authors in the rebuttal:\n\"Our key finding is that minimizing the classification risk under a corrupted distribution can minimize the classification risk of the worst-case clean distribution (in the f-divergence ball).\"\n\nI think this is the claim from the experimental results. I am not sure if the success of the proposed method is really because of that finding the author suggested, but the loss itself has some mechanics that make it robust to noise, e.g., adaptive sample selection.\n\nAlthough I am still not fully convinced with the motivation of the paper and still doubting whether NPCL works well because of the given motivation, I still believe that the proposed NPCL should improve the performance and also give a new perspective to deal with noisy labels. I like the idea of the paper. Thus, I increased my score."}, "signatures": ["ICLR.cc/2020/Conference/Paper1438/AnonReviewer3"], "readers": ["ICLR.cc/2020/Conference/Paper1438/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper1438/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs", "everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1438/AnonReviewer3", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Curriculum Loss: Robust Learning and Generalization  against Label Corruption", "authors": ["Yueming Lyu", "Ivor W. Tsang"], "authorids": ["lv_yueming@outlook.com", "ivor.tsang@uts.edu.au"], "keywords": ["Curriculum Learning", "deep learning"], "TL;DR": "A novel loss bridges curriculum learning and robust learning", "abstract": "Deep neural networks (DNNs) have great expressive power, which can even memorize samples with wrong labels. It is vitally important to reiterate robustness and generalization in DNNs against label corruption. To this end, this paper studies the 0-1 loss, which has a monotonic relationship between empirical adversary (reweighted) risk (Hu et al. 2018). Although the 0-1 loss is robust to outliers, it is also difficult to optimize.   To efficiently optimize the 0-1 loss while keeping its robust properties, we propose a very simple and efficient loss, i.e. curriculum loss (CL). Our CL  is a tighter upper bound of the 0-1 loss compared with conventional summation based surrogate losses.  Moreover, CL can adaptively select samples for stagewise training. As a result, our loss can be deemed as a novel perspective of curriculum sample selection strategy, which bridges a connection between curriculum learning and robust learning.     Experimental results on noisy MNIST, CIFAR10 and CIFAR100 dataset validate the robustness of the proposed loss.", "pdf": "/pdf/800966a39eedb870f2172779e97ac57edbff69e5.pdf", "paperhash": "lyu|curriculum_loss_robust_learning_and_generalization_against_label_corruption", "_bibtex": "@inproceedings{\nLyu2020Curriculum,\ntitle={Curriculum Loss: Robust Learning and Generalization  against Label Corruption},\nauthor={Yueming Lyu and Ivor W. Tsang},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=rkgt0REKwS}\n}", "full_presentation_video": "", "original_pdf": "/attachment/8f92c68c81714ce3ea0423465464268d22752db5.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "rkgt0REKwS", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper1438/Authors", "ICLR.cc/2020/Conference/Paper1438/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper1438/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper1438/Reviewers", "ICLR.cc/2020/Conference/Paper1438/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper1438/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper1438/Authors|ICLR.cc/2020/Conference/Paper1438/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504156009, "tmdate": 1576860561953, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper1438/Authors", "ICLR.cc/2020/Conference/Paper1438/Reviewers", "ICLR.cc/2020/Conference/Paper1438/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper1438/-/Official_Comment"}}}, {"id": "jTC0ChX6YM", "original": null, "number": 1, "cdate": 1576798723272, "ddate": null, "tcdate": 1576798723272, "tmdate": 1576800913278, "tddate": null, "forum": "rkgt0REKwS", "replyto": "rkgt0REKwS", "invitation": "ICLR.cc/2020/Conference/Paper1438/-/Decision", "content": {"decision": "Accept (Poster)", "comment": "This paper studies learning with noisy labels by integrating the idea of curriculum learning.\n\nAll reviewers and AC are happy with novelty, clear write-up and experimental results.\n\nI recommend acceptance. \n", "title": "Paper Decision"}, "signatures": ["ICLR.cc/2020/Conference/Program_Chairs"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Program_Chairs"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Curriculum Loss: Robust Learning and Generalization  against Label Corruption", "authors": ["Yueming Lyu", "Ivor W. Tsang"], "authorids": ["lv_yueming@outlook.com", "ivor.tsang@uts.edu.au"], "keywords": ["Curriculum Learning", "deep learning"], "TL;DR": "A novel loss bridges curriculum learning and robust learning", "abstract": "Deep neural networks (DNNs) have great expressive power, which can even memorize samples with wrong labels. It is vitally important to reiterate robustness and generalization in DNNs against label corruption. To this end, this paper studies the 0-1 loss, which has a monotonic relationship between empirical adversary (reweighted) risk (Hu et al. 2018). Although the 0-1 loss is robust to outliers, it is also difficult to optimize.   To efficiently optimize the 0-1 loss while keeping its robust properties, we propose a very simple and efficient loss, i.e. curriculum loss (CL). Our CL  is a tighter upper bound of the 0-1 loss compared with conventional summation based surrogate losses.  Moreover, CL can adaptively select samples for stagewise training. As a result, our loss can be deemed as a novel perspective of curriculum sample selection strategy, which bridges a connection between curriculum learning and robust learning.     Experimental results on noisy MNIST, CIFAR10 and CIFAR100 dataset validate the robustness of the proposed loss.", "pdf": "/pdf/800966a39eedb870f2172779e97ac57edbff69e5.pdf", "paperhash": "lyu|curriculum_loss_robust_learning_and_generalization_against_label_corruption", "_bibtex": "@inproceedings{\nLyu2020Curriculum,\ntitle={Curriculum Loss: Robust Learning and Generalization  against Label Corruption},\nauthor={Yueming Lyu and Ivor W. Tsang},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=rkgt0REKwS}\n}", "full_presentation_video": "", "original_pdf": "/attachment/8f92c68c81714ce3ea0423465464268d22752db5.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "tags": [], "invitation": {"reply": {"writers": {"description": "How your identity will be displayed.", "values-regex": ["ICLR.cc/2020/Conference/Program_Chairs"]}, "signatures": {"values": ["ICLR.cc/2020/Conference/Program_Chairs"], "description": "How your identity will be displayed."}, "content": {"decision": {"value-radio": ["Accept (Spotlight)", "Accept (Talk)", "Accept (Poster)", "Reject"], "description": "Decision", "required": true, "order": 2}, "title": {"value": "Paper Decision", "required": true, "order": 1}, "comment": {"value-regex": "[\\S\\s]{0,5000}", "description": "", "required": false, "order": 3}}, "forum": "rkgt0REKwS", "replyto": "rkgt0REKwS", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}}, "expdate": 1576854540000, "duedate": 1576853940000, "multiReply": false, "readers": ["everyone"], "invitees": ["ICLR.cc/2020/Conference/Program_Chairs"], "tcdate": 1576795711973, "tmdate": 1576800261263, "super": "ICLR.cc/2020/Conference/-/Decision", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper1438/-/Decision"}}}, {"id": "SkxvXnoatH", "original": null, "number": 2, "cdate": 1571826719332, "ddate": null, "tcdate": 1571826719332, "tmdate": 1574320393057, "tddate": null, "forum": "rkgt0REKwS", "replyto": "rkgt0REKwS", "invitation": "ICLR.cc/2020/Conference/Paper1438/-/Official_Review", "content": {"experience_assessment": "I have published one or two papers in this area.", "rating": "6: Weak Accept", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "title": "Official Blind Review #4", "review": "After rebuttal,\n\nI think the authors made a valid argument to address my concerns on evaluation. So, I'd like to increase my score as weak accept! \n\n=====\n\n\nSummary:\n\nTo handle noisy labels, this paper proposed a curriculum loss that corresponds to the upper bound of 0-1 loss. Using synthetic noisy labels on MNIST and CIFAR, the authors verified that the proposed method can significantly improve the robustness against noisy labels.\n\nDetailed comments:\n\nOverall, the paper is well-written and the ideas are novel. However, experiments are a little weak due to weak baselines and experimental setups (see suggestions for more details). I will consider raising my score according to the rebuttal.\n\nSuggestions:\n\n1. Could the authors consider more baselines like D2L [Ma' 18] and Reweight [Ren' 18] \n\n2. Similar to [Lee' 19], could the authors evaluate the performance of the proposed methods on more realistic noisy labels such as semantic noisy labels and open-set noisy labels? \n\n[Lee' 19] robust inference via generative classifiers for handling noisy labels, In ICML, 2019.\n\n[Ma' 18] Dimensionality-Driven Learning with Noisy Labels, In ICML, 2018.\n\n[Ren' 18] Learning to Reweight Examples for Robust Deep Learning, In ICML, 2018.", "review_assessment:_checking_correctness_of_derivations_and_theory": "I did not assess the derivations or theory."}, "signatures": ["ICLR.cc/2020/Conference/Paper1438/AnonReviewer4"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1438/AnonReviewer4"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Curriculum Loss: Robust Learning and Generalization  against Label Corruption", "authors": ["Yueming Lyu", "Ivor W. Tsang"], "authorids": ["lv_yueming@outlook.com", "ivor.tsang@uts.edu.au"], "keywords": ["Curriculum Learning", "deep learning"], "TL;DR": "A novel loss bridges curriculum learning and robust learning", "abstract": "Deep neural networks (DNNs) have great expressive power, which can even memorize samples with wrong labels. It is vitally important to reiterate robustness and generalization in DNNs against label corruption. To this end, this paper studies the 0-1 loss, which has a monotonic relationship between empirical adversary (reweighted) risk (Hu et al. 2018). Although the 0-1 loss is robust to outliers, it is also difficult to optimize.   To efficiently optimize the 0-1 loss while keeping its robust properties, we propose a very simple and efficient loss, i.e. curriculum loss (CL). Our CL  is a tighter upper bound of the 0-1 loss compared with conventional summation based surrogate losses.  Moreover, CL can adaptively select samples for stagewise training. As a result, our loss can be deemed as a novel perspective of curriculum sample selection strategy, which bridges a connection between curriculum learning and robust learning.     Experimental results on noisy MNIST, CIFAR10 and CIFAR100 dataset validate the robustness of the proposed loss.", "pdf": "/pdf/800966a39eedb870f2172779e97ac57edbff69e5.pdf", "paperhash": "lyu|curriculum_loss_robust_learning_and_generalization_against_label_corruption", "_bibtex": "@inproceedings{\nLyu2020Curriculum,\ntitle={Curriculum Loss: Robust Learning and Generalization  against Label Corruption},\nauthor={Yueming Lyu and Ivor W. Tsang},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=rkgt0REKwS}\n}", "full_presentation_video": "", "original_pdf": "/attachment/8f92c68c81714ce3ea0423465464268d22752db5.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "rkgt0REKwS", "replyto": "rkgt0REKwS", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper1438/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper1438/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1575475077888, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper1438/Reviewers"], "noninvitees": [], "tcdate": 1570237737394, "tmdate": 1575475077900, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper1438/-/Official_Review"}}}, {"id": "S1efYqIiKr", "original": null, "number": 1, "cdate": 1571674746149, "ddate": null, "tcdate": 1571674746149, "tmdate": 1574273556414, "tddate": null, "forum": "rkgt0REKwS", "replyto": "rkgt0REKwS", "invitation": "ICLR.cc/2020/Conference/Paper1438/-/Official_Review", "content": {"experience_assessment": "I have published one or two papers in this area.", "rating": "6: Weak Accept", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "title": "Official Blind Review #3", "review": "Summary: This paper proposes a new loss function: curriculum loss, which is a meta-loss function that we can still specify an existing surrogate loss to use this loss function. This meta-loss function guarantees to be tighter than using a traditional pointwise-sum loss function as used in the empirical risk minimization framework. Intuitively, the proposed CL loss embed the sample selection process in the objective function. The authors suggest that it is robust against label corruption because it is tighter and provided promising experimental results.\n\n========================================================\nClarity:\nThe paper is well-written and easy to follow. \n\n========================================================\nSignificance:\nThe proposed paradigm is interesting and I am convinced that it can be useful under label noise. The experiments look promising. Future work about the analysis of NPCL/CL is also interesting to consider (e.g., which surrogate loss to use, rigorous theoretical guarantee, etc.). I think the proposed method is impactful. \n\n========================================================\nComments:\nThe proposed method is interesting and can give a tighter bound for any surrogate loss by using this method (CL). Moreover, the author suggested a simple extension of CL for label corruption (NPCL) and the performance is impressive. I would like to vote accept for this paper but the following point highly concerns me and I am not sure about the correctness (see the concern below). It is about the motivation not the proposed method.\n\nConcerns about motivation:\n\nI disagree with the original motivation of this paper. The authors used the result of Hu et al. 2018 to motivate the use of CL. To my knowledge, the main point raised by Hu et al. is as follows:\n\nIn classification, minimizing the adversarial risk yields the same solution as using the standard empirical risk. This suggests that minimizing the adversarial risk may not enhance the robustness of a classifier. Yet, it may still be useful when we consider regression (other settings but not classification). As a result, in classification, we should try other methods to make a robust classifier. Then, Hu et al. considered to utilize some kind of structural assumption to make a robust classifier. From their title: \"Does Distributionally Robust Supervised Learning Give Robust Classifiers?\", I think they suggested \"No\" as an answer and the discussion about 0-1 loss in the curriculum loss paper will be contradicted to them from the motivation perspective. \n\nFurthermore, regarding the adversarial risk, it is not focusing on the label noise but rather the noise of the feature-label pair, i.e, perturb (x,y) adversarially within an f-divergence ball. However, in my opinion, if we randomly flip the label of the data regardless of x (as the authors and existing work did in experiments when considering label corruption: symmetric, partial, etc.), we cannot be confident to state that the f-divergence between test distribution and corrupted training distribution is small under label noise. \n\nAnother point to motivate the use of 0-1 loss that the author mentioned is when we have outliers (Masnadi-Shirazi & Vasconcelos, 2009). This makes sense and this is a famous argument to discourage the use of too steep loss functions, e.g., exponential loss. I think this motivation is fine but it is not directly related to label corruption because we do not add out-of-distribution data but rather the label noise. Furthermore, the authors did not inject any outliers in the experiments in my understanding. I think this is totally no problem because we are focusing on label noise here, but this makes the motivation about outliers less important when we are talking about label noise.\n\nI think the most important direction both in theory and experiments about the robustness to label noise of the 0-1 loss is that 0-1 loss satisfies a \"symmetric property\", i.e., \\ell(z)+\\ell(-z) = Constant for a margin-based loss function in binary classification. Under symmetric label noise, \"the minimizer of the expected symmetric noise risk (a risk that the label is corrupted by coin flipping noise) is identical to the minimizer of the clean risk (normal risk)\". Although it is not empirically but the expected version, it gives a good insight about the advantage of directly minimizing 0-1 loss under label noise. This is first pointed out by \n\n[1] Manwani et al.: Noise tolerance under risk minimization, IEEE Transactions on Cybernetics 43 (2013) \n[2] Ghosh et al.: Making risk minimization tolerant to label noise Neurocomputing 160 (2015): 93-107. \n\n([1] focused on the 0-1 loss while [2] extended it to symmetric losses.)\n\nThen, it was extended to the multiclass loss by the following paper:\n\n[3] Ghosh et al.: Robust loss functions under label noise for deep neural networks. AAAI2017. \n\nThe advantage of symmetric losses is also discussed in this paper that the authors already cited in the symmetric noise experiment section. \n\n[4] van Rooyen et al.: Learning with symmetric label noise: The importance of being unhinged, NeurIPS2015\n\nThe advantage of the symmetric condition and 0-1 loss is also discussed in a more general noise scenario and more evaluation metrics:\n\n[5] van Rooyen et. al: An average classification algorithm. arXiv:1506.01520, 2015\n[6] Charoenphakdee et al.: On symmetric losses for learning from corrupted labels, ICML2019\n\nAnd the following paper that was also cited in the submitted work and compared:\n\n[7] Zhang and Sabuncu: Generalized cross-entropy loss for training deep neural networks with noisy labels, NeurIPS2018\n\nis also inspired by the robustness of the symmetric losses (including 0-1 loss). They argued that although the symmetric loss (MAE) for multiclass proposed by Ghosh AAAI2017 is robust, it is hard to train for challenging datasets, and they try to relevate this condition while making it easier to train.  This paper outperformed [7] and I think it is clearer and better to build a story along this line.\n\nIn short, here is the key message why I think the current motivation does not feel right. When we have noisy labeled data, instead of motivating the use of 0-1 loss by suggesting that \n\n\"If we have clean labeled data, minimizing the \"adversarial\" ERM risk using \"clean\" labeled data yields the same minimizer as minimizing the \"standard\" ERM risk using \"clean\" labeled data\",\n\nI believe the story to motivate the robustness of 0-1 loss under label noise should be \n\n\"If we have noisy labeled data, minimizing the \"standard\" or \"modified\" risk using \"noisy\" labeled data yields the same minimizer as minimizing the \"standard\" ERM risk using \"clean\" label data\"\n\nThe latter statement corresponds to the literature I suggested. \n\nApart from the motivation raised by the authors, as we can see from this curriculum loss paper, NPCL nicely outperformed generalized cross entropy loss in [7], which is impressive.\n\n========================================================\nDecision.\nI strongly feel that motivating the noise robustness of 0-1 loss by discussing about the adversarial risk (Hu et al.) is misleading. Nevertheless, I feel the proposed method itself makes a lot of sense and I am impressed by the results. If the author can convince me that using the current motivation of the paper is suitable, I am happy to improve the score. Another way is to agree to modify the motivation part. Given the experiments were done, it is not to difficult to change the motivation of the paper. At this point, I have decided to give a weak reject. \n\n========================================================\nQuestions:\n1. Is it straightforward to combine NPCL with Co-teaching/Mentornet/Co-teaching+?\n2. Does the traditional theory about classification-calibration (Zhang, 2004, Bartlett+, 2006) can guarantee the Bayes-optimal solution if we use NPCL?\n\n========================================================\nMinor comments:\n1. Page 9: Both our NPCL and Generalized Cross Entropy(GCE) << space missing between Entropy and (\n\nUpdate: I have read the rebuttal. Although I am still not fully convinced with the motivation of the paper and still doubting whether NPCL works well because of the given motivation, I still believe that the proposed NPCL should give a new perspective to deal with noisy labels. I like the idea of the paper. Thus, I change the score to Weak Accept.\n", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory."}, "signatures": ["ICLR.cc/2020/Conference/Paper1438/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1438/AnonReviewer3"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Curriculum Loss: Robust Learning and Generalization  against Label Corruption", "authors": ["Yueming Lyu", "Ivor W. Tsang"], "authorids": ["lv_yueming@outlook.com", "ivor.tsang@uts.edu.au"], "keywords": ["Curriculum Learning", "deep learning"], "TL;DR": "A novel loss bridges curriculum learning and robust learning", "abstract": "Deep neural networks (DNNs) have great expressive power, which can even memorize samples with wrong labels. It is vitally important to reiterate robustness and generalization in DNNs against label corruption. To this end, this paper studies the 0-1 loss, which has a monotonic relationship between empirical adversary (reweighted) risk (Hu et al. 2018). Although the 0-1 loss is robust to outliers, it is also difficult to optimize.   To efficiently optimize the 0-1 loss while keeping its robust properties, we propose a very simple and efficient loss, i.e. curriculum loss (CL). Our CL  is a tighter upper bound of the 0-1 loss compared with conventional summation based surrogate losses.  Moreover, CL can adaptively select samples for stagewise training. As a result, our loss can be deemed as a novel perspective of curriculum sample selection strategy, which bridges a connection between curriculum learning and robust learning.     Experimental results on noisy MNIST, CIFAR10 and CIFAR100 dataset validate the robustness of the proposed loss.", "pdf": "/pdf/800966a39eedb870f2172779e97ac57edbff69e5.pdf", "paperhash": "lyu|curriculum_loss_robust_learning_and_generalization_against_label_corruption", "_bibtex": "@inproceedings{\nLyu2020Curriculum,\ntitle={Curriculum Loss: Robust Learning and Generalization  against Label Corruption},\nauthor={Yueming Lyu and Ivor W. Tsang},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=rkgt0REKwS}\n}", "full_presentation_video": "", "original_pdf": "/attachment/8f92c68c81714ce3ea0423465464268d22752db5.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "rkgt0REKwS", "replyto": "rkgt0REKwS", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper1438/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper1438/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1575475077888, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper1438/Reviewers"], "noninvitees": [], "tcdate": 1570237737394, "tmdate": 1575475077900, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper1438/-/Official_Review"}}}, {"id": "rJezxPnojH", "original": null, "number": 4, "cdate": 1573795561694, "ddate": null, "tcdate": 1573795561694, "tmdate": 1573795561694, "tddate": null, "forum": "rkgt0REKwS", "replyto": "S1efYqIiKr", "invitation": "ICLR.cc/2020/Conference/Paper1438/-/Official_Comment", "content": {"title": "Clarify the motivation.", "comment": "\nThanks for your comments.  We acknowledge your concern. Here, we want to clarify some misunderstandings about our motivation. \n\nOur motivation is not \"If we have clean labeled data, minimizing the \"adversarial\" ERM risk using \"clean\" labeled data yields the same minimizer as minimizing the \"standard\" ERM risk using \"clean\" labeled data.\"  The reviewer\u2019s concern is training with the clean distribution. However,  our motivation is to train on a corrupted training distribution p(x,y),  not a clean distribution, and we want our model to perform well on the worst-case clean distribution (in the f-divergence ball).  \n\nCompared with Hu et al., our motivation is not training with  \"adversarial\" ERM to improve training with classification risk under the clean distribution.  Our key finding is that minimizing the classification risk under a corrupted distribution can minimize the classification risk of the worst-case clean distribution(in the f-divergence ball). There is no contradiction to Hu et al. Note that the worst-case classification risk is an upper bound of the classification risk of the true clean distribution, minimizing the worst-case classification risk can usually decrease the true classification risk.\n\nSpecifically, suppose we have an observable training distribution p(x,y). The observable distribution p(x,y) may be corrupted from an underlying clean distribution q(x,y). We train a model based on the training distribution p(x,y), but we want our model to perform well on the clean distribution q(x,y). Since we do not know the clean distribution q(x,y), we want our model to perform well even for the worst-case clean distribution q, with the assumption that the f-divergence between the corrupted distribution p and the clean distribution q is bounded by delta.   Because of Theorem 1, we do not need to optimize the worst-case risk directly; we can optimize the classification risk (on the corrupted training distribution) instead.\n\nWe provide a more detailed explanation in Appendix A and update the paper to make the motivation clear.\n\n\nThanks for the suggestion of another line of analysis of the robustness of 0-1 loss.\n\nActually, the \"symmetric property\" of robust loss is derived under additional assumptions of noise type. For example, In Ghosh AAAI2017, they make assumptions of uniform noise,  simple non-uniform noise, and class conditional noise. \n\nIf we assume the noise is uniform, minimizing the (empirical) risk of 0-1 loss using noisy data leads to a same minimizer as minimizing the (empirical) risk for the clean distribution. (Ghosh AAAI2017)\n\nIf we do not assume the noise type, minimizing the risk of 0-1 loss using noisy data leads to a same minimizer as minimizing the risk of the worst-case clean distribution (in the f-divergence ball), which is the case of this work.\n\nThe robustness of 0-1 is interesting; we will further analyze this robustness in further work.\n"}, "signatures": ["ICLR.cc/2020/Conference/Paper1438/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1438/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Curriculum Loss: Robust Learning and Generalization  against Label Corruption", "authors": ["Yueming Lyu", "Ivor W. Tsang"], "authorids": ["lv_yueming@outlook.com", "ivor.tsang@uts.edu.au"], "keywords": ["Curriculum Learning", "deep learning"], "TL;DR": "A novel loss bridges curriculum learning and robust learning", "abstract": "Deep neural networks (DNNs) have great expressive power, which can even memorize samples with wrong labels. It is vitally important to reiterate robustness and generalization in DNNs against label corruption. To this end, this paper studies the 0-1 loss, which has a monotonic relationship between empirical adversary (reweighted) risk (Hu et al. 2018). Although the 0-1 loss is robust to outliers, it is also difficult to optimize.   To efficiently optimize the 0-1 loss while keeping its robust properties, we propose a very simple and efficient loss, i.e. curriculum loss (CL). Our CL  is a tighter upper bound of the 0-1 loss compared with conventional summation based surrogate losses.  Moreover, CL can adaptively select samples for stagewise training. As a result, our loss can be deemed as a novel perspective of curriculum sample selection strategy, which bridges a connection between curriculum learning and robust learning.     Experimental results on noisy MNIST, CIFAR10 and CIFAR100 dataset validate the robustness of the proposed loss.", "pdf": "/pdf/800966a39eedb870f2172779e97ac57edbff69e5.pdf", "paperhash": "lyu|curriculum_loss_robust_learning_and_generalization_against_label_corruption", "_bibtex": "@inproceedings{\nLyu2020Curriculum,\ntitle={Curriculum Loss: Robust Learning and Generalization  against Label Corruption},\nauthor={Yueming Lyu and Ivor W. Tsang},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=rkgt0REKwS}\n}", "full_presentation_video": "", "original_pdf": "/attachment/8f92c68c81714ce3ea0423465464268d22752db5.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "rkgt0REKwS", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper1438/Authors", "ICLR.cc/2020/Conference/Paper1438/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper1438/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper1438/Reviewers", "ICLR.cc/2020/Conference/Paper1438/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper1438/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper1438/Authors|ICLR.cc/2020/Conference/Paper1438/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504156009, "tmdate": 1576860561953, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper1438/Authors", "ICLR.cc/2020/Conference/Paper1438/Reviewers", "ICLR.cc/2020/Conference/Paper1438/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper1438/-/Official_Comment"}}}, {"id": "BJlutLhioB", "original": null, "number": 3, "cdate": 1573795455812, "ddate": null, "tcdate": 1573795455812, "tmdate": 1573795455812, "tddate": null, "forum": "rkgt0REKwS", "replyto": "SkxvXnoatH", "invitation": "ICLR.cc/2020/Conference/Paper1438/-/Official_Comment", "content": {"title": "More experiments for evaluation", "comment": "\n\nThanks for your comments. \n\nWe provide the suggested experiments in Appendix B.\nWe use the open-sourced code of Lee et al., ICML 2019 on GitHub. We only change the loss by our CL and NPCL. The experimental results show the effectiveness of our CL/NPCL. Note that CL/NPCL is a single loss for network training; one can combine them with the ensemble method (Lee et al. 2019) to boost the performance.\n"}, "signatures": ["ICLR.cc/2020/Conference/Paper1438/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1438/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Curriculum Loss: Robust Learning and Generalization  against Label Corruption", "authors": ["Yueming Lyu", "Ivor W. Tsang"], "authorids": ["lv_yueming@outlook.com", "ivor.tsang@uts.edu.au"], "keywords": ["Curriculum Learning", "deep learning"], "TL;DR": "A novel loss bridges curriculum learning and robust learning", "abstract": "Deep neural networks (DNNs) have great expressive power, which can even memorize samples with wrong labels. It is vitally important to reiterate robustness and generalization in DNNs against label corruption. To this end, this paper studies the 0-1 loss, which has a monotonic relationship between empirical adversary (reweighted) risk (Hu et al. 2018). Although the 0-1 loss is robust to outliers, it is also difficult to optimize.   To efficiently optimize the 0-1 loss while keeping its robust properties, we propose a very simple and efficient loss, i.e. curriculum loss (CL). Our CL  is a tighter upper bound of the 0-1 loss compared with conventional summation based surrogate losses.  Moreover, CL can adaptively select samples for stagewise training. As a result, our loss can be deemed as a novel perspective of curriculum sample selection strategy, which bridges a connection between curriculum learning and robust learning.     Experimental results on noisy MNIST, CIFAR10 and CIFAR100 dataset validate the robustness of the proposed loss.", "pdf": "/pdf/800966a39eedb870f2172779e97ac57edbff69e5.pdf", "paperhash": "lyu|curriculum_loss_robust_learning_and_generalization_against_label_corruption", "_bibtex": "@inproceedings{\nLyu2020Curriculum,\ntitle={Curriculum Loss: Robust Learning and Generalization  against Label Corruption},\nauthor={Yueming Lyu and Ivor W. Tsang},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=rkgt0REKwS}\n}", "full_presentation_video": "", "original_pdf": "/attachment/8f92c68c81714ce3ea0423465464268d22752db5.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "rkgt0REKwS", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper1438/Authors", "ICLR.cc/2020/Conference/Paper1438/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper1438/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper1438/Reviewers", "ICLR.cc/2020/Conference/Paper1438/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper1438/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper1438/Authors|ICLR.cc/2020/Conference/Paper1438/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504156009, "tmdate": 1576860561953, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper1438/Authors", "ICLR.cc/2020/Conference/Paper1438/Reviewers", "ICLR.cc/2020/Conference/Paper1438/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper1438/-/Official_Comment"}}}, {"id": "BJe6rL3jsS", "original": null, "number": 2, "cdate": 1573795396746, "ddate": null, "tcdate": 1573795396746, "tmdate": 1573795396746, "tddate": null, "forum": "rkgt0REKwS", "replyto": "HJghRHVAKr", "invitation": "ICLR.cc/2020/Conference/Paper1438/-/Official_Comment", "content": {"title": "Explanation and more experiments.", "comment": "\nThanks for your comments.\n\n1. Explanation of Eq.(9)\n \nThe difficulty of optimizing the 0-1 loss is that the 0-1 loss has zero gradients in almost everywhere (except at the breaking point). This issue prevents us from using first-order methods to optimize the 0-1 loss. Eq.(9) provides a surrogate of the 0-1 loss with non-zero subgradient for optimization, while preserving robust properties of the 0-1 loss. Note that our goal is to construct a tight upper bound of the 0-1 loss while preserving informative (sub)gradients. Eq.(9) balances the 0-1 loss and conventional surrogate by selecting (the trust) samples (index) for training progressively.\n\n2. We provide experiments on Tiny-ImageNet in Appendix B. We use ResNet18 as the testbed. Both symmetric 20% and symmetric 50% noise cases are evaluated. The experimental results show that NPCL can improve performance on the more difficult dataset Tiny-ImageNet. \n\n3. In Table 2 and 3, the NPCL, Co-teaching, and Co-teaching+ use the true noise rate. We further evaluate CL on CIFAR10, CIFAR100, and Tiny-ImageNet. The experimental results are provided in Appendix B.  It shows that CL can obtain comparable results with NPCL. Moreover, CL obtains better performance on CIFAR10 and CIFAR100 with uniform noise, and competitive performance on cases with semantic noise, compared to the ensemble methods (RoG) of Lee et al., ICML 2019. Note that CL does not have parameters. It is much more convenient to use. \n"}, "signatures": ["ICLR.cc/2020/Conference/Paper1438/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1438/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Curriculum Loss: Robust Learning and Generalization  against Label Corruption", "authors": ["Yueming Lyu", "Ivor W. Tsang"], "authorids": ["lv_yueming@outlook.com", "ivor.tsang@uts.edu.au"], "keywords": ["Curriculum Learning", "deep learning"], "TL;DR": "A novel loss bridges curriculum learning and robust learning", "abstract": "Deep neural networks (DNNs) have great expressive power, which can even memorize samples with wrong labels. It is vitally important to reiterate robustness and generalization in DNNs against label corruption. To this end, this paper studies the 0-1 loss, which has a monotonic relationship between empirical adversary (reweighted) risk (Hu et al. 2018). Although the 0-1 loss is robust to outliers, it is also difficult to optimize.   To efficiently optimize the 0-1 loss while keeping its robust properties, we propose a very simple and efficient loss, i.e. curriculum loss (CL). Our CL  is a tighter upper bound of the 0-1 loss compared with conventional summation based surrogate losses.  Moreover, CL can adaptively select samples for stagewise training. As a result, our loss can be deemed as a novel perspective of curriculum sample selection strategy, which bridges a connection between curriculum learning and robust learning.     Experimental results on noisy MNIST, CIFAR10 and CIFAR100 dataset validate the robustness of the proposed loss.", "pdf": "/pdf/800966a39eedb870f2172779e97ac57edbff69e5.pdf", "paperhash": "lyu|curriculum_loss_robust_learning_and_generalization_against_label_corruption", "_bibtex": "@inproceedings{\nLyu2020Curriculum,\ntitle={Curriculum Loss: Robust Learning and Generalization  against Label Corruption},\nauthor={Yueming Lyu and Ivor W. Tsang},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=rkgt0REKwS}\n}", "full_presentation_video": "", "original_pdf": "/attachment/8f92c68c81714ce3ea0423465464268d22752db5.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "rkgt0REKwS", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper1438/Authors", "ICLR.cc/2020/Conference/Paper1438/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper1438/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper1438/Reviewers", "ICLR.cc/2020/Conference/Paper1438/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper1438/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper1438/Authors|ICLR.cc/2020/Conference/Paper1438/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504156009, "tmdate": 1576860561953, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper1438/Authors", "ICLR.cc/2020/Conference/Paper1438/Reviewers", "ICLR.cc/2020/Conference/Paper1438/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper1438/-/Official_Comment"}}}, {"id": "HJghRHVAKr", "original": null, "number": 3, "cdate": 1571861971721, "ddate": null, "tcdate": 1571861971721, "tmdate": 1572972469060, "tddate": null, "forum": "rkgt0REKwS", "replyto": "rkgt0REKwS", "invitation": "ICLR.cc/2020/Conference/Paper1438/-/Official_Review", "content": {"experience_assessment": "I have read many papers in this area.", "rating": "6: Weak Accept", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #1", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "This paper tackles the problem of learning with noisy labels and proposes a novel cost function that integrates the idea of curriculum learning with the robustness of 0/1 loss. The resulting cost function is theoretically justified and experimentally validated. \n\nPros:\n(1) The proposed cost function is novel in its design, especially the aspect of curriculum learning with a computationally efficient implementation, as in Algorithm 1.\n(2) The new cost function could be treated as a simple-to-implement add-on to make learning more robust to noisy labels. \n(3) The introduction is well formulated and organized with focused motivation.\n\nCons:\n(1) Equ. 9 requires more explanation of the intuition of using a combination of conventional surrogate loss and 0/1 loss, and furthermore the role of the index indicator in balancing the above two parts.\n(2) Curriculum learning focuses on easy example followed by hard ones. Yet noisy examples are mixed with difficult ones in your formulation of sample selection mechanism (index indicator). The pruned examples are therefore more likely to have a high proportion of hard examples, which is undesirable. To illustrates the effectiveness of the proposed algorithm against such scenarios , one would like to see experiments on more difficult datasets such as Tiny-ImageNet. \n(3) It is not clear if the quantitative results in Table 2 and 3 are produced with the pre-defined \\epsilon beforehand or with grid search as done in Table 4. Knowing \\epsilon would render comparison unfair for baselines.\n \nOther remarks:\n(1) E(u) threshold parameter changes from \u201cn\u201d in equation 11 to \u201cC\u201d in equation 13 (probably considering equation 9). In Equ 13, C is given as \"n+0/1 loss\", its transition to the other alternative forms in Equ 18 is not fully explained. \n(2) The purpose of proposition 1 is unclear and may be at least shortened.\n(3) Should have used some uncertainty metric instead.\n(4) Incremental improvement over SOTA. SOTA was actually better in some cases."}, "signatures": ["ICLR.cc/2020/Conference/Paper1438/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1438/AnonReviewer1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Curriculum Loss: Robust Learning and Generalization  against Label Corruption", "authors": ["Yueming Lyu", "Ivor W. Tsang"], "authorids": ["lv_yueming@outlook.com", "ivor.tsang@uts.edu.au"], "keywords": ["Curriculum Learning", "deep learning"], "TL;DR": "A novel loss bridges curriculum learning and robust learning", "abstract": "Deep neural networks (DNNs) have great expressive power, which can even memorize samples with wrong labels. It is vitally important to reiterate robustness and generalization in DNNs against label corruption. To this end, this paper studies the 0-1 loss, which has a monotonic relationship between empirical adversary (reweighted) risk (Hu et al. 2018). Although the 0-1 loss is robust to outliers, it is also difficult to optimize.   To efficiently optimize the 0-1 loss while keeping its robust properties, we propose a very simple and efficient loss, i.e. curriculum loss (CL). Our CL  is a tighter upper bound of the 0-1 loss compared with conventional summation based surrogate losses.  Moreover, CL can adaptively select samples for stagewise training. As a result, our loss can be deemed as a novel perspective of curriculum sample selection strategy, which bridges a connection between curriculum learning and robust learning.     Experimental results on noisy MNIST, CIFAR10 and CIFAR100 dataset validate the robustness of the proposed loss.", "pdf": "/pdf/800966a39eedb870f2172779e97ac57edbff69e5.pdf", "paperhash": "lyu|curriculum_loss_robust_learning_and_generalization_against_label_corruption", "_bibtex": "@inproceedings{\nLyu2020Curriculum,\ntitle={Curriculum Loss: Robust Learning and Generalization  against Label Corruption},\nauthor={Yueming Lyu and Ivor W. Tsang},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=rkgt0REKwS}\n}", "full_presentation_video": "", "original_pdf": "/attachment/8f92c68c81714ce3ea0423465464268d22752db5.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "rkgt0REKwS", "replyto": "rkgt0REKwS", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper1438/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper1438/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1575475077888, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper1438/Reviewers"], "noninvitees": [], "tcdate": 1570237737394, "tmdate": 1575475077900, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper1438/-/Official_Review"}}}], "count": 9}