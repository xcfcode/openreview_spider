{"notes": [{"id": "Bkel6ertwS", "original": "ryg5RxWFDB", "number": 2562, "cdate": 1569439928398, "ddate": null, "tcdate": 1569439928398, "tmdate": 1577168282563, "tddate": null, "forum": "Bkel6ertwS", "replyto": null, "invitation": "ICLR.cc/2020/Conference/-/Blind_Submission", "content": {"authorids": ["michal.rozenwald@gmail.com", "agalitzina@gmail.com", "ekhrameeva@gmail.com", "grigory.sapunov@gmail.codelfm", "mikhail.gelfand@gmail.com"], "title": "Learning DNA folding patterns with Recurrent Neural Networks ", "authors": ["Michal Rozenwald", "Aleksandra Galitsyna", "Ekaterina Khrameeva", "Grigory Sapunov", "Mikhail S. Gelfand"], "pdf": "/pdf/203cd6f32544775beb171bdda9ed7221c2e0829e.pdf", "TL;DR": "We apply RNN to solve the biological problem of chromatin folding patterns prediction from epigenetic marks and demonstrate for the first time that utilization of memory of sequential states on DNA molecule is significant for the best performance.", "abstract": "\nThe recent expansion of machine learning applications to molecular biology proved to have a significant contribution to our understanding of biological systems, and genome functioning in particular. Technological advances enabled the collection of large epigenetic datasets, including information about various DNA binding factors (ChIP-Seq) and DNA spatial structure (Hi-C). Several studies have confirmed the correlation between DNA binding factors and Topologically Associating Domains (TADs) in DNA structure. However, the information about physical proximity represented by genomic coordinate was not yet used for the improvement of the prediction models.\n\nIn this research, we focus on Machine Learning methods for prediction of folding patterns of DNA in a classical model organism Drosophila melanogaster. The paper considers linear models with four types of regularization, Gradient Boosting and Recurrent Neural Networks for the prediction of chromatin folding patterns from epigenetic marks. The bidirectional LSTM RNN model outperformed all the models and gained the best prediction scores. This demonstrates the utilization of complex models and the importance of memory of sequential DNA states for the chromatin folding. We identify informative epigenetic features that lead to the further conclusion of their biological significance.", "code": "https://www.dropbox.com/sh/izy4exnkosd309o/AACl7N8xZX1X13EOSwC_mNj1a?dl=0", "keywords": ["Machine Learning", "Recurrent Neural Networks", "3D chromatin structure", "topologically associating domains", "computational biology."], "paperhash": "rozenwald|learning_dna_folding_patterns_with_recurrent_neural_networks", "original_pdf": "/attachment/562ad6f8c069a79a93b4f771ddc6a7e1199bc114.pdf", "_bibtex": "@misc{\nrozenwald2020learning,\ntitle={Learning {\\{}DNA{\\}} folding patterns with Recurrent Neural Networks },\nauthor={Michal Rozenwald and Aleksandra Galitsyna and Ekaterina Khrameeva and Grigory Sapunov and Mikhail S. Gelfand},\nyear={2020},\nurl={https://openreview.net/forum?id=Bkel6ertwS}\n}"}, "signatures": ["ICLR.cc/2020/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference"], "details": {"replyCount": 10, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"reply": {"readers": {"values-regex": ".*"}, "writers": {"values": ["ICLR.cc/2020/Conference"]}, "signatures": {"values": ["ICLR.cc/2020/Conference"]}, "content": {"spotlight_video": {"value-regex": ".*"}, "full_presentation_video": {"value-regex": ".*"}, "original_pdf": {"required": false, "description": "Upload a PDF file that ends with .pdf", "value-regex": ".*"}, "appendix": {"value-regex": ".*"}, "authorids": {"values-regex": ".*"}, "poster": {"value-regex": ".*"}, "authors": {"values": ["Anonymous"]}, "slides": {"value-regex": ".*"}}}, "final": [], "signatures": ["ICLR.cc/2020/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference"], "noninvitees": [], "tcdate": 1569271260237, "tmdate": 1593459412141, "id": "ICLR.cc/2020/Conference/-/Blind_Submission"}}, "tauthor": "OpenReview.net"}, {"id": "0emF5aKs-X", "original": null, "number": 1, "cdate": 1576798752203, "ddate": null, "tcdate": 1576798752203, "tmdate": 1576800883435, "tddate": null, "forum": "Bkel6ertwS", "replyto": "Bkel6ertwS", "invitation": "ICLR.cc/2020/Conference/Paper2562/-/Decision", "content": {"decision": "Reject", "comment": "The authors consider the problem of predicting DNA folding patterns.                                                               \nThey use a range of simple, linear models and find that a bi-LSTM architecture                                                     \nyielded best performance.                                                                                                          \n                                                                                                                                   \nThis paper is below acceptance.                                                                                                    \nReviewers pointed out strong similarity to previously published work.                                                              \nFurthermore the manuscript lacked in clarity, leaving uncertain eg details about                                                   \nexperimental details. ", "title": "Paper Decision"}, "signatures": ["ICLR.cc/2020/Conference/Program_Chairs"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Program_Chairs"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["michal.rozenwald@gmail.com", "agalitzina@gmail.com", "ekhrameeva@gmail.com", "grigory.sapunov@gmail.codelfm", "mikhail.gelfand@gmail.com"], "title": "Learning DNA folding patterns with Recurrent Neural Networks ", "authors": ["Michal Rozenwald", "Aleksandra Galitsyna", "Ekaterina Khrameeva", "Grigory Sapunov", "Mikhail S. Gelfand"], "pdf": "/pdf/203cd6f32544775beb171bdda9ed7221c2e0829e.pdf", "TL;DR": "We apply RNN to solve the biological problem of chromatin folding patterns prediction from epigenetic marks and demonstrate for the first time that utilization of memory of sequential states on DNA molecule is significant for the best performance.", "abstract": "\nThe recent expansion of machine learning applications to molecular biology proved to have a significant contribution to our understanding of biological systems, and genome functioning in particular. Technological advances enabled the collection of large epigenetic datasets, including information about various DNA binding factors (ChIP-Seq) and DNA spatial structure (Hi-C). Several studies have confirmed the correlation between DNA binding factors and Topologically Associating Domains (TADs) in DNA structure. However, the information about physical proximity represented by genomic coordinate was not yet used for the improvement of the prediction models.\n\nIn this research, we focus on Machine Learning methods for prediction of folding patterns of DNA in a classical model organism Drosophila melanogaster. The paper considers linear models with four types of regularization, Gradient Boosting and Recurrent Neural Networks for the prediction of chromatin folding patterns from epigenetic marks. The bidirectional LSTM RNN model outperformed all the models and gained the best prediction scores. This demonstrates the utilization of complex models and the importance of memory of sequential DNA states for the chromatin folding. We identify informative epigenetic features that lead to the further conclusion of their biological significance.", "code": "https://www.dropbox.com/sh/izy4exnkosd309o/AACl7N8xZX1X13EOSwC_mNj1a?dl=0", "keywords": ["Machine Learning", "Recurrent Neural Networks", "3D chromatin structure", "topologically associating domains", "computational biology."], "paperhash": "rozenwald|learning_dna_folding_patterns_with_recurrent_neural_networks", "original_pdf": "/attachment/562ad6f8c069a79a93b4f771ddc6a7e1199bc114.pdf", "_bibtex": "@misc{\nrozenwald2020learning,\ntitle={Learning {\\{}DNA{\\}} folding patterns with Recurrent Neural Networks },\nauthor={Michal Rozenwald and Aleksandra Galitsyna and Ekaterina Khrameeva and Grigory Sapunov and Mikhail S. Gelfand},\nyear={2020},\nurl={https://openreview.net/forum?id=Bkel6ertwS}\n}"}, "tags": [], "invitation": {"reply": {"writers": {"description": "How your identity will be displayed.", "values-regex": ["ICLR.cc/2020/Conference/Program_Chairs"]}, "signatures": {"values": ["ICLR.cc/2020/Conference/Program_Chairs"], "description": "How your identity will be displayed."}, "content": {"decision": {"value-radio": ["Accept (Spotlight)", "Accept (Talk)", "Accept (Poster)", "Reject"], "description": "Decision", "required": true, "order": 2}, "title": {"value": "Paper Decision", "required": true, "order": 1}, "comment": {"value-regex": "[\\S\\s]{0,5000}", "description": "", "required": false, "order": 3}}, "forum": "Bkel6ertwS", "replyto": "Bkel6ertwS", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}}, "expdate": 1576854540000, "duedate": 1576853940000, "multiReply": false, "readers": ["everyone"], "invitees": ["ICLR.cc/2020/Conference/Program_Chairs"], "tcdate": 1576795703786, "tmdate": 1576800251233, "super": "ICLR.cc/2020/Conference/-/Decision", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper2562/-/Decision"}}}, {"id": "HygflpY3sH", "original": null, "number": 3, "cdate": 1573850346161, "ddate": null, "tcdate": 1573850346161, "tmdate": 1573854211389, "tddate": null, "forum": "Bkel6ertwS", "replyto": "HylmAQEc_B", "invitation": "ICLR.cc/2020/Conference/Paper2562/-/Official_Comment", "content": {"title": "Response to Blind Review #2", "comment": "Thank you very much for your detailed review! Comments below:\n\n1. The main focused of this work is to predict the information that characterizes the 3D chromatin structure instead of the HI-C full reconstruction. We do not use the Hi-C map as input to our models, on the other hand, we are interested in exploring what other biological experiments can bring insides into the formation of chromatin folding. No other full published work was performed to predict Topologically Associated Domain characteristics from ChIP-seq data, to the best of our knowledge. \n\nWe have expanded the literature review and the description of the differences between the published papers.\n\n2. DNA molecule is folded in a complex 3D architecture that contains local regions of higher number of contacts called Topologically Associating Domains (TADs), that affect the regions from 20 000 to 200 000 DNA base pairs (20 Kb and 200 Kb for brevity, according to the naming conventions). We sought for a measure that will represent the presence of TADs in the genome from Hi-C input data. Gamma transitional is a good candidate for that, although the process of its calculation is a complicated procedure. \n\nThe input features of our model were the ChIP-Seq properties for sets of chromatin marks. \nThe resolution of the Hi-C map that we use is 20 000 basepairs  (20 Kb). This required the ChIP-Seq features to be calculated as the integrated value from the available ChIP-Seq signal for the corresponding 20 Kb.  Bins from the end of the chromosomes were taken together with parts of the ends of the next chromosome. Each feature is a float number that characterizes each DNA bin. Thus, the features were represented directly after the pre-processing that is described in section 3.1. This data was not binarized.\n\n3. DNA is a long structured molecule formed out of nucleotides arranged in a linear sequence. \nDNA is double-stranded meaning each nucleotide has a complementary pair, together called a base pair. DNA molecule might be several million base pairs (Mb) long and serves as the storage and the means of the utilization of genetic information. The information content of DNA is equivalent if read in forward and reverse direction, thus all local properties of its sequence should be independent of the selected direction.\nThe input of the models are features that characterize the DNA segments which encourages us to us DNA sequentiality properties. Regions of the DNA that are physically close to each other are more likely to have similar gamma transitional scores. \n\nWe selected bidirectional LSTM RNN to use this property of DNA molecule in the architecture itself. Similarly to the usage of recurrent neural networks for text application where the sequential order matters. \n\n4. For all the models the wMSE was used as training loss, which is important for the comparison of the models.\n\n5. Currently, we perform the features importance extraction using features drop out. Correlating the activations of LSTM units with input features and also analyze if importances depend on the position of features is a good direction for further research.\n\n6. Section 4.3 Methods contain information about the hyper-parameters of the biLSTM that we evaluated (page 4). For instance, number of LSTM Units, number of training Epochs, the sequence length of input RNN objects of consecutive DNA bins.\nMain results of the experiment are shown on Figure 5. \n\n7. The wMSE was chosen as it is a straightforward approach for the weighting of the samples. \nHowever, we have calculated the values of the metrics to compare the results and added them to the paper.\n\n8. DNA from the left and the right to the central bin could potentially have the same level of importance for predicting the characteristic of the 3D structure of the chromatin. The Bidirectional LSTM kept information from both sides of the central bin. One output value is produced for each set of DNA bing and no hidden states are ignored, all the stated features contribute to the final prediction.  \n\nAs a result:\ni) We have extended the literature review section and added the suggested papers. And pointing out the difference between the paper\u2019s focus.\nii) We have expanded the description of the data and methods to increase the clarity of the work.\niii) We have also added a broader set of evaluation matrices to prove the performance quality of our research.\n"}, "signatures": ["ICLR.cc/2020/Conference/Paper2562/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper2562/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["michal.rozenwald@gmail.com", "agalitzina@gmail.com", "ekhrameeva@gmail.com", "grigory.sapunov@gmail.codelfm", "mikhail.gelfand@gmail.com"], "title": "Learning DNA folding patterns with Recurrent Neural Networks ", "authors": ["Michal Rozenwald", "Aleksandra Galitsyna", "Ekaterina Khrameeva", "Grigory Sapunov", "Mikhail S. Gelfand"], "pdf": "/pdf/203cd6f32544775beb171bdda9ed7221c2e0829e.pdf", "TL;DR": "We apply RNN to solve the biological problem of chromatin folding patterns prediction from epigenetic marks and demonstrate for the first time that utilization of memory of sequential states on DNA molecule is significant for the best performance.", "abstract": "\nThe recent expansion of machine learning applications to molecular biology proved to have a significant contribution to our understanding of biological systems, and genome functioning in particular. Technological advances enabled the collection of large epigenetic datasets, including information about various DNA binding factors (ChIP-Seq) and DNA spatial structure (Hi-C). Several studies have confirmed the correlation between DNA binding factors and Topologically Associating Domains (TADs) in DNA structure. However, the information about physical proximity represented by genomic coordinate was not yet used for the improvement of the prediction models.\n\nIn this research, we focus on Machine Learning methods for prediction of folding patterns of DNA in a classical model organism Drosophila melanogaster. The paper considers linear models with four types of regularization, Gradient Boosting and Recurrent Neural Networks for the prediction of chromatin folding patterns from epigenetic marks. The bidirectional LSTM RNN model outperformed all the models and gained the best prediction scores. This demonstrates the utilization of complex models and the importance of memory of sequential DNA states for the chromatin folding. We identify informative epigenetic features that lead to the further conclusion of their biological significance.", "code": "https://www.dropbox.com/sh/izy4exnkosd309o/AACl7N8xZX1X13EOSwC_mNj1a?dl=0", "keywords": ["Machine Learning", "Recurrent Neural Networks", "3D chromatin structure", "topologically associating domains", "computational biology."], "paperhash": "rozenwald|learning_dna_folding_patterns_with_recurrent_neural_networks", "original_pdf": "/attachment/562ad6f8c069a79a93b4f771ddc6a7e1199bc114.pdf", "_bibtex": "@misc{\nrozenwald2020learning,\ntitle={Learning {\\{}DNA{\\}} folding patterns with Recurrent Neural Networks },\nauthor={Michal Rozenwald and Aleksandra Galitsyna and Ekaterina Khrameeva and Grigory Sapunov and Mikhail S. Gelfand},\nyear={2020},\nurl={https://openreview.net/forum?id=Bkel6ertwS}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "Bkel6ertwS", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper2562/Authors", "ICLR.cc/2020/Conference/Paper2562/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper2562/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper2562/Reviewers", "ICLR.cc/2020/Conference/Paper2562/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper2562/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper2562/Authors|ICLR.cc/2020/Conference/Paper2562/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504139458, "tmdate": 1576860534455, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper2562/Authors", "ICLR.cc/2020/Conference/Paper2562/Reviewers", "ICLR.cc/2020/Conference/Paper2562/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper2562/-/Official_Comment"}}}, {"id": "r1e_byc2sH", "original": null, "number": 5, "cdate": 1573850880125, "ddate": null, "tcdate": 1573850880125, "tmdate": 1573853014711, "tddate": null, "forum": "Bkel6ertwS", "replyto": "ryg8ROfaYH", "invitation": "ICLR.cc/2020/Conference/Paper2562/-/Official_Comment", "content": {"title": "Response to Blind Review #1", "comment": "Thank you very much for your thoughtful review! Comments below:\n\na) We have expanded the description for the wMSE in the paper. The parameter K in the wMSE definition stands for the number of input objects (in test/val/train sets). \n\nb) To increase clarity we have updated the definition of the loss function to be called modified wMSE. \n\nc) Fixed the citation.\n\nd) We have rephrased the suggested paragraph about the DNA properties.\nDNA is a long structured molecule formed out of nucleotides arranged in a linear sequence. DNA is double-stranded which means each nucleotide has a complementary pair, together called a base pair. DNA molecule might be several million base pairs (Mb) long and serves as the storage and the means of the utilization of genetic information. The information content of DNA is equivalent if read in forward and reverse direction, thus all local properties of its sequence should be independent of the selected direction. To use this property of DNA molecule, we selected bidirectional LSTM RNN architecture \n\ne) Corrected the x-axis label.\n\nf) We have expanded the discussion about the models choice and the advantage of using Neural networks. The NNs keep the information about the local processes. While the linear regression model looks only at one data point. The LSTM keeps in memory information about the bins that are surrounding the central bin. In comparison to other models for RNNs the sequential order models meters mostly.\n\ng) We have extended the description of the evaluation of the experiments.\n"}, "signatures": ["ICLR.cc/2020/Conference/Paper2562/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper2562/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["michal.rozenwald@gmail.com", "agalitzina@gmail.com", "ekhrameeva@gmail.com", "grigory.sapunov@gmail.codelfm", "mikhail.gelfand@gmail.com"], "title": "Learning DNA folding patterns with Recurrent Neural Networks ", "authors": ["Michal Rozenwald", "Aleksandra Galitsyna", "Ekaterina Khrameeva", "Grigory Sapunov", "Mikhail S. Gelfand"], "pdf": "/pdf/203cd6f32544775beb171bdda9ed7221c2e0829e.pdf", "TL;DR": "We apply RNN to solve the biological problem of chromatin folding patterns prediction from epigenetic marks and demonstrate for the first time that utilization of memory of sequential states on DNA molecule is significant for the best performance.", "abstract": "\nThe recent expansion of machine learning applications to molecular biology proved to have a significant contribution to our understanding of biological systems, and genome functioning in particular. Technological advances enabled the collection of large epigenetic datasets, including information about various DNA binding factors (ChIP-Seq) and DNA spatial structure (Hi-C). Several studies have confirmed the correlation between DNA binding factors and Topologically Associating Domains (TADs) in DNA structure. However, the information about physical proximity represented by genomic coordinate was not yet used for the improvement of the prediction models.\n\nIn this research, we focus on Machine Learning methods for prediction of folding patterns of DNA in a classical model organism Drosophila melanogaster. The paper considers linear models with four types of regularization, Gradient Boosting and Recurrent Neural Networks for the prediction of chromatin folding patterns from epigenetic marks. The bidirectional LSTM RNN model outperformed all the models and gained the best prediction scores. This demonstrates the utilization of complex models and the importance of memory of sequential DNA states for the chromatin folding. We identify informative epigenetic features that lead to the further conclusion of their biological significance.", "code": "https://www.dropbox.com/sh/izy4exnkosd309o/AACl7N8xZX1X13EOSwC_mNj1a?dl=0", "keywords": ["Machine Learning", "Recurrent Neural Networks", "3D chromatin structure", "topologically associating domains", "computational biology."], "paperhash": "rozenwald|learning_dna_folding_patterns_with_recurrent_neural_networks", "original_pdf": "/attachment/562ad6f8c069a79a93b4f771ddc6a7e1199bc114.pdf", "_bibtex": "@misc{\nrozenwald2020learning,\ntitle={Learning {\\{}DNA{\\}} folding patterns with Recurrent Neural Networks },\nauthor={Michal Rozenwald and Aleksandra Galitsyna and Ekaterina Khrameeva and Grigory Sapunov and Mikhail S. Gelfand},\nyear={2020},\nurl={https://openreview.net/forum?id=Bkel6ertwS}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "Bkel6ertwS", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper2562/Authors", "ICLR.cc/2020/Conference/Paper2562/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper2562/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper2562/Reviewers", "ICLR.cc/2020/Conference/Paper2562/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper2562/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper2562/Authors|ICLR.cc/2020/Conference/Paper2562/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504139458, "tmdate": 1576860534455, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper2562/Authors", "ICLR.cc/2020/Conference/Paper2562/Reviewers", "ICLR.cc/2020/Conference/Paper2562/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper2562/-/Official_Comment"}}}, {"id": "H1lpF642sS", "original": null, "number": 2, "cdate": 1573830021437, "ddate": null, "tcdate": 1573830021437, "tmdate": 1573852934964, "tddate": null, "forum": "Bkel6ertwS", "replyto": "Bkel6ertwS", "invitation": "ICLR.cc/2020/Conference/Paper2562/-/Official_Comment", "content": {"title": "Thank you for the reviews and updates based on the comments", "comment": "Thank you very much for your thoughtful review! We have revised the paper according to the suggestions and would like to answer the reviewer\u2019s questions as follows:\n\n1. Our work is focused on predicting the information that characterizes the 3D chromatin structure. We do not use the Hi-C map as input to our models, on the other hand, we are interested in exploring what other biological experiments can bring insides into the formation of chromatin folding. \nTo the best of our knowledge, no other full published work predict Topologically Associated Domain characteristic Transitional Gamma from ChIP-seq data.\n\n2. We have expanded the literature review and the description of the differences between the published papers.\n\n3. The information content of DNA molecule is equivalent if read in forward and reverse direction, thus all local properties of its sequence should be independent of the selected direction. We sought for a model that will use this property of the DNA and thus selected bidirectional LSTM RNN architecture. \n\n4. All of the models were trained using the custom weighed MSE metric as loss function, to present a fair comparison of the results. \n\n5. We have added a table with a broader list of models and calculated additional evaluation matrices as was suggested by the reviewers. Now you can find the MSE, MAE, R^2 and weighted MSE score for the training and test sets of different types of the explored models. \n\n6. The best results were achieved using the bidirectional LSTM RNN model. It proves that the utilization of the linear sequence properties of the DNA brings valuable improvement.\n\n7. Moreover, there was no other baseline model ever provided for this biologically meaningful dataset. As a result, now we have a set of models with full evaluation scores. \n\nWe have made some changes to our manuscript according to the suggestions, expanded the description of the models as well as the data and added a set of evaluations. "}, "signatures": ["ICLR.cc/2020/Conference/Paper2562/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper2562/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["michal.rozenwald@gmail.com", "agalitzina@gmail.com", "ekhrameeva@gmail.com", "grigory.sapunov@gmail.codelfm", "mikhail.gelfand@gmail.com"], "title": "Learning DNA folding patterns with Recurrent Neural Networks ", "authors": ["Michal Rozenwald", "Aleksandra Galitsyna", "Ekaterina Khrameeva", "Grigory Sapunov", "Mikhail S. Gelfand"], "pdf": "/pdf/203cd6f32544775beb171bdda9ed7221c2e0829e.pdf", "TL;DR": "We apply RNN to solve the biological problem of chromatin folding patterns prediction from epigenetic marks and demonstrate for the first time that utilization of memory of sequential states on DNA molecule is significant for the best performance.", "abstract": "\nThe recent expansion of machine learning applications to molecular biology proved to have a significant contribution to our understanding of biological systems, and genome functioning in particular. Technological advances enabled the collection of large epigenetic datasets, including information about various DNA binding factors (ChIP-Seq) and DNA spatial structure (Hi-C). Several studies have confirmed the correlation between DNA binding factors and Topologically Associating Domains (TADs) in DNA structure. However, the information about physical proximity represented by genomic coordinate was not yet used for the improvement of the prediction models.\n\nIn this research, we focus on Machine Learning methods for prediction of folding patterns of DNA in a classical model organism Drosophila melanogaster. The paper considers linear models with four types of regularization, Gradient Boosting and Recurrent Neural Networks for the prediction of chromatin folding patterns from epigenetic marks. The bidirectional LSTM RNN model outperformed all the models and gained the best prediction scores. This demonstrates the utilization of complex models and the importance of memory of sequential DNA states for the chromatin folding. We identify informative epigenetic features that lead to the further conclusion of their biological significance.", "code": "https://www.dropbox.com/sh/izy4exnkosd309o/AACl7N8xZX1X13EOSwC_mNj1a?dl=0", "keywords": ["Machine Learning", "Recurrent Neural Networks", "3D chromatin structure", "topologically associating domains", "computational biology."], "paperhash": "rozenwald|learning_dna_folding_patterns_with_recurrent_neural_networks", "original_pdf": "/attachment/562ad6f8c069a79a93b4f771ddc6a7e1199bc114.pdf", "_bibtex": "@misc{\nrozenwald2020learning,\ntitle={Learning {\\{}DNA{\\}} folding patterns with Recurrent Neural Networks },\nauthor={Michal Rozenwald and Aleksandra Galitsyna and Ekaterina Khrameeva and Grigory Sapunov and Mikhail S. Gelfand},\nyear={2020},\nurl={https://openreview.net/forum?id=Bkel6ertwS}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "Bkel6ertwS", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper2562/Authors", "ICLR.cc/2020/Conference/Paper2562/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper2562/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper2562/Reviewers", "ICLR.cc/2020/Conference/Paper2562/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper2562/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper2562/Authors|ICLR.cc/2020/Conference/Paper2562/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504139458, "tmdate": 1576860534455, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper2562/Authors", "ICLR.cc/2020/Conference/Paper2562/Reviewers", "ICLR.cc/2020/Conference/Paper2562/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper2562/-/Official_Comment"}}}, {"id": "rkeXVCKhsH", "original": null, "number": 4, "cdate": 1573850667370, "ddate": null, "tcdate": 1573850667370, "tmdate": 1573850667370, "tddate": null, "forum": "Bkel6ertwS", "replyto": "rJe0SjlScS", "invitation": "ICLR.cc/2020/Conference/Paper2562/-/Official_Comment", "content": {"title": "Response to Blind Review #3", "comment": "Thank you very much for your thoughtful review! Comments below:\n\nIn the current work, we define an architecture of a machine learning algorithm that will effectively solve the problem of prediction of DNA structure (TADs) formation as assessed by gamma transitional from the binding of well-studied factors of chromatin in Drosophila. \nDue to biological reasons, we do not expect the underlying mechanism of TADs formation to be the same for other cell types and organisms, thus we didn\u2019t test our trained models on other Hi-C datasets. Due to the fundamentally different nature of experiments, we also didn\u2019t try to test our models on ATAC-Seq data. Of note, ATAC-Seq contains information about DNA binding of all the factors and does not allow an explanation of what factors are explanatory for the structure formation. However, these ideas are highlighting new directions for further research.\n\nThe value 11 comes from the distribution of the target value Transitional Gamma. Thus, in order to give higher value to the smaller true values, we divide the difference between the maximum value and the true value of the bin by the maximum value. In order to avoid division and multiplication by 0 instead of the maximum value we max_value + 1.  The updated description of the weighted MSE function can be found in the new version of the paper.\n\nIn order to show the advantage of using the LSTM model, we added the results of more experiments for a broader set of evaluation metrics. "}, "signatures": ["ICLR.cc/2020/Conference/Paper2562/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper2562/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["michal.rozenwald@gmail.com", "agalitzina@gmail.com", "ekhrameeva@gmail.com", "grigory.sapunov@gmail.codelfm", "mikhail.gelfand@gmail.com"], "title": "Learning DNA folding patterns with Recurrent Neural Networks ", "authors": ["Michal Rozenwald", "Aleksandra Galitsyna", "Ekaterina Khrameeva", "Grigory Sapunov", "Mikhail S. Gelfand"], "pdf": "/pdf/203cd6f32544775beb171bdda9ed7221c2e0829e.pdf", "TL;DR": "We apply RNN to solve the biological problem of chromatin folding patterns prediction from epigenetic marks and demonstrate for the first time that utilization of memory of sequential states on DNA molecule is significant for the best performance.", "abstract": "\nThe recent expansion of machine learning applications to molecular biology proved to have a significant contribution to our understanding of biological systems, and genome functioning in particular. Technological advances enabled the collection of large epigenetic datasets, including information about various DNA binding factors (ChIP-Seq) and DNA spatial structure (Hi-C). Several studies have confirmed the correlation between DNA binding factors and Topologically Associating Domains (TADs) in DNA structure. However, the information about physical proximity represented by genomic coordinate was not yet used for the improvement of the prediction models.\n\nIn this research, we focus on Machine Learning methods for prediction of folding patterns of DNA in a classical model organism Drosophila melanogaster. The paper considers linear models with four types of regularization, Gradient Boosting and Recurrent Neural Networks for the prediction of chromatin folding patterns from epigenetic marks. The bidirectional LSTM RNN model outperformed all the models and gained the best prediction scores. This demonstrates the utilization of complex models and the importance of memory of sequential DNA states for the chromatin folding. We identify informative epigenetic features that lead to the further conclusion of their biological significance.", "code": "https://www.dropbox.com/sh/izy4exnkosd309o/AACl7N8xZX1X13EOSwC_mNj1a?dl=0", "keywords": ["Machine Learning", "Recurrent Neural Networks", "3D chromatin structure", "topologically associating domains", "computational biology."], "paperhash": "rozenwald|learning_dna_folding_patterns_with_recurrent_neural_networks", "original_pdf": "/attachment/562ad6f8c069a79a93b4f771ddc6a7e1199bc114.pdf", "_bibtex": "@misc{\nrozenwald2020learning,\ntitle={Learning {\\{}DNA{\\}} folding patterns with Recurrent Neural Networks },\nauthor={Michal Rozenwald and Aleksandra Galitsyna and Ekaterina Khrameeva and Grigory Sapunov and Mikhail S. Gelfand},\nyear={2020},\nurl={https://openreview.net/forum?id=Bkel6ertwS}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "Bkel6ertwS", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper2562/Authors", "ICLR.cc/2020/Conference/Paper2562/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper2562/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper2562/Reviewers", "ICLR.cc/2020/Conference/Paper2562/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper2562/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper2562/Authors|ICLR.cc/2020/Conference/Paper2562/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504139458, "tmdate": 1576860534455, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper2562/Authors", "ICLR.cc/2020/Conference/Paper2562/Reviewers", "ICLR.cc/2020/Conference/Paper2562/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper2562/-/Official_Comment"}}}, {"id": "HylmAQEc_B", "original": null, "number": 1, "cdate": 1570550731116, "ddate": null, "tcdate": 1570550731116, "tmdate": 1572972322120, "tddate": null, "forum": "Bkel6ertwS", "replyto": "Bkel6ertwS", "invitation": "ICLR.cc/2020/Conference/Paper2562/-/Official_Review", "content": {"rating": "1: Reject", "experience_assessment": "I have published in this field for several years.", "review_assessment:_checking_correctness_of_derivations_and_theory": "N/A", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #2", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review": "The authors compared a bidirectional LSTM to traditional machine learning models for genomic contact prediction. Although the paper presents an interesting application of ML, I vote for rejection since i)  the paper is similar to previously published works and lacks methodological novelty, ii) the description about the data and methods is not written clearly enough, and iii) the evaluation needs to be strengthened by additional baseline models and evaluation metrics.\n\nMajor comments\n=============\n1. As pointed out by Maria Anna Rapsomaniki, the paper is similar to previously published papers, which are not cited.\n\n2. It is unclear which features were used as inputs. How were the features that are described in section 3.1 represented? Are these binary values or the mean of the Hi-C signal over the genomic region? What does 20kb mean? How were genomic segments of different chromosomes treated?\n\n3. The motivation of using a biLSTM in section 4.3 is unclear. What has the choice of a biLSTM to do with the fact that DNA is double stranded? The DNA is not used as input to the model and genomic contacts can be formed between non-adjacent segments. Please compare recurrent models to non-recurrent models such as fully connected or convolutional networks.\n\n4. The authors used the weighted MSE as evaluation metric, which was used as training loss of the biLSTM, but it is unclear if the same loss was used for linear and gradient boosting regression. To understand if the performance differences are due to the loss function or model architecture, the authors should use the same loss function for training all models, and use additional evaluation metrics such as the MSE and R^2 score.\n\n5. The authors used linear regression weights to quantify feature importance (figure 4). It is unclear if the biLSTM assigned the same importance to features. To quantify the importance of features learned by the biLSTM, the authors could consider correlating the activations of LSTM units with input features, and also analyze if importances depend on the position of features.\n\n6. Which hyper-parameters of the biLSTM and baseline method did the authors tune and how?\n\n7. The authors should compare the described weighted MSE to the mean squared logarithmic error loss, which is commonly used for penalizing large errors less.\n\n8. Why did the authors use the activation of the center LSTM hidden state instead of concatenating the last hidden state of the forward and reverse LSTM? By using the center hidden state, half of the forward and reverse LSTM activations are ignored."}, "signatures": ["ICLR.cc/2020/Conference/Paper2562/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper2562/AnonReviewer2"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["michal.rozenwald@gmail.com", "agalitzina@gmail.com", "ekhrameeva@gmail.com", "grigory.sapunov@gmail.codelfm", "mikhail.gelfand@gmail.com"], "title": "Learning DNA folding patterns with Recurrent Neural Networks ", "authors": ["Michal Rozenwald", "Aleksandra Galitsyna", "Ekaterina Khrameeva", "Grigory Sapunov", "Mikhail S. Gelfand"], "pdf": "/pdf/203cd6f32544775beb171bdda9ed7221c2e0829e.pdf", "TL;DR": "We apply RNN to solve the biological problem of chromatin folding patterns prediction from epigenetic marks and demonstrate for the first time that utilization of memory of sequential states on DNA molecule is significant for the best performance.", "abstract": "\nThe recent expansion of machine learning applications to molecular biology proved to have a significant contribution to our understanding of biological systems, and genome functioning in particular. Technological advances enabled the collection of large epigenetic datasets, including information about various DNA binding factors (ChIP-Seq) and DNA spatial structure (Hi-C). Several studies have confirmed the correlation between DNA binding factors and Topologically Associating Domains (TADs) in DNA structure. However, the information about physical proximity represented by genomic coordinate was not yet used for the improvement of the prediction models.\n\nIn this research, we focus on Machine Learning methods for prediction of folding patterns of DNA in a classical model organism Drosophila melanogaster. The paper considers linear models with four types of regularization, Gradient Boosting and Recurrent Neural Networks for the prediction of chromatin folding patterns from epigenetic marks. The bidirectional LSTM RNN model outperformed all the models and gained the best prediction scores. This demonstrates the utilization of complex models and the importance of memory of sequential DNA states for the chromatin folding. We identify informative epigenetic features that lead to the further conclusion of their biological significance.", "code": "https://www.dropbox.com/sh/izy4exnkosd309o/AACl7N8xZX1X13EOSwC_mNj1a?dl=0", "keywords": ["Machine Learning", "Recurrent Neural Networks", "3D chromatin structure", "topologically associating domains", "computational biology."], "paperhash": "rozenwald|learning_dna_folding_patterns_with_recurrent_neural_networks", "original_pdf": "/attachment/562ad6f8c069a79a93b4f771ddc6a7e1199bc114.pdf", "_bibtex": "@misc{\nrozenwald2020learning,\ntitle={Learning {\\{}DNA{\\}} folding patterns with Recurrent Neural Networks },\nauthor={Michal Rozenwald and Aleksandra Galitsyna and Ekaterina Khrameeva and Grigory Sapunov and Mikhail S. Gelfand},\nyear={2020},\nurl={https://openreview.net/forum?id=Bkel6ertwS}\n}"}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "Bkel6ertwS", "replyto": "Bkel6ertwS", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper2562/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper2562/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1575577537697, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper2562/Reviewers"], "noninvitees": [], "tcdate": 1570237721075, "tmdate": 1575577537711, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper2562/-/Official_Review"}}}, {"id": "ryg8ROfaYH", "original": null, "number": 2, "cdate": 1571789006502, "ddate": null, "tcdate": 1571789006502, "tmdate": 1572972322050, "tddate": null, "forum": "Bkel6ertwS", "replyto": "Bkel6ertwS", "invitation": "ICLR.cc/2020/Conference/Paper2562/-/Official_Review", "content": {"experience_assessment": "I have read many papers in this area.", "rating": "3: Weak Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #1", "review_assessment:_checking_correctness_of_derivations_and_theory": "N/A", "review": "The authors utilise DNA spatial structures called Topologically-associative domains (TADs) from Hi-C data (of the Drosophila fly) and epigenetic marks (such as binding factors) from Chiq-seq data, thereby making use of physical proximity, to predict DNA folding patterns. The authors use a bidirectional LSTM RNN further emphasising that memory of the DNA states contributes to chromatin folding structures.\n\nThe paper offers for a good read. \n\nBelow are comments for improvement and clarification.\n\na) There is only one equation in the paper and this is also not given clearly. What is the K being summed over? \n\nb) wMSE is an old concept and depending on the objective function, the equation can vary. Therefore, change the sentence to read that the authors have a \u2018modified' wMSE instead. \n\nc) Section 3.2, Page 3 last line: what is [5]?\n\nd) Section 4.3: 3rd paragraph, last line. Consider formalising the sentence, it will make it more readable. \n\ne) Figure 5: Right panel (top and bottom): correct the x-axis label\n\nf) There is no discussion explaining why regression is better or worse than a neural network, in this application setting. \n\ng) Figure 6 and associated experiment is very interesting and important. The authors should elaborate why, in certain cases, there were huge negative errors in training whereas the test error was positive."}, "signatures": ["ICLR.cc/2020/Conference/Paper2562/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper2562/AnonReviewer1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["michal.rozenwald@gmail.com", "agalitzina@gmail.com", "ekhrameeva@gmail.com", "grigory.sapunov@gmail.codelfm", "mikhail.gelfand@gmail.com"], "title": "Learning DNA folding patterns with Recurrent Neural Networks ", "authors": ["Michal Rozenwald", "Aleksandra Galitsyna", "Ekaterina Khrameeva", "Grigory Sapunov", "Mikhail S. Gelfand"], "pdf": "/pdf/203cd6f32544775beb171bdda9ed7221c2e0829e.pdf", "TL;DR": "We apply RNN to solve the biological problem of chromatin folding patterns prediction from epigenetic marks and demonstrate for the first time that utilization of memory of sequential states on DNA molecule is significant for the best performance.", "abstract": "\nThe recent expansion of machine learning applications to molecular biology proved to have a significant contribution to our understanding of biological systems, and genome functioning in particular. Technological advances enabled the collection of large epigenetic datasets, including information about various DNA binding factors (ChIP-Seq) and DNA spatial structure (Hi-C). Several studies have confirmed the correlation between DNA binding factors and Topologically Associating Domains (TADs) in DNA structure. However, the information about physical proximity represented by genomic coordinate was not yet used for the improvement of the prediction models.\n\nIn this research, we focus on Machine Learning methods for prediction of folding patterns of DNA in a classical model organism Drosophila melanogaster. The paper considers linear models with four types of regularization, Gradient Boosting and Recurrent Neural Networks for the prediction of chromatin folding patterns from epigenetic marks. The bidirectional LSTM RNN model outperformed all the models and gained the best prediction scores. This demonstrates the utilization of complex models and the importance of memory of sequential DNA states for the chromatin folding. We identify informative epigenetic features that lead to the further conclusion of their biological significance.", "code": "https://www.dropbox.com/sh/izy4exnkosd309o/AACl7N8xZX1X13EOSwC_mNj1a?dl=0", "keywords": ["Machine Learning", "Recurrent Neural Networks", "3D chromatin structure", "topologically associating domains", "computational biology."], "paperhash": "rozenwald|learning_dna_folding_patterns_with_recurrent_neural_networks", "original_pdf": "/attachment/562ad6f8c069a79a93b4f771ddc6a7e1199bc114.pdf", "_bibtex": "@misc{\nrozenwald2020learning,\ntitle={Learning {\\{}DNA{\\}} folding patterns with Recurrent Neural Networks },\nauthor={Michal Rozenwald and Aleksandra Galitsyna and Ekaterina Khrameeva and Grigory Sapunov and Mikhail S. Gelfand},\nyear={2020},\nurl={https://openreview.net/forum?id=Bkel6ertwS}\n}"}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "Bkel6ertwS", "replyto": "Bkel6ertwS", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper2562/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper2562/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1575577537697, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper2562/Reviewers"], "noninvitees": [], "tcdate": 1570237721075, "tmdate": 1575577537711, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper2562/-/Official_Review"}}}, {"id": "rJe0SjlScS", "original": null, "number": 3, "cdate": 1572305734385, "ddate": null, "tcdate": 1572305734385, "tmdate": 1572972322006, "tddate": null, "forum": "Bkel6ertwS", "replyto": "Bkel6ertwS", "invitation": "ICLR.cc/2020/Conference/Paper2562/-/Official_Review", "content": {"experience_assessment": "I have published one or two papers in this area.", "rating": "3: Weak Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #3", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "The paper predicts DNA folding using different machine learning methods. The authors show that LSTM out performs other methods. They attribute this to the memory of sequential DNA and LSTM model structure. They also propose a weighted mean squared error that improves the performance of the proposed model.\n\nThe authors compare the LSTM model with other classical approaches showing better performance based on predictive and quality metrics, applied to Hi-C data for drosophila, for predicting TADs.\n\nMy major concern is that it is not clear if the improvement is a by-product of LSTM without the proposed new metric. A fair comparison would also consider similar loss function designs for other approaches or at least comparing to a vanilla LSTM model. \n\nAlso the approach lacks illustration of generalizability. The definition of the loss function is also very specific (why 11?) and I wonder if this is generalizable to other Hi-C datasets or predictions based on other epigenetic features beyond ChIP-seq, e.g. ATAC-seq. \n"}, "signatures": ["ICLR.cc/2020/Conference/Paper2562/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper2562/AnonReviewer3"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["michal.rozenwald@gmail.com", "agalitzina@gmail.com", "ekhrameeva@gmail.com", "grigory.sapunov@gmail.codelfm", "mikhail.gelfand@gmail.com"], "title": "Learning DNA folding patterns with Recurrent Neural Networks ", "authors": ["Michal Rozenwald", "Aleksandra Galitsyna", "Ekaterina Khrameeva", "Grigory Sapunov", "Mikhail S. Gelfand"], "pdf": "/pdf/203cd6f32544775beb171bdda9ed7221c2e0829e.pdf", "TL;DR": "We apply RNN to solve the biological problem of chromatin folding patterns prediction from epigenetic marks and demonstrate for the first time that utilization of memory of sequential states on DNA molecule is significant for the best performance.", "abstract": "\nThe recent expansion of machine learning applications to molecular biology proved to have a significant contribution to our understanding of biological systems, and genome functioning in particular. Technological advances enabled the collection of large epigenetic datasets, including information about various DNA binding factors (ChIP-Seq) and DNA spatial structure (Hi-C). Several studies have confirmed the correlation between DNA binding factors and Topologically Associating Domains (TADs) in DNA structure. However, the information about physical proximity represented by genomic coordinate was not yet used for the improvement of the prediction models.\n\nIn this research, we focus on Machine Learning methods for prediction of folding patterns of DNA in a classical model organism Drosophila melanogaster. The paper considers linear models with four types of regularization, Gradient Boosting and Recurrent Neural Networks for the prediction of chromatin folding patterns from epigenetic marks. The bidirectional LSTM RNN model outperformed all the models and gained the best prediction scores. This demonstrates the utilization of complex models and the importance of memory of sequential DNA states for the chromatin folding. We identify informative epigenetic features that lead to the further conclusion of their biological significance.", "code": "https://www.dropbox.com/sh/izy4exnkosd309o/AACl7N8xZX1X13EOSwC_mNj1a?dl=0", "keywords": ["Machine Learning", "Recurrent Neural Networks", "3D chromatin structure", "topologically associating domains", "computational biology."], "paperhash": "rozenwald|learning_dna_folding_patterns_with_recurrent_neural_networks", "original_pdf": "/attachment/562ad6f8c069a79a93b4f771ddc6a7e1199bc114.pdf", "_bibtex": "@misc{\nrozenwald2020learning,\ntitle={Learning {\\{}DNA{\\}} folding patterns with Recurrent Neural Networks },\nauthor={Michal Rozenwald and Aleksandra Galitsyna and Ekaterina Khrameeva and Grigory Sapunov and Mikhail S. Gelfand},\nyear={2020},\nurl={https://openreview.net/forum?id=Bkel6ertwS}\n}"}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "Bkel6ertwS", "replyto": "Bkel6ertwS", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper2562/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper2562/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1575577537697, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper2562/Reviewers"], "noninvitees": [], "tcdate": 1570237721075, "tmdate": 1575577537711, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper2562/-/Official_Review"}}}, {"id": "HylET_-0OB", "original": null, "number": 1, "cdate": 1570801852097, "ddate": null, "tcdate": 1570801852097, "tmdate": 1570801852097, "tddate": null, "forum": "Bkel6ertwS", "replyto": "B1gJ-kcNdH", "invitation": "ICLR.cc/2020/Conference/Paper2562/-/Official_Comment", "content": {"comment": "Dear Maria Anna Rapomaniki, thank you for your feedback.\nIn our paper, we sought to base our literature review on indexed full-size papers published in journals or main track of conferences. We are aware of the works you mention but we decided not to include them in our review also because they were presented at workshops, not the main tracks. The authors of these works might be expected to develop their work further. For instance, the work https://ieeexplore.ieee.org/document/8621486 was presented at the Analysis and modeling of the three-dimensional structure of chromatin Workshop http://mccmb.belozersky.msu.ru/2018/chromatin.html. Moreover, this paper is a short abstract and it does not contain a detailed description of what exactly was done.\nAs for the difference between the work https://arxiv.org/abs/1811.09619, we predict the folding pattern characteristic obtained directly from the Hi-C map, but not the 3D structure using ChIP-seq data. This is the major reason why we didn't cite this paper in the first place. However, this work looks promising and worth mentioning, thus we will be happy to cite this work in the next iteration of paper improvement if supported by reviewers.\nKind regards. ", "title": "Addressing the related work comment"}, "signatures": ["ICLR.cc/2020/Conference/Paper2562/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper2562/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["michal.rozenwald@gmail.com", "agalitzina@gmail.com", "ekhrameeva@gmail.com", "grigory.sapunov@gmail.codelfm", "mikhail.gelfand@gmail.com"], "title": "Learning DNA folding patterns with Recurrent Neural Networks ", "authors": ["Michal Rozenwald", "Aleksandra Galitsyna", "Ekaterina Khrameeva", "Grigory Sapunov", "Mikhail S. Gelfand"], "pdf": "/pdf/203cd6f32544775beb171bdda9ed7221c2e0829e.pdf", "TL;DR": "We apply RNN to solve the biological problem of chromatin folding patterns prediction from epigenetic marks and demonstrate for the first time that utilization of memory of sequential states on DNA molecule is significant for the best performance.", "abstract": "\nThe recent expansion of machine learning applications to molecular biology proved to have a significant contribution to our understanding of biological systems, and genome functioning in particular. Technological advances enabled the collection of large epigenetic datasets, including information about various DNA binding factors (ChIP-Seq) and DNA spatial structure (Hi-C). Several studies have confirmed the correlation between DNA binding factors and Topologically Associating Domains (TADs) in DNA structure. However, the information about physical proximity represented by genomic coordinate was not yet used for the improvement of the prediction models.\n\nIn this research, we focus on Machine Learning methods for prediction of folding patterns of DNA in a classical model organism Drosophila melanogaster. The paper considers linear models with four types of regularization, Gradient Boosting and Recurrent Neural Networks for the prediction of chromatin folding patterns from epigenetic marks. The bidirectional LSTM RNN model outperformed all the models and gained the best prediction scores. This demonstrates the utilization of complex models and the importance of memory of sequential DNA states for the chromatin folding. We identify informative epigenetic features that lead to the further conclusion of their biological significance.", "code": "https://www.dropbox.com/sh/izy4exnkosd309o/AACl7N8xZX1X13EOSwC_mNj1a?dl=0", "keywords": ["Machine Learning", "Recurrent Neural Networks", "3D chromatin structure", "topologically associating domains", "computational biology."], "paperhash": "rozenwald|learning_dna_folding_patterns_with_recurrent_neural_networks", "original_pdf": "/attachment/562ad6f8c069a79a93b4f771ddc6a7e1199bc114.pdf", "_bibtex": "@misc{\nrozenwald2020learning,\ntitle={Learning {\\{}DNA{\\}} folding patterns with Recurrent Neural Networks },\nauthor={Michal Rozenwald and Aleksandra Galitsyna and Ekaterina Khrameeva and Grigory Sapunov and Mikhail S. Gelfand},\nyear={2020},\nurl={https://openreview.net/forum?id=Bkel6ertwS}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "Bkel6ertwS", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper2562/Authors", "ICLR.cc/2020/Conference/Paper2562/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper2562/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper2562/Reviewers", "ICLR.cc/2020/Conference/Paper2562/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper2562/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper2562/Authors|ICLR.cc/2020/Conference/Paper2562/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504139458, "tmdate": 1576860534455, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper2562/Authors", "ICLR.cc/2020/Conference/Paper2562/Reviewers", "ICLR.cc/2020/Conference/Paper2562/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper2562/-/Official_Comment"}}}, {"id": "B1gJ-kcNdH", "original": null, "number": 1, "cdate": 1570180855427, "ddate": null, "tcdate": 1570180855427, "tmdate": 1570180855427, "tddate": null, "forum": "Bkel6ertwS", "replyto": "Bkel6ertwS", "invitation": "ICLR.cc/2020/Conference/Paper2562/-/Public_Comment", "content": {"comment": "Although the topic is very interesting, there are some issues with its novelty. We noticed that the proposed article is very similar the work published in 2018 at the IEEE International Conference on Bioinformatics and Biomedicine (BIBM) which is indexed: https://ieeexplore.ieee.org/document/8621486. The authors should cite this article and clearly state what are the improvements. Moreover, the idea of predicting genome folding via an LSTM model has been explored even before the BIBM conference here: https://arxiv.org/abs/1811.09619 and also presented at the NeurIPS 2018 Workshop: http://www.quantum-machine.org/workshops/nips2018/. Since the two models are strikingly similar, the authors should again cite this very relevant work and provide a discussion over the improvements. Thanks!", "title": "Already published and related work "}, "signatures": ["~Maria_Anna_Rapsomaniki1"], "readers": ["everyone"], "nonreaders": [], "writers": ["~Maria_Anna_Rapsomaniki1", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["michal.rozenwald@gmail.com", "agalitzina@gmail.com", "ekhrameeva@gmail.com", "grigory.sapunov@gmail.codelfm", "mikhail.gelfand@gmail.com"], "title": "Learning DNA folding patterns with Recurrent Neural Networks ", "authors": ["Michal Rozenwald", "Aleksandra Galitsyna", "Ekaterina Khrameeva", "Grigory Sapunov", "Mikhail S. Gelfand"], "pdf": "/pdf/203cd6f32544775beb171bdda9ed7221c2e0829e.pdf", "TL;DR": "We apply RNN to solve the biological problem of chromatin folding patterns prediction from epigenetic marks and demonstrate for the first time that utilization of memory of sequential states on DNA molecule is significant for the best performance.", "abstract": "\nThe recent expansion of machine learning applications to molecular biology proved to have a significant contribution to our understanding of biological systems, and genome functioning in particular. Technological advances enabled the collection of large epigenetic datasets, including information about various DNA binding factors (ChIP-Seq) and DNA spatial structure (Hi-C). Several studies have confirmed the correlation between DNA binding factors and Topologically Associating Domains (TADs) in DNA structure. However, the information about physical proximity represented by genomic coordinate was not yet used for the improvement of the prediction models.\n\nIn this research, we focus on Machine Learning methods for prediction of folding patterns of DNA in a classical model organism Drosophila melanogaster. The paper considers linear models with four types of regularization, Gradient Boosting and Recurrent Neural Networks for the prediction of chromatin folding patterns from epigenetic marks. The bidirectional LSTM RNN model outperformed all the models and gained the best prediction scores. This demonstrates the utilization of complex models and the importance of memory of sequential DNA states for the chromatin folding. We identify informative epigenetic features that lead to the further conclusion of their biological significance.", "code": "https://www.dropbox.com/sh/izy4exnkosd309o/AACl7N8xZX1X13EOSwC_mNj1a?dl=0", "keywords": ["Machine Learning", "Recurrent Neural Networks", "3D chromatin structure", "topologically associating domains", "computational biology."], "paperhash": "rozenwald|learning_dna_folding_patterns_with_recurrent_neural_networks", "original_pdf": "/attachment/562ad6f8c069a79a93b4f771ddc6a7e1199bc114.pdf", "_bibtex": "@misc{\nrozenwald2020learning,\ntitle={Learning {\\{}DNA{\\}} folding patterns with Recurrent Neural Networks },\nauthor={Michal Rozenwald and Aleksandra Galitsyna and Ekaterina Khrameeva and Grigory Sapunov and Mikhail S. Gelfand},\nyear={2020},\nurl={https://openreview.net/forum?id=Bkel6ertwS}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "Bkel6ertwS", "readers": {"values": ["everyone"], "description": "User groups that will be able to read this comment."}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "~.*"}}, "readers": ["everyone"], "tcdate": 1569504178507, "tmdate": 1576860568107, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["everyone"], "noninvitees": ["ICLR.cc/2020/Conference/Paper2562/Authors", "ICLR.cc/2020/Conference/Paper2562/Reviewers", "ICLR.cc/2020/Conference/Paper2562/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper2562/-/Public_Comment"}}}], "count": 11}