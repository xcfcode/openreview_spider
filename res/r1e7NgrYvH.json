{"notes": [{"id": "r1e7NgrYvH", "original": "rylF4IlFPB", "number": 2243, "cdate": 1569439787475, "ddate": null, "tcdate": 1569439787475, "tmdate": 1577168215652, "tddate": null, "forum": "r1e7NgrYvH", "replyto": null, "invitation": "ICLR.cc/2020/Conference/-/Blind_Submission", "content": {"authorids": ["cts17@mails.tsinghua.edu.cn", "lepangdan@outlook.com", "liufurui2@huawei.com", "chenzhitang2@huawei.com"], "title": "DO-AutoEncoder: Learning and Intervening Bivariate Causal Mechanisms in Images", "authors": ["Tianshuo Cong", "Dan Peng", "Furui Liu", "Zhitang Chen"], "pdf": "/pdf/c75e7d930ec5a0bf2427b3cc38fcc6a8fe9ef579.pdf", "TL;DR": "We propose a new framework  for deep representation learning that fully capture bivariate causal relationship in the images.", "abstract": "Some fundamental limitations of deep learning have been exposed such as lacking generalizability and being vunerable to adversarial attack. Instead, researchers realize that causation is much more stable than association relationship in data. In this paper, we propose a new framework called do-calculus AutoEncoder(DO-AE) for deep representation learning that fully capture bivariate causal relationship in the images which allows us to intervene in images generation process. DO-AE consists of two key ingredients: causal relationship mining in images and intervention-enabling deep causal structured representation learning. The goal here is to learn deep representations that correspond to the concepts in the physical world as well as their causal structure. To verify the proposed method, we create a dataset named PHY2D, which contains abstract graphic description in accordance with the laws of physics. Our experiments demonstrate our method is able to correctly identify the bivariate causal relationship between concepts in images and the representation learned enables a do-calculus manipulation to images, which generates artificial images that might possibly break the physical law depending on where we intervene the causal system.", "keywords": ["Causality discovery", "AutoEncoder", "Deep representation learning", "Do-calculus"], "paperhash": "cong|doautoencoder_learning_and_intervening_bivariate_causal_mechanisms_in_images", "original_pdf": "/attachment/c75e7d930ec5a0bf2427b3cc38fcc6a8fe9ef579.pdf", "_bibtex": "@misc{\ncong2020doautoencoder,\ntitle={{\\{}DO{\\}}-AutoEncoder: Learning and Intervening Bivariate Causal Mechanisms in Images},\nauthor={Tianshuo Cong and Dan Peng and Furui Liu and Zhitang Chen},\nyear={2020},\nurl={https://openreview.net/forum?id=r1e7NgrYvH}\n}"}, "signatures": ["ICLR.cc/2020/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference"], "details": {"replyCount": 7, "writable": false, "overwriting": [], "revisions": false, "tags": [], "invitation": {"reply": {"readers": {"values-regex": ".*"}, "writers": {"values": ["ICLR.cc/2020/Conference"]}, "signatures": {"values": ["ICLR.cc/2020/Conference"]}, "content": {"spotlight_video": {"value-regex": ".*"}, "full_presentation_video": {"value-regex": ".*"}, "original_pdf": {"required": false, "description": "Upload a PDF file that ends with .pdf", "value-regex": ".*"}, "appendix": {"value-regex": ".*"}, "authorids": {"values-regex": ".*"}, "poster": {"value-regex": ".*"}, "authors": {"values": ["Anonymous"]}, "slides": {"value-regex": ".*"}}}, "final": [], "signatures": ["ICLR.cc/2020/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference"], "noninvitees": [], "tcdate": 1569271260237, "tmdate": 1593459412141, "id": "ICLR.cc/2020/Conference/-/Blind_Submission"}}, "tauthor": "OpenReview.net"}, {"id": "rpuGy8Snh9", "original": null, "number": 1, "cdate": 1576798744145, "ddate": null, "tcdate": 1576798744145, "tmdate": 1576800892002, "tddate": null, "forum": "r1e7NgrYvH", "replyto": "r1e7NgrYvH", "invitation": "ICLR.cc/2020/Conference/Paper2243/-/Decision", "content": {"decision": "Reject", "comment": "The idea of integrating causality into an auto-encoder is interesting and very timely. While the reviewers find this paper to contain some interesting ideas, the technical contributions and mathematical rigor, scope of the method, and the presentation of results would need to be significantly improved in order for this work to reach the quality bar of ICLR.", "title": "Paper Decision"}, "signatures": ["ICLR.cc/2020/Conference/Program_Chairs"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Program_Chairs"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["cts17@mails.tsinghua.edu.cn", "lepangdan@outlook.com", "liufurui2@huawei.com", "chenzhitang2@huawei.com"], "title": "DO-AutoEncoder: Learning and Intervening Bivariate Causal Mechanisms in Images", "authors": ["Tianshuo Cong", "Dan Peng", "Furui Liu", "Zhitang Chen"], "pdf": "/pdf/c75e7d930ec5a0bf2427b3cc38fcc6a8fe9ef579.pdf", "TL;DR": "We propose a new framework  for deep representation learning that fully capture bivariate causal relationship in the images.", "abstract": "Some fundamental limitations of deep learning have been exposed such as lacking generalizability and being vunerable to adversarial attack. Instead, researchers realize that causation is much more stable than association relationship in data. In this paper, we propose a new framework called do-calculus AutoEncoder(DO-AE) for deep representation learning that fully capture bivariate causal relationship in the images which allows us to intervene in images generation process. DO-AE consists of two key ingredients: causal relationship mining in images and intervention-enabling deep causal structured representation learning. The goal here is to learn deep representations that correspond to the concepts in the physical world as well as their causal structure. To verify the proposed method, we create a dataset named PHY2D, which contains abstract graphic description in accordance with the laws of physics. Our experiments demonstrate our method is able to correctly identify the bivariate causal relationship between concepts in images and the representation learned enables a do-calculus manipulation to images, which generates artificial images that might possibly break the physical law depending on where we intervene the causal system.", "keywords": ["Causality discovery", "AutoEncoder", "Deep representation learning", "Do-calculus"], "paperhash": "cong|doautoencoder_learning_and_intervening_bivariate_causal_mechanisms_in_images", "original_pdf": "/attachment/c75e7d930ec5a0bf2427b3cc38fcc6a8fe9ef579.pdf", "_bibtex": "@misc{\ncong2020doautoencoder,\ntitle={{\\{}DO{\\}}-AutoEncoder: Learning and Intervening Bivariate Causal Mechanisms in Images},\nauthor={Tianshuo Cong and Dan Peng and Furui Liu and Zhitang Chen},\nyear={2020},\nurl={https://openreview.net/forum?id=r1e7NgrYvH}\n}"}, "tags": [], "invitation": {"reply": {"writers": {"description": "How your identity will be displayed.", "values-regex": ["ICLR.cc/2020/Conference/Program_Chairs"]}, "signatures": {"values": ["ICLR.cc/2020/Conference/Program_Chairs"], "description": "How your identity will be displayed."}, "content": {"decision": {"value-radio": ["Accept (Spotlight)", "Accept (Talk)", "Accept (Poster)", "Reject"], "description": "Decision", "required": true, "order": 2}, "title": {"value": "Paper Decision", "required": true, "order": 1}, "comment": {"value-regex": "[\\S\\s]{0,5000}", "description": "", "required": false, "order": 3}}, "forum": "r1e7NgrYvH", "replyto": "r1e7NgrYvH", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}}, "expdate": 1576854540000, "duedate": 1576853940000, "multiReply": false, "readers": ["everyone"], "invitees": ["ICLR.cc/2020/Conference/Program_Chairs"], "tcdate": 1576795725196, "tmdate": 1576800276986, "super": "ICLR.cc/2020/Conference/-/Decision", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper2243/-/Decision"}}}, {"id": "HyxLcHJnsB", "original": null, "number": 3, "cdate": 1573807501975, "ddate": null, "tcdate": 1573807501975, "tmdate": 1573807501975, "tddate": null, "forum": "r1e7NgrYvH", "replyto": "SyxvfpcntB", "invitation": "ICLR.cc/2020/Conference/Paper2243/-/Official_Comment", "content": {"title": "Response to reviewer #3", "comment": "We thank reviewer #3 for his review. \n\n-We will enhance the writing ability to make the narrative of the paper more professional and rigorous.\n\n-There are a number of variables and complicated causal graph in natural images, we want to use the artificial data to conduct a preliminary exploration. Our next work will focus on discovering  causal relationship in real world. \n\nThank you again for your time sincerely."}, "signatures": ["ICLR.cc/2020/Conference/Paper2243/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper2243/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["cts17@mails.tsinghua.edu.cn", "lepangdan@outlook.com", "liufurui2@huawei.com", "chenzhitang2@huawei.com"], "title": "DO-AutoEncoder: Learning and Intervening Bivariate Causal Mechanisms in Images", "authors": ["Tianshuo Cong", "Dan Peng", "Furui Liu", "Zhitang Chen"], "pdf": "/pdf/c75e7d930ec5a0bf2427b3cc38fcc6a8fe9ef579.pdf", "TL;DR": "We propose a new framework  for deep representation learning that fully capture bivariate causal relationship in the images.", "abstract": "Some fundamental limitations of deep learning have been exposed such as lacking generalizability and being vunerable to adversarial attack. Instead, researchers realize that causation is much more stable than association relationship in data. In this paper, we propose a new framework called do-calculus AutoEncoder(DO-AE) for deep representation learning that fully capture bivariate causal relationship in the images which allows us to intervene in images generation process. DO-AE consists of two key ingredients: causal relationship mining in images and intervention-enabling deep causal structured representation learning. The goal here is to learn deep representations that correspond to the concepts in the physical world as well as their causal structure. To verify the proposed method, we create a dataset named PHY2D, which contains abstract graphic description in accordance with the laws of physics. Our experiments demonstrate our method is able to correctly identify the bivariate causal relationship between concepts in images and the representation learned enables a do-calculus manipulation to images, which generates artificial images that might possibly break the physical law depending on where we intervene the causal system.", "keywords": ["Causality discovery", "AutoEncoder", "Deep representation learning", "Do-calculus"], "paperhash": "cong|doautoencoder_learning_and_intervening_bivariate_causal_mechanisms_in_images", "original_pdf": "/attachment/c75e7d930ec5a0bf2427b3cc38fcc6a8fe9ef579.pdf", "_bibtex": "@misc{\ncong2020doautoencoder,\ntitle={{\\{}DO{\\}}-AutoEncoder: Learning and Intervening Bivariate Causal Mechanisms in Images},\nauthor={Tianshuo Cong and Dan Peng and Furui Liu and Zhitang Chen},\nyear={2020},\nurl={https://openreview.net/forum?id=r1e7NgrYvH}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "r1e7NgrYvH", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper2243/Authors", "ICLR.cc/2020/Conference/Paper2243/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper2243/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper2243/Reviewers", "ICLR.cc/2020/Conference/Paper2243/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper2243/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper2243/Authors|ICLR.cc/2020/Conference/Paper2243/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504144235, "tmdate": 1576860560888, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper2243/Authors", "ICLR.cc/2020/Conference/Paper2243/Reviewers", "ICLR.cc/2020/Conference/Paper2243/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper2243/-/Official_Comment"}}}, {"id": "BJxLxHJ2sr", "original": null, "number": 2, "cdate": 1573807341834, "ddate": null, "tcdate": 1573807341834, "tmdate": 1573807341834, "tddate": null, "forum": "r1e7NgrYvH", "replyto": "HyeKwG52tH", "invitation": "ICLR.cc/2020/Conference/Paper2243/-/Official_Comment", "content": {"title": "Response to reviewer #2", "comment": "We are grateful for R2's constructive suggestions and we believe they could greatly improve our paper.\n\n-As your proposition said, though for our dataset the two variables are given, it is quite different from causal discovery from measurement data. Our model fits for high dimensional visual data, which is a main contribution of this work. \n\n-We separate the image into two part for two reasons:\n  1.Reduce the mutual interference between variables. \n  2.Our paper is mainly based on the following assumption: The Kolmogorov complexity of conditional and marginal distributions is smaller in causal direction than that in anti-causal direction. In Figure 2, the part I of DO-AE is to estimate K(P_x), the part II is to estimate K(P_{y|x}). The outputs of these two part make up the whole image, we want to intervene in whole images generation process, so two parts of the DO-AE are indispensable.\n\n-We will access related work you recommend\uff0cand cite the related work about causality with VAE.\n\nThank you again for your detail comments."}, "signatures": ["ICLR.cc/2020/Conference/Paper2243/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper2243/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["cts17@mails.tsinghua.edu.cn", "lepangdan@outlook.com", "liufurui2@huawei.com", "chenzhitang2@huawei.com"], "title": "DO-AutoEncoder: Learning and Intervening Bivariate Causal Mechanisms in Images", "authors": ["Tianshuo Cong", "Dan Peng", "Furui Liu", "Zhitang Chen"], "pdf": "/pdf/c75e7d930ec5a0bf2427b3cc38fcc6a8fe9ef579.pdf", "TL;DR": "We propose a new framework  for deep representation learning that fully capture bivariate causal relationship in the images.", "abstract": "Some fundamental limitations of deep learning have been exposed such as lacking generalizability and being vunerable to adversarial attack. Instead, researchers realize that causation is much more stable than association relationship in data. In this paper, we propose a new framework called do-calculus AutoEncoder(DO-AE) for deep representation learning that fully capture bivariate causal relationship in the images which allows us to intervene in images generation process. DO-AE consists of two key ingredients: causal relationship mining in images and intervention-enabling deep causal structured representation learning. The goal here is to learn deep representations that correspond to the concepts in the physical world as well as their causal structure. To verify the proposed method, we create a dataset named PHY2D, which contains abstract graphic description in accordance with the laws of physics. Our experiments demonstrate our method is able to correctly identify the bivariate causal relationship between concepts in images and the representation learned enables a do-calculus manipulation to images, which generates artificial images that might possibly break the physical law depending on where we intervene the causal system.", "keywords": ["Causality discovery", "AutoEncoder", "Deep representation learning", "Do-calculus"], "paperhash": "cong|doautoencoder_learning_and_intervening_bivariate_causal_mechanisms_in_images", "original_pdf": "/attachment/c75e7d930ec5a0bf2427b3cc38fcc6a8fe9ef579.pdf", "_bibtex": "@misc{\ncong2020doautoencoder,\ntitle={{\\{}DO{\\}}-AutoEncoder: Learning and Intervening Bivariate Causal Mechanisms in Images},\nauthor={Tianshuo Cong and Dan Peng and Furui Liu and Zhitang Chen},\nyear={2020},\nurl={https://openreview.net/forum?id=r1e7NgrYvH}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "r1e7NgrYvH", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper2243/Authors", "ICLR.cc/2020/Conference/Paper2243/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper2243/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper2243/Reviewers", "ICLR.cc/2020/Conference/Paper2243/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper2243/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper2243/Authors|ICLR.cc/2020/Conference/Paper2243/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504144235, "tmdate": 1576860560888, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper2243/Authors", "ICLR.cc/2020/Conference/Paper2243/Reviewers", "ICLR.cc/2020/Conference/Paper2243/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper2243/-/Official_Comment"}}}, {"id": "ByePp4yniH", "original": null, "number": 1, "cdate": 1573807294643, "ddate": null, "tcdate": 1573807294643, "tmdate": 1573807294643, "tddate": null, "forum": "r1e7NgrYvH", "replyto": "SkgN4O6TFB", "invitation": "ICLR.cc/2020/Conference/Paper2243/-/Official_Comment", "content": {"title": "Response to reviewer #1", "comment": "We thank reviewer #1 for his comments of our paper. \n\n-First of all, we are sorry about the grammatical errors in this paper, we will fix them to increase the readability of the paper.\n\n-Our aim is to construct the causal graph from the given images. This kind of exploration is challenging, we provide a physics dataset to explore the possibilities that this problem can solve. Our model functionality is built on the presence of known arrows\uff0cand the causal graph reflected by the images in the dataset has an arrow. DO-AE focus on learning the direction of the arrow(No arrow situation is not within our consideration). By the way, the right causal graph for the spring example is: A <-> B.\n\n-We decide the net is rich or not by determining the quality of the generated images visually and intuitively. We agree that increasing the statistical experiments and setting quantitative estimate index could make the results more convincing. We will improve this part in next version. \n\nThank you again for your feedback."}, "signatures": ["ICLR.cc/2020/Conference/Paper2243/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper2243/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["cts17@mails.tsinghua.edu.cn", "lepangdan@outlook.com", "liufurui2@huawei.com", "chenzhitang2@huawei.com"], "title": "DO-AutoEncoder: Learning and Intervening Bivariate Causal Mechanisms in Images", "authors": ["Tianshuo Cong", "Dan Peng", "Furui Liu", "Zhitang Chen"], "pdf": "/pdf/c75e7d930ec5a0bf2427b3cc38fcc6a8fe9ef579.pdf", "TL;DR": "We propose a new framework  for deep representation learning that fully capture bivariate causal relationship in the images.", "abstract": "Some fundamental limitations of deep learning have been exposed such as lacking generalizability and being vunerable to adversarial attack. Instead, researchers realize that causation is much more stable than association relationship in data. In this paper, we propose a new framework called do-calculus AutoEncoder(DO-AE) for deep representation learning that fully capture bivariate causal relationship in the images which allows us to intervene in images generation process. DO-AE consists of two key ingredients: causal relationship mining in images and intervention-enabling deep causal structured representation learning. The goal here is to learn deep representations that correspond to the concepts in the physical world as well as their causal structure. To verify the proposed method, we create a dataset named PHY2D, which contains abstract graphic description in accordance with the laws of physics. Our experiments demonstrate our method is able to correctly identify the bivariate causal relationship between concepts in images and the representation learned enables a do-calculus manipulation to images, which generates artificial images that might possibly break the physical law depending on where we intervene the causal system.", "keywords": ["Causality discovery", "AutoEncoder", "Deep representation learning", "Do-calculus"], "paperhash": "cong|doautoencoder_learning_and_intervening_bivariate_causal_mechanisms_in_images", "original_pdf": "/attachment/c75e7d930ec5a0bf2427b3cc38fcc6a8fe9ef579.pdf", "_bibtex": "@misc{\ncong2020doautoencoder,\ntitle={{\\{}DO{\\}}-AutoEncoder: Learning and Intervening Bivariate Causal Mechanisms in Images},\nauthor={Tianshuo Cong and Dan Peng and Furui Liu and Zhitang Chen},\nyear={2020},\nurl={https://openreview.net/forum?id=r1e7NgrYvH}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "r1e7NgrYvH", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper2243/Authors", "ICLR.cc/2020/Conference/Paper2243/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper2243/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper2243/Reviewers", "ICLR.cc/2020/Conference/Paper2243/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper2243/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper2243/Authors|ICLR.cc/2020/Conference/Paper2243/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504144235, "tmdate": 1576860560888, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper2243/Authors", "ICLR.cc/2020/Conference/Paper2243/Reviewers", "ICLR.cc/2020/Conference/Paper2243/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper2243/-/Official_Comment"}}}, {"id": "HyeKwG52tH", "original": null, "number": 1, "cdate": 1571754592778, "ddate": null, "tcdate": 1571754592778, "tmdate": 1572972364346, "tddate": null, "forum": "r1e7NgrYvH", "replyto": "r1e7NgrYvH", "invitation": "ICLR.cc/2020/Conference/Paper2243/-/Official_Review", "content": {"rating": "1: Reject", "experience_assessment": "I have published one or two papers in this area.", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #2", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review": "This paper presented an image data that are generated from two variables using some physics law. It also proposed a model to identify the causal relationship between the two variables using the image dataset. The method, in general, utilize the general idea that the causal direction is easier for the model to describe than the anti-causal direction. So the image is fad into a VAE based model in two different ways. The one with lower loses represents the correct causal direction. \n\nPros:\n1. Causal discovery is, in general, an interesting problem and causal discovery based on representation learning are of great importance.  \n2. The dataset presented can be used for generic causal discovery evaluation which can be useful for the community.\n\nCons and other details:\n1. The method assumes that A and B are known and given which is very unrealistic in natural images. Also with this assumption, the problem is not much different from causal discovery from measurement data rather than image data. \n2. Based on the previous point, the method, in general, does not match the motivation in the introduction where a causal representation needs to be learned as the images are already separated into different components. \n3. The method cannot be scaled to more than two variables even with all components given as it requires exponentially many trials of the method. This setting is not so interesting anymore with image input. \n4. There is much-related work with causality and representation learning also causality with NN or VAE. None of these related work has been discussed.  for example Leon Bottou https://arxiv.org/pdf/1907.02893.pdf; Many works from Mingming Gong etc\n5. The math is not very rigorous in general. For example, Eq(2) s a valid-loss but not likelihood. Also, the work did not say what likelihood under what distribution. This is propositional to Gaussian likelihood which may work fine in practice but the math presentation is not rigorous.  \n6. For the method (see figure 2), I did not see why the first part needs to be there as the second part takes the ground truth A as input. Using only the second part of the model which tries to see whether A->B is easier or B->A is easier is sufficient for the aim of identifying the relationship between given A and B. \n7. The dataset may be more useful to the causality community if it is released as a simulator rather than the images. \n"}, "signatures": ["ICLR.cc/2020/Conference/Paper2243/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper2243/AnonReviewer2"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["cts17@mails.tsinghua.edu.cn", "lepangdan@outlook.com", "liufurui2@huawei.com", "chenzhitang2@huawei.com"], "title": "DO-AutoEncoder: Learning and Intervening Bivariate Causal Mechanisms in Images", "authors": ["Tianshuo Cong", "Dan Peng", "Furui Liu", "Zhitang Chen"], "pdf": "/pdf/c75e7d930ec5a0bf2427b3cc38fcc6a8fe9ef579.pdf", "TL;DR": "We propose a new framework  for deep representation learning that fully capture bivariate causal relationship in the images.", "abstract": "Some fundamental limitations of deep learning have been exposed such as lacking generalizability and being vunerable to adversarial attack. Instead, researchers realize that causation is much more stable than association relationship in data. In this paper, we propose a new framework called do-calculus AutoEncoder(DO-AE) for deep representation learning that fully capture bivariate causal relationship in the images which allows us to intervene in images generation process. DO-AE consists of two key ingredients: causal relationship mining in images and intervention-enabling deep causal structured representation learning. The goal here is to learn deep representations that correspond to the concepts in the physical world as well as their causal structure. To verify the proposed method, we create a dataset named PHY2D, which contains abstract graphic description in accordance with the laws of physics. Our experiments demonstrate our method is able to correctly identify the bivariate causal relationship between concepts in images and the representation learned enables a do-calculus manipulation to images, which generates artificial images that might possibly break the physical law depending on where we intervene the causal system.", "keywords": ["Causality discovery", "AutoEncoder", "Deep representation learning", "Do-calculus"], "paperhash": "cong|doautoencoder_learning_and_intervening_bivariate_causal_mechanisms_in_images", "original_pdf": "/attachment/c75e7d930ec5a0bf2427b3cc38fcc6a8fe9ef579.pdf", "_bibtex": "@misc{\ncong2020doautoencoder,\ntitle={{\\{}DO{\\}}-AutoEncoder: Learning and Intervening Bivariate Causal Mechanisms in Images},\nauthor={Tianshuo Cong and Dan Peng and Furui Liu and Zhitang Chen},\nyear={2020},\nurl={https://openreview.net/forum?id=r1e7NgrYvH}\n}"}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "r1e7NgrYvH", "replyto": "r1e7NgrYvH", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper2243/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper2243/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1575828631300, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper2243/Reviewers"], "noninvitees": [], "tcdate": 1570237725640, "tmdate": 1575828631314, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper2243/-/Official_Review"}}}, {"id": "SyxvfpcntB", "original": null, "number": 2, "cdate": 1571757326725, "ddate": null, "tcdate": 1571757326725, "tmdate": 1572972364310, "tddate": null, "forum": "r1e7NgrYvH", "replyto": "r1e7NgrYvH", "invitation": "ICLR.cc/2020/Conference/Paper2243/-/Official_Review", "content": {"experience_assessment": "I have read many papers in this area.", "rating": "1: Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #3", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "In summary: This paper is not ready for publication. The paper contains some potentially interesting ideas, but the presentation quality is not sufficient for publication. The paper should be substantially improved before re-submission.\n\nStrengths:\n- Causality is an important and established research area, and papers on this topic would be timely.\n- Paper contains some interesting ideas to integrate causality into an auto-encoder (but see weaknesses below)\n- Paper proposes a new dataset for evaluating causal mechanisms (but the approach is not evaluated)\n\nWeaknesses:\n- The quality of the writing is inappropriate for a scientific venue. Language throughout the paper is loose, eg \"physics is a hot topic\" or \"People have studied causality for a long time\" or \"Causality is a bridge between science and philosophy\" The paper should be re-written so that it is precise and clear.\n- The technical approach has several typos and lacks discussion of the approach. Instead, several high-level statements are made, with long equations. This makes appreciating the contribution of the paper difficult. \n- The dataset is potentially interesting, but it is artificial. A much more exciting dataset would be realistic data.\n- The experiments only evaluate the likelihood, but it is not clear whether this is on a training or testing set. \n"}, "signatures": ["ICLR.cc/2020/Conference/Paper2243/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper2243/AnonReviewer3"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["cts17@mails.tsinghua.edu.cn", "lepangdan@outlook.com", "liufurui2@huawei.com", "chenzhitang2@huawei.com"], "title": "DO-AutoEncoder: Learning and Intervening Bivariate Causal Mechanisms in Images", "authors": ["Tianshuo Cong", "Dan Peng", "Furui Liu", "Zhitang Chen"], "pdf": "/pdf/c75e7d930ec5a0bf2427b3cc38fcc6a8fe9ef579.pdf", "TL;DR": "We propose a new framework  for deep representation learning that fully capture bivariate causal relationship in the images.", "abstract": "Some fundamental limitations of deep learning have been exposed such as lacking generalizability and being vunerable to adversarial attack. Instead, researchers realize that causation is much more stable than association relationship in data. In this paper, we propose a new framework called do-calculus AutoEncoder(DO-AE) for deep representation learning that fully capture bivariate causal relationship in the images which allows us to intervene in images generation process. DO-AE consists of two key ingredients: causal relationship mining in images and intervention-enabling deep causal structured representation learning. The goal here is to learn deep representations that correspond to the concepts in the physical world as well as their causal structure. To verify the proposed method, we create a dataset named PHY2D, which contains abstract graphic description in accordance with the laws of physics. Our experiments demonstrate our method is able to correctly identify the bivariate causal relationship between concepts in images and the representation learned enables a do-calculus manipulation to images, which generates artificial images that might possibly break the physical law depending on where we intervene the causal system.", "keywords": ["Causality discovery", "AutoEncoder", "Deep representation learning", "Do-calculus"], "paperhash": "cong|doautoencoder_learning_and_intervening_bivariate_causal_mechanisms_in_images", "original_pdf": "/attachment/c75e7d930ec5a0bf2427b3cc38fcc6a8fe9ef579.pdf", "_bibtex": "@misc{\ncong2020doautoencoder,\ntitle={{\\{}DO{\\}}-AutoEncoder: Learning and Intervening Bivariate Causal Mechanisms in Images},\nauthor={Tianshuo Cong and Dan Peng and Furui Liu and Zhitang Chen},\nyear={2020},\nurl={https://openreview.net/forum?id=r1e7NgrYvH}\n}"}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "r1e7NgrYvH", "replyto": "r1e7NgrYvH", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper2243/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper2243/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1575828631300, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper2243/Reviewers"], "noninvitees": [], "tcdate": 1570237725640, "tmdate": 1575828631314, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper2243/-/Official_Review"}}}, {"id": "SkgN4O6TFB", "original": null, "number": 3, "cdate": 1571833899583, "ddate": null, "tcdate": 1571833899583, "tmdate": 1572972364258, "tddate": null, "forum": "r1e7NgrYvH", "replyto": "r1e7NgrYvH", "invitation": "ICLR.cc/2020/Conference/Paper2243/-/Official_Review", "content": {"experience_assessment": "I do not know much about this area.", "rating": "6: Weak Accept", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #1", "review_assessment:_checking_correctness_of_derivations_and_theory": "N/A", "review": "Thank you for your submission.\n\n- What is the specific question/problem tackled by the paper?\n\nThe paper proposes a VAE architecture to learn causal relations and allow for interventions. The architecture requires knowledge of the causal graph, and the direction of the causal arrows are inferred by comparing the log-likelihoods of generated images. The architecture may also require knowledge that an arrow exists between two vertices. This relies on the principle that \"low-capacity\" neural networks can predict better along the causal arrows (with the cause as input and the effect as the output) than in the opposite direction (with the effect as input and the cause as the output).\n\nThe paper focuses on the graph (A, B) where one wants to understand whether A causes B, or B causes A. The paper also discusses intervening in this graph.\n\nThe paper uses a new dataset for evaluating the approach, based on simple Newtonian systems. \n\n- Is the approach well motivated, including being well-placed in the literature?\n\nI think the motivation is adequate, but the review of the literature glosses over related work (or the absence thereof) in predicting the direction of arrows in causal graphs. The comparison of the proposed dataset against existing ones is missing.\n\n- Does the paper support the claims? This includes determining if results, whether theoretical or empirical, are correct and if they are scientifically rigorous.\n\nThe procedure for determining whether A causes B (or B causes A) is qualitative. The paper demonstrates that the performance gap between the correct and incorrect explanations is consistently distinguishable across multiple experiments.\n\nVisual inspection of the generated images is also used for assessing the quality of the models.\n\nBecause the results are qualitative, the support for the claims is not as strong as it could be (with quantitative results).\n\n- Summarize what the paper claims to do/contribute. Be positive and generous.\n\nThe paper has two main contributions:\n* Evidence to the Independent Mechanism principle (in a setting different from Bengio et al.'s transfer setup).\n* A new dataset for evaluating learning causal arrows (with accessible ground-truths).\n\nI think these are interesting contributions.\n\n- Is the paper clearly written?\n\nThe paper has a number of grammatical errors that should be fixed.\n\nThe explanation of how the latent interventions are made is important and should be included.\n\n- Clearly state your decision (accept or reject) with one or two key reasons for this choice.\n\nI vote for a weak accept.\n\n- Provide supporting arguments for the reasons for the decision.\n\nI trust that the writing issues will be addressed in due course, but I am also concerned about the fact that evaluations are qualitative. The qualitative results provide support for the contributions that could be strengthened. \n\nThe dataset is also an interesting contribution and it is a good idea to give it visibility. For this, though, it is important that the paper assess its strengths and limitations in comparison to alternative datasets.\n\n- Provide additional feedback with the aim to improve the paper. Make it clear that these points are here to help, and not necessarily part of your decision assessment.\n\nI am not convinced that mentioning Kolmogorov complexity is an efficient use of the space. I think the content could be improved by making the motivation section more concise and adding a few more experimental results or discussion.\n\nWhich discussions would be good to have? I think it should be noted that the intervention on effect should behave as demonstrated (creating implausible scenarios). Also some more development on the spring example: What is the right causal graph for it, and can the arrows in that graph be learned?\n\nQuantitative results would also improve the paper. Maybe decide between A->B or A<-B based on a statistical test?\n\nYou give an example about elephant-grassland association. Please cite a source for that.\n\nSuppose that both likelihoods for A->B and B<-A are about the same. How do you decide if your model is too rich, or if there's no relationship? (This is an important question to understand if the method requires knowledge that an (A,B) arrow exists or not.)\n\nThe panels in Figure 5 do not support the claim. The simple net gets better at the cause, but in some cases the rich representation does a better job at the effect.\n\nI think the physics dataset is also a contribution, so its originality & impact should be discussed in comparison to related work. Why is this an adequate benchmark? How does it address limitations of other benchmarks that could be used to evaluate proposed solutions for the problem in question?\n\nIn summary, my suggestions for improving the paper are:\n1) Make sure & demonstrate (by adequate discussion of related work) the originality of the contributions:\n1.1) The method for detecting the direction of causal arrows.\n1.2) The dataset as a benchmark for the problem being studied.\n2) Report quantitative results across the dataset and maybe across multiple setups for each name/physical law, with good coverage. You may consider a test set where the parameters are within the sampling range of your training set, and also outside the sampling range (where success of the method would be even more interesting). "}, "signatures": ["ICLR.cc/2020/Conference/Paper2243/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper2243/AnonReviewer1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["cts17@mails.tsinghua.edu.cn", "lepangdan@outlook.com", "liufurui2@huawei.com", "chenzhitang2@huawei.com"], "title": "DO-AutoEncoder: Learning and Intervening Bivariate Causal Mechanisms in Images", "authors": ["Tianshuo Cong", "Dan Peng", "Furui Liu", "Zhitang Chen"], "pdf": "/pdf/c75e7d930ec5a0bf2427b3cc38fcc6a8fe9ef579.pdf", "TL;DR": "We propose a new framework  for deep representation learning that fully capture bivariate causal relationship in the images.", "abstract": "Some fundamental limitations of deep learning have been exposed such as lacking generalizability and being vunerable to adversarial attack. Instead, researchers realize that causation is much more stable than association relationship in data. In this paper, we propose a new framework called do-calculus AutoEncoder(DO-AE) for deep representation learning that fully capture bivariate causal relationship in the images which allows us to intervene in images generation process. DO-AE consists of two key ingredients: causal relationship mining in images and intervention-enabling deep causal structured representation learning. The goal here is to learn deep representations that correspond to the concepts in the physical world as well as their causal structure. To verify the proposed method, we create a dataset named PHY2D, which contains abstract graphic description in accordance with the laws of physics. Our experiments demonstrate our method is able to correctly identify the bivariate causal relationship between concepts in images and the representation learned enables a do-calculus manipulation to images, which generates artificial images that might possibly break the physical law depending on where we intervene the causal system.", "keywords": ["Causality discovery", "AutoEncoder", "Deep representation learning", "Do-calculus"], "paperhash": "cong|doautoencoder_learning_and_intervening_bivariate_causal_mechanisms_in_images", "original_pdf": "/attachment/c75e7d930ec5a0bf2427b3cc38fcc6a8fe9ef579.pdf", "_bibtex": "@misc{\ncong2020doautoencoder,\ntitle={{\\{}DO{\\}}-AutoEncoder: Learning and Intervening Bivariate Causal Mechanisms in Images},\nauthor={Tianshuo Cong and Dan Peng and Furui Liu and Zhitang Chen},\nyear={2020},\nurl={https://openreview.net/forum?id=r1e7NgrYvH}\n}"}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "r1e7NgrYvH", "replyto": "r1e7NgrYvH", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper2243/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper2243/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1575828631300, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper2243/Reviewers"], "noninvitees": [], "tcdate": 1570237725640, "tmdate": 1575828631314, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper2243/-/Official_Review"}}}], "count": 8}