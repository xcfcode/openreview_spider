{"notes": [{"id": "Pzj6fzU6wkj", "original": "ozklVYYNYVS", "number": 2324, "cdate": 1601308256190, "ddate": null, "tcdate": 1601308256190, "tmdate": 1615911523455, "tddate": null, "forum": "Pzj6fzU6wkj", "replyto": null, "invitation": "ICLR.cc/2021/Conference/-/Blind_Submission", "content": {"title": "IsarStep: a Benchmark for High-level Mathematical Reasoning", "authorids": ["~Wenda_Li1", "~Lei_Yu4", "~Yuhuai_Wu1", "lp15@cam.ac.uk"], "authors": ["Wenda Li", "Lei Yu", "Yuhuai Wu", "Lawrence C. Paulson"], "keywords": ["mathematical reasoning", "dataset", "benchmark", "reasoning", "transformer"], "abstract": "A well-defined benchmark is essential for measuring and accelerating research progress of machine learning models. In this paper, we present a benchmark for high-level mathematical reasoning and study the reasoning capabilities of neural sequence-to-sequence models. We build a non-synthetic dataset from the largest repository of proofs written by human experts in a theorem prover. The dataset has a broad coverage of undergraduate and research-level mathematical and computer science theorems. In our defined task, a model is required to fill in a missing intermediate proposition given surrounding proofs. This task provides a starting point for the long-term goal of having machines generate human-readable proofs automatically. Our experiments and analysis reveal that while the task is challenging, neural models can capture non-trivial mathematical reasoning. We further design a hierarchical transformer that outperforms the transformer baseline. ", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "li|isarstep_a_benchmark_for_highlevel_mathematical_reasoning", "one-sentence_summary": "We present a benchmark for high-level mathematical reasoning and study the reasoning capabilities of neural sequence-to-sequence models. ", "supplementary_material": "/attachment/c4ffbcc06fe39373cc0175e85faf7976f01086c8.zip", "pdf": "/pdf/c9fb7dd359102a00d8676684bd704c54961a5285.pdf", "venue": "ICLR 2021 Poster", "venueid": "ICLR.cc/2021/Conference", "_bibtex": "@inproceedings{\nli2021isarstep,\ntitle={IsarStep: a Benchmark for High-level Mathematical Reasoning},\nauthor={Wenda Li and Lei Yu and Yuhuai Wu and Lawrence C. Paulson},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=Pzj6fzU6wkj}\n}"}, "signatures": ["ICLR.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference"], "details": {"replyCount": 16, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"reply": {"readers": {"values-regex": ".*"}, "writers": {"values": ["ICLR.cc/2021/Conference"]}, "signatures": {"values": ["ICLR.cc/2021/Conference"]}, "content": {"authors": {"values": ["Anonymous"]}, "authorids": {"values-regex": ".*"}, "reviewed_version_(pdf)": {"required": false, "description": "Upload a PDF file that ends with .pdf", "value-regex": ".*"}}}, "signatures": ["ICLR.cc/2021/Conference"], "readers": ["everyone"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["~", "OpenReview.net/Support"], "tcdate": 1601308008205, "tmdate": 1614984599368, "id": "ICLR.cc/2021/Conference/-/Blind_Submission"}}, "tauthor": "OpenReview.net"}, {"id": "Rqitu0e1ZWg", "original": null, "number": 1, "cdate": 1610040425345, "ddate": null, "tcdate": 1610040425345, "tmdate": 1610474024646, "tddate": null, "forum": "Pzj6fzU6wkj", "replyto": "Pzj6fzU6wkj", "invitation": "ICLR.cc/2021/Conference/Paper2324/-/Decision", "content": {"title": "Final Decision", "decision": "Accept (Poster)", "comment": "This paper introduces a clever new problem that may prove useful in the advancement of Automatic Theorem Proving -- finding intermediate steps in a proof. A non-synthetic benchmark is created based on a large human-created dataset of proofs. Neural models were shown to have non-trivial performance. Reviewers were convinced that this is ultimately a useful benchmark."}, "signatures": ["ICLR.cc/2021/Conference/Program_Chairs"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference/Program_Chairs"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "IsarStep: a Benchmark for High-level Mathematical Reasoning", "authorids": ["~Wenda_Li1", "~Lei_Yu4", "~Yuhuai_Wu1", "lp15@cam.ac.uk"], "authors": ["Wenda Li", "Lei Yu", "Yuhuai Wu", "Lawrence C. Paulson"], "keywords": ["mathematical reasoning", "dataset", "benchmark", "reasoning", "transformer"], "abstract": "A well-defined benchmark is essential for measuring and accelerating research progress of machine learning models. In this paper, we present a benchmark for high-level mathematical reasoning and study the reasoning capabilities of neural sequence-to-sequence models. We build a non-synthetic dataset from the largest repository of proofs written by human experts in a theorem prover. The dataset has a broad coverage of undergraduate and research-level mathematical and computer science theorems. In our defined task, a model is required to fill in a missing intermediate proposition given surrounding proofs. This task provides a starting point for the long-term goal of having machines generate human-readable proofs automatically. Our experiments and analysis reveal that while the task is challenging, neural models can capture non-trivial mathematical reasoning. We further design a hierarchical transformer that outperforms the transformer baseline. ", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "li|isarstep_a_benchmark_for_highlevel_mathematical_reasoning", "one-sentence_summary": "We present a benchmark for high-level mathematical reasoning and study the reasoning capabilities of neural sequence-to-sequence models. ", "supplementary_material": "/attachment/c4ffbcc06fe39373cc0175e85faf7976f01086c8.zip", "pdf": "/pdf/c9fb7dd359102a00d8676684bd704c54961a5285.pdf", "venue": "ICLR 2021 Poster", "venueid": "ICLR.cc/2021/Conference", "_bibtex": "@inproceedings{\nli2021isarstep,\ntitle={IsarStep: a Benchmark for High-level Mathematical Reasoning},\nauthor={Wenda Li and Lei Yu and Yuhuai Wu and Lawrence C. Paulson},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=Pzj6fzU6wkj}\n}"}, "tags": [], "invitation": {"reply": {"forum": "Pzj6fzU6wkj", "replyto": "Pzj6fzU6wkj", "readers": {"values": ["everyone"]}, "writers": {"values": ["ICLR.cc/2021/Conference/Program_Chairs"]}, "signatures": {"values": ["ICLR.cc/2021/Conference/Program_Chairs"]}, "content": {"title": {"value": "Final Decision"}, "decision": {"value-radio": ["Accept (Oral)", "Accept (Spotlight)", "Accept (Poster)", "Reject"]}, "comment": {"value-regex": "[\\S\\s]{0,50000}", "markdown": true}}}, "multiReply": false, "signatures": ["ICLR.cc/2021/Conference"], "readers": ["everyone"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Program_Chairs"], "tcdate": 1610040425332, "tmdate": 1610474024629, "id": "ICLR.cc/2021/Conference/Paper2324/-/Decision"}}}, {"id": "Qj38VJ_-WNt", "original": null, "number": 4, "cdate": 1604051623442, "ddate": null, "tcdate": 1604051623442, "tmdate": 1606802679545, "tddate": null, "forum": "Pzj6fzU6wkj", "replyto": "Pzj6fzU6wkj", "invitation": "ICLR.cc/2021/Conference/Paper2324/-/Official_Review", "content": {"title": "Nice dataset, not quite novel", "review": "The paper introduces a dataset for proposing intermediate\nlemmas/conjectures based on a repository of Isabelle\nformalizations. It also does an evaluation of neural\nsequence-to-sequence methods on the dataset complemented to some\nextent by ATP evaluation. A hierarchical transformer is proposed that\noutperforms a transformer baseline.\n\nThis is a useful task and such datasets are useful. Apart from the\ndataset being based on Isabelle (which is indeed a major proof\nassistant with a nice library), there is however not much\nnovelty. Similar datasets have been extracted from other libraries and\nneural experiments have been done over them. To those cited, I would\nadd [1] based on the large E_conj dataset [2] created in 2017.\nCompared to the dataset presented here, [2] also provides an effective\ncomputational metric (based on hundreds of thousands of E prover runs)\nfor judging the usefulness of the intermediate lemmas. Such datasets\nare easy to produce and to scale up to orders of magnitude larger\nsizes.  \n\nSimilar works also include AIMLEAP [3] and the datasets created by\nPiotrowski using seq2seq for predicting the next tableau steps [4].\n\nOne big issue with the dataset compared to the related work is that it\nis not clear how to run the ATP evaluation. The interesting parts of\ncombining ML and TP typically occur when one can easily run tools on\nboth sides, do feedback loops, etc.\n\nOn the other hand, the ML study seems interesting, it is good that the\nIsabelle library is starting to be used this way, and the hierarchical\ntransformer seems to help. Hence my neutral to mildly positive score,\neven though the claims about the uniqueness of the benchmark should be\ncorrected.\n\n\nSome more detailed remarks:\n\np2: give a pointer to declarative vs procedural proofs - the sqrt 2 example has been largely developed by Wiedijk and the declarative proof style comes from Mizar\n\np4: Free variable normalization\n==> \ntreating of (eigen)variables has been a big topic in the ML-for-TP area. For the most recent feature-based encodings see e.g. the ENIGMA approach. For principled neural treatment, see e.g. the work of Olsak on invariant GNNs [3].\n\np6: how is the ATP evaluation done?\n\nReferences:\n\n[1] Zarathustra Goertzel and Josef Urban: Usefulness of Lemmas via Graph Neural Networks. \nhttp://aitp-conference.org/2019/abstract/AITP_2019_paper_32.pdf \n\n[2] https://github.com/JUrban/E_conj\n\n[3] Learning to Advise an Equational Prover\nChad E. Brown, Bartosz Piotrowski, and Josef Urban\nhttp://aitp-conference.org/2020/abstract/paper_32.pdf\n\n[4] Bartosz Piotrowski, Josef Urban:\nGuiding Inferences in Connection Tableau by Recurrent Neural Networks. CICM 2020: 309-314\n\n[5] Miroslav Ols\u00e1k et al:\nProperty Invariant Embedding for Automated Reasoning. ECAI 2020: 1395-1402\n\n================\n\nUPDATE\n\nThanks to the authors for their replies and paper updates. My overall evaluation remains on the slightly positive side: I believe that conjecturing is an important task and Isabelle provides a nice corpus for that. Even if declarative proof corpora based on Mizar have been used for similar ML/TP tasks before and the work is not quite novel.\n\nFurther notes:\n\n- I would recommend exporting the corpus in the TPTP format. This typically makes the ATP evaluation and building of ML/ATP feedback loops (much) more accessible to ATP researchers, allows including the benchmark in the CASC LTB (large-theory batch) competition, etc. This has been done before [6] for the large corpus of declarative Jaskowski-style Mizar proofs that can be easily used in a similar way as the Isabelle data provided here.\n\n- I do not quite agree with the response claim that E_conj is synthetic and focused on ranking and classification. It is derived from a real-world (Mizar) problem set and the ATP-synthesized lemmas are equipped with a metric of their real-world usefulness. So the various tasks such as regression, ranking, classification and (indeed) synthesis (there is nothing hard about synthesis in the E_conj scenario) have a direct impact in terms of suitable splitting of the real-world ATP problems and their easier solution. It is the same cut introduction task as the authors consider here, just with much more data derived from ATP runs and their characteristics rather than from human proofs. This kind of ATP-based data augmentation is one of the most useful ones in the ML-for-TP domain - quite often more useful than working with human proofs [7] because the ultimate evaluation scenario typically involves ATPs. So it is certainly not the kind of artificial/synthetic task that has an unclear real-world value.\n\n[6] Josef Urban, Geoff Sutcliffe: ATP-based Cross-Verification of Mizar Proofs: Method, Systems, and First Experiments. Math. Comput. Sci. 2(2): 231-251 (2008)\n\n[7] Daniel K\u00fchlwein, Josef Urban: Learning from Multiple Proofs: First Experiments. PAAR@IJCAR 2012: 82-94\n", "rating": "6: Marginally above acceptance threshold", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["ICLR.cc/2021/Conference/Paper2324/AnonReviewer4"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2324/AnonReviewer4"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "IsarStep: a Benchmark for High-level Mathematical Reasoning", "authorids": ["~Wenda_Li1", "~Lei_Yu4", "~Yuhuai_Wu1", "lp15@cam.ac.uk"], "authors": ["Wenda Li", "Lei Yu", "Yuhuai Wu", "Lawrence C. Paulson"], "keywords": ["mathematical reasoning", "dataset", "benchmark", "reasoning", "transformer"], "abstract": "A well-defined benchmark is essential for measuring and accelerating research progress of machine learning models. In this paper, we present a benchmark for high-level mathematical reasoning and study the reasoning capabilities of neural sequence-to-sequence models. We build a non-synthetic dataset from the largest repository of proofs written by human experts in a theorem prover. The dataset has a broad coverage of undergraduate and research-level mathematical and computer science theorems. In our defined task, a model is required to fill in a missing intermediate proposition given surrounding proofs. This task provides a starting point for the long-term goal of having machines generate human-readable proofs automatically. Our experiments and analysis reveal that while the task is challenging, neural models can capture non-trivial mathematical reasoning. We further design a hierarchical transformer that outperforms the transformer baseline. ", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "li|isarstep_a_benchmark_for_highlevel_mathematical_reasoning", "one-sentence_summary": "We present a benchmark for high-level mathematical reasoning and study the reasoning capabilities of neural sequence-to-sequence models. ", "supplementary_material": "/attachment/c4ffbcc06fe39373cc0175e85faf7976f01086c8.zip", "pdf": "/pdf/c9fb7dd359102a00d8676684bd704c54961a5285.pdf", "venue": "ICLR 2021 Poster", "venueid": "ICLR.cc/2021/Conference", "_bibtex": "@inproceedings{\nli2021isarstep,\ntitle={IsarStep: a Benchmark for High-level Mathematical Reasoning},\nauthor={Wenda Li and Lei Yu and Yuhuai Wu and Lawrence C. Paulson},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=Pzj6fzU6wkj}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq . ***Please remember to file the Code-of-Ethics report. Once you submitted the review, a link to the report will be visible in the bottom right corner of your review.***", "required": true, "markdown": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}, "forum": "Pzj6fzU6wkj", "replyto": "Pzj6fzU6wkj", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"], "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper2324/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1607428800000, "duedate": 1606752000000, "multiReply": false, "readers": ["everyone"], "tcdate": 1602538099020, "tmdate": 1606915779603, "super": "ICLR.cc/2021/Conference/-/Official_Review", "signatures": ["OpenReview.net"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Paper2324/Reviewers", "OpenReview.net/Support"], "id": "ICLR.cc/2021/Conference/Paper2324/-/Official_Review"}}}, {"id": "GC4uAfD5yiO", "original": null, "number": 12, "cdate": 1606239000732, "ddate": null, "tcdate": 1606239000732, "tmdate": 1606239000732, "tddate": null, "forum": "Pzj6fzU6wkj", "replyto": "LZ4z3Aqi94o", "invitation": "ICLR.cc/2021/Conference/Paper2324/-/Official_Comment", "content": {"title": "Score", "comment": "Based on your answers and inspecting the dataset, I have increased my score."}, "signatures": ["ICLR.cc/2021/Conference/Paper2324/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2324/AnonReviewer1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "IsarStep: a Benchmark for High-level Mathematical Reasoning", "authorids": ["~Wenda_Li1", "~Lei_Yu4", "~Yuhuai_Wu1", "lp15@cam.ac.uk"], "authors": ["Wenda Li", "Lei Yu", "Yuhuai Wu", "Lawrence C. Paulson"], "keywords": ["mathematical reasoning", "dataset", "benchmark", "reasoning", "transformer"], "abstract": "A well-defined benchmark is essential for measuring and accelerating research progress of machine learning models. In this paper, we present a benchmark for high-level mathematical reasoning and study the reasoning capabilities of neural sequence-to-sequence models. We build a non-synthetic dataset from the largest repository of proofs written by human experts in a theorem prover. The dataset has a broad coverage of undergraduate and research-level mathematical and computer science theorems. In our defined task, a model is required to fill in a missing intermediate proposition given surrounding proofs. This task provides a starting point for the long-term goal of having machines generate human-readable proofs automatically. Our experiments and analysis reveal that while the task is challenging, neural models can capture non-trivial mathematical reasoning. We further design a hierarchical transformer that outperforms the transformer baseline. ", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "li|isarstep_a_benchmark_for_highlevel_mathematical_reasoning", "one-sentence_summary": "We present a benchmark for high-level mathematical reasoning and study the reasoning capabilities of neural sequence-to-sequence models. ", "supplementary_material": "/attachment/c4ffbcc06fe39373cc0175e85faf7976f01086c8.zip", "pdf": "/pdf/c9fb7dd359102a00d8676684bd704c54961a5285.pdf", "venue": "ICLR 2021 Poster", "venueid": "ICLR.cc/2021/Conference", "_bibtex": "@inproceedings{\nli2021isarstep,\ntitle={IsarStep: a Benchmark for High-level Mathematical Reasoning},\nauthor={Wenda Li and Lei Yu and Yuhuai Wu and Lawrence C. Paulson},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=Pzj6fzU6wkj}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "Pzj6fzU6wkj", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper2324/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper2324/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper2324/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper2324/Authors|ICLR.cc/2021/Conference/Paper2324/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2324/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923849753, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper2324/-/Official_Comment"}}}, {"id": "Qh8bG0hmhl_", "original": null, "number": 2, "cdate": 1603703985583, "ddate": null, "tcdate": 1603703985583, "tmdate": 1606238948032, "tddate": null, "forum": "Pzj6fzU6wkj", "replyto": "Pzj6fzU6wkj", "invitation": "ICLR.cc/2021/Conference/Paper2324/-/Official_Review", "content": {"title": "The largest problem is that the dataset is said to be available, but the link is expressed as xxxx.", "review": "This paper presents a non-synthetic dataset generated from the Isabelle AFP, the largest mechanised proof repository for the task of filling in a missing intermediate proposition given surrounding proofs. Together with the dataset the paper presents a hierarchical transformer model (HAT). Top-10 accuracy, which is the percentage of target proposition appearing in the top 10 generated propositions, is 37.2 for their HAT model. The task this paper addresses is important for theorem proving practitioners, and synthesising propositions appears to be a more difficult challenge compared to other ML tasks in theorem proving (choosing useful lemmas or choosing tactics).\n\nStrengths:\n\n- The database is produced from a non-synthetic dataset called the Archive of Formal Proofs (AFP). AFP is a good source to produce a database that covers diverse topics.\n- The newly proposed hierarchical transformer model outperforms the baseline models.\n- The evaluation includes a comparison to models reported by other researchers.\n- The paper uses a simple motivating example, which helps readers understand the task.\n- The evaluation results reported in Table 1 and Table 2 are good for the difficult task of synthesising propositions for diverse problems from the AFP.\n\n# Weakness\n- The link to the dataset and model is missing as well as the link to their \"test suite to check the correctness of types and the validity of the generated propositions using automatic theorem provers\". This is a serious problem to evaluate the paper. The results presented in Tables 1 and 2 are good for the difficult task of proposition synthesis, and I want to test their model for some problems myself. Without the link this is not possible\n\n- The contribution to the proof automation is surprisingly small. They reported 70 cases out of about 3000 are newly proved given the generated intermediate propositions from their HAT model. From the numbers reported in Table 2, I would expect more improvements could be achieved. Without further investigation it is hard to understand this discrepancy.\n\n# Further comments:\n\n- Maybe, it is better to give short names to F1 ~ F5 instead of Fs and numbers?  For example, F1 can be \"target\" in bold or in teletype font.\n- In Section 3.1, the example token pops out of the column for the main text. Maybe removing spaces after the left parenthesis and before the right parenthesis helps?\n- In Section 4, the vector \"x\" is underlined. Is this aligned with the convention in the community? I saw that \"x\" with an over-line to denote vectors in the past.\n- \"as the sequence of source propositions with I propositions\" -> \"as the sequence of I source propositions\"?\n- In Section 5.2,  it seems reasonable to consider \"alternative valid propositions\". Can you formally introduce the definition of \"correct proposition\"? I guess a \"correct proposition\" is a proposition that matches either the corresponding ground truth or one of the alternative valid propositions. Am I right?\n- In the paragraph for Alternative  Valid Propositions in Section 5.2, \"5% more correct propositions\" -> \"5 percentage point more correct propositions\"?\n- In Section 5.2, the reported contribution to the automation is surprisingly small considering the numbers reported in Table 1 and Table 2. 70 out of 3000 is a 2.3 percentage point increment, even though the previous paragraph says \"alternative propositions contribute 5% more correct positions\".  Does this mean that some of propositions produced by HAT are valid intermediate lemmas that can be derived from local propositions (F2) and that can be used to prove the goal (F3), but the ATPs are so strong that they can prove F3 from F2 without the valid intermediate lemmas, i.e. IsarStep tends to include small steps that can be skipped by the state-of-the-art ATPs? It is natural if this happens since ATPs are continuously improved and sometimes Isabelle users intentionally write down small steps that are not necessary for the state-of-the-art ATPs.\n- In Table 3 in Appendix B, I guess you forgot to multiply numbers by 100 to compute percentage. If so, these numbers in Table 3 appear to be good to me, and it is interesting to know that Transformer slightly outperforms HAT in Table 3 even though HAT outperforms Transformer for producing \"correct propositions\".\n", "rating": "7: Good paper, accept", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}, "signatures": ["ICLR.cc/2021/Conference/Paper2324/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2324/AnonReviewer1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "IsarStep: a Benchmark for High-level Mathematical Reasoning", "authorids": ["~Wenda_Li1", "~Lei_Yu4", "~Yuhuai_Wu1", "lp15@cam.ac.uk"], "authors": ["Wenda Li", "Lei Yu", "Yuhuai Wu", "Lawrence C. Paulson"], "keywords": ["mathematical reasoning", "dataset", "benchmark", "reasoning", "transformer"], "abstract": "A well-defined benchmark is essential for measuring and accelerating research progress of machine learning models. In this paper, we present a benchmark for high-level mathematical reasoning and study the reasoning capabilities of neural sequence-to-sequence models. We build a non-synthetic dataset from the largest repository of proofs written by human experts in a theorem prover. The dataset has a broad coverage of undergraduate and research-level mathematical and computer science theorems. In our defined task, a model is required to fill in a missing intermediate proposition given surrounding proofs. This task provides a starting point for the long-term goal of having machines generate human-readable proofs automatically. Our experiments and analysis reveal that while the task is challenging, neural models can capture non-trivial mathematical reasoning. We further design a hierarchical transformer that outperforms the transformer baseline. ", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "li|isarstep_a_benchmark_for_highlevel_mathematical_reasoning", "one-sentence_summary": "We present a benchmark for high-level mathematical reasoning and study the reasoning capabilities of neural sequence-to-sequence models. ", "supplementary_material": "/attachment/c4ffbcc06fe39373cc0175e85faf7976f01086c8.zip", "pdf": "/pdf/c9fb7dd359102a00d8676684bd704c54961a5285.pdf", "venue": "ICLR 2021 Poster", "venueid": "ICLR.cc/2021/Conference", "_bibtex": "@inproceedings{\nli2021isarstep,\ntitle={IsarStep: a Benchmark for High-level Mathematical Reasoning},\nauthor={Wenda Li and Lei Yu and Yuhuai Wu and Lawrence C. Paulson},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=Pzj6fzU6wkj}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq . ***Please remember to file the Code-of-Ethics report. Once you submitted the review, a link to the report will be visible in the bottom right corner of your review.***", "required": true, "markdown": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}, "forum": "Pzj6fzU6wkj", "replyto": "Pzj6fzU6wkj", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"], "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper2324/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1607428800000, "duedate": 1606752000000, "multiReply": false, "readers": ["everyone"], "tcdate": 1602538099020, "tmdate": 1606915779603, "super": "ICLR.cc/2021/Conference/-/Official_Review", "signatures": ["OpenReview.net"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Paper2324/Reviewers", "OpenReview.net/Support"], "id": "ICLR.cc/2021/Conference/Paper2324/-/Official_Review"}}}, {"id": "wKXS6ksUdsK", "original": null, "number": 11, "cdate": 1606223699339, "ddate": null, "tcdate": 1606223699339, "tmdate": 1606223699339, "tddate": null, "forum": "Pzj6fzU6wkj", "replyto": "GoVE8PJLT1", "invitation": "ICLR.cc/2021/Conference/Paper2324/-/Official_Comment", "content": {"title": "Does our rebuttal address your concerns?", "comment": "We wonder if our rebuttal have addressed your concerns. If not, we are happy to clarify further. Please let us know. Thank you very much."}, "signatures": ["ICLR.cc/2021/Conference/Paper2324/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2324/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "IsarStep: a Benchmark for High-level Mathematical Reasoning", "authorids": ["~Wenda_Li1", "~Lei_Yu4", "~Yuhuai_Wu1", "lp15@cam.ac.uk"], "authors": ["Wenda Li", "Lei Yu", "Yuhuai Wu", "Lawrence C. Paulson"], "keywords": ["mathematical reasoning", "dataset", "benchmark", "reasoning", "transformer"], "abstract": "A well-defined benchmark is essential for measuring and accelerating research progress of machine learning models. In this paper, we present a benchmark for high-level mathematical reasoning and study the reasoning capabilities of neural sequence-to-sequence models. We build a non-synthetic dataset from the largest repository of proofs written by human experts in a theorem prover. The dataset has a broad coverage of undergraduate and research-level mathematical and computer science theorems. In our defined task, a model is required to fill in a missing intermediate proposition given surrounding proofs. This task provides a starting point for the long-term goal of having machines generate human-readable proofs automatically. Our experiments and analysis reveal that while the task is challenging, neural models can capture non-trivial mathematical reasoning. We further design a hierarchical transformer that outperforms the transformer baseline. ", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "li|isarstep_a_benchmark_for_highlevel_mathematical_reasoning", "one-sentence_summary": "We present a benchmark for high-level mathematical reasoning and study the reasoning capabilities of neural sequence-to-sequence models. ", "supplementary_material": "/attachment/c4ffbcc06fe39373cc0175e85faf7976f01086c8.zip", "pdf": "/pdf/c9fb7dd359102a00d8676684bd704c54961a5285.pdf", "venue": "ICLR 2021 Poster", "venueid": "ICLR.cc/2021/Conference", "_bibtex": "@inproceedings{\nli2021isarstep,\ntitle={IsarStep: a Benchmark for High-level Mathematical Reasoning},\nauthor={Wenda Li and Lei Yu and Yuhuai Wu and Lawrence C. Paulson},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=Pzj6fzU6wkj}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "Pzj6fzU6wkj", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper2324/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper2324/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper2324/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper2324/Authors|ICLR.cc/2021/Conference/Paper2324/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2324/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923849753, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper2324/-/Official_Comment"}}}, {"id": "LZ4z3Aqi94o", "original": null, "number": 10, "cdate": 1606222372224, "ddate": null, "tcdate": 1606222372224, "tmdate": 1606222372224, "tddate": null, "forum": "Pzj6fzU6wkj", "replyto": "ZlZI87b8jt", "invitation": "ICLR.cc/2021/Conference/Paper2324/-/Official_Comment", "content": {"title": "Does our rebuttal address your concerns? ", "comment": "We wonder if our rebuttal have addressed your concerns. If not, we are happy to clarify further. Please let us know. Thank you very much."}, "signatures": ["ICLR.cc/2021/Conference/Paper2324/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2324/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "IsarStep: a Benchmark for High-level Mathematical Reasoning", "authorids": ["~Wenda_Li1", "~Lei_Yu4", "~Yuhuai_Wu1", "lp15@cam.ac.uk"], "authors": ["Wenda Li", "Lei Yu", "Yuhuai Wu", "Lawrence C. Paulson"], "keywords": ["mathematical reasoning", "dataset", "benchmark", "reasoning", "transformer"], "abstract": "A well-defined benchmark is essential for measuring and accelerating research progress of machine learning models. In this paper, we present a benchmark for high-level mathematical reasoning and study the reasoning capabilities of neural sequence-to-sequence models. We build a non-synthetic dataset from the largest repository of proofs written by human experts in a theorem prover. The dataset has a broad coverage of undergraduate and research-level mathematical and computer science theorems. In our defined task, a model is required to fill in a missing intermediate proposition given surrounding proofs. This task provides a starting point for the long-term goal of having machines generate human-readable proofs automatically. Our experiments and analysis reveal that while the task is challenging, neural models can capture non-trivial mathematical reasoning. We further design a hierarchical transformer that outperforms the transformer baseline. ", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "li|isarstep_a_benchmark_for_highlevel_mathematical_reasoning", "one-sentence_summary": "We present a benchmark for high-level mathematical reasoning and study the reasoning capabilities of neural sequence-to-sequence models. ", "supplementary_material": "/attachment/c4ffbcc06fe39373cc0175e85faf7976f01086c8.zip", "pdf": "/pdf/c9fb7dd359102a00d8676684bd704c54961a5285.pdf", "venue": "ICLR 2021 Poster", "venueid": "ICLR.cc/2021/Conference", "_bibtex": "@inproceedings{\nli2021isarstep,\ntitle={IsarStep: a Benchmark for High-level Mathematical Reasoning},\nauthor={Wenda Li and Lei Yu and Yuhuai Wu and Lawrence C. Paulson},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=Pzj6fzU6wkj}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "Pzj6fzU6wkj", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper2324/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper2324/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper2324/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper2324/Authors|ICLR.cc/2021/Conference/Paper2324/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2324/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923849753, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper2324/-/Official_Comment"}}}, {"id": "RKCuEMRSeN_", "original": null, "number": 8, "cdate": 1605977529402, "ddate": null, "tcdate": 1605977529402, "tmdate": 1606143731031, "tddate": null, "forum": "Pzj6fzU6wkj", "replyto": "Hkop7OvBFbA", "invitation": "ICLR.cc/2021/Conference/Paper2324/-/Official_Comment", "content": {"title": "Thank you", "comment": "Many thanks again for your efforts and suggestions. They really have helped us improve the paper. "}, "signatures": ["ICLR.cc/2021/Conference/Paper2324/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2324/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "IsarStep: a Benchmark for High-level Mathematical Reasoning", "authorids": ["~Wenda_Li1", "~Lei_Yu4", "~Yuhuai_Wu1", "lp15@cam.ac.uk"], "authors": ["Wenda Li", "Lei Yu", "Yuhuai Wu", "Lawrence C. Paulson"], "keywords": ["mathematical reasoning", "dataset", "benchmark", "reasoning", "transformer"], "abstract": "A well-defined benchmark is essential for measuring and accelerating research progress of machine learning models. In this paper, we present a benchmark for high-level mathematical reasoning and study the reasoning capabilities of neural sequence-to-sequence models. We build a non-synthetic dataset from the largest repository of proofs written by human experts in a theorem prover. The dataset has a broad coverage of undergraduate and research-level mathematical and computer science theorems. In our defined task, a model is required to fill in a missing intermediate proposition given surrounding proofs. This task provides a starting point for the long-term goal of having machines generate human-readable proofs automatically. Our experiments and analysis reveal that while the task is challenging, neural models can capture non-trivial mathematical reasoning. We further design a hierarchical transformer that outperforms the transformer baseline. ", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "li|isarstep_a_benchmark_for_highlevel_mathematical_reasoning", "one-sentence_summary": "We present a benchmark for high-level mathematical reasoning and study the reasoning capabilities of neural sequence-to-sequence models. ", "supplementary_material": "/attachment/c4ffbcc06fe39373cc0175e85faf7976f01086c8.zip", "pdf": "/pdf/c9fb7dd359102a00d8676684bd704c54961a5285.pdf", "venue": "ICLR 2021 Poster", "venueid": "ICLR.cc/2021/Conference", "_bibtex": "@inproceedings{\nli2021isarstep,\ntitle={IsarStep: a Benchmark for High-level Mathematical Reasoning},\nauthor={Wenda Li and Lei Yu and Yuhuai Wu and Lawrence C. Paulson},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=Pzj6fzU6wkj}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "Pzj6fzU6wkj", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper2324/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper2324/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper2324/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper2324/Authors|ICLR.cc/2021/Conference/Paper2324/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2324/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923849753, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper2324/-/Official_Comment"}}}, {"id": "ZlZI87b8jt", "original": null, "number": 9, "cdate": 1606139373649, "ddate": null, "tcdate": 1606139373649, "tmdate": 1606139373649, "tddate": null, "forum": "Pzj6fzU6wkj", "replyto": "bLc8eUJRrsI", "invitation": "ICLR.cc/2021/Conference/Paper2324/-/Official_Comment", "content": {"title": "Further elaboration regarding the automation improvement", "comment": "We have added the following paragraph to the appendix. We hope this can, to some extent, explain the small improvement in automation. \n\nWith such settings, Sledgehammer can automatically prove the goal F.3 in 1984/4908 examples. By incorporating the ground truth F.1, the derivations (i.e., to prove both $F.2 \\Rightarrow F.1$ and $F.1 \\Rightarrow F.3$) can be closed automatically in 2243 examples. Among the 1125 examples that HAT produces an exact match, 466 of them have a 'small' gap: Sledgehammer discharges the goal F.3 directly; 61 of gaps are 'just right': the introduced intermediate step $F.1$ can help Sledgehammer bridge the gap; most of the remaining 598 examples have 'large' gaps (in either $F.2 \\Rightarrow F.1$ or $F.1 \\Rightarrow F.3$) that are beyond the capability of Sledgehammer. It appears that the insignificant amount of automation improvement can be attributed to the limited number of 'just right' gaps that are within the reach of Sledgehammer.\n\nWe have also addressed your further comments in the updated version. \n\nThank you again for your insightful suggestions!\n"}, "signatures": ["ICLR.cc/2021/Conference/Paper2324/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2324/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "IsarStep: a Benchmark for High-level Mathematical Reasoning", "authorids": ["~Wenda_Li1", "~Lei_Yu4", "~Yuhuai_Wu1", "lp15@cam.ac.uk"], "authors": ["Wenda Li", "Lei Yu", "Yuhuai Wu", "Lawrence C. Paulson"], "keywords": ["mathematical reasoning", "dataset", "benchmark", "reasoning", "transformer"], "abstract": "A well-defined benchmark is essential for measuring and accelerating research progress of machine learning models. In this paper, we present a benchmark for high-level mathematical reasoning and study the reasoning capabilities of neural sequence-to-sequence models. We build a non-synthetic dataset from the largest repository of proofs written by human experts in a theorem prover. The dataset has a broad coverage of undergraduate and research-level mathematical and computer science theorems. In our defined task, a model is required to fill in a missing intermediate proposition given surrounding proofs. This task provides a starting point for the long-term goal of having machines generate human-readable proofs automatically. Our experiments and analysis reveal that while the task is challenging, neural models can capture non-trivial mathematical reasoning. We further design a hierarchical transformer that outperforms the transformer baseline. ", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "li|isarstep_a_benchmark_for_highlevel_mathematical_reasoning", "one-sentence_summary": "We present a benchmark for high-level mathematical reasoning and study the reasoning capabilities of neural sequence-to-sequence models. ", "supplementary_material": "/attachment/c4ffbcc06fe39373cc0175e85faf7976f01086c8.zip", "pdf": "/pdf/c9fb7dd359102a00d8676684bd704c54961a5285.pdf", "venue": "ICLR 2021 Poster", "venueid": "ICLR.cc/2021/Conference", "_bibtex": "@inproceedings{\nli2021isarstep,\ntitle={IsarStep: a Benchmark for High-level Mathematical Reasoning},\nauthor={Wenda Li and Lei Yu and Yuhuai Wu and Lawrence C. Paulson},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=Pzj6fzU6wkj}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "Pzj6fzU6wkj", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper2324/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper2324/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper2324/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper2324/Authors|ICLR.cc/2021/Conference/Paper2324/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2324/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923849753, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper2324/-/Official_Comment"}}}, {"id": "Rtp1tIz8K3N", "original": null, "number": 1, "cdate": 1603640792069, "ddate": null, "tcdate": 1603640792069, "tmdate": 1606058667967, "tddate": null, "forum": "Pzj6fzU6wkj", "replyto": "Pzj6fzU6wkj", "invitation": "ICLR.cc/2021/Conference/Paper2324/-/Official_Review", "content": {"title": "IsarStep: a Benchmark for High-level Mathematical Reasoning", "review": "The authors propose a new benchmark task to evaluate the high-level reasoning capabilities of machine learning models (specifically sequence-to-sequence models) in the context of proof assistants. The task consists of predicting the intermediate proposition from its surrounding ones, namely its previous and its subsequent propositions. The experimental analysis provides evidence on the difficulty of the task at hand. The authors propose also a solution based on a hierarchical transformer, which is able to better capture the mathematical relations of intra- and inter-propositions compared to existing sequence-to-sequence models, as demonstrated by quantitative as well as qualitative analyses.\n\nThe paper is clearly written and has a good balance between technicality and readability.\nProvided examples are pedagogical to better understand the introduced concepts. Also, it is positive the fact that the authors are prone to publish their data and code to foster the reproducibility of the experiments.\n\nThe major drawback with the paper is in the weak/not well supported motivations of the proposed benchmark task. Also, a discussion of the differences between the proposed model and existing hierarchical transformer architectures is missing. Please, refer below to more detailed comments.\n\nTaking into account that it's not clear to me why the proposed benchmark task is necessary to advance the research in the field of proof assistants, I consider the paper marginally below the acceptance threshold and therefore recommend for an initial rejection. Nevertheless, I'm willing to raise my score if the authors can provide a better explanation on their motivations or provide more convincing arguments supporting the need of their proposed benchmark task. Furthermore, I suggest the authors to discuss some missing related work on hierarchical transformers.\n\nDETAILED COMMENTS\n\nThe authors argue that \"solving the IsarStep task will be potentially helpful for improving the automation of theorem provers, because proposing a valid intermediate proposition will help to reduce their search space significantly\". In general, I agree with the authors that developing benchmarks is an essential driving factor in research and that designing methods able to reduce the search space is essential to improve the automation of theorem provers. I'm not able to see why and how IsarStep can drive this advancement though.\nProofs, both procedural and declarative ones, are inherently sequential and IsarStep breaks this sequentiality by assuming that the proposition subsequent to the missing one is given. For instance, consider the same example used in Section 2 to prove the irrationality of the square root of 2. Why can statement (3) be considered given and in which practical situations does the task of predicting (2) given (1) and (3) occur? Does the IsarStep task occur in practice when proving new conjectures? Wouldn't it be more natural to predict (2) and subsequently (3) by having only (1)?\n\nFurthermore, in which sense is solving IsarStep \"a first step towards the long-term goal of sketching complete human-readable proofs automatically\"? Can you elaborate more on that?\n\nHierarchical transformers have been already proposed in natural language for the purposes of document summarization [1-2]. Can you relate with these existing works and particularly discuss what are the architectural novelties of your proposed transformer, as this is one of the contributions listed in the introduction?\n\nMINOR COMMENTS\n\nIn the experimental section regarding the visualisation of attention, can you specify what is F2 and what is F3?\n\n[1] Zhang et al. HIBERT: Document Level Pre-training of Hierarchical Bidirectional Transformers for Document Summarization. ACL 2019\n[2] Liu and Lapata. Hierarchical Transformers for Multi-Document Summarization. ACL 2019\n\n#########################\n\nUPDATE\n\nAuthors have clarified the doubts raised by my questions. I believe that the task proposed in the paper provides new insights on the weaknesses of deep learning models. Therefore, solving the task is important to advance the automation of proof assistants through machine learning. Based on this, I recommend for acceptance.", "rating": "6: Marginally above acceptance threshold", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["ICLR.cc/2021/Conference/Paper2324/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2324/AnonReviewer2"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "IsarStep: a Benchmark for High-level Mathematical Reasoning", "authorids": ["~Wenda_Li1", "~Lei_Yu4", "~Yuhuai_Wu1", "lp15@cam.ac.uk"], "authors": ["Wenda Li", "Lei Yu", "Yuhuai Wu", "Lawrence C. Paulson"], "keywords": ["mathematical reasoning", "dataset", "benchmark", "reasoning", "transformer"], "abstract": "A well-defined benchmark is essential for measuring and accelerating research progress of machine learning models. In this paper, we present a benchmark for high-level mathematical reasoning and study the reasoning capabilities of neural sequence-to-sequence models. We build a non-synthetic dataset from the largest repository of proofs written by human experts in a theorem prover. The dataset has a broad coverage of undergraduate and research-level mathematical and computer science theorems. In our defined task, a model is required to fill in a missing intermediate proposition given surrounding proofs. This task provides a starting point for the long-term goal of having machines generate human-readable proofs automatically. Our experiments and analysis reveal that while the task is challenging, neural models can capture non-trivial mathematical reasoning. We further design a hierarchical transformer that outperforms the transformer baseline. ", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "li|isarstep_a_benchmark_for_highlevel_mathematical_reasoning", "one-sentence_summary": "We present a benchmark for high-level mathematical reasoning and study the reasoning capabilities of neural sequence-to-sequence models. ", "supplementary_material": "/attachment/c4ffbcc06fe39373cc0175e85faf7976f01086c8.zip", "pdf": "/pdf/c9fb7dd359102a00d8676684bd704c54961a5285.pdf", "venue": "ICLR 2021 Poster", "venueid": "ICLR.cc/2021/Conference", "_bibtex": "@inproceedings{\nli2021isarstep,\ntitle={IsarStep: a Benchmark for High-level Mathematical Reasoning},\nauthor={Wenda Li and Lei Yu and Yuhuai Wu and Lawrence C. Paulson},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=Pzj6fzU6wkj}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq . ***Please remember to file the Code-of-Ethics report. Once you submitted the review, a link to the report will be visible in the bottom right corner of your review.***", "required": true, "markdown": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}, "forum": "Pzj6fzU6wkj", "replyto": "Pzj6fzU6wkj", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"], "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper2324/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1607428800000, "duedate": 1606752000000, "multiReply": false, "readers": ["everyone"], "tcdate": 1602538099020, "tmdate": 1606915779603, "super": "ICLR.cc/2021/Conference/-/Official_Review", "signatures": ["OpenReview.net"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Paper2324/Reviewers", "OpenReview.net/Support"], "id": "ICLR.cc/2021/Conference/Paper2324/-/Official_Review"}}}, {"id": "Hkop7OvBFbA", "original": null, "number": 7, "cdate": 1605882484117, "ddate": null, "tcdate": 1605882484117, "tmdate": 1605882484117, "tddate": null, "forum": "Pzj6fzU6wkj", "replyto": "i_s3Tlzy4kq", "invitation": "ICLR.cc/2021/Conference/Paper2324/-/Official_Comment", "content": {"title": "Points clarified by the authors", "comment": "Thank you for addressing and clarifying my points.\nI found the argument about the non-sequentiality nature of theorem proving convincing. Originally, this was my most important concern. Also, it's good to see that you have discussed the differences of your model with existing hierarchical transformers.\n\nBased on this, I'm happy to increase my score and recommend for acceptance.\n"}, "signatures": ["ICLR.cc/2021/Conference/Paper2324/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2324/AnonReviewer2"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "IsarStep: a Benchmark for High-level Mathematical Reasoning", "authorids": ["~Wenda_Li1", "~Lei_Yu4", "~Yuhuai_Wu1", "lp15@cam.ac.uk"], "authors": ["Wenda Li", "Lei Yu", "Yuhuai Wu", "Lawrence C. Paulson"], "keywords": ["mathematical reasoning", "dataset", "benchmark", "reasoning", "transformer"], "abstract": "A well-defined benchmark is essential for measuring and accelerating research progress of machine learning models. In this paper, we present a benchmark for high-level mathematical reasoning and study the reasoning capabilities of neural sequence-to-sequence models. We build a non-synthetic dataset from the largest repository of proofs written by human experts in a theorem prover. The dataset has a broad coverage of undergraduate and research-level mathematical and computer science theorems. In our defined task, a model is required to fill in a missing intermediate proposition given surrounding proofs. This task provides a starting point for the long-term goal of having machines generate human-readable proofs automatically. Our experiments and analysis reveal that while the task is challenging, neural models can capture non-trivial mathematical reasoning. We further design a hierarchical transformer that outperforms the transformer baseline. ", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "li|isarstep_a_benchmark_for_highlevel_mathematical_reasoning", "one-sentence_summary": "We present a benchmark for high-level mathematical reasoning and study the reasoning capabilities of neural sequence-to-sequence models. ", "supplementary_material": "/attachment/c4ffbcc06fe39373cc0175e85faf7976f01086c8.zip", "pdf": "/pdf/c9fb7dd359102a00d8676684bd704c54961a5285.pdf", "venue": "ICLR 2021 Poster", "venueid": "ICLR.cc/2021/Conference", "_bibtex": "@inproceedings{\nli2021isarstep,\ntitle={IsarStep: a Benchmark for High-level Mathematical Reasoning},\nauthor={Wenda Li and Lei Yu and Yuhuai Wu and Lawrence C. Paulson},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=Pzj6fzU6wkj}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "Pzj6fzU6wkj", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper2324/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper2324/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper2324/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper2324/Authors|ICLR.cc/2021/Conference/Paper2324/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2324/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923849753, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper2324/-/Official_Comment"}}}, {"id": "4hgR9ERDOUt", "original": null, "number": 6, "cdate": 1605470269068, "ddate": null, "tcdate": 1605470269068, "tmdate": 1605470269068, "tddate": null, "forum": "Pzj6fzU6wkj", "replyto": "Rtp1tIz8K3N", "invitation": "ICLR.cc/2021/Conference/Paper2324/-/Official_Comment", "content": {"title": "Author response 2", "comment": "**What is F.2 and what is F.3**: In the example of the visualisation of attention, the source is F.2: F.3:$x_{70} \\in x_{39}$ F.4:$x_{57} \\subseteq x_{39}$, where F.2 is the set of used local propositions (which is empty here), F.3 is the goal we wish to derive (here it is $x_{70} \\in x_{39}$), and F.4 is the additional set of propositions we can use to derive F.3 (here it only contains $x_{57} \\subseteq x_{39}$). Therefore, the source can be interpreted as \u2018In conjunction with $x_{57} \\subseteq x_{39}$, what do we need to derive $x_{70} \\in x_{39}$?\u2019, and the target answer is $x_{70} \\in x_{57}$."}, "signatures": ["ICLR.cc/2021/Conference/Paper2324/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2324/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "IsarStep: a Benchmark for High-level Mathematical Reasoning", "authorids": ["~Wenda_Li1", "~Lei_Yu4", "~Yuhuai_Wu1", "lp15@cam.ac.uk"], "authors": ["Wenda Li", "Lei Yu", "Yuhuai Wu", "Lawrence C. Paulson"], "keywords": ["mathematical reasoning", "dataset", "benchmark", "reasoning", "transformer"], "abstract": "A well-defined benchmark is essential for measuring and accelerating research progress of machine learning models. In this paper, we present a benchmark for high-level mathematical reasoning and study the reasoning capabilities of neural sequence-to-sequence models. We build a non-synthetic dataset from the largest repository of proofs written by human experts in a theorem prover. The dataset has a broad coverage of undergraduate and research-level mathematical and computer science theorems. In our defined task, a model is required to fill in a missing intermediate proposition given surrounding proofs. This task provides a starting point for the long-term goal of having machines generate human-readable proofs automatically. Our experiments and analysis reveal that while the task is challenging, neural models can capture non-trivial mathematical reasoning. We further design a hierarchical transformer that outperforms the transformer baseline. ", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "li|isarstep_a_benchmark_for_highlevel_mathematical_reasoning", "one-sentence_summary": "We present a benchmark for high-level mathematical reasoning and study the reasoning capabilities of neural sequence-to-sequence models. ", "supplementary_material": "/attachment/c4ffbcc06fe39373cc0175e85faf7976f01086c8.zip", "pdf": "/pdf/c9fb7dd359102a00d8676684bd704c54961a5285.pdf", "venue": "ICLR 2021 Poster", "venueid": "ICLR.cc/2021/Conference", "_bibtex": "@inproceedings{\nli2021isarstep,\ntitle={IsarStep: a Benchmark for High-level Mathematical Reasoning},\nauthor={Wenda Li and Lei Yu and Yuhuai Wu and Lawrence C. Paulson},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=Pzj6fzU6wkj}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "Pzj6fzU6wkj", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper2324/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper2324/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper2324/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper2324/Authors|ICLR.cc/2021/Conference/Paper2324/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2324/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923849753, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper2324/-/Official_Comment"}}}, {"id": "i_s3Tlzy4kq", "original": null, "number": 5, "cdate": 1605470102108, "ddate": null, "tcdate": 1605470102108, "tmdate": 1605470102108, "tddate": null, "forum": "Pzj6fzU6wkj", "replyto": "Rtp1tIz8K3N", "invitation": "ICLR.cc/2021/Conference/Paper2324/-/Official_Comment", "content": {"title": "Author response 1", "comment": "Thank you for your thoughtful review.\n\n**Non-sequential proving**: We agree that both procedural/tactic and declarative proofs appear sequential in the surface form of complete proofs, i.e., a sequence of tactic applications in procedural proofs or intermediate propositions in declarative ones. However, we argue that devising those proofs is not really a sequential process. Even in tactic proofs, the users of proof assistants are constantly required to conjecture and prove auxiliary lemmas before proceeding with tactics. When developing declarative proofs, the process is usually more non-sequential. For example, starting with the initial state (e.g., to drive False given 2 is rational) we are likely to sketch/conjecture a few key intermediate propositions first (e.g., a b are coprime, a is even, and a is even) that potentially reduce the gap between \u20182 is rational\u2019 and \u2018False\u2019. We then attempt to close the derivation by invoking ATPs. If it fails, we elaborate the derivation with more intermediate steps so that the gap between consecutive ones becomes smaller. We conjecture that bridging large gaps (e.g., 2 is rational -> False) is harder than smaller ones (e.g., 2 b^2 = a^2 -> \\exists c. a = 2 c), so we start with building a relatively easy benchmark on small gaps -- IsarStep, which already appears challenging to existing models. \n\n**Example in Section 2**: Back to the example in Section 2, predicting (2) should not only condition on (1) but also a step along the follow-up derivation, otherwise (2) is merely a valid derivation from (1) without a clear goal. Among all the steps along the derivation including \u2018b is even\u2019 and the eventual goal \u2018False\u2019, we believe that the immediate next step (3) is the easiest condition (3) to solve the synthesis task successfully, hence we use it as a starting point for benchmarking proposition synthesis. \n\n**Towards sketching human-readable proofs**: We say that IsarStep is a step towards sketching human-readable proofs because\n1. The mined proofs are declarative proofs, a proof style very close to human prose proofs. The proofs are legible, even to people who are not familiar with the system, and they capture high-level structures like those in human proofs.  \n2. A prerequisite for generating a complete proof is the ability to generate a single step of a proof given sufficient conditions. We, therefore, start from such a simpler problem before we investigate whether it is possible for an agent to generate complete human-readable proofs. We provide sufficient condition for the single step of a proof by providing surrounding proofs and letting the agent fill in the gap of proofs. If agents have difficulty in solving our defined task, then it is impossible for them to generate complete proofs.\n\nIn particular for Reason 1, the declarative proofs are very different from the previous tactic synthesis frameworks, such as HOList, CoqGym, and TacticToe, where the agent attempts to select a tactic (from a predefined set whose size is usually less than 40) and some arguments (e.g., a pointer to a previously proved lemma) for each proof state. A synthesised tactic proof can be accepted by a proof assistant but is not legible and appears far different from the informal one (which in a sense is a sequence of intermediate propositions such as \u20182 b^2 = a^2\u2019 and \u2018a is even\u2019). \n\n**Hierarchical models**: We have added a paragraph relating hierarchical models in the related work section. We also include the discussion here. Hierarchical models have been proposed to solve natural language processing tasks such as document representation (Yang et al., 2016) and document summarisation (Zhang et al.,2019; Liu & Lapata, 2019). Both our hierarchical transformer (HAT) and those models share the similar spirit of introducing local layers to encode local sentences (or propositions) and global layers to capture cross sentence (or proposition) information. However, our HAT is different from their hierarchical models in the way of representing sentences (or propositions): while their models encode sentences into fixed-size vectors, the representation of a proposition in our model is a matrix of dynamic size. The model by Liu & Lapata (2019) has a more sophisticated architecture for capturing sentence representations compared to those by Yang et al. (2016) and Zhang et al. (2019), where they introduce multi-head pooling to encode sentences with different attention weights. Compared to Liu& Lapata (2019)\u2019s model, our model does not introduce additional parameters beyond the standard transformers. Another subtle difference between our model and the existing models is the way of doing positional encoding. Unlike documents where the order of sentences matters, propositions within each category of our IsarStep task do not require an order. Therefore, we do not encode the positional information of different propositions."}, "signatures": ["ICLR.cc/2021/Conference/Paper2324/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2324/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "IsarStep: a Benchmark for High-level Mathematical Reasoning", "authorids": ["~Wenda_Li1", "~Lei_Yu4", "~Yuhuai_Wu1", "lp15@cam.ac.uk"], "authors": ["Wenda Li", "Lei Yu", "Yuhuai Wu", "Lawrence C. Paulson"], "keywords": ["mathematical reasoning", "dataset", "benchmark", "reasoning", "transformer"], "abstract": "A well-defined benchmark is essential for measuring and accelerating research progress of machine learning models. In this paper, we present a benchmark for high-level mathematical reasoning and study the reasoning capabilities of neural sequence-to-sequence models. We build a non-synthetic dataset from the largest repository of proofs written by human experts in a theorem prover. The dataset has a broad coverage of undergraduate and research-level mathematical and computer science theorems. In our defined task, a model is required to fill in a missing intermediate proposition given surrounding proofs. This task provides a starting point for the long-term goal of having machines generate human-readable proofs automatically. Our experiments and analysis reveal that while the task is challenging, neural models can capture non-trivial mathematical reasoning. We further design a hierarchical transformer that outperforms the transformer baseline. ", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "li|isarstep_a_benchmark_for_highlevel_mathematical_reasoning", "one-sentence_summary": "We present a benchmark for high-level mathematical reasoning and study the reasoning capabilities of neural sequence-to-sequence models. ", "supplementary_material": "/attachment/c4ffbcc06fe39373cc0175e85faf7976f01086c8.zip", "pdf": "/pdf/c9fb7dd359102a00d8676684bd704c54961a5285.pdf", "venue": "ICLR 2021 Poster", "venueid": "ICLR.cc/2021/Conference", "_bibtex": "@inproceedings{\nli2021isarstep,\ntitle={IsarStep: a Benchmark for High-level Mathematical Reasoning},\nauthor={Wenda Li and Lei Yu and Yuhuai Wu and Lawrence C. Paulson},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=Pzj6fzU6wkj}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "Pzj6fzU6wkj", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper2324/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper2324/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper2324/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper2324/Authors|ICLR.cc/2021/Conference/Paper2324/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2324/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923849753, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper2324/-/Official_Comment"}}}, {"id": "xRQGdGXAMGi", "original": null, "number": 4, "cdate": 1605469760157, "ddate": null, "tcdate": 1605469760157, "tmdate": 1605469760157, "tddate": null, "forum": "Pzj6fzU6wkj", "replyto": "ywrsWrcbTVb", "invitation": "ICLR.cc/2021/Conference/Paper2324/-/Official_Comment", "content": {"title": "Author response ", "comment": "Thanks for liking the paper and thanks for your kind feedback.\n\nWe have run the convolutional seq2seq model [1] as another baseline model. Please refer to Table 3 in the revised version of the paper for additional results. Now we have results from the three major types of neural networks: the convolutional model, RNN, and the transformer. \n\nApplying pretrained models on the Isarstep dataset is an interesting idea. We have tried pretraining the MASS model on the propositions of our training data following the open source directory (https://github.com/microsoft/MASS/tree/master/MASS-summarization). Our initial experimental results on MASS so far aren't great. We got 4% accuracy on our test set -- there seems to be a bug somewhere. We are still investigating the problem. In the meantime, we found that some concurrent work has explored the idea of pretraining on theorem proving. For example, Polu & Sutskever [2] show that the GPT-3 language model additionally pretrained with mathematical equations mined from the web can generate propositions that enable theorem provers to prove more theorems automatically. Rabe et al. (2020) [3] pretrain masked language models on proofs mined from the HOList dataset and apply the pretrained models to the downstream tasks of type inference and predicting conjectures. We will leave the investigation of the effectiveness of different pretraining methods and different source of pretraining data for IsarStep for future work.\n\n[1] Jonas Gehring, Michael Auli, David Grangier, Denis Yarats, Yann N. Dauphin, Convolutional Sequence to Sequence Learning, ICML 2019.\n\n[2] Stanislas Polu, Ilya Sutskever, Generative Language Modeling for Automated Theorem Proving, arXiv, 2020.\n\n[3] Markus N Rabe, Dennis Lee, Kshitij Bansal, and Christian Szegedy.  Mathematical reasoning viaself-supervised skip-tree training.arXiv preprint arXiv:2006.04757, 2020.\n"}, "signatures": ["ICLR.cc/2021/Conference/Paper2324/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2324/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "IsarStep: a Benchmark for High-level Mathematical Reasoning", "authorids": ["~Wenda_Li1", "~Lei_Yu4", "~Yuhuai_Wu1", "lp15@cam.ac.uk"], "authors": ["Wenda Li", "Lei Yu", "Yuhuai Wu", "Lawrence C. Paulson"], "keywords": ["mathematical reasoning", "dataset", "benchmark", "reasoning", "transformer"], "abstract": "A well-defined benchmark is essential for measuring and accelerating research progress of machine learning models. In this paper, we present a benchmark for high-level mathematical reasoning and study the reasoning capabilities of neural sequence-to-sequence models. We build a non-synthetic dataset from the largest repository of proofs written by human experts in a theorem prover. The dataset has a broad coverage of undergraduate and research-level mathematical and computer science theorems. In our defined task, a model is required to fill in a missing intermediate proposition given surrounding proofs. This task provides a starting point for the long-term goal of having machines generate human-readable proofs automatically. Our experiments and analysis reveal that while the task is challenging, neural models can capture non-trivial mathematical reasoning. We further design a hierarchical transformer that outperforms the transformer baseline. ", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "li|isarstep_a_benchmark_for_highlevel_mathematical_reasoning", "one-sentence_summary": "We present a benchmark for high-level mathematical reasoning and study the reasoning capabilities of neural sequence-to-sequence models. ", "supplementary_material": "/attachment/c4ffbcc06fe39373cc0175e85faf7976f01086c8.zip", "pdf": "/pdf/c9fb7dd359102a00d8676684bd704c54961a5285.pdf", "venue": "ICLR 2021 Poster", "venueid": "ICLR.cc/2021/Conference", "_bibtex": "@inproceedings{\nli2021isarstep,\ntitle={IsarStep: a Benchmark for High-level Mathematical Reasoning},\nauthor={Wenda Li and Lei Yu and Yuhuai Wu and Lawrence C. Paulson},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=Pzj6fzU6wkj}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "Pzj6fzU6wkj", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper2324/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper2324/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper2324/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper2324/Authors|ICLR.cc/2021/Conference/Paper2324/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2324/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923849753, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper2324/-/Official_Comment"}}}, {"id": "GoVE8PJLT1", "original": null, "number": 3, "cdate": 1605469585972, "ddate": null, "tcdate": 1605469585972, "tmdate": 1605469678816, "tddate": null, "forum": "Pzj6fzU6wkj", "replyto": "Qj38VJ_-WNt", "invitation": "ICLR.cc/2021/Conference/Paper2324/-/Official_Comment", "content": {"title": "Author response", "comment": "Thank you for your thoughtful review. \n\n**Related Work**: We appreciate the pointer to the additional related papers, and have cited & discussed them in our related work section. However, we argue that although proposition synthesis (or conjecturing) has been investigated before, most of them are derived from templates in a rule-based fashion. And there are few datasets where the benchmarked models are required to synthesise propositions from scratch from a big vocabulary of 30K mathematical tokens. The most related one is [0], which was cited and compared within our paper. In contrast, we believe both [1] and [3]  focus on classification/ranking tasks. A notable feature of our dataset is that it is non-synthetic: each target proposition in our dataset is from a human input rather than a step in automatic theorem proving. We believe that intermediate steps extracted from proofs produced by saturation-style/connection-based automatic theorem provers such as those from [2] and [4] are unlikely to reflect human-like/human-level conjecturing, which is what we want to model and benchmark in IsarStep.\n\n**ATP evaluation**: We have defined diagnostic commands (i.e.,  \u2018check_derivation\u2019 and \u2018check_derivation_C\u2019 in EvaluationSuite/Isabelle2019_adapted/src/HOL/Sequence_Evaluation.thy), which take output sequences from neural models as arguments. These diagnostic commands will be inserted to appropriate positions of the corresponding Isabelle theory file, and this modified theory file will be built using Isabelle binaries. Upon building, the diagnostic command will attempt to parse the sequence to a valid Isabelle term F.1\u2019. If succeeded, the command will subsequently call Sledgehammer (with the default 30s timeout) to check the derivations like F.2 -> F.1\u2019\u2019 and F.1\u2019 -> F.3. More details can be found in the source code of our test suite, which is available from the submitted supplementary material.\n\n**Sqrt2 example**: We have added a pointer to Wiedijk\u2019s comparison [5] and the Mizar system, but the sqrt2 example in our paper was independently developed by us and was largely different from the one presented in Wiedijk\u2019s book.\n\n[0] Josef Urban and Jan Jakubuv. First neural conjecturing datasets and experiments. In Christoph Benzm\u00fcller and Bruce R. Miller (eds.), Intelligent Computer Mathematics, 2020.\n\n[1] Zarathustra Goertzel and Josef Urban: Usefulness of Lemmas via Graph Neural Networks. http://aitp-conference.org/2019/abstract/AITP_2019_paper_32.pdf\n\n[2] https://github.com/JUrban/E_conj\n\n[3] Learning to Advise an Equational Prover Chad E. Brown, Bartosz Piotrowski, and Josef Urban http://aitp-conference.org/2020/abstract/paper_32.pdf\n\n[4] Bartosz Piotrowski, Josef Urban: Guiding Inferences in Connection Tableau by Recurrent Neural Networks. CICM 2020: 309-314\n\n[5] Freek Wiedijk. The seventeen provers of the world. Springer, 2006.\n"}, "signatures": ["ICLR.cc/2021/Conference/Paper2324/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2324/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "IsarStep: a Benchmark for High-level Mathematical Reasoning", "authorids": ["~Wenda_Li1", "~Lei_Yu4", "~Yuhuai_Wu1", "lp15@cam.ac.uk"], "authors": ["Wenda Li", "Lei Yu", "Yuhuai Wu", "Lawrence C. Paulson"], "keywords": ["mathematical reasoning", "dataset", "benchmark", "reasoning", "transformer"], "abstract": "A well-defined benchmark is essential for measuring and accelerating research progress of machine learning models. In this paper, we present a benchmark for high-level mathematical reasoning and study the reasoning capabilities of neural sequence-to-sequence models. We build a non-synthetic dataset from the largest repository of proofs written by human experts in a theorem prover. The dataset has a broad coverage of undergraduate and research-level mathematical and computer science theorems. In our defined task, a model is required to fill in a missing intermediate proposition given surrounding proofs. This task provides a starting point for the long-term goal of having machines generate human-readable proofs automatically. Our experiments and analysis reveal that while the task is challenging, neural models can capture non-trivial mathematical reasoning. We further design a hierarchical transformer that outperforms the transformer baseline. ", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "li|isarstep_a_benchmark_for_highlevel_mathematical_reasoning", "one-sentence_summary": "We present a benchmark for high-level mathematical reasoning and study the reasoning capabilities of neural sequence-to-sequence models. ", "supplementary_material": "/attachment/c4ffbcc06fe39373cc0175e85faf7976f01086c8.zip", "pdf": "/pdf/c9fb7dd359102a00d8676684bd704c54961a5285.pdf", "venue": "ICLR 2021 Poster", "venueid": "ICLR.cc/2021/Conference", "_bibtex": "@inproceedings{\nli2021isarstep,\ntitle={IsarStep: a Benchmark for High-level Mathematical Reasoning},\nauthor={Wenda Li and Lei Yu and Yuhuai Wu and Lawrence C. Paulson},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=Pzj6fzU6wkj}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "Pzj6fzU6wkj", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper2324/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper2324/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper2324/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper2324/Authors|ICLR.cc/2021/Conference/Paper2324/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2324/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923849753, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper2324/-/Official_Comment"}}}, {"id": "bLc8eUJRrsI", "original": null, "number": 2, "cdate": 1605359757433, "ddate": null, "tcdate": 1605359757433, "tmdate": 1605359757433, "tddate": null, "forum": "Pzj6fzU6wkj", "replyto": "Qh8bG0hmhl_", "invitation": "ICLR.cc/2021/Conference/Paper2324/-/Official_Comment", "content": {"title": "Author response to the availability of dataset & automation", "comment": "Thank you for your thoughtful review. \n\nYou can find the dataset, model, and test suite in the supplementary materials. Please let us know if there\u2019s any trouble using them on your platform. We will replace the xxx in the paper with an actual Github link once the anonymous period is over.\n\nAs for the small increase in automation, there are two reasons for this. When the gap is small enough, Sledgehammer can automatically prove F.3 without being supplied with F.1. This happens in about one-third of the correct synthesises (i.e., those matching either the corresponding ground truth or one of the alternative valid propositions). For the majority of cases, the gaps in F.2 -> F.1 and F.1 -> F.3 are still too big for Sledgehammer to fill in, so the bottleneck is at the ATPs (even with correctly synthesised propositions). We believe further automation can be achieved if tactic-synthesis frameworks like HOList and TacticToe in HOL4 can be jointly incorporated with Sledgehammer to close the gaps between propositions. At the moment, we are re-running our test suite and will update the paper with more discussions on the automation issue.\n\nSince the paper is mainly focusing on providing a benchmark for synthesising propositions, we don\u2019t agree that the small improvement of automation is a weakness of the paper. We actually believe that it is a good finding showing that existing neural seq2seq models are not able to solve the problem yet and therefore it hopefully will encourage more work focusing on the improvement of automation.\n\nWe will address your other comments in the revised version of the paper."}, "signatures": ["ICLR.cc/2021/Conference/Paper2324/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2324/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "IsarStep: a Benchmark for High-level Mathematical Reasoning", "authorids": ["~Wenda_Li1", "~Lei_Yu4", "~Yuhuai_Wu1", "lp15@cam.ac.uk"], "authors": ["Wenda Li", "Lei Yu", "Yuhuai Wu", "Lawrence C. Paulson"], "keywords": ["mathematical reasoning", "dataset", "benchmark", "reasoning", "transformer"], "abstract": "A well-defined benchmark is essential for measuring and accelerating research progress of machine learning models. In this paper, we present a benchmark for high-level mathematical reasoning and study the reasoning capabilities of neural sequence-to-sequence models. We build a non-synthetic dataset from the largest repository of proofs written by human experts in a theorem prover. The dataset has a broad coverage of undergraduate and research-level mathematical and computer science theorems. In our defined task, a model is required to fill in a missing intermediate proposition given surrounding proofs. This task provides a starting point for the long-term goal of having machines generate human-readable proofs automatically. Our experiments and analysis reveal that while the task is challenging, neural models can capture non-trivial mathematical reasoning. We further design a hierarchical transformer that outperforms the transformer baseline. ", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "li|isarstep_a_benchmark_for_highlevel_mathematical_reasoning", "one-sentence_summary": "We present a benchmark for high-level mathematical reasoning and study the reasoning capabilities of neural sequence-to-sequence models. ", "supplementary_material": "/attachment/c4ffbcc06fe39373cc0175e85faf7976f01086c8.zip", "pdf": "/pdf/c9fb7dd359102a00d8676684bd704c54961a5285.pdf", "venue": "ICLR 2021 Poster", "venueid": "ICLR.cc/2021/Conference", "_bibtex": "@inproceedings{\nli2021isarstep,\ntitle={IsarStep: a Benchmark for High-level Mathematical Reasoning},\nauthor={Wenda Li and Lei Yu and Yuhuai Wu and Lawrence C. Paulson},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=Pzj6fzU6wkj}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "Pzj6fzU6wkj", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper2324/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper2324/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper2324/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper2324/Authors|ICLR.cc/2021/Conference/Paper2324/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2324/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923849753, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper2324/-/Official_Comment"}}}, {"id": "ywrsWrcbTVb", "original": null, "number": 3, "cdate": 1603805385178, "ddate": null, "tcdate": 1603805385178, "tmdate": 1605024238267, "tddate": null, "forum": "Pzj6fzU6wkj", "replyto": "Pzj6fzU6wkj", "invitation": "ICLR.cc/2021/Conference/Paper2324/-/Official_Review", "content": {"title": "Official Blind Review #3", "review": "##########################################################################\n\nSummary:\n\nThis paper proposes a benchmark for high-level mathematical reasoning and study the reasoning capabilities of neural sequence-to-sequence models. This is a non-synthetic dataset from the largest repository of proofs written by human experts in a theorem prover, which has a broad coverage of undergraduate and research-level mathematical and computer science theorems. Based on this dataset, the model need to fill in a missing intermediate proposition given surrounding proofs, named as IsarStep. It's a very interesting task. This task provides a starting point for the long-term goal of having machines generate human-readable proofs automatically. The experiments and analysis also reveal that neural models can capture non-trivial mathematical reasoning.\n\n\n##########################################################################\n\nReasons for score: \n\n \nOverall, I strongly vote for accepting. I think this is a very important work and this benchwork would benefit to other fresh ideas and new approaches for mathematical reasoning related research. My only concern is that as a benchmark, do authors need to conduct more experiments and baseline models on their data set to be more convincing?\n\n \n##########################################################################Pros: \n\nPros:\n\n+ 1. The paper mined a large corpus of formal proofs and defined a proposition generation task as a benchmark for testing machine learning models\u2019 mathematical reasoning capabilities. Such beckmark is important and beneficial to the development of the artificial intelligence community.\n\n \n+ 2. The proposed HAT model is novel for better capturing reasoning between source and target propositions. The design of two types of layers is reasonable and interesting. The local layers model the correlation between tokens within a proposition, and the global layers model the correlation between propositions.\n\n \n+ 3. This paper provides comprehensive experiments, including both qualitative analysis and quantitative results, to show the effectiveness of the proposed model. Experiments and analysis reveal that while the IsarStep task is challenging, neural models can capture non-trivial mathematical reasoning.\n\n\n+ 4. The paper is well-written and the design decisions are clearly explained. The comparison of benchmark methods is also interesting to read. In general, I think this is a worthy publication. \n\n \n##########################################################################\n\nCons: \n\nMy only concern is that as a benchmark, do authors need to conduct more experiments and baseline models on their data set to be more convincing? The authors only use two baseline models: RNNSearch and transformer, it seems to be insufficient. At Bert era, do those improved models based on Generative Learning tasks could also be applied to IsarStep as baseline, like MASS(Masked Sequence to Sequence Pre-training for Language Generation)/UNILM(Uni\ufb01ed Language Model Pre-training for Natural Language Understanding and Generation)?", "rating": "9: Top 15% of accepted papers, strong accept", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["ICLR.cc/2021/Conference/Paper2324/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2324/AnonReviewer3"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "IsarStep: a Benchmark for High-level Mathematical Reasoning", "authorids": ["~Wenda_Li1", "~Lei_Yu4", "~Yuhuai_Wu1", "lp15@cam.ac.uk"], "authors": ["Wenda Li", "Lei Yu", "Yuhuai Wu", "Lawrence C. Paulson"], "keywords": ["mathematical reasoning", "dataset", "benchmark", "reasoning", "transformer"], "abstract": "A well-defined benchmark is essential for measuring and accelerating research progress of machine learning models. In this paper, we present a benchmark for high-level mathematical reasoning and study the reasoning capabilities of neural sequence-to-sequence models. We build a non-synthetic dataset from the largest repository of proofs written by human experts in a theorem prover. The dataset has a broad coverage of undergraduate and research-level mathematical and computer science theorems. In our defined task, a model is required to fill in a missing intermediate proposition given surrounding proofs. This task provides a starting point for the long-term goal of having machines generate human-readable proofs automatically. Our experiments and analysis reveal that while the task is challenging, neural models can capture non-trivial mathematical reasoning. We further design a hierarchical transformer that outperforms the transformer baseline. ", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "li|isarstep_a_benchmark_for_highlevel_mathematical_reasoning", "one-sentence_summary": "We present a benchmark for high-level mathematical reasoning and study the reasoning capabilities of neural sequence-to-sequence models. ", "supplementary_material": "/attachment/c4ffbcc06fe39373cc0175e85faf7976f01086c8.zip", "pdf": "/pdf/c9fb7dd359102a00d8676684bd704c54961a5285.pdf", "venue": "ICLR 2021 Poster", "venueid": "ICLR.cc/2021/Conference", "_bibtex": "@inproceedings{\nli2021isarstep,\ntitle={IsarStep: a Benchmark for High-level Mathematical Reasoning},\nauthor={Wenda Li and Lei Yu and Yuhuai Wu and Lawrence C. Paulson},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=Pzj6fzU6wkj}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq . ***Please remember to file the Code-of-Ethics report. Once you submitted the review, a link to the report will be visible in the bottom right corner of your review.***", "required": true, "markdown": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}, "forum": "Pzj6fzU6wkj", "replyto": "Pzj6fzU6wkj", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"], "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper2324/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1607428800000, "duedate": 1606752000000, "multiReply": false, "readers": ["everyone"], "tcdate": 1602538099020, "tmdate": 1606915779603, "super": "ICLR.cc/2021/Conference/-/Official_Review", "signatures": ["OpenReview.net"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Paper2324/Reviewers", "OpenReview.net/Support"], "id": "ICLR.cc/2021/Conference/Paper2324/-/Official_Review"}}}], "count": 17}