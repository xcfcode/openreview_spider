{"notes": [{"tddate": null, "replyto": null, "ddate": null, "tmdate": 1528124292827, "tcdate": 1518472656157, "number": 334, "cdate": 1518472656157, "id": "HJ_CpYyDz", "invitation": "ICLR.cc/2018/Workshop/-/Submission", "forum": "HJ_CpYyDz", "signatures": ["~Chen_Ma1"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Workshop"], "content": {"title": "Universal Successor Representations for Transfer Reinforcement Learning", "abstract": "The objective of transfer reinforcement learning is to generalize from a set of previous tasks to unseen new tasks. In this work, we focus on the transfer scenario where the dynamics among tasks are the same, but their goals differ. Although general value function (Sutton et al., 2011) has been shown to be useful for knowledge transfer, learning a universal value function can be challenging in practice. To attack this, we propose (1) to use universal successor representations (USR) to represent the transferable knowledge and (2) a USR approximator (USRA) that can be trained by interacting with the environment. Our experiments show that USR can be effectively applied to new tasks, and the agent initialized by the trained USRA can achieve the goal considerably faster than random initialization.", "paperhash": "ma|universal_successor_representations_for_transfer_reinforcement_learning", "_bibtex": "@misc{\n  ma2018universal,\n  title={Universal Successor Representations for Transfer Reinforcement Learning},\n  author={Chen Ma and Junfeng Wen and Yoshua Bengio},\n  year={2018},\n  url={https://openreview.net/forum?id=HJ_CpYyDz}\n}", "authorids": ["chenchloem@gmail.com", "junfengwen@gmail.com", "yoshua.umontreal@gmail.com"], "authors": ["Chen Ma", "Junfeng Wen", "Yoshua Bengio"], "keywords": ["Reinforcement Learning", "Transfer Learning", "Deep Learning", "Successor Representations"], "pdf": "/pdf/c1de94d4832962b65a4444ee1f4c8b648a241e00.pdf"}, "nonreaders": [], "details": {"replyCount": 4, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1518472800000, "tmdate": 1518474081690, "id": "ICLR.cc/2018/Workshop/-/Submission", "writers": ["ICLR.cc/2018/Workshop"], "signatures": ["ICLR.cc/2018/Workshop"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": null, "replyto": null, "writers": {"values": ["ICLR.cc/2018/Workshop"]}, "signatures": {"values-regex": "~.*|ICLR.cc/2018/Workshop", "description": "Your authorized identity to be associated with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"pdf": {"required": true, "order": 9, "value-regex": "upload", "description": "Upload a PDF file that ends with .pdf"}, "title": {"required": true, "order": 1, "description": "Title of paper.", "value-regex": ".{1,250}"}, "abstract": {"required": true, "order": 8, "description": "Abstract of paper.", "value-regex": "[\\S\\s]{1,5000}"}, "authors": {"required": true, "order": 2, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of author names. Please provide real names; identities will be anonymized."}, "keywords": {"order": 6, "values-regex": "(^$)|[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of keywords."}, "TL;DR": {"required": false, "order": 7, "description": "\"Too Long; Didn't Read\": a short sentence describing your paper", "value-regex": "[^\\n]{0,500}"}, "authorids": {"required": true, "order": 3, "values-regex": "([a-z0-9_\\-\\.]{2,}@[a-z0-9_\\-\\.]{2,}\\.[a-z]{2,},){0,}([a-z0-9_\\-\\.]{2,}@[a-z0-9_\\-\\.]{2,}\\.[a-z]{2,})", "description": "Comma separated list of author email addresses, lowercased, in the same order as above. For authors with existing OpenReview accounts, please make sure that the provided email address(es) match those listed in the author's profile. Please provide real emails; identities will be anonymized."}}}, "nonreaders": [], "noninvitees": [], "expdate": 1526248800000, "cdate": 1518474081690}}}, {"tddate": null, "ddate": null, "original": null, "tmdate": 1521582989258, "tcdate": 1519581539438, "number": 1, "cdate": 1519581539438, "id": "HJiDt_guM", "invitation": "ICLR.cc/2018/Workshop/-/Paper334/Official_Review", "forum": "HJ_CpYyDz", "replyto": "HJ_CpYyDz", "signatures": ["ICLR.cc/2018/Workshop/Paper334/AnonReviewer2"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Workshop/Paper334/AnonReviewer2"], "content": {"title": "Good starting point", "rating": "6: Marginally above acceptance threshold", "review": "- A brief summary of the paper's contributions, in the context of prior work.\nThe paper studies how a policy can generalize between different goals in a maze, keeping the dynamics the same. Besides the standard actor-critic approach, the authors also learn a linear model for the reward, for a given goal. This approach is evaluated in a maze environment. Authors measure generalization by evaluating the distance between 1) trained policy + unseen goal 2) policy trained on that same goal. \n\n- An assessment of novelty, clarity, significance, and quality.\nThe paper presents preliminary results, that welcome 1) more experiments + baseline comparisons in more challenging environments 2) analysis of what similarity between tasks the reward features are capturing and 3) more precise quantification of the minimal number of tasks to generalize well.\n\n- A list of pros and cons (reasons to accept/reject).\npro: good direction \ncon: \n- no analysis / visualization of task features\n- no baselines (meta-learning approaches, hierarchical approaches)\n", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Universal Successor Representations for Transfer Reinforcement Learning", "abstract": "The objective of transfer reinforcement learning is to generalize from a set of previous tasks to unseen new tasks. In this work, we focus on the transfer scenario where the dynamics among tasks are the same, but their goals differ. Although general value function (Sutton et al., 2011) has been shown to be useful for knowledge transfer, learning a universal value function can be challenging in practice. To attack this, we propose (1) to use universal successor representations (USR) to represent the transferable knowledge and (2) a USR approximator (USRA) that can be trained by interacting with the environment. Our experiments show that USR can be effectively applied to new tasks, and the agent initialized by the trained USRA can achieve the goal considerably faster than random initialization.", "paperhash": "ma|universal_successor_representations_for_transfer_reinforcement_learning", "_bibtex": "@misc{\n  ma2018universal,\n  title={Universal Successor Representations for Transfer Reinforcement Learning},\n  author={Chen Ma and Junfeng Wen and Yoshua Bengio},\n  year={2018},\n  url={https://openreview.net/forum?id=HJ_CpYyDz}\n}", "authorids": ["chenchloem@gmail.com", "junfengwen@gmail.com", "yoshua.umontreal@gmail.com"], "authors": ["Chen Ma", "Junfeng Wen", "Yoshua Bengio"], "keywords": ["Reinforcement Learning", "Transfer Learning", "Deep Learning", "Successor Representations"], "pdf": "/pdf/c1de94d4832962b65a4444ee1f4c8b648a241e00.pdf"}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1520657999000, "tmdate": 1521582989070, "id": "ICLR.cc/2018/Workshop/-/Paper334/Official_Review", "writers": ["ICLR.cc/2018/Workshop"], "signatures": ["ICLR.cc/2018/Workshop"], "readers": ["everyone"], "invitees": ["ICLR.cc/2018/Workshop/Paper334/Reviewers"], "noninvitees": ["ICLR.cc/2018/Workshop/Paper334/AnonReviewer2", "ICLR.cc/2018/Workshop/Paper334/AnonReviewer1", "ICLR.cc/2018/Workshop/Paper334/AnonReviewer3"], "reply": {"forum": "HJ_CpYyDz", "replyto": "HJ_CpYyDz", "writers": {"values-regex": "ICLR.cc/2018/Workshop/Paper334/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2018/Workshop/Paper334/AnonReviewer[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"required": true, "order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"required": true, "order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "value-regex": "[\\S\\s]{1,200000}"}, "rating": {"required": true, "order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"required": true, "order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1528433999000, "cdate": 1521582989070}}}, {"tddate": null, "ddate": null, "original": null, "tmdate": 1521582910124, "tcdate": 1520441069163, "number": 2, "cdate": 1520441069163, "id": "HyHlDcT_z", "invitation": "ICLR.cc/2018/Workshop/-/Paper334/Official_Review", "forum": "HJ_CpYyDz", "replyto": "HJ_CpYyDz", "signatures": ["ICLR.cc/2018/Workshop/Paper334/AnonReviewer1"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Workshop/Paper334/AnonReviewer1"], "content": {"title": "A nice idea for transfer learning in reinforcement learning domains with universal successor representations, however it fails to distinguish/compare existing work on transfer learning with success features.", "rating": "5: Marginally below acceptance threshold", "review": "Pros: 1) a very principled a framework for transfer reinforcement learning. \n2) showing promising results\nCons:  1) there is a restriction here that the dynamics among tasks are the same and only goal location changes. It is unclear what is the motivation for such an assumption.\n2)  lacking comparison to existing very related work.  The idea in this paper is very close to the following paper\nBarreto et al. Successor Features for Transfer in Reinforcement Learning, NIPS 17\nIt might better if a comparison and more discussions regarding the differences between the proposed method and the above reference are provided.\n", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Universal Successor Representations for Transfer Reinforcement Learning", "abstract": "The objective of transfer reinforcement learning is to generalize from a set of previous tasks to unseen new tasks. In this work, we focus on the transfer scenario where the dynamics among tasks are the same, but their goals differ. Although general value function (Sutton et al., 2011) has been shown to be useful for knowledge transfer, learning a universal value function can be challenging in practice. To attack this, we propose (1) to use universal successor representations (USR) to represent the transferable knowledge and (2) a USR approximator (USRA) that can be trained by interacting with the environment. Our experiments show that USR can be effectively applied to new tasks, and the agent initialized by the trained USRA can achieve the goal considerably faster than random initialization.", "paperhash": "ma|universal_successor_representations_for_transfer_reinforcement_learning", "_bibtex": "@misc{\n  ma2018universal,\n  title={Universal Successor Representations for Transfer Reinforcement Learning},\n  author={Chen Ma and Junfeng Wen and Yoshua Bengio},\n  year={2018},\n  url={https://openreview.net/forum?id=HJ_CpYyDz}\n}", "authorids": ["chenchloem@gmail.com", "junfengwen@gmail.com", "yoshua.umontreal@gmail.com"], "authors": ["Chen Ma", "Junfeng Wen", "Yoshua Bengio"], "keywords": ["Reinforcement Learning", "Transfer Learning", "Deep Learning", "Successor Representations"], "pdf": "/pdf/c1de94d4832962b65a4444ee1f4c8b648a241e00.pdf"}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1520657999000, "tmdate": 1521582989070, "id": "ICLR.cc/2018/Workshop/-/Paper334/Official_Review", "writers": ["ICLR.cc/2018/Workshop"], "signatures": ["ICLR.cc/2018/Workshop"], "readers": ["everyone"], "invitees": ["ICLR.cc/2018/Workshop/Paper334/Reviewers"], "noninvitees": ["ICLR.cc/2018/Workshop/Paper334/AnonReviewer2", "ICLR.cc/2018/Workshop/Paper334/AnonReviewer1", "ICLR.cc/2018/Workshop/Paper334/AnonReviewer3"], "reply": {"forum": "HJ_CpYyDz", "replyto": "HJ_CpYyDz", "writers": {"values-regex": "ICLR.cc/2018/Workshop/Paper334/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2018/Workshop/Paper334/AnonReviewer[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"required": true, "order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"required": true, "order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "value-regex": "[\\S\\s]{1,200000}"}, "rating": {"required": true, "order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"required": true, "order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1528433999000, "cdate": 1521582989070}}}, {"tddate": null, "ddate": null, "original": null, "tmdate": 1521582699361, "tcdate": 1520709497575, "number": 3, "cdate": 1520709497575, "id": "ByMKyhWKf", "invitation": "ICLR.cc/2018/Workshop/-/Paper334/Official_Review", "forum": "HJ_CpYyDz", "replyto": "HJ_CpYyDz", "signatures": ["ICLR.cc/2018/Workshop/Paper334/AnonReviewer3"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Workshop/Paper334/AnonReviewer3"], "content": {"title": "Accept", "rating": "9: Top 15% of accepted papers, strong accept", "review": "- The key idea is to factor the state-action or value function into expected discounted features and reward. This factorization has been explored in the past as the authors note but they generalize it for many goals. So in effect this is a very sound integration of two basic ideas -- successor representations and generalized value functions (GVFs or UVFAs). So USRs generalize SRs using GVFs/UVFAs. This is an important direction to explore and I encourage the authors to follow through with this work\n\n- It would help to show visualizations of the goal space on the grid to get an intuition of the generalization\n\n- It would also be interesting to see how few of source goals does it need to generalize on unseen goals", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Universal Successor Representations for Transfer Reinforcement Learning", "abstract": "The objective of transfer reinforcement learning is to generalize from a set of previous tasks to unseen new tasks. In this work, we focus on the transfer scenario where the dynamics among tasks are the same, but their goals differ. Although general value function (Sutton et al., 2011) has been shown to be useful for knowledge transfer, learning a universal value function can be challenging in practice. To attack this, we propose (1) to use universal successor representations (USR) to represent the transferable knowledge and (2) a USR approximator (USRA) that can be trained by interacting with the environment. Our experiments show that USR can be effectively applied to new tasks, and the agent initialized by the trained USRA can achieve the goal considerably faster than random initialization.", "paperhash": "ma|universal_successor_representations_for_transfer_reinforcement_learning", "_bibtex": "@misc{\n  ma2018universal,\n  title={Universal Successor Representations for Transfer Reinforcement Learning},\n  author={Chen Ma and Junfeng Wen and Yoshua Bengio},\n  year={2018},\n  url={https://openreview.net/forum?id=HJ_CpYyDz}\n}", "authorids": ["chenchloem@gmail.com", "junfengwen@gmail.com", "yoshua.umontreal@gmail.com"], "authors": ["Chen Ma", "Junfeng Wen", "Yoshua Bengio"], "keywords": ["Reinforcement Learning", "Transfer Learning", "Deep Learning", "Successor Representations"], "pdf": "/pdf/c1de94d4832962b65a4444ee1f4c8b648a241e00.pdf"}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1520657999000, "tmdate": 1521582989070, "id": "ICLR.cc/2018/Workshop/-/Paper334/Official_Review", "writers": ["ICLR.cc/2018/Workshop"], "signatures": ["ICLR.cc/2018/Workshop"], "readers": ["everyone"], "invitees": ["ICLR.cc/2018/Workshop/Paper334/Reviewers"], "noninvitees": ["ICLR.cc/2018/Workshop/Paper334/AnonReviewer2", "ICLR.cc/2018/Workshop/Paper334/AnonReviewer1", "ICLR.cc/2018/Workshop/Paper334/AnonReviewer3"], "reply": {"forum": "HJ_CpYyDz", "replyto": "HJ_CpYyDz", "writers": {"values-regex": "ICLR.cc/2018/Workshop/Paper334/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2018/Workshop/Paper334/AnonReviewer[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"required": true, "order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"required": true, "order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "value-regex": "[\\S\\s]{1,200000}"}, "rating": {"required": true, "order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"required": true, "order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1528433999000, "cdate": 1521582989070}}}, {"tddate": null, "ddate": null, "original": null, "tmdate": 1521573563025, "tcdate": 1521573563025, "number": 88, "cdate": 1521573562684, "id": "Bk7pA0Atf", "invitation": "ICLR.cc/2018/Workshop/-/Acceptance_Decision", "forum": "HJ_CpYyDz", "replyto": "HJ_CpYyDz", "signatures": ["ICLR.cc/2018/Workshop/Program_Chairs"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Workshop/Program_Chairs"], "content": {"decision": "Accept", "title": "ICLR 2018 Workshop Acceptance Decision", "comment": "Congratulations, your paper was accepted to the ICLR workshop."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Universal Successor Representations for Transfer Reinforcement Learning", "abstract": "The objective of transfer reinforcement learning is to generalize from a set of previous tasks to unseen new tasks. In this work, we focus on the transfer scenario where the dynamics among tasks are the same, but their goals differ. Although general value function (Sutton et al., 2011) has been shown to be useful for knowledge transfer, learning a universal value function can be challenging in practice. To attack this, we propose (1) to use universal successor representations (USR) to represent the transferable knowledge and (2) a USR approximator (USRA) that can be trained by interacting with the environment. Our experiments show that USR can be effectively applied to new tasks, and the agent initialized by the trained USRA can achieve the goal considerably faster than random initialization.", "paperhash": "ma|universal_successor_representations_for_transfer_reinforcement_learning", "_bibtex": "@misc{\n  ma2018universal,\n  title={Universal Successor Representations for Transfer Reinforcement Learning},\n  author={Chen Ma and Junfeng Wen and Yoshua Bengio},\n  year={2018},\n  url={https://openreview.net/forum?id=HJ_CpYyDz}\n}", "authorids": ["chenchloem@gmail.com", "junfengwen@gmail.com", "yoshua.umontreal@gmail.com"], "authors": ["Chen Ma", "Junfeng Wen", "Yoshua Bengio"], "keywords": ["Reinforcement Learning", "Transfer Learning", "Deep Learning", "Successor Representations"], "pdf": "/pdf/c1de94d4832962b65a4444ee1f4c8b648a241e00.pdf"}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "tmdate": 1518629844880, "id": "ICLR.cc/2018/Workshop/-/Acceptance_Decision", "writers": ["ICLR.cc/2018/Workshop"], "signatures": ["ICLR.cc/2018/Workshop"], "readers": ["everyone"], "invitees": ["ICLR.cc/2018/Workshop/Program_Chairs"], "reply": {"forum": null, "replyto": null, "invitation": "ICLR.cc/2018/Workshop/-/Submission", "writers": {"values": ["ICLR.cc/2018/Workshop/Program_Chairs"]}, "signatures": {"description": "How your identity will be displayed with the above content.", "values": ["ICLR.cc/2018/Workshop/Program_Chairs"]}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["ICLR.cc/2018/Workshop/Program_Chairs", "everyone"]}, "content": {"title": {"required": true, "order": 1, "value": "ICLR 2018 Workshop Acceptance Decision"}, "comment": {"required": false, "order": 3, "description": "(optional) Comment on this decision.", "value-regex": "[\\S\\s]{0,5000}"}, "decision": {"required": true, "order": 2, "value-dropdown": ["Accept", "Reject"]}}}, "nonreaders": [], "noninvitees": [], "cdate": 1518629844880}}}], "count": 5}