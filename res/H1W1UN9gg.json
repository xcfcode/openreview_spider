{"notes": [{"tddate": null, "replyto": null, "ddate": null, "tmdate": 1488579126707, "tcdate": 1478276569300, "number": 215, "id": "H1W1UN9gg", "invitation": "ICLR.cc/2017/conference/-/submission", "forum": "H1W1UN9gg", "signatures": ["~Samuel_Stern_Schoenholz1"], "readers": ["everyone"], "content": {"title": "Deep Information Propagation", "abstract": "We study the behavior of untrained neural networks whose weights and biases are randomly distributed using mean field theory. We show the existence of depth scales that naturally limit the maximum depth of signal propagation through these random networks. Our main practical result is to show that random networks may be trained precisely when information can travel through them. Thus, the depth scales that we identify provide bounds on how deep a network may be trained for a specific choice of hyperparameters. As a corollary to this, we argue that in networks at the edge of chaos, one of these depth scales diverges. Thus arbitrarily deep networks may be trained only sufficiently close to criticality. We show that the presence of dropout destroys the order-to-chaos critical point and therefore strongly limits the maximum trainable depth for random networks. Finally, we develop a mean field theory for backpropagation and we show that the ordered and chaotic phases correspond to regions of vanishing and exploding gradient respectively.", "pdf": "/pdf/49b3f245e912ffb5845d079da65751b3e4fe4ad1.pdf", "TL;DR": "We predict whether randomly initialized neural networks can be trained by studying whether or not information can travel through them.", "paperhash": "schoenholz|deep_information_propagation", "keywords": ["Theory", "Deep learning"], "conflicts": ["google.com", "stanford.edu"], "authors": ["Samuel S. Schoenholz", "Justin Gilmer", "Surya Ganguli", "Jascha Sohl-Dickstein"], "authorids": ["schsam@google.com", "gilmer@google.com", "sganguli@stanford.edu", "jaschasd@google.com"]}, "writers": [], "nonreaders": [], "details": {"replyCount": 8, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1475686800000, "tmdate": 1478287705855, "id": "ICLR.cc/2017/conference/-/submission", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/pcs"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": null, "replyto": null, "writers": {"values-regex": "~.*"}, "signatures": {"values-regex": "~.*", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"pdf": {"required": true, "order": 5, "description": "Either upload a PDF file or provide a direct link to your PDF on ArXiv (link must begin with http(s) and end with .pdf)", "value-regex": "upload|(http|https):\\/\\/.+\\.pdf"}, "title": {"required": true, "order": 1, "description": "Title of paper.", "value-regex": ".{1,250}"}, "abstract": {"required": true, "order": 4, "description": "Abstract of paper.", "value-regex": "[\\S\\s]{1,5000}"}, "authors": {"required": true, "order": 2, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of author names, as they appear in the paper."}, "conflicts": {"required": true, "order": 100, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of email domains of people who would have a conflict of interest in reviewing this paper, (e.g., cs.umass.edu;google.com, etc.)."}, "keywords": {"order": 6, "description": "Comma separated list of keywords.", "values-dropdown": ["Theory", "Computer vision", "Speech", "Natural language processing", "Deep learning", "Unsupervised Learning", "Supervised Learning", "Semi-Supervised Learning", "Reinforcement Learning", "Transfer Learning", "Multi-modal learning", "Applications", "Optimization", "Structured prediction", "Games"]}, "TL;DR": {"required": false, "order": 3, "description": "\"Too Long; Didn't Read\": a short sentence describing your paper", "value-regex": "[^\\n]{0,250}"}, "authorids": {"required": true, "order": 3, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of author email addresses, in the same order as above."}}}, "nonreaders": [], "noninvitees": [], "expdate": 1483462800000, "cdate": 1478287705855}}}, {"tddate": null, "ddate": null, "cdate": null, "tmdate": 1486396437928, "tcdate": 1486396437928, "number": 1, "id": "rJ0zhfLug", "invitation": "ICLR.cc/2017/conference/-/paper215/acceptance", "forum": "H1W1UN9gg", "replyto": "H1W1UN9gg", "signatures": ["ICLR.cc/2017/pcs"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/pcs"], "content": {"title": "ICLR committee final decision", "comment": "This is one of the two top papers in my stack. In total the reviews are a little bit on the light side in terms of level of detail and there are some concerns regarding how useful the results are from a practical point of view. However, I am confident that the paper should be accepted. ", "decision": "Accept (Poster)"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Deep Information Propagation", "abstract": "We study the behavior of untrained neural networks whose weights and biases are randomly distributed using mean field theory. We show the existence of depth scales that naturally limit the maximum depth of signal propagation through these random networks. Our main practical result is to show that random networks may be trained precisely when information can travel through them. Thus, the depth scales that we identify provide bounds on how deep a network may be trained for a specific choice of hyperparameters. As a corollary to this, we argue that in networks at the edge of chaos, one of these depth scales diverges. Thus arbitrarily deep networks may be trained only sufficiently close to criticality. We show that the presence of dropout destroys the order-to-chaos critical point and therefore strongly limits the maximum trainable depth for random networks. Finally, we develop a mean field theory for backpropagation and we show that the ordered and chaotic phases correspond to regions of vanishing and exploding gradient respectively.", "pdf": "/pdf/49b3f245e912ffb5845d079da65751b3e4fe4ad1.pdf", "TL;DR": "We predict whether randomly initialized neural networks can be trained by studying whether or not information can travel through them.", "paperhash": "schoenholz|deep_information_propagation", "keywords": ["Theory", "Deep learning"], "conflicts": ["google.com", "stanford.edu"], "authors": ["Samuel S. Schoenholz", "Justin Gilmer", "Surya Ganguli", "Jascha Sohl-Dickstein"], "authorids": ["schsam@google.com", "gilmer@google.com", "sganguli@stanford.edu", "jaschasd@google.com"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1486396438432, "id": "ICLR.cc/2017/conference/-/paper215/acceptance", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/pcs"], "noninvitees": ["ICLR.cc/2017/pcs"], "reply": {"forum": "H1W1UN9gg", "replyto": "H1W1UN9gg", "writers": {"values-regex": "ICLR.cc/2017/pcs"}, "signatures": {"values-regex": "ICLR.cc/2017/pcs", "description": "Your displayed identity associated with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your decision.", "value": "ICLR committee final decision"}, "comment": {"required": true, "order": 2, "description": "Decision comments.", "value-regex": "[\\S\\s]{1,5000}"}, "decision": {"required": true, "order": 3, "value-radio": ["Accept (Oral)", "Accept (Poster)", "Reject", "Invite to Workshop Track"]}}}, "nonreaders": [], "cdate": 1486396438432}}}, {"tddate": null, "tmdate": 1484361288263, "tcdate": 1484361288263, "number": 3, "id": "B1e8CWvUl", "invitation": "ICLR.cc/2017/conference/-/paper215/public/comment", "forum": "H1W1UN9gg", "replyto": "rJGLovrHx", "signatures": ["~Samuel_Stern_Schoenholz1"], "readers": ["everyone"], "writers": ["~Samuel_Stern_Schoenholz1"], "content": {"title": "Response", "comment": "Thanks for your comment. During evaluation of both the test / training accuracy dropout is indeed turned off."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Deep Information Propagation", "abstract": "We study the behavior of untrained neural networks whose weights and biases are randomly distributed using mean field theory. We show the existence of depth scales that naturally limit the maximum depth of signal propagation through these random networks. Our main practical result is to show that random networks may be trained precisely when information can travel through them. Thus, the depth scales that we identify provide bounds on how deep a network may be trained for a specific choice of hyperparameters. As a corollary to this, we argue that in networks at the edge of chaos, one of these depth scales diverges. Thus arbitrarily deep networks may be trained only sufficiently close to criticality. We show that the presence of dropout destroys the order-to-chaos critical point and therefore strongly limits the maximum trainable depth for random networks. Finally, we develop a mean field theory for backpropagation and we show that the ordered and chaotic phases correspond to regions of vanishing and exploding gradient respectively.", "pdf": "/pdf/49b3f245e912ffb5845d079da65751b3e4fe4ad1.pdf", "TL;DR": "We predict whether randomly initialized neural networks can be trained by studying whether or not information can travel through them.", "paperhash": "schoenholz|deep_information_propagation", "keywords": ["Theory", "Deep learning"], "conflicts": ["google.com", "stanford.edu"], "authors": ["Samuel S. Schoenholz", "Justin Gilmer", "Surya Ganguli", "Jascha Sohl-Dickstein"], "authorids": ["schsam@google.com", "gilmer@google.com", "sganguli@stanford.edu", "jaschasd@google.com"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287681630, "id": "ICLR.cc/2017/conference/-/paper215/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "H1W1UN9gg", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper215/reviewers", "ICLR.cc/2017/conference/paper215/areachairs"], "cdate": 1485287681630}}}, {"tddate": null, "tmdate": 1484361185661, "tcdate": 1484361185661, "number": 2, "id": "BJcyCWwLl", "invitation": "ICLR.cc/2017/conference/-/paper215/public/comment", "forum": "H1W1UN9gg", "replyto": "H1gjgmjEx", "signatures": ["~Samuel_Stern_Schoenholz1"], "readers": ["everyone"], "writers": ["~Samuel_Stern_Schoenholz1"], "content": {"title": "Response", "comment": "Thank you for your thoughtful comments! They have prompted us to clarify several points in the paper. \n\n>> Minor point on presentation: Speaking of the \"evolution\" of x_{i;a} as it travels through the network could give some readers helpful intuition, but for me it was confusing because x_{*;a} is the immutable input vector, and it's the just-introduced z and y variables that represent its so-called evolution, no?\n\nThis is an interesting point. You are correct that in some sense the x_{i;a} is more of an initial condition for the dynamics which evolve through the z and y variables. Nonetheless, we do feel that describing the \"evolution\" of x_{i;a} with slightly looser language might be useful to some. We have added a small clarifying remark in the paper to this point.\n\n>> In interpreting this analysis - A network may be trainable if information does not pass through it, if the training steps, by whatever reason, perturb the weights so that information starts to pass through it (without subsequently perturbing the weights to stop information from passing through it.) Perhaps this could be clarified by a definition of \u201ctraining algorithm\u201d?\n\nIt is true that the weights of a network could be perturbed from an initialization in which no information could flow through it to one close enough to criticality such that information could once again travel through the network. Such a procedure would by construction be dataset / label independent. We therefore feel that this would amount to pre-training, as opposed to training, the neural network.\n\nHaving said this, we feel that exploring pre-training schemes on the basis of information flow and criticality would be very interesting to pursue and we have added a short discussion to that effect to our manuscript.\n\n>>Comments on central claims:\n>>Previous work on initializing neural networks to promote information flow (e.g. Glorot & Bengio, http://jmlr.org/proceedings/papers/v9/glorot10a/glorot10a.pdf) concluded (1) that the number of units in the next layer and the previous layer should both figure into the variance of the elements of the weight matrices, and (2) that they should be drawn from a Uniform distribution rather than a Gaussian. Could the authors comment on the merit of that initialization strategy in light of this analysis?\n\nThank you for pointing out this interesting paper by Glorot & Bengio. We have added a short discussion of their work to our paper. To respond to your specific points: \n\n(1) They find that the number of units in the next layer and previous layer are relevant for gradient backpropagation (as opposed to signal forward propagation.) This is true for us as well (see eq. 15). Indeed when we discuss vanishing/exploding gradients we restrict our attention to networks of constant width for this reason. A more thorough discussion of non-constant width networks would be interesting. \n\n(2) The crux of the mean field approximation rests with the use of the central limit theorem to approximate the pre-activations as a gaussian. So long as the weights are i.i.d. the specific distribution of the weights will not affect our results (note that this is not the case for the bias distribution.) Thus, we expect our results to hold for uniformly distributed weights.  \n\nOne caveat is that our results hold only for nonzero bias variance (which is not what is done in Glorot & Bengio). The phase diagram when the bias variance is zero is slightly different as is the accompanying analysis.\n\n>>Comments on evaluation:\n>>Why does the dashed line in the result figures correspond to twice the depth scale instead of just the depth scale? What is the significance of 14000 steps of SGD on MNIST? Does it represent convergence of SGD? Why are all the best SGD models well above the depth scale? Why is there a little dark area precisely under the peak in Figure 5(a) and (c)? That\u2019s interesting - initializations that propagate error best seem untrainable at the depths traditionally used - but only with SGD not RMSProp?\n\nThe bright red region above the depth scale and the dark area below the peak were a result of plotting inconsistencies. First, the small dark area referenced in fig 5 (a) and (c) was a missing datapoint. Second, the red region was due to a poor choice of binning and is not statistically significant. Thank you for being so diligent. We have updated the figure to include this missing point and round our training accuracy.\n\nRelated to this point, one might notice that at large depths right at criticality our previous results made it seem as though networks were untrainable. This was due to a confluence of two effects: first, the grid spacing we used in generating fig 5 was too large when the depth of the networks became large and second, the learning rate must be lowered as the depth increases (as was noted in the paper by Saxe et al. (2014)). We therefore reran the networks for figure 5 using a smaller grid spacing and lower learning rate near criticality. We have updated the corresponding figures.\n\nYour question on our choices for the experiments is a good one. When $L = n\\xi_c$ for some integer n, our results show that the signal passing through the network is attenuated by a factor of $e^n$. Therefore, it is likely (and obviously true) that networks can be trained when they are deeper than $\\xi_c$. The exact pre-factor of $\\xi_c$ is not so important as the overall form of $\\xi_c$. We have included a short discussion of this fact. We have also added to fig. 5(a) different curves corresponding to different $n\\xi_c$. We find, approximately, that networks can be trained when $L<6\\xi_c$. We have therefore updated all of the figures in the paper to use the line $6\\xi_c$ instead of $2\\xi_c$.\n\nThere is no real significance of 14k steps of SGD on MNIST except that it is long enough that the vast majority of the SGD runs have converged.\n\n>>The accuracy of the trained models on CIFAR-10 and MNIST are not reported - it seems important to the overall argument of the paper that the sorts of networks underlying Figures 5 and 6 are the same as the ones that people would consider state-of-art within the model class (fully connected, sigmoidal nonlinearities, etc.).\n\nIt is important to note that our theoretical results are only valid in the pre-training regime and bound whether or not a specific architecture can be trained. As yet, they do not have any obvious connection with the final accuracy. Having said this, once our models are sufficiently large they all overfit both CIFAR-10 and MNIST (and so have perfect training accuracy.) The test accuracy of our models is therefore somewhat low (~98% in the case of MNIST and ~55% in the case of CIFAR10), but simultaneously is not a quantity that we were particularly interested in maximizing. We agree that we should have reported these numbers and have added them to the text.\n\n"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Deep Information Propagation", "abstract": "We study the behavior of untrained neural networks whose weights and biases are randomly distributed using mean field theory. We show the existence of depth scales that naturally limit the maximum depth of signal propagation through these random networks. Our main practical result is to show that random networks may be trained precisely when information can travel through them. Thus, the depth scales that we identify provide bounds on how deep a network may be trained for a specific choice of hyperparameters. As a corollary to this, we argue that in networks at the edge of chaos, one of these depth scales diverges. Thus arbitrarily deep networks may be trained only sufficiently close to criticality. We show that the presence of dropout destroys the order-to-chaos critical point and therefore strongly limits the maximum trainable depth for random networks. Finally, we develop a mean field theory for backpropagation and we show that the ordered and chaotic phases correspond to regions of vanishing and exploding gradient respectively.", "pdf": "/pdf/49b3f245e912ffb5845d079da65751b3e4fe4ad1.pdf", "TL;DR": "We predict whether randomly initialized neural networks can be trained by studying whether or not information can travel through them.", "paperhash": "schoenholz|deep_information_propagation", "keywords": ["Theory", "Deep learning"], "conflicts": ["google.com", "stanford.edu"], "authors": ["Samuel S. Schoenholz", "Justin Gilmer", "Surya Ganguli", "Jascha Sohl-Dickstein"], "authorids": ["schsam@google.com", "gilmer@google.com", "sganguli@stanford.edu", "jaschasd@google.com"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287681630, "id": "ICLR.cc/2017/conference/-/paper215/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "H1W1UN9gg", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper215/reviewers", "ICLR.cc/2017/conference/paper215/areachairs"], "cdate": 1485287681630}}}, {"tddate": null, "tmdate": 1483205449921, "tcdate": 1483205449921, "number": 1, "id": "rJGLovrHx", "invitation": "ICLR.cc/2017/conference/-/paper215/public/comment", "forum": "H1W1UN9gg", "replyto": "H1W1UN9gg", "signatures": ["~Greg_Yang1"], "readers": ["everyone"], "writers": ["~Greg_Yang1"], "content": {"title": "dropout", "comment": "Just making sure, your experiments with dropout follows the convention that during evaluation, it is turned off?"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Deep Information Propagation", "abstract": "We study the behavior of untrained neural networks whose weights and biases are randomly distributed using mean field theory. We show the existence of depth scales that naturally limit the maximum depth of signal propagation through these random networks. Our main practical result is to show that random networks may be trained precisely when information can travel through them. Thus, the depth scales that we identify provide bounds on how deep a network may be trained for a specific choice of hyperparameters. As a corollary to this, we argue that in networks at the edge of chaos, one of these depth scales diverges. Thus arbitrarily deep networks may be trained only sufficiently close to criticality. We show that the presence of dropout destroys the order-to-chaos critical point and therefore strongly limits the maximum trainable depth for random networks. Finally, we develop a mean field theory for backpropagation and we show that the ordered and chaotic phases correspond to regions of vanishing and exploding gradient respectively.", "pdf": "/pdf/49b3f245e912ffb5845d079da65751b3e4fe4ad1.pdf", "TL;DR": "We predict whether randomly initialized neural networks can be trained by studying whether or not information can travel through them.", "paperhash": "schoenholz|deep_information_propagation", "keywords": ["Theory", "Deep learning"], "conflicts": ["google.com", "stanford.edu"], "authors": ["Samuel S. Schoenholz", "Justin Gilmer", "Surya Ganguli", "Jascha Sohl-Dickstein"], "authorids": ["schsam@google.com", "gilmer@google.com", "sganguli@stanford.edu", "jaschasd@google.com"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287681630, "id": "ICLR.cc/2017/conference/-/paper215/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "H1W1UN9gg", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper215/reviewers", "ICLR.cc/2017/conference/paper215/areachairs"], "cdate": 1485287681630}}}, {"tddate": null, "tmdate": 1482530968040, "tcdate": 1482530968040, "number": 3, "id": "H1gjgmjEx", "invitation": "ICLR.cc/2017/conference/-/paper215/official/review", "forum": "H1W1UN9gg", "replyto": "H1W1UN9gg", "signatures": ["ICLR.cc/2017/conference/paper215/AnonReviewer4"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/conference/paper215/AnonReviewer4"], "content": {"title": "interesting analysis - empirical results could be clarified", "rating": "8: Top 50% of accepted papers, clear accept", "review": "I'm not familiar enough with mean-field techniques to judge the soundness of Eq 2, but I'm willing to roll with it.\n\nMinor point on presentation: Speaking of the \"evolution\" of x_{i;a} as it travels through the network could give some readers helpful intuition, but for me it was confusing because x_{*;a} is the immutable input vector, and it's the just-introduced z and y variables that represent its so-called evolution, no?\n\nIn interpreting this analysis - A network may be trainable if information does not pass through it, if the training steps, by whatever reason, perturb the weights so that information starts to pass through it (without subsequently perturbing the weights to stop information from passing through it.) Perhaps this could be clarified by a definition of \u201ctraining algorithm\u201d?\n\nComments on central claims:\nPrevious work on initializing neural networks to promote information flow (e.g. Glorot & Bengio, http://jmlr.org/proceedings/papers/v9/glorot10a/glorot10a.pdf) concluded (1) that the number of units in the next layer and the previous layer should both figure into the variance of the elements of the weight matrices, and (2) that they should be drawn from a Uniform distribution rather than a Gaussian. Could the authors comment on the merit of that initialization strategy in light of this analysis?\n\nComments on evaluation:\nWhy does the dashed line in the result figures correspond to twice the depth scale instead of just the depth scale? What is the significance of 14000 steps of SGD on MNIST? Does it represent convergence of SGD? Why are all the best SGD models well above the depth scale? Why is there a little dark area precisely under the peak in Figure 5(a) and (c)? That\u2019s interesting - initializations that propagate error best seem untrainable at the depths traditionally used - but only with SGD not RMSProp?\n\nThe accuracy of the trained models on CIFAR-10 and MNIST are not reported - it seems important to the overall argument of the paper that the sorts of networks underlying Figures 5 and 6 are the same as the ones that people would consider state-of-art within the model class (fully connected, sigmoidal nonlinearities, etc.).\n", "confidence": "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Deep Information Propagation", "abstract": "We study the behavior of untrained neural networks whose weights and biases are randomly distributed using mean field theory. We show the existence of depth scales that naturally limit the maximum depth of signal propagation through these random networks. Our main practical result is to show that random networks may be trained precisely when information can travel through them. Thus, the depth scales that we identify provide bounds on how deep a network may be trained for a specific choice of hyperparameters. As a corollary to this, we argue that in networks at the edge of chaos, one of these depth scales diverges. Thus arbitrarily deep networks may be trained only sufficiently close to criticality. We show that the presence of dropout destroys the order-to-chaos critical point and therefore strongly limits the maximum trainable depth for random networks. Finally, we develop a mean field theory for backpropagation and we show that the ordered and chaotic phases correspond to regions of vanishing and exploding gradient respectively.", "pdf": "/pdf/49b3f245e912ffb5845d079da65751b3e4fe4ad1.pdf", "TL;DR": "We predict whether randomly initialized neural networks can be trained by studying whether or not information can travel through them.", "paperhash": "schoenholz|deep_information_propagation", "keywords": ["Theory", "Deep learning"], "conflicts": ["google.com", "stanford.edu"], "authors": ["Samuel S. Schoenholz", "Justin Gilmer", "Surya Ganguli", "Jascha Sohl-Dickstein"], "authorids": ["schsam@google.com", "gilmer@google.com", "sganguli@stanford.edu", "jaschasd@google.com"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1481932799000, "tmdate": 1482530968654, "id": "ICLR.cc/2017/conference/-/paper215/official/review", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/conference/paper215/reviewers"], "noninvitees": ["ICLR.cc/2017/conference/paper215/AnonReviewer2", "ICLR.cc/2017/conference/paper215/AnonReviewer3", "ICLR.cc/2017/conference/paper215/AnonReviewer4"], "reply": {"forum": "H1W1UN9gg", "replyto": "H1W1UN9gg", "writers": {"values-regex": "ICLR.cc/2017/conference/paper215/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/conference/paper215/AnonReviewer[0-9]+"}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "value-regex": "[\\S\\s]{1,20000}"}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1489708799000, "cdate": 1482530968654}}}, {"tddate": null, "tmdate": 1482530337060, "tcdate": 1482530337060, "number": 1, "content": {"title": "-", "question": "-"}, "id": "S1K7RfsVx", "invitation": "ICLR.cc/2017/conference/-/paper215/pre-review/question", "forum": "H1W1UN9gg", "replyto": "H1W1UN9gg", "signatures": ["ICLR.cc/2017/conference/paper215/AnonReviewer4"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/conference/paper215/AnonReviewer4"], "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Deep Information Propagation", "abstract": "We study the behavior of untrained neural networks whose weights and biases are randomly distributed using mean field theory. We show the existence of depth scales that naturally limit the maximum depth of signal propagation through these random networks. Our main practical result is to show that random networks may be trained precisely when information can travel through them. Thus, the depth scales that we identify provide bounds on how deep a network may be trained for a specific choice of hyperparameters. As a corollary to this, we argue that in networks at the edge of chaos, one of these depth scales diverges. Thus arbitrarily deep networks may be trained only sufficiently close to criticality. We show that the presence of dropout destroys the order-to-chaos critical point and therefore strongly limits the maximum trainable depth for random networks. Finally, we develop a mean field theory for backpropagation and we show that the ordered and chaotic phases correspond to regions of vanishing and exploding gradient respectively.", "pdf": "/pdf/49b3f245e912ffb5845d079da65751b3e4fe4ad1.pdf", "TL;DR": "We predict whether randomly initialized neural networks can be trained by studying whether or not information can travel through them.", "paperhash": "schoenholz|deep_information_propagation", "keywords": ["Theory", "Deep learning"], "conflicts": ["google.com", "stanford.edu"], "authors": ["Samuel S. Schoenholz", "Justin Gilmer", "Surya Ganguli", "Jascha Sohl-Dickstein"], "authorids": ["schsam@google.com", "gilmer@google.com", "sganguli@stanford.edu", "jaschasd@google.com"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1480741199000, "tmdate": 1482530337622, "id": "ICLR.cc/2017/conference/-/paper215/pre-review/question", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/conference/paper215/reviewers"], "noninvitees": ["ICLR.cc/2017/conference/paper215/AnonReviewer4"], "reply": {"forum": "H1W1UN9gg", "replyto": "H1W1UN9gg", "writers": {"values-regex": "ICLR.cc/2017/conference/paper215/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/conference/paper215/AnonReviewer[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your question.", "value-regex": ".{1,500}"}, "question": {"order": 2, "description": "Your question", "value-regex": "[\\S\\s]{1,5000}"}}}, "nonreaders": [], "expdate": 1488517199000, "cdate": 1482530337622}}}, {"tddate": null, "tmdate": 1481906340945, "tcdate": 1481906340945, "number": 2, "id": "BJasd5ZEe", "invitation": "ICLR.cc/2017/conference/-/paper215/official/review", "forum": "H1W1UN9gg", "replyto": "H1W1UN9gg", "signatures": ["ICLR.cc/2017/conference/paper215/AnonReviewer3"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/conference/paper215/AnonReviewer3"], "content": {"title": "An important and thorough contribution to the theoretical analysis of deep neural networks", "rating": "9: Top 15% of accepted papers, strong accept", "review": "The paper expands a recent mean-field approximation of deep random neural networks to study depth-dependent information propagation, its phase-dependence and the influence of drop-out. The paper is extremely well written, the mathematical analysis is thorough and numerical experiments are included that underscore the theoretical results. Overall the paper stands out as one of the few papers that thoroughly analyses training and performance of deep nets.", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Deep Information Propagation", "abstract": "We study the behavior of untrained neural networks whose weights and biases are randomly distributed using mean field theory. We show the existence of depth scales that naturally limit the maximum depth of signal propagation through these random networks. Our main practical result is to show that random networks may be trained precisely when information can travel through them. Thus, the depth scales that we identify provide bounds on how deep a network may be trained for a specific choice of hyperparameters. As a corollary to this, we argue that in networks at the edge of chaos, one of these depth scales diverges. Thus arbitrarily deep networks may be trained only sufficiently close to criticality. We show that the presence of dropout destroys the order-to-chaos critical point and therefore strongly limits the maximum trainable depth for random networks. Finally, we develop a mean field theory for backpropagation and we show that the ordered and chaotic phases correspond to regions of vanishing and exploding gradient respectively.", "pdf": "/pdf/49b3f245e912ffb5845d079da65751b3e4fe4ad1.pdf", "TL;DR": "We predict whether randomly initialized neural networks can be trained by studying whether or not information can travel through them.", "paperhash": "schoenholz|deep_information_propagation", "keywords": ["Theory", "Deep learning"], "conflicts": ["google.com", "stanford.edu"], "authors": ["Samuel S. Schoenholz", "Justin Gilmer", "Surya Ganguli", "Jascha Sohl-Dickstein"], "authorids": ["schsam@google.com", "gilmer@google.com", "sganguli@stanford.edu", "jaschasd@google.com"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1481932799000, "tmdate": 1482530968654, "id": "ICLR.cc/2017/conference/-/paper215/official/review", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/conference/paper215/reviewers"], "noninvitees": ["ICLR.cc/2017/conference/paper215/AnonReviewer2", "ICLR.cc/2017/conference/paper215/AnonReviewer3", "ICLR.cc/2017/conference/paper215/AnonReviewer4"], "reply": {"forum": "H1W1UN9gg", "replyto": "H1W1UN9gg", "writers": {"values-regex": "ICLR.cc/2017/conference/paper215/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/conference/paper215/AnonReviewer[0-9]+"}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "value-regex": "[\\S\\s]{1,20000}"}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1489708799000, "cdate": 1482530968654}}}, {"tddate": null, "tmdate": 1481600222501, "tcdate": 1481600222497, "number": 1, "id": "rJU1aJpXx", "invitation": "ICLR.cc/2017/conference/-/paper215/official/review", "forum": "H1W1UN9gg", "replyto": "H1W1UN9gg", "signatures": ["ICLR.cc/2017/conference/paper215/AnonReviewer2"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/conference/paper215/AnonReviewer2"], "content": {"title": "Excellent analysis ", "rating": "8: Top 50% of accepted papers, clear accept", "review": "This paper presents a mathematical analysis of how information is propagated through deep feed-forward neural networks, with novel analysis addressing the problem of vanishing and exploding gradients in the backward pass of backpropagation and the use of the dropout algorithm. The paper is clear and well-written, the analysis is thorough, and the experimental results showing agreement with the model are very nice. ", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Deep Information Propagation", "abstract": "We study the behavior of untrained neural networks whose weights and biases are randomly distributed using mean field theory. We show the existence of depth scales that naturally limit the maximum depth of signal propagation through these random networks. Our main practical result is to show that random networks may be trained precisely when information can travel through them. Thus, the depth scales that we identify provide bounds on how deep a network may be trained for a specific choice of hyperparameters. As a corollary to this, we argue that in networks at the edge of chaos, one of these depth scales diverges. Thus arbitrarily deep networks may be trained only sufficiently close to criticality. We show that the presence of dropout destroys the order-to-chaos critical point and therefore strongly limits the maximum trainable depth for random networks. Finally, we develop a mean field theory for backpropagation and we show that the ordered and chaotic phases correspond to regions of vanishing and exploding gradient respectively.", "pdf": "/pdf/49b3f245e912ffb5845d079da65751b3e4fe4ad1.pdf", "TL;DR": "We predict whether randomly initialized neural networks can be trained by studying whether or not information can travel through them.", "paperhash": "schoenholz|deep_information_propagation", "keywords": ["Theory", "Deep learning"], "conflicts": ["google.com", "stanford.edu"], "authors": ["Samuel S. Schoenholz", "Justin Gilmer", "Surya Ganguli", "Jascha Sohl-Dickstein"], "authorids": ["schsam@google.com", "gilmer@google.com", "sganguli@stanford.edu", "jaschasd@google.com"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1481932799000, "tmdate": 1482530968654, "id": "ICLR.cc/2017/conference/-/paper215/official/review", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/conference/paper215/reviewers"], "noninvitees": ["ICLR.cc/2017/conference/paper215/AnonReviewer2", "ICLR.cc/2017/conference/paper215/AnonReviewer3", "ICLR.cc/2017/conference/paper215/AnonReviewer4"], "reply": {"forum": "H1W1UN9gg", "replyto": "H1W1UN9gg", "writers": {"values-regex": "ICLR.cc/2017/conference/paper215/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/conference/paper215/AnonReviewer[0-9]+"}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "value-regex": "[\\S\\s]{1,20000}"}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1489708799000, "cdate": 1482530968654}}}], "count": 9}