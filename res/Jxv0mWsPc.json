{"notes": [{"id": "Jxv0mWsPc", "original": "VyXscOXNKL", "number": 22, "cdate": 1582750157140, "ddate": null, "tcdate": 1582750157140, "tmdate": 1587925109679, "tddate": null, "forum": "Jxv0mWsPc", "replyto": null, "invitation": "ICLR.cc/2020/Workshop/DeepDiffEq/-/Blind_Submission", "content": {"title": "Fast Convergence for Langevin with Matrix Manifold Structure", "authors": ["Ankur Moitra", "Andrej Risteski"], "authorids": ["moitra@mit.edu", "aristesk@andrew.cmu.edu"], "keywords": ["Langevin", "diffusion", "Ricci Curvature", "Poincare inequality"], "TL;DR": "We analyze Langevin dynamics in non-log-concave settings in the presence of (matrix) manifold structure ", "abstract": "\nIn this paper, we study the problem of sampling from distributions of the form p(x) \\propto e^{-\\beta f(x)} for some function f whose values and gradients we can query. This mode of access to f is natural in the scenarios in which such problems arise, for instance sampling from posteriors in parametric Bayesian models. Classical results show that a natural random walk, Langevin diffusion, mixes rapidly when f is convex. Unfortunately, even in simple examples, the applications listed above will entail working with functions f that are nonconvex -- for which sampling from p may in general require an exponential number of queries.\nIn this paper, we study one aspect of nonconvexity relevant for modern machine learning applications: existence of invariances (symmetries) in the function f, as a result of which the distribution p will have manifolds of points with equal probability. We give a recipe for proving mixing time bounds of Langevin dynamics in order to sample from manifolds of local optima of the function f in settings where the distribution is well-concentrated around them. We specialize our arguments to classic matrix factorization-like Bayesian inference problems where we get noisy measurements A(XX^T), X \\in R^{d \\times k} of a low-rank matrix, i.e. f(X) = \\|A(XX^T) - b\\|^2_2, X \\in R^{d \\times k}, and \\beta the inverse of the variance of the noise. Such functions f are invariant under orthogonal transformations, and include problems like matrix factorization, sensing, completion. Beyond sampling, Langevin dynamics is a popular toy model for studying stochastic gradient descent. Along these lines, we believe that our work is an important first step towards understanding how SGD behaves when there is a high degree of symmetry in the space of parameters the produce the same output.", "pdf": "/pdf/018f3616aba6d1dcf83919e5846338ae3799773a.pdf", "paperhash": "moitra|fast_convergence_for_langevin_with_matrix_manifold_structure", "_bibtex": "@inproceedings{\nmoitra2020fast,\ntitle={Fast Convergence for Langevin with Matrix Manifold Structure},\nauthor={Ankur Moitra and Andrej Risteski},\nbooktitle={ICLR 2020 Workshop on Integration of Deep Neural Models and Differential Equations},\nyear={2020},\nurl={https://openreview.net/forum?id=Jxv0mWsPc}\n}"}, "signatures": ["ICLR.cc/2020/Workshop/DeepDiffEq"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Workshop/DeepDiffEq"], "details": {"replyCount": 1, "writable": false, "overwriting": [], "revisions": false, "tags": [], "invitation": {"reply": {"readers": {"values-regex": ".*"}, "writers": {"values": ["ICLR.cc/2020/Workshop/DeepDiffEq"]}, "signatures": {"values": ["ICLR.cc/2020/Workshop/DeepDiffEq"]}, "content": {"authors": {"values": ["Anonymous"]}, "authorids": {"values-regex": ".*"}}}, "signatures": ["ICLR.cc/2020/Workshop/DeepDiffEq"], "readers": ["everyone"], "writers": ["ICLR.cc/2020/Workshop/DeepDiffEq"], "invitees": ["~"], "tcdate": 1582750147213, "tmdate": 1587924718420, "id": "ICLR.cc/2020/Workshop/DeepDiffEq/-/Blind_Submission"}}, "tauthor": "OpenReview.net"}, {"id": "QJ-B-nN26c", "original": null, "number": 1, "cdate": 1582774719496, "ddate": null, "tcdate": 1582774719496, "tmdate": 1582774719496, "tddate": null, "forum": "Jxv0mWsPc", "replyto": "Jxv0mWsPc", "invitation": "ICLR.cc/2020/Workshop/DeepDiffEq/Paper22/-/Decision", "content": {"decision": "Accept (Poster)", "title": "Paper Decision"}, "signatures": ["ICLR.cc/2020/Workshop/DeepDiffEq/Program_Chairs"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Workshop/DeepDiffEq/Program_Chairs"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Fast Convergence for Langevin with Matrix Manifold Structure", "authors": ["Ankur Moitra", "Andrej Risteski"], "authorids": ["moitra@mit.edu", "aristesk@andrew.cmu.edu"], "keywords": ["Langevin", "diffusion", "Ricci Curvature", "Poincare inequality"], "TL;DR": "We analyze Langevin dynamics in non-log-concave settings in the presence of (matrix) manifold structure ", "abstract": "\nIn this paper, we study the problem of sampling from distributions of the form p(x) \\propto e^{-\\beta f(x)} for some function f whose values and gradients we can query. This mode of access to f is natural in the scenarios in which such problems arise, for instance sampling from posteriors in parametric Bayesian models. Classical results show that a natural random walk, Langevin diffusion, mixes rapidly when f is convex. Unfortunately, even in simple examples, the applications listed above will entail working with functions f that are nonconvex -- for which sampling from p may in general require an exponential number of queries.\nIn this paper, we study one aspect of nonconvexity relevant for modern machine learning applications: existence of invariances (symmetries) in the function f, as a result of which the distribution p will have manifolds of points with equal probability. We give a recipe for proving mixing time bounds of Langevin dynamics in order to sample from manifolds of local optima of the function f in settings where the distribution is well-concentrated around them. We specialize our arguments to classic matrix factorization-like Bayesian inference problems where we get noisy measurements A(XX^T), X \\in R^{d \\times k} of a low-rank matrix, i.e. f(X) = \\|A(XX^T) - b\\|^2_2, X \\in R^{d \\times k}, and \\beta the inverse of the variance of the noise. Such functions f are invariant under orthogonal transformations, and include problems like matrix factorization, sensing, completion. Beyond sampling, Langevin dynamics is a popular toy model for studying stochastic gradient descent. Along these lines, we believe that our work is an important first step towards understanding how SGD behaves when there is a high degree of symmetry in the space of parameters the produce the same output.", "pdf": "/pdf/018f3616aba6d1dcf83919e5846338ae3799773a.pdf", "paperhash": "moitra|fast_convergence_for_langevin_with_matrix_manifold_structure", "_bibtex": "@inproceedings{\nmoitra2020fast,\ntitle={Fast Convergence for Langevin with Matrix Manifold Structure},\nauthor={Ankur Moitra and Andrej Risteski},\nbooktitle={ICLR 2020 Workshop on Integration of Deep Neural Models and Differential Equations},\nyear={2020},\nurl={https://openreview.net/forum?id=Jxv0mWsPc}\n}"}, "tags": [], "invitation": {"reply": {"writers": {"values": ["ICLR.cc/2020/Workshop/DeepDiffEq/Program_Chairs"], "description": "How your identity will be displayed."}, "signatures": {"values": ["ICLR.cc/2020/Workshop/DeepDiffEq/Program_Chairs"], "description": "How your identity will be displayed."}, "content": {"title": {"order": 1, "required": true, "value": "Paper Decision"}, "decision": {"order": 2, "required": true, "value-radio": ["Accept (Oral)", "Accept (Poster)", "Reject"], "description": "Decision"}, "comment": {"order": 3, "required": false, "value-regex": "[\\S\\s]{0,5000}", "description": ""}}, "forum": "Jxv0mWsPc", "replyto": "Jxv0mWsPc", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}}, "cdate": 1582156800000, "expdate": 1589155200000, "duedate": 1588291200000, "multiReply": false, "readers": ["everyone"], "invitees": ["ICLR.cc/2020/Workshop/DeepDiffEq/Program_Chairs"], "tcdate": 1582771074323, "tmdate": 1587925016996, "super": "ICLR.cc/2020/Workshop/DeepDiffEq/-/Decision", "signatures": ["ICLR.cc/2020/Workshop/DeepDiffEq"], "writers": ["ICLR.cc/2020/Workshop/DeepDiffEq"], "id": "ICLR.cc/2020/Workshop/DeepDiffEq/Paper22/-/Decision"}}}], "count": 2}