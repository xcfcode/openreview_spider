{"notes": [{"tddate": null, "ddate": null, "original": null, "tmdate": 1521582793888, "tcdate": 1520627610537, "number": 1, "cdate": 1520627610537, "id": "H1fjkOgtM", "invitation": "ICLR.cc/2018/Workshop/-/Paper57/Official_Review", "forum": "SkJdByaUG", "replyto": "SkJdByaUG", "signatures": ["ICLR.cc/2018/Workshop/Paper57/AnonReviewer3"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Workshop/Paper57/AnonReviewer3"], "content": {"title": "Well-known combination of LSTM and discretisation of time series", "rating": "5: Marginally below acceptance threshold", "review": "This paper studies the use of LSTMs to do nonlinear time-series forecasting while explicitly expressing prediction uncertainty, by modeling the univariate or multivariate scalar values as probability distribution functions using multinomials over discretised time-series.\n\nFollowing an LSTM by a softmax and replacing regression by a classification task is a well known trick for LSTM (please see the PixelRNN and derived papers, e.g., \"Pixel recurrent neural networks\" by Van Den Oord et al, 2016). As such, there is nothing novel in this paper.\n\nWhat would have been interesting here would have been an exhaustive study of time series generation (iterated prediction) while sampling y^{hat}_{t+j} (for j > 1), a subject that is barely mentioned in section 2.3 when talking about Sequential Monte-Carlo. However, the authors get lost in long exposition in section 2.1 and 2.2. Is it necessary to introduce psi_s and psi_h? Does y^{hat} get used as input? Could equations (4) and (5) get replaced by saying: \"we discretise the time series into categorical values\"? The cross-entropy regularisation bit is novel, though.\n\nThe results seem good but miss an important baseline: plain LSTMs!\n\nFigure 1 should use the same symbols for (a) and (b). ", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Forecasting probability distribution of nonlinear time series", "abstract": "We propose DE-RNN to learn the probability density function (PDF) of a nonlinear time series, and compute the temporal evolution of the PDF for a probabilistic forecast. A Recurrent Neural Network (RNN) based model is employed to learn a nonlinear operator for temporal evolution of the stochastic process. We use a softmax layer for a numerical discretization of a PDF, which transforms a function approximation problem to a classification problem. Explicit and implicit regularization strategies are introduced to impose a smoothness condition on the estimated probability distribution. A multiple-step forecast is achieved by computing the time evolution of PDF.", "pdf": "/pdf/f69d523efa6e146cc773b38295daa68d2fb9908d.pdf", "TL;DR": "We propose DE-RNN to learn the probability density function of a nonlinear time series by using numerical discretization and to make a forecast of the time evolution of the probability density function by using a sequential Monte Carlo method.", "paperhash": "yeo|forecasting_probability_distribution_of_nonlinear_time_series", "keywords": ["Recurrent Neural Network", "forecast", "density estimation", "nonlinear time series", "dynamical system", "uncertainty quantification"], "authors": ["Kyongmin Yeo", "Igor Melnyk", "Nam Nguyen", "Eun Kyung Lee"], "authorids": ["kyeo@us.ibm.com", "igor.melnyk@ibm.com", "nnguyen@us.ibm.com", "eunkyung.lee@us.ibm.com"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1520657999000, "tmdate": 1521582793691, "id": "ICLR.cc/2018/Workshop/-/Paper57/Official_Review", "writers": ["ICLR.cc/2018/Workshop"], "signatures": ["ICLR.cc/2018/Workshop"], "readers": ["everyone"], "invitees": ["ICLR.cc/2018/Workshop/Paper57/Reviewers"], "noninvitees": ["ICLR.cc/2018/Workshop/Paper57/AnonReviewer3", "ICLR.cc/2018/Workshop/Paper57/AnonReviewer2", "ICLR.cc/2018/Workshop/Paper57/AnonReviewer1"], "reply": {"forum": "SkJdByaUG", "replyto": "SkJdByaUG", "writers": {"values-regex": "ICLR.cc/2018/Workshop/Paper57/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2018/Workshop/Paper57/AnonReviewer[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"required": true, "order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"required": true, "order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "value-regex": "[\\S\\s]{1,200000}"}, "rating": {"required": true, "order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"required": true, "order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1528433999000, "cdate": 1521582793691}}}, {"tddate": null, "ddate": null, "original": null, "tmdate": 1521582667233, "tcdate": 1520748828834, "number": 2, "cdate": 1520748828834, "id": "HJB7FSMtM", "invitation": "ICLR.cc/2018/Workshop/-/Paper57/Official_Review", "forum": "SkJdByaUG", "replyto": "SkJdByaUG", "signatures": ["ICLR.cc/2018/Workshop/Paper57/AnonReviewer2"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Workshop/Paper57/AnonReviewer2"], "content": {"title": "Interesting work which could be potentially improved", "rating": "5: Marginally below acceptance threshold", "review": "This paper seeks to solve time-series PDF estimation problem. It applies a RNN to capture the temporal dependency over the past observations. It also uses a grid discretization to transform a PDF estimation formulation into a classification problem. Experiments show that the proposed approach perform favorably compared to DeepAR, AR and GP. However, the paper can be potentially improved in the following aspects. First, the scalability of DE-RNN is not discussed in the experiments. One can imagine that the number of grids determines the prediction performance, and due to the curse of dimensionality it will requires large number of training examples. The experiments only give results in a one-dimensional setting, which is not sufficiently convincing. Second, this paper seems to extend to multi-dimensional cases, which will make the training even harder. Moreover, the critical part of multi-variate time-series is that the interdependency among different dimensions is important to the prediction of each individual dimension. However, the paper totally ignores this dependency, which makes this setting not very useful in practice. Third, the paper proposes two ways of regularization but fails give the comparison of the two. It also lacks of training setting specification for the other baselines. ", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Forecasting probability distribution of nonlinear time series", "abstract": "We propose DE-RNN to learn the probability density function (PDF) of a nonlinear time series, and compute the temporal evolution of the PDF for a probabilistic forecast. A Recurrent Neural Network (RNN) based model is employed to learn a nonlinear operator for temporal evolution of the stochastic process. We use a softmax layer for a numerical discretization of a PDF, which transforms a function approximation problem to a classification problem. Explicit and implicit regularization strategies are introduced to impose a smoothness condition on the estimated probability distribution. A multiple-step forecast is achieved by computing the time evolution of PDF.", "pdf": "/pdf/f69d523efa6e146cc773b38295daa68d2fb9908d.pdf", "TL;DR": "We propose DE-RNN to learn the probability density function of a nonlinear time series by using numerical discretization and to make a forecast of the time evolution of the probability density function by using a sequential Monte Carlo method.", "paperhash": "yeo|forecasting_probability_distribution_of_nonlinear_time_series", "keywords": ["Recurrent Neural Network", "forecast", "density estimation", "nonlinear time series", "dynamical system", "uncertainty quantification"], "authors": ["Kyongmin Yeo", "Igor Melnyk", "Nam Nguyen", "Eun Kyung Lee"], "authorids": ["kyeo@us.ibm.com", "igor.melnyk@ibm.com", "nnguyen@us.ibm.com", "eunkyung.lee@us.ibm.com"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1520657999000, "tmdate": 1521582793691, "id": "ICLR.cc/2018/Workshop/-/Paper57/Official_Review", "writers": ["ICLR.cc/2018/Workshop"], "signatures": ["ICLR.cc/2018/Workshop"], "readers": ["everyone"], "invitees": ["ICLR.cc/2018/Workshop/Paper57/Reviewers"], "noninvitees": ["ICLR.cc/2018/Workshop/Paper57/AnonReviewer3", "ICLR.cc/2018/Workshop/Paper57/AnonReviewer2", "ICLR.cc/2018/Workshop/Paper57/AnonReviewer1"], "reply": {"forum": "SkJdByaUG", "replyto": "SkJdByaUG", "writers": {"values-regex": "ICLR.cc/2018/Workshop/Paper57/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2018/Workshop/Paper57/AnonReviewer[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"required": true, "order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"required": true, "order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "value-regex": "[\\S\\s]{1,200000}"}, "rating": {"required": true, "order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"required": true, "order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1528433999000, "cdate": 1521582793691}}}, {"tddate": null, "ddate": null, "original": null, "tmdate": 1521582648987, "tcdate": 1520791842017, "number": 3, "cdate": 1520791842017, "id": "S197Zxmtf", "invitation": "ICLR.cc/2018/Workshop/-/Paper57/Official_Review", "forum": "SkJdByaUG", "replyto": "SkJdByaUG", "signatures": ["ICLR.cc/2018/Workshop/Paper57/AnonReviewer1"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Workshop/Paper57/AnonReviewer1"], "content": {"title": "Review", "rating": "6: Marginally above acceptance threshold", "review": "This paper proposes an approach to non-linear time-series prediction that outperforms previous approach on several datasets.", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Forecasting probability distribution of nonlinear time series", "abstract": "We propose DE-RNN to learn the probability density function (PDF) of a nonlinear time series, and compute the temporal evolution of the PDF for a probabilistic forecast. A Recurrent Neural Network (RNN) based model is employed to learn a nonlinear operator for temporal evolution of the stochastic process. We use a softmax layer for a numerical discretization of a PDF, which transforms a function approximation problem to a classification problem. Explicit and implicit regularization strategies are introduced to impose a smoothness condition on the estimated probability distribution. A multiple-step forecast is achieved by computing the time evolution of PDF.", "pdf": "/pdf/f69d523efa6e146cc773b38295daa68d2fb9908d.pdf", "TL;DR": "We propose DE-RNN to learn the probability density function of a nonlinear time series by using numerical discretization and to make a forecast of the time evolution of the probability density function by using a sequential Monte Carlo method.", "paperhash": "yeo|forecasting_probability_distribution_of_nonlinear_time_series", "keywords": ["Recurrent Neural Network", "forecast", "density estimation", "nonlinear time series", "dynamical system", "uncertainty quantification"], "authors": ["Kyongmin Yeo", "Igor Melnyk", "Nam Nguyen", "Eun Kyung Lee"], "authorids": ["kyeo@us.ibm.com", "igor.melnyk@ibm.com", "nnguyen@us.ibm.com", "eunkyung.lee@us.ibm.com"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1520657999000, "tmdate": 1521582793691, "id": "ICLR.cc/2018/Workshop/-/Paper57/Official_Review", "writers": ["ICLR.cc/2018/Workshop"], "signatures": ["ICLR.cc/2018/Workshop"], "readers": ["everyone"], "invitees": ["ICLR.cc/2018/Workshop/Paper57/Reviewers"], "noninvitees": ["ICLR.cc/2018/Workshop/Paper57/AnonReviewer3", "ICLR.cc/2018/Workshop/Paper57/AnonReviewer2", "ICLR.cc/2018/Workshop/Paper57/AnonReviewer1"], "reply": {"forum": "SkJdByaUG", "replyto": "SkJdByaUG", "writers": {"values-regex": "ICLR.cc/2018/Workshop/Paper57/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2018/Workshop/Paper57/AnonReviewer[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"required": true, "order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"required": true, "order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "value-regex": "[\\S\\s]{1,200000}"}, "rating": {"required": true, "order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"required": true, "order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1528433999000, "cdate": 1521582793691}}}, {"tddate": null, "ddate": null, "original": null, "tmdate": 1521573582431, "tcdate": 1521573582431, "number": 168, "cdate": 1521573582093, "id": "HkIARA0Yz", "invitation": "ICLR.cc/2018/Workshop/-/Acceptance_Decision", "forum": "SkJdByaUG", "replyto": "SkJdByaUG", "signatures": ["ICLR.cc/2018/Workshop/Program_Chairs"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Workshop/Program_Chairs"], "content": {"decision": "Reject", "title": "ICLR 2018 Workshop Acceptance Decision", "comment": "Based on the reviews, this paper has not been accepted for presentation at the ICLR workshop. However, the conversation and updates can continue to appear here on OpenReview."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Forecasting probability distribution of nonlinear time series", "abstract": "We propose DE-RNN to learn the probability density function (PDF) of a nonlinear time series, and compute the temporal evolution of the PDF for a probabilistic forecast. A Recurrent Neural Network (RNN) based model is employed to learn a nonlinear operator for temporal evolution of the stochastic process. We use a softmax layer for a numerical discretization of a PDF, which transforms a function approximation problem to a classification problem. Explicit and implicit regularization strategies are introduced to impose a smoothness condition on the estimated probability distribution. A multiple-step forecast is achieved by computing the time evolution of PDF.", "pdf": "/pdf/f69d523efa6e146cc773b38295daa68d2fb9908d.pdf", "TL;DR": "We propose DE-RNN to learn the probability density function of a nonlinear time series by using numerical discretization and to make a forecast of the time evolution of the probability density function by using a sequential Monte Carlo method.", "paperhash": "yeo|forecasting_probability_distribution_of_nonlinear_time_series", "keywords": ["Recurrent Neural Network", "forecast", "density estimation", "nonlinear time series", "dynamical system", "uncertainty quantification"], "authors": ["Kyongmin Yeo", "Igor Melnyk", "Nam Nguyen", "Eun Kyung Lee"], "authorids": ["kyeo@us.ibm.com", "igor.melnyk@ibm.com", "nnguyen@us.ibm.com", "eunkyung.lee@us.ibm.com"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "tmdate": 1518629844880, "id": "ICLR.cc/2018/Workshop/-/Acceptance_Decision", "writers": ["ICLR.cc/2018/Workshop"], "signatures": ["ICLR.cc/2018/Workshop"], "readers": ["everyone"], "invitees": ["ICLR.cc/2018/Workshop/Program_Chairs"], "reply": {"forum": null, "replyto": null, "invitation": "ICLR.cc/2018/Workshop/-/Submission", "writers": {"values": ["ICLR.cc/2018/Workshop/Program_Chairs"]}, "signatures": {"description": "How your identity will be displayed with the above content.", "values": ["ICLR.cc/2018/Workshop/Program_Chairs"]}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["ICLR.cc/2018/Workshop/Program_Chairs", "everyone"]}, "content": {"title": {"required": true, "order": 1, "value": "ICLR 2018 Workshop Acceptance Decision"}, "comment": {"required": false, "order": 3, "description": "(optional) Comment on this decision.", "value-regex": "[\\S\\s]{0,5000}"}, "decision": {"required": true, "order": 2, "value-dropdown": ["Accept", "Reject"]}}}, "nonreaders": [], "noninvitees": [], "cdate": 1518629844880}}}, {"tddate": null, "replyto": null, "ddate": null, "tmdate": 1518298561000, "tcdate": 1518298471051, "number": 57, "cdate": 1518298471051, "id": "SkJdByaUG", "invitation": "ICLR.cc/2018/Workshop/-/Submission", "forum": "SkJdByaUG", "signatures": ["~Kyongmin_Yeo1"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Workshop"], "content": {"title": "Forecasting probability distribution of nonlinear time series", "abstract": "We propose DE-RNN to learn the probability density function (PDF) of a nonlinear time series, and compute the temporal evolution of the PDF for a probabilistic forecast. A Recurrent Neural Network (RNN) based model is employed to learn a nonlinear operator for temporal evolution of the stochastic process. We use a softmax layer for a numerical discretization of a PDF, which transforms a function approximation problem to a classification problem. Explicit and implicit regularization strategies are introduced to impose a smoothness condition on the estimated probability distribution. A multiple-step forecast is achieved by computing the time evolution of PDF.", "pdf": "/pdf/f69d523efa6e146cc773b38295daa68d2fb9908d.pdf", "TL;DR": "We propose DE-RNN to learn the probability density function of a nonlinear time series by using numerical discretization and to make a forecast of the time evolution of the probability density function by using a sequential Monte Carlo method.", "paperhash": "yeo|forecasting_probability_distribution_of_nonlinear_time_series", "keywords": ["Recurrent Neural Network", "forecast", "density estimation", "nonlinear time series", "dynamical system", "uncertainty quantification"], "authors": ["Kyongmin Yeo", "Igor Melnyk", "Nam Nguyen", "Eun Kyung Lee"], "authorids": ["kyeo@us.ibm.com", "igor.melnyk@ibm.com", "nnguyen@us.ibm.com", "eunkyung.lee@us.ibm.com"]}, "nonreaders": [], "details": {"replyCount": 4, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1518472800000, "tmdate": 1518474081690, "id": "ICLR.cc/2018/Workshop/-/Submission", "writers": ["ICLR.cc/2018/Workshop"], "signatures": ["ICLR.cc/2018/Workshop"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": null, "replyto": null, "writers": {"values": ["ICLR.cc/2018/Workshop"]}, "signatures": {"values-regex": "~.*|ICLR.cc/2018/Workshop", "description": "Your authorized identity to be associated with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"pdf": {"required": true, "order": 9, "value-regex": "upload", "description": "Upload a PDF file that ends with .pdf"}, "title": {"required": true, "order": 1, "description": "Title of paper.", "value-regex": ".{1,250}"}, "abstract": {"required": true, "order": 8, "description": "Abstract of paper.", "value-regex": "[\\S\\s]{1,5000}"}, "authors": {"required": true, "order": 2, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of author names. Please provide real names; identities will be anonymized."}, "keywords": {"order": 6, "values-regex": "(^$)|[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of keywords."}, "TL;DR": {"required": false, "order": 7, "description": "\"Too Long; Didn't Read\": a short sentence describing your paper", "value-regex": "[^\\n]{0,500}"}, "authorids": {"required": true, "order": 3, "values-regex": "([a-z0-9_\\-\\.]{2,}@[a-z0-9_\\-\\.]{2,}\\.[a-z]{2,},){0,}([a-z0-9_\\-\\.]{2,}@[a-z0-9_\\-\\.]{2,}\\.[a-z]{2,})", "description": "Comma separated list of author email addresses, lowercased, in the same order as above. For authors with existing OpenReview accounts, please make sure that the provided email address(es) match those listed in the author's profile. Please provide real emails; identities will be anonymized."}}}, "nonreaders": [], "noninvitees": [], "expdate": 1526248800000, "cdate": 1518474081690}}}], "count": 5}