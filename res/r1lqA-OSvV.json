{"notes": [{"id": "r1lqA-OSvV", "original": "ByeKC-dHPN", "number": 10, "cdate": 1552413137648, "ddate": null, "tcdate": 1552413137648, "tmdate": 1562082108963, "tddate": null, "forum": "r1lqA-OSvV", "replyto": null, "invitation": "ICLR.cc/2019/Workshop/LLD/-/Blind_Submission", "content": {"title": "SOSELETO: A Unified Approach to Transfer Learning and Training with Noisy Labels", "authors": ["Or Litany", "Daniel Freedman"], "authorids": ["orlitany@gmail.com", "danielfreedman@google.com"], "keywords": ["transfer learning"], "TL;DR": "Learning with limited training data by exploiting \"helpful\" instances from a rich data source.  ", "abstract": "We present SOSELETO (SOurce SELEction for Target Optimization), a new method for exploiting a source dataset to solve a classification problem on a target dataset.  SOSELETO is based on the following simple intuition: some source examples are more informative than others for the target problem.  To capture this intuition, source samples are each given weights; these weights are solved for jointly with the source and target classification problems via a bilevel optimization scheme.  The target therefore gets to choose the source samples which are most informative for its own classification task.  Furthermore, the bilevel nature of the optimization acts as a kind of regularization on the target, mitigating overfitting.  SOSELETO may be applied to both classic transfer learning, as well as the problem of training on datasets with noisy labels; we show state of the art results on both of these problems.", "pdf": "/pdf/4da5973b3623450512bcb88b5574d9c90a4426cc.pdf", "paperhash": "litany|soseleto_a_unified_approach_to_transfer_learning_and_training_with_noisy_labels"}, "signatures": ["ICLR.cc/2019/Workshop/LLD"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Workshop/LLD"], "details": {"replyCount": 3, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"id": "ICLR.cc/2019/Workshop/LLD/-/Blind_Submission", "cdate": 1548689671889, "reply": {"forum": null, "replyto": null, "readers": {"values-regex": ".*"}, "writers": {"values": ["ICLR.cc/2019/Workshop/LLD"]}, "signatures": {"values": ["ICLR.cc/2019/Workshop/LLD"]}, "content": {"authors": {"values-regex": ".*"}, "authorids": {"values-regex": ".*"}}}, "tcdate": 1548689671889, "tmdate": 1557933709646, "readers": ["everyone"], "writers": ["ICLR.cc/2019/Workshop/LLD"], "invitees": ["~"], "signatures": ["ICLR.cc/2019/Workshop/LLD"], "details": {"writable": true}}}, "tauthor": "ICLR.cc/2019/Workshop/LLD"}, {"id": "SyxqSwRvt4", "original": null, "number": 1, "cdate": 1554667329808, "ddate": null, "tcdate": 1554667329808, "tmdate": 1555512017075, "tddate": null, "forum": "r1lqA-OSvV", "replyto": "r1lqA-OSvV", "invitation": "ICLR.cc/2019/Workshop/LLD/-/Paper10/Official_Review", "content": {"title": "Well motivated work with interesting idea", "review": "Pros:\n- clear and concise writing, clear motivation for the transfer learning part\n- sufficient detail presented for each experiment\n- interesting idea to relate an approach for training with noisy labels to one for transfer learning, and show improvement on previous noisy label results\n\nCons:\n- Figure 1 text is not readable (axis labels, legends, titles)\n", "rating": "4: Top 50% of accepted papers, clear accept", "confidence": "2: The reviewer is fairly confident that the evaluation is correct"}, "signatures": ["ICLR.cc/2019/Workshop/LLD/Paper10/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Workshop/LLD/Paper10/AnonReviewer2"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "SOSELETO: A Unified Approach to Transfer Learning and Training with Noisy Labels", "authors": ["Or Litany", "Daniel Freedman"], "authorids": ["orlitany@gmail.com", "danielfreedman@google.com"], "keywords": ["transfer learning"], "TL;DR": "Learning with limited training data by exploiting \"helpful\" instances from a rich data source.  ", "abstract": "We present SOSELETO (SOurce SELEction for Target Optimization), a new method for exploiting a source dataset to solve a classification problem on a target dataset.  SOSELETO is based on the following simple intuition: some source examples are more informative than others for the target problem.  To capture this intuition, source samples are each given weights; these weights are solved for jointly with the source and target classification problems via a bilevel optimization scheme.  The target therefore gets to choose the source samples which are most informative for its own classification task.  Furthermore, the bilevel nature of the optimization acts as a kind of regularization on the target, mitigating overfitting.  SOSELETO may be applied to both classic transfer learning, as well as the problem of training on datasets with noisy labels; we show state of the art results on both of these problems.", "pdf": "/pdf/4da5973b3623450512bcb88b5574d9c90a4426cc.pdf", "paperhash": "litany|soseleto_a_unified_approach_to_transfer_learning_and_training_with_noisy_labels"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Workshop/LLD/-/Paper10/Official_Review", "cdate": 1553713420659, "expdate": 1555718400000, "duedate": 1554681600000, "reply": {"forum": "r1lqA-OSvV", "replyto": "r1lqA-OSvV", "writers": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2019/Workshop/LLD/Paper10/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2019/Workshop/LLD/Paper10/AnonReviewer[0-9]+"}, "readers": {"values": ["everyone"], "description": "The users who will be allowed to read the above content."}, "content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "required": true}, "rating": {"order": 3, "value-dropdown": ["5: Top 15% of accepted papers, strong accept", "4: Top 50% of accepted papers, clear accept", "3: Marginally above acceptance threshold", "2: Marginally below acceptance threshold", "1: Strong rejection"], "required": true}, "confidence": {"order": 4, "value-radio": ["3: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "2: The reviewer is fairly confident that the evaluation is correct", "1: The reviewer's evaluation is an educated guess"], "required": true}}}, "tcdate": 1553713420659, "tmdate": 1555511818478, "readers": ["everyone"], "writers": ["ICLR.cc/2019/Workshop/LLD"], "invitees": ["ICLR.cc/2019/Workshop/LLD/Paper10/Reviewers"], "signatures": ["ICLR.cc/2019/Workshop/LLD"]}}}, {"id": "SkgLM7m_FN", "original": null, "number": 2, "cdate": 1554686734301, "ddate": null, "tcdate": 1554686734301, "tmdate": 1555511886079, "tddate": null, "forum": "r1lqA-OSvV", "replyto": "r1lqA-OSvV", "invitation": "ICLR.cc/2019/Workshop/LLD/-/Paper10/Official_Review", "content": {"title": "Intuitive idea with solid execution. Promising experimental results", "review": "This paper presents a unified framework for transfer learning and learning with (large amounts of) noisily-labeled (source) data. The authors assume the source and target classifiers share the same \u201crepresentation layers\u201d and only differ by the \u201cclassification layers\u201d.  They then jointly learn these layers as well as the source example weights. Specifically, the authors formulate the problem as a bilevel optimization problem and design the learning process such that the exterior level minimizes the target loss only through the source weights.  As a result, the target classifier can only control/adjust the features representation by adjusting the source example weights. Finally, the authors prove that under certain conditions this bilevel optimization procedure will converge and empirically show it helps learning. \n\nOverall the paper is in good shape. I would like to see more (empirical) analysis on the convergence condition and understand how likely the condition at the end of page 9 will be satisfied. Also, some hyper-parameter sensitively analysis on lambda_{a} and lambda_{p} will be interesting. Finally, there are some minor mistakes (listed below) that need to be fixed:\n1. in the equation (1), change min to argmin\n2. in page 8 appendix A line 5, \u201cA summer of SOSELETO algorithm appears in (Algorithm) 1\u201d\n3. in page 10 Appendix E line 2, Section \u201c???\u201d", "rating": "4: Top 50% of accepted papers, clear accept", "confidence": "1: The reviewer's evaluation is an educated guess"}, "signatures": ["ICLR.cc/2019/Workshop/LLD/Paper10/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Workshop/LLD/Paper10/AnonReviewer1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "SOSELETO: A Unified Approach to Transfer Learning and Training with Noisy Labels", "authors": ["Or Litany", "Daniel Freedman"], "authorids": ["orlitany@gmail.com", "danielfreedman@google.com"], "keywords": ["transfer learning"], "TL;DR": "Learning with limited training data by exploiting \"helpful\" instances from a rich data source.  ", "abstract": "We present SOSELETO (SOurce SELEction for Target Optimization), a new method for exploiting a source dataset to solve a classification problem on a target dataset.  SOSELETO is based on the following simple intuition: some source examples are more informative than others for the target problem.  To capture this intuition, source samples are each given weights; these weights are solved for jointly with the source and target classification problems via a bilevel optimization scheme.  The target therefore gets to choose the source samples which are most informative for its own classification task.  Furthermore, the bilevel nature of the optimization acts as a kind of regularization on the target, mitigating overfitting.  SOSELETO may be applied to both classic transfer learning, as well as the problem of training on datasets with noisy labels; we show state of the art results on both of these problems.", "pdf": "/pdf/4da5973b3623450512bcb88b5574d9c90a4426cc.pdf", "paperhash": "litany|soseleto_a_unified_approach_to_transfer_learning_and_training_with_noisy_labels"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Workshop/LLD/-/Paper10/Official_Review", "cdate": 1553713420659, "expdate": 1555718400000, "duedate": 1554681600000, "reply": {"forum": "r1lqA-OSvV", "replyto": "r1lqA-OSvV", "writers": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2019/Workshop/LLD/Paper10/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2019/Workshop/LLD/Paper10/AnonReviewer[0-9]+"}, "readers": {"values": ["everyone"], "description": "The users who will be allowed to read the above content."}, "content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "required": true}, "rating": {"order": 3, "value-dropdown": ["5: Top 15% of accepted papers, strong accept", "4: Top 50% of accepted papers, clear accept", "3: Marginally above acceptance threshold", "2: Marginally below acceptance threshold", "1: Strong rejection"], "required": true}, "confidence": {"order": 4, "value-radio": ["3: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "2: The reviewer is fairly confident that the evaluation is correct", "1: The reviewer's evaluation is an educated guess"], "required": true}}}, "tcdate": 1553713420659, "tmdate": 1555511818478, "readers": ["everyone"], "writers": ["ICLR.cc/2019/Workshop/LLD"], "invitees": ["ICLR.cc/2019/Workshop/LLD/Paper10/Reviewers"], "signatures": ["ICLR.cc/2019/Workshop/LLD"]}}}, {"id": "BJe4ClEFYE", "original": null, "number": 1, "cdate": 1554755787977, "ddate": null, "tcdate": 1554755787977, "tmdate": 1555510985329, "tddate": null, "forum": "r1lqA-OSvV", "replyto": "r1lqA-OSvV", "invitation": "ICLR.cc/2019/Workshop/LLD/-/Paper10/Decision", "content": {"title": "Acceptance Decision", "decision": "Accept"}, "signatures": ["ICLR.cc/2019/Workshop/LLD/Program_Chairs"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Workshop/LLD/Program_Chairs"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "SOSELETO: A Unified Approach to Transfer Learning and Training with Noisy Labels", "authors": ["Or Litany", "Daniel Freedman"], "authorids": ["orlitany@gmail.com", "danielfreedman@google.com"], "keywords": ["transfer learning"], "TL;DR": "Learning with limited training data by exploiting \"helpful\" instances from a rich data source.  ", "abstract": "We present SOSELETO (SOurce SELEction for Target Optimization), a new method for exploiting a source dataset to solve a classification problem on a target dataset.  SOSELETO is based on the following simple intuition: some source examples are more informative than others for the target problem.  To capture this intuition, source samples are each given weights; these weights are solved for jointly with the source and target classification problems via a bilevel optimization scheme.  The target therefore gets to choose the source samples which are most informative for its own classification task.  Furthermore, the bilevel nature of the optimization acts as a kind of regularization on the target, mitigating overfitting.  SOSELETO may be applied to both classic transfer learning, as well as the problem of training on datasets with noisy labels; we show state of the art results on both of these problems.", "pdf": "/pdf/4da5973b3623450512bcb88b5574d9c90a4426cc.pdf", "paperhash": "litany|soseleto_a_unified_approach_to_transfer_learning_and_training_with_noisy_labels"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Workshop/LLD/-/Paper10/Decision", "cdate": 1554736069610, "reply": {"forum": "r1lqA-OSvV", "replyto": "r1lqA-OSvV", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-regex": ["ICLR.cc/2019/Workshop/LLD/Program_Chairs"], "description": "How your identity will be displayed."}, "signatures": {"values": ["ICLR.cc/2019/Workshop/LLD/Program_Chairs"], "description": "How your identity will be displayed."}, "content": {"title": {"order": 1, "required": true, "value": "Acceptance Decision"}, "decision": {"order": 2, "required": true, "value-radio": ["Accept", "Reject"], "description": "Acceptance decision"}, "comment": {"order": 3, "required": false, "value-regex": "[\\S\\s]{0,5000}", "description": ""}}}, "tcdate": 1554736069610, "tmdate": 1555510969092, "readers": ["everyone"], "writers": ["ICLR.cc/2019/Workshop/LLD"], "invitees": ["ICLR.cc/2019/Workshop/LLD/Program_Chairs"], "signatures": ["ICLR.cc/2019/Workshop/LLD"]}}}], "count": 4}