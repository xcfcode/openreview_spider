{"notes": [{"id": "1qJtBS8QF9", "original": "B8qk8bXl0eE", "number": 154, "cdate": 1601308025918, "ddate": null, "tcdate": 1601308025918, "tmdate": 1614985620240, "tddate": null, "forum": "1qJtBS8QF9", "replyto": null, "invitation": "ICLR.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Graph View-Consistent Learning Network", "authorids": ["liaozl20@lzu.edu.cn", "~Kun_Zhan1"], "authors": ["Zhuolin Liao", "Kun Zhan"], "keywords": [], "abstract": "Recent years, methods based on neural networks have made great achievements in solving large and complex graph problems. However, high efficiency of these methods depends on large training and validation sets, while the acquisition of ground-truth labels is expensive and time-consuming. In this paper, a graph view-consistent learning network (GVCLN) is specially designed for the semi-supervised learning when the number of the labeled samples is very small. We fully exploit the neighborhood aggregation capability of GVCLN and use dual views to obtain different representations. Although the two views have different viewing angles, their observation objects are the same, so their observation representations need to be consistent. For view-consistent representations between two views, two loss functions are designed besides a supervised loss. The supervised loss uses the known labeled set, while a view-consistent loss is applied to the two views to obtain the consistent representation and a pseudo-label loss is designed by using the common high-confidence predictions. GVCLN with these loss functions can obtain the view-consistent representations of the original feature. We also find that preprocessing the node features with specific filter before training is good for subsequent classification tasks. Related experiments have been done on the three citation network datasets of Cora, Citeseer, and PubMed. On several node classification tasks, GVCLN achieves state-of-the-art performance.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "liao|graph_viewconsistent_learning_network", "supplementary_material": "/attachment/0690ecf654706f560eac7692fe5387aece799984.zip", "pdf": "/pdf/990167c4e2db5d40eceeff5471753fc2e40fcdc6.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=qdx0kvVbw", "_bibtex": "@misc{\nliao2021graph,\ntitle={Graph View-Consistent Learning Network},\nauthor={Zhuolin Liao and Kun Zhan},\nyear={2021},\nurl={https://openreview.net/forum?id=1qJtBS8QF9}\n}"}, "signatures": ["ICLR.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference"], "details": {"replyCount": 11, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"reply": {"readers": {"values-regex": ".*"}, "writers": {"values": ["ICLR.cc/2021/Conference"]}, "signatures": {"values": ["ICLR.cc/2021/Conference"]}, "content": {"authors": {"values": ["Anonymous"]}, "authorids": {"values-regex": ".*"}, "reviewed_version_(pdf)": {"required": false, "description": "Upload a PDF file that ends with .pdf", "value-regex": ".*"}}}, "signatures": ["ICLR.cc/2021/Conference"], "readers": ["everyone"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["~", "OpenReview.net/Support"], "tcdate": 1601308008205, "tmdate": 1614984599368, "id": "ICLR.cc/2021/Conference/-/Blind_Submission"}}, "tauthor": "OpenReview.net"}, {"id": "i6ugmXgcEh", "original": null, "number": 1, "cdate": 1610040539041, "ddate": null, "tcdate": 1610040539041, "tmdate": 1610474149352, "tddate": null, "forum": "1qJtBS8QF9", "replyto": "1qJtBS8QF9", "invitation": "ICLR.cc/2021/Conference/Paper154/-/Decision", "content": {"title": "Final Decision", "decision": "Reject", "comment": "The authors consider view-consistency when learning graph neural networks. However, as mentioned by the reviewers, the novelty of the proposed method is limited and the rationality of the implementation is not convincing. More deep discussions about related papers and analytic experiments are required to support this work. Additionally, I have concerns about the scalability of the method --- whether it can deal with more than two views and how it will perform are not studied in this work. I tend to reject it based on its current status. "}, "signatures": ["ICLR.cc/2021/Conference/Program_Chairs"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference/Program_Chairs"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Graph View-Consistent Learning Network", "authorids": ["liaozl20@lzu.edu.cn", "~Kun_Zhan1"], "authors": ["Zhuolin Liao", "Kun Zhan"], "keywords": [], "abstract": "Recent years, methods based on neural networks have made great achievements in solving large and complex graph problems. However, high efficiency of these methods depends on large training and validation sets, while the acquisition of ground-truth labels is expensive and time-consuming. In this paper, a graph view-consistent learning network (GVCLN) is specially designed for the semi-supervised learning when the number of the labeled samples is very small. We fully exploit the neighborhood aggregation capability of GVCLN and use dual views to obtain different representations. Although the two views have different viewing angles, their observation objects are the same, so their observation representations need to be consistent. For view-consistent representations between two views, two loss functions are designed besides a supervised loss. The supervised loss uses the known labeled set, while a view-consistent loss is applied to the two views to obtain the consistent representation and a pseudo-label loss is designed by using the common high-confidence predictions. GVCLN with these loss functions can obtain the view-consistent representations of the original feature. We also find that preprocessing the node features with specific filter before training is good for subsequent classification tasks. Related experiments have been done on the three citation network datasets of Cora, Citeseer, and PubMed. On several node classification tasks, GVCLN achieves state-of-the-art performance.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "liao|graph_viewconsistent_learning_network", "supplementary_material": "/attachment/0690ecf654706f560eac7692fe5387aece799984.zip", "pdf": "/pdf/990167c4e2db5d40eceeff5471753fc2e40fcdc6.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=qdx0kvVbw", "_bibtex": "@misc{\nliao2021graph,\ntitle={Graph View-Consistent Learning Network},\nauthor={Zhuolin Liao and Kun Zhan},\nyear={2021},\nurl={https://openreview.net/forum?id=1qJtBS8QF9}\n}"}, "tags": [], "invitation": {"reply": {"forum": "1qJtBS8QF9", "replyto": "1qJtBS8QF9", "readers": {"values": ["everyone"]}, "writers": {"values": ["ICLR.cc/2021/Conference/Program_Chairs"]}, "signatures": {"values": ["ICLR.cc/2021/Conference/Program_Chairs"]}, "content": {"title": {"value": "Final Decision"}, "decision": {"value-radio": ["Accept (Oral)", "Accept (Spotlight)", "Accept (Poster)", "Reject"]}, "comment": {"value-regex": "[\\S\\s]{0,50000}", "markdown": true}}}, "multiReply": false, "signatures": ["ICLR.cc/2021/Conference"], "readers": ["everyone"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Program_Chairs"], "tcdate": 1610040539026, "tmdate": 1610474149335, "id": "ICLR.cc/2021/Conference/Paper154/-/Decision"}}}, {"id": "u1SA5T4DCVW", "original": null, "number": 2, "cdate": 1605416146722, "ddate": null, "tcdate": 1605416146722, "tmdate": 1605416494539, "tddate": null, "forum": "1qJtBS8QF9", "replyto": "TiTlgrvK1lN", "invitation": "ICLR.cc/2021/Conference/Paper154/-/Official_Comment", "content": {"title": "Response to Reviewer 5", "comment": "First of all, thank you very much for your valuable comments on our paper. However, we found that there are some discrepancies in your comment with our paper, and we are here to present a statement. What we use in our paper is the consistency between the two views, instead of constructing positive and negative pairs by data enhancement as contrastive learning, that is\uff0cour paper is quite different from contrastive learning model. Therefore, the similarity to contrastive learning mentioned in your comment does not hold. As for self-training, our method is indeed used.  We use self-training to extract pseudo-labels to provide sufficient guidance for model training, but our purpose of using self-training is to provide consistency to the model. Regarding the second shortcoming mentioned in your comment, we think you may have misunderstood it. What we express in the paper is that the existing methods require a large number of known label nodes for training, and our proposed method can perform efficiently in the case of label scarcity, but it is not effective on large graphs as you said."}, "signatures": ["ICLR.cc/2021/Conference/Paper154/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper154/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Graph View-Consistent Learning Network", "authorids": ["liaozl20@lzu.edu.cn", "~Kun_Zhan1"], "authors": ["Zhuolin Liao", "Kun Zhan"], "keywords": [], "abstract": "Recent years, methods based on neural networks have made great achievements in solving large and complex graph problems. However, high efficiency of these methods depends on large training and validation sets, while the acquisition of ground-truth labels is expensive and time-consuming. In this paper, a graph view-consistent learning network (GVCLN) is specially designed for the semi-supervised learning when the number of the labeled samples is very small. We fully exploit the neighborhood aggregation capability of GVCLN and use dual views to obtain different representations. Although the two views have different viewing angles, their observation objects are the same, so their observation representations need to be consistent. For view-consistent representations between two views, two loss functions are designed besides a supervised loss. The supervised loss uses the known labeled set, while a view-consistent loss is applied to the two views to obtain the consistent representation and a pseudo-label loss is designed by using the common high-confidence predictions. GVCLN with these loss functions can obtain the view-consistent representations of the original feature. We also find that preprocessing the node features with specific filter before training is good for subsequent classification tasks. Related experiments have been done on the three citation network datasets of Cora, Citeseer, and PubMed. On several node classification tasks, GVCLN achieves state-of-the-art performance.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "liao|graph_viewconsistent_learning_network", "supplementary_material": "/attachment/0690ecf654706f560eac7692fe5387aece799984.zip", "pdf": "/pdf/990167c4e2db5d40eceeff5471753fc2e40fcdc6.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=qdx0kvVbw", "_bibtex": "@misc{\nliao2021graph,\ntitle={Graph View-Consistent Learning Network},\nauthor={Zhuolin Liao and Kun Zhan},\nyear={2021},\nurl={https://openreview.net/forum?id=1qJtBS8QF9}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "1qJtBS8QF9", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper154/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper154/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper154/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper154/Authors|ICLR.cc/2021/Conference/Paper154/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper154/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923874049, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper154/-/Official_Comment"}}}, {"id": "nBTVc3lIVPD", "original": null, "number": 6, "cdate": 1605416319229, "ddate": null, "tcdate": 1605416319229, "tmdate": 1605416319229, "tddate": null, "forum": "1qJtBS8QF9", "replyto": "H0X9-xH8ZG1", "invitation": "ICLR.cc/2021/Conference/Paper154/-/Official_Comment", "content": {"title": "Response to Reviewer 2", "comment": "First of all, thank you for your valuable comments on our paper. We have made a detailed description of how to select pseudo labels in the appendix of the paper. The appendix is placed in the additional materials of the paper, not at the end of the paper. This is our negligence. We accept your comments humbly."}, "signatures": ["ICLR.cc/2021/Conference/Paper154/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper154/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Graph View-Consistent Learning Network", "authorids": ["liaozl20@lzu.edu.cn", "~Kun_Zhan1"], "authors": ["Zhuolin Liao", "Kun Zhan"], "keywords": [], "abstract": "Recent years, methods based on neural networks have made great achievements in solving large and complex graph problems. However, high efficiency of these methods depends on large training and validation sets, while the acquisition of ground-truth labels is expensive and time-consuming. In this paper, a graph view-consistent learning network (GVCLN) is specially designed for the semi-supervised learning when the number of the labeled samples is very small. We fully exploit the neighborhood aggregation capability of GVCLN and use dual views to obtain different representations. Although the two views have different viewing angles, their observation objects are the same, so their observation representations need to be consistent. For view-consistent representations between two views, two loss functions are designed besides a supervised loss. The supervised loss uses the known labeled set, while a view-consistent loss is applied to the two views to obtain the consistent representation and a pseudo-label loss is designed by using the common high-confidence predictions. GVCLN with these loss functions can obtain the view-consistent representations of the original feature. We also find that preprocessing the node features with specific filter before training is good for subsequent classification tasks. Related experiments have been done on the three citation network datasets of Cora, Citeseer, and PubMed. On several node classification tasks, GVCLN achieves state-of-the-art performance.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "liao|graph_viewconsistent_learning_network", "supplementary_material": "/attachment/0690ecf654706f560eac7692fe5387aece799984.zip", "pdf": "/pdf/990167c4e2db5d40eceeff5471753fc2e40fcdc6.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=qdx0kvVbw", "_bibtex": "@misc{\nliao2021graph,\ntitle={Graph View-Consistent Learning Network},\nauthor={Zhuolin Liao and Kun Zhan},\nyear={2021},\nurl={https://openreview.net/forum?id=1qJtBS8QF9}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "1qJtBS8QF9", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper154/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper154/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper154/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper154/Authors|ICLR.cc/2021/Conference/Paper154/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper154/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923874049, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper154/-/Official_Comment"}}}, {"id": "4WLpPbCjWb8", "original": null, "number": 5, "cdate": 1605416286609, "ddate": null, "tcdate": 1605416286609, "tmdate": 1605416286609, "tddate": null, "forum": "1qJtBS8QF9", "replyto": "wXZ7TGmPGLR", "invitation": "ICLR.cc/2021/Conference/Paper154/-/Official_Comment", "content": {"title": "Response to Reviewer 3", "comment": "First of all, thank you for your valuable comments for our paper. Due to the length of the article, we did not give a detailed explanation of the specific theory. In the appendix, we have made a detailed description of the parameter setting and the selection of pseudo-labels. The appendix is in the additional materials submitted, but not directly added to the end of the paper. This is an oversight of our work. For the lack of theoretical proofs you mentioned, we will pay more attention to the improvement of the paper in the future. Thank you for your comments."}, "signatures": ["ICLR.cc/2021/Conference/Paper154/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper154/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Graph View-Consistent Learning Network", "authorids": ["liaozl20@lzu.edu.cn", "~Kun_Zhan1"], "authors": ["Zhuolin Liao", "Kun Zhan"], "keywords": [], "abstract": "Recent years, methods based on neural networks have made great achievements in solving large and complex graph problems. However, high efficiency of these methods depends on large training and validation sets, while the acquisition of ground-truth labels is expensive and time-consuming. In this paper, a graph view-consistent learning network (GVCLN) is specially designed for the semi-supervised learning when the number of the labeled samples is very small. We fully exploit the neighborhood aggregation capability of GVCLN and use dual views to obtain different representations. Although the two views have different viewing angles, their observation objects are the same, so their observation representations need to be consistent. For view-consistent representations between two views, two loss functions are designed besides a supervised loss. The supervised loss uses the known labeled set, while a view-consistent loss is applied to the two views to obtain the consistent representation and a pseudo-label loss is designed by using the common high-confidence predictions. GVCLN with these loss functions can obtain the view-consistent representations of the original feature. We also find that preprocessing the node features with specific filter before training is good for subsequent classification tasks. Related experiments have been done on the three citation network datasets of Cora, Citeseer, and PubMed. On several node classification tasks, GVCLN achieves state-of-the-art performance.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "liao|graph_viewconsistent_learning_network", "supplementary_material": "/attachment/0690ecf654706f560eac7692fe5387aece799984.zip", "pdf": "/pdf/990167c4e2db5d40eceeff5471753fc2e40fcdc6.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=qdx0kvVbw", "_bibtex": "@misc{\nliao2021graph,\ntitle={Graph View-Consistent Learning Network},\nauthor={Zhuolin Liao and Kun Zhan},\nyear={2021},\nurl={https://openreview.net/forum?id=1qJtBS8QF9}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "1qJtBS8QF9", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper154/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper154/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper154/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper154/Authors|ICLR.cc/2021/Conference/Paper154/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper154/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923874049, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper154/-/Official_Comment"}}}, {"id": "akzEP3pDls9", "original": null, "number": 4, "cdate": 1605416256337, "ddate": null, "tcdate": 1605416256337, "tmdate": 1605416256337, "tddate": null, "forum": "1qJtBS8QF9", "replyto": "6SBGi0kbn94", "invitation": "ICLR.cc/2021/Conference/Paper154/-/Official_Comment", "content": {"title": "Response to Reviewer 1", "comment": "First of all, thank you for your valuable comments on our paper. Regarding your question of how pseudo-labels work, we used the two loss functions and accuracy graphs in the experiment to give a proof, which shows that adding pseudo-labels can indeed improve the performance of the network. As for the comparison with the contrastive learning model, since the baseline used in our paper is \"Break the ceiling: Stronger multi-scale deep graph convolutional networks.\", there is no need to compare with the contrastive learning. We will humbly adopt the advantages and disadvantages you put forward."}, "signatures": ["ICLR.cc/2021/Conference/Paper154/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper154/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Graph View-Consistent Learning Network", "authorids": ["liaozl20@lzu.edu.cn", "~Kun_Zhan1"], "authors": ["Zhuolin Liao", "Kun Zhan"], "keywords": [], "abstract": "Recent years, methods based on neural networks have made great achievements in solving large and complex graph problems. However, high efficiency of these methods depends on large training and validation sets, while the acquisition of ground-truth labels is expensive and time-consuming. In this paper, a graph view-consistent learning network (GVCLN) is specially designed for the semi-supervised learning when the number of the labeled samples is very small. We fully exploit the neighborhood aggregation capability of GVCLN and use dual views to obtain different representations. Although the two views have different viewing angles, their observation objects are the same, so their observation representations need to be consistent. For view-consistent representations between two views, two loss functions are designed besides a supervised loss. The supervised loss uses the known labeled set, while a view-consistent loss is applied to the two views to obtain the consistent representation and a pseudo-label loss is designed by using the common high-confidence predictions. GVCLN with these loss functions can obtain the view-consistent representations of the original feature. We also find that preprocessing the node features with specific filter before training is good for subsequent classification tasks. Related experiments have been done on the three citation network datasets of Cora, Citeseer, and PubMed. On several node classification tasks, GVCLN achieves state-of-the-art performance.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "liao|graph_viewconsistent_learning_network", "supplementary_material": "/attachment/0690ecf654706f560eac7692fe5387aece799984.zip", "pdf": "/pdf/990167c4e2db5d40eceeff5471753fc2e40fcdc6.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=qdx0kvVbw", "_bibtex": "@misc{\nliao2021graph,\ntitle={Graph View-Consistent Learning Network},\nauthor={Zhuolin Liao and Kun Zhan},\nyear={2021},\nurl={https://openreview.net/forum?id=1qJtBS8QF9}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "1qJtBS8QF9", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper154/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper154/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper154/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper154/Authors|ICLR.cc/2021/Conference/Paper154/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper154/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923874049, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper154/-/Official_Comment"}}}, {"id": "08kHSXFTv-F", "original": null, "number": 3, "cdate": 1605416223834, "ddate": null, "tcdate": 1605416223834, "tmdate": 1605416223834, "tddate": null, "forum": "1qJtBS8QF9", "replyto": "DvMEEYMXToa", "invitation": "ICLR.cc/2021/Conference/Paper154/-/Official_Comment", "content": {"title": "Response to Reviewer 4", "comment": "First of all, thank you for your valuable comments on every part of our paper, and we will pay more attention to it in future paper writing. [Introduction & Related work] We introduced some existing papers based on spectral methods and non-spectral methods, and introduced some methods related to our papers. But there is really a lack of introduction to the development of the entire graph neural network. [Model architecture] Our model uses a three-headed representation. This is because we have found in experiments that using three-headed representation and randomly discarding can make the network retain more useful representation information and prevent over-fitting. The difference between view 1 and view 2 is mainly reflected in the first half, so the final output layer, we use clique convolution layer. For the setting of the volume layer, we have a detailed introduction in the \"Settings\" of the experiment. We did not upload our code in time, this is our negligence, but we will publish our code as soon as the paper is received."}, "signatures": ["ICLR.cc/2021/Conference/Paper154/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper154/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Graph View-Consistent Learning Network", "authorids": ["liaozl20@lzu.edu.cn", "~Kun_Zhan1"], "authors": ["Zhuolin Liao", "Kun Zhan"], "keywords": [], "abstract": "Recent years, methods based on neural networks have made great achievements in solving large and complex graph problems. However, high efficiency of these methods depends on large training and validation sets, while the acquisition of ground-truth labels is expensive and time-consuming. In this paper, a graph view-consistent learning network (GVCLN) is specially designed for the semi-supervised learning when the number of the labeled samples is very small. We fully exploit the neighborhood aggregation capability of GVCLN and use dual views to obtain different representations. Although the two views have different viewing angles, their observation objects are the same, so their observation representations need to be consistent. For view-consistent representations between two views, two loss functions are designed besides a supervised loss. The supervised loss uses the known labeled set, while a view-consistent loss is applied to the two views to obtain the consistent representation and a pseudo-label loss is designed by using the common high-confidence predictions. GVCLN with these loss functions can obtain the view-consistent representations of the original feature. We also find that preprocessing the node features with specific filter before training is good for subsequent classification tasks. Related experiments have been done on the three citation network datasets of Cora, Citeseer, and PubMed. On several node classification tasks, GVCLN achieves state-of-the-art performance.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "liao|graph_viewconsistent_learning_network", "supplementary_material": "/attachment/0690ecf654706f560eac7692fe5387aece799984.zip", "pdf": "/pdf/990167c4e2db5d40eceeff5471753fc2e40fcdc6.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=qdx0kvVbw", "_bibtex": "@misc{\nliao2021graph,\ntitle={Graph View-Consistent Learning Network},\nauthor={Zhuolin Liao and Kun Zhan},\nyear={2021},\nurl={https://openreview.net/forum?id=1qJtBS8QF9}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "1qJtBS8QF9", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper154/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper154/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper154/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper154/Authors|ICLR.cc/2021/Conference/Paper154/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper154/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923874049, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper154/-/Official_Comment"}}}, {"id": "H0X9-xH8ZG1", "original": null, "number": 1, "cdate": 1603725842552, "ddate": null, "tcdate": 1603725842552, "tmdate": 1605024752592, "tddate": null, "forum": "1qJtBS8QF9", "replyto": "1qJtBS8QF9", "invitation": "ICLR.cc/2021/Conference/Paper154/-/Official_Review", "content": {"title": "Official review", "review": "[Summary]\nIn this paper, a graph view-consistent learning framework (GVCLN) is proposed. Specifically, two view learners are used to give predictions for the input. Then, a consistency loss is employed to force the two viewers giving the same predictions. Moreover, a co-training scheme is proposed to alleviate the label sparsity problem.\n\n[Pros]\n+ This paper is easy to follow.\n\n[Cons]\n- The novelty of this work is limited. It seems that this work is a simple combination of [1] and [2], with slight modification. Also, the authors are suggested to include more baselines, especially augmentation-based methods, e.g., [3].\n- Three studied datasets are of small scales, which are well know to have unstable results.\n- It is not clear how to select high-confidence pseudo labels. More experiments, e.g., parameter sensitivity analysis wrt the confidence threshold, ablation studies of the two loss, are needed.\n\n[Evaluation]\nOverall this paper presents a simple yet effective framework to semi-supervised node classification. However, the novelty of this work is limited and more experiments are necessary.\n\n[Ref]\n[1] A Simple Framework for Contrastive Learning of Visual Representations, in ICML, 2020\n\n[2] Multi-Stage Self-Supervised Learning for Graph Convolutional Networks on Graphs with Few Labeled Nodes, in AAAI, 2020\n\n[3] NodeAug: Semi-Supervised Node Classification with Data Augmentation, in KDD, 2020\n", "rating": "3: Clear rejection", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["ICLR.cc/2021/Conference/Paper154/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper154/AnonReviewer2"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Graph View-Consistent Learning Network", "authorids": ["liaozl20@lzu.edu.cn", "~Kun_Zhan1"], "authors": ["Zhuolin Liao", "Kun Zhan"], "keywords": [], "abstract": "Recent years, methods based on neural networks have made great achievements in solving large and complex graph problems. However, high efficiency of these methods depends on large training and validation sets, while the acquisition of ground-truth labels is expensive and time-consuming. In this paper, a graph view-consistent learning network (GVCLN) is specially designed for the semi-supervised learning when the number of the labeled samples is very small. We fully exploit the neighborhood aggregation capability of GVCLN and use dual views to obtain different representations. Although the two views have different viewing angles, their observation objects are the same, so their observation representations need to be consistent. For view-consistent representations between two views, two loss functions are designed besides a supervised loss. The supervised loss uses the known labeled set, while a view-consistent loss is applied to the two views to obtain the consistent representation and a pseudo-label loss is designed by using the common high-confidence predictions. GVCLN with these loss functions can obtain the view-consistent representations of the original feature. We also find that preprocessing the node features with specific filter before training is good for subsequent classification tasks. Related experiments have been done on the three citation network datasets of Cora, Citeseer, and PubMed. On several node classification tasks, GVCLN achieves state-of-the-art performance.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "liao|graph_viewconsistent_learning_network", "supplementary_material": "/attachment/0690ecf654706f560eac7692fe5387aece799984.zip", "pdf": "/pdf/990167c4e2db5d40eceeff5471753fc2e40fcdc6.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=qdx0kvVbw", "_bibtex": "@misc{\nliao2021graph,\ntitle={Graph View-Consistent Learning Network},\nauthor={Zhuolin Liao and Kun Zhan},\nyear={2021},\nurl={https://openreview.net/forum?id=1qJtBS8QF9}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq . ***Please remember to file the Code-of-Ethics report. Once you submitted the review, a link to the report will be visible in the bottom right corner of your review.***", "required": true, "markdown": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}, "forum": "1qJtBS8QF9", "replyto": "1qJtBS8QF9", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"], "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper154/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1607428800000, "duedate": 1606752000000, "multiReply": false, "readers": ["everyone"], "tcdate": 1602538149256, "tmdate": 1606915810879, "super": "ICLR.cc/2021/Conference/-/Official_Review", "signatures": ["OpenReview.net"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Paper154/Reviewers", "OpenReview.net/Support"], "id": "ICLR.cc/2021/Conference/Paper154/-/Official_Review"}}}, {"id": "wXZ7TGmPGLR", "original": null, "number": 2, "cdate": 1603766551696, "ddate": null, "tcdate": 1603766551696, "tmdate": 1605024752530, "tddate": null, "forum": "1qJtBS8QF9", "replyto": "1qJtBS8QF9", "invitation": "ICLR.cc/2021/Conference/Paper154/-/Official_Review", "content": {"title": "This paper tries to address the limited training data problem by exploiting the consistency between different views of the graph data. However, important details and justification are missing.", "review": "This paper tries to address the limited training data problem by exploiting the consistency between different views of the graph data. However, important details and justification are missing. The major problems are:\n\n(1)\tThe proposed model lacks detailed explanation and justification. How do you generate the view for the graph from its features? How and why do you obtain three head representations using graph convolution or graph attention? Why using convolution and attention for the two views respectively? How do you do dropout? Why using the same graph convolution layer later for the two views? After seven lines of introduction of the model, the paper is focused on training, and leave all the above questions behind.\n(2)\tFor training, how do you judge \u02cb\u02cbhigh confidence predictions\u2019\u2019 for generating pseudo-labels? What do you mean by \u02cb\u02cbthe same prediction representations\u2019\u2019, \u02cb\u02cbverification set\u2019\u2019 and \u02cb\u02cblabel rates\u2019\u2019? Moreover, with limited training data, how do you obtain \u02cb\u02cbwell trained\u2019\u2019 two-view networks? What is the \u02cb\u02cbstop condition\u2019\u2019, simply max epochs?\n(3)\tThe authors give some settings of parameters and say that the other parameters are specified in the appendix. However, after references there is no appendix.\n\nTo summarize, without justification, the proposed model is not convincing. Without details of the model and implementation, this work is difficult to reproduce.\n", "rating": "3: Clear rejection", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["ICLR.cc/2021/Conference/Paper154/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper154/AnonReviewer3"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Graph View-Consistent Learning Network", "authorids": ["liaozl20@lzu.edu.cn", "~Kun_Zhan1"], "authors": ["Zhuolin Liao", "Kun Zhan"], "keywords": [], "abstract": "Recent years, methods based on neural networks have made great achievements in solving large and complex graph problems. However, high efficiency of these methods depends on large training and validation sets, while the acquisition of ground-truth labels is expensive and time-consuming. In this paper, a graph view-consistent learning network (GVCLN) is specially designed for the semi-supervised learning when the number of the labeled samples is very small. We fully exploit the neighborhood aggregation capability of GVCLN and use dual views to obtain different representations. Although the two views have different viewing angles, their observation objects are the same, so their observation representations need to be consistent. For view-consistent representations between two views, two loss functions are designed besides a supervised loss. The supervised loss uses the known labeled set, while a view-consistent loss is applied to the two views to obtain the consistent representation and a pseudo-label loss is designed by using the common high-confidence predictions. GVCLN with these loss functions can obtain the view-consistent representations of the original feature. We also find that preprocessing the node features with specific filter before training is good for subsequent classification tasks. Related experiments have been done on the three citation network datasets of Cora, Citeseer, and PubMed. On several node classification tasks, GVCLN achieves state-of-the-art performance.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "liao|graph_viewconsistent_learning_network", "supplementary_material": "/attachment/0690ecf654706f560eac7692fe5387aece799984.zip", "pdf": "/pdf/990167c4e2db5d40eceeff5471753fc2e40fcdc6.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=qdx0kvVbw", "_bibtex": "@misc{\nliao2021graph,\ntitle={Graph View-Consistent Learning Network},\nauthor={Zhuolin Liao and Kun Zhan},\nyear={2021},\nurl={https://openreview.net/forum?id=1qJtBS8QF9}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq . ***Please remember to file the Code-of-Ethics report. Once you submitted the review, a link to the report will be visible in the bottom right corner of your review.***", "required": true, "markdown": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}, "forum": "1qJtBS8QF9", "replyto": "1qJtBS8QF9", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"], "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper154/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1607428800000, "duedate": 1606752000000, "multiReply": false, "readers": ["everyone"], "tcdate": 1602538149256, "tmdate": 1606915810879, "super": "ICLR.cc/2021/Conference/-/Official_Review", "signatures": ["OpenReview.net"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Paper154/Reviewers", "OpenReview.net/Support"], "id": "ICLR.cc/2021/Conference/Paper154/-/Official_Review"}}}, {"id": "DvMEEYMXToa", "original": null, "number": 4, "cdate": 1604036861570, "ddate": null, "tcdate": 1604036861570, "tmdate": 1605024752451, "tddate": null, "forum": "1qJtBS8QF9", "replyto": "1qJtBS8QF9", "invitation": "ICLR.cc/2021/Conference/Paper154/-/Official_Review", "content": {"title": "Lack of innovation and lack of clear architecture analysis", "review": "This paper proposes a view-consistent framework to address the issues of expensive labels. In particular, this work first uses graph neural networks and graph attention networks to construct two different latent features of the same data. Then, it uses the same classification neural networks to produce the node classification outcomes. Finally, it uses the classification outcome to construct a so-called \"view loss\". In addition, it uses an incremental strategy to gradually included pseudo labels until some termination conditions are satisfied. \n\nOverall, the paper is easy to understood. However, I think the paper can be improved in each sections:\n[Introduction & Related work]\nThe authors can better organize their presentation on the development and understanding of Graph Neural Networks. At the current stage, these content does not seem to connect to the current development of GNN. \n\n[Model architecture]\n3.1\n1, can the authors explain the reason of using three-head representation? Also, why do the authors use the same non-linear graph convolution layers? Is it because the feature is different already? Can the authors specify the detail settings on this graph convolution layers? I did not find it in other places?\n\n3.2\n2, I can roughly understand the reason of introducing the contrastive learning and co-training. However, maybe the authors should put of the content in the related work part and emphasise the difference of view-consistent algorithm from these two methods. Plus, I did not find experiments that uses the data augmentation method (instead of the view-consistent method). I can see there is contrast learning comparison, however, the other settings of constrast learning may be different?\n3, the inclusion of pseudo labels are not well explained in this section. I was expecting to see more systematic analysis on this procedure, however, the current version can not fully convince me on this procedure. \n4, small issues: view 1 and viewer 1 are both used in the paper and they should be consistent. Eq. (5) and Eq. (6) can be well formatted to save more space for presentation. \n\n[Experiments]\n5, I am expecting to see the implementation code for at least the neural network specification in the main paper or supplementary material. However, they are missing. \n", "rating": "4: Ok but not good enough - rejection", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["ICLR.cc/2021/Conference/Paper154/AnonReviewer4"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper154/AnonReviewer4"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Graph View-Consistent Learning Network", "authorids": ["liaozl20@lzu.edu.cn", "~Kun_Zhan1"], "authors": ["Zhuolin Liao", "Kun Zhan"], "keywords": [], "abstract": "Recent years, methods based on neural networks have made great achievements in solving large and complex graph problems. However, high efficiency of these methods depends on large training and validation sets, while the acquisition of ground-truth labels is expensive and time-consuming. In this paper, a graph view-consistent learning network (GVCLN) is specially designed for the semi-supervised learning when the number of the labeled samples is very small. We fully exploit the neighborhood aggregation capability of GVCLN and use dual views to obtain different representations. Although the two views have different viewing angles, their observation objects are the same, so their observation representations need to be consistent. For view-consistent representations between two views, two loss functions are designed besides a supervised loss. The supervised loss uses the known labeled set, while a view-consistent loss is applied to the two views to obtain the consistent representation and a pseudo-label loss is designed by using the common high-confidence predictions. GVCLN with these loss functions can obtain the view-consistent representations of the original feature. We also find that preprocessing the node features with specific filter before training is good for subsequent classification tasks. Related experiments have been done on the three citation network datasets of Cora, Citeseer, and PubMed. On several node classification tasks, GVCLN achieves state-of-the-art performance.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "liao|graph_viewconsistent_learning_network", "supplementary_material": "/attachment/0690ecf654706f560eac7692fe5387aece799984.zip", "pdf": "/pdf/990167c4e2db5d40eceeff5471753fc2e40fcdc6.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=qdx0kvVbw", "_bibtex": "@misc{\nliao2021graph,\ntitle={Graph View-Consistent Learning Network},\nauthor={Zhuolin Liao and Kun Zhan},\nyear={2021},\nurl={https://openreview.net/forum?id=1qJtBS8QF9}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq . ***Please remember to file the Code-of-Ethics report. Once you submitted the review, a link to the report will be visible in the bottom right corner of your review.***", "required": true, "markdown": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}, "forum": "1qJtBS8QF9", "replyto": "1qJtBS8QF9", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"], "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper154/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1607428800000, "duedate": 1606752000000, "multiReply": false, "readers": ["everyone"], "tcdate": 1602538149256, "tmdate": 1606915810879, "super": "ICLR.cc/2021/Conference/-/Official_Review", "signatures": ["OpenReview.net"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Paper154/Reviewers", "OpenReview.net/Support"], "id": "ICLR.cc/2021/Conference/Paper154/-/Official_Review"}}}, {"id": "6SBGi0kbn94", "original": null, "number": 3, "cdate": 1603984049117, "ddate": null, "tcdate": 1603984049117, "tmdate": 1605024752372, "tddate": null, "forum": "1qJtBS8QF9", "replyto": "1qJtBS8QF9", "invitation": "ICLR.cc/2021/Conference/Paper154/-/Official_Review", "content": {"title": "A multi-view learning approach for inferring graph representation with incremental improvement in performance", "review": "This paper adopts a multi-view learning approach for graph representation learning where some labels are assumed to be available. It uses graph convolution network (GCN) and graph attention network (GAT) to create two different views of the same graph and then define a loss function to force the output due to the two views to be consistent. The low label rate scenario is considered and pseudo labels are created to define an additional loss function to better enforce consistency. Three datasets are used for performance evaluation.\n\nPros:\n- The problem addressed is an important one.\n- The problem formulation is a reasonable one.\n- The paper is clearly presented in general.\n\nCons:\n- The view-consistency idea is good but not particularly new. The two graph \u201cviews\u201d are based on existing graph embedding methods. So, I consider the originality of this work is limited.\n- Only incremental improvement in performance is demonstrated in the experimental results.\n- The graphs being evaluated are not particularly large.\n\nComments:\n- In Eq 7, the two terms for supervised loss l_sup^(1) and l_sup^(2) are not clearly defined.\n\nQn:\n- In the conclusion, there is some discussion about how pseudo labels contribute. It will be interesting to see how crucial the pseudo label term contributes to the overall the performance. \n- How will the proposed method be compared with some contrastive learning in terms of performance?\n\n", "rating": "4: Ok but not good enough - rejection", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}, "signatures": ["ICLR.cc/2021/Conference/Paper154/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper154/AnonReviewer1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Graph View-Consistent Learning Network", "authorids": ["liaozl20@lzu.edu.cn", "~Kun_Zhan1"], "authors": ["Zhuolin Liao", "Kun Zhan"], "keywords": [], "abstract": "Recent years, methods based on neural networks have made great achievements in solving large and complex graph problems. However, high efficiency of these methods depends on large training and validation sets, while the acquisition of ground-truth labels is expensive and time-consuming. In this paper, a graph view-consistent learning network (GVCLN) is specially designed for the semi-supervised learning when the number of the labeled samples is very small. We fully exploit the neighborhood aggregation capability of GVCLN and use dual views to obtain different representations. Although the two views have different viewing angles, their observation objects are the same, so their observation representations need to be consistent. For view-consistent representations between two views, two loss functions are designed besides a supervised loss. The supervised loss uses the known labeled set, while a view-consistent loss is applied to the two views to obtain the consistent representation and a pseudo-label loss is designed by using the common high-confidence predictions. GVCLN with these loss functions can obtain the view-consistent representations of the original feature. We also find that preprocessing the node features with specific filter before training is good for subsequent classification tasks. Related experiments have been done on the three citation network datasets of Cora, Citeseer, and PubMed. On several node classification tasks, GVCLN achieves state-of-the-art performance.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "liao|graph_viewconsistent_learning_network", "supplementary_material": "/attachment/0690ecf654706f560eac7692fe5387aece799984.zip", "pdf": "/pdf/990167c4e2db5d40eceeff5471753fc2e40fcdc6.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=qdx0kvVbw", "_bibtex": "@misc{\nliao2021graph,\ntitle={Graph View-Consistent Learning Network},\nauthor={Zhuolin Liao and Kun Zhan},\nyear={2021},\nurl={https://openreview.net/forum?id=1qJtBS8QF9}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq . ***Please remember to file the Code-of-Ethics report. Once you submitted the review, a link to the report will be visible in the bottom right corner of your review.***", "required": true, "markdown": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}, "forum": "1qJtBS8QF9", "replyto": "1qJtBS8QF9", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"], "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper154/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1607428800000, "duedate": 1606752000000, "multiReply": false, "readers": ["everyone"], "tcdate": 1602538149256, "tmdate": 1606915810879, "super": "ICLR.cc/2021/Conference/-/Official_Review", "signatures": ["OpenReview.net"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Paper154/Reviewers", "OpenReview.net/Support"], "id": "ICLR.cc/2021/Conference/Paper154/-/Official_Review"}}}, {"id": "TiTlgrvK1lN", "original": null, "number": 5, "cdate": 1604608286808, "ddate": null, "tcdate": 1604608286808, "tmdate": 1605024752311, "tddate": null, "forum": "1qJtBS8QF9", "replyto": "1qJtBS8QF9", "invitation": "ICLR.cc/2021/Conference/Paper154/-/Official_Review", "content": {"title": "A multi-view contrastive learning framework for node classification with fewer labels.", "review": "Advantage:\n\nThe paper concentrated on an important perspective of graph learning: to utilize a small number of labels for large-scale graph learning. The framework is well demonstrated and the paper is easy to follow. \n\nWeakness:\n\n1. Novelty: My main concern of the paper is about the paper's novelty. There are already some works having similar multi-view contrastive learning frameworks, such as [1]. `Besides, The learning loss of the proposed method is similar to the self-training loss in SimCLR v2 [2].\n\n2. Experiment: The experiment results are not sufficient. The author claimed the proposed method is efficient for graph classification on large training datasets. But the experiment is conducted on three small graph datasets. Results on more larger datasets [3] are expected to support the effectiveness of the proposed method.\n\nReference:\n[1] Contrastive Multi-View Representation Learning on Graphs, ICML 2020\n[2] Big Self-Supervised Models are Strong Semi-Supervised Learners, NeurIPS 2020\n[3] Open Graph Benchmark: Datasets for Machine Learning on Graphs", "rating": "5: Marginally below acceptance threshold", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}, "signatures": ["ICLR.cc/2021/Conference/Paper154/AnonReviewer5"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper154/AnonReviewer5"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Graph View-Consistent Learning Network", "authorids": ["liaozl20@lzu.edu.cn", "~Kun_Zhan1"], "authors": ["Zhuolin Liao", "Kun Zhan"], "keywords": [], "abstract": "Recent years, methods based on neural networks have made great achievements in solving large and complex graph problems. However, high efficiency of these methods depends on large training and validation sets, while the acquisition of ground-truth labels is expensive and time-consuming. In this paper, a graph view-consistent learning network (GVCLN) is specially designed for the semi-supervised learning when the number of the labeled samples is very small. We fully exploit the neighborhood aggregation capability of GVCLN and use dual views to obtain different representations. Although the two views have different viewing angles, their observation objects are the same, so their observation representations need to be consistent. For view-consistent representations between two views, two loss functions are designed besides a supervised loss. The supervised loss uses the known labeled set, while a view-consistent loss is applied to the two views to obtain the consistent representation and a pseudo-label loss is designed by using the common high-confidence predictions. GVCLN with these loss functions can obtain the view-consistent representations of the original feature. We also find that preprocessing the node features with specific filter before training is good for subsequent classification tasks. Related experiments have been done on the three citation network datasets of Cora, Citeseer, and PubMed. On several node classification tasks, GVCLN achieves state-of-the-art performance.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "liao|graph_viewconsistent_learning_network", "supplementary_material": "/attachment/0690ecf654706f560eac7692fe5387aece799984.zip", "pdf": "/pdf/990167c4e2db5d40eceeff5471753fc2e40fcdc6.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=qdx0kvVbw", "_bibtex": "@misc{\nliao2021graph,\ntitle={Graph View-Consistent Learning Network},\nauthor={Zhuolin Liao and Kun Zhan},\nyear={2021},\nurl={https://openreview.net/forum?id=1qJtBS8QF9}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq . ***Please remember to file the Code-of-Ethics report. Once you submitted the review, a link to the report will be visible in the bottom right corner of your review.***", "required": true, "markdown": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}, "forum": "1qJtBS8QF9", "replyto": "1qJtBS8QF9", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"], "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper154/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1607428800000, "duedate": 1606752000000, "multiReply": false, "readers": ["everyone"], "tcdate": 1602538149256, "tmdate": 1606915810879, "super": "ICLR.cc/2021/Conference/-/Official_Review", "signatures": ["OpenReview.net"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Paper154/Reviewers", "OpenReview.net/Support"], "id": "ICLR.cc/2021/Conference/Paper154/-/Official_Review"}}}], "count": 12}