{"notes": [{"tddate": null, "ddate": null, "original": null, "tmdate": 1521573621476, "tcdate": 1521573621476, "number": 329, "cdate": 1521573621107, "id": "Skpxy115f", "invitation": "ICLR.cc/2018/Workshop/-/Acceptance_Decision", "forum": "Bk0xiI1Dz", "replyto": "Bk0xiI1Dz", "signatures": ["ICLR.cc/2018/Workshop/Program_Chairs"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Workshop/Program_Chairs"], "content": {"decision": "Accept", "title": "ICLR 2018 Workshop Acceptance Decision", "comment": "This paper was invited to the workshop track based on reviews at the main conference."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Exploring Deep Recurrent Models with Reinforcement Learning for Molecule Design", "abstract": "The design of small molecules with bespoke properties is of central importance to drug discovery.  However significant challenges yet remain for computational methods, despite recent advances such as deep recurrent networks and reinforcement learning strategies for sequence generation, and it can be difficult to compare results across different works.  This work proposes 19 benchmarks selected by subject experts, expands smaller datasets previously used to approximately 1.1 million training molecules, and explores how to apply new reinforcement learning techniques effectively for molecular design.  The benchmarks here, built as OpenAI Gym environments, will be open-sourced to encourage innovation in molecular design algorithms and to enable usage by those without a background in chemistry.  Finally, this work explores recent development in reinforcement-learning methods with excellent sample complexity (the A2C and PPO algorithms) and investigates their behavior in molecular generation, demonstrating significant performance gains compared to standard reinforcement learning techniques.", "pdf": "/pdf/0fc7d6e230f9a413cf9d08d7cf9273f4a8affb4f.pdf", "TL;DR": "We investigate a variety of RL algorithms for molecular generation and define new benchmarks (to be released as an OpenAI Gym), finding PPO and a hill-climbing MLE algorithm work best.", "paperhash": "neil|exploring_deep_recurrent_models_with_reinforcement_learning_for_molecule_design", "_bibtex": "@misc{\nneil2018exploring,\ntitle={Exploring Deep Recurrent Models with Reinforcement Learning for Molecule Design},\nauthor={Daniel Neil, Marwin Segler, Laura Guasch, Mohamed Ahmed, Dean Plumbley, Matthew Sellwood, Nathan Brown},\nyear={2018},\nurl={https://openreview.net/forum?id=HkcTe-bR-},\n}", "keywords": ["reinforcement learning", "molecule design", "de novo design", "ppo", "sample-efficient reinforcement learning", "chemistry"], "authors": ["Daniel Neil", "Marwin Segler", "Laura Guasch", "Mohamed Ahmed", "Dean Plumbley", "Matthew Sellwood", "Nathan Brown"], "authorids": ["daniel.neil@benevolent.ai", "marwin.segler@benevolent.ai", "laura.guasch@benevolent.ai", "mohamed.ahmed@benevolent.ai", "dean.plumbley@benevolent.ai", "matthew.sellwood@benevolent.ai", "nathan.brown@benevolent.ai"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "tmdate": 1518629844880, "id": "ICLR.cc/2018/Workshop/-/Acceptance_Decision", "writers": ["ICLR.cc/2018/Workshop"], "signatures": ["ICLR.cc/2018/Workshop"], "readers": ["everyone"], "invitees": ["ICLR.cc/2018/Workshop/Program_Chairs"], "reply": {"forum": null, "replyto": null, "invitation": "ICLR.cc/2018/Workshop/-/Submission", "writers": {"values": ["ICLR.cc/2018/Workshop/Program_Chairs"]}, "signatures": {"description": "How your identity will be displayed with the above content.", "values": ["ICLR.cc/2018/Workshop/Program_Chairs"]}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["ICLR.cc/2018/Workshop/Program_Chairs", "everyone"]}, "content": {"title": {"required": true, "order": 1, "value": "ICLR 2018 Workshop Acceptance Decision"}, "comment": {"required": false, "order": 3, "description": "(optional) Comment on this decision.", "value-regex": "[\\S\\s]{0,5000}"}, "decision": {"required": true, "order": 2, "value-dropdown": ["Accept", "Reject"]}}}, "nonreaders": [], "noninvitees": [], "cdate": 1518629844880}}}, {"tddate": null, "ddate": null, "tmdate": 1518730170125, "tcdate": 1518459638241, "number": 191, "cdate": 1518459638241, "id": "Bk0xiI1Dz", "invitation": "ICLR.cc/2018/Workshop/-/Submission", "forum": "Bk0xiI1Dz", "original": "HkcTe-bR-", "signatures": ["ICLR.cc/2018/Workshop"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Workshop"], "content": {"title": "Exploring Deep Recurrent Models with Reinforcement Learning for Molecule Design", "abstract": "The design of small molecules with bespoke properties is of central importance to drug discovery.  However significant challenges yet remain for computational methods, despite recent advances such as deep recurrent networks and reinforcement learning strategies for sequence generation, and it can be difficult to compare results across different works.  This work proposes 19 benchmarks selected by subject experts, expands smaller datasets previously used to approximately 1.1 million training molecules, and explores how to apply new reinforcement learning techniques effectively for molecular design.  The benchmarks here, built as OpenAI Gym environments, will be open-sourced to encourage innovation in molecular design algorithms and to enable usage by those without a background in chemistry.  Finally, this work explores recent development in reinforcement-learning methods with excellent sample complexity (the A2C and PPO algorithms) and investigates their behavior in molecular generation, demonstrating significant performance gains compared to standard reinforcement learning techniques.", "pdf": "/pdf/0fc7d6e230f9a413cf9d08d7cf9273f4a8affb4f.pdf", "TL;DR": "We investigate a variety of RL algorithms for molecular generation and define new benchmarks (to be released as an OpenAI Gym), finding PPO and a hill-climbing MLE algorithm work best.", "paperhash": "neil|exploring_deep_recurrent_models_with_reinforcement_learning_for_molecule_design", "_bibtex": "@misc{\nneil2018exploring,\ntitle={Exploring Deep Recurrent Models with Reinforcement Learning for Molecule Design},\nauthor={Daniel Neil, Marwin Segler, Laura Guasch, Mohamed Ahmed, Dean Plumbley, Matthew Sellwood, Nathan Brown},\nyear={2018},\nurl={https://openreview.net/forum?id=HkcTe-bR-},\n}", "keywords": ["reinforcement learning", "molecule design", "de novo design", "ppo", "sample-efficient reinforcement learning", "chemistry"], "authors": ["Daniel Neil", "Marwin Segler", "Laura Guasch", "Mohamed Ahmed", "Dean Plumbley", "Matthew Sellwood", "Nathan Brown"], "authorids": ["daniel.neil@benevolent.ai", "marwin.segler@benevolent.ai", "laura.guasch@benevolent.ai", "mohamed.ahmed@benevolent.ai", "dean.plumbley@benevolent.ai", "matthew.sellwood@benevolent.ai", "nathan.brown@benevolent.ai"]}, "nonreaders": [], "details": {"replyCount": 1, "writable": false, "overwriting": [], "revisions": true, "tags": [], "original": {"tddate": null, "ddate": null, "tmdate": 1518730170125, "tcdate": 1509130433985, "number": 646, "cdate": 1518730170113, "id": "HkcTe-bR-", "invitation": "ICLR.cc/2018/Conference/-/Blind_Submission", "forum": "HkcTe-bR-", "original": "SkY6xZWR-", "signatures": ["ICLR.cc/2018/Conference"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Conference"], "content": {"title": "Exploring Deep Recurrent Models with Reinforcement Learning for Molecule Design", "abstract": "The design of small molecules with bespoke properties is of central importance to drug discovery.  However significant challenges yet remain for computational methods, despite recent advances such as deep recurrent networks and reinforcement learning strategies for sequence generation, and it can be difficult to compare results across different works.  This work proposes 19 benchmarks selected by subject experts, expands smaller datasets previously used to approximately 1.1 million training molecules, and explores how to apply new reinforcement learning techniques effectively for molecular design.  The benchmarks here, built as OpenAI Gym environments, will be open-sourced to encourage innovation in molecular design algorithms and to enable usage by those without a background in chemistry.  Finally, this work explores recent development in reinforcement-learning methods with excellent sample complexity (the A2C and PPO algorithms) and investigates their behavior in molecular generation, demonstrating significant performance gains compared to standard reinforcement learning techniques.", "pdf": "/pdf/5d588e627b43b3439f7fef2564614907bc5766ca.pdf", "TL;DR": "We investigate a variety of RL algorithms for molecular generation and define new benchmarks (to be released as an OpenAI Gym), finding PPO and a hill-climbing MLE algorithm work best.", "paperhash": "neil|exploring_deep_recurrent_models_with_reinforcement_learning_for_molecule_design", "_bibtex": "@misc{\nneil2018exploring,\ntitle={Exploring Deep Recurrent Models with Reinforcement Learning for Molecule Design},\nauthor={Daniel Neil and Marwin Segler and Laura Guasch and Mohamed Ahmed and Dean Plumbley and Matthew Sellwood and Nathan Brown},\nyear={2018},\nurl={https://openreview.net/forum?id=HkcTe-bR-},\n}", "keywords": ["reinforcement learning", "molecule design", "de novo design", "ppo", "sample-efficient reinforcement learning"], "authors": ["Daniel Neil", "Marwin Segler", "Laura Guasch", "Mohamed Ahmed", "Dean Plumbley", "Matthew Sellwood", "Nathan Brown"], "authorids": ["daniel.neil@benevolent.ai", "marwin.segler@benevolent.ai", "laura.guasch@benevolent.ai", "mohamed.ahmed@benevolent.ai", "dean.plumbley@benevolent.ai", "matthew.sellwood@benevolent.ai", "nathan.brown@benevolent.ai"]}, "nonreaders": []}, "originalWritable": false, "originalInvitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "tmdate": 1506717071958, "id": "ICLR.cc/2018/Conference/-/Blind_Submission", "writers": ["ICLR.cc/2018/Conference"], "signatures": ["ICLR.cc/2018/Conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2018/Conference"], "reply": {"forum": null, "replyto": null, "writers": {"values": ["ICLR.cc/2018/Conference"]}, "signatures": {"description": "How your identity will be displayed with the above content.", "values": ["ICLR.cc/2018/Conference"]}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"authors": {"required": false, "order": 1, "values-regex": ".*", "description": "Comma separated list of author names, as they appear in the paper."}, "authorids": {"required": false, "order": 2, "values-regex": ".*", "description": "Comma separated list of author email addresses, in the same order as above."}}}, "nonreaders": [], "noninvitees": [], "cdate": 1506717071958}, "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1518472800000, "tmdate": 1518474081690, "id": "ICLR.cc/2018/Workshop/-/Submission", "writers": ["ICLR.cc/2018/Workshop"], "signatures": ["ICLR.cc/2018/Workshop"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": null, "replyto": null, "writers": {"values": ["ICLR.cc/2018/Workshop"]}, "signatures": {"values-regex": "~.*|ICLR.cc/2018/Workshop", "description": "Your authorized identity to be associated with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"pdf": {"required": true, "order": 9, "value-regex": "upload", "description": "Upload a PDF file that ends with .pdf"}, "title": {"required": true, "order": 1, "description": "Title of paper.", "value-regex": ".{1,250}"}, "abstract": {"required": true, "order": 8, "description": "Abstract of paper.", "value-regex": "[\\S\\s]{1,5000}"}, "authors": {"required": true, "order": 2, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of author names. Please provide real names; identities will be anonymized."}, "keywords": {"order": 6, "values-regex": "(^$)|[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of keywords."}, "TL;DR": {"required": false, "order": 7, "description": "\"Too Long; Didn't Read\": a short sentence describing your paper", "value-regex": "[^\\n]{0,500}"}, "authorids": {"required": true, "order": 3, "values-regex": "([a-z0-9_\\-\\.]{2,}@[a-z0-9_\\-\\.]{2,}\\.[a-z]{2,},){0,}([a-z0-9_\\-\\.]{2,}@[a-z0-9_\\-\\.]{2,}\\.[a-z]{2,})", "description": "Comma separated list of author email addresses, lowercased, in the same order as above. For authors with existing OpenReview accounts, please make sure that the provided email address(es) match those listed in the author's profile. Please provide real emails; identities will be anonymized."}}}, "nonreaders": [], "noninvitees": [], "expdate": 1526248800000, "cdate": 1518474081690}}, "tauthor": "ICLR.cc/2018/Workshop"}], "count": 2}