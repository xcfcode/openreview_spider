{"notes": [{"id": "Ig-VyQc-MLK", "original": "xQEZ0gjDabR", "number": 5, "cdate": 1601308009897, "ddate": null, "tcdate": 1601308009897, "tmdate": 1611607663865, "tddate": null, "forum": "Ig-VyQc-MLK", "replyto": null, "invitation": "ICLR.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Pruning Neural Networks at Initialization: Why Are We Missing the Mark?", "authorids": ["~Jonathan_Frankle1", "~Gintare_Karolina_Dziugaite1", "~Daniel_Roy1", "~Michael_Carbin1"], "authors": ["Jonathan Frankle", "Gintare Karolina Dziugaite", "Daniel Roy", "Michael Carbin"], "keywords": ["Pruning", "Sparsity", "Lottery Ticket", "Science"], "abstract": "Recent work has explored the possibility of pruning neural networks at initialization. We assess proposals for doing so: SNIP (Lee et al., 2019), GraSP (Wang et al., 2020), SynFlow (Tanaka et al., 2020), and magnitude pruning. Although these methods surpass the trivial baseline of random pruning, they remain below the accuracy of magnitude pruning after training, and we endeavor to understand why. We show that, unlike pruning after training, randomly shuffling the weights these methods prune within each layer or sampling new initial values preserves or improves accuracy. As such, the per-weight pruning decisions made by these methods can be replaced by a per-layer choice of the fraction of weights to prune. This property suggests broader challenges with the underlying pruning heuristics, the desire to prune at initialization, or both.", "one-sentence_summary": "Methods for pruning neural nets at initialization perform the same or better when shuffling or reinitializing the weights they prune in each layer, a way in which they differ from SOTA weight-pruning methods after training.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "frankle|pruning_neural_networks_at_initialization_why_are_we_missing_the_mark", "supplementary_material": "/attachment/53da61b6607bb8f4e57707d3ae1dbba3d15d52f3.zip", "pdf": "/pdf/f6ac2e779528102e5a404479ffdebc7aa54decd9.pdf", "venueid": "ICLR.cc/2021/Conference", "venue": "ICLR 2021 Poster", "_bibtex": "@inproceedings{\nfrankle2021pruning,\ntitle={Pruning Neural Networks at Initialization: Why Are We Missing the Mark?},\nauthor={Jonathan Frankle and Gintare Karolina Dziugaite and Daniel Roy and Michael Carbin},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=Ig-VyQc-MLK}\n}"}, "signatures": ["ICLR.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference"], "details": {"replyCount": 14, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"reply": {"readers": {"values-regex": ".*"}, "writers": {"values": ["ICLR.cc/2021/Conference"]}, "signatures": {"values": ["ICLR.cc/2021/Conference"]}, "content": {"authors": {"values": ["Anonymous"]}, "authorids": {"values-regex": ".*"}, "reviewed_version_(pdf)": {"required": false, "description": "Upload a PDF file that ends with .pdf", "value-regex": ".*"}}}, "signatures": ["ICLR.cc/2021/Conference"], "readers": ["everyone"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["~", "OpenReview.net/Support"], "tcdate": 1601308008205, "tmdate": 1614984599368, "id": "ICLR.cc/2021/Conference/-/Blind_Submission"}}, "tauthor": "OpenReview.net"}, {"id": "BYqCF49Ktck", "original": null, "number": 1, "cdate": 1610040402845, "ddate": null, "tcdate": 1610040402845, "tmdate": 1610473998995, "tddate": null, "forum": "Ig-VyQc-MLK", "replyto": "Ig-VyQc-MLK", "invitation": "ICLR.cc/2021/Conference/Paper5/-/Decision", "content": {"title": "Final Decision", "decision": "Accept (Poster)", "comment": "The paper analyses several approaches to pruning at initialization, compared to after training. There was a large gap in reviewers appreciation of the paper, but I think that the pros outdo the cons as the paper show a lot of insights overall. I recommend accepting the paper."}, "signatures": ["ICLR.cc/2021/Conference/Program_Chairs"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference/Program_Chairs"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Pruning Neural Networks at Initialization: Why Are We Missing the Mark?", "authorids": ["~Jonathan_Frankle1", "~Gintare_Karolina_Dziugaite1", "~Daniel_Roy1", "~Michael_Carbin1"], "authors": ["Jonathan Frankle", "Gintare Karolina Dziugaite", "Daniel Roy", "Michael Carbin"], "keywords": ["Pruning", "Sparsity", "Lottery Ticket", "Science"], "abstract": "Recent work has explored the possibility of pruning neural networks at initialization. We assess proposals for doing so: SNIP (Lee et al., 2019), GraSP (Wang et al., 2020), SynFlow (Tanaka et al., 2020), and magnitude pruning. Although these methods surpass the trivial baseline of random pruning, they remain below the accuracy of magnitude pruning after training, and we endeavor to understand why. We show that, unlike pruning after training, randomly shuffling the weights these methods prune within each layer or sampling new initial values preserves or improves accuracy. As such, the per-weight pruning decisions made by these methods can be replaced by a per-layer choice of the fraction of weights to prune. This property suggests broader challenges with the underlying pruning heuristics, the desire to prune at initialization, or both.", "one-sentence_summary": "Methods for pruning neural nets at initialization perform the same or better when shuffling or reinitializing the weights they prune in each layer, a way in which they differ from SOTA weight-pruning methods after training.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "frankle|pruning_neural_networks_at_initialization_why_are_we_missing_the_mark", "supplementary_material": "/attachment/53da61b6607bb8f4e57707d3ae1dbba3d15d52f3.zip", "pdf": "/pdf/f6ac2e779528102e5a404479ffdebc7aa54decd9.pdf", "venueid": "ICLR.cc/2021/Conference", "venue": "ICLR 2021 Poster", "_bibtex": "@inproceedings{\nfrankle2021pruning,\ntitle={Pruning Neural Networks at Initialization: Why Are We Missing the Mark?},\nauthor={Jonathan Frankle and Gintare Karolina Dziugaite and Daniel Roy and Michael Carbin},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=Ig-VyQc-MLK}\n}"}, "tags": [], "invitation": {"reply": {"forum": "Ig-VyQc-MLK", "replyto": "Ig-VyQc-MLK", "readers": {"values": ["everyone"]}, "writers": {"values": ["ICLR.cc/2021/Conference/Program_Chairs"]}, "signatures": {"values": ["ICLR.cc/2021/Conference/Program_Chairs"]}, "content": {"title": {"value": "Final Decision"}, "decision": {"value-radio": ["Accept (Oral)", "Accept (Spotlight)", "Accept (Poster)", "Reject"]}, "comment": {"value-regex": "[\\S\\s]{0,50000}", "markdown": true}}}, "multiReply": false, "signatures": ["ICLR.cc/2021/Conference"], "readers": ["everyone"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Program_Chairs"], "tcdate": 1610040402831, "tmdate": 1610473998979, "id": "ICLR.cc/2021/Conference/Paper5/-/Decision"}}}, {"id": "ksnRmL86yP", "original": null, "number": 3, "cdate": 1603923028776, "ddate": null, "tcdate": 1603923028776, "tmdate": 1606797665961, "tddate": null, "forum": "Ig-VyQc-MLK", "replyto": "Ig-VyQc-MLK", "invitation": "ICLR.cc/2021/Conference/Paper5/-/Official_Review", "content": {"title": "Official blind review #3", "review": "##########################################################################\n\nSummary:\n\nGenerating a pruned network falls into two broad categories: 1) spend some extra time and effort to train or fine-tune the pruned model after first training a dense version, or 2) cut out that extra time and effort by generating a sparse network \"from scratch.\"  While approach (1) has historically given the best accuracy, recent advances (such as the lottery ticket hypothesis) suggest that there are sparse networks hidden in the initialization that don't need to first be trained, if only we could divine the structure of those models.  Approach (2) seeks to do just this: determine the connectivity as close to initialization possible.  However, even the best results taking this second path fall short when compared to the accuracy of the former path - why is this?  The submission pokes at three recent techniques to pull out some commonalities that are *not* shared with (1), suggesting possible issues that need to be overcome to improve accuracy, and proposes a set of experiments and comparisons that should be part of any new technique that claims to discover a good sparse mask at initialization.\n\n##########################################################################\n\nReasons for score: \n\nOverall, this submission raises some important questions (why is from-scratch pruning falling short of SOTA accuracy?), empirically shows the performance of some leading techniques (and that they fall short in a well-motivated range of sparsities), and, via ablation studies, points towards some potential reasons.  More importantly, these findings are interesting:\n- There's no single SOTA method for sparse-from-scratch training\n- There's a need for consistent reporting in this area, and the ablation studies performed have been shown to lead to useful insights; adopting them as standard for future work seems fruitful.\n\nI think these are enough to warrant an \"above-the-threshold\" rating, but a higher rating would require empirical results on more networks on large-scale data sets, or the inclusion of techniques the submission itself suggests might be a promising direction forward in the current gauntlet of tests.\n\n##########################################################################\n\nPros:\n\n+ The organization of the paper makes it easy to follow the logical progression and points being raised.\n+ The direct comparisons of three recent techniques (SNIP, GraSP, and SynFlow) on different networks and data sets fills in some gaps in the literature.\n+ Further, the ablation studies performed on these techniques yield surprising results, both in isolation (inverting GraSP improves accuracy!) and when compared to magnitude pruning after training (these three are invariant to shuffling and re-initialization).\n\n##########################################################################\n\nCons:\n\n- Experiments on large data sets are limited to RN50 on ImageNet.\n- The three particular techniques chosen (SNIP, GraSP, SynFlow) aren't particularly motivated - why these three, and not other recent techniques?  (A potential answer may be that there's no training before pruning is finished, but why is this important?)\n- Mostly tongue-in-cheek: the submission doesn't answer all the questions it raises, unfortunately.\n\n##########################################################################\n\nQuestions:\n\n- What benefit do the three at-initialization \"static\" pruning techniques have over those that reduce training FLOPs and memory requirements but allow the sparse mask to change dynamically, like RigL (Evci et al., 2020) and sparse momentum (Dettmers and Zettlemoyer, 2019)?  Is there a reason they do not belong in the current lineup?  The overhead of occasionally updating the mask shouldn't be too imposing.\n\n- In the final paragraph, it is suggested that it may be tricky to compare the training cost of \"a method that prunes to sparsity s at step t against a method that prunes to sparsity s' < s at step t' > t.  If method A prunes to a higher sparsity at an earlier time step, shouldn't it cost strictly less than method B, which prunes to a lower sparsity later in training?\n\n##########################################################################\n\nMinor suggestions:\n\nFigure 2 is never referenced in the text (that I could find), and LTR isn't defined until the following page.\n\n\n##########################################################################\n\nUpdates are appreciated\n\nHi, Authors,\n\nI appreciate the updates you've made to the paper and the responses to my questions.  You're quite correct that RN50 and ImageNet is sufficient to illustrate deficiencies.\n\n(I'd still want to see broader experiments for claims of some new method overcoming these deficiencies, though!  When broadening scope to other tasks, I'd expect the authors of prior methods designed for vision tasks would be okay with use of their methods as baselines if there are no methods designed specifically for those new tasks.)\n\nWith this in mind, I'll update my rating to a 7.", "rating": "7: Good paper, accept", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "signatures": ["ICLR.cc/2021/Conference/Paper5/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper5/AnonReviewer3"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Pruning Neural Networks at Initialization: Why Are We Missing the Mark?", "authorids": ["~Jonathan_Frankle1", "~Gintare_Karolina_Dziugaite1", "~Daniel_Roy1", "~Michael_Carbin1"], "authors": ["Jonathan Frankle", "Gintare Karolina Dziugaite", "Daniel Roy", "Michael Carbin"], "keywords": ["Pruning", "Sparsity", "Lottery Ticket", "Science"], "abstract": "Recent work has explored the possibility of pruning neural networks at initialization. We assess proposals for doing so: SNIP (Lee et al., 2019), GraSP (Wang et al., 2020), SynFlow (Tanaka et al., 2020), and magnitude pruning. Although these methods surpass the trivial baseline of random pruning, they remain below the accuracy of magnitude pruning after training, and we endeavor to understand why. We show that, unlike pruning after training, randomly shuffling the weights these methods prune within each layer or sampling new initial values preserves or improves accuracy. As such, the per-weight pruning decisions made by these methods can be replaced by a per-layer choice of the fraction of weights to prune. This property suggests broader challenges with the underlying pruning heuristics, the desire to prune at initialization, or both.", "one-sentence_summary": "Methods for pruning neural nets at initialization perform the same or better when shuffling or reinitializing the weights they prune in each layer, a way in which they differ from SOTA weight-pruning methods after training.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "frankle|pruning_neural_networks_at_initialization_why_are_we_missing_the_mark", "supplementary_material": "/attachment/53da61b6607bb8f4e57707d3ae1dbba3d15d52f3.zip", "pdf": "/pdf/f6ac2e779528102e5a404479ffdebc7aa54decd9.pdf", "venueid": "ICLR.cc/2021/Conference", "venue": "ICLR 2021 Poster", "_bibtex": "@inproceedings{\nfrankle2021pruning,\ntitle={Pruning Neural Networks at Initialization: Why Are We Missing the Mark?},\nauthor={Jonathan Frankle and Gintare Karolina Dziugaite and Daniel Roy and Michael Carbin},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=Ig-VyQc-MLK}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq . ***Please remember to file the Code-of-Ethics report. Once you submitted the review, a link to the report will be visible in the bottom right corner of your review.***", "required": true, "markdown": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}, "forum": "Ig-VyQc-MLK", "replyto": "Ig-VyQc-MLK", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"], "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper5/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1607428800000, "duedate": 1606752000000, "multiReply": false, "readers": ["everyone"], "tcdate": 1602538151740, "tmdate": 1606915773395, "super": "ICLR.cc/2021/Conference/-/Official_Review", "signatures": ["OpenReview.net"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Paper5/Reviewers", "OpenReview.net/Support"], "id": "ICLR.cc/2021/Conference/Paper5/-/Official_Review"}}}, {"id": "UdcCYV85z1", "original": null, "number": 4, "cdate": 1604026839716, "ddate": null, "tcdate": 1604026839716, "tmdate": 1606719066215, "tddate": null, "forum": "Ig-VyQc-MLK", "replyto": "Ig-VyQc-MLK", "invitation": "ICLR.cc/2021/Conference/Paper5/-/Official_Review", "content": {"title": "Some conclusions of this paper are unsubstantiated or should be rephrased", "review": "## Summary \n\nThe paper provides an extensive empirical analysis of Pruning-at-Initialization (PaI) techniques and compares it against two pruning methods after (or during) training. This comparison sheds some light on why pruning at initialization is inherently hard. Furthermore, the comparison among PaI methods with various ablations shows some inherent properties that are common to PaI methods and the benefits/drawbacks of certain methods. With these experiments, certain conclusions are reached among them an important one is that PaI methods only determine what is the fraction of weights to be pruned in each layer rather than which weights to prune.\n\n## Strengths\n\n1. Quantitative comparison of PaI methods is an important contribution to the community. In addition, the paper extensively analyses them with various ablations (eg, shuffle the layerwise masks, reinitialization) which uncovers various properties of PaI methods previously not conveyed clearly in the respective papers.\n\n2. Extensive analysis shows that there is a performance gap of PaI methods compared to Pruning-after-Training (PaT) methods (understandably) and attempts to explore the potential reasons. This analysis uncovers some inherent difficulties of PaI. The analysis provided in this paper could serve as a guide to better understand and improve PaI methods.\n\n3. Overall the paper is clearly written and sufficient details are provided in the appendix.\n\n## Weaknesses\n\nThe main weaknesses of the manuscript in my opinion are as follows:\n\n1. Some conclusions of this paper are unsubstantiated or should be rephrased:\n\t- First, the experiments mainly convey the inherent difficulties of PaI rather than the issues with specific methods themselves. To address this concern, the methods (SNIP, GraSP, SynFlow) are performed during training and showed that they perform inferior to LTR in Fig. 6. However, this comparison is unfair as LTR has additional information which is obtained after training (pruning mask is obtained after training but applied during training) and those PaI methods are not specifically designed to be performed during/after training (even so some perform reasonably well). In short, it is not clear that the performance of PaT can be matched by PaI given only the information at initialization. Note that, having access to the pruning mask after training defeats the purpose of PaI since given an already trained network, one might as well simply prune at the end (no need to retrain from scratch). I believe, Sec. 7 has some discussions about this (not complete) but should come early in the paper and emphasized. Please clarify and rephrase certain parts (especially in the introduction). \n\t- One of the main conclusions: \"PaI methods only determine what is the fraction of weights to be pruned in each layer rather than which weights to prune\" should be rephrased. In fact, it is possible to have a pathological case (eg, disconnected layers at a given pruning ratio) where knowing the optimal pruning ratio is not sufficient to obtain matching accuracy. These pathological cases are not observed in practice due to the random component (initialization or shuffling) and it should be emphasized. Also, since the weight initialization is iid Gaussian, there may not be sufficient information for PaI methods to select each weight individually but rather select them as a group in each layer or whole network.\n\t- Another hypothesis that the performance gap between PaI and PaT is due to the robustness of PaI methods to shuffling, reinitialization, etc, are also not clear. I understand that there is a correlation exists that some PaT methods are not robust to such variations. But it is NOT clearly demonstrated that being robust to such variations is necessarily a bad thing for PaI. In fact, one would think it is a good thing that PaI methods are robust to such variations given that there is not a lot of information available at initialization (note initialization is iid) to perform effective pruning and it seems these methods are robust and perform competitively to unpruned networks.\n\n2. Inconsistency of SNIP being independent to initialization:\n\t- In the last paragraph of page 5, it is mentioned that SNIP is independent to what initialization is used. However, there is a follow-up work of SNIP showing that it could be beneficial for SNIP if the network is initialized to have good signal propagation [a]. Please discuss this in the context to avoid any misinterpretations.\n\n3. Issue with random shuffling:\n\t- The random shuffling experiment needs some refinement in my opinion. I believe PaI methods such as SNIP, GraSP or SynFlow might have some unpruned weights which are not updated during training (ie, they are disconnected in the signal propagation path). In my personal experience, I observed that there are about 1-2% of unpruned disconnected weights in the network (in particular layers this value could be up to 10%) for SNIP (meaning they can be removed) depending on the network. This means the effective sparsity is slightly lower than what is observed in SNIP (not mentioned in the original paper though) and presumably in other methods as well. This observation would be applicable to random shuffling as well. I mean, after random shuffling there might be some unpruned disconnected weights and they could be removed before training, leading to higher effective sparsity. Furthermore, the existence of unpruned disconnected weights could be the reason for similar behaviour even after random shuffling in each layer. \n\nI found the experiments in this paper to be thorough but I think the deduced conclusions are slightly off with respect to the observations in the experiments. I believe this paper will be a good contribution to the pruning literature if the conclusions are tightened.\n\n## Minor Comments\n\n1. Related work: SNIP is not a follow-up of LTH but rather they are concurrent works published in ICLR 2019.\n2. Abstract: I think \"undermines\" might be a strong word given that there are questions regarding deduced conclusions.\n\n## References\n\n- [a] Lee, N., Ajanthan, T., Gould, S. and Torr, P.H., 2020. A signal propagation perspective for pruning neural networks at initialization. ICLR.", "rating": "6: Marginally above acceptance threshold", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}, "signatures": ["ICLR.cc/2021/Conference/Paper5/AnonReviewer4"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper5/AnonReviewer4"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Pruning Neural Networks at Initialization: Why Are We Missing the Mark?", "authorids": ["~Jonathan_Frankle1", "~Gintare_Karolina_Dziugaite1", "~Daniel_Roy1", "~Michael_Carbin1"], "authors": ["Jonathan Frankle", "Gintare Karolina Dziugaite", "Daniel Roy", "Michael Carbin"], "keywords": ["Pruning", "Sparsity", "Lottery Ticket", "Science"], "abstract": "Recent work has explored the possibility of pruning neural networks at initialization. We assess proposals for doing so: SNIP (Lee et al., 2019), GraSP (Wang et al., 2020), SynFlow (Tanaka et al., 2020), and magnitude pruning. Although these methods surpass the trivial baseline of random pruning, they remain below the accuracy of magnitude pruning after training, and we endeavor to understand why. We show that, unlike pruning after training, randomly shuffling the weights these methods prune within each layer or sampling new initial values preserves or improves accuracy. As such, the per-weight pruning decisions made by these methods can be replaced by a per-layer choice of the fraction of weights to prune. This property suggests broader challenges with the underlying pruning heuristics, the desire to prune at initialization, or both.", "one-sentence_summary": "Methods for pruning neural nets at initialization perform the same or better when shuffling or reinitializing the weights they prune in each layer, a way in which they differ from SOTA weight-pruning methods after training.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "frankle|pruning_neural_networks_at_initialization_why_are_we_missing_the_mark", "supplementary_material": "/attachment/53da61b6607bb8f4e57707d3ae1dbba3d15d52f3.zip", "pdf": "/pdf/f6ac2e779528102e5a404479ffdebc7aa54decd9.pdf", "venueid": "ICLR.cc/2021/Conference", "venue": "ICLR 2021 Poster", "_bibtex": "@inproceedings{\nfrankle2021pruning,\ntitle={Pruning Neural Networks at Initialization: Why Are We Missing the Mark?},\nauthor={Jonathan Frankle and Gintare Karolina Dziugaite and Daniel Roy and Michael Carbin},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=Ig-VyQc-MLK}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq . ***Please remember to file the Code-of-Ethics report. Once you submitted the review, a link to the report will be visible in the bottom right corner of your review.***", "required": true, "markdown": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}, "forum": "Ig-VyQc-MLK", "replyto": "Ig-VyQc-MLK", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"], "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper5/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1607428800000, "duedate": 1606752000000, "multiReply": false, "readers": ["everyone"], "tcdate": 1602538151740, "tmdate": 1606915773395, "super": "ICLR.cc/2021/Conference/-/Official_Review", "signatures": ["OpenReview.net"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Paper5/Reviewers", "OpenReview.net/Support"], "id": "ICLR.cc/2021/Conference/Paper5/-/Official_Review"}}}, {"id": "gn8RiTChQVX", "original": null, "number": 14, "cdate": 1606232467871, "ddate": null, "tcdate": 1606232467871, "tmdate": 1606232467871, "tddate": null, "forum": "Ig-VyQc-MLK", "replyto": "rLklmQxfPz", "invitation": "ICLR.cc/2021/Conference/Paper5/-/Official_Comment", "content": {"title": "Author Response (Part 1)", "comment": "We thank the reviewer for their detailed feedback. We have responded to the reviewer\u2019s comments in-line below, and we ask the reviewer to look at our revised paper where noted.\n\n---\n\n_This paper proposes to achieve the following goal: to understand why early pruning methods perform worse than pruning after training._\n\nTo clarify, this is only one of our goals. As we state in the introduction: (Goal 1) \u201cOur purpose is to clarify the state of the art [in pruning at initialization], shed light on the strengths and weaknesses of existing methods, understand their behavior in practice, [and] set baselines for the future.\u201d\n\nOnly after we determine that these methods do not match the accuracy of pruning after training and perform similarly to magnitude pruning at initialization do we seek to (Goal 2) understand whether \u201cthere are broader challenges particular to pruning at initialization.\u201d\n\nThis review mainly focuses on Goal 2, but we wish to emphasize to the reviewer that Goal 1 is also an important contribution.\n\n---\n\n_The paper appears to be focused on studying and debunking the early pruning methods..._\n\nThese serve the dual purpose of addressing Goal 1 and providing evidence for Goal 2. We believe that our efforts toward this goal are an important contribution to the pruning literature.\n\n---\n\n_...rather than finding out why pruning after training is better than pruning early._\n\n_This work does not explain \u201cwhy all methods fall short of magnitude pruning after training in a convincing manner.\u201d_\n\nWe don't explain why all methods fall short of magnitude pruning after training. This would have been a very challenging goal. However, we believe we take important steps toward understanding the differences in behavior between four methods for pruning at initialization and a standard method for pruning after training. This provides an important foundation for further inquiry into whether it may more generally be difficult to prune at initialization and match the accuracy of pruning after training.\nWe have revised the paper to make clear that our results demonstrate a correlation between accuracy and insensitivity to ablations that lays the foundation for future causal understanding of the gap between pruning after training and a suite of methods for pruning at initialization.\n\n---\n\n_The result of random pruning...and the failure of GraSP when inverted are quite interesting, but they remain empirical without contributing directly to fulfill the purpose._\n\n_Some of the conclusions drawn from the ablation studies are not convincing (e.g., lack of specificity or insensitivity to initialization may limit performance)._\n\nWe know of no SOTA weight-pruning methods in the literature that maintain their accuracy under the shuffling or reinitialization ablations. Performing these ablations on SOTA weight-pruning methods consistently leads to lower accuracy [Han et al., 2015; Frankle & Carbin, 2019; Frankle et al., 2020]. These results raise the question of whether methods that, in effect, only specify the layerwise proportions by which to randomly prune (rather than the specific connections or weights to prune) will be restricted to a lower stratum of accuracy. Since the early pruning methods reach the same accuracy regardless of whether pruning occurs randomly per-layer, they would be restricted to this lower stratum of accuracy if this is the case. Although this is not conclusive proof that it is impossible for a pruning method to reach state-of-the-art tradeoffs based on layerwise proportions alone, there are no examples of pruning methods with this property among the dozens of published methods in the literature. Our significant empirical work has uncovered these phenomena, laying the groundwork for further empirical and theoretical studies.\n\nThe result of the inversion experiment (\u201cthe failure of GraSP\u201d) addresses Goal 1: \u201cshed[ding] light on the strengths and weaknesses of existing methods\u201d and \u201cunderstand[ing] their behavior in practice.\u201d\n\nWith respect to the concern that our results remain empirical, we are focused on the behavior of these methods in practice, and we believe that our analysis is rigorous with respect to the four methods we examine. Our results raise broader questions that could be a valuable subject for future theoretical treatment (e.g., Is randomly pruning in a layerwise manner or pruning in a manner insensitive to reinitialization inherently restricted to lower accuracy? Is it impossible for a certain class of pruning methods to prune in a manner that is sensitive to these ablations at initialization?). However, conducting this theoretical analysis is beyond the scope of our practically oriented study.\nFinally, as we note at the end of Section 5, the practical behavior of these methods differs from that predicted by the theoretical analysis of these methods in the papers that proposed them, raising questions about whether existing theory provides a productive means for analyzing these techniques.\n"}, "signatures": ["ICLR.cc/2021/Conference/Paper5/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper5/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Pruning Neural Networks at Initialization: Why Are We Missing the Mark?", "authorids": ["~Jonathan_Frankle1", "~Gintare_Karolina_Dziugaite1", "~Daniel_Roy1", "~Michael_Carbin1"], "authors": ["Jonathan Frankle", "Gintare Karolina Dziugaite", "Daniel Roy", "Michael Carbin"], "keywords": ["Pruning", "Sparsity", "Lottery Ticket", "Science"], "abstract": "Recent work has explored the possibility of pruning neural networks at initialization. We assess proposals for doing so: SNIP (Lee et al., 2019), GraSP (Wang et al., 2020), SynFlow (Tanaka et al., 2020), and magnitude pruning. Although these methods surpass the trivial baseline of random pruning, they remain below the accuracy of magnitude pruning after training, and we endeavor to understand why. We show that, unlike pruning after training, randomly shuffling the weights these methods prune within each layer or sampling new initial values preserves or improves accuracy. As such, the per-weight pruning decisions made by these methods can be replaced by a per-layer choice of the fraction of weights to prune. This property suggests broader challenges with the underlying pruning heuristics, the desire to prune at initialization, or both.", "one-sentence_summary": "Methods for pruning neural nets at initialization perform the same or better when shuffling or reinitializing the weights they prune in each layer, a way in which they differ from SOTA weight-pruning methods after training.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "frankle|pruning_neural_networks_at_initialization_why_are_we_missing_the_mark", "supplementary_material": "/attachment/53da61b6607bb8f4e57707d3ae1dbba3d15d52f3.zip", "pdf": "/pdf/f6ac2e779528102e5a404479ffdebc7aa54decd9.pdf", "venueid": "ICLR.cc/2021/Conference", "venue": "ICLR 2021 Poster", "_bibtex": "@inproceedings{\nfrankle2021pruning,\ntitle={Pruning Neural Networks at Initialization: Why Are We Missing the Mark?},\nauthor={Jonathan Frankle and Gintare Karolina Dziugaite and Daniel Roy and Michael Carbin},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=Ig-VyQc-MLK}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "Ig-VyQc-MLK", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper5/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper5/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper5/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper5/Authors|ICLR.cc/2021/Conference/Paper5/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper5/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923875250, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper5/-/Official_Comment"}}}, {"id": "D5hK4V7k27D", "original": null, "number": 13, "cdate": 1606232363182, "ddate": null, "tcdate": 1606232363182, "tmdate": 1606232363182, "tddate": null, "forum": "Ig-VyQc-MLK", "replyto": "rLklmQxfPz", "invitation": "ICLR.cc/2021/Conference/Paper5/-/Official_Comment", "content": {"title": "Author Response (Part 2)", "comment": "_Some of the claims are not expected to generalize either (e.g., shuffling to fully-connected layers, initializing with different standard deviations of the normal distribution)._\n\nIn Appendix K.2, we specifically address shuffling fully-connected layers. Our claims about the ablations indeed generalize for the range of sparsities we consider.\n\nWe study one modified initialization scheme (N(0, 1)) for the purposes of exploring how the pruning techniques behave when the initialization variance does not scale with layer sizes in the way that He initialization does. Our goal is an existential result (SNIP, GraSP, and SynFlow can \u201cmaintain accuracy in a case where the initialization is not informative for pruning in this way\u201d) rather than a universal result (e.g., that these methods work with all possible initializations), so we do not believe it is relevant whether this result generalizes to other initialization schemes. We have modified the text (\u201ceven when the initialization is not informative\u201d -> \u201cin a case where the initialization is not informative\u201d) to ensure this point is clear.\n\n---\n\n_[The] test for the effect of training with the same saliency measure [in Section 6]...does not contribute to proving anything for why early pruning methods is underperformed by pruning after training._\n\nOur goal in performing this ablation was to determine whether the behaviors we observe earlier in the paper (lower accuracy than pruning after training and insensitivity to the ablations) are intrinsic to these particular pruning heuristics or whether they are specific to using these heuristics at initialization. We find that (with the possible exception of GraSP) these behaviors occur at initialization but not after a small amount of training. We do so by showing that the subnetworks that SNIP, SynFlow and magnitude find after initialization are able to reach higher accuracy (Section 6) and are sensitive to the ablations (Appendix F.2). This result means that our observations are specific to initialization and, more broadly, it raises a question about whether pruning at initialization inherently entails lower accuracy and insensitivity to the ablations.\nWe have updated the description of this experiment in Sections 1 and 6 to improve clarity.\nFinally, although we show that these methods encounter particular difficulties at initialization, we admittedly do not identify the underlying properties of the network at initialization that lead to these difficulties (i.e., \u201cwhy\u201d these behaviors occur at initialization in particular). We have added a paragraph to the discussion explicitly mentioning this open question.\n\n---\n\n_One of the potentially many reasons that pruning early methods is underperformed by pruning after training methods could merely be the fact that the former is not trained before it gets pruned as opposed to the latter yielding the observed performance gap quite obviously._\n\nWe interpret this comment as posing the following hypothesis: _pruning later in training leads to higher accuracy in Section 6 because the network already has high accuracy when pruning occurs._ As a counterexample, consider random pruning (the orange line in Figure 6). If this hypothesis were true, then the performance of random pruning should also improve when pruning later in training. As Figure 6 shows, this is clearly not the case. We have added a sentence (Section 6 Paragraph 3) to specifically address this point.\n"}, "signatures": ["ICLR.cc/2021/Conference/Paper5/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper5/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Pruning Neural Networks at Initialization: Why Are We Missing the Mark?", "authorids": ["~Jonathan_Frankle1", "~Gintare_Karolina_Dziugaite1", "~Daniel_Roy1", "~Michael_Carbin1"], "authors": ["Jonathan Frankle", "Gintare Karolina Dziugaite", "Daniel Roy", "Michael Carbin"], "keywords": ["Pruning", "Sparsity", "Lottery Ticket", "Science"], "abstract": "Recent work has explored the possibility of pruning neural networks at initialization. We assess proposals for doing so: SNIP (Lee et al., 2019), GraSP (Wang et al., 2020), SynFlow (Tanaka et al., 2020), and magnitude pruning. Although these methods surpass the trivial baseline of random pruning, they remain below the accuracy of magnitude pruning after training, and we endeavor to understand why. We show that, unlike pruning after training, randomly shuffling the weights these methods prune within each layer or sampling new initial values preserves or improves accuracy. As such, the per-weight pruning decisions made by these methods can be replaced by a per-layer choice of the fraction of weights to prune. This property suggests broader challenges with the underlying pruning heuristics, the desire to prune at initialization, or both.", "one-sentence_summary": "Methods for pruning neural nets at initialization perform the same or better when shuffling or reinitializing the weights they prune in each layer, a way in which they differ from SOTA weight-pruning methods after training.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "frankle|pruning_neural_networks_at_initialization_why_are_we_missing_the_mark", "supplementary_material": "/attachment/53da61b6607bb8f4e57707d3ae1dbba3d15d52f3.zip", "pdf": "/pdf/f6ac2e779528102e5a404479ffdebc7aa54decd9.pdf", "venueid": "ICLR.cc/2021/Conference", "venue": "ICLR 2021 Poster", "_bibtex": "@inproceedings{\nfrankle2021pruning,\ntitle={Pruning Neural Networks at Initialization: Why Are We Missing the Mark?},\nauthor={Jonathan Frankle and Gintare Karolina Dziugaite and Daniel Roy and Michael Carbin},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=Ig-VyQc-MLK}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "Ig-VyQc-MLK", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper5/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper5/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper5/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper5/Authors|ICLR.cc/2021/Conference/Paper5/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper5/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923875250, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper5/-/Official_Comment"}}}, {"id": "mXFOmQwq5yJ", "original": null, "number": 11, "cdate": 1606231427364, "ddate": null, "tcdate": 1606231427364, "tmdate": 1606232263875, "tddate": null, "forum": "Ig-VyQc-MLK", "replyto": "UdcCYV85z1", "invitation": "ICLR.cc/2021/Conference/Paper5/-/Official_Comment", "content": {"title": "Author Response (Part 2)", "comment": "_Since the weight initialization is iid Gaussian, there may not be sufficient information for pruning methods to select each weight individually but rather to select them as a group in each layer or the whole network._\n\nWe are uncertain about the specific technical weakness in our paper that this comment refers to and we would appreciate clarification.\n\nWe agree that this is a possible hypothesis for why it may be difficult or impossible to prune in a weight-specific or initialization-specific manner at initialization. However, we do not understand why this hypothesis is listed as a weakness of our paper: it would answer our question about the possible difficulty of pruning in a weight-specific or initialization-specific manner at initialization (Section 1 Paragraph 11, Section 7 Paragraph 7), and we do not make any claims about the specific mechanism that makes it difficult to do so at initialization (a point we specifically discuss in the newly-added Section 7 Paragraph 8). \n\n---\n\n_Another hypothesis that the performance gap between PaI and PaT is due to the robustness of PaI methods to shuffling, reinitialization, etc, are also not clear. I understand that a correlation exists that some PaT methods are not robust to such variations. But it is NOT clearly demonstrated that being robust to such variations is necessarily a bad thing for PaI_\n\nWe have revised the paper to make clear that our results demonstrate a correlation between accuracy and insensitivity to ablations that lays the foundation for future causal understanding of the gap between pruning after training and these methods for pruning at initialization.\n\nWe know of no SOTA methods for pruning weights after training in the literature that can maintain its accuracy under these ablations. Performing these ablations on these methods consistently leads to lower accuracy [Han et al., 2015; Frankle & Carbin, 2019; Frankle et al., 2020]. These results certainly raise the question of whether methods that, in effect, only specify the layerwise proportions in which to randomly prune (rather than the specific connections or weights to prune) will be restricted to this lower stratum of accuracy (which we interpret as a bad thing for pruning at initialization). More broadly, this raises the question of whether it may be impossible to prune at initialization in a way that could not be replaced by randomly pruning at the same per-layer rates, in which case, on networks like ResNet-50 on ImageNet, there may be inherent trade-offs to pruning at initialization (since existing methods cannot match full accuracy at any appreciable sparsity).\n\n---\n\n_In fact, one would think it is a good thing that PaI methods are robust to such variations given that there is not a lot of information available at initialization (note initialization is iid) to perform effective pruning and it seems these methods are robust and perform competitively to unpruned networks._\n\nIt is possible that maintaining accuracy under the ablations may be a benefit in some way, but this is orthogonal to the implication that methods that maintain accuracy under these ablations may be restricted to a lower stratum of accuracy.\n\nAs to whether these methods perform competitively to unpruned networks, it depends on the definition of \u201ccompetitively.\u201d Due to the subjectivity of this term, we focus on whether methods can match the accuracy of the unpruned networks. Our experiments in Section 4 show that it is not the case that these methods perform \u201ccompetitively\u201d according to this criterion: for example, on the most realistic benchmark (ResNet-50 on ImageNet), none of these methods can reach full accuracy at any sparsity we consider.\n\n---\n\n_In the last paragraph of page 5, it is mentioned that SNIP is independent to what initialization is used. However, there is a follow-up work of SNIP showing that it could be beneficial for SNIP if the network is initialized to have good signal propagation [a]._\n\nThank you for bringing this work to our attention. We have updated this paragraph to clarify that we are only describing one specific initialization in our experiment (\u201ceven when the initialization is not informative\u201d -> \u201cin a case where the initialization is not informative\u201d), and we have added a footnote noting the relationship between SNIP and initialization as described in the reference you provide.\n\n---\n\n_SNIP is not a follow-up of LTH._\n\nWe have updated the text accordingly - thank you for this clarification.\n\n---\n\n_I think \u201cundermines\u201d might be a strong word._\n\nWe have removed all language of this kind from our paper, particularly in the abstract and the last paragraph in Section 5. We would appreciate any follow-up suggestions you have for further improving the way we address this point."}, "signatures": ["ICLR.cc/2021/Conference/Paper5/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper5/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Pruning Neural Networks at Initialization: Why Are We Missing the Mark?", "authorids": ["~Jonathan_Frankle1", "~Gintare_Karolina_Dziugaite1", "~Daniel_Roy1", "~Michael_Carbin1"], "authors": ["Jonathan Frankle", "Gintare Karolina Dziugaite", "Daniel Roy", "Michael Carbin"], "keywords": ["Pruning", "Sparsity", "Lottery Ticket", "Science"], "abstract": "Recent work has explored the possibility of pruning neural networks at initialization. We assess proposals for doing so: SNIP (Lee et al., 2019), GraSP (Wang et al., 2020), SynFlow (Tanaka et al., 2020), and magnitude pruning. Although these methods surpass the trivial baseline of random pruning, they remain below the accuracy of magnitude pruning after training, and we endeavor to understand why. We show that, unlike pruning after training, randomly shuffling the weights these methods prune within each layer or sampling new initial values preserves or improves accuracy. As such, the per-weight pruning decisions made by these methods can be replaced by a per-layer choice of the fraction of weights to prune. This property suggests broader challenges with the underlying pruning heuristics, the desire to prune at initialization, or both.", "one-sentence_summary": "Methods for pruning neural nets at initialization perform the same or better when shuffling or reinitializing the weights they prune in each layer, a way in which they differ from SOTA weight-pruning methods after training.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "frankle|pruning_neural_networks_at_initialization_why_are_we_missing_the_mark", "supplementary_material": "/attachment/53da61b6607bb8f4e57707d3ae1dbba3d15d52f3.zip", "pdf": "/pdf/f6ac2e779528102e5a404479ffdebc7aa54decd9.pdf", "venueid": "ICLR.cc/2021/Conference", "venue": "ICLR 2021 Poster", "_bibtex": "@inproceedings{\nfrankle2021pruning,\ntitle={Pruning Neural Networks at Initialization: Why Are We Missing the Mark?},\nauthor={Jonathan Frankle and Gintare Karolina Dziugaite and Daniel Roy and Michael Carbin},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=Ig-VyQc-MLK}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "Ig-VyQc-MLK", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper5/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper5/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper5/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper5/Authors|ICLR.cc/2021/Conference/Paper5/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper5/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923875250, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper5/-/Official_Comment"}}}, {"id": "6_cBX34CE6M", "original": null, "number": 10, "cdate": 1606230676599, "ddate": null, "tcdate": 1606230676599, "tmdate": 1606231624399, "tddate": null, "forum": "Ig-VyQc-MLK", "replyto": "UdcCYV85z1", "invitation": "ICLR.cc/2021/Conference/Paper5/-/Official_Comment", "content": {"title": "Author Response (Part 3)", "comment": "_The random shuffling experiment needs some refinement in my opinion. I believe PaI methods such as SNIP, GraSP, or SynFlow might have some unpruned weights which are not updated during training._\n\nWe interpret this comment to mean the following:\n\n> _It is possible that SNIP, GraSP, and SynFlow leave some weights unpruned but disconnected, which means the \u201ceffective sparsity\u201d (the sparsity when also eliminating disconnected weights) of these networks is higher than the \u201cactual sparsity\u201d (the sparsity when taking into account connections that are explicitly pruned). Furthermore, when randomly shuffling, some of these disconnected weights may become reconnected. As such, random shuffling might appear to maintain performance simply because it has a lower effective sparsity than the unmodified pruning technique._\n\nTo evaluate this hypothesis, we added Appendix N, in which we compare the effective sparsities for SNIP, GraSP, and SynFlow with and without randomly shuffling.\n\n**TLDR: At the highest matching actual sparsity, the effective sparsity of the shuffled network was larger by a negligible amount: at most 1.0026x (i.e., 0.26%) larger than the unmodified network and in most cases closer to 1.0005x (i.e., 0.05%) larger. At more extreme sparsities, this ratio was higher but still small: at most 1.0353x (i.e., 3.5% larger) and in most cases closer to 1.003x (i.e., 0.3%) larger.**\n\n**Full details:**\nTo determine which weights were disconnected, we:\n1. Set each weight in the network to 1 (if unpruned) or 0 (if pruned).\n2. Forward-propagated a single example comprising all 1\u2019s.\n3. Computed the sum of the logits.\n4. Computed the gradients with respect to this sum.\n5. Prune any unpruned weight with a gradient of 0.\n\nFor each \u201cactual sparsity,\u201d we computed the ratio of $\\frac{\\text{effective parameters in the shuffled network}}{\\text{effective parameters in the unmodified network}}$.\n\nA summary of our results is below (see Appendix N for full data). Please refer to the TLDR above for our summary of the data. We conclude that, although random shuffling does often restore some disconnected parameters, the actual fraction of parameters it restores is minuscule at and beyond the matching sparsities we focus on. These differences are so small that the effective sparsities round to the same values as the actual sparsities on the x-axis labels of our plots.\n\n| Network                  | Pruning Method | Ratio at Highest Matching Sparsity | Ratio at Highest Sparsity We Include |\n|--------------------------|----------------|------------------------------------|--------------------------------------|\n| ResNet-20 (CIFAR-10)     | Magnitude      | 1.0000                             | 1.0016                               |\n|                          | SNIP           | 1.0006                             | 1.0353                               |\n|                          | GraSP          | 1.0000                             | 1.0197                               |\n|                          | SynFlow        | 1.0000                             | 0.9921                               |\n| VGG-16 (CIFAR-10)        | Magnitude      | 1.0000                             | 0.9998                               |\n|                          | SNIP           | 1.0007                             | 1.0058                               |\n|                          | GraSP          | 1.0003                             | 1.0036                               |\n|                          | SynFlow        | 1.0000                             | 1.0001                               |\n| ResNet-18 (TinyImageNet) | Magnitude      | 1.0003                             | 1.0000                               |\n|                          | SNIP           | 1.0026                             | 1.0227                               |\n|                          | GraSP          | 1.0011                             | 1.0030                               |\n|                          | SynFlow        | 1.0001                             | 1.0001                               |\n| ResNet-50 (ImageNet)     | Magnitude      | 1.0000                             | 0.9979                               |\n|                          | SNIP           | 1.0003                             | 1.0016                               |\n|                          | GraSP          | 1.0000                             | 1.0009                               |\n|                          | SynFlow        | 1.0000                             | 1.0001                               |\n"}, "signatures": ["ICLR.cc/2021/Conference/Paper5/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper5/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Pruning Neural Networks at Initialization: Why Are We Missing the Mark?", "authorids": ["~Jonathan_Frankle1", "~Gintare_Karolina_Dziugaite1", "~Daniel_Roy1", "~Michael_Carbin1"], "authors": ["Jonathan Frankle", "Gintare Karolina Dziugaite", "Daniel Roy", "Michael Carbin"], "keywords": ["Pruning", "Sparsity", "Lottery Ticket", "Science"], "abstract": "Recent work has explored the possibility of pruning neural networks at initialization. We assess proposals for doing so: SNIP (Lee et al., 2019), GraSP (Wang et al., 2020), SynFlow (Tanaka et al., 2020), and magnitude pruning. Although these methods surpass the trivial baseline of random pruning, they remain below the accuracy of magnitude pruning after training, and we endeavor to understand why. We show that, unlike pruning after training, randomly shuffling the weights these methods prune within each layer or sampling new initial values preserves or improves accuracy. As such, the per-weight pruning decisions made by these methods can be replaced by a per-layer choice of the fraction of weights to prune. This property suggests broader challenges with the underlying pruning heuristics, the desire to prune at initialization, or both.", "one-sentence_summary": "Methods for pruning neural nets at initialization perform the same or better when shuffling or reinitializing the weights they prune in each layer, a way in which they differ from SOTA weight-pruning methods after training.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "frankle|pruning_neural_networks_at_initialization_why_are_we_missing_the_mark", "supplementary_material": "/attachment/53da61b6607bb8f4e57707d3ae1dbba3d15d52f3.zip", "pdf": "/pdf/f6ac2e779528102e5a404479ffdebc7aa54decd9.pdf", "venueid": "ICLR.cc/2021/Conference", "venue": "ICLR 2021 Poster", "_bibtex": "@inproceedings{\nfrankle2021pruning,\ntitle={Pruning Neural Networks at Initialization: Why Are We Missing the Mark?},\nauthor={Jonathan Frankle and Gintare Karolina Dziugaite and Daniel Roy and Michael Carbin},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=Ig-VyQc-MLK}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "Ig-VyQc-MLK", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper5/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper5/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper5/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper5/Authors|ICLR.cc/2021/Conference/Paper5/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper5/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923875250, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper5/-/Official_Comment"}}}, {"id": "MBXQQkeVcq", "original": null, "number": 12, "cdate": 1606231491147, "ddate": null, "tcdate": 1606231491147, "tmdate": 1606231491147, "tddate": null, "forum": "Ig-VyQc-MLK", "replyto": "UdcCYV85z1", "invitation": "ICLR.cc/2021/Conference/Paper5/-/Official_Comment", "content": {"title": "Author Response (Part 1)", "comment": "We thank the reviewer for their knowledgeable comments and detailed suggestions. We have taken these comments very seriously, and we have revised the paper accordingly. We would appreciate it if the reviewer would look at our responses below and our updated paper in detail.\n\n---\n\n_The experiments mainly convey the inherent difficulties of PaI rather than the issues with the specific methods themselves._\n\nWe agree that our results do raise the question of whether there are inherent difficulties to pruning at initialization and that this question is an important takeaway of our paper.\n\nAt the same time, our experiments are only able to discern challenges specific to the methods that we study, and we cannot make strong claims about inherent difficulties of pruning at initialization based on these results. The difficulties may be due to the methods themselves rather than to inherent difficulties of pruning at initialization.\n\nWe have revised the paper to make this narrative clear (Section 1 Paragraph 11, Section 7 Paragraph 6).\n\n\n---\n\n_This comparison [in Section 6]  is unfair as LTR has additional information which is obtained after training._\n\n_PaI methods are not specifically designed to be performed during/after training._\n\nWe have made changes throughout the paper to address these concerns. In particular:\n\n1. We have explicitly clarified that SNIP, GraSP, and SynFlow were not designed to prune after initialization (Section 1 Paragraph 13, Section 6 Paragraph 2, Section 7 Paragraph 12) and that we are evaluating them outside of the setting for which they were designed (Section 6 Paragraph 2).\n2. We have clarified that, for the experiment in Section 6, we are interested in whether accuracy improves and whether the methods become sensitive to the ablations, not the specific level of final accuracy (Section 6 Paragraph 2).\n3. We have removed any judgment about which methods are SOTA after initialization, since the methods were not designed for this purpose (deleted from Section 7). We have also removed any statements that imply performance that is lower than LTR reflects a weakness of the methods (deleted from Section 1 and Section 6).\n4. The remaining comparisons to the performance of LTR (Section 6 Paragraph 5, Section 7 Paragraph 12) are stated with the context that it may be impossible to reach this performance in practice since LTR has access to information from the end of training.\n---\n\n_It is not clear that the performance of PaT can be matched by PaI given only the information at initialization._\n\n_I believe Sec. 7 has some discussions about this but should come early in the paper and emphasized._\n\nWe have made the following changes to address this concern:\n1. We have removed all statements in the paper that set the expectation that the techniques for pruning at initialization should be able to match the performance of pruning after training (deleted from the following locations in the original manuscript: Section 1 Paragraph 6, Section 1 Paragraph 11, Section 3 Paragraph 9, Section 7 Paragraph 6).\n\n2. We have also removed all statements that imply that it is a shortcoming of the methods that they do not match this performance (deleted from the following locations in the original manuscript: Section 1 Paragraphs 7,8,9,11, Section 4 Paragraph 5, Section 5 Paragraph 1); in particular, the phrases \u201cfall short\u201d and \u201cunderperform\u201d no longer appear in the paper\n\n3. We have revised Section 1 to make clear that it may not be possible to match the performance of pruning after training by pruning at initialization (in the updated manuscript: Section 1 Paragraph 9).\n\n4. In place of these comparisons, we have added a new research question: \u201care there broader challenges particular to pruning at initialization?\u201d (Section 1 Paragraph 7).  This question was already implicit in the paper, but it was previously conflated with the question of whether methods for pruning at initialization could match methods for pruning after training. Thanks to your feedback, we have teased apart these questions, which we believe significantly improves the clarity of the manuscript.\n---\n_One of the main conclusions: \"PaI methods only determine what is the fraction of weights to be pruned in each layer rather than which weights to prune\" should be rephrased. It is possible to have a pathological case (e.g., disconnected layers at a given pruning ratio) where knowing the optimal pruning ratio is not sufficient to obtain matching accuracy.  These pathological cases are not observed in practice due to the random component (initialization or shuffling) and it should be emphasized._\n\nWe have added a footnote in Section 5 Paragraph 3 (where we first run the random shuffling experiment) to clarify that, at extreme sparsities or under an unlucky random draw, it is possible that shuffling could lead to lower accuracy (although we do not ever observe this behavior ourselves for the settings and sparsities we consider).\n"}, "signatures": ["ICLR.cc/2021/Conference/Paper5/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper5/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Pruning Neural Networks at Initialization: Why Are We Missing the Mark?", "authorids": ["~Jonathan_Frankle1", "~Gintare_Karolina_Dziugaite1", "~Daniel_Roy1", "~Michael_Carbin1"], "authors": ["Jonathan Frankle", "Gintare Karolina Dziugaite", "Daniel Roy", "Michael Carbin"], "keywords": ["Pruning", "Sparsity", "Lottery Ticket", "Science"], "abstract": "Recent work has explored the possibility of pruning neural networks at initialization. We assess proposals for doing so: SNIP (Lee et al., 2019), GraSP (Wang et al., 2020), SynFlow (Tanaka et al., 2020), and magnitude pruning. Although these methods surpass the trivial baseline of random pruning, they remain below the accuracy of magnitude pruning after training, and we endeavor to understand why. We show that, unlike pruning after training, randomly shuffling the weights these methods prune within each layer or sampling new initial values preserves or improves accuracy. As such, the per-weight pruning decisions made by these methods can be replaced by a per-layer choice of the fraction of weights to prune. This property suggests broader challenges with the underlying pruning heuristics, the desire to prune at initialization, or both.", "one-sentence_summary": "Methods for pruning neural nets at initialization perform the same or better when shuffling or reinitializing the weights they prune in each layer, a way in which they differ from SOTA weight-pruning methods after training.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "frankle|pruning_neural_networks_at_initialization_why_are_we_missing_the_mark", "supplementary_material": "/attachment/53da61b6607bb8f4e57707d3ae1dbba3d15d52f3.zip", "pdf": "/pdf/f6ac2e779528102e5a404479ffdebc7aa54decd9.pdf", "venueid": "ICLR.cc/2021/Conference", "venue": "ICLR 2021 Poster", "_bibtex": "@inproceedings{\nfrankle2021pruning,\ntitle={Pruning Neural Networks at Initialization: Why Are We Missing the Mark?},\nauthor={Jonathan Frankle and Gintare Karolina Dziugaite and Daniel Roy and Michael Carbin},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=Ig-VyQc-MLK}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "Ig-VyQc-MLK", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper5/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper5/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper5/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper5/Authors|ICLR.cc/2021/Conference/Paper5/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper5/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923875250, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper5/-/Official_Comment"}}}, {"id": "sABi3fraO48", "original": null, "number": 9, "cdate": 1606230250880, "ddate": null, "tcdate": 1606230250880, "tmdate": 1606230250880, "tddate": null, "forum": "Ig-VyQc-MLK", "replyto": "1_tU0ekSpyu", "invitation": "ICLR.cc/2021/Conference/Paper5/-/Official_Comment", "content": {"title": "Paper is Updated", "comment": "We wanted to notify you that we have posted our revised version of the paper. As promised, we have addressed the typo in the final paragraph and have reintroduced a reference to Figure 2 in the introduction. We have also made many changes throughout to address comments from other reviewers."}, "signatures": ["ICLR.cc/2021/Conference/Paper5/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper5/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Pruning Neural Networks at Initialization: Why Are We Missing the Mark?", "authorids": ["~Jonathan_Frankle1", "~Gintare_Karolina_Dziugaite1", "~Daniel_Roy1", "~Michael_Carbin1"], "authors": ["Jonathan Frankle", "Gintare Karolina Dziugaite", "Daniel Roy", "Michael Carbin"], "keywords": ["Pruning", "Sparsity", "Lottery Ticket", "Science"], "abstract": "Recent work has explored the possibility of pruning neural networks at initialization. We assess proposals for doing so: SNIP (Lee et al., 2019), GraSP (Wang et al., 2020), SynFlow (Tanaka et al., 2020), and magnitude pruning. Although these methods surpass the trivial baseline of random pruning, they remain below the accuracy of magnitude pruning after training, and we endeavor to understand why. We show that, unlike pruning after training, randomly shuffling the weights these methods prune within each layer or sampling new initial values preserves or improves accuracy. As such, the per-weight pruning decisions made by these methods can be replaced by a per-layer choice of the fraction of weights to prune. This property suggests broader challenges with the underlying pruning heuristics, the desire to prune at initialization, or both.", "one-sentence_summary": "Methods for pruning neural nets at initialization perform the same or better when shuffling or reinitializing the weights they prune in each layer, a way in which they differ from SOTA weight-pruning methods after training.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "frankle|pruning_neural_networks_at_initialization_why_are_we_missing_the_mark", "supplementary_material": "/attachment/53da61b6607bb8f4e57707d3ae1dbba3d15d52f3.zip", "pdf": "/pdf/f6ac2e779528102e5a404479ffdebc7aa54decd9.pdf", "venueid": "ICLR.cc/2021/Conference", "venue": "ICLR 2021 Poster", "_bibtex": "@inproceedings{\nfrankle2021pruning,\ntitle={Pruning Neural Networks at Initialization: Why Are We Missing the Mark?},\nauthor={Jonathan Frankle and Gintare Karolina Dziugaite and Daniel Roy and Michael Carbin},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=Ig-VyQc-MLK}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "Ig-VyQc-MLK", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper5/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper5/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper5/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper5/Authors|ICLR.cc/2021/Conference/Paper5/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper5/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923875250, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper5/-/Official_Comment"}}}, {"id": "ZmbeIzDCJl", "original": null, "number": 8, "cdate": 1606230212453, "ddate": null, "tcdate": 1606230212453, "tmdate": 1606230212453, "tddate": null, "forum": "Ig-VyQc-MLK", "replyto": "0BDYt6OB62c", "invitation": "ICLR.cc/2021/Conference/Paper5/-/Official_Comment", "content": {"title": "Paper is Updated", "comment": "We wanted to notify you that we have posted our revised version of the paper. As promised, we have added a paragraph to the discussion explaining the various justifications for pruning at initialization. We have also made many changes throughout to address comments from other reviewers."}, "signatures": ["ICLR.cc/2021/Conference/Paper5/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper5/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Pruning Neural Networks at Initialization: Why Are We Missing the Mark?", "authorids": ["~Jonathan_Frankle1", "~Gintare_Karolina_Dziugaite1", "~Daniel_Roy1", "~Michael_Carbin1"], "authors": ["Jonathan Frankle", "Gintare Karolina Dziugaite", "Daniel Roy", "Michael Carbin"], "keywords": ["Pruning", "Sparsity", "Lottery Ticket", "Science"], "abstract": "Recent work has explored the possibility of pruning neural networks at initialization. We assess proposals for doing so: SNIP (Lee et al., 2019), GraSP (Wang et al., 2020), SynFlow (Tanaka et al., 2020), and magnitude pruning. Although these methods surpass the trivial baseline of random pruning, they remain below the accuracy of magnitude pruning after training, and we endeavor to understand why. We show that, unlike pruning after training, randomly shuffling the weights these methods prune within each layer or sampling new initial values preserves or improves accuracy. As such, the per-weight pruning decisions made by these methods can be replaced by a per-layer choice of the fraction of weights to prune. This property suggests broader challenges with the underlying pruning heuristics, the desire to prune at initialization, or both.", "one-sentence_summary": "Methods for pruning neural nets at initialization perform the same or better when shuffling or reinitializing the weights they prune in each layer, a way in which they differ from SOTA weight-pruning methods after training.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "frankle|pruning_neural_networks_at_initialization_why_are_we_missing_the_mark", "supplementary_material": "/attachment/53da61b6607bb8f4e57707d3ae1dbba3d15d52f3.zip", "pdf": "/pdf/f6ac2e779528102e5a404479ffdebc7aa54decd9.pdf", "venueid": "ICLR.cc/2021/Conference", "venue": "ICLR 2021 Poster", "_bibtex": "@inproceedings{\nfrankle2021pruning,\ntitle={Pruning Neural Networks at Initialization: Why Are We Missing the Mark?},\nauthor={Jonathan Frankle and Gintare Karolina Dziugaite and Daniel Roy and Michael Carbin},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=Ig-VyQc-MLK}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "Ig-VyQc-MLK", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper5/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper5/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper5/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper5/Authors|ICLR.cc/2021/Conference/Paper5/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper5/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923875250, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper5/-/Official_Comment"}}}, {"id": "1_tU0ekSpyu", "original": null, "number": 5, "cdate": 1605799972200, "ddate": null, "tcdate": 1605799972200, "tmdate": 1605799972200, "tddate": null, "forum": "Ig-VyQc-MLK", "replyto": "ksnRmL86yP", "invitation": "ICLR.cc/2021/Conference/Paper5/-/Official_Comment", "content": {"title": "Author Response", "comment": "We thank the reviewer for the detailed feedback. We have responded to the reviewer\u2019s comments in-line below.\n\n---\n\n_A higher rating would require empirical results on more networks on large-scale datasets_\n_Experiments on large data sets are limited to RN50 on ImageNet._\n\nWhen it comes to networks, datasets, and scale, our paper is the most comprehensive study ever conducted on the topic of pruning neural networks at initialization, and we pushed our resources and our budget to the limit in order to make this happen.\n\nIn the main body of our paper alone, we present results from training more than 11,000 networks. This includes training about 600 networks (14 sparsities) on ImageNet; for comparison, the GraSP paper (Wang et al.) is the only paper on pruning at initialization that includes any results on ImageNet, and it contains just 36 networks (3 sparsities) trained on the task.\n\nSince our purpose was to rigorously evaluate and examine these techniques, we chose to focus our limited resources on fewer settings in depth rather than more settings in a shallower manner. The papers introducing the methods we look at primarily (SNIP) or only (GraSP, SynFlow) studied image classification; our work therefore assesses these methods in their original domains. We were cognizant that reviewers or authors might consider it unfair if we included other computer vision tasks or natural language processing tasks for which these techniques were not designed.\n\nAlthough we agree that any empirical paper is stronger if it includes more settings, we believe the current experiments are convincing and comprehensive and we lack the resources to add more large-scale settings.\n\n---\n\n_Inclusion of techniques the submission itself suggests might be a promising direction forward in the current gauntlet of tests._\n\nWe intentionally restricted our paper to analysis of existing techniques. We wanted to avoid confusing the purpose of our paper by mixing analysis of existing techniques with an entirely new proposal. Even by restricting our scope in this way, the present results still fill 8 pages in the main body and 27 pages of appendices.\n\n---\n\n_The three particular techniques chosen (SNIP, GraSP, SynFlow) aren\u2019t particularly motivated. Why these three, and not other recent techniques?_\n\nTo the best of our knowledge, SNIP, GraSP, SynFlow, and NTT are the only published methods specifically designed to prune neural networks at initialization. We did not include NTT because the original paper only evaluated the technique on small networks for MNIST and CIFAR-10 (smaller than the smallest setting we consider).\n\nAs we discuss in the related work (Section 2), the only other proposed methods for pruning at initialization that we could find at the time of submission are iterative variations of SNIP (de Jorge et al. 2020 and Verdenius et al. 2020). We consider iterative SNIP in Appendix G.\n\n---\n\n_Is there a reason [dynamic sparsity techniques] do not belong in the current lineup?_\n\nAlthough dynamic pruning methods (e.g., Mocanu et al., Dettmers & Zettlemoyer, Evci et al.) are an exciting direction for training sparse networks from the start, they are beyond the scope of this work. Our goal was to study the growing literature on pruning at initialization and to highlight the apparent difficulty of doing so; dynamic pruning methods begin with a sparse network, but they mainly prune after initialization, so they do not fall into this category. Many of our experiments do not make sense in the context of dynamic pruning, for example reinitializing after pruning (Section 5) and pruning only at a specific point in training (Section 6).\n\n---\n\n_The final paragraph._\n\nThis was a typo. One of the < signs was backwards. We have corrected this mistake in the updated manuscript (to be posted shortly).\n\n---\n\n_Figure 2 is never referenced in the text._\n\nThis was an editing mistake, and we appreciate that you brought this to our attention. We are re-inserting a reference to this figure in the introduction (updated manuscript to come shortly). We intend Figure 2 to serve as a quick reference for the experiments we perform and how they differ from the experiments in prior work."}, "signatures": ["ICLR.cc/2021/Conference/Paper5/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper5/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Pruning Neural Networks at Initialization: Why Are We Missing the Mark?", "authorids": ["~Jonathan_Frankle1", "~Gintare_Karolina_Dziugaite1", "~Daniel_Roy1", "~Michael_Carbin1"], "authors": ["Jonathan Frankle", "Gintare Karolina Dziugaite", "Daniel Roy", "Michael Carbin"], "keywords": ["Pruning", "Sparsity", "Lottery Ticket", "Science"], "abstract": "Recent work has explored the possibility of pruning neural networks at initialization. We assess proposals for doing so: SNIP (Lee et al., 2019), GraSP (Wang et al., 2020), SynFlow (Tanaka et al., 2020), and magnitude pruning. Although these methods surpass the trivial baseline of random pruning, they remain below the accuracy of magnitude pruning after training, and we endeavor to understand why. We show that, unlike pruning after training, randomly shuffling the weights these methods prune within each layer or sampling new initial values preserves or improves accuracy. As such, the per-weight pruning decisions made by these methods can be replaced by a per-layer choice of the fraction of weights to prune. This property suggests broader challenges with the underlying pruning heuristics, the desire to prune at initialization, or both.", "one-sentence_summary": "Methods for pruning neural nets at initialization perform the same or better when shuffling or reinitializing the weights they prune in each layer, a way in which they differ from SOTA weight-pruning methods after training.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "frankle|pruning_neural_networks_at_initialization_why_are_we_missing_the_mark", "supplementary_material": "/attachment/53da61b6607bb8f4e57707d3ae1dbba3d15d52f3.zip", "pdf": "/pdf/f6ac2e779528102e5a404479ffdebc7aa54decd9.pdf", "venueid": "ICLR.cc/2021/Conference", "venue": "ICLR 2021 Poster", "_bibtex": "@inproceedings{\nfrankle2021pruning,\ntitle={Pruning Neural Networks at Initialization: Why Are We Missing the Mark?},\nauthor={Jonathan Frankle and Gintare Karolina Dziugaite and Daniel Roy and Michael Carbin},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=Ig-VyQc-MLK}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "Ig-VyQc-MLK", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper5/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper5/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper5/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper5/Authors|ICLR.cc/2021/Conference/Paper5/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper5/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923875250, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper5/-/Official_Comment"}}}, {"id": "0BDYt6OB62c", "original": null, "number": 4, "cdate": 1605799725007, "ddate": null, "tcdate": 1605799725007, "tmdate": 1605799787855, "tddate": null, "forum": "Ig-VyQc-MLK", "replyto": "8ZDWAD4Lrly", "invitation": "ICLR.cc/2021/Conference/Paper5/-/Official_Comment", "content": {"title": "Author Response", "comment": "We are grateful that the reviewer appreciated our purpose and the potential significance of our work. We have responded to the reviewer\u2019s comments in-line below.\n\n---\n\n_The only qualm I have with the results are that there are not more on different architectures._\n\nWhen it comes to networks, datasets, and scale, our paper is the most comprehensive study ever conducted on the topic of pruning neural networks at initialization, and we pushed our resources and our budget to the limit in order to make this happen.\n\nIn the main body of our paper alone, we present results from training more than 11,000 networks. This includes training about 600 networks (14 sparsities) on ImageNet; for comparison, the GraSP paper (Wang et al.) is the only paper on pruning at initialization that includes any results on ImageNet, and it contains just 36 networks (3 sparsities) trained on the task.\n\nSince our purpose was to rigorously evaluate and examine these techniques, we chose to focus our limited resources on fewer settings in depth rather than more settings in a shallower manner. The papers introducing the methods we look at primarily (SNIP) or only (GraSP, SynFlow) studied image classification; our work therefore assesses these methods in their original domains. We were cognizant that reviewers or authors might consider it unfair if we included other computer vision tasks or natural language processing tasks for which these techniques were not designed.\n\nAlthough we agree that any empirical paper is stronger if it includes more settings, we believe the current experiments are convincing and comprehensive and we lack the resources to add more large-scale settings.\n\n---\n\n_I would have liked to see a discussion on why we would even want to prune at initialization._\n\nWe are in the process of updating the discussion section to provide an overview for possible motivations for pruning at initialization. We will post another update once this is complete.\n\n---\n\n_Perhaps a comparison to other sparse training methods would be in order._\n\nThe most prominent alternative class of sparse training methods are those that dynamically change the sparsity pattern throughout training (e.g., Mocanu et al., Dettmers & Zettlemoyer, Evci et al.). This is an exciting alternative direction for training sparse networks from the start, however, they are beyond the scope of this work. Our goal was to study the growing literature on pruning at initialization and to highlight the apparent difficulty of doing so; dynamic pruning methods begin with a sparse network, but they mainly prune after initialization, so they do not fall into this category. Many of our experiments do not make sense in the context of dynamic pruning, for example reinitializing after pruning (Section 5) and pruning only at a specific point in training (Section 6)."}, "signatures": ["ICLR.cc/2021/Conference/Paper5/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper5/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Pruning Neural Networks at Initialization: Why Are We Missing the Mark?", "authorids": ["~Jonathan_Frankle1", "~Gintare_Karolina_Dziugaite1", "~Daniel_Roy1", "~Michael_Carbin1"], "authors": ["Jonathan Frankle", "Gintare Karolina Dziugaite", "Daniel Roy", "Michael Carbin"], "keywords": ["Pruning", "Sparsity", "Lottery Ticket", "Science"], "abstract": "Recent work has explored the possibility of pruning neural networks at initialization. We assess proposals for doing so: SNIP (Lee et al., 2019), GraSP (Wang et al., 2020), SynFlow (Tanaka et al., 2020), and magnitude pruning. Although these methods surpass the trivial baseline of random pruning, they remain below the accuracy of magnitude pruning after training, and we endeavor to understand why. We show that, unlike pruning after training, randomly shuffling the weights these methods prune within each layer or sampling new initial values preserves or improves accuracy. As such, the per-weight pruning decisions made by these methods can be replaced by a per-layer choice of the fraction of weights to prune. This property suggests broader challenges with the underlying pruning heuristics, the desire to prune at initialization, or both.", "one-sentence_summary": "Methods for pruning neural nets at initialization perform the same or better when shuffling or reinitializing the weights they prune in each layer, a way in which they differ from SOTA weight-pruning methods after training.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "frankle|pruning_neural_networks_at_initialization_why_are_we_missing_the_mark", "supplementary_material": "/attachment/53da61b6607bb8f4e57707d3ae1dbba3d15d52f3.zip", "pdf": "/pdf/f6ac2e779528102e5a404479ffdebc7aa54decd9.pdf", "venueid": "ICLR.cc/2021/Conference", "venue": "ICLR 2021 Poster", "_bibtex": "@inproceedings{\nfrankle2021pruning,\ntitle={Pruning Neural Networks at Initialization: Why Are We Missing the Mark?},\nauthor={Jonathan Frankle and Gintare Karolina Dziugaite and Daniel Roy and Michael Carbin},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=Ig-VyQc-MLK}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "Ig-VyQc-MLK", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper5/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper5/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper5/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper5/Authors|ICLR.cc/2021/Conference/Paper5/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper5/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923875250, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper5/-/Official_Comment"}}}, {"id": "8ZDWAD4Lrly", "original": null, "number": 1, "cdate": 1603896741249, "ddate": null, "tcdate": 1603896741249, "tmdate": 1605024778154, "tddate": null, "forum": "Ig-VyQc-MLK", "replyto": "Ig-VyQc-MLK", "invitation": "ICLR.cc/2021/Conference/Paper5/-/Official_Review", "content": {"title": "An excellent tour-de-force review which carefully understands, investigates and scrutinizes recent work in neural network pruning from scratch", "review": "A recent trend of 'pruning at initialization' in neural network pruning has left me baffled. It's counter-intuitive that neural networks can be pruned at initialisation, improving results for the training done thereafter. Nitpicking semantics, one could hardly even call this a pruning technique, since there is no a-priori knowledge of the dataset distilled in the network. Perhaps it's more aptly referred to as a method of sparse initialisation methods.\nThe authors of this paper seem to have had the same doubts when it comes to the pruning at initialization literature, and put the magnifying glass on these methods that have recently been published. In an extensive and comprehensive study, they show that pruning at initialization methods do naught but set per-layer sparsity rates, where the sparse initialization might as well have been random.\n\nWriting these types of papers is important. It's essentially a survey paper, reproducing results from other papers, and testing their claims. In moving forward in this field, this type of work is crucial in filtering out the sense from the nonsense. Although the paper does not provide any new shiny optimization method, or stellar new GAN with a funny name, I highly laude the authors for working on this survey, and I believe the impact on the model efficiency community of this work is significant.\n\nNow on to the nitty-gritty of the paper. The key argument that shuffling the weights within a layer, essentially functioning like a re-initialization with a given per-layer sparsity ratio, is solid, convincing and damning. The inversion arguments equally so. The only qualm I have with the results are that there are not more on different architectures... but I hardly think that's necessary to make the point. If these methods were to work as intended, it should show on the common computer vision architectures we work with.\n\nThe paper is well-written and well-structured. Clear and concise, with an extensive appendix highlighting more background information, and showing that the authors know the field very well. They covered every angle I could think of to put a crowbar in the paper and pry open some problems. \n\nI would have liked to see a discussion on why we would even want to prune at initialization, because the arguments in the paper only really come to light if we consider the utility of the methods. Sure, pruning at initialization is worse than pruning, but perhaps there are reasons to prune at initialization anyway. Are we looking at this as a research exercise? A quest to improve our understanding of networks? Is it done for sparse training? If it's the latter, a discussion on this, and perhaps a comparison to other sparse training methods would be in order.", "rating": "9: Top 15% of accepted papers, strong accept", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}, "signatures": ["ICLR.cc/2021/Conference/Paper5/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper5/AnonReviewer2"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Pruning Neural Networks at Initialization: Why Are We Missing the Mark?", "authorids": ["~Jonathan_Frankle1", "~Gintare_Karolina_Dziugaite1", "~Daniel_Roy1", "~Michael_Carbin1"], "authors": ["Jonathan Frankle", "Gintare Karolina Dziugaite", "Daniel Roy", "Michael Carbin"], "keywords": ["Pruning", "Sparsity", "Lottery Ticket", "Science"], "abstract": "Recent work has explored the possibility of pruning neural networks at initialization. We assess proposals for doing so: SNIP (Lee et al., 2019), GraSP (Wang et al., 2020), SynFlow (Tanaka et al., 2020), and magnitude pruning. Although these methods surpass the trivial baseline of random pruning, they remain below the accuracy of magnitude pruning after training, and we endeavor to understand why. We show that, unlike pruning after training, randomly shuffling the weights these methods prune within each layer or sampling new initial values preserves or improves accuracy. As such, the per-weight pruning decisions made by these methods can be replaced by a per-layer choice of the fraction of weights to prune. This property suggests broader challenges with the underlying pruning heuristics, the desire to prune at initialization, or both.", "one-sentence_summary": "Methods for pruning neural nets at initialization perform the same or better when shuffling or reinitializing the weights they prune in each layer, a way in which they differ from SOTA weight-pruning methods after training.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "frankle|pruning_neural_networks_at_initialization_why_are_we_missing_the_mark", "supplementary_material": "/attachment/53da61b6607bb8f4e57707d3ae1dbba3d15d52f3.zip", "pdf": "/pdf/f6ac2e779528102e5a404479ffdebc7aa54decd9.pdf", "venueid": "ICLR.cc/2021/Conference", "venue": "ICLR 2021 Poster", "_bibtex": "@inproceedings{\nfrankle2021pruning,\ntitle={Pruning Neural Networks at Initialization: Why Are We Missing the Mark?},\nauthor={Jonathan Frankle and Gintare Karolina Dziugaite and Daniel Roy and Michael Carbin},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=Ig-VyQc-MLK}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq . ***Please remember to file the Code-of-Ethics report. Once you submitted the review, a link to the report will be visible in the bottom right corner of your review.***", "required": true, "markdown": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}, "forum": "Ig-VyQc-MLK", "replyto": "Ig-VyQc-MLK", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"], "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper5/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1607428800000, "duedate": 1606752000000, "multiReply": false, "readers": ["everyone"], "tcdate": 1602538151740, "tmdate": 1606915773395, "super": "ICLR.cc/2021/Conference/-/Official_Review", "signatures": ["OpenReview.net"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Paper5/Reviewers", "OpenReview.net/Support"], "id": "ICLR.cc/2021/Conference/Paper5/-/Official_Review"}}}, {"id": "rLklmQxfPz", "original": null, "number": 2, "cdate": 1603896821690, "ddate": null, "tcdate": 1603896821690, "tmdate": 1605024778096, "tddate": null, "forum": "Ig-VyQc-MLK", "replyto": "Ig-VyQc-MLK", "invitation": "ICLR.cc/2021/Conference/Paper5/-/Official_Review", "content": {"title": "Not convincing enough to support the claim", "review": "This is an empirical work assessing some of the recent works of early pruning methods in an effort to understand why early pruning methods perform worse than pruning after training methods. The paper is written very well, and some of the findings are interesting leaving important questions to address. Some major concerns remain though.\n\nThe paper proposes to achieve the following goal: to understand why early pruning methods perform worse than pruning after training methods.To achieve this, what the paper chooses to do is basically to measure their final performances and compare them to each other, and then to check for some ablation studies.\n\nObviously, the results (Figure 3) show which performs better than the other (i.e. pruning after training > pruning early), meaning that this result itself in terms of the final performance does not suffice to prove any cause or effect to explain the behaviors in comparison aimed to understand.\n\nIn the ablation studies (Section 5), the paper appears to be focused on studying and debunking the early pruning methods rather than finding *why* pruning after training is better than pruning early. For example, the result of random shuffling (early pruning methods for finding layerwise proportions) and the failure of GraSP when inverted are quite interesting, but they remain empirical without contributing directly to fulfill the purpose; some of the conclusions drawn from the ablation studies are not convincing (e.g., lack of specificity or insensitivity to initialization may limit performance); some of the claims are not expected to generalize either (e.g., shuffling to fully-connected layers, initializing with different standard deviations of the normal distribution).\n\nIn fact, an intuitive ablation setting is to test for the effect of training with the same saliency measure, as done in Section 6, but unfortunately the result out of this seems to be unhelpful for figuring out the potential cause of poor performances for pruning early methods. The results however show that early pruning methods improve after some training, indicating that training to some degree before pruning helps to increase the performance of the pruned model. One of the potentially many reasons that pruning early methods is underperformed by pruning after training methods could merely be the fact that the former is not trained before it gets pruned as opposed to the latter yielding the observed performance gap quite obviously. Anyway, the fact that they (after some training) still do not perform better than LTR (which requires oracle information) does not contribute to proving anything for why pruning early methods is underperformed by pruning after training either.\n\nIn short, this work does not explain \"why all methods fall short of magnitude pruning after training\" in a convincing manner, and the contributions are considered not quite significant overall.", "rating": "4: Ok but not good enough - rejection", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["ICLR.cc/2021/Conference/Paper5/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper5/AnonReviewer1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Pruning Neural Networks at Initialization: Why Are We Missing the Mark?", "authorids": ["~Jonathan_Frankle1", "~Gintare_Karolina_Dziugaite1", "~Daniel_Roy1", "~Michael_Carbin1"], "authors": ["Jonathan Frankle", "Gintare Karolina Dziugaite", "Daniel Roy", "Michael Carbin"], "keywords": ["Pruning", "Sparsity", "Lottery Ticket", "Science"], "abstract": "Recent work has explored the possibility of pruning neural networks at initialization. We assess proposals for doing so: SNIP (Lee et al., 2019), GraSP (Wang et al., 2020), SynFlow (Tanaka et al., 2020), and magnitude pruning. Although these methods surpass the trivial baseline of random pruning, they remain below the accuracy of magnitude pruning after training, and we endeavor to understand why. We show that, unlike pruning after training, randomly shuffling the weights these methods prune within each layer or sampling new initial values preserves or improves accuracy. As such, the per-weight pruning decisions made by these methods can be replaced by a per-layer choice of the fraction of weights to prune. This property suggests broader challenges with the underlying pruning heuristics, the desire to prune at initialization, or both.", "one-sentence_summary": "Methods for pruning neural nets at initialization perform the same or better when shuffling or reinitializing the weights they prune in each layer, a way in which they differ from SOTA weight-pruning methods after training.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "frankle|pruning_neural_networks_at_initialization_why_are_we_missing_the_mark", "supplementary_material": "/attachment/53da61b6607bb8f4e57707d3ae1dbba3d15d52f3.zip", "pdf": "/pdf/f6ac2e779528102e5a404479ffdebc7aa54decd9.pdf", "venueid": "ICLR.cc/2021/Conference", "venue": "ICLR 2021 Poster", "_bibtex": "@inproceedings{\nfrankle2021pruning,\ntitle={Pruning Neural Networks at Initialization: Why Are We Missing the Mark?},\nauthor={Jonathan Frankle and Gintare Karolina Dziugaite and Daniel Roy and Michael Carbin},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=Ig-VyQc-MLK}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq . ***Please remember to file the Code-of-Ethics report. Once you submitted the review, a link to the report will be visible in the bottom right corner of your review.***", "required": true, "markdown": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}, "forum": "Ig-VyQc-MLK", "replyto": "Ig-VyQc-MLK", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"], "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper5/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1607428800000, "duedate": 1606752000000, "multiReply": false, "readers": ["everyone"], "tcdate": 1602538151740, "tmdate": 1606915773395, "super": "ICLR.cc/2021/Conference/-/Official_Review", "signatures": ["OpenReview.net"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Paper5/Reviewers", "OpenReview.net/Support"], "id": "ICLR.cc/2021/Conference/Paper5/-/Official_Review"}}}], "count": 15}