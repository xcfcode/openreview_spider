{"notes": [{"tddate": null, "replyto": null, "ddate": null, "tmdate": 1528124455016, "tcdate": 1518430378485, "number": 107, "cdate": 1518430378485, "id": "BkG3_ykDz", "invitation": "ICLR.cc/2018/Workshop/-/Submission", "forum": "BkG3_ykDz", "signatures": ["~Sam_Leroux1"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Workshop"], "content": {"title": "IamNN: Iterative and Adaptive Mobile Neural Network for efficient image classification", "abstract": "Deep residual networks (ResNets) made a recent breakthrough in deep learning. The core idea of ResNets is to have shortcut connections between layers that allow the network to be much deeper while still being easy to optimize avoiding vanishing gradients. These shortcut connections have interesting properties that make ResNets behave differently from other typical network architectures. In this work we use these properties to design a network based on a ResNet but with parameter sharing and with adaptive computation time. The resulting network is much smaller than the original network and can adapt the computational cost to the complexity of the input image.", "paperhash": "leroux|iamnn_iterative_and_adaptive_mobile_neural_network_for_efficient_image_classification", "keywords": ["efficient neural network", "resource constrained", "mobile", "weight sharing", "adaptive computation time"], "_bibtex": "@misc{\n  leroux2018iamnn:,\n  title={IamNN: Iterative and Adaptive Mobile Neural Network for efficient image classification},\n  author={Sam Leroux and Pavlo Molchanov and Pieter Simoens and Bart Dhoedt and Thomas Breuel and Jan Kautz},\n  year={2018},\n  url={https://openreview.net/forum?id=BkG3_ykDz}\n}", "authorids": ["sam.leroux@ugent.be", "pmolchanov@nvidia.com", "pieter.simoens@ugent.be", "bart.dhoedt@ugent.be", "tbreuel@nvidia.com", "jkautz@nvidia.com"], "authors": ["Sam Leroux", "Pavlo Molchanov", "Pieter Simoens", "Bart Dhoedt", "Thomas Breuel", "Jan Kautz"], "TL;DR": "A ResNet inspired network with a small memory footprint that can adapt the computational cost to the complexity of the input.", "pdf": "/pdf/6eed1ee749e3b54fa92881d54a1a3dffb5716933.pdf"}, "nonreaders": [], "details": {"replyCount": 3, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1518472800000, "tmdate": 1518474081690, "id": "ICLR.cc/2018/Workshop/-/Submission", "writers": ["ICLR.cc/2018/Workshop"], "signatures": ["ICLR.cc/2018/Workshop"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": null, "replyto": null, "writers": {"values": ["ICLR.cc/2018/Workshop"]}, "signatures": {"values-regex": "~.*|ICLR.cc/2018/Workshop", "description": "Your authorized identity to be associated with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"pdf": {"required": true, "order": 9, "value-regex": "upload", "description": "Upload a PDF file that ends with .pdf"}, "title": {"required": true, "order": 1, "description": "Title of paper.", "value-regex": ".{1,250}"}, "abstract": {"required": true, "order": 8, "description": "Abstract of paper.", "value-regex": "[\\S\\s]{1,5000}"}, "authors": {"required": true, "order": 2, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of author names. Please provide real names; identities will be anonymized."}, "keywords": {"order": 6, "values-regex": "(^$)|[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of keywords."}, "TL;DR": {"required": false, "order": 7, "description": "\"Too Long; Didn't Read\": a short sentence describing your paper", "value-regex": "[^\\n]{0,500}"}, "authorids": {"required": true, "order": 3, "values-regex": "([a-z0-9_\\-\\.]{2,}@[a-z0-9_\\-\\.]{2,}\\.[a-z]{2,},){0,}([a-z0-9_\\-\\.]{2,}@[a-z0-9_\\-\\.]{2,}\\.[a-z]{2,})", "description": "Comma separated list of author email addresses, lowercased, in the same order as above. For authors with existing OpenReview accounts, please make sure that the provided email address(es) match those listed in the author's profile. Please provide real emails; identities will be anonymized."}}}, "nonreaders": [], "noninvitees": [], "expdate": 1526248800000, "cdate": 1518474081690}}}, {"tddate": null, "ddate": null, "original": null, "tmdate": 1521582830252, "tcdate": 1520605494660, "number": 1, "cdate": 1520605494660, "id": "B11HKfeYf", "invitation": "ICLR.cc/2018/Workshop/-/Paper107/Official_Review", "forum": "BkG3_ykDz", "replyto": "BkG3_ykDz", "signatures": ["ICLR.cc/2018/Workshop/Paper107/AnonReviewer1"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Workshop/Paper107/AnonReviewer1"], "content": {"title": "Results are not so good", "rating": "6: Marginally above acceptance threshold", "review": "Enhancing deep CNN model efficiency is very important. This paper combines two existing techniques (sharing weights across layers) and ACT to develop a new architecture for ResNet, in a nice way. The presented idea and architecture are interesting. But the evaluation results are not so impressive. It is slightly better than GoogleNet but not so good as ShuffleNet and MobileNet. As discussed by the authors, the model can be further compressed using separate convolutions. It will be interesting to see such results.", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "IamNN: Iterative and Adaptive Mobile Neural Network for efficient image classification", "abstract": "Deep residual networks (ResNets) made a recent breakthrough in deep learning. The core idea of ResNets is to have shortcut connections between layers that allow the network to be much deeper while still being easy to optimize avoiding vanishing gradients. These shortcut connections have interesting properties that make ResNets behave differently from other typical network architectures. In this work we use these properties to design a network based on a ResNet but with parameter sharing and with adaptive computation time. The resulting network is much smaller than the original network and can adapt the computational cost to the complexity of the input image.", "paperhash": "leroux|iamnn_iterative_and_adaptive_mobile_neural_network_for_efficient_image_classification", "keywords": ["efficient neural network", "resource constrained", "mobile", "weight sharing", "adaptive computation time"], "_bibtex": "@misc{\n  leroux2018iamnn:,\n  title={IamNN: Iterative and Adaptive Mobile Neural Network for efficient image classification},\n  author={Sam Leroux and Pavlo Molchanov and Pieter Simoens and Bart Dhoedt and Thomas Breuel and Jan Kautz},\n  year={2018},\n  url={https://openreview.net/forum?id=BkG3_ykDz}\n}", "authorids": ["sam.leroux@ugent.be", "pmolchanov@nvidia.com", "pieter.simoens@ugent.be", "bart.dhoedt@ugent.be", "tbreuel@nvidia.com", "jkautz@nvidia.com"], "authors": ["Sam Leroux", "Pavlo Molchanov", "Pieter Simoens", "Bart Dhoedt", "Thomas Breuel", "Jan Kautz"], "TL;DR": "A ResNet inspired network with a small memory footprint that can adapt the computational cost to the complexity of the input.", "pdf": "/pdf/6eed1ee749e3b54fa92881d54a1a3dffb5716933.pdf"}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1520657999000, "tmdate": 1521582830068, "id": "ICLR.cc/2018/Workshop/-/Paper107/Official_Review", "writers": ["ICLR.cc/2018/Workshop"], "signatures": ["ICLR.cc/2018/Workshop"], "readers": ["everyone"], "invitees": ["ICLR.cc/2018/Workshop/Paper107/Reviewers"], "noninvitees": ["ICLR.cc/2018/Workshop/Paper107/AnonReviewer1", "ICLR.cc/2018/Workshop/Paper107/AnonReviewer3"], "reply": {"forum": "BkG3_ykDz", "replyto": "BkG3_ykDz", "writers": {"values-regex": "ICLR.cc/2018/Workshop/Paper107/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2018/Workshop/Paper107/AnonReviewer[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"required": true, "order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"required": true, "order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "value-regex": "[\\S\\s]{1,200000}"}, "rating": {"required": true, "order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"required": true, "order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1528433999000, "cdate": 1521582830068}}}, {"tddate": null, "ddate": null, "original": null, "tmdate": 1521582828513, "tcdate": 1520607950744, "number": 2, "cdate": 1520607950744, "id": "SkPRzQeKz", "invitation": "ICLR.cc/2018/Workshop/-/Paper107/Official_Review", "forum": "BkG3_ykDz", "replyto": "BkG3_ykDz", "signatures": ["ICLR.cc/2018/Workshop/Paper107/AnonReviewer3"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Workshop/Paper107/AnonReviewer3"], "content": {"title": "Important research direction; further careful analysis needed", "rating": "7: Good paper, accept", "review": "This paper proposes a method of training neural networks with:\na) fewer free parameters (weights), and,\nb) variable cost of inference\ncompared to an original Highway or Residual network. The cost of inference is restricted to be less than or equal to the original network.\n\nThe method is a natural consequence of the iterative estimation view of Highway and Residual networks put forth by Greff et al., so it only applies to networks that conform to this view. The reduction in parameters is achieved by tying the weights of multiple layers/blocks, and the variable number of feature estimation steps is learned using ACT proposed by Graves.\n\nThis is a very natural marriage of recent ideas and has practical significance. However, the results are certainly preliminary. \nThe authors use a very large ResNet101 as baseline for CIFAR datasets (>40M Params), when much smaller deep networks also perform very well on them. Does the method only appear to work well when the baseline network uses too many parameters/FLOPS to begin with? Is there a benefit over simply training a smaller network?\nNevertheless, the preliminary results seem sufficient for a workshop acceptance. I hope that the authors will be careful in discussing the implications of the current results.\n\nI should also point out that Adaptive Computation in general is not completely new, additional references are mentioned by Graves (2016).\n\nPros:\n- important direction of model development\n- encouraging initial results combining ACT and iterative estimation\n\nCons:\n- important comparisons are missing, eventual final results may not be convincing", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "IamNN: Iterative and Adaptive Mobile Neural Network for efficient image classification", "abstract": "Deep residual networks (ResNets) made a recent breakthrough in deep learning. The core idea of ResNets is to have shortcut connections between layers that allow the network to be much deeper while still being easy to optimize avoiding vanishing gradients. These shortcut connections have interesting properties that make ResNets behave differently from other typical network architectures. In this work we use these properties to design a network based on a ResNet but with parameter sharing and with adaptive computation time. The resulting network is much smaller than the original network and can adapt the computational cost to the complexity of the input image.", "paperhash": "leroux|iamnn_iterative_and_adaptive_mobile_neural_network_for_efficient_image_classification", "keywords": ["efficient neural network", "resource constrained", "mobile", "weight sharing", "adaptive computation time"], "_bibtex": "@misc{\n  leroux2018iamnn:,\n  title={IamNN: Iterative and Adaptive Mobile Neural Network for efficient image classification},\n  author={Sam Leroux and Pavlo Molchanov and Pieter Simoens and Bart Dhoedt and Thomas Breuel and Jan Kautz},\n  year={2018},\n  url={https://openreview.net/forum?id=BkG3_ykDz}\n}", "authorids": ["sam.leroux@ugent.be", "pmolchanov@nvidia.com", "pieter.simoens@ugent.be", "bart.dhoedt@ugent.be", "tbreuel@nvidia.com", "jkautz@nvidia.com"], "authors": ["Sam Leroux", "Pavlo Molchanov", "Pieter Simoens", "Bart Dhoedt", "Thomas Breuel", "Jan Kautz"], "TL;DR": "A ResNet inspired network with a small memory footprint that can adapt the computational cost to the complexity of the input.", "pdf": "/pdf/6eed1ee749e3b54fa92881d54a1a3dffb5716933.pdf"}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1520657999000, "tmdate": 1521582830068, "id": "ICLR.cc/2018/Workshop/-/Paper107/Official_Review", "writers": ["ICLR.cc/2018/Workshop"], "signatures": ["ICLR.cc/2018/Workshop"], "readers": ["everyone"], "invitees": ["ICLR.cc/2018/Workshop/Paper107/Reviewers"], "noninvitees": ["ICLR.cc/2018/Workshop/Paper107/AnonReviewer1", "ICLR.cc/2018/Workshop/Paper107/AnonReviewer3"], "reply": {"forum": "BkG3_ykDz", "replyto": "BkG3_ykDz", "writers": {"values-regex": "ICLR.cc/2018/Workshop/Paper107/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2018/Workshop/Paper107/AnonReviewer[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"required": true, "order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"required": true, "order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "value-regex": "[\\S\\s]{1,200000}"}, "rating": {"required": true, "order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"required": true, "order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1528433999000, "cdate": 1521582830068}}}, {"tddate": null, "ddate": null, "original": null, "tmdate": 1521573560694, "tcdate": 1521573560694, "number": 78, "cdate": 1521573560348, "id": "HkZT0RCYG", "invitation": "ICLR.cc/2018/Workshop/-/Acceptance_Decision", "forum": "BkG3_ykDz", "replyto": "BkG3_ykDz", "signatures": ["ICLR.cc/2018/Workshop/Program_Chairs"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Workshop/Program_Chairs"], "content": {"decision": "Accept", "title": "ICLR 2018 Workshop Acceptance Decision", "comment": "Congratulations, your paper was accepted to the ICLR workshop."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "IamNN: Iterative and Adaptive Mobile Neural Network for efficient image classification", "abstract": "Deep residual networks (ResNets) made a recent breakthrough in deep learning. The core idea of ResNets is to have shortcut connections between layers that allow the network to be much deeper while still being easy to optimize avoiding vanishing gradients. These shortcut connections have interesting properties that make ResNets behave differently from other typical network architectures. In this work we use these properties to design a network based on a ResNet but with parameter sharing and with adaptive computation time. The resulting network is much smaller than the original network and can adapt the computational cost to the complexity of the input image.", "paperhash": "leroux|iamnn_iterative_and_adaptive_mobile_neural_network_for_efficient_image_classification", "keywords": ["efficient neural network", "resource constrained", "mobile", "weight sharing", "adaptive computation time"], "_bibtex": "@misc{\n  leroux2018iamnn:,\n  title={IamNN: Iterative and Adaptive Mobile Neural Network for efficient image classification},\n  author={Sam Leroux and Pavlo Molchanov and Pieter Simoens and Bart Dhoedt and Thomas Breuel and Jan Kautz},\n  year={2018},\n  url={https://openreview.net/forum?id=BkG3_ykDz}\n}", "authorids": ["sam.leroux@ugent.be", "pmolchanov@nvidia.com", "pieter.simoens@ugent.be", "bart.dhoedt@ugent.be", "tbreuel@nvidia.com", "jkautz@nvidia.com"], "authors": ["Sam Leroux", "Pavlo Molchanov", "Pieter Simoens", "Bart Dhoedt", "Thomas Breuel", "Jan Kautz"], "TL;DR": "A ResNet inspired network with a small memory footprint that can adapt the computational cost to the complexity of the input.", "pdf": "/pdf/6eed1ee749e3b54fa92881d54a1a3dffb5716933.pdf"}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "tmdate": 1518629844880, "id": "ICLR.cc/2018/Workshop/-/Acceptance_Decision", "writers": ["ICLR.cc/2018/Workshop"], "signatures": ["ICLR.cc/2018/Workshop"], "readers": ["everyone"], "invitees": ["ICLR.cc/2018/Workshop/Program_Chairs"], "reply": {"forum": null, "replyto": null, "invitation": "ICLR.cc/2018/Workshop/-/Submission", "writers": {"values": ["ICLR.cc/2018/Workshop/Program_Chairs"]}, "signatures": {"description": "How your identity will be displayed with the above content.", "values": ["ICLR.cc/2018/Workshop/Program_Chairs"]}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["ICLR.cc/2018/Workshop/Program_Chairs", "everyone"]}, "content": {"title": {"required": true, "order": 1, "value": "ICLR 2018 Workshop Acceptance Decision"}, "comment": {"required": false, "order": 3, "description": "(optional) Comment on this decision.", "value-regex": "[\\S\\s]{0,5000}"}, "decision": {"required": true, "order": 2, "value-dropdown": ["Accept", "Reject"]}}}, "nonreaders": [], "noninvitees": [], "cdate": 1518629844880}}}], "count": 4}