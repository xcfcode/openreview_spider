{"notes": [{"id": "S1ltj47xdE", "original": "HJeYATKFDV", "number": 29, "cdate": 1553114273481, "ddate": null, "tcdate": 1553114273481, "tmdate": 1562082104366, "tddate": null, "forum": "S1ltj47xdE", "replyto": null, "invitation": "ICLR.cc/2019/Workshop/LLD/-/Blind_Submission", "content": {"title": "Passage Ranking with Weak Supervision", "authors": ["Peng Xu", "Xiaofei Ma", "Ramesh Nallapati", "Bing Xiang"], "authorids": ["pengx@amazon.com", "xiaofeim@amazon.com", "rnallapa@amazon.com", "bxiang@amazon.com"], "keywords": ["Passage Ranking", "Weak Supervision", "BERT Models"], "TL;DR": "We propose a weak supervision training pipeline based on the data programming framework for ranking tasks, in which we train a BERT-base ranking model and establish the new SOTA.", "abstract": "In this paper, we propose a \\textit{weak supervision} framework for neural ranking tasks based on the data programming paradigm \\citep{Ratner2016}, which enables us to leverage multiple weak supervision signals from different sources. Empirically, we consider two sources of weak supervision signals, unsupervised ranking functions and semantic feature similarities. We train a BERT-based passage-ranking model (which achieves new state-of-the-art performances on two benchmark datasets with full supervision) in our weak supervision framework. Without using ground-truth training labels, BERT-PR models outperform BM25 baseline by a large margin on all three datasets and even beat the previous state-of-the-art results with full supervision on two of datasets.", "pdf": "/pdf/fb303b25b1d8291d03497a3bbddda483b29142c4.pdf", "paperhash": "xu|passage_ranking_with_weak_supervision"}, "signatures": ["ICLR.cc/2019/Workshop/LLD"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Workshop/LLD"], "details": {"replyCount": 2, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"id": "ICLR.cc/2019/Workshop/LLD/-/Blind_Submission", "cdate": 1548689671889, "reply": {"forum": null, "replyto": null, "readers": {"values-regex": ".*"}, "writers": {"values": ["ICLR.cc/2019/Workshop/LLD"]}, "signatures": {"values": ["ICLR.cc/2019/Workshop/LLD"]}, "content": {"authors": {"values-regex": ".*"}, "authorids": {"values-regex": ".*"}}}, "tcdate": 1548689671889, "tmdate": 1557933709646, "readers": ["everyone"], "writers": ["ICLR.cc/2019/Workshop/LLD"], "invitees": ["~"], "signatures": ["ICLR.cc/2019/Workshop/LLD"], "details": {"writable": true}}}, "tauthor": "OpenReview.net"}, {"id": "HkxeVLCAYE", "original": null, "number": 1, "cdate": 1555125799728, "ddate": null, "tcdate": 1555125799728, "tmdate": 1555511874969, "tddate": null, "forum": "S1ltj47xdE", "replyto": "S1ltj47xdE", "invitation": "ICLR.cc/2019/Workshop/LLD/-/Paper29/Official_Review", "content": {"title": "Good empirical contribution", "review": "The authors tackle the problem of passage ranking (i.e. given a query, rank the relevance of set of passages to this query), and propose using an interesting combination of two existing approaches: BERT, which has achieved state-of-the-art result on many similar NLP problems, and the weak supervision framework proposed by Ratner et al. (2016). The authors show that this combination obtains results that are better than the current fully supervised state-of-the-art.\n\nOverall, although the different components of this system are not novel, this work seems to have a good contribution as an application paper since the results look good, and the topic is also very relevant to this workshop. However, my most major concern is the comparison with other similar approaches (in terms of methods and results). Specifically, there seems to be a related paper that is not properly discussed, nor fully compared with in terms of results (see my comments below).\n\nStrengths:\n- the problem is very relevant to this workshop.\n- the results look good.\n- the explanations are generally clear and easy to follow.\n\n\nMajor weaknesses:\n- it sounds from the authors' description that the work of Nogueira & Cho (2019)  is very similar, and yet this paper doesn't discuss the similarities in enough detail. For instance \"Nogueira & Cho (2019) does not have an MLP module\" -- so what does it have instead?  Also, do they also do weakly supervised training?\n- why are the results of Nogueira & Cho (2019) not reported in the table (except for one number in the footnote)?\n- the citation for the most similar work is incomplete, it only says \"Rodrigo Nogueira and Kyunghyun Cho. Passage Re-ranking with BERT. 2019.\", with no information where to find it.\n- it's unclear from this paper whether there are other weakly supervised approaches on these datasets, other than the traditional ranking scores the authors used as baseline. If the aren't, that should be specified. If there are, they should be compared and reported in the table too.\n\nMinor issues:\n- authors refer to BM25 scores without ever explaining what they are (e.g. \"models trained on labels solely generated from BM25 scores\"), which can be an issue for anyone who hasn't specifically worked in information retrieval.\n- there are a few grammatical mistakes.\n- why did the authors chose the hidden state of the CLS token as the embedding that is used as input to the MLP?\n- what is s_ij in the \"Supervised Training\" paragraph of section 2?", "rating": "4: Top 50% of accepted papers, clear accept", "confidence": "2: The reviewer is fairly confident that the evaluation is correct"}, "signatures": ["ICLR.cc/2019/Workshop/LLD/Paper29/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Workshop/LLD/Paper29/AnonReviewer1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Passage Ranking with Weak Supervision", "authors": ["Peng Xu", "Xiaofei Ma", "Ramesh Nallapati", "Bing Xiang"], "authorids": ["pengx@amazon.com", "xiaofeim@amazon.com", "rnallapa@amazon.com", "bxiang@amazon.com"], "keywords": ["Passage Ranking", "Weak Supervision", "BERT Models"], "TL;DR": "We propose a weak supervision training pipeline based on the data programming framework for ranking tasks, in which we train a BERT-base ranking model and establish the new SOTA.", "abstract": "In this paper, we propose a \\textit{weak supervision} framework for neural ranking tasks based on the data programming paradigm \\citep{Ratner2016}, which enables us to leverage multiple weak supervision signals from different sources. Empirically, we consider two sources of weak supervision signals, unsupervised ranking functions and semantic feature similarities. We train a BERT-based passage-ranking model (which achieves new state-of-the-art performances on two benchmark datasets with full supervision) in our weak supervision framework. Without using ground-truth training labels, BERT-PR models outperform BM25 baseline by a large margin on all three datasets and even beat the previous state-of-the-art results with full supervision on two of datasets.", "pdf": "/pdf/fb303b25b1d8291d03497a3bbddda483b29142c4.pdf", "paperhash": "xu|passage_ranking_with_weak_supervision"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Workshop/LLD/-/Paper29/Official_Review", "cdate": 1553713417294, "expdate": 1555718400000, "duedate": 1554681600000, "reply": {"forum": "S1ltj47xdE", "replyto": "S1ltj47xdE", "writers": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2019/Workshop/LLD/Paper29/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2019/Workshop/LLD/Paper29/AnonReviewer[0-9]+"}, "readers": {"values": ["everyone"], "description": "The users who will be allowed to read the above content."}, "content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "required": true}, "rating": {"order": 3, "value-dropdown": ["5: Top 15% of accepted papers, strong accept", "4: Top 50% of accepted papers, clear accept", "3: Marginally above acceptance threshold", "2: Marginally below acceptance threshold", "1: Strong rejection"], "required": true}, "confidence": {"order": 4, "value-radio": ["3: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "2: The reviewer is fairly confident that the evaluation is correct", "1: The reviewer's evaluation is an educated guess"], "required": true}}}, "tcdate": 1553713417294, "tmdate": 1555511814874, "readers": ["everyone"], "writers": ["ICLR.cc/2019/Workshop/LLD"], "invitees": ["ICLR.cc/2019/Workshop/LLD/Paper29/Reviewers"], "signatures": ["ICLR.cc/2019/Workshop/LLD"]}}}, {"id": "SJx3e53z54", "original": null, "number": 1, "cdate": 1555380723945, "ddate": null, "tcdate": 1555380723945, "tmdate": 1555510980034, "tddate": null, "forum": "S1ltj47xdE", "replyto": "S1ltj47xdE", "invitation": "ICLR.cc/2019/Workshop/LLD/-/Paper29/Decision", "content": {"title": "Acceptance Decision", "decision": "Accept"}, "signatures": ["ICLR.cc/2019/Workshop/LLD/Program_Chairs"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Workshop/LLD/Program_Chairs"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Passage Ranking with Weak Supervision", "authors": ["Peng Xu", "Xiaofei Ma", "Ramesh Nallapati", "Bing Xiang"], "authorids": ["pengx@amazon.com", "xiaofeim@amazon.com", "rnallapa@amazon.com", "bxiang@amazon.com"], "keywords": ["Passage Ranking", "Weak Supervision", "BERT Models"], "TL;DR": "We propose a weak supervision training pipeline based on the data programming framework for ranking tasks, in which we train a BERT-base ranking model and establish the new SOTA.", "abstract": "In this paper, we propose a \\textit{weak supervision} framework for neural ranking tasks based on the data programming paradigm \\citep{Ratner2016}, which enables us to leverage multiple weak supervision signals from different sources. Empirically, we consider two sources of weak supervision signals, unsupervised ranking functions and semantic feature similarities. We train a BERT-based passage-ranking model (which achieves new state-of-the-art performances on two benchmark datasets with full supervision) in our weak supervision framework. Without using ground-truth training labels, BERT-PR models outperform BM25 baseline by a large margin on all three datasets and even beat the previous state-of-the-art results with full supervision on two of datasets.", "pdf": "/pdf/fb303b25b1d8291d03497a3bbddda483b29142c4.pdf", "paperhash": "xu|passage_ranking_with_weak_supervision"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Workshop/LLD/-/Paper29/Decision", "cdate": 1554736066262, "reply": {"forum": "S1ltj47xdE", "replyto": "S1ltj47xdE", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-regex": ["ICLR.cc/2019/Workshop/LLD/Program_Chairs"], "description": "How your identity will be displayed."}, "signatures": {"values": ["ICLR.cc/2019/Workshop/LLD/Program_Chairs"], "description": "How your identity will be displayed."}, "content": {"title": {"order": 1, "required": true, "value": "Acceptance Decision"}, "decision": {"order": 2, "required": true, "value-radio": ["Accept", "Reject"], "description": "Acceptance decision"}, "comment": {"order": 3, "required": false, "value-regex": "[\\S\\s]{0,5000}", "description": ""}}}, "tcdate": 1554736066262, "tmdate": 1555510972414, "readers": ["everyone"], "writers": ["ICLR.cc/2019/Workshop/LLD"], "invitees": ["ICLR.cc/2019/Workshop/LLD/Program_Chairs"], "signatures": ["ICLR.cc/2019/Workshop/LLD"]}}}], "count": 3}