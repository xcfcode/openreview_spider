{"notes": [{"tddate": null, "replyto": null, "ddate": null, "tmdate": 1528124433594, "tcdate": 1518475503178, "number": 360, "cdate": 1518475503178, "id": "HyDgK9yDM", "invitation": "ICLR.cc/2018/Workshop/-/Submission", "forum": "HyDgK9yDM", "signatures": ["~Keyvan_Kasiri1"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Workshop"], "content": {"title": "Efficient Network Structure via Ensemble Deep Evolutionary Synthesis", "abstract": "While deep neural networks have shown promising results in a wide range of\napplications on highly powerful computational devices, one challenging task is\nto deploy a deep neural network on embedded devices for the widespread use.\nDeep neural networks and specially convolutional neural networks are usually\nover-parameterized and one possible solution is to remodel the network architecture\nwith a smaller network architecture with a trade-off on modeling accuracy\nand performance. Here we take advantage of meta-learning algorithms to synthesize\na more efficient model while it boosts the modeling performance. To this\nend, we propose an ensemble of deep evolutionary intelligence frameworks where\nit synthesizes several very efficient models with less than 3% drop on modeling\naccuracy and then aggregates them to boost the modeling performance. Experimental\nresults demonstrates that the proposed ensemble of Deep Evolutionary\nSynthesis approach synthesizes an ensemble model which is 1.5X smaller than\nthe original network architecture while performing more accurate (83.30% compared\nto 83.18%) than the original network in terms of modeling accuracy for\nbinary object segmentation.", "paperhash": "kasiri|efficient_network_structure_via_ensemble_deep_evolutionary_synthesis", "_bibtex": "@misc{\n  kasiri2018efficient,\n  title={Efficient Network Structure via Ensemble Deep Evolutionary Synthesis},\n  author={Keyvan Kasiri and Mohammad Javad Shafiee and Alexander Wong and Justin Eichel},\n  year={2018},\n  url={https://openreview.net/forum?id=HyDgK9yDM}\n}", "authorids": ["kkasiri@uwaterloo.ca", "mjshafiee@uwaterloo.ca", "awong@uwaterloo.ca", "jeichel@miovision.com"], "authors": ["Keyvan Kasiri", "Mohammad Javad Shafiee", "Alexander Wong", "Justin Eichel"], "keywords": ["Deep neural networks", "evolutionary synthesis", "ensemble learning"], "pdf": "/pdf/ab4f8bd5f45e7da19425f91b7649dafa11939977.pdf"}, "nonreaders": [], "details": {"replyCount": 3, "writable": false, "overwriting": [], "revisions": false, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1518472800000, "tmdate": 1518474081690, "id": "ICLR.cc/2018/Workshop/-/Submission", "writers": ["ICLR.cc/2018/Workshop"], "signatures": ["ICLR.cc/2018/Workshop"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": null, "replyto": null, "writers": {"values": ["ICLR.cc/2018/Workshop"]}, "signatures": {"values-regex": "~.*|ICLR.cc/2018/Workshop", "description": "Your authorized identity to be associated with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"pdf": {"required": true, "order": 9, "value-regex": "upload", "description": "Upload a PDF file that ends with .pdf"}, "title": {"required": true, "order": 1, "description": "Title of paper.", "value-regex": ".{1,250}"}, "abstract": {"required": true, "order": 8, "description": "Abstract of paper.", "value-regex": "[\\S\\s]{1,5000}"}, "authors": {"required": true, "order": 2, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of author names. Please provide real names; identities will be anonymized."}, "keywords": {"order": 6, "values-regex": "(^$)|[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of keywords."}, "TL;DR": {"required": false, "order": 7, "description": "\"Too Long; Didn't Read\": a short sentence describing your paper", "value-regex": "[^\\n]{0,500}"}, "authorids": {"required": true, "order": 3, "values-regex": "([a-z0-9_\\-\\.]{2,}@[a-z0-9_\\-\\.]{2,}\\.[a-z]{2,},){0,}([a-z0-9_\\-\\.]{2,}@[a-z0-9_\\-\\.]{2,}\\.[a-z]{2,})", "description": "Comma separated list of author email addresses, lowercased, in the same order as above. For authors with existing OpenReview accounts, please make sure that the provided email address(es) match those listed in the author's profile. Please provide real emails; identities will be anonymized."}}}, "nonreaders": [], "noninvitees": [], "expdate": 1526248800000, "cdate": 1518474081690}}}, {"tddate": null, "ddate": null, "original": null, "tmdate": 1521582904229, "tcdate": 1520458263991, "number": 1, "cdate": 1520458263991, "id": "SklmqA6OM", "invitation": "ICLR.cc/2018/Workshop/-/Paper360/Official_Review", "forum": "HyDgK9yDM", "replyto": "HyDgK9yDM", "signatures": ["ICLR.cc/2018/Workshop/Paper360/AnonReviewer3"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Workshop/Paper360/AnonReviewer3"], "content": {"title": "The idea of generating neural networks using evolutionary computing is not new", "rating": "5: Marginally below acceptance threshold", "review": "The authors of this paper propose an idea of generating CNN networks using evolutionary computing. Generally speaking, this idea has a long history, where the main challenges are coding strategies and computational efficiency. This paper does not answer the essential questions in this topic: How many generations are needed for the producing good individuals? In each generation, what the number of individual networks? How many networks are sufficient in the ensemble learning based decision making?\n\nMinors:\nperforming more accurate -> performing more accurately\n\nMulti-Column deep neural network -> Multi-column deep neural network\n\ninspiring from biological evolution -> inspired from biological evolution\n\nwas proposed in ?: missing citation\n\nI could not understand this phase \"in synthesised in generation g\"", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Efficient Network Structure via Ensemble Deep Evolutionary Synthesis", "abstract": "While deep neural networks have shown promising results in a wide range of\napplications on highly powerful computational devices, one challenging task is\nto deploy a deep neural network on embedded devices for the widespread use.\nDeep neural networks and specially convolutional neural networks are usually\nover-parameterized and one possible solution is to remodel the network architecture\nwith a smaller network architecture with a trade-off on modeling accuracy\nand performance. Here we take advantage of meta-learning algorithms to synthesize\na more efficient model while it boosts the modeling performance. To this\nend, we propose an ensemble of deep evolutionary intelligence frameworks where\nit synthesizes several very efficient models with less than 3% drop on modeling\naccuracy and then aggregates them to boost the modeling performance. Experimental\nresults demonstrates that the proposed ensemble of Deep Evolutionary\nSynthesis approach synthesizes an ensemble model which is 1.5X smaller than\nthe original network architecture while performing more accurate (83.30% compared\nto 83.18%) than the original network in terms of modeling accuracy for\nbinary object segmentation.", "paperhash": "kasiri|efficient_network_structure_via_ensemble_deep_evolutionary_synthesis", "_bibtex": "@misc{\n  kasiri2018efficient,\n  title={Efficient Network Structure via Ensemble Deep Evolutionary Synthesis},\n  author={Keyvan Kasiri and Mohammad Javad Shafiee and Alexander Wong and Justin Eichel},\n  year={2018},\n  url={https://openreview.net/forum?id=HyDgK9yDM}\n}", "authorids": ["kkasiri@uwaterloo.ca", "mjshafiee@uwaterloo.ca", "awong@uwaterloo.ca", "jeichel@miovision.com"], "authors": ["Keyvan Kasiri", "Mohammad Javad Shafiee", "Alexander Wong", "Justin Eichel"], "keywords": ["Deep neural networks", "evolutionary synthesis", "ensemble learning"], "pdf": "/pdf/ab4f8bd5f45e7da19425f91b7649dafa11939977.pdf"}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1520657999000, "tmdate": 1521582904045, "id": "ICLR.cc/2018/Workshop/-/Paper360/Official_Review", "writers": ["ICLR.cc/2018/Workshop"], "signatures": ["ICLR.cc/2018/Workshop"], "readers": ["everyone"], "invitees": ["ICLR.cc/2018/Workshop/Paper360/Reviewers"], "noninvitees": ["ICLR.cc/2018/Workshop/Paper360/AnonReviewer3", "ICLR.cc/2018/Workshop/Paper360/AnonReviewer1"], "reply": {"forum": "HyDgK9yDM", "replyto": "HyDgK9yDM", "writers": {"values-regex": "ICLR.cc/2018/Workshop/Paper360/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2018/Workshop/Paper360/AnonReviewer[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"required": true, "order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"required": true, "order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "value-regex": "[\\S\\s]{1,200000}"}, "rating": {"required": true, "order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"required": true, "order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1528433999000, "cdate": 1521582904045}}}, {"tddate": null, "ddate": null, "original": null, "tmdate": 1521582768357, "tcdate": 1520637803277, "number": 2, "cdate": 1520637803277, "id": "rJQOPcgFG", "invitation": "ICLR.cc/2018/Workshop/-/Paper360/Official_Review", "forum": "HyDgK9yDM", "replyto": "HyDgK9yDM", "signatures": ["ICLR.cc/2018/Workshop/Paper360/AnonReviewer1"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Workshop/Paper360/AnonReviewer1"], "content": {"title": "Hard to understand, very few experiments.", "rating": "2: Strong rejection", "review": "As I understand it, this paper proposes a way to \"evolve\" a network into a set of sparse versions of the model; this evolutionary process is then used to \"synthesize\" several variations of the original model, which are then combined as an ensemble.  They show through an experiment on a small image dataset that the performance of the ensemble is able to achieve slightly better performance than the original model, even though it uses less memory.\n\nMy largest complaints about this paper are in regard to clarity, and quality of experiments.  The evolutionary process is barely described (the different terms in equations (1) and (2) are not defined precisely).  The writing is quite hard to understand.  The dataset used is rather small, and I was not familiar with it in advance.  Very few experimental results are reported; they simply synthesize three version of the same model, and take the ensemble.  They do not compare the results to baselines, such as other methods for network pruning, or consider using structured matrices in order to reduce the memory footprint of their models (their stated goal).  It is unclear to me what the novel contribution of this paper is, or whether the experimental results are significant (since they don't compare to baselines, and they run a very small number of experiments).\n\nI am not familiar with the existing work on evolutionary synthesis of DNNs, so it is hard for me to comment on how this work builds on that work.", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Efficient Network Structure via Ensemble Deep Evolutionary Synthesis", "abstract": "While deep neural networks have shown promising results in a wide range of\napplications on highly powerful computational devices, one challenging task is\nto deploy a deep neural network on embedded devices for the widespread use.\nDeep neural networks and specially convolutional neural networks are usually\nover-parameterized and one possible solution is to remodel the network architecture\nwith a smaller network architecture with a trade-off on modeling accuracy\nand performance. Here we take advantage of meta-learning algorithms to synthesize\na more efficient model while it boosts the modeling performance. To this\nend, we propose an ensemble of deep evolutionary intelligence frameworks where\nit synthesizes several very efficient models with less than 3% drop on modeling\naccuracy and then aggregates them to boost the modeling performance. Experimental\nresults demonstrates that the proposed ensemble of Deep Evolutionary\nSynthesis approach synthesizes an ensemble model which is 1.5X smaller than\nthe original network architecture while performing more accurate (83.30% compared\nto 83.18%) than the original network in terms of modeling accuracy for\nbinary object segmentation.", "paperhash": "kasiri|efficient_network_structure_via_ensemble_deep_evolutionary_synthesis", "_bibtex": "@misc{\n  kasiri2018efficient,\n  title={Efficient Network Structure via Ensemble Deep Evolutionary Synthesis},\n  author={Keyvan Kasiri and Mohammad Javad Shafiee and Alexander Wong and Justin Eichel},\n  year={2018},\n  url={https://openreview.net/forum?id=HyDgK9yDM}\n}", "authorids": ["kkasiri@uwaterloo.ca", "mjshafiee@uwaterloo.ca", "awong@uwaterloo.ca", "jeichel@miovision.com"], "authors": ["Keyvan Kasiri", "Mohammad Javad Shafiee", "Alexander Wong", "Justin Eichel"], "keywords": ["Deep neural networks", "evolutionary synthesis", "ensemble learning"], "pdf": "/pdf/ab4f8bd5f45e7da19425f91b7649dafa11939977.pdf"}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1520657999000, "tmdate": 1521582904045, "id": "ICLR.cc/2018/Workshop/-/Paper360/Official_Review", "writers": ["ICLR.cc/2018/Workshop"], "signatures": ["ICLR.cc/2018/Workshop"], "readers": ["everyone"], "invitees": ["ICLR.cc/2018/Workshop/Paper360/Reviewers"], "noninvitees": ["ICLR.cc/2018/Workshop/Paper360/AnonReviewer3", "ICLR.cc/2018/Workshop/Paper360/AnonReviewer1"], "reply": {"forum": "HyDgK9yDM", "replyto": "HyDgK9yDM", "writers": {"values-regex": "ICLR.cc/2018/Workshop/Paper360/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2018/Workshop/Paper360/AnonReviewer[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"required": true, "order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"required": true, "order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "value-regex": "[\\S\\s]{1,200000}"}, "rating": {"required": true, "order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"required": true, "order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1528433999000, "cdate": 1521582904045}}}, {"tddate": null, "ddate": null, "original": null, "tmdate": 1521573604489, "tcdate": 1521573604489, "number": 258, "cdate": 1521573604149, "id": "Hyn1yyyqM", "invitation": "ICLR.cc/2018/Workshop/-/Acceptance_Decision", "forum": "HyDgK9yDM", "replyto": "HyDgK9yDM", "signatures": ["ICLR.cc/2018/Workshop/Program_Chairs"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Workshop/Program_Chairs"], "content": {"decision": "Reject", "title": "ICLR 2018 Workshop Acceptance Decision", "comment": "Based on the reviews, this paper has not been accepted for presentation at the ICLR workshop. However, the conversation and updates can continue to appear here on OpenReview."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Efficient Network Structure via Ensemble Deep Evolutionary Synthesis", "abstract": "While deep neural networks have shown promising results in a wide range of\napplications on highly powerful computational devices, one challenging task is\nto deploy a deep neural network on embedded devices for the widespread use.\nDeep neural networks and specially convolutional neural networks are usually\nover-parameterized and one possible solution is to remodel the network architecture\nwith a smaller network architecture with a trade-off on modeling accuracy\nand performance. Here we take advantage of meta-learning algorithms to synthesize\na more efficient model while it boosts the modeling performance. To this\nend, we propose an ensemble of deep evolutionary intelligence frameworks where\nit synthesizes several very efficient models with less than 3% drop on modeling\naccuracy and then aggregates them to boost the modeling performance. Experimental\nresults demonstrates that the proposed ensemble of Deep Evolutionary\nSynthesis approach synthesizes an ensemble model which is 1.5X smaller than\nthe original network architecture while performing more accurate (83.30% compared\nto 83.18%) than the original network in terms of modeling accuracy for\nbinary object segmentation.", "paperhash": "kasiri|efficient_network_structure_via_ensemble_deep_evolutionary_synthesis", "_bibtex": "@misc{\n  kasiri2018efficient,\n  title={Efficient Network Structure via Ensemble Deep Evolutionary Synthesis},\n  author={Keyvan Kasiri and Mohammad Javad Shafiee and Alexander Wong and Justin Eichel},\n  year={2018},\n  url={https://openreview.net/forum?id=HyDgK9yDM}\n}", "authorids": ["kkasiri@uwaterloo.ca", "mjshafiee@uwaterloo.ca", "awong@uwaterloo.ca", "jeichel@miovision.com"], "authors": ["Keyvan Kasiri", "Mohammad Javad Shafiee", "Alexander Wong", "Justin Eichel"], "keywords": ["Deep neural networks", "evolutionary synthesis", "ensemble learning"], "pdf": "/pdf/ab4f8bd5f45e7da19425f91b7649dafa11939977.pdf"}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "tmdate": 1518629844880, "id": "ICLR.cc/2018/Workshop/-/Acceptance_Decision", "writers": ["ICLR.cc/2018/Workshop"], "signatures": ["ICLR.cc/2018/Workshop"], "readers": ["everyone"], "invitees": ["ICLR.cc/2018/Workshop/Program_Chairs"], "reply": {"forum": null, "replyto": null, "invitation": "ICLR.cc/2018/Workshop/-/Submission", "writers": {"values": ["ICLR.cc/2018/Workshop/Program_Chairs"]}, "signatures": {"description": "How your identity will be displayed with the above content.", "values": ["ICLR.cc/2018/Workshop/Program_Chairs"]}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["ICLR.cc/2018/Workshop/Program_Chairs", "everyone"]}, "content": {"title": {"required": true, "order": 1, "value": "ICLR 2018 Workshop Acceptance Decision"}, "comment": {"required": false, "order": 3, "description": "(optional) Comment on this decision.", "value-regex": "[\\S\\s]{0,5000}"}, "decision": {"required": true, "order": 2, "value-dropdown": ["Accept", "Reject"]}}}, "nonreaders": [], "noninvitees": [], "cdate": 1518629844880}}}], "count": 4}