{"notes": [{"id": "B1lXfA4Ywr", "original": "HkeGkhNdPB", "number": 996, "cdate": 1569439242733, "ddate": null, "tcdate": 1569439242733, "tmdate": 1577168249405, "tddate": null, "forum": "B1lXfA4Ywr", "replyto": null, "invitation": "ICLR.cc/2020/Conference/-/Blind_Submission", "content": {"title": "Towards Modular Algorithm Induction", "authors": ["Daniel A. Abolafia", "Rishabh Singh", "Manzil Zaheer", "Charles Sutton"], "authorids": ["danabo@google.com", "rising@google.com", "manzilzaheer@google.com", "charlessutton@google.com"], "keywords": ["algorithm induction", "reinforcement learning", "program synthesis", "modular"], "TL;DR": "An architecture for learning to compose modules to learn algorithmic tasks.", "abstract": "We present a modular neural network architecture MAIN that learns algorithms given a set of input-output examples. MAIN consists of a neural controller that interacts with a variable-length input tape and learns to compose modules together with their corresponding argument choices. Unlike previous approaches, MAIN uses a general domain-agnostic mechanism for selection of modules and their arguments. It uses a general input tape layout together with a parallel history tape to indicate most recently used locations. Finally, it uses a memoryless controller with a length-invariant self-attention based input tape encoding to allow for random access to tape locations. The MAIN architecture is trained end-to-end using reinforcement learning from a set of input-output examples. We evaluate MAIN on five algorithmic tasks and show that it can learn policies that generalizes perfectly to inputs of much longer lengths than the ones used for training.", "pdf": "/pdf/6b97229cdf77f9fbae8046d3c6c1bf1614a4272a.pdf", "paperhash": "abolafia|towards_modular_algorithm_induction", "original_pdf": "/attachment/6b97229cdf77f9fbae8046d3c6c1bf1614a4272a.pdf", "_bibtex": "@misc{\nabolafia2020towards,\ntitle={Towards Modular Algorithm Induction},\nauthor={Daniel A. Abolafia and Rishabh Singh and Manzil Zaheer and Charles Sutton},\nyear={2020},\nurl={https://openreview.net/forum?id=B1lXfA4Ywr}\n}"}, "signatures": ["ICLR.cc/2020/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference"], "details": {"replyCount": 5, "writable": false, "overwriting": [], "revisions": false, "tags": [], "invitation": {"reply": {"readers": {"values-regex": ".*"}, "writers": {"values": ["ICLR.cc/2020/Conference"]}, "signatures": {"values": ["ICLR.cc/2020/Conference"]}, "content": {"spotlight_video": {"value-regex": ".*"}, "full_presentation_video": {"value-regex": ".*"}, "original_pdf": {"required": false, "description": "Upload a PDF file that ends with .pdf", "value-regex": ".*"}, "appendix": {"value-regex": ".*"}, "authorids": {"values-regex": ".*"}, "poster": {"value-regex": ".*"}, "authors": {"values": ["Anonymous"]}, "slides": {"value-regex": ".*"}}}, "final": [], "signatures": ["ICLR.cc/2020/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference"], "noninvitees": [], "tcdate": 1569271260237, "tmdate": 1593459412141, "id": "ICLR.cc/2020/Conference/-/Blind_Submission"}}, "tauthor": "OpenReview.net"}, {"id": "GEsHWZ-9cW", "original": null, "number": 1, "cdate": 1576798711749, "ddate": null, "tcdate": 1576798711749, "tmdate": 1576800924635, "tddate": null, "forum": "B1lXfA4Ywr", "replyto": "B1lXfA4Ywr", "invitation": "ICLR.cc/2020/Conference/Paper996/-/Decision", "content": {"decision": "Reject", "comment": "The reviewers all agreed that although there is a sensible idea here, the method and presentation need a lot of work, especially their treatment of related methods.", "title": "Paper Decision"}, "signatures": ["ICLR.cc/2020/Conference/Program_Chairs"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Program_Chairs"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Towards Modular Algorithm Induction", "authors": ["Daniel A. Abolafia", "Rishabh Singh", "Manzil Zaheer", "Charles Sutton"], "authorids": ["danabo@google.com", "rising@google.com", "manzilzaheer@google.com", "charlessutton@google.com"], "keywords": ["algorithm induction", "reinforcement learning", "program synthesis", "modular"], "TL;DR": "An architecture for learning to compose modules to learn algorithmic tasks.", "abstract": "We present a modular neural network architecture MAIN that learns algorithms given a set of input-output examples. MAIN consists of a neural controller that interacts with a variable-length input tape and learns to compose modules together with their corresponding argument choices. Unlike previous approaches, MAIN uses a general domain-agnostic mechanism for selection of modules and their arguments. It uses a general input tape layout together with a parallel history tape to indicate most recently used locations. Finally, it uses a memoryless controller with a length-invariant self-attention based input tape encoding to allow for random access to tape locations. The MAIN architecture is trained end-to-end using reinforcement learning from a set of input-output examples. We evaluate MAIN on five algorithmic tasks and show that it can learn policies that generalizes perfectly to inputs of much longer lengths than the ones used for training.", "pdf": "/pdf/6b97229cdf77f9fbae8046d3c6c1bf1614a4272a.pdf", "paperhash": "abolafia|towards_modular_algorithm_induction", "original_pdf": "/attachment/6b97229cdf77f9fbae8046d3c6c1bf1614a4272a.pdf", "_bibtex": "@misc{\nabolafia2020towards,\ntitle={Towards Modular Algorithm Induction},\nauthor={Daniel A. Abolafia and Rishabh Singh and Manzil Zaheer and Charles Sutton},\nyear={2020},\nurl={https://openreview.net/forum?id=B1lXfA4Ywr}\n}"}, "tags": [], "invitation": {"reply": {"writers": {"description": "How your identity will be displayed.", "values-regex": ["ICLR.cc/2020/Conference/Program_Chairs"]}, "signatures": {"values": ["ICLR.cc/2020/Conference/Program_Chairs"], "description": "How your identity will be displayed."}, "content": {"decision": {"value-radio": ["Accept (Spotlight)", "Accept (Talk)", "Accept (Poster)", "Reject"], "description": "Decision", "required": true, "order": 2}, "title": {"value": "Paper Decision", "required": true, "order": 1}, "comment": {"value-regex": "[\\S\\s]{0,5000}", "description": "", "required": false, "order": 3}}, "forum": "B1lXfA4Ywr", "replyto": "B1lXfA4Ywr", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}}, "expdate": 1576854540000, "duedate": 1576853940000, "multiReply": false, "readers": ["everyone"], "invitees": ["ICLR.cc/2020/Conference/Program_Chairs"], "tcdate": 1576795727943, "tmdate": 1576800280254, "super": "ICLR.cc/2020/Conference/-/Decision", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper996/-/Decision"}}}, {"id": "B1lEE5CKiH", "original": null, "number": 2, "cdate": 1573673516449, "ddate": null, "tcdate": 1573673516449, "tmdate": 1573673516449, "tddate": null, "forum": "B1lXfA4Ywr", "replyto": "B1lXfA4Ywr", "invitation": "ICLR.cc/2020/Conference/Paper996/-/Official_Comment", "content": {"title": "Thank you for the reviews", "comment": "Thanks to all of the reviewers for your time and for the very helpful comments. We will take them into account when revising this paper."}, "signatures": ["ICLR.cc/2020/Conference/Paper996/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper996/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Towards Modular Algorithm Induction", "authors": ["Daniel A. Abolafia", "Rishabh Singh", "Manzil Zaheer", "Charles Sutton"], "authorids": ["danabo@google.com", "rising@google.com", "manzilzaheer@google.com", "charlessutton@google.com"], "keywords": ["algorithm induction", "reinforcement learning", "program synthesis", "modular"], "TL;DR": "An architecture for learning to compose modules to learn algorithmic tasks.", "abstract": "We present a modular neural network architecture MAIN that learns algorithms given a set of input-output examples. MAIN consists of a neural controller that interacts with a variable-length input tape and learns to compose modules together with their corresponding argument choices. Unlike previous approaches, MAIN uses a general domain-agnostic mechanism for selection of modules and their arguments. It uses a general input tape layout together with a parallel history tape to indicate most recently used locations. Finally, it uses a memoryless controller with a length-invariant self-attention based input tape encoding to allow for random access to tape locations. The MAIN architecture is trained end-to-end using reinforcement learning from a set of input-output examples. We evaluate MAIN on five algorithmic tasks and show that it can learn policies that generalizes perfectly to inputs of much longer lengths than the ones used for training.", "pdf": "/pdf/6b97229cdf77f9fbae8046d3c6c1bf1614a4272a.pdf", "paperhash": "abolafia|towards_modular_algorithm_induction", "original_pdf": "/attachment/6b97229cdf77f9fbae8046d3c6c1bf1614a4272a.pdf", "_bibtex": "@misc{\nabolafia2020towards,\ntitle={Towards Modular Algorithm Induction},\nauthor={Daniel A. Abolafia and Rishabh Singh and Manzil Zaheer and Charles Sutton},\nyear={2020},\nurl={https://openreview.net/forum?id=B1lXfA4Ywr}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "B1lXfA4Ywr", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper996/Authors", "ICLR.cc/2020/Conference/Paper996/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper996/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper996/Reviewers", "ICLR.cc/2020/Conference/Paper996/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper996/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper996/Authors|ICLR.cc/2020/Conference/Paper996/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504162893, "tmdate": 1576860547360, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper996/Authors", "ICLR.cc/2020/Conference/Paper996/Reviewers", "ICLR.cc/2020/Conference/Paper996/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper996/-/Official_Comment"}}}, {"id": "HygP6m6FjB", "original": null, "number": 3, "cdate": 1573667775100, "ddate": null, "tcdate": 1573667775100, "tmdate": 1573667896966, "tddate": null, "forum": "B1lXfA4Ywr", "replyto": "B1lXfA4Ywr", "invitation": "ICLR.cc/2020/Conference/Paper996/-/Official_Review", "content": {"experience_assessment": "I have read many papers in this area.", "rating": "1: Reject", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "title": "Official Blind Review #2", "review": "This paper proposes a new variation of modular neural networks. Specifically, they proposed a new architecture for the neural controller that selects which module to use given the current state and history computations, and evaluated the architectures for five symbolic tasks. I'm leaning towards rejection because:\n1. The story is confusing. Instead of framing algorithm induction as a program synthesis task, the paper told the story from the modular networks's view. This is quite confusing as most of work in this line of research usually assumes the modules are neural networks and are learned, while this paper uses user provided modules. This should then be framed as doing program synthesis with pre-specified primitive functions. This work hence is quite close to NPI [1]. A RL version of NPI is also recently proposed [2].\n2. Lack of novelty. Continuing from the previous point, it seems it is not easy to distinguish the main idea of this work and the work of NPI. There are two differences. There's an architectural difference about how one deals with history. NPI uses a LSTM and this work uses the last time step's computation configuration as input to a FNN. It is unclear why one is better than the other? Such modification is also lack of motivation, unexplained in the paper. Another difference is about how one designs the tasks/environments. This work uses a working tape while NPI uses programming traces.\n3. Lack of baseline comparisons. In the experiment section, no previous work are evaluated and compared to the proposed method, leaving one unknown how well the proposed method compares with previously known work.\n\nThat being said, there are still some merits in the paper. The currently known work for training NPI with RL [2] does not support argument predictions, while this work does. I do not know if this is due to the interface/environment that's designed for the tasks in the paper, but I recommend the authors to rewrite the story and clarify these differences more clearly. Also how general is this environment? For harder programming tasks, can one still uses tape? How scalable is this?\n\nMinor point\n- How do you use FNN to produce all actions of the controller? Do you use a different heads for different action output? Or do you use an autoregressive architecture? Have you tried both and compared?\n\n[1] Neural Programmer-Interpreters.\n[2] Learning Compositional Neural Programs with Recursive Tree Search and Planning.", "review_assessment:_checking_correctness_of_derivations_and_theory": "N/A"}, "signatures": ["ICLR.cc/2020/Conference/Paper996/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper996/AnonReviewer2"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Towards Modular Algorithm Induction", "authors": ["Daniel A. Abolafia", "Rishabh Singh", "Manzil Zaheer", "Charles Sutton"], "authorids": ["danabo@google.com", "rising@google.com", "manzilzaheer@google.com", "charlessutton@google.com"], "keywords": ["algorithm induction", "reinforcement learning", "program synthesis", "modular"], "TL;DR": "An architecture for learning to compose modules to learn algorithmic tasks.", "abstract": "We present a modular neural network architecture MAIN that learns algorithms given a set of input-output examples. MAIN consists of a neural controller that interacts with a variable-length input tape and learns to compose modules together with their corresponding argument choices. Unlike previous approaches, MAIN uses a general domain-agnostic mechanism for selection of modules and their arguments. It uses a general input tape layout together with a parallel history tape to indicate most recently used locations. Finally, it uses a memoryless controller with a length-invariant self-attention based input tape encoding to allow for random access to tape locations. The MAIN architecture is trained end-to-end using reinforcement learning from a set of input-output examples. We evaluate MAIN on five algorithmic tasks and show that it can learn policies that generalizes perfectly to inputs of much longer lengths than the ones used for training.", "pdf": "/pdf/6b97229cdf77f9fbae8046d3c6c1bf1614a4272a.pdf", "paperhash": "abolafia|towards_modular_algorithm_induction", "original_pdf": "/attachment/6b97229cdf77f9fbae8046d3c6c1bf1614a4272a.pdf", "_bibtex": "@misc{\nabolafia2020towards,\ntitle={Towards Modular Algorithm Induction},\nauthor={Daniel A. Abolafia and Rishabh Singh and Manzil Zaheer and Charles Sutton},\nyear={2020},\nurl={https://openreview.net/forum?id=B1lXfA4Ywr}\n}"}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "B1lXfA4Ywr", "replyto": "B1lXfA4Ywr", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper996/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper996/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1574722376000, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper996/Reviewers"], "noninvitees": [], "tcdate": 1570237743909, "tmdate": 1574723085822, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper996/-/Official_Review"}}}, {"id": "SJlbBsl5FB", "original": null, "number": 1, "cdate": 1571584824919, "ddate": null, "tcdate": 1571584824919, "tmdate": 1572972525701, "tddate": null, "forum": "B1lXfA4Ywr", "replyto": "B1lXfA4Ywr", "invitation": "ICLR.cc/2020/Conference/Paper996/-/Official_Review", "content": {"rating": "1: Reject", "experience_assessment": "I have published in this field for several years.", "review_assessment:_checking_correctness_of_derivations_and_theory": "N/A", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #3", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review": "This paper proposes a novel modular neural architecture for algorithm induction. The modules are fixed and a controller policy is learned which outputs a distribution over modules and input/output locations on a memory tape. An oracle (which knows the correct answer) is necessary to decide when to stop computing. The controller is trained by a variant of REINFORCE.\n\nMy main concern with this paper is that there is zero experimental comparison against previous neural program induction approaches. It makes it difficult to evaluate whether the specifics of the proposed architecture actually are advantageous (albeit the authors argue so in table 1, it is not clear that these differences translate in better learning).\n\nI find it rather disappointing that the controller needs to be stopped using an oracle which knows the right answer, making the practical use of such an architecture essentially infeasible in practice. It is also disappointing that a different subset of predefined modules is chosen for each task. I understand it helps to not have unnecessary modules in the module set, but it seems to be another weakness of the approach, and there was no evaluation against using the same full set for all tasks. Also, it is not clear that the chosen set of modules is sufficiently  general and universal, which  would be necessary to scale this approach to learn arbitrary programs.\n\nSince the controller is trained by REINFORCE, one could be concerned that the gradient estimator has high variance (compared to methods based on soft-attention where one can backprop all the way through a sequence of actions). It would thus have been good to verify how sample complexity worsens as the complexity of the task  scales up, but there is no such analysis.\n\nConsidering the above issues, I suggest to reject that submission.\n\nMinor:\n\nPage 4, 2nd par, the text refers to sigma_t \"shown above\", which has not yet been introduced (comes in the middle of page 5).\n\nPage 7, 2nd par, \"linear schedule starting at 1M and ending at 18M\" needs to be clarified. 1M what?\n\nPage 8, \"generalize perfectly\": it does not seem to be the case since none of the experiments have led to 10/10 successes.  Are the \"runs\" mentioned training runs?\n"}, "signatures": ["ICLR.cc/2020/Conference/Paper996/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper996/AnonReviewer3"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Towards Modular Algorithm Induction", "authors": ["Daniel A. Abolafia", "Rishabh Singh", "Manzil Zaheer", "Charles Sutton"], "authorids": ["danabo@google.com", "rising@google.com", "manzilzaheer@google.com", "charlessutton@google.com"], "keywords": ["algorithm induction", "reinforcement learning", "program synthesis", "modular"], "TL;DR": "An architecture for learning to compose modules to learn algorithmic tasks.", "abstract": "We present a modular neural network architecture MAIN that learns algorithms given a set of input-output examples. MAIN consists of a neural controller that interacts with a variable-length input tape and learns to compose modules together with their corresponding argument choices. Unlike previous approaches, MAIN uses a general domain-agnostic mechanism for selection of modules and their arguments. It uses a general input tape layout together with a parallel history tape to indicate most recently used locations. Finally, it uses a memoryless controller with a length-invariant self-attention based input tape encoding to allow for random access to tape locations. The MAIN architecture is trained end-to-end using reinforcement learning from a set of input-output examples. We evaluate MAIN on five algorithmic tasks and show that it can learn policies that generalizes perfectly to inputs of much longer lengths than the ones used for training.", "pdf": "/pdf/6b97229cdf77f9fbae8046d3c6c1bf1614a4272a.pdf", "paperhash": "abolafia|towards_modular_algorithm_induction", "original_pdf": "/attachment/6b97229cdf77f9fbae8046d3c6c1bf1614a4272a.pdf", "_bibtex": "@misc{\nabolafia2020towards,\ntitle={Towards Modular Algorithm Induction},\nauthor={Daniel A. Abolafia and Rishabh Singh and Manzil Zaheer and Charles Sutton},\nyear={2020},\nurl={https://openreview.net/forum?id=B1lXfA4Ywr}\n}"}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "B1lXfA4Ywr", "replyto": "B1lXfA4Ywr", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper996/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper996/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1574722376000, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper996/Reviewers"], "noninvitees": [], "tcdate": 1570237743909, "tmdate": 1574723085822, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper996/-/Official_Review"}}}, {"id": "H1gspdehFH", "original": null, "number": 2, "cdate": 1571715266685, "ddate": null, "tcdate": 1571715266685, "tmdate": 1572972525668, "tddate": null, "forum": "B1lXfA4Ywr", "replyto": "B1lXfA4Ywr", "invitation": "ICLR.cc/2020/Conference/Paper996/-/Official_Review", "content": {"rating": "1: Reject", "experience_assessment": "I do not know much about this area.", "review_assessment:_checking_correctness_of_derivations_and_theory": "N/A", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #1", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review": "This paper proposes Modular Algorithm Induction Network (MAIN) that learns algorithms given input-output examples. MAIN is equipped with several components that make it perform better than baselines, but probably the most important part is its use of modules to break-down algorithmic tasks into simpler problems. MAIN is learned end-to-end using reinforcement learning and demonstrated to perform well in several tasks.\n\nThe paper provides a good comparison between the proposed architectures and other related works. The idea to compose modules is reasonable. Nevertheless, I find this paper somewhat incomplete and not ready for publication. The most critical part is its lack of experimental validation. Table 2 presents a bunch of success rates without comparison to other methods. Unless being an expert or practitioner having the experience to implement baselines, it is hard to assess how good the proposed algorithm is. The authors provide some ablations and some of them may roughly correspond to the baselines, but the most import part - introducing modules and a mechanism to compose them actually helps - is not demonstrated in the paper at all. Hence I think the experiment section demonstrated nothing but a proof-of-concept (the proposed algorithm seems to work).\n\nThe main section describing the algorithm is not very comprehensive. I could imagine how difficult it would be to reproduce the results in the paper. It would be better to specify more detailed architectural choices.\n\nOverall, I agree with the main point of the paper but vote for the rejection for now, and the paper needs a major revision on its experimental validation and presentation."}, "signatures": ["ICLR.cc/2020/Conference/Paper996/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper996/AnonReviewer1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Towards Modular Algorithm Induction", "authors": ["Daniel A. Abolafia", "Rishabh Singh", "Manzil Zaheer", "Charles Sutton"], "authorids": ["danabo@google.com", "rising@google.com", "manzilzaheer@google.com", "charlessutton@google.com"], "keywords": ["algorithm induction", "reinforcement learning", "program synthesis", "modular"], "TL;DR": "An architecture for learning to compose modules to learn algorithmic tasks.", "abstract": "We present a modular neural network architecture MAIN that learns algorithms given a set of input-output examples. MAIN consists of a neural controller that interacts with a variable-length input tape and learns to compose modules together with their corresponding argument choices. Unlike previous approaches, MAIN uses a general domain-agnostic mechanism for selection of modules and their arguments. It uses a general input tape layout together with a parallel history tape to indicate most recently used locations. Finally, it uses a memoryless controller with a length-invariant self-attention based input tape encoding to allow for random access to tape locations. The MAIN architecture is trained end-to-end using reinforcement learning from a set of input-output examples. We evaluate MAIN on five algorithmic tasks and show that it can learn policies that generalizes perfectly to inputs of much longer lengths than the ones used for training.", "pdf": "/pdf/6b97229cdf77f9fbae8046d3c6c1bf1614a4272a.pdf", "paperhash": "abolafia|towards_modular_algorithm_induction", "original_pdf": "/attachment/6b97229cdf77f9fbae8046d3c6c1bf1614a4272a.pdf", "_bibtex": "@misc{\nabolafia2020towards,\ntitle={Towards Modular Algorithm Induction},\nauthor={Daniel A. Abolafia and Rishabh Singh and Manzil Zaheer and Charles Sutton},\nyear={2020},\nurl={https://openreview.net/forum?id=B1lXfA4Ywr}\n}"}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "B1lXfA4Ywr", "replyto": "B1lXfA4Ywr", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper996/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper996/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1574722376000, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper996/Reviewers"], "noninvitees": [], "tcdate": 1570237743909, "tmdate": 1574723085822, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper996/-/Official_Review"}}}], "count": 6}