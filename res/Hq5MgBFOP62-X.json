{"notes": [{"ddate": null, "legacy_migration": true, "tmdate": 1393276320000, "tcdate": 1393276320000, "number": 5, "id": "11m21yPQdjv49", "invitation": "ICLR.cc/2014/-/submission/conference/review", "forum": "Hq5MgBFOP62-X", "replyto": "Hq5MgBFOP62-X", "signatures": ["David Eigen"], "readers": ["everyone"], "writers": ["anonymous"], "content": {"title": "", "review": "We would like to thank all the reviewers for their comments and feedback.  We have integrated many of the suggestions into a new version (v4) of the paper, and are continuing to make revisions.  This version has been submitted to ArXiv and will appear later today, on Tue, 25 Feb 2014 01:00:00 GMT.\r\n\r\n\r\nIn response to your comments:\r\n\r\n\r\n- 'some of the tables and minor notes ... could be moved to an appendix'; \r\n- 'essential ideas should be distilled ... and the details ... relegated to an appendix'\r\n\r\nThanks for these suggestions.  We are currently working to factor out the details and make the paper more succinct.  Some progress on this has already been made in the newest version (v4), and we are now working on another revision with further editing.\r\n\r\n\r\n\r\n- 'exposition on \u201cdense application\u201d and why this is a computational savings is less clear than it could be'\r\n- 'clarity of exposition in certain parts'\r\n\r\nThis section has been updated in the new version (v4), and should be clearer.  Many other parts of the text have also been revised, and we are continuing to make edits for this.\r\n\r\n\r\n\r\n- 'Some discussion of not just which hyperparameters were chosen but how and why'\r\n- 'rough idea of the relative importance of horizontal flipping and other tricks described in 3.3, it would be useful to know'\r\n- 'more detail on computational efficiency/accuracy compromise'\r\n\r\nThanks for the suggestions.  We will try to discuss some of these questions more in the next revision (v5) of the paper (this has not yet been included in v4).  We do not have systematic comparisons for many of these, though, but further studies of them could make good followup work.\r\n\r\n\r\n\r\n- 'results on PASCAL'\r\n\r\nThanks for the suggestion.  This is likely not something we will be able to get done for this paper, but we agree it would be interesting to see, and may look at this in the future."}, "nonreaders": [], "details": {"replyCount": 0, "overwriting": [], "revisions": false, "forumContent": {"title": "OverFeat: Integrated Recognition, Localization and Detection using Convolutional Networks", "decision": "submitted, no decision", "abstract": "We present an integrated framework for using Convolutional Networks for classification, localization and detection. We show how a multiscale and sliding window approach can be efficiently implemented within a ConvNet. We also introduce a novel deep learning approach to localization by learning to predict object boundaries. Bounding boxes are then accumulated rather than suppressed in order to increase detection confidence. We show that different tasks can be learnt simultaneously using a single shared network. This integrated framework is the winner of the localization task of the ImageNet Large Scale Visual Recognition Challenge 2013 (ILSVRC2013), and produced near state of the art results for the detection and classifications tasks. Finally, we release a feature extractor from our best model called OverFeat.", "pdf": "https://arxiv.org/abs/1312.6229", "paperhash": "mathieu|overfeat_integrated_recognition_localization_and_detection_using_convolutional_networks", "keywords": [], "conflicts": [], "authors": ["Michael Mathieu", "Yann LeCun", "Rob Fergus", "David Eigen", "Pierre Sermanet", "Xiang Zhang"], "authorids": ["mathieu@cs.nyu.edu", "ylecun@gmail.com", "robfergus@gmail.com", "deigen@cs.nyu.edu", "pierre.sermanet@gmail.com", "xiang@cs.nyu.edu"]}, "tags": [], "invitation": {}}}, {"ddate": null, "legacy_migration": true, "tmdate": 1392859140000, "tcdate": 1392859140000, "number": 3, "id": "yuF4yCcCBOna3", "invitation": "ICLR.cc/2014/-/submission/conference/review", "forum": "Hq5MgBFOP62-X", "replyto": "Hq5MgBFOP62-X", "signatures": ["anonymous reviewer 4a93"], "readers": ["everyone"], "writers": ["anonymous"], "content": {"title": "review of OverFeat: Integrated Recognition, Localization and Detection using Convolutional Networks", "review": "This paper demonstrates a convolutional architecture for simultaneously detecting and localizing ImageNet objects. It is the winner of localization task of ILSVRCS2013 competition and that by itself makes it interesting.\r\n\r\nThey implement a combined architecture where first 5 layers share features compute features that are used for both classification and localization tasks.\r\n\r\nA lot of detail goes into constructing an architecture in a way as to make network windows aligned with the objeect. They use 6 scales increased in steps between 1.08 and 1.27 (why this arbitrary choice of steps?) along with 1 pixel offsets and a skip feature connections at the top to prevent the stride from being too large.\r\n\r\nThis is a solid paper which summarizes significant body of work in neural network design, which makes its relevance to ICLR high.\r\n\r\nSome suggestions:\r\n-- I wish the authors gave more detail on computational efficiency/accuracy compromise since that needs to be considered when running in an industrial setting.  For instance, coarse vs fine stride seems to provide 1% absolute improvement, while requiring 9x more computation at the lowest level. How much does that affect total computation? This could be done by adding an extra column 'FLOPS' to Table 5."}, "nonreaders": [], "details": {"replyCount": 0, "overwriting": [], "revisions": false, "forumContent": {"title": "OverFeat: Integrated Recognition, Localization and Detection using Convolutional Networks", "decision": "submitted, no decision", "abstract": "We present an integrated framework for using Convolutional Networks for classification, localization and detection. We show how a multiscale and sliding window approach can be efficiently implemented within a ConvNet. We also introduce a novel deep learning approach to localization by learning to predict object boundaries. Bounding boxes are then accumulated rather than suppressed in order to increase detection confidence. We show that different tasks can be learnt simultaneously using a single shared network. This integrated framework is the winner of the localization task of the ImageNet Large Scale Visual Recognition Challenge 2013 (ILSVRC2013), and produced near state of the art results for the detection and classifications tasks. Finally, we release a feature extractor from our best model called OverFeat.", "pdf": "https://arxiv.org/abs/1312.6229", "paperhash": "mathieu|overfeat_integrated_recognition_localization_and_detection_using_convolutional_networks", "keywords": [], "conflicts": [], "authors": ["Michael Mathieu", "Yann LeCun", "Rob Fergus", "David Eigen", "Pierre Sermanet", "Xiang Zhang"], "authorids": ["mathieu@cs.nyu.edu", "ylecun@gmail.com", "robfergus@gmail.com", "deigen@cs.nyu.edu", "pierre.sermanet@gmail.com", "xiang@cs.nyu.edu"]}, "tags": [], "invitation": {}}}, {"ddate": null, "legacy_migration": true, "tmdate": 1392094080000, "tcdate": 1392094080000, "number": 4, "id": "QV0KQRSaXWk1w", "invitation": "ICLR.cc/2014/-/submission/conference/review", "forum": "Hq5MgBFOP62-X", "replyto": "Hq5MgBFOP62-X", "signatures": ["anonymous reviewer c233"], "readers": ["everyone"], "writers": ["anonymous"], "content": {"title": "review of OverFeat: Integrated Recognition, Localization and Detection using Convolutional Networks", "review": "The authors present a system that is capable of classification, localization and detection, to the advantage of all three. The starting point of Krizhevsky\u2019s 2012 work is adapted to produce an architecture capable of simultaneously solving all tasks, with the feature extraction component being shared across tasks. They propose to scan the entire convolutional net across the entire image at several scales, reusing the relevant computations from overlapping regions already processed, making both classification and (per-class) bounding box predictions at each and a clever scheme for aggregating evidence for the bounding box across predictions, and lots of other tricks. They evaluate on ILSVRC 2012 and 2013 tasks with excellent results.\r\n\r\nNovelty: low-medium\r\nQuality: high\r\n\r\nPros\r\n- This is an excellent piece of applied vision research. The results on ILSVRC speak for themselves, really.\r\n- It brings to light some potentially non-obvious (to a convolutional networks neophyte) advantages of convolutional nets for tasks like this, namely that dense application\r\n- Details are copiously documented: this is an excellent example of authors paying serious mind to the reproducibility of their work, a tendency that is sorely lacking in computer vision and machine learning in general. Please keep up the good work in future publications.\r\n\r\nCons\r\n- There isn\u2019t a lot of methodological novelty, although there is some in the tricks employed to deal with subsampling, etc. (to my knowledge, these are novel). That said, it is a tour-de-force application paper, so I don\u2019t see this as a serious drawback.\r\n- The only serious barrier to publication I see is clarity of exposition in certain parts.\r\n- Some discussion of not just which hyperparameters were chosen but how and why, including some rationale for departures from Krizhevsky\u2019s architecture, would be nice (e.g. the learning rate schedule, your choice to drop contrast normalization, non-overlapping pooling regions, etc.). Providing the details as statement of fact is good, but insights into how you made some of these decisions would make for more compelling reading, especially to those familiar with the Krizhevsky work.\r\n- The organization of the paper could also use work: essential ideas should be distilled into an 8ish page manuscript and the details (which, as I said, are an extremely positive feature of this paper) relegated to an appendix.\r\n\r\nDetailed comments:\r\n- If you have some rough idea of the relative importance of horizontal flipping and other tricks described in 3.3, it would be useful to know. I don\u2019t expect an exhaustive ablative analysis, but even an informal statement as to which elements seem to be the most critical would be interesting.\r\n- The exposition on \u201cdense application\u201d and why this is a computational savings is less clear than it could be (section 3.5). Basically what you are trying to get across, I think, is that applying a convolutional net to every PxP window of an MxN image, where P << M and P << N, can be performed efficiently by convolving each layer of filters and doing the pooling and so on with the entire image at once, reusing computation for overlapping window regions, and thus it is much more efficient than if you had some arbitrary black box that you had to apply at every window location and reuse no computation whatsoever. However the text was very unclear on this point, and a reader with less background may not understand what you mean (which would be a shame, as this is a very important point, practically speaking). I\u2019m sure I\u2019ve heard this idea spoken of before -- is this the first time it\u2019s appeared in print? If not, I\u2019d make sure to include a citation."}, "nonreaders": [], "details": {"replyCount": 0, "overwriting": [], "revisions": false, "forumContent": {"title": "OverFeat: Integrated Recognition, Localization and Detection using Convolutional Networks", "decision": "submitted, no decision", "abstract": "We present an integrated framework for using Convolutional Networks for classification, localization and detection. We show how a multiscale and sliding window approach can be efficiently implemented within a ConvNet. We also introduce a novel deep learning approach to localization by learning to predict object boundaries. Bounding boxes are then accumulated rather than suppressed in order to increase detection confidence. We show that different tasks can be learnt simultaneously using a single shared network. This integrated framework is the winner of the localization task of the ImageNet Large Scale Visual Recognition Challenge 2013 (ILSVRC2013), and produced near state of the art results for the detection and classifications tasks. Finally, we release a feature extractor from our best model called OverFeat.", "pdf": "https://arxiv.org/abs/1312.6229", "paperhash": "mathieu|overfeat_integrated_recognition_localization_and_detection_using_convolutional_networks", "keywords": [], "conflicts": [], "authors": ["Michael Mathieu", "Yann LeCun", "Rob Fergus", "David Eigen", "Pierre Sermanet", "Xiang Zhang"], "authorids": ["mathieu@cs.nyu.edu", "ylecun@gmail.com", "robfergus@gmail.com", "deigen@cs.nyu.edu", "pierre.sermanet@gmail.com", "xiang@cs.nyu.edu"]}, "tags": [], "invitation": {}}}, {"ddate": null, "legacy_migration": true, "tmdate": 1391813220000, "tcdate": 1391813220000, "number": 2, "id": "AiU-7_Wwg37jx", "invitation": "ICLR.cc/2014/-/submission/conference/review", "forum": "Hq5MgBFOP62-X", "replyto": "Hq5MgBFOP62-X", "signatures": ["anonymous reviewer be85"], "readers": ["everyone"], "writers": ["anonymous"], "content": {"title": "review of OverFeat: Integrated Recognition, Localization and Detection using Convolutional Networks", "review": "The paper presents a method for object recognition, localization and detection that uses a single convolutional neural network to locate and classify objects in images. \u00a0The basic architecture is similar to Krizhevsky\u2019s ImageNet 2012 system, but with modifications to apply it efficiently in a \u201csliding window\u201d fashion and to produce accurate bounding boxes by training a regressor to predict the precise position of the bounding box relative to the sliding window detector. \u00a0Numerous tweaks are documented for making this system work well including: \u00a0multi-scale evaluation over widely-spaced scales, custom shifting/pooling at the top layers to help compensate for spatial subsampling of the network, per-class regressors to localize objects relative to the input window, and a simple merging procedure to combine the regressed boxes into final detections. \u00a0This method is shown to achieve state-of-the-art results on ImageNet localization and detection tasks while also being relatively fast.\r\n\r\nOverall, this paper presents a very thorough accounting of a fully functioning detection pipeline based on convnets that is the top performer on one of the toughest vision tasks around. \u00a0One of the challenges with reporting results like this is to make them reproducible, and I think this paper includes all of the details that a researcher would need to do so, which is really excellent. \u00a0\r\n\r\nThere is currently a lot of work on detection architectures (e.g., from Erhan et al.) but this one is fairly complete and high-performing. \u00a0So, while there aren\u2019t huge new ideas here, considering the depth of experiments and the cornucopia of tricks for maximizing performance the work looks very worthwhile.\r\n\r\nPros:\r\n\r\nEnd-to-end training of the entire detection and localization pipeline. \u00a0The decomposition into 3 clean stepping stones (classifier, localizer, detector) is a nice strategy.\r\n\r\nState-of-the-art detection performance on Image-Net.\r\n\r\nCons:\r\n\r\nSomewhat \u201cspecialized\u201d convnet architecture to deal with subsampling issues and multi-scale (e.g., it is mentioned that the detector of Fig 11 also uses multiple scales for context)\r\n\r\nOther:\r\nThe text is very detailed in order to make the system reproducible. \u00a0This is great, but perhaps some of the tables and minor notes [parameter settings, etc.] could be moved to an appendix to tighten up the text."}, "nonreaders": [], "details": {"replyCount": 0, "overwriting": [], "revisions": false, "forumContent": {"title": "OverFeat: Integrated Recognition, Localization and Detection using Convolutional Networks", "decision": "submitted, no decision", "abstract": "We present an integrated framework for using Convolutional Networks for classification, localization and detection. We show how a multiscale and sliding window approach can be efficiently implemented within a ConvNet. We also introduce a novel deep learning approach to localization by learning to predict object boundaries. Bounding boxes are then accumulated rather than suppressed in order to increase detection confidence. We show that different tasks can be learnt simultaneously using a single shared network. This integrated framework is the winner of the localization task of the ImageNet Large Scale Visual Recognition Challenge 2013 (ILSVRC2013), and produced near state of the art results for the detection and classifications tasks. Finally, we release a feature extractor from our best model called OverFeat.", "pdf": "https://arxiv.org/abs/1312.6229", "paperhash": "mathieu|overfeat_integrated_recognition_localization_and_detection_using_convolutional_networks", "keywords": [], "conflicts": [], "authors": ["Michael Mathieu", "Yann LeCun", "Rob Fergus", "David Eigen", "Pierre Sermanet", "Xiang Zhang"], "authorids": ["mathieu@cs.nyu.edu", "ylecun@gmail.com", "robfergus@gmail.com", "deigen@cs.nyu.edu", "pierre.sermanet@gmail.com", "xiang@cs.nyu.edu"]}, "tags": [], "invitation": {}}}, {"ddate": null, "legacy_migration": true, "tmdate": 1391644680000, "tcdate": 1391644680000, "number": 1, "id": "yGNSGHgls9Irb", "invitation": "ICLR.cc/2014/-/submission/conference/review", "forum": "Hq5MgBFOP62-X", "replyto": "Hq5MgBFOP62-X", "signatures": ["Liangliang Cao"], "readers": ["everyone"], "writers": ["anonymous"], "content": {"title": "", "review": "It is a very nice work and I enjoy reading the paper. Now I believe the era of 'deformable part model' (by Felzenszwalb, McAllester, Ramanan et al) in CV detection will find its successor soon. We will witness another revolution in the field of object detection after talking about DPM for 5 years. \r\n\r\nOne comment of the paper: Is it possible to know the results of applying Overfeat to PASCAL detection dataset? I am also interested the comparison with NEC's Regionlets (No.2 place in ImageNet 2013 detection) on PASCAL. \r\n\r\nBut even without results on PASCAL, this paper still deserves an acceptance from any conference."}, "nonreaders": [], "details": {"replyCount": 0, "overwriting": [], "revisions": false, "forumContent": {"title": "OverFeat: Integrated Recognition, Localization and Detection using Convolutional Networks", "decision": "submitted, no decision", "abstract": "We present an integrated framework for using Convolutional Networks for classification, localization and detection. We show how a multiscale and sliding window approach can be efficiently implemented within a ConvNet. We also introduce a novel deep learning approach to localization by learning to predict object boundaries. Bounding boxes are then accumulated rather than suppressed in order to increase detection confidence. We show that different tasks can be learnt simultaneously using a single shared network. This integrated framework is the winner of the localization task of the ImageNet Large Scale Visual Recognition Challenge 2013 (ILSVRC2013), and produced near state of the art results for the detection and classifications tasks. Finally, we release a feature extractor from our best model called OverFeat.", "pdf": "https://arxiv.org/abs/1312.6229", "paperhash": "mathieu|overfeat_integrated_recognition_localization_and_detection_using_convolutional_networks", "keywords": [], "conflicts": [], "authors": ["Michael Mathieu", "Yann LeCun", "Rob Fergus", "David Eigen", "Pierre Sermanet", "Xiang Zhang"], "authorids": ["mathieu@cs.nyu.edu", "ylecun@gmail.com", "robfergus@gmail.com", "deigen@cs.nyu.edu", "pierre.sermanet@gmail.com", "xiang@cs.nyu.edu"]}, "tags": [], "invitation": {}}}, {"replyto": null, "ddate": null, "legacy_migration": true, "tmdate": 1387870140000, "tcdate": 1387870140000, "number": 44, "id": "Hq5MgBFOP62-X", "invitation": "ICLR.cc/2014/conference/-/submission", "forum": "Hq5MgBFOP62-X", "signatures": ["mathieu@cs.nyu.edu"], "readers": ["everyone"], "content": {"title": "OverFeat: Integrated Recognition, Localization and Detection using Convolutional Networks", "decision": "submitted, no decision", "abstract": "We present an integrated framework for using Convolutional Networks for classification, localization and detection. We show how a multiscale and sliding window approach can be efficiently implemented within a ConvNet. We also introduce a novel deep learning approach to localization by learning to predict object boundaries. Bounding boxes are then accumulated rather than suppressed in order to increase detection confidence. We show that different tasks can be learnt simultaneously using a single shared network. This integrated framework is the winner of the localization task of the ImageNet Large Scale Visual Recognition Challenge 2013 (ILSVRC2013), and produced near state of the art results for the detection and classifications tasks. Finally, we release a feature extractor from our best model called OverFeat.", "pdf": "https://arxiv.org/abs/1312.6229", "paperhash": "mathieu|overfeat_integrated_recognition_localization_and_detection_using_convolutional_networks", "keywords": [], "conflicts": [], "authors": ["Michael Mathieu", "Yann LeCun", "Rob Fergus", "David Eigen", "Pierre Sermanet", "Xiang Zhang"], "authorids": ["mathieu@cs.nyu.edu", "ylecun@gmail.com", "robfergus@gmail.com", "deigen@cs.nyu.edu", "pierre.sermanet@gmail.com", "xiang@cs.nyu.edu"]}, "writers": [], "details": {"replyCount": 5, "writable": false, "overwriting": [], "revisions": false, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1369422751717, "tmdate": 1496674357195, "id": "ICLR.cc/2014/conference/-/submission", "writers": ["ICLR.cc/2014"], "signatures": ["OpenReview.net"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": null, "replyto": null, "writers": {"values-regex": "~.*"}, "signatures": {"values-regex": "~.*", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"pdf": {"required": true, "order": 5, "description": "Either upload a PDF file or provide a direct link to your PDF on ArXiv (link must begin with http(s) and end with .pdf)", "value-regex": "upload|(http|https):\\/\\/.+\\.pdf"}, "title": {"required": true, "order": 1, "description": "Title of paper.", "value-regex": ".{1,250}"}, "abstract": {"required": true, "order": 4, "description": "Abstract of paper.", "value-regex": "[\\S\\s]{1,5000}"}, "authors": {"required": true, "order": 2, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of author names, as they appear in the paper."}, "conflicts": {"required": true, "order": 100, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of email domains of people who would have a conflict of interest in reviewing this paper, (e.g., cs.umass.edu;google.com, etc.)."}, "keywords": {"order": 6, "description": "Comma separated list of keywords.", "values-dropdown": []}, "authorids": {"required": true, "order": 3, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of author email addresses, in the same order as above."}}}, "nonreaders": [], "noninvitees": [], "expdate": 1377198751717, "cdate": 1496674357195}}}], "count": 6}