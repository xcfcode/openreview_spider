{"notes": [{"tddate": null, "replyto": null, "ddate": null, "tmdate": 1488569308316, "tcdate": 1478279572162, "number": 240, "id": "SJ25-B5eg", "invitation": "ICLR.cc/2017/conference/-/submission", "forum": "SJ25-B5eg", "signatures": ["~Lei_Yu1"], "readers": ["everyone"], "content": {"title": "The Neural Noisy Channel", "abstract": "We formulate sequence to sequence transduction as a noisy channel decoding problem and use recurrent neural networks to parameterise the source and channel models. Unlike direct models which can suffer from explaining-away effects during training, noisy channel models must produce outputs that explain their inputs, and their component models can be trained with not only paired training samples but also unpaired samples from the marginal output distribution. Using a latent variable to control how much of the conditioning sequence the channel model needs to read in order to generate a subsequent symbol, we obtain a tractable and effective beam search decoder. Experimental results on abstractive sentence summarisation, morphological inflection, and machine translation show that noisy channel models outperform direct models, and that they significantly benefit from increased amounts of unpaired output data that direct models cannot easily use.", "pdf": "/pdf/587cf5979157e003499aa4188ed3aa8e78064016.pdf", "TL;DR": "We formulate sequence to sequence transduction as a noisy channel decoding  problem and use recurrent neural networks to parameterise the source and channel  models.", "paperhash": "yu|the_neural_noisy_channel", "authors": ["Lei Yu", "Phil Blunsom", "Chris Dyer", "Edward Grefenstette", "Tomas Kocisky"], "keywords": ["Natural language processing", "Deep learning", "Semi-Supervised Learning"], "conflicts": ["google.com", "ox.ac.uk"], "authorids": ["lei.yu@cs.ox.ac.uk", "pblunsom@google.com", "cdyer@google.com", "etg@google.com", "tkocisky@google.com"]}, "writers": [], "nonreaders": [], "details": {"replyCount": 13, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1475686800000, "tmdate": 1478287705855, "id": "ICLR.cc/2017/conference/-/submission", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/pcs"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": null, "replyto": null, "writers": {"values-regex": "~.*"}, "signatures": {"values-regex": "~.*", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"pdf": {"required": true, "order": 5, "description": "Either upload a PDF file or provide a direct link to your PDF on ArXiv (link must begin with http(s) and end with .pdf)", "value-regex": "upload|(http|https):\\/\\/.+\\.pdf"}, "title": {"required": true, "order": 1, "description": "Title of paper.", "value-regex": ".{1,250}"}, "abstract": {"required": true, "order": 4, "description": "Abstract of paper.", "value-regex": "[\\S\\s]{1,5000}"}, "authors": {"required": true, "order": 2, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of author names, as they appear in the paper."}, "conflicts": {"required": true, "order": 100, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of email domains of people who would have a conflict of interest in reviewing this paper, (e.g., cs.umass.edu;google.com, etc.)."}, "keywords": {"order": 6, "description": "Comma separated list of keywords.", "values-dropdown": ["Theory", "Computer vision", "Speech", "Natural language processing", "Deep learning", "Unsupervised Learning", "Supervised Learning", "Semi-Supervised Learning", "Reinforcement Learning", "Transfer Learning", "Multi-modal learning", "Applications", "Optimization", "Structured prediction", "Games"]}, "TL;DR": {"required": false, "order": 3, "description": "\"Too Long; Didn't Read\": a short sentence describing your paper", "value-regex": "[^\\n]{0,250}"}, "authorids": {"required": true, "order": 3, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of author email addresses, in the same order as above."}}}, "nonreaders": [], "noninvitees": [], "expdate": 1483462800000, "cdate": 1478287705855}}}, {"tddate": null, "ddate": null, "cdate": null, "tmdate": 1486396452986, "tcdate": 1486396452986, "number": 1, "id": "Hy6m3zLOl", "invitation": "ICLR.cc/2017/conference/-/paper240/acceptance", "forum": "SJ25-B5eg", "replyto": "SJ25-B5eg", "signatures": ["ICLR.cc/2017/pcs"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/pcs"], "content": {"title": "ICLR committee final decision", "comment": "This paper adapts NMT to a noisy channel formulation utilizing the recently developed SSNT framework. The paper is well-written and has solid experimental results. Howver, the paper can be improved with a bit more originality and impact. In, short the pros and cons of the paper are:\n \n Pro: \n - Clarity: All agree paper was very \"well written\" \n - Quality: Reviewers note the \"strong experimental section\". Comprehensive results. \n \n Cons: \n - Originality: There were concerns about technical novelty: (a) \"this paper does not present anything that is particular novel on top of the SSNT\" (b) not that \"conceptually different from the work of Tillmann et al\". \n - Impact: Reviewers were not completely convinced that this method could not work with simpler means. For instance by using clever reranking or utilizing the deep speech style unprincipled combination. However, this paper does produce a better approach for this problem.", "decision": "Accept (Poster)"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "The Neural Noisy Channel", "abstract": "We formulate sequence to sequence transduction as a noisy channel decoding problem and use recurrent neural networks to parameterise the source and channel models. Unlike direct models which can suffer from explaining-away effects during training, noisy channel models must produce outputs that explain their inputs, and their component models can be trained with not only paired training samples but also unpaired samples from the marginal output distribution. Using a latent variable to control how much of the conditioning sequence the channel model needs to read in order to generate a subsequent symbol, we obtain a tractable and effective beam search decoder. Experimental results on abstractive sentence summarisation, morphological inflection, and machine translation show that noisy channel models outperform direct models, and that they significantly benefit from increased amounts of unpaired output data that direct models cannot easily use.", "pdf": "/pdf/587cf5979157e003499aa4188ed3aa8e78064016.pdf", "TL;DR": "We formulate sequence to sequence transduction as a noisy channel decoding  problem and use recurrent neural networks to parameterise the source and channel  models.", "paperhash": "yu|the_neural_noisy_channel", "authors": ["Lei Yu", "Phil Blunsom", "Chris Dyer", "Edward Grefenstette", "Tomas Kocisky"], "keywords": ["Natural language processing", "Deep learning", "Semi-Supervised Learning"], "conflicts": ["google.com", "ox.ac.uk"], "authorids": ["lei.yu@cs.ox.ac.uk", "pblunsom@google.com", "cdyer@google.com", "etg@google.com", "tkocisky@google.com"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1486396453507, "id": "ICLR.cc/2017/conference/-/paper240/acceptance", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/pcs"], "noninvitees": ["ICLR.cc/2017/pcs"], "reply": {"forum": "SJ25-B5eg", "replyto": "SJ25-B5eg", "writers": {"values-regex": "ICLR.cc/2017/pcs"}, "signatures": {"values-regex": "ICLR.cc/2017/pcs", "description": "Your displayed identity associated with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your decision.", "value": "ICLR committee final decision"}, "comment": {"required": true, "order": 2, "description": "Decision comments.", "value-regex": "[\\S\\s]{1,5000}"}, "decision": {"required": true, "order": 3, "value-radio": ["Accept (Oral)", "Accept (Poster)", "Reject", "Invite to Workshop Track"]}}}, "nonreaders": [], "cdate": 1486396453507}}}, {"tddate": null, "tmdate": 1485635058164, "tcdate": 1485635058164, "number": 7, "id": "Sk9xRdqwe", "invitation": "ICLR.cc/2017/conference/-/paper240/public/comment", "forum": "SJ25-B5eg", "replyto": "Hymc1VSPl", "signatures": ["~Lei_Yu1"], "readers": ["everyone"], "writers": ["~Lei_Yu1"], "content": {"title": "Response", "comment": "Hi Tamer,\n\nThanks for your comment. I've updated the related work section of our paper to include a discussion of the paper Alignment-Based Neural Machine Translation. The revised version of our paper should be on arXiv soon. I think the model in your proposed paper is more closely related to the direct model, i.e. the model presented in the EMNLP paper Online Segment to Segment Neural Transduction, where the conditional distribution is factored into the product of alignment and word probabilities due to the introduction of latent variable. In this paper, based on the noisy channel model, the conditional probability p(output sequence y| input sequence x) is decomposed into the channel model p(x | y) and the language model p(y) so that abundant unpaired data can be used.\n\nIn terms of the MT experiments, we haven't experimented on larger dataset yet, but that's in our TODO list. With my current implementation (without any tricks for speeding things up), it takes about 3 days to train the direct/channel model on the 184k sentence pairs with 1 GPU of Tesla K40m. I'm sure there's a big room of improvement regarding the training time, which can be achieved both from the algorithm side and the engineering side. We are working on this direction too. "}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "The Neural Noisy Channel", "abstract": "We formulate sequence to sequence transduction as a noisy channel decoding problem and use recurrent neural networks to parameterise the source and channel models. Unlike direct models which can suffer from explaining-away effects during training, noisy channel models must produce outputs that explain their inputs, and their component models can be trained with not only paired training samples but also unpaired samples from the marginal output distribution. Using a latent variable to control how much of the conditioning sequence the channel model needs to read in order to generate a subsequent symbol, we obtain a tractable and effective beam search decoder. Experimental results on abstractive sentence summarisation, morphological inflection, and machine translation show that noisy channel models outperform direct models, and that they significantly benefit from increased amounts of unpaired output data that direct models cannot easily use.", "pdf": "/pdf/587cf5979157e003499aa4188ed3aa8e78064016.pdf", "TL;DR": "We formulate sequence to sequence transduction as a noisy channel decoding  problem and use recurrent neural networks to parameterise the source and channel  models.", "paperhash": "yu|the_neural_noisy_channel", "authors": ["Lei Yu", "Phil Blunsom", "Chris Dyer", "Edward Grefenstette", "Tomas Kocisky"], "keywords": ["Natural language processing", "Deep learning", "Semi-Supervised Learning"], "conflicts": ["google.com", "ox.ac.uk"], "authorids": ["lei.yu@cs.ox.ac.uk", "pblunsom@google.com", "cdyer@google.com", "etg@google.com", "tkocisky@google.com"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287670678, "id": "ICLR.cc/2017/conference/-/paper240/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "SJ25-B5eg", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper240/reviewers", "ICLR.cc/2017/conference/paper240/areachairs"], "cdate": 1485287670678}}}, {"tddate": null, "tmdate": 1485287332293, "tcdate": 1485287307064, "number": 6, "id": "Hymc1VSPl", "invitation": "ICLR.cc/2017/conference/-/paper240/public/comment", "forum": "SJ25-B5eg", "replyto": "SJ25-B5eg", "signatures": ["~Tamer_Alkhouli1"], "readers": ["everyone"], "writers": ["~Tamer_Alkhouli1"], "content": {"title": "Comments on related work and MT experiments", "comment": "This is an interesting paper that investigates alternative neural machine translation approaches. Falling back to traditional concepts machine translation while using powerful neural models is essential to understanding the leap achieved by neural machine translation over conventional methods.\n\nIn terms of related work, there is a close relation to the paper Alignment-Based Neural Machine Translation (Alkhouli et al. 2016)*, whether in the decomposition of the model into neural alignment and  lexical/word probabilities, or using a weighted log-linear combination to combine the models which are eventually used in a standalone decoder. A notable difference is that the paper uses direct translation models (as opposed to the inverted ones proposed by the authors here), and the fact that the models are trained on word-aligned data which speeds up training. As for the alignment model, the former choses to model non-monotone source jumps whereas the current paper choses two classes (emit and shift) to model monotone alignments. In (Alkhouli et al. 2016), decoding is done using a beam search decoder that hypothesizes alignments and word translations\n\nAs for the MT experiments, did you try the model combination using larger data (i.e. >=100M tokens). How long did the current models take to train on the 184K sentence pairs you are using? It would also be interesting to see how much you gain/lose if the models were to be trained using given word alignments (e.g. obtained using GIZA++). Training then should be faster.\n\n* https://www.aclweb.org/anthology/W/W16/W16-2206.pdf"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "The Neural Noisy Channel", "abstract": "We formulate sequence to sequence transduction as a noisy channel decoding problem and use recurrent neural networks to parameterise the source and channel models. Unlike direct models which can suffer from explaining-away effects during training, noisy channel models must produce outputs that explain their inputs, and their component models can be trained with not only paired training samples but also unpaired samples from the marginal output distribution. Using a latent variable to control how much of the conditioning sequence the channel model needs to read in order to generate a subsequent symbol, we obtain a tractable and effective beam search decoder. Experimental results on abstractive sentence summarisation, morphological inflection, and machine translation show that noisy channel models outperform direct models, and that they significantly benefit from increased amounts of unpaired output data that direct models cannot easily use.", "pdf": "/pdf/587cf5979157e003499aa4188ed3aa8e78064016.pdf", "TL;DR": "We formulate sequence to sequence transduction as a noisy channel decoding  problem and use recurrent neural networks to parameterise the source and channel  models.", "paperhash": "yu|the_neural_noisy_channel", "authors": ["Lei Yu", "Phil Blunsom", "Chris Dyer", "Edward Grefenstette", "Tomas Kocisky"], "keywords": ["Natural language processing", "Deep learning", "Semi-Supervised Learning"], "conflicts": ["google.com", "ox.ac.uk"], "authorids": ["lei.yu@cs.ox.ac.uk", "pblunsom@google.com", "cdyer@google.com", "etg@google.com", "tkocisky@google.com"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287670678, "id": "ICLR.cc/2017/conference/-/paper240/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "SJ25-B5eg", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper240/reviewers", "ICLR.cc/2017/conference/paper240/areachairs"], "cdate": 1485287670678}}}, {"tddate": null, "tmdate": 1484083824777, "tcdate": 1484083824777, "number": 5, "id": "H1K_G0zIl", "invitation": "ICLR.cc/2017/conference/-/paper240/public/comment", "forum": "SJ25-B5eg", "replyto": "Bk_9pwZrl", "signatures": ["~Lei_Yu1"], "readers": ["everyone"], "writers": ["~Lei_Yu1"], "content": {"title": "Response", "comment": "Thanks for your review.\n\nWe will add the results for direct + LM + bias soon, but our preliminary experiments indicated this is a quite ineffective combination (in line with previous findings of Gulcehre et al., 2015).\n\nThe hyperparameters in Eq3 controls how much each model contributes to the score of output sequences. In the sentence compression task, increasing the weight for the channel model (\\lambda_1) and and the bias (\\lambda_4) results in higher recall and lower precision. Increasing the weights for the direct model (\\lambda_2) and language model (\\lambda_3) results in lower recall and higher precision. The bias for length is less sensitive than the others. On the heldout dataset with 1000 sentence pairs, ROUGE recall/precision increase/decrease by 1 point when \\lambda_4 is increased by 0.2. The ratio between \\lambda_1, \\lambda_2 and \\lambda_3 influences the performance significantly. The model behaves badly when the ratio, i.e. the difference between \\lambdas, is big. For example, keeping the other weights to 1, decrease \\lambda_3 from 1.0 to 0.8, the ROUGE-1 precision drops from ~33 to 30. If \\lambda_3 is set to 0.5, the ROUGE-1 precision drops even further reaching ~23. We simply use grid search to find the relatively optimal hyperparameters, with the range of [0.2, 0.5, 0.8, 1.0].\n\nThe performance is not sensitive to the beam size K1 and K2. Using a big K1 and K2 does not have much difference as using smaller ones. We did not tune these values in the experiments.\n\nIn general, our decoding algorithm shares the same search criterion as the work of Tillmann et al. (1997). There are a few subtle differences: 1) Without any pruning, as described in (Tillmann et al, 1997), the decoding algorithm has a complexity of I * J_max * |V|^2, where I is the length of the source sequence, and J_max is the maximum length of target sequence and |V| is the size of vocabulary. We reduce the complexity to I * I * J_max * |V| by introducing the auxiliary direct model to propose a constant number of candidate output sequences, followed by reranking with the noisy channel model. 2) In the work of Tillmann et al. (1997), they restrict the difference z_j - z_{j - 1} (jump size) to be no greater than 2 and use a bigram language model. By contrast, in our algorithm, we don\u2019t have this restriction.\n"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "The Neural Noisy Channel", "abstract": "We formulate sequence to sequence transduction as a noisy channel decoding problem and use recurrent neural networks to parameterise the source and channel models. Unlike direct models which can suffer from explaining-away effects during training, noisy channel models must produce outputs that explain their inputs, and their component models can be trained with not only paired training samples but also unpaired samples from the marginal output distribution. Using a latent variable to control how much of the conditioning sequence the channel model needs to read in order to generate a subsequent symbol, we obtain a tractable and effective beam search decoder. Experimental results on abstractive sentence summarisation, morphological inflection, and machine translation show that noisy channel models outperform direct models, and that they significantly benefit from increased amounts of unpaired output data that direct models cannot easily use.", "pdf": "/pdf/587cf5979157e003499aa4188ed3aa8e78064016.pdf", "TL;DR": "We formulate sequence to sequence transduction as a noisy channel decoding  problem and use recurrent neural networks to parameterise the source and channel  models.", "paperhash": "yu|the_neural_noisy_channel", "authors": ["Lei Yu", "Phil Blunsom", "Chris Dyer", "Edward Grefenstette", "Tomas Kocisky"], "keywords": ["Natural language processing", "Deep learning", "Semi-Supervised Learning"], "conflicts": ["google.com", "ox.ac.uk"], "authorids": ["lei.yu@cs.ox.ac.uk", "pblunsom@google.com", "cdyer@google.com", "etg@google.com", "tkocisky@google.com"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287670678, "id": "ICLR.cc/2017/conference/-/paper240/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "SJ25-B5eg", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper240/reviewers", "ICLR.cc/2017/conference/paper240/areachairs"], "cdate": 1485287670678}}}, {"tddate": null, "tmdate": 1484083368897, "tcdate": 1484083368897, "number": 4, "id": "H1-heCz8e", "invitation": "ICLR.cc/2017/conference/-/paper240/public/comment", "forum": "SJ25-B5eg", "replyto": "Hyfg6dyNx", "signatures": ["~Lei_Yu1"], "readers": ["everyone"], "writers": ["~Lei_Yu1"], "content": {"title": "Response", "comment": "Thanks for your review. We will add the results for direct + LM + bias soon.\nThe direct model in the paper refers to SSNT."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "The Neural Noisy Channel", "abstract": "We formulate sequence to sequence transduction as a noisy channel decoding problem and use recurrent neural networks to parameterise the source and channel models. Unlike direct models which can suffer from explaining-away effects during training, noisy channel models must produce outputs that explain their inputs, and their component models can be trained with not only paired training samples but also unpaired samples from the marginal output distribution. Using a latent variable to control how much of the conditioning sequence the channel model needs to read in order to generate a subsequent symbol, we obtain a tractable and effective beam search decoder. Experimental results on abstractive sentence summarisation, morphological inflection, and machine translation show that noisy channel models outperform direct models, and that they significantly benefit from increased amounts of unpaired output data that direct models cannot easily use.", "pdf": "/pdf/587cf5979157e003499aa4188ed3aa8e78064016.pdf", "TL;DR": "We formulate sequence to sequence transduction as a noisy channel decoding  problem and use recurrent neural networks to parameterise the source and channel  models.", "paperhash": "yu|the_neural_noisy_channel", "authors": ["Lei Yu", "Phil Blunsom", "Chris Dyer", "Edward Grefenstette", "Tomas Kocisky"], "keywords": ["Natural language processing", "Deep learning", "Semi-Supervised Learning"], "conflicts": ["google.com", "ox.ac.uk"], "authorids": ["lei.yu@cs.ox.ac.uk", "pblunsom@google.com", "cdyer@google.com", "etg@google.com", "tkocisky@google.com"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287670678, "id": "ICLR.cc/2017/conference/-/paper240/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "SJ25-B5eg", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper240/reviewers", "ICLR.cc/2017/conference/paper240/areachairs"], "cdate": 1485287670678}}}, {"tddate": null, "tmdate": 1483813903000, "tcdate": 1483813903000, "number": 3, "id": "HJDfN3RHl", "invitation": "ICLR.cc/2017/conference/-/paper240/official/comment", "forum": "SJ25-B5eg", "replyto": "SJ25-B5eg", "signatures": ["ICLR.cc/2017/conference/paper240/areachair1"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/conference/paper240/areachair1"], "content": {"title": "Authors: Reviews now in, chance for rebuttal", "comment": "Hi authors,\n\nWe apologize for the delay. There are now 3 full reviews on this work. When you have an opportunity please enter in a rebuttal so that reviewers can discuss. "}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "The Neural Noisy Channel", "abstract": "We formulate sequence to sequence transduction as a noisy channel decoding problem and use recurrent neural networks to parameterise the source and channel models. Unlike direct models which can suffer from explaining-away effects during training, noisy channel models must produce outputs that explain their inputs, and their component models can be trained with not only paired training samples but also unpaired samples from the marginal output distribution. Using a latent variable to control how much of the conditioning sequence the channel model needs to read in order to generate a subsequent symbol, we obtain a tractable and effective beam search decoder. Experimental results on abstractive sentence summarisation, morphological inflection, and machine translation show that noisy channel models outperform direct models, and that they significantly benefit from increased amounts of unpaired output data that direct models cannot easily use.", "pdf": "/pdf/587cf5979157e003499aa4188ed3aa8e78064016.pdf", "TL;DR": "We formulate sequence to sequence transduction as a noisy channel decoding  problem and use recurrent neural networks to parameterise the source and channel  models.", "paperhash": "yu|the_neural_noisy_channel", "authors": ["Lei Yu", "Phil Blunsom", "Chris Dyer", "Edward Grefenstette", "Tomas Kocisky"], "keywords": ["Natural language processing", "Deep learning", "Semi-Supervised Learning"], "conflicts": ["google.com", "ox.ac.uk"], "authorids": ["lei.yu@cs.ox.ac.uk", "pblunsom@google.com", "cdyer@google.com", "etg@google.com", "tkocisky@google.com"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287670551, "id": "ICLR.cc/2017/conference/-/paper240/official/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "reply": {"forum": "SJ25-B5eg", "writers": {"values-regex": "ICLR.cc/2017/conference/paper240/(AnonReviewer|areachair)[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/conference/paper240/(AnonReviewer|areachair)[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": [], "invitees": ["ICLR.cc/2017/conference/paper240/reviewers", "ICLR.cc/2017/conference/paper240/areachairs"], "cdate": 1485287670551}}}, {"tddate": null, "tmdate": 1483488298775, "tcdate": 1483488298775, "number": 3, "id": "BJXEh2FBe", "invitation": "ICLR.cc/2017/conference/-/paper240/official/review", "forum": "SJ25-B5eg", "replyto": "SJ25-B5eg", "signatures": ["ICLR.cc/2017/conference/paper240/AnonReviewer4"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/conference/paper240/AnonReviewer4"], "content": {"title": "Review", "rating": "7: Good paper, accept", "review": "This paper proposes to use an SSNT model of p(x|y) to allow for a noisy channel model of conditional generation that (still) allows for incremental generation of y. The authors also propose an approximate search strategy for decoding, and do an extensive empirical evaluation.\n\nPROs: This paper is generally well written, and the SSNT model is quite interesting and its application here well motivated. Furthermore, the empirical evaluation is very well done, and the authors obtain good results.\n\nCONs: One might be concerned about whether the additional training and decoding complexity is warranted. For instance, one might plausibly obtain the benefits of the proposed approach by reranking (full) outputs from a standard seq2seq model with a score combining p(y|x), p(x|y), and p(y). (It's worth noting that Li et al. (NAACL 2016) do something similar for conversation modeling). At the same time, being able to rerank during search may be helpful, and so it might be nice to see some experiments addressing this.\n\nOther Comments: \n - Given that the main thrust of the paper is to provide a model for p(x|y), the paper might be slightly clearer if Section 2 were presented from the perspective of modeling p(x|y) instead of switching back to p(y|x) as in the original Yu et al. paper. \n\n - It initially seems strange to suggest a noisy-channel model as a way of addressing the \"explaining away\" problem, since now you have an explicit, uncalibrated p(y) term. However, since seq2seq models appear to naturally do a lot of target-side language modeling, incorporating an explicit p(x|y) term seems quite clever.\n", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "The Neural Noisy Channel", "abstract": "We formulate sequence to sequence transduction as a noisy channel decoding problem and use recurrent neural networks to parameterise the source and channel models. Unlike direct models which can suffer from explaining-away effects during training, noisy channel models must produce outputs that explain their inputs, and their component models can be trained with not only paired training samples but also unpaired samples from the marginal output distribution. Using a latent variable to control how much of the conditioning sequence the channel model needs to read in order to generate a subsequent symbol, we obtain a tractable and effective beam search decoder. Experimental results on abstractive sentence summarisation, morphological inflection, and machine translation show that noisy channel models outperform direct models, and that they significantly benefit from increased amounts of unpaired output data that direct models cannot easily use.", "pdf": "/pdf/587cf5979157e003499aa4188ed3aa8e78064016.pdf", "TL;DR": "We formulate sequence to sequence transduction as a noisy channel decoding  problem and use recurrent neural networks to parameterise the source and channel  models.", "paperhash": "yu|the_neural_noisy_channel", "authors": ["Lei Yu", "Phil Blunsom", "Chris Dyer", "Edward Grefenstette", "Tomas Kocisky"], "keywords": ["Natural language processing", "Deep learning", "Semi-Supervised Learning"], "conflicts": ["google.com", "ox.ac.uk"], "authorids": ["lei.yu@cs.ox.ac.uk", "pblunsom@google.com", "cdyer@google.com", "etg@google.com", "tkocisky@google.com"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1481932799000, "tmdate": 1483488299403, "id": "ICLR.cc/2017/conference/-/paper240/official/review", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/conference/paper240/reviewers"], "noninvitees": ["ICLR.cc/2017/conference/paper240/AnonReviewer1", "ICLR.cc/2017/conference/paper240/AnonReviewer3", "ICLR.cc/2017/conference/paper240/AnonReviewer4"], "reply": {"forum": "SJ25-B5eg", "replyto": "SJ25-B5eg", "writers": {"values-regex": "ICLR.cc/2017/conference/paper240/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/conference/paper240/AnonReviewer[0-9]+"}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "value-regex": "[\\S\\s]{1,20000}"}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1489708799000, "cdate": 1483488299403}}}, {"tddate": null, "tmdate": 1482943887874, "tcdate": 1482943887874, "number": 2, "id": "Bk_9pwZrl", "invitation": "ICLR.cc/2017/conference/-/paper240/official/review", "forum": "SJ25-B5eg", "replyto": "SJ25-B5eg", "signatures": ["ICLR.cc/2017/conference/paper240/AnonReviewer3"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/conference/paper240/AnonReviewer3"], "content": {"title": "hideously late review", "rating": "7: Good paper, accept", "review": "The paper proposes an online variant of segment to segment transducers, which allows to circumvent the necessity of observing whole sentence, before making target predictions. Authors mostly build on their previous work, allowing additionally to leverage independent priors on the target hypotheses, like the language grammar or sentence length.\n\nStrong points:\n- well written, interesting idea of combining various sources of information in a Bayesian framework for seq2seq models\nHandling something in an online manner typically makes things more difficult, and this is what the authors are trying to do here - which is definitely of interest to the community\n- strong experimental section, with some strong results (though not complete: see weak points)\n\nWeak points:\n- Authors do not improve on computational complexity (w.r.t Tillmann proposal), hence the algorithms may be found difficult to apply in scenarios where inputs may be long (this already takes into account a rather constrained model of alignment latent variables)\n- What about the baseline where you only combine direct, LM and bias contributions (no channel)? Was there any (non-obvious) algorithmic constraint why - this has not been included?\n\nSome other (minor) comments:\n\n- Related to the first weak point: can you elaborate more on how the clue of your work is conceptually different from the work of Tillmann et al. (1997) (except, of course, the fact you use connectionist discriminative models to derive particular conditional probabilities). \n- How sensitive is the model to different choices of hyper-parameters in eq (3). Do you naively search through the search space of those, or do something more clever?\n- Some more comments on details of the auxiliary direct model would be definitely of interest.\n- How crucial is the correct choice of the pruning variables (K1 and K2)? \n- Sec. 2: makes no Markovian assumptions -> no first-order Markovian assumption?\n\nTypos:\nTable 1: chanel -> channel (one before last row)\n\nApologies for late review.", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "The Neural Noisy Channel", "abstract": "We formulate sequence to sequence transduction as a noisy channel decoding problem and use recurrent neural networks to parameterise the source and channel models. Unlike direct models which can suffer from explaining-away effects during training, noisy channel models must produce outputs that explain their inputs, and their component models can be trained with not only paired training samples but also unpaired samples from the marginal output distribution. Using a latent variable to control how much of the conditioning sequence the channel model needs to read in order to generate a subsequent symbol, we obtain a tractable and effective beam search decoder. Experimental results on abstractive sentence summarisation, morphological inflection, and machine translation show that noisy channel models outperform direct models, and that they significantly benefit from increased amounts of unpaired output data that direct models cannot easily use.", "pdf": "/pdf/587cf5979157e003499aa4188ed3aa8e78064016.pdf", "TL;DR": "We formulate sequence to sequence transduction as a noisy channel decoding  problem and use recurrent neural networks to parameterise the source and channel  models.", "paperhash": "yu|the_neural_noisy_channel", "authors": ["Lei Yu", "Phil Blunsom", "Chris Dyer", "Edward Grefenstette", "Tomas Kocisky"], "keywords": ["Natural language processing", "Deep learning", "Semi-Supervised Learning"], "conflicts": ["google.com", "ox.ac.uk"], "authorids": ["lei.yu@cs.ox.ac.uk", "pblunsom@google.com", "cdyer@google.com", "etg@google.com", "tkocisky@google.com"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1481932799000, "tmdate": 1483488299403, "id": "ICLR.cc/2017/conference/-/paper240/official/review", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/conference/paper240/reviewers"], "noninvitees": ["ICLR.cc/2017/conference/paper240/AnonReviewer1", "ICLR.cc/2017/conference/paper240/AnonReviewer3", "ICLR.cc/2017/conference/paper240/AnonReviewer4"], "reply": {"forum": "SJ25-B5eg", "replyto": "SJ25-B5eg", "writers": {"values-regex": "ICLR.cc/2017/conference/paper240/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/conference/paper240/AnonReviewer[0-9]+"}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "value-regex": "[\\S\\s]{1,20000}"}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1489708799000, "cdate": 1483488299403}}}, {"tddate": null, "tmdate": 1481768170378, "tcdate": 1481768170372, "number": 1, "id": "Hyfg6dyNx", "invitation": "ICLR.cc/2017/conference/-/paper240/official/review", "forum": "SJ25-B5eg", "replyto": "SJ25-B5eg", "signatures": ["ICLR.cc/2017/conference/paper240/AnonReviewer1"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/conference/paper240/AnonReviewer1"], "content": {"title": "Review", "rating": "6: Marginally above acceptance threshold", "review": "This paper proposes the neural noisy channel model, P(x|y), where (x, y) is a input-to-out sequence pair,  based on the authors' previous work on segment to segment neural transduction (SSNT) model. For the noisy channel model, the key difference from sequence-to-sequence is that the complete sequence y is not observed beforehand. SSNT handles this problem elegantly by performing incremental alignment and prediction. However, this paper does not present anything that is particular novel on top of the SSNT. The SSNT model is still applicable by reverting the input and output sequences. The authors said that an unidirectional LSTM has to be used as an encoder instead of the bidirectional LSTM, but I think the difference is minor. The decoding algorithm presented in the appendix is relatively new. \n\nThe experimental study is very comprehensive and strong, however, there is one important baseline number that is missing for all the experiments. Can you give the number that uses direct + LM + bias, and if you can give direct + bias number would be even better. Although using a LM for the direct model does not make a lot of sense mathematically, however, it works pretty well in practice, and the LM can rescore and smooth your predictions, see \n\nDeep Speech 2: End-to-End Speech Recognition in English and Mandarin\n\nfrom Baidu for example. I think the LM may be also the key to explain why noisy channel is much better than direct model in Table 3. A couple minor questions are\n\n1. it is not very clear to me is your direct model in the experiments SSNT or sequence-to-sequence model?\n\n2. O(|x|^2*|y|) training complexity is OK, but it would be great to further cut down the computational cost, as it is still very expensive for long input sequences, for example, for paragraph or document level modeling, or speech sequences. \n\nThe paper is well written, and overall, it is still an interesting paper, as the channel model is always of great interest to the general public.\n", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "The Neural Noisy Channel", "abstract": "We formulate sequence to sequence transduction as a noisy channel decoding problem and use recurrent neural networks to parameterise the source and channel models. Unlike direct models which can suffer from explaining-away effects during training, noisy channel models must produce outputs that explain their inputs, and their component models can be trained with not only paired training samples but also unpaired samples from the marginal output distribution. Using a latent variable to control how much of the conditioning sequence the channel model needs to read in order to generate a subsequent symbol, we obtain a tractable and effective beam search decoder. Experimental results on abstractive sentence summarisation, morphological inflection, and machine translation show that noisy channel models outperform direct models, and that they significantly benefit from increased amounts of unpaired output data that direct models cannot easily use.", "pdf": "/pdf/587cf5979157e003499aa4188ed3aa8e78064016.pdf", "TL;DR": "We formulate sequence to sequence transduction as a noisy channel decoding  problem and use recurrent neural networks to parameterise the source and channel  models.", "paperhash": "yu|the_neural_noisy_channel", "authors": ["Lei Yu", "Phil Blunsom", "Chris Dyer", "Edward Grefenstette", "Tomas Kocisky"], "keywords": ["Natural language processing", "Deep learning", "Semi-Supervised Learning"], "conflicts": ["google.com", "ox.ac.uk"], "authorids": ["lei.yu@cs.ox.ac.uk", "pblunsom@google.com", "cdyer@google.com", "etg@google.com", "tkocisky@google.com"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1481932799000, "tmdate": 1483488299403, "id": "ICLR.cc/2017/conference/-/paper240/official/review", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/conference/paper240/reviewers"], "noninvitees": ["ICLR.cc/2017/conference/paper240/AnonReviewer1", "ICLR.cc/2017/conference/paper240/AnonReviewer3", "ICLR.cc/2017/conference/paper240/AnonReviewer4"], "reply": {"forum": "SJ25-B5eg", "replyto": "SJ25-B5eg", "writers": {"values-regex": "ICLR.cc/2017/conference/paper240/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/conference/paper240/AnonReviewer[0-9]+"}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "value-regex": "[\\S\\s]{1,20000}"}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1489708799000, "cdate": 1483488299403}}}, {"tddate": null, "tmdate": 1480984187136, "tcdate": 1480984187130, "number": 3, "id": "SJ7t8KmQe", "invitation": "ICLR.cc/2017/conference/-/paper240/public/comment", "forum": "SJ25-B5eg", "replyto": "rJ6BqxXXe", "signatures": ["~Lei_Yu1"], "readers": ["everyone"], "writers": ["~Lei_Yu1"], "content": {"title": "Response", "comment": "Thanks for your comment, we will edit the paper to make it clearer.\n\nIn terms of your questions --\nThe effect of length bias: smaller/no length bias tends to generate shorter output sequence. That results in higher precision and lower recall in ROUGE.\n\nThe alignment transition: Yes, the decoding algorithm runs frame-by-frame. It is consistent with the model defined in Section 2.1.\n\nThe function getCandidateOutputs: yes, it means to obtain partial candidate outputs via backtracing. We include this function in the pseudocode in order to present the algorithm clearly. In practice, these partial output sequences can be cached without backtracing.\n\n\n"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "The Neural Noisy Channel", "abstract": "We formulate sequence to sequence transduction as a noisy channel decoding problem and use recurrent neural networks to parameterise the source and channel models. Unlike direct models which can suffer from explaining-away effects during training, noisy channel models must produce outputs that explain their inputs, and their component models can be trained with not only paired training samples but also unpaired samples from the marginal output distribution. Using a latent variable to control how much of the conditioning sequence the channel model needs to read in order to generate a subsequent symbol, we obtain a tractable and effective beam search decoder. Experimental results on abstractive sentence summarisation, morphological inflection, and machine translation show that noisy channel models outperform direct models, and that they significantly benefit from increased amounts of unpaired output data that direct models cannot easily use.", "pdf": "/pdf/587cf5979157e003499aa4188ed3aa8e78064016.pdf", "TL;DR": "We formulate sequence to sequence transduction as a noisy channel decoding  problem and use recurrent neural networks to parameterise the source and channel  models.", "paperhash": "yu|the_neural_noisy_channel", "authors": ["Lei Yu", "Phil Blunsom", "Chris Dyer", "Edward Grefenstette", "Tomas Kocisky"], "keywords": ["Natural language processing", "Deep learning", "Semi-Supervised Learning"], "conflicts": ["google.com", "ox.ac.uk"], "authorids": ["lei.yu@cs.ox.ac.uk", "pblunsom@google.com", "cdyer@google.com", "etg@google.com", "tkocisky@google.com"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287670678, "id": "ICLR.cc/2017/conference/-/paper240/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "SJ25-B5eg", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper240/reviewers", "ICLR.cc/2017/conference/paper240/areachairs"], "cdate": 1485287670678}}}, {"tddate": null, "tmdate": 1480979341211, "tcdate": 1480979312105, "number": 2, "id": "BJd_Q_Q7e", "invitation": "ICLR.cc/2017/conference/-/paper240/public/comment", "forum": "SJ25-B5eg", "replyto": "Hk9c-6hzg", "signatures": ["~Lei_Yu1"], "readers": ["everyone"], "writers": ["~Lei_Yu1"], "content": {"title": "Response to \"Difference from previous work\"", "comment": "Thanks for your comment. In this work, we factorise p (output sequence y | input sequence x) into the product of a \"channel model\" p(x | y) and \"source model\" p(y), which is a language model in these experiments. We let the segment to segment neural transduction model (SSNT) of Yu et al. (EMNLP, 2016) parameterise p(x | y), the reverse transduction, and an LSTM language model parameterise p(y). Note that in order to serve as a channel model, the predicted token is required to condition on the incrementally constructed context, i.e. an unidirectional LSTM is used as the encoder of the channel model. In the Yu et al. work, p(y | x) was modelled directly without the two-part factorisation, and thus suffers from the explaining away problems we discuss in the introduction. A second difference is that in this work, we train SSNT and the language model separately, in many experiments using different data resources. For the channel model, the training procedure is the same as that described in Yu et al, 2016.\n\nFinally, we propose a novel decoding algorithm which is described in Section 3 in the paper. The pseudocode is provided in Appendix A. To briefly summarise the decoding algorithm, we employ the direct model to guide the beam search, and use the noisy channel model or a linear combination of the noisy channel model and the direct model to rerank the partial outputs in the beam.\n"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "The Neural Noisy Channel", "abstract": "We formulate sequence to sequence transduction as a noisy channel decoding problem and use recurrent neural networks to parameterise the source and channel models. Unlike direct models which can suffer from explaining-away effects during training, noisy channel models must produce outputs that explain their inputs, and their component models can be trained with not only paired training samples but also unpaired samples from the marginal output distribution. Using a latent variable to control how much of the conditioning sequence the channel model needs to read in order to generate a subsequent symbol, we obtain a tractable and effective beam search decoder. Experimental results on abstractive sentence summarisation, morphological inflection, and machine translation show that noisy channel models outperform direct models, and that they significantly benefit from increased amounts of unpaired output data that direct models cannot easily use.", "pdf": "/pdf/587cf5979157e003499aa4188ed3aa8e78064016.pdf", "TL;DR": "We formulate sequence to sequence transduction as a noisy channel decoding  problem and use recurrent neural networks to parameterise the source and channel  models.", "paperhash": "yu|the_neural_noisy_channel", "authors": ["Lei Yu", "Phil Blunsom", "Chris Dyer", "Edward Grefenstette", "Tomas Kocisky"], "keywords": ["Natural language processing", "Deep learning", "Semi-Supervised Learning"], "conflicts": ["google.com", "ox.ac.uk"], "authorids": ["lei.yu@cs.ox.ac.uk", "pblunsom@google.com", "cdyer@google.com", "etg@google.com", "tkocisky@google.com"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287670678, "id": "ICLR.cc/2017/conference/-/paper240/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "SJ25-B5eg", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper240/reviewers", "ICLR.cc/2017/conference/paper240/areachairs"], "cdate": 1485287670678}}}, {"tddate": null, "tmdate": 1480948293442, "tcdate": 1480948293436, "number": 1, "id": "rJ6BqxXXe", "invitation": "ICLR.cc/2017/conference/-/paper240/public/comment", "forum": "SJ25-B5eg", "replyto": "SJ25-B5eg", "signatures": ["~Mirko_Hannemann1"], "readers": ["everyone"], "writers": ["~Mirko_Hannemann1"], "content": {"title": "comments on readability", "comment": "After presenting everything as noisy channel (i.e. p(x|y)), it would be beneficial to also mention p(x|y) in the model description in section 2 and in the inference section 2.2.\n\nIn section 3, the presentation changes to using p(x|y), before more exactly introducing, how p(x|y) is modeled and trained.\nIt is not immediately clear, what is the auxiliary direct model q(y,z|x) - i.e. it is the model inferred in section 2.2. (== proposal model == decoding model).\n\nThe explaining paragraph in section 3: \"the search problem remains nontrivial [...] softmax over the input variables\",\ncould be made more clear by saying, that in the model p(x|y) we need to avoid conditioning on the full (output word) sequence y,\nwhich is possible by using only the forward LSTM on the outputs. \n\nThe sentence in section 3 is not complete: \"The top K1 partial output sequences.\"\n\nIn Tables 1/2, you should introduce the meaning of RG-1/RG-2/RG-L.\nWhat is the effect of leaving out/adding the length bias?\nbias(uni)/bias(bi) is misleading, it should be channel(bi)/direct(bi)\n\nThe alignment transition model (EMIT/SHIFT) is calculated frame-by-frame (end of section 2.1). Is also the decoding algorithm in appendix A running frame-by-frame? \n\nIn Appendix A, the function getCandidateOutputs is not clear. Does it mean a partial backtrace to obtain the full sequence y_1..j?"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "The Neural Noisy Channel", "abstract": "We formulate sequence to sequence transduction as a noisy channel decoding problem and use recurrent neural networks to parameterise the source and channel models. Unlike direct models which can suffer from explaining-away effects during training, noisy channel models must produce outputs that explain their inputs, and their component models can be trained with not only paired training samples but also unpaired samples from the marginal output distribution. Using a latent variable to control how much of the conditioning sequence the channel model needs to read in order to generate a subsequent symbol, we obtain a tractable and effective beam search decoder. Experimental results on abstractive sentence summarisation, morphological inflection, and machine translation show that noisy channel models outperform direct models, and that they significantly benefit from increased amounts of unpaired output data that direct models cannot easily use.", "pdf": "/pdf/587cf5979157e003499aa4188ed3aa8e78064016.pdf", "TL;DR": "We formulate sequence to sequence transduction as a noisy channel decoding  problem and use recurrent neural networks to parameterise the source and channel  models.", "paperhash": "yu|the_neural_noisy_channel", "authors": ["Lei Yu", "Phil Blunsom", "Chris Dyer", "Edward Grefenstette", "Tomas Kocisky"], "keywords": ["Natural language processing", "Deep learning", "Semi-Supervised Learning"], "conflicts": ["google.com", "ox.ac.uk"], "authorids": ["lei.yu@cs.ox.ac.uk", "pblunsom@google.com", "cdyer@google.com", "etg@google.com", "tkocisky@google.com"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287670678, "id": "ICLR.cc/2017/conference/-/paper240/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "SJ25-B5eg", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper240/reviewers", "ICLR.cc/2017/conference/paper240/areachairs"], "cdate": 1485287670678}}}, {"tddate": null, "tmdate": 1480540561954, "tcdate": 1480540561950, "number": 1, "id": "Hk9c-6hzg", "invitation": "ICLR.cc/2017/conference/-/paper240/pre-review/question", "forum": "SJ25-B5eg", "replyto": "SJ25-B5eg", "signatures": ["ICLR.cc/2017/conference/paper240/AnonReviewer1"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/conference/paper240/AnonReviewer1"], "content": {"title": "Difference from previous work", "question": "Please can you explain how much it is different from your previous work in terms of the model and training algorithm, i.e. Yu et al 2016 Online segment to segment neural transduction, apart from the experiments?"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "The Neural Noisy Channel", "abstract": "We formulate sequence to sequence transduction as a noisy channel decoding problem and use recurrent neural networks to parameterise the source and channel models. Unlike direct models which can suffer from explaining-away effects during training, noisy channel models must produce outputs that explain their inputs, and their component models can be trained with not only paired training samples but also unpaired samples from the marginal output distribution. Using a latent variable to control how much of the conditioning sequence the channel model needs to read in order to generate a subsequent symbol, we obtain a tractable and effective beam search decoder. Experimental results on abstractive sentence summarisation, morphological inflection, and machine translation show that noisy channel models outperform direct models, and that they significantly benefit from increased amounts of unpaired output data that direct models cannot easily use.", "pdf": "/pdf/587cf5979157e003499aa4188ed3aa8e78064016.pdf", "TL;DR": "We formulate sequence to sequence transduction as a noisy channel decoding  problem and use recurrent neural networks to parameterise the source and channel  models.", "paperhash": "yu|the_neural_noisy_channel", "authors": ["Lei Yu", "Phil Blunsom", "Chris Dyer", "Edward Grefenstette", "Tomas Kocisky"], "keywords": ["Natural language processing", "Deep learning", "Semi-Supervised Learning"], "conflicts": ["google.com", "ox.ac.uk"], "authorids": ["lei.yu@cs.ox.ac.uk", "pblunsom@google.com", "cdyer@google.com", "etg@google.com", "tkocisky@google.com"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1480741199000, "tmdate": 1480959387700, "id": "ICLR.cc/2017/conference/-/paper240/pre-review/question", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/conference/paper240/reviewers"], "noninvitees": ["ICLR.cc/2017/conference/paper240/AnonReviewer1"], "reply": {"forum": "SJ25-B5eg", "replyto": "SJ25-B5eg", "writers": {"values-regex": "ICLR.cc/2017/conference/paper240/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/conference/paper240/AnonReviewer[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your question.", "value-regex": ".{1,500}"}, "question": {"order": 2, "description": "Your question", "value-regex": "[\\S\\s]{1,5000}"}}}, "nonreaders": [], "expdate": 1488517199000, "cdate": 1480959387700}}}], "count": 14}