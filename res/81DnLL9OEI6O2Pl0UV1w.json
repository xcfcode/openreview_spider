{"notes": [{"tddate": null, "number": null, "ddate": null, "cdate": null, "tmdate": 1458266188869, "tcdate": 1458266188869, "id": "MwVY2A13BTqxwkg1t7PR", "invitation": "ICLR.cc/2016/workshop/-/paper/136/comment", "forum": "81DnLL9OEI6O2Pl0UV1w", "replyto": "3QxoKp4MGup7y9wltPEg", "signatures": ["~Philipp_Matthias_Gysel1"], "readers": ["everyone"], "writers": ["~Philipp_Matthias_Gysel1"], "content": {"title": "Paper is updated with results and details on fine-tuning", "comment": "Dear Reviewer, thank you very much for your reply.\n\nIndependent quantization\n---------------------------------\nThis is an important and interesting question. Indeed, quantizing one network part affects the \"optimal\" quantization strategy of other network parts. As described in section 4, we first analyse the range of numbers (weights + outputs) to find the necessary number of bits in the integer part. We chose this strategy, which ensures no saturation happens. Other strategies might yield better results. We found for small networks, a thorough DSE yields slightly better results. However, for large networks, a thorough DSE would probably exceed the hardware developer's patience. Moreover, with fine-tuning in the loop, the partition of integer and fractional part becomes a little less important. Once Ristretto made its final choice of integer bits, it starts analyzing the required bit-width. Please let me know in case this doesn't answer your question yet.\n\nFine-tuning\n---------------\nWe added results on fixed point fine-tuning. We successfully fine-tuned 3 nets on the ImageNet data set. Moreover, the paper contains a detailed description how Ristretto fine-tunes discrete-valued weights.\n\nLatest ResNet and VGG\n------------------------------\nThanks for the great suggestion. We added 2 more nets to the paper. We now present fine-tuned AlexNet (CaffeNet), GoogLeNet and SqueezeNet, all of which classify images into the 1000 ImageNet categories. ResNet would definitely be very interesting too."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"CMT_id": "", "title": "Hardware-Oriented Approximation of Convolutional Neural Networks", "abstract": "High computational complexity hinders the widespread usage of Convolutional Neural Networks (CNNs), especially in mobile devices. Hardware accelerators are arguably the most promising approach for reducing both execution time and power consumption. One of the most important steps in accelerator development is hardware-oriented model approximation. In this paper we present Ristretto, a model approximation framework that analyzes a given CNN with respect to numerical resolution used in representing weights and outputs of convolutional and fully connected layers. Ristretto can condense models by using fixed point arithmetic and representation instead of floating point. Moreover, Ristretto fine-tunes the resulting fixed point network. Given a maximum error tolerance of 1%, Ristretto can successfully condense CaffeNet and SqueezeNet to 8-bit. The code for Ristretto is available.", "pdf": "http://arxiv.org/pdf/1604.03168v2.pdf", "paperhash": "gysel|hardwareoriented_approximation_of_convolutional_neural_networks", "conflicts": ["ece.ucdavis.edu"], "authors": ["Philipp Gysel", "Mohammad Motamedi", "Soheil Ghiasi"], "authorids": ["pmgysel@ucdavis.edu", "mmotamedi@ucdavis.edu", "ghiasi@ucdavis.edu"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "tmdate": null, "cdate": 1455826691564, "ddate": null, "super": null, "final": null, "tcdate": 1455826691564, "id": "ICLR.cc/2016/workshop/-/paper/136/comment", "writers": ["ICLR.cc/2016/workshop"], "signatures": ["ICLR.cc/2016/workshop"], "readers": ["everyone"], "reply": {"pdf": null, "replyto": null, "writers": {"values-regex": "~.*"}, "forum": "81DnLL9OEI6O2Pl0UV1w", "signatures": {"values-regex": "~.*", "description": "Your displayed identity associated with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,5000}"}}}, "invitees": ["~", "ICLR.cc/2016/workshop/paper/136/reviewer/10"], "nonreaders": [], "noninvitees": []}}}, {"tddate": null, "number": null, "ddate": null, "cdate": null, "tmdate": 1458232264391, "tcdate": 1458232264391, "id": "3QxoKp4MGup7y9wltPEg", "invitation": "ICLR.cc/2016/workshop/-/paper/136/review/12", "forum": "81DnLL9OEI6O2Pl0UV1w", "replyto": "81DnLL9OEI6O2Pl0UV1w", "signatures": ["ICLR.cc/2016/workshop/paper/136/reviewer/12"], "readers": ["everyone"], "writers": ["ICLR.cc/2016/workshop/paper/136/reviewer/12"], "content": {"title": "Interesting workshop paper", "rating": "7: Good paper, accept", "review": "\nThe paper proposes a framework for quantizing the weights & activations within models trained in the Caffe framework, dramatically reducing the memory and computation requirements for big convnets used for image recognition. This makes the models useful for deployment on mobile devices and other low-power platforms. \n\nThe system is well designed and achieves compelling results, across 3 different models (widely varying in size). The application is an important one. \n\nSeveral points:\n\n- The quantizations are performed independently for each layer. How can you be sure that the errors won\u2019t compound up, making the final outputs inaccurate.\n\n- Fine-tuning is an obvious improvement, so it great that this is a future refinement. \n\n- It would be good to show results for the latest ResNet and VGG models which use 3x3 kernels. It isn\u2019t clear how these will compress. Also some implementations use the Winograd transforms, but might also affect the precision that you can get away with.\n\nIn summary, it is an interesting piece of work and should be accepted to the workshop track.", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"CMT_id": "", "title": "Hardware-Oriented Approximation of Convolutional Neural Networks", "abstract": "High computational complexity hinders the widespread usage of Convolutional Neural Networks (CNNs), especially in mobile devices. Hardware accelerators are arguably the most promising approach for reducing both execution time and power consumption. One of the most important steps in accelerator development is hardware-oriented model approximation. In this paper we present Ristretto, a model approximation framework that analyzes a given CNN with respect to numerical resolution used in representing weights and outputs of convolutional and fully connected layers. Ristretto can condense models by using fixed point arithmetic and representation instead of floating point. Moreover, Ristretto fine-tunes the resulting fixed point network. Given a maximum error tolerance of 1%, Ristretto can successfully condense CaffeNet and SqueezeNet to 8-bit. The code for Ristretto is available.", "pdf": "http://arxiv.org/pdf/1604.03168v2.pdf", "paperhash": "gysel|hardwareoriented_approximation_of_convolutional_neural_networks", "conflicts": ["ece.ucdavis.edu"], "authors": ["Philipp Gysel", "Mohammad Motamedi", "Soheil Ghiasi"], "authorids": ["pmgysel@ucdavis.edu", "mmotamedi@ucdavis.edu", "ghiasi@ucdavis.edu"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "tmdate": null, "cdate": 1456580037414, "ddate": null, "super": null, "final": null, "duedate": 1460725200000, "tcdate": 1456580037414, "id": "ICLR.cc/2016/workshop/-/paper/136/review/12", "writers": ["ICLR.cc/2016/workshop"], "signatures": ["ICLR.cc/2016/workshop"], "reply": {"pdf": null, "forum": "81DnLL9OEI6O2Pl0UV1w", "replyto": "81DnLL9OEI6O2Pl0UV1w", "writers": {"values-regex": "(~.*)|ICLR.cc/2016/workshop/paper/[0-9]+/reviewer/[0-9]+)"}, "signatures": {"values-regex": "(~.*)|ICLR.cc/2016/workshop/paper/[0-9]+/reviewer/[0-9]+)", "description": "Your displayed identity associated with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "value-regex": "[\\S\\s]{1,5000}"}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "invitees": [], "nonreaders": [], "noninvitees": [], "readers": ["everyone", "ICLR.cc/2016/workshop/paper/136/reviewer/12", "ICLR.cc/2016/workshop"], "expdate": 1468501200000}}}, {"tddate": null, "number": null, "ddate": null, "cdate": null, "tmdate": 1458229389508, "tcdate": 1458229389508, "id": "6XArYQ9DYIrVp0EvsEBq", "invitation": "ICLR.cc/2016/workshop/-/paper/136/comment", "forum": "81DnLL9OEI6O2Pl0UV1w", "replyto": "gZ9vBw9rytAPowrRUAZL", "signatures": ["~Philipp_Matthias_Gysel1"], "readers": ["everyone"], "writers": ["~Philipp_Matthias_Gysel1"], "content": {"title": "We add results on fine tuned GoogleNet and SqueezeNet", "comment": "Thank you very much for your suggestions and questions.\n\nRecent architectures:\n--------------------------\nAccording to your advise, we used our Ristretto framework to condense GoogleNet and SqueezeNet (http://arxiv.org/abs/1602.07360). Both nets were trimmed to 8-bit in convolutional and fully connected layers, as well as fine tuned in fixed point. Here we report top-1 classification accuracies on the ImageNet validation data set:\nSqueezeNet, 32-bit floating point: 57.68%, 8-bit dynamic fixed point: 57.09% (the resulting net parameter size is below 2MB).\nBVLC GoogLeNet, 32-bit floating point: 68.93%, 8-bit dynamic fixed point: 66.49%.\nWe updated the paper with these numbers. Moreover, we will add a section on the fine tuning procedure.\n\nDynamic fixed point:\n--------------------------\nYou are right, most layer outputs are in a similar range. The same holds for parameters. The big advantage of dynamic fixed point is that we can use different numerical representations for the layer outputs than for parameters. While layer outputs can be relatively big, network parameters are much smaller and require more bits in the fractional part.\n\nBatch normalization:\n--------------------------\nI assume you were referring to batch normalization layers. The intermediate results in batch normalization (as well as local response normalization, LRN) span a wide dynamic range, which is the reason why most recently proposed FPGA implementations favor floating point arithmetic for these layers (or nets without normalization layers, such as VGG and SqueezeNet). Since convolutional and fully connected layers make up for the large part of arithmetic operations and layer parameters, we first focused on these layers. As a side note, the current version of Ristretto supports custom mini-floating point arithmetic, which can be applied to LRN layers.\n\nHelper tool for scientific breakthroughs:\n-----------------------------------------------\nEven though there have been various proposals for network trimming, to the best of our knowledge, there is no open-source project that would allow for fast and in-depth analysis of different fixed point representations for deep CNNs. We are confident Ristretto will help researchers to speedup the development of hardware accelerator designs."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"CMT_id": "", "title": "Hardware-Oriented Approximation of Convolutional Neural Networks", "abstract": "High computational complexity hinders the widespread usage of Convolutional Neural Networks (CNNs), especially in mobile devices. Hardware accelerators are arguably the most promising approach for reducing both execution time and power consumption. One of the most important steps in accelerator development is hardware-oriented model approximation. In this paper we present Ristretto, a model approximation framework that analyzes a given CNN with respect to numerical resolution used in representing weights and outputs of convolutional and fully connected layers. Ristretto can condense models by using fixed point arithmetic and representation instead of floating point. Moreover, Ristretto fine-tunes the resulting fixed point network. Given a maximum error tolerance of 1%, Ristretto can successfully condense CaffeNet and SqueezeNet to 8-bit. The code for Ristretto is available.", "pdf": "http://arxiv.org/pdf/1604.03168v2.pdf", "paperhash": "gysel|hardwareoriented_approximation_of_convolutional_neural_networks", "conflicts": ["ece.ucdavis.edu"], "authors": ["Philipp Gysel", "Mohammad Motamedi", "Soheil Ghiasi"], "authorids": ["pmgysel@ucdavis.edu", "mmotamedi@ucdavis.edu", "ghiasi@ucdavis.edu"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "tmdate": null, "cdate": 1455826691564, "ddate": null, "super": null, "final": null, "tcdate": 1455826691564, "id": "ICLR.cc/2016/workshop/-/paper/136/comment", "writers": ["ICLR.cc/2016/workshop"], "signatures": ["ICLR.cc/2016/workshop"], "readers": ["everyone"], "reply": {"pdf": null, "replyto": null, "writers": {"values-regex": "~.*"}, "forum": "81DnLL9OEI6O2Pl0UV1w", "signatures": {"values-regex": "~.*", "description": "Your displayed identity associated with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,5000}"}}}, "invitees": ["~", "ICLR.cc/2016/workshop/paper/136/reviewer/10"], "nonreaders": [], "noninvitees": []}}}, {"tddate": null, "number": null, "ddate": null, "cdate": null, "tmdate": 1458184956466, "tcdate": 1458184956466, "id": "gZ9vBw9rytAPowrRUAZL", "invitation": "ICLR.cc/2016/workshop/-/paper/136/review/11", "forum": "81DnLL9OEI6O2Pl0UV1w", "replyto": "81DnLL9OEI6O2Pl0UV1w", "signatures": ["ICLR.cc/2016/workshop/paper/136/reviewer/11"], "readers": ["everyone"], "writers": ["ICLR.cc/2016/workshop/paper/136/reviewer/11"], "content": {"title": "Offline model quantization tool, useful tool but not scientifically groundbreaking.", "rating": "5: Marginally below acceptance threshold", "review": "The authors present a framework that can quantize Caffe models into 8-bit and lower fixed-point precision models, which is useful for lowering memory and energy consumption on embedded devices. The compression is an iterative algorithm that determines data statistics to figure out activation and parameter ranges that can be compressed, and conditionally optimizes convolutional weights, fully connected weights and activations given the compression of the other parts.\nThis work focuses on processing models already trained with high numerical precision (32 bits float) and compress them, as opposed to other work that tries to train directly with quantized operations.\n\nResults seem good (trimming AlexNet model from 32-bit floating point to 8 bits with only .3% degradation), however I am not familiar enough with this domain to know how this compares to other quantization work and cannot comment on originality.\n\nWhile this is a very useful tool to have for some people, it is not very significant from a scientific point of view.\n\nComment:\n- The tested networks do not have batch-normalization layers I assume, batchnorm is pretty standard nowadays and thus dynamic fixed point may be much less useful when things are normalized. The paper would be stronger if it showed results for more recent architectures as well and answer this point.\n\n", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"CMT_id": "", "title": "Hardware-Oriented Approximation of Convolutional Neural Networks", "abstract": "High computational complexity hinders the widespread usage of Convolutional Neural Networks (CNNs), especially in mobile devices. Hardware accelerators are arguably the most promising approach for reducing both execution time and power consumption. One of the most important steps in accelerator development is hardware-oriented model approximation. In this paper we present Ristretto, a model approximation framework that analyzes a given CNN with respect to numerical resolution used in representing weights and outputs of convolutional and fully connected layers. Ristretto can condense models by using fixed point arithmetic and representation instead of floating point. Moreover, Ristretto fine-tunes the resulting fixed point network. Given a maximum error tolerance of 1%, Ristretto can successfully condense CaffeNet and SqueezeNet to 8-bit. The code for Ristretto is available.", "pdf": "http://arxiv.org/pdf/1604.03168v2.pdf", "paperhash": "gysel|hardwareoriented_approximation_of_convolutional_neural_networks", "conflicts": ["ece.ucdavis.edu"], "authors": ["Philipp Gysel", "Mohammad Motamedi", "Soheil Ghiasi"], "authorids": ["pmgysel@ucdavis.edu", "mmotamedi@ucdavis.edu", "ghiasi@ucdavis.edu"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "tmdate": null, "cdate": 1456580037724, "ddate": null, "super": null, "final": null, "duedate": 1460725200000, "tcdate": 1456580037724, "id": "ICLR.cc/2016/workshop/-/paper/136/review/11", "writers": ["ICLR.cc/2016/workshop"], "signatures": ["ICLR.cc/2016/workshop"], "reply": {"pdf": null, "forum": "81DnLL9OEI6O2Pl0UV1w", "replyto": "81DnLL9OEI6O2Pl0UV1w", "writers": {"values-regex": "(~.*)|ICLR.cc/2016/workshop/paper/[0-9]+/reviewer/[0-9]+)"}, "signatures": {"values-regex": "(~.*)|ICLR.cc/2016/workshop/paper/[0-9]+/reviewer/[0-9]+)", "description": "Your displayed identity associated with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "value-regex": "[\\S\\s]{1,5000}"}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "invitees": [], "nonreaders": [], "noninvitees": [], "readers": ["everyone", "ICLR.cc/2016/workshop/paper/136/reviewer/11", "ICLR.cc/2016/workshop"], "expdate": 1468501200000}}}, {"tddate": null, "number": null, "replyto": null, "ddate": null, "cdate": null, "tmdate": 1455826690392, "tcdate": 1455826690392, "id": "81DnLL9OEI6O2Pl0UV1w", "invitation": "ICLR.cc/2016/workshop/-/submission", "forum": "81DnLL9OEI6O2Pl0UV1w", "signatures": ["~Philipp_Matthias_Gysel1"], "readers": ["everyone"], "writers": ["~Philipp_Matthias_Gysel1"], "content": {"CMT_id": "", "title": "Hardware-Oriented Approximation of Convolutional Neural Networks", "abstract": "High computational complexity hinders the widespread usage of Convolutional Neural Networks (CNNs), especially in mobile devices. Hardware accelerators are arguably the most promising approach for reducing both execution time and power consumption. One of the most important steps in accelerator development is hardware-oriented model approximation. In this paper we present Ristretto, a model approximation framework that analyzes a given CNN with respect to numerical resolution used in representing weights and outputs of convolutional and fully connected layers. Ristretto can condense models by using fixed point arithmetic and representation instead of floating point. Moreover, Ristretto fine-tunes the resulting fixed point network. Given a maximum error tolerance of 1%, Ristretto can successfully condense CaffeNet and SqueezeNet to 8-bit. The code for Ristretto is available.", "pdf": "http://arxiv.org/pdf/1604.03168v2.pdf", "paperhash": "gysel|hardwareoriented_approximation_of_convolutional_neural_networks", "conflicts": ["ece.ucdavis.edu"], "authors": ["Philipp Gysel", "Mohammad Motamedi", "Soheil Ghiasi"], "authorids": ["pmgysel@ucdavis.edu", "mmotamedi@ucdavis.edu", "ghiasi@ucdavis.edu"]}, "nonreaders": [], "details": {"replyCount": 4, "writable": false, "overwriting": [], "revisions": false, "tags": [], "invitation": {"rdate": null, "tddate": null, "tmdate": null, "cdate": 1454464564200, "ddate": null, "super": null, "final": null, "duedate": 1455833700000, "tcdate": 1454464564200, "id": "ICLR.cc/2016/workshop/-/submission", "writers": ["ICLR.cc/2016/workshop"], "signatures": ["ICLR.cc/2016/workshop"], "readers": ["everyone"], "reply": {"pdf": null, "forum": null, "replyto": null, "writers": {"values-regex": "~.*"}, "signatures": {"values-regex": "~.*", "description": "Your displayed identity associated with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"pdf": {"order": 4, "description": "Either upload a PDF file or provide a direct link to your PDF on ArXiv.", "value-regex": "upload|http://arxiv.org/pdf/.+"}, "title": {"order": 3, "description": "Title of paper.", "value-regex": ".{0,500}"}, "abstract": {"order": 4, "description": "Abstract of paper.", "value-regex": "[\\S\\s]{1,5000}"}, "authors": {"order": 1, "description": "Comma separated list of author names, as they appear in the paper.", "value-regex": "[^,\\n]+(,[^,\\n]+)*"}, "author_emails": {"order": 2, "description": "Comma separated list of author email addresses, in the same order as above.", "value-regex": "[^,\\n]+(,[^,\\n]+)*"}, "conflicts": {"order": 100, "description": "Semi-colon separated list of email domains of people who would have a conflict of interest in reviewing this paper, (e.g., cs.umass.edu;google.com, etc.).", "value-regex": "^([a-zA-Z0-9][a-zA-Z0-9-_]{0,61}[a-zA-Z0-9]{0,1}\\.([a-zA-Z]{1,6}|[a-zA-Z0-9-]{1,30}\\.[a-zA-Z]{2,3}))+(;[a-zA-Z0-9][a-zA-Z0-9-_]{0,61}[a-zA-Z0-9]{0,1}\\.([a-zA-Z]{1,6}|[a-zA-Z0-9-]{1,30}\\.[a-zA-Z]{2,3}))*$"}, "CMT_id": {"order": 5, "value-regex": ".*", "description": "If the paper is a resubmission from the ICLR 2016 Conference Track, enter its CMT ID; otherwise, leave blank."}}}, "invitees": [], "nonreaders": [], "noninvitees": [], "expdate": 1463609700000}}}], "count": 5}