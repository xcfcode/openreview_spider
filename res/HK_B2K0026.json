{"notes": [{"id": "HK_B2K0026", "original": "g8U641FxlwW", "number": 3474, "cdate": 1601308385560, "ddate": null, "tcdate": 1601308385560, "tmdate": 1614985660678, "tddate": null, "forum": "HK_B2K0026", "replyto": null, "invitation": "ICLR.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Attention Based Joint Learning for Supervised Electrocardiogram Arrhythmia Differentiation with Unsupervised Abnormal Beat Segmentation", "authorids": ["~Xinrong_Hu1", "wl960201@163.com", "635386607@qq.com", "41421891@qq.com", "~Jian_Zhuang1", "~Yiyu_Shi1"], "authors": ["Xinrong Hu", "long wen", "shushui wang", "Dongpo Liang", "Jian Zhuang", "Yiyu Shi"], "keywords": ["interpretability", "multitask learning", "attention mechanism", "electrocardiography"], "abstract": "Deep learning has shown great promise in arrhythmia classification in electrocar- diogram (ECG). Existing works, when classifying an ECG segment with multiple beats, do not identify the locations of the anomalies, which reduces clinical inter- pretability. On the other hand, segmenting abnormal beats by deep learning usu- ally requires annotation for a large number of regular and irregular beats, which can be laborious, sometimes even challenging, with strong inter-observer variabil- ity between experts. In this work, we propose a method capable of not only dif- ferentiating arrhythmia but also segmenting the associated abnormal beats in the ECG segment. The only annotation used in the training is the type of abnormal beats and no segmentation labels are needed. Imitating human\u2019s perception of an ECG signal, the framework consists of a segmenter and classifier. The segmenter outputs an attention map, which aims to highlight the abnormal sections in the ECG by element-wise modulation. Afterwards, the signals are sent to a classifier for arrhythmia differentiation. Though the training data is only labeled to super- vise the classifier, the segmenter and the classifier are trained in an end-to-end manner so that optimizing classification performance also adjusts how the abnor- mal beats are segmented. Validation of our method is conducted on two dataset. We observe that involving the unsupervised segmentation in fact boosts the clas- sification performance. Meanwhile, a grade study performed by experts suggests that the segmenter also achieves satisfactory quality in identifying abnormal beats, which significantly enhances the interpretability of the classification results.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "hu|attention_based_joint_learning_for_supervised_electrocardiogram_arrhythmia_differentiation_with_unsupervised_abnormal_beat_segmentation", "one-sentence_summary": "This paper presents a joint learning framework for supervised arrhythmia differentiation with unsupervised abnormal heart beat seg mentation on ECG, where the two tasks can benefit from each other.  ", "pdf": "/pdf/609e06c71d4acfd8f207a05915c3578cd58404b2.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=HOFhU3Uy5x", "_bibtex": "@misc{\nhu2021attention,\ntitle={Attention Based Joint Learning for Supervised Electrocardiogram Arrhythmia Differentiation with Unsupervised Abnormal Beat Segmentation},\nauthor={Xinrong Hu and long wen and shushui wang and Dongpo Liang and Jian Zhuang and Yiyu Shi},\nyear={2021},\nurl={https://openreview.net/forum?id=HK_B2K0026}\n}"}, "signatures": ["ICLR.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference"], "details": {"replyCount": 9, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"reply": {"readers": {"values-regex": ".*"}, "writers": {"values": ["ICLR.cc/2021/Conference"]}, "signatures": {"values": ["ICLR.cc/2021/Conference"]}, "content": {"authors": {"values": ["Anonymous"]}, "authorids": {"values-regex": ".*"}, "reviewed_version_(pdf)": {"required": false, "description": "Upload a PDF file that ends with .pdf", "value-regex": ".*"}}}, "signatures": ["ICLR.cc/2021/Conference"], "readers": ["everyone"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["~", "OpenReview.net/Support"], "tcdate": 1601308008205, "tmdate": 1614984599368, "id": "ICLR.cc/2021/Conference/-/Blind_Submission"}}, "tauthor": "OpenReview.net"}, {"id": "f-eeKCdS88", "original": null, "number": 1, "cdate": 1610040501211, "ddate": null, "tcdate": 1610040501211, "tmdate": 1610474107966, "tddate": null, "forum": "HK_B2K0026", "replyto": "HK_B2K0026", "invitation": "ICLR.cc/2021/Conference/Paper3474/-/Decision", "content": {"title": "Final Decision", "decision": "Reject", "comment": "This paper received 4 reviews with mixed initial ratings: 5, 6, 4, 4. The main concerns of R1, R4 and R2, who gave unfavorable scores, included: insufficient evaluation (lack of experiments on public datasets, small sample size), an ad-hoc nature and overall limited novelty of the method, a number of issues with the presentation. In response to that, the authors submitted a new revision and provided detailed answers to each of the reviews separately. After having read the rebuttals, the reviewers (including R3, who initially gave a positive rating) felt that this work overall lacks methodological novelty and does not meet the bar for ICLR.\nAs a result, the final recommendation is to reject."}, "signatures": ["ICLR.cc/2021/Conference/Program_Chairs"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference/Program_Chairs"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Attention Based Joint Learning for Supervised Electrocardiogram Arrhythmia Differentiation with Unsupervised Abnormal Beat Segmentation", "authorids": ["~Xinrong_Hu1", "wl960201@163.com", "635386607@qq.com", "41421891@qq.com", "~Jian_Zhuang1", "~Yiyu_Shi1"], "authors": ["Xinrong Hu", "long wen", "shushui wang", "Dongpo Liang", "Jian Zhuang", "Yiyu Shi"], "keywords": ["interpretability", "multitask learning", "attention mechanism", "electrocardiography"], "abstract": "Deep learning has shown great promise in arrhythmia classification in electrocar- diogram (ECG). Existing works, when classifying an ECG segment with multiple beats, do not identify the locations of the anomalies, which reduces clinical inter- pretability. On the other hand, segmenting abnormal beats by deep learning usu- ally requires annotation for a large number of regular and irregular beats, which can be laborious, sometimes even challenging, with strong inter-observer variabil- ity between experts. In this work, we propose a method capable of not only dif- ferentiating arrhythmia but also segmenting the associated abnormal beats in the ECG segment. The only annotation used in the training is the type of abnormal beats and no segmentation labels are needed. Imitating human\u2019s perception of an ECG signal, the framework consists of a segmenter and classifier. The segmenter outputs an attention map, which aims to highlight the abnormal sections in the ECG by element-wise modulation. Afterwards, the signals are sent to a classifier for arrhythmia differentiation. Though the training data is only labeled to super- vise the classifier, the segmenter and the classifier are trained in an end-to-end manner so that optimizing classification performance also adjusts how the abnor- mal beats are segmented. Validation of our method is conducted on two dataset. We observe that involving the unsupervised segmentation in fact boosts the clas- sification performance. Meanwhile, a grade study performed by experts suggests that the segmenter also achieves satisfactory quality in identifying abnormal beats, which significantly enhances the interpretability of the classification results.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "hu|attention_based_joint_learning_for_supervised_electrocardiogram_arrhythmia_differentiation_with_unsupervised_abnormal_beat_segmentation", "one-sentence_summary": "This paper presents a joint learning framework for supervised arrhythmia differentiation with unsupervised abnormal heart beat seg mentation on ECG, where the two tasks can benefit from each other.  ", "pdf": "/pdf/609e06c71d4acfd8f207a05915c3578cd58404b2.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=HOFhU3Uy5x", "_bibtex": "@misc{\nhu2021attention,\ntitle={Attention Based Joint Learning for Supervised Electrocardiogram Arrhythmia Differentiation with Unsupervised Abnormal Beat Segmentation},\nauthor={Xinrong Hu and long wen and shushui wang and Dongpo Liang and Jian Zhuang and Yiyu Shi},\nyear={2021},\nurl={https://openreview.net/forum?id=HK_B2K0026}\n}"}, "tags": [], "invitation": {"reply": {"forum": "HK_B2K0026", "replyto": "HK_B2K0026", "readers": {"values": ["everyone"]}, "writers": {"values": ["ICLR.cc/2021/Conference/Program_Chairs"]}, "signatures": {"values": ["ICLR.cc/2021/Conference/Program_Chairs"]}, "content": {"title": {"value": "Final Decision"}, "decision": {"value-radio": ["Accept (Oral)", "Accept (Spotlight)", "Accept (Poster)", "Reject"]}, "comment": {"value-regex": "[\\S\\s]{0,50000}", "markdown": true}}}, "multiReply": false, "signatures": ["ICLR.cc/2021/Conference"], "readers": ["everyone"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Program_Chairs"], "tcdate": 1610040501199, "tmdate": 1610474107951, "id": "ICLR.cc/2021/Conference/Paper3474/-/Decision"}}}, {"id": "nsYbfQVfIwZ", "original": null, "number": 2, "cdate": 1603897577921, "ddate": null, "tcdate": 1603897577921, "tmdate": 1606576137681, "tddate": null, "forum": "HK_B2K0026", "replyto": "HK_B2K0026", "invitation": "ICLR.cc/2021/Conference/Paper3474/-/Official_Review", "content": {"title": "This paper presents an semi-supervised approach for ECG segmentation and PVC classification. The application is well motivated. I have some concerns about the experimental evaluation and novelty described below.  I think it has the makings of a promising paper but would like to see responses to these questions.", "review": "This paper presents a method for segmentation and classification of ECG data applied to the task to segmenting and detecting Premature Ventricular Contractions (PVC). The taks is semi-supervised, in the sense that segmentation labels are not required by labels for the PVC events (classification) are used.\nThe authors motivate this application quite well and detecting abnormalities in ECG signals is an important task of clinical relevance.  I can understand why segmentation labels may be very laborious to collect and unsupervised methods would be desirable.\n\nThe proposed approach builds upon U-Net and introduces some task specific changes.  However, I would argue that this is primarily an application paper. I don't mean that as a criticism necessarily, I think that strong and well motivated applications of machine learning are important and informative. However, it would be helpful if the authors could discuss more about how their approach might generalize to other tasks, both the detection of other types of arrythmias and other temporal segmentation and classification tasks.  \n\nMy main comments regarding the paper are around the experimental evalutation.  The authors highlight that there are some published baselines for this task or at least similar related works (e.g., Moskalenko et al. (2019); Oh et al. (2019)) and/or the authors could have applied classification on top of features extracted using Pan-Tompkins - but that would be a more crude baseline.  While I recognize that these approaches might not enable unsuperivsed segmentation and so direct comparisons on that might be hard with the full approach they propose.  It might be possible to present a comparison of classification metrics on their own. Perhaps I am misunderstanding but it doesn't seem as though Table 1 includes such a comparison, rather the baselines are different from the previous published methods - is that correct?  I would almost describe Table 1 as ablation results rather than a comparison with other published baselines. I'd like to know the author's response to that and if Table 1 does show these results perhaps linking the rows to the previous approaches might be helpful?  Or justifying why it isn't appropriate to show these comparisons. I don't say this just because the authors should show better numbers, but rather to ground the chose baselines in the context of previous work in this space.\n\nBuilding from the previous point. I think this paper would be an excellent case for for showing transfer learning results, it seems to me that PhysioNet provides a large amount of available data for ECG classification.  A couple of question I'd like to hear the authors responses to:\n1) Why did they not do any experiments on these public datasets?  Is there a reason they are not appropriate?  Do they not have the right labels, are they not large enough, do you need full 12 lead recordings (I am not sure if they are avaiable on PhysioNet datasets - but I imagine so.)\n2) Even if training your method on your dataset is preferable, it would seem natural to test it on a set from PhysioNet, perhaps even with a different type of arrythmia, to see how much performance degrades? This I think would be most informative, both showing segmentation and classification results.\n\nFig. 3 is a nice illustration, but it is quite difficult to read.  I might suggest reorganizing it.  I am not sure showing multiple leads is necessary and maybe limiting to two columns might help.  I'd encourage the authors to leverage supplementary material to show more examples as I do think these help.  \n\nFinally, physiological signals are notorious for having large individual variation.  I'd be interested to have the authors discuss more about this. I couldn't find the information about how the train/val/test splits were organized and whether this was person independent etc.  The following sentence in Section 4.2 \"We apply five-fold cross-validation with different classes evenly distributed between folds, and the average performance is reported\" doesn't seem to mention that.  Knowing more about the splits would be very helpful.  This is perhaps another reason that performing experiments on at least one PhysioNet dataset would be helpful as the train, val, test splits could be released.  But I acknowledge that the authors say they will release their data which is good.", "rating": "5: Marginally below acceptance threshold", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["ICLR.cc/2021/Conference/Paper3474/AnonReviewer4"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper3474/AnonReviewer4"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Attention Based Joint Learning for Supervised Electrocardiogram Arrhythmia Differentiation with Unsupervised Abnormal Beat Segmentation", "authorids": ["~Xinrong_Hu1", "wl960201@163.com", "635386607@qq.com", "41421891@qq.com", "~Jian_Zhuang1", "~Yiyu_Shi1"], "authors": ["Xinrong Hu", "long wen", "shushui wang", "Dongpo Liang", "Jian Zhuang", "Yiyu Shi"], "keywords": ["interpretability", "multitask learning", "attention mechanism", "electrocardiography"], "abstract": "Deep learning has shown great promise in arrhythmia classification in electrocar- diogram (ECG). Existing works, when classifying an ECG segment with multiple beats, do not identify the locations of the anomalies, which reduces clinical inter- pretability. On the other hand, segmenting abnormal beats by deep learning usu- ally requires annotation for a large number of regular and irregular beats, which can be laborious, sometimes even challenging, with strong inter-observer variabil- ity between experts. In this work, we propose a method capable of not only dif- ferentiating arrhythmia but also segmenting the associated abnormal beats in the ECG segment. The only annotation used in the training is the type of abnormal beats and no segmentation labels are needed. Imitating human\u2019s perception of an ECG signal, the framework consists of a segmenter and classifier. The segmenter outputs an attention map, which aims to highlight the abnormal sections in the ECG by element-wise modulation. Afterwards, the signals are sent to a classifier for arrhythmia differentiation. Though the training data is only labeled to super- vise the classifier, the segmenter and the classifier are trained in an end-to-end manner so that optimizing classification performance also adjusts how the abnor- mal beats are segmented. Validation of our method is conducted on two dataset. We observe that involving the unsupervised segmentation in fact boosts the clas- sification performance. Meanwhile, a grade study performed by experts suggests that the segmenter also achieves satisfactory quality in identifying abnormal beats, which significantly enhances the interpretability of the classification results.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "hu|attention_based_joint_learning_for_supervised_electrocardiogram_arrhythmia_differentiation_with_unsupervised_abnormal_beat_segmentation", "one-sentence_summary": "This paper presents a joint learning framework for supervised arrhythmia differentiation with unsupervised abnormal heart beat seg mentation on ECG, where the two tasks can benefit from each other.  ", "pdf": "/pdf/609e06c71d4acfd8f207a05915c3578cd58404b2.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=HOFhU3Uy5x", "_bibtex": "@misc{\nhu2021attention,\ntitle={Attention Based Joint Learning for Supervised Electrocardiogram Arrhythmia Differentiation with Unsupervised Abnormal Beat Segmentation},\nauthor={Xinrong Hu and long wen and shushui wang and Dongpo Liang and Jian Zhuang and Yiyu Shi},\nyear={2021},\nurl={https://openreview.net/forum?id=HK_B2K0026}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq . ***Please remember to file the Code-of-Ethics report. Once you submitted the review, a link to the report will be visible in the bottom right corner of your review.***", "required": true, "markdown": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}, "forum": "HK_B2K0026", "replyto": "HK_B2K0026", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"], "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper3474/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1607428800000, "duedate": 1606752000000, "multiReply": false, "readers": ["everyone"], "tcdate": 1602538075164, "tmdate": 1606915800458, "super": "ICLR.cc/2021/Conference/-/Official_Review", "signatures": ["OpenReview.net"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Paper3474/Reviewers", "OpenReview.net/Support"], "id": "ICLR.cc/2021/Conference/Paper3474/-/Official_Review"}}}, {"id": "1eQcpQx2mI", "original": null, "number": 5, "cdate": 1605542135390, "ddate": null, "tcdate": 1605542135390, "tmdate": 1605542135390, "tddate": null, "forum": "HK_B2K0026", "replyto": "lTXSA9uRWAe", "invitation": "ICLR.cc/2021/Conference/Paper3474/-/Official_Comment", "content": {"title": "Response to some comments and questions", "comment": "1, Regarding the comment \u201cThe topic seems too narrow for the computer science community.\u201d \n\nWe add extra experiment on other public ECG dataset to demonstrate the generalization of our methods on ECG classification problem. The accuracy and AUC-ROC increases by 0.006 and 0.002 respectively with a segmenter added to the classifier. Meanwhile, we also observe a promising segmentation result.  \n\n2, Regarding the comment \u201cBut (image) segmentation works are also worth (or even more) investigating.\u201d \n\nIt\u2019s worth noticing that our work focus on unsupervised segmentation. It\u2019s true that the modification of image segmentation models can fit in ECG segmentation, and this is actually how some works concerning ECG segmentation do.  However, they all need annotations, as we mentioned in paragraph 2 in section 1, while in our work we focus on unsupervised segmentation. We notice that there are emerging works concerning unsupervised image segmentation methods very recently. Yet due to the very different nature between nature images and ECG signals, these unsupervised methods can hardly be directly applied to ECG segmentation. \n\n3, Response to the concern about the evaluation of segmentation \n\nFor evaluation of segmentation results, the example we gave in Fig 4 is the illustration of the three classes in the grade study. Actually, we asked independent expert cardiologists to do blind grade study on the segmentation result (100 ECG segments) and the result is shown in Fig 5. We think it would be too much work for a conference paper to conduct multi-site study (and it is very rare too).  \n\n4, More details about data preprocessing \n\nFor data prepcocessing, we use butter filter to build a low-pass filter with threshold frequency of 60. What\u2019s more, we apply a low pass FIR filter to remove the baseline drift and the cutoff frequency is 4. \n\n5, Response to \u201cIn figure 3, are there duplicate attention maps in every column?\u201d \n\nYes, there are. We enforce the output of U-Net to have only one channel and duplicate it into 12 copies so that the attention maps for 12 leads are exactly the same. This is because the arrhythmia occurs synchronously for the 12 leads. "}, "signatures": ["ICLR.cc/2021/Conference/Paper3474/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper3474/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Attention Based Joint Learning for Supervised Electrocardiogram Arrhythmia Differentiation with Unsupervised Abnormal Beat Segmentation", "authorids": ["~Xinrong_Hu1", "wl960201@163.com", "635386607@qq.com", "41421891@qq.com", "~Jian_Zhuang1", "~Yiyu_Shi1"], "authors": ["Xinrong Hu", "long wen", "shushui wang", "Dongpo Liang", "Jian Zhuang", "Yiyu Shi"], "keywords": ["interpretability", "multitask learning", "attention mechanism", "electrocardiography"], "abstract": "Deep learning has shown great promise in arrhythmia classification in electrocar- diogram (ECG). Existing works, when classifying an ECG segment with multiple beats, do not identify the locations of the anomalies, which reduces clinical inter- pretability. On the other hand, segmenting abnormal beats by deep learning usu- ally requires annotation for a large number of regular and irregular beats, which can be laborious, sometimes even challenging, with strong inter-observer variabil- ity between experts. In this work, we propose a method capable of not only dif- ferentiating arrhythmia but also segmenting the associated abnormal beats in the ECG segment. The only annotation used in the training is the type of abnormal beats and no segmentation labels are needed. Imitating human\u2019s perception of an ECG signal, the framework consists of a segmenter and classifier. The segmenter outputs an attention map, which aims to highlight the abnormal sections in the ECG by element-wise modulation. Afterwards, the signals are sent to a classifier for arrhythmia differentiation. Though the training data is only labeled to super- vise the classifier, the segmenter and the classifier are trained in an end-to-end manner so that optimizing classification performance also adjusts how the abnor- mal beats are segmented. Validation of our method is conducted on two dataset. We observe that involving the unsupervised segmentation in fact boosts the clas- sification performance. Meanwhile, a grade study performed by experts suggests that the segmenter also achieves satisfactory quality in identifying abnormal beats, which significantly enhances the interpretability of the classification results.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "hu|attention_based_joint_learning_for_supervised_electrocardiogram_arrhythmia_differentiation_with_unsupervised_abnormal_beat_segmentation", "one-sentence_summary": "This paper presents a joint learning framework for supervised arrhythmia differentiation with unsupervised abnormal heart beat seg mentation on ECG, where the two tasks can benefit from each other.  ", "pdf": "/pdf/609e06c71d4acfd8f207a05915c3578cd58404b2.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=HOFhU3Uy5x", "_bibtex": "@misc{\nhu2021attention,\ntitle={Attention Based Joint Learning for Supervised Electrocardiogram Arrhythmia Differentiation with Unsupervised Abnormal Beat Segmentation},\nauthor={Xinrong Hu and long wen and shushui wang and Dongpo Liang and Jian Zhuang and Yiyu Shi},\nyear={2021},\nurl={https://openreview.net/forum?id=HK_B2K0026}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "HK_B2K0026", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper3474/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper3474/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper3474/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper3474/Authors|ICLR.cc/2021/Conference/Paper3474/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper3474/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923837161, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper3474/-/Official_Comment"}}}, {"id": "z6E0ts5WSbB", "original": null, "number": 4, "cdate": 1605541989505, "ddate": null, "tcdate": 1605541989505, "tmdate": 1605541989505, "tddate": null, "forum": "HK_B2K0026", "replyto": "nsYbfQVfIwZ", "invitation": "ICLR.cc/2021/Conference/Paper3474/-/Official_Comment", "content": {"title": "Response to some comments and questions", "comment": "1, Response to the concern about the experimental evaluation \n\nActually, Moskalenko et al. (2019); Oh et al. (2019) deals with ECG segmentation problem and the Pan-Tompkins algorithm is used for finding QRS complexity\u2019s position in an ECG signal, and none of them can be used for ECG classification. Table 1 lists the comparison of classification results of different methods, which are more related to the works mentioned in the first paragraph of section 1. The commonly used models for ECG classification include CNN and CRNN. Different works make problem-specific modification to CNN or CRNN for the target problem/dataset and there does not exist a state-of-the-art approach for the PVC differentiation problem. The \u201cclassifier only\u201d in Table 1 stands for the CNN baseline similar to the state-of-the-art in many other ECG classification problems, while we get poor classification performance with CRNN so that we didn\u2019t present it. Note that Hong et al., (2019) actually uses a similar baseline for comparison without referring to a specific previous work. \n\n2, Response to the two questions about PhysioNet \n\nRegarding PhysioNet, we did run experiments on a dataset derived from public MIT-BIH dataset to classify ECG segments with atrial premature beat (APB) and ones with premature ventricular contraction (PVC). For this task, the baseline method only using CNN models achieves almost 99% accuracy, so the necessity for adding a segmenter is minor. Still, we do observe improvement of classification performance with our methods and a promising segmentation result. We will add it to the new version of our paper. On the other hand, the problem of differentiating subclass of PVC is more challenging with low classification accuracy, so there is a large room for improvement.  As for transfer learning, each ECG classification problem is quite unique in terms of features and PVC differentiation is among the most difficult ones. Therefore transfer learning does not work well.  \n \n3, Regarding how the train/val/test splits are organized \nIt\u2019s a good point to mention physiological signals\u2019 large individual variation. Actually, for each patient, there are at most three segments and in many cases one patient has only one segment. When doing k-fold validation, we split patients not segments into k folds. "}, "signatures": ["ICLR.cc/2021/Conference/Paper3474/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper3474/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Attention Based Joint Learning for Supervised Electrocardiogram Arrhythmia Differentiation with Unsupervised Abnormal Beat Segmentation", "authorids": ["~Xinrong_Hu1", "wl960201@163.com", "635386607@qq.com", "41421891@qq.com", "~Jian_Zhuang1", "~Yiyu_Shi1"], "authors": ["Xinrong Hu", "long wen", "shushui wang", "Dongpo Liang", "Jian Zhuang", "Yiyu Shi"], "keywords": ["interpretability", "multitask learning", "attention mechanism", "electrocardiography"], "abstract": "Deep learning has shown great promise in arrhythmia classification in electrocar- diogram (ECG). Existing works, when classifying an ECG segment with multiple beats, do not identify the locations of the anomalies, which reduces clinical inter- pretability. On the other hand, segmenting abnormal beats by deep learning usu- ally requires annotation for a large number of regular and irregular beats, which can be laborious, sometimes even challenging, with strong inter-observer variabil- ity between experts. In this work, we propose a method capable of not only dif- ferentiating arrhythmia but also segmenting the associated abnormal beats in the ECG segment. The only annotation used in the training is the type of abnormal beats and no segmentation labels are needed. Imitating human\u2019s perception of an ECG signal, the framework consists of a segmenter and classifier. The segmenter outputs an attention map, which aims to highlight the abnormal sections in the ECG by element-wise modulation. Afterwards, the signals are sent to a classifier for arrhythmia differentiation. Though the training data is only labeled to super- vise the classifier, the segmenter and the classifier are trained in an end-to-end manner so that optimizing classification performance also adjusts how the abnor- mal beats are segmented. Validation of our method is conducted on two dataset. We observe that involving the unsupervised segmentation in fact boosts the clas- sification performance. Meanwhile, a grade study performed by experts suggests that the segmenter also achieves satisfactory quality in identifying abnormal beats, which significantly enhances the interpretability of the classification results.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "hu|attention_based_joint_learning_for_supervised_electrocardiogram_arrhythmia_differentiation_with_unsupervised_abnormal_beat_segmentation", "one-sentence_summary": "This paper presents a joint learning framework for supervised arrhythmia differentiation with unsupervised abnormal heart beat seg mentation on ECG, where the two tasks can benefit from each other.  ", "pdf": "/pdf/609e06c71d4acfd8f207a05915c3578cd58404b2.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=HOFhU3Uy5x", "_bibtex": "@misc{\nhu2021attention,\ntitle={Attention Based Joint Learning for Supervised Electrocardiogram Arrhythmia Differentiation with Unsupervised Abnormal Beat Segmentation},\nauthor={Xinrong Hu and long wen and shushui wang and Dongpo Liang and Jian Zhuang and Yiyu Shi},\nyear={2021},\nurl={https://openreview.net/forum?id=HK_B2K0026}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "HK_B2K0026", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper3474/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper3474/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper3474/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper3474/Authors|ICLR.cc/2021/Conference/Paper3474/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper3474/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923837161, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper3474/-/Official_Comment"}}}, {"id": "16zUzUM8Ig", "original": null, "number": 3, "cdate": 1605541837354, "ddate": null, "tcdate": 1605541837354, "tmdate": 1605541935029, "tddate": null, "forum": "HK_B2K0026", "replyto": "rFHOnxFFtzA", "invitation": "ICLR.cc/2021/Conference/Paper3474/-/Official_Comment", "content": {"title": "Response to some comments and questions", "comment": "Thank you for your advices, we will edit our paper trying to make our writing more understandable. \n\n1, Regarding the comment \u201cthe proposed approach seems rather ad-hoc\" \n\nI agree that combining segmentation and classification is not a novel invention. However, our contribution is a new way of unsupervised learning through the assistance of supervised learning on a related but different task. By combining unsupervised segmentation and supervised classification in the form of attention maps directly on input images, which provides some explainability to the classification task.  \n\n2, Regarding the comment \u201cthere is no systematic evaluation how the method compares to other state-of-the-art ECG classification methods\u201d \n\nAs for comparison to other state-of-the-art ECG classification methods, when focusing on classifying a segment of ECG segment, there are two types of widely used methods, which are CNN and CRNN (combination of CNN and RNN). In Table 1, the \u201cclassifier only\u201d represents the CNN baseline. We also tried CRNN method but the accuracy is only around 70% due to the challenging nature of the PVC differentiation problem as explained in Section 1. Hence we chose not to present the result. \n\nResponse to detailed comments: \n\ni. What is the output of the classifier? Is this a binary label? Or a multi-class label? \n\nThe labels are binary. Please kindly refer to Section 5.1, where we have made it clear \u201cWe evaluate the performance of all methods on two tasks: differentiating PVC originating in LV and RV, as well as PVC originating in LVOT and RVOT\u201d. \n\nii. \u201c\u2026 the output of S has only 1 channel and we expand it channel-wise so that it matches the channel dimension of the ECG signal \u2026\u201d \u2013 What exactly is meant here? In Fig 1 it seems that the segmentation output has naturally 12 channels? Should the segmentation be identical for all channels? \n\nThe segmentation result should be identical for all channels since the abnormality occurs at the same time for all 12 leads. To enforce that, we set the output of the segmenter to have only one channel and duplicate it 12 times, which is called \u201cexpand\u201d in the paper. After that, we apply a pooling layer. In Fig 1, the after-pooling attention map is not the output of segmenter s. We should make it clear in Fig-1 that the segmenter should not contain the two-step postprocessing afterwards. \n\niii. \u201cWe do not use the output of the segmenter L as the attention map directly but instead perform a pooling with large kernel size first\u201d \u2013 Why is this done? What does \u201clarge kernel\u201d mean? \n\nWe explain it shortly afterwards \u201cout of consideration for both interpretability and performance\u201d. We would like to generate a window-like attention map so that the abnormality area is uniformly highlighted in contrast to normal beats. Besides, if the attention weight varies in the \u201cwindow\u201d, the shape of abnormal beats would be distorted. As for \u201clarge kernel\u201d, traditional 3*3, 5*5 max pooling layers\u2019 kernel size is 3 and 5. Global max pooling\u2019s kernel size is the shape of input signal. In our case, the kernel size is almost half of the beat length (e.g. 200). Compared to traditional 3*3 max pooling, our pooling has pretty \u201clarge\u201d kernel. \n\niv. Where is the attention map in Fig. 1? \n\nThe attention map is marked by the orange line segment, the input to the Hadmard production. \n\nv. How are the Premature Ventricular Contraction (PVC) origin labels defined? Is that a single time point (per channel or common for all channels) or a time window? \n\nThe PVC origin label is segment-wise, which means for each segment (12-leads) there is only one label denoting whether there are LV or RV (LVOT or RVOT) beats. "}, "signatures": ["ICLR.cc/2021/Conference/Paper3474/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper3474/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Attention Based Joint Learning for Supervised Electrocardiogram Arrhythmia Differentiation with Unsupervised Abnormal Beat Segmentation", "authorids": ["~Xinrong_Hu1", "wl960201@163.com", "635386607@qq.com", "41421891@qq.com", "~Jian_Zhuang1", "~Yiyu_Shi1"], "authors": ["Xinrong Hu", "long wen", "shushui wang", "Dongpo Liang", "Jian Zhuang", "Yiyu Shi"], "keywords": ["interpretability", "multitask learning", "attention mechanism", "electrocardiography"], "abstract": "Deep learning has shown great promise in arrhythmia classification in electrocar- diogram (ECG). Existing works, when classifying an ECG segment with multiple beats, do not identify the locations of the anomalies, which reduces clinical inter- pretability. On the other hand, segmenting abnormal beats by deep learning usu- ally requires annotation for a large number of regular and irregular beats, which can be laborious, sometimes even challenging, with strong inter-observer variabil- ity between experts. In this work, we propose a method capable of not only dif- ferentiating arrhythmia but also segmenting the associated abnormal beats in the ECG segment. The only annotation used in the training is the type of abnormal beats and no segmentation labels are needed. Imitating human\u2019s perception of an ECG signal, the framework consists of a segmenter and classifier. The segmenter outputs an attention map, which aims to highlight the abnormal sections in the ECG by element-wise modulation. Afterwards, the signals are sent to a classifier for arrhythmia differentiation. Though the training data is only labeled to super- vise the classifier, the segmenter and the classifier are trained in an end-to-end manner so that optimizing classification performance also adjusts how the abnor- mal beats are segmented. Validation of our method is conducted on two dataset. We observe that involving the unsupervised segmentation in fact boosts the clas- sification performance. Meanwhile, a grade study performed by experts suggests that the segmenter also achieves satisfactory quality in identifying abnormal beats, which significantly enhances the interpretability of the classification results.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "hu|attention_based_joint_learning_for_supervised_electrocardiogram_arrhythmia_differentiation_with_unsupervised_abnormal_beat_segmentation", "one-sentence_summary": "This paper presents a joint learning framework for supervised arrhythmia differentiation with unsupervised abnormal heart beat seg mentation on ECG, where the two tasks can benefit from each other.  ", "pdf": "/pdf/609e06c71d4acfd8f207a05915c3578cd58404b2.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=HOFhU3Uy5x", "_bibtex": "@misc{\nhu2021attention,\ntitle={Attention Based Joint Learning for Supervised Electrocardiogram Arrhythmia Differentiation with Unsupervised Abnormal Beat Segmentation},\nauthor={Xinrong Hu and long wen and shushui wang and Dongpo Liang and Jian Zhuang and Yiyu Shi},\nyear={2021},\nurl={https://openreview.net/forum?id=HK_B2K0026}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "HK_B2K0026", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper3474/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper3474/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper3474/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper3474/Authors|ICLR.cc/2021/Conference/Paper3474/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper3474/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923837161, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper3474/-/Official_Comment"}}}, {"id": "QzGcQ-thdL", "original": null, "number": 2, "cdate": 1605541740661, "ddate": null, "tcdate": 1605541740661, "tmdate": 1605541894348, "tddate": null, "forum": "HK_B2K0026", "replyto": "7AM3ttMwsxI", "invitation": "ICLR.cc/2021/Conference/Paper3474/-/Official_Comment", "content": {"title": "Response to some comments and questions", "comment": "1, Regarding the comment \u201cThe work is light on theory and the contribution mostly resides on the empirical improvement\u201d \n\nOur work\u2019s contribution in theory is providing a new way of unsupervised learning through the assistance of supervised learning on a related but different task. In this particular problem, it is done by backpropagating the supervised classification loss to the unsupervised segmenter. Besides, we propose an explicit attention approach directly on the input signal, different from those in the literature which apply attention on intermediate features, for better explainability of the results. We further discuss why pooling is important for the attention map.  \n\n2, Regarding the comment \u201cthe evidence for this improvement is not rock solid, as it is shown on a single dataset, which has a rather small sample size\u201d \n\nFor more generalized conclusion, we have added the comparison results between our method and the baseline on a public dataset MIT-BIH to the new vision of our paper in section 4. The accuracy and AUC-ROC increases by 0.007 and 0.005 respectively with a segmenter added to the classifier. The dataset has total samples of almost 3000 and the baseline already reaches 0.98 (accuracy) and0.99 (AUC-ROC), so we think the improvement is acceptable. Meanwhile, we also observe a promising segmentation result. \n\n3, Response to the question about hyperparameter selection \n\nIn terms of hyperparameters, both learning rate and architecture parameters are fixed independent of the dataset (we used the same setting in the new experiment on the public dataset). The kernel size linearly depends on the sample frequency of the dataset, which is natural. For different datasets, we can normalize the sampling frequency to use the same kernel size, as has been shown in the newly added experiments on the public dataset.  \n\n4, Response to the \"not really significant improvement\u201d \n\nLastly, thanks for providing a new perspective on evaluating the solidity of our result. Actually, when n=500 and assume the true accuracy is 90%, the confidence interval with 95% confidence is +/- 2.62%. I can understand your concern that the margin between the accuracy of our method and baseline is smaller than the 95% confidence interval. However, the hypothesis behind this calculation is that test results for different samples are independent, which is not true in our case. This could lead to smaller deviation. Besides, it\u2019s hard to attain 5% accuracy increase anyway when the baseline accuracy already reaches 90%. On the other hand, this confidence interval theory only applies to accuracy not for specificity, sensitivity, and AUC-ROC. Therefore, by showing the comparison of these metrics, we can also conclude performance improvement with our method. "}, "signatures": ["ICLR.cc/2021/Conference/Paper3474/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper3474/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Attention Based Joint Learning for Supervised Electrocardiogram Arrhythmia Differentiation with Unsupervised Abnormal Beat Segmentation", "authorids": ["~Xinrong_Hu1", "wl960201@163.com", "635386607@qq.com", "41421891@qq.com", "~Jian_Zhuang1", "~Yiyu_Shi1"], "authors": ["Xinrong Hu", "long wen", "shushui wang", "Dongpo Liang", "Jian Zhuang", "Yiyu Shi"], "keywords": ["interpretability", "multitask learning", "attention mechanism", "electrocardiography"], "abstract": "Deep learning has shown great promise in arrhythmia classification in electrocar- diogram (ECG). Existing works, when classifying an ECG segment with multiple beats, do not identify the locations of the anomalies, which reduces clinical inter- pretability. On the other hand, segmenting abnormal beats by deep learning usu- ally requires annotation for a large number of regular and irregular beats, which can be laborious, sometimes even challenging, with strong inter-observer variabil- ity between experts. In this work, we propose a method capable of not only dif- ferentiating arrhythmia but also segmenting the associated abnormal beats in the ECG segment. The only annotation used in the training is the type of abnormal beats and no segmentation labels are needed. Imitating human\u2019s perception of an ECG signal, the framework consists of a segmenter and classifier. The segmenter outputs an attention map, which aims to highlight the abnormal sections in the ECG by element-wise modulation. Afterwards, the signals are sent to a classifier for arrhythmia differentiation. Though the training data is only labeled to super- vise the classifier, the segmenter and the classifier are trained in an end-to-end manner so that optimizing classification performance also adjusts how the abnor- mal beats are segmented. Validation of our method is conducted on two dataset. We observe that involving the unsupervised segmentation in fact boosts the clas- sification performance. Meanwhile, a grade study performed by experts suggests that the segmenter also achieves satisfactory quality in identifying abnormal beats, which significantly enhances the interpretability of the classification results.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "hu|attention_based_joint_learning_for_supervised_electrocardiogram_arrhythmia_differentiation_with_unsupervised_abnormal_beat_segmentation", "one-sentence_summary": "This paper presents a joint learning framework for supervised arrhythmia differentiation with unsupervised abnormal heart beat seg mentation on ECG, where the two tasks can benefit from each other.  ", "pdf": "/pdf/609e06c71d4acfd8f207a05915c3578cd58404b2.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=HOFhU3Uy5x", "_bibtex": "@misc{\nhu2021attention,\ntitle={Attention Based Joint Learning for Supervised Electrocardiogram Arrhythmia Differentiation with Unsupervised Abnormal Beat Segmentation},\nauthor={Xinrong Hu and long wen and shushui wang and Dongpo Liang and Jian Zhuang and Yiyu Shi},\nyear={2021},\nurl={https://openreview.net/forum?id=HK_B2K0026}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "HK_B2K0026", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper3474/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper3474/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper3474/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper3474/Authors|ICLR.cc/2021/Conference/Paper3474/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper3474/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923837161, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper3474/-/Official_Comment"}}}, {"id": "lTXSA9uRWAe", "original": null, "number": 1, "cdate": 1603701363627, "ddate": null, "tcdate": 1603701363627, "tmdate": 1605023994058, "tddate": null, "forum": "HK_B2K0026", "replyto": "HK_B2K0026", "invitation": "ICLR.cc/2021/Conference/Paper3474/-/Official_Review", "content": {"title": "Interesting paper, but the topic is too narrow; related image segmentation works needed", "review": "This paper proposes a deep neural network for Premature Ventricular Contraction (PVC) differentiation and segmentation from electrocardiogram (ECG) signals. The network is jointly trained as a segmenter and a classifier with a multitask learning manner. Differentiation is achieved by the classifier, and segmentation is achieved by pooling for window-style attention from segmenter\u2019s output. Quantitative experiments show better performance than baselines on differentiation tasks. Qualitative experiments show the effectiveness of segmentation tasks. \n\nThe results look interesting, and it might have a broader impact on practical usage for AI models in the clinical environment. However, my concerns are: \n\n1) The topic seems too narrow for the computer science community. More likely a paper of the biomedical engineering community or computing cardiology community. The proposed method also lacks in-depth technical/theoretical analysis; thus the paper novelty is limited. \n\n2) The related works include multitask learning and attention mechanisms. But (image) segmentation works are also worth (or even more) investigating. Just a simple modification of image segmentation neural networks (such as Conv2D -> Conv1D) can make them suitable for ECG segmentation tasks. \n\n3) For the evaluation of segmentation, only several cases of qualitative evaluations are not convincing. At least, a comprehensive user study by a community of cardiologists is needed. \n\nSome questions:\n\n- Could you provide more details about data preprocessing? Which filters do you use? What are the cut-off frequencies for high-pass filter and low-pass filter? \n\n- In figure 3, are there duplicate attention maps in every column?\n", "rating": "4: Ok but not good enough - rejection", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["ICLR.cc/2021/Conference/Paper3474/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper3474/AnonReviewer2"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Attention Based Joint Learning for Supervised Electrocardiogram Arrhythmia Differentiation with Unsupervised Abnormal Beat Segmentation", "authorids": ["~Xinrong_Hu1", "wl960201@163.com", "635386607@qq.com", "41421891@qq.com", "~Jian_Zhuang1", "~Yiyu_Shi1"], "authors": ["Xinrong Hu", "long wen", "shushui wang", "Dongpo Liang", "Jian Zhuang", "Yiyu Shi"], "keywords": ["interpretability", "multitask learning", "attention mechanism", "electrocardiography"], "abstract": "Deep learning has shown great promise in arrhythmia classification in electrocar- diogram (ECG). Existing works, when classifying an ECG segment with multiple beats, do not identify the locations of the anomalies, which reduces clinical inter- pretability. On the other hand, segmenting abnormal beats by deep learning usu- ally requires annotation for a large number of regular and irregular beats, which can be laborious, sometimes even challenging, with strong inter-observer variabil- ity between experts. In this work, we propose a method capable of not only dif- ferentiating arrhythmia but also segmenting the associated abnormal beats in the ECG segment. The only annotation used in the training is the type of abnormal beats and no segmentation labels are needed. Imitating human\u2019s perception of an ECG signal, the framework consists of a segmenter and classifier. The segmenter outputs an attention map, which aims to highlight the abnormal sections in the ECG by element-wise modulation. Afterwards, the signals are sent to a classifier for arrhythmia differentiation. Though the training data is only labeled to super- vise the classifier, the segmenter and the classifier are trained in an end-to-end manner so that optimizing classification performance also adjusts how the abnor- mal beats are segmented. Validation of our method is conducted on two dataset. We observe that involving the unsupervised segmentation in fact boosts the clas- sification performance. Meanwhile, a grade study performed by experts suggests that the segmenter also achieves satisfactory quality in identifying abnormal beats, which significantly enhances the interpretability of the classification results.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "hu|attention_based_joint_learning_for_supervised_electrocardiogram_arrhythmia_differentiation_with_unsupervised_abnormal_beat_segmentation", "one-sentence_summary": "This paper presents a joint learning framework for supervised arrhythmia differentiation with unsupervised abnormal heart beat seg mentation on ECG, where the two tasks can benefit from each other.  ", "pdf": "/pdf/609e06c71d4acfd8f207a05915c3578cd58404b2.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=HOFhU3Uy5x", "_bibtex": "@misc{\nhu2021attention,\ntitle={Attention Based Joint Learning for Supervised Electrocardiogram Arrhythmia Differentiation with Unsupervised Abnormal Beat Segmentation},\nauthor={Xinrong Hu and long wen and shushui wang and Dongpo Liang and Jian Zhuang and Yiyu Shi},\nyear={2021},\nurl={https://openreview.net/forum?id=HK_B2K0026}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq . ***Please remember to file the Code-of-Ethics report. Once you submitted the review, a link to the report will be visible in the bottom right corner of your review.***", "required": true, "markdown": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}, "forum": "HK_B2K0026", "replyto": "HK_B2K0026", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"], "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper3474/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1607428800000, "duedate": 1606752000000, "multiReply": false, "readers": ["everyone"], "tcdate": 1602538075164, "tmdate": 1606915800458, "super": "ICLR.cc/2021/Conference/-/Official_Review", "signatures": ["OpenReview.net"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Paper3474/Reviewers", "OpenReview.net/Support"], "id": "ICLR.cc/2021/Conference/Paper3474/-/Official_Review"}}}, {"id": "rFHOnxFFtzA", "original": null, "number": 3, "cdate": 1603907806985, "ddate": null, "tcdate": 1603907806985, "tmdate": 1605023993918, "tddate": null, "forum": "HK_B2K0026", "replyto": "HK_B2K0026", "invitation": "ICLR.cc/2021/Conference/Paper3474/-/Official_Review", "content": {"title": "CNN-based approach for segmentation and classification of ECG signals which is quite ad-hoc and limited novelty", "review": "The paper proposes a framework for the classification of arrhythmias in electrocardiogram (ECG) data. The proposed approach performs segmentation and classification of the ECG signal. The segmenter performs segmentation of the signal (also called attention map) even though the term segmentation is not quite correct. This attention-modulated signal is then classified to identify the origin of Premature Ventricular Contraction (PVC).  The proposed approach is evaluated on a dataset from a single machine consisting of 508 segments (I am not sure what \u201csegments\u201d means in this context). The results seem ok, but it is not clear to me what level of performance is required in order to achieve a similar level of performance as an expert.\n\nMain concern is that the proposed approach seems rather ad-hoc: The combination of segmentation (or attention) and classification in a joint fashion seems hardly new and while the results obtained are good, there is no systematic evaluation how the method compares to other state-of-the-art ECG classification methods. Another problem is that the writing in the paper is not always clear and it is often unclear what exactly the authors are doing. As a result, it is quite difficult to exactly assess what the authors have done or what they mean.\n\nDetailed comments:\n\n\u2022 What is the output of the classifier? Is this a binary label? Or a multi-class label?\n\u2022 The authors write \u201c\u2026 the output of S has only 1 channel and we expand it channel-wise so that it matches the channel dimension of the ECG signal \u2026\u201d \u2013 What exactly is meant here? In Fig 1 it seems that the segmentation output has naturally 12 channels? Should the segmentation be identical for all channels?\n\u2022 \u201cWe do not use the output of the segmenter L as the attention map directly but instead perform a pooling with large kernel size first\u201d \u2013 Why is this done? What does \u201clarge kernel\u201d mean?\n\u2022 Where is the attention map in Fig. 1?\n\u2022 How are the Premature Ventricular Contraction (PVC) origin labels defined? Is that a single time point (per channel or common for all channels) or a time window? \n", "rating": "6: Marginally above acceptance threshold", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["ICLR.cc/2021/Conference/Paper3474/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper3474/AnonReviewer3"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Attention Based Joint Learning for Supervised Electrocardiogram Arrhythmia Differentiation with Unsupervised Abnormal Beat Segmentation", "authorids": ["~Xinrong_Hu1", "wl960201@163.com", "635386607@qq.com", "41421891@qq.com", "~Jian_Zhuang1", "~Yiyu_Shi1"], "authors": ["Xinrong Hu", "long wen", "shushui wang", "Dongpo Liang", "Jian Zhuang", "Yiyu Shi"], "keywords": ["interpretability", "multitask learning", "attention mechanism", "electrocardiography"], "abstract": "Deep learning has shown great promise in arrhythmia classification in electrocar- diogram (ECG). Existing works, when classifying an ECG segment with multiple beats, do not identify the locations of the anomalies, which reduces clinical inter- pretability. On the other hand, segmenting abnormal beats by deep learning usu- ally requires annotation for a large number of regular and irregular beats, which can be laborious, sometimes even challenging, with strong inter-observer variabil- ity between experts. In this work, we propose a method capable of not only dif- ferentiating arrhythmia but also segmenting the associated abnormal beats in the ECG segment. The only annotation used in the training is the type of abnormal beats and no segmentation labels are needed. Imitating human\u2019s perception of an ECG signal, the framework consists of a segmenter and classifier. The segmenter outputs an attention map, which aims to highlight the abnormal sections in the ECG by element-wise modulation. Afterwards, the signals are sent to a classifier for arrhythmia differentiation. Though the training data is only labeled to super- vise the classifier, the segmenter and the classifier are trained in an end-to-end manner so that optimizing classification performance also adjusts how the abnor- mal beats are segmented. Validation of our method is conducted on two dataset. We observe that involving the unsupervised segmentation in fact boosts the clas- sification performance. Meanwhile, a grade study performed by experts suggests that the segmenter also achieves satisfactory quality in identifying abnormal beats, which significantly enhances the interpretability of the classification results.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "hu|attention_based_joint_learning_for_supervised_electrocardiogram_arrhythmia_differentiation_with_unsupervised_abnormal_beat_segmentation", "one-sentence_summary": "This paper presents a joint learning framework for supervised arrhythmia differentiation with unsupervised abnormal heart beat seg mentation on ECG, where the two tasks can benefit from each other.  ", "pdf": "/pdf/609e06c71d4acfd8f207a05915c3578cd58404b2.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=HOFhU3Uy5x", "_bibtex": "@misc{\nhu2021attention,\ntitle={Attention Based Joint Learning for Supervised Electrocardiogram Arrhythmia Differentiation with Unsupervised Abnormal Beat Segmentation},\nauthor={Xinrong Hu and long wen and shushui wang and Dongpo Liang and Jian Zhuang and Yiyu Shi},\nyear={2021},\nurl={https://openreview.net/forum?id=HK_B2K0026}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq . ***Please remember to file the Code-of-Ethics report. Once you submitted the review, a link to the report will be visible in the bottom right corner of your review.***", "required": true, "markdown": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}, "forum": "HK_B2K0026", "replyto": "HK_B2K0026", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"], "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper3474/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1607428800000, "duedate": 1606752000000, "multiReply": false, "readers": ["everyone"], "tcdate": 1602538075164, "tmdate": 1606915800458, "super": "ICLR.cc/2021/Conference/-/Official_Review", "signatures": ["OpenReview.net"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Paper3474/Reviewers", "OpenReview.net/Support"], "id": "ICLR.cc/2021/Conference/Paper3474/-/Official_Review"}}}, {"id": "7AM3ttMwsxI", "original": null, "number": 4, "cdate": 1603993770455, "ddate": null, "tcdate": 1603993770455, "tmdate": 1605023993853, "tddate": null, "forum": "HK_B2K0026", "replyto": "HK_B2K0026", "invitation": "ICLR.cc/2021/Conference/Paper3474/-/Official_Review", "content": {"title": "Empirical evidence has some loopholes", "review": "This manuscript contributes a neural architecture to classify arrhythmia type from ECG data. The signal treated as 1D, and the architecture performs joint segmentation-classification detecting the abnormal beats and then classifying them as a function of their origine. It uses U-nets for segmentation and, for classification CNN and one fully-connected layer. The unet segmentation generates weights that are considered as an attention map and multipled with the original time series after pooling on a window (which amounts to smoothing).\n\nCompared to the prior art, the central contribution put forward is the addition of the segmentation component of the architecture.\n\nThe work is light on theory and the contribution mostly resides on the empirical improvement. However, the evidence for this improvement is not rock solid, as it is shown on a single dataset, which has a rather small sample size. Also, I fear that hyper-parameters are not set fully independent of the final error measure.\n\nHow are hyper-parameters (such as learning rate or architecture parameters) chosen? Given the procedure exposed in section 5.2, it seems to me that some of the architecture parameters (kernel size) where not chosen independently of the test set. Such choice will incur a positive bias with regards to the actual expected generalization error.\n\nWith n=500 and an accuracy of 90%, the p=.05 confidence interval of a binomial model is 5%. Hence, the improvements observed by adding the segmentation on top of the classifier do not seem really significant.\n\n", "rating": "5: Marginally below acceptance threshold", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["ICLR.cc/2021/Conference/Paper3474/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper3474/AnonReviewer1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Attention Based Joint Learning for Supervised Electrocardiogram Arrhythmia Differentiation with Unsupervised Abnormal Beat Segmentation", "authorids": ["~Xinrong_Hu1", "wl960201@163.com", "635386607@qq.com", "41421891@qq.com", "~Jian_Zhuang1", "~Yiyu_Shi1"], "authors": ["Xinrong Hu", "long wen", "shushui wang", "Dongpo Liang", "Jian Zhuang", "Yiyu Shi"], "keywords": ["interpretability", "multitask learning", "attention mechanism", "electrocardiography"], "abstract": "Deep learning has shown great promise in arrhythmia classification in electrocar- diogram (ECG). Existing works, when classifying an ECG segment with multiple beats, do not identify the locations of the anomalies, which reduces clinical inter- pretability. On the other hand, segmenting abnormal beats by deep learning usu- ally requires annotation for a large number of regular and irregular beats, which can be laborious, sometimes even challenging, with strong inter-observer variabil- ity between experts. In this work, we propose a method capable of not only dif- ferentiating arrhythmia but also segmenting the associated abnormal beats in the ECG segment. The only annotation used in the training is the type of abnormal beats and no segmentation labels are needed. Imitating human\u2019s perception of an ECG signal, the framework consists of a segmenter and classifier. The segmenter outputs an attention map, which aims to highlight the abnormal sections in the ECG by element-wise modulation. Afterwards, the signals are sent to a classifier for arrhythmia differentiation. Though the training data is only labeled to super- vise the classifier, the segmenter and the classifier are trained in an end-to-end manner so that optimizing classification performance also adjusts how the abnor- mal beats are segmented. Validation of our method is conducted on two dataset. We observe that involving the unsupervised segmentation in fact boosts the clas- sification performance. Meanwhile, a grade study performed by experts suggests that the segmenter also achieves satisfactory quality in identifying abnormal beats, which significantly enhances the interpretability of the classification results.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "hu|attention_based_joint_learning_for_supervised_electrocardiogram_arrhythmia_differentiation_with_unsupervised_abnormal_beat_segmentation", "one-sentence_summary": "This paper presents a joint learning framework for supervised arrhythmia differentiation with unsupervised abnormal heart beat seg mentation on ECG, where the two tasks can benefit from each other.  ", "pdf": "/pdf/609e06c71d4acfd8f207a05915c3578cd58404b2.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=HOFhU3Uy5x", "_bibtex": "@misc{\nhu2021attention,\ntitle={Attention Based Joint Learning for Supervised Electrocardiogram Arrhythmia Differentiation with Unsupervised Abnormal Beat Segmentation},\nauthor={Xinrong Hu and long wen and shushui wang and Dongpo Liang and Jian Zhuang and Yiyu Shi},\nyear={2021},\nurl={https://openreview.net/forum?id=HK_B2K0026}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq . ***Please remember to file the Code-of-Ethics report. Once you submitted the review, a link to the report will be visible in the bottom right corner of your review.***", "required": true, "markdown": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}, "forum": "HK_B2K0026", "replyto": "HK_B2K0026", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"], "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper3474/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1607428800000, "duedate": 1606752000000, "multiReply": false, "readers": ["everyone"], "tcdate": 1602538075164, "tmdate": 1606915800458, "super": "ICLR.cc/2021/Conference/-/Official_Review", "signatures": ["OpenReview.net"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Paper3474/Reviewers", "OpenReview.net/Support"], "id": "ICLR.cc/2021/Conference/Paper3474/-/Official_Review"}}}], "count": 10}