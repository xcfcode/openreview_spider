{"notes": [{"id": "FmMKSO4e8JK", "original": "nqyttlqGkBf", "number": 2157, "cdate": 1601308237604, "ddate": null, "tcdate": 1601308237604, "tmdate": 1615876909459, "tddate": null, "forum": "FmMKSO4e8JK", "replyto": null, "invitation": "ICLR.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Offline Model-Based Optimization via Normalized Maximum Likelihood Estimation", "authorids": ["~Justin_Fu1", "~Sergey_Levine1"], "authors": ["Justin Fu", "Sergey Levine"], "keywords": ["model-based optimization", "normalized maximum likelihood"], "abstract": "In this work we consider data-driven optimization problems where one must maximize a function given only queries at a fixed set of points. This problem setting emerges in many domains where function evaluation is a complex and expensive process, such as in the design of materials, vehicles, or neural network architectures. Because the available data typically only covers a small manifold of the possible space of inputs, a principal challenge is to be able to construct algorithms that can reason about uncertainty and out-of-distribution values, since a naive optimizer can easily exploit an estimated model to return adversarial inputs. We propose to tackle the MBO problem by leveraging the normalized maximum-likelihood (NML) estimator, which provides a principled approach to handling uncertainty and out-of-distribution inputs. While in the standard formulation NML is intractable, we propose a tractable approximation that allows us to scale our method to high-capacity neural network models. We demonstrate that our method can effectively optimize high-dimensional design problems in a variety of disciplines such as chemistry, biology, and materials engineering.", "one-sentence_summary": "Offline, data-driven optimization using normalized maximum likelihood to produce robust function estimates.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "fu|offline_modelbased_optimization_via_normalized_maximum_likelihood_estimation", "pdf": "/pdf/4fc7d9a4093bc9bafddf46785cafda74e0be40ce.pdf", "venue": "ICLR 2021 Poster", "venueid": "ICLR.cc/2021/Conference", "_bibtex": "@inproceedings{\nfu2021offline,\ntitle={Offline Model-Based Optimization via Normalized Maximum Likelihood Estimation},\nauthor={Justin Fu and Sergey Levine},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=FmMKSO4e8JK}\n}"}, "signatures": ["ICLR.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference"], "details": {"replyCount": 12, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"reply": {"readers": {"values-regex": ".*"}, "writers": {"values": ["ICLR.cc/2021/Conference"]}, "signatures": {"values": ["ICLR.cc/2021/Conference"]}, "content": {"authors": {"values": ["Anonymous"]}, "authorids": {"values-regex": ".*"}, "reviewed_version_(pdf)": {"required": false, "description": "Upload a PDF file that ends with .pdf", "value-regex": ".*"}}}, "signatures": ["ICLR.cc/2021/Conference"], "readers": ["everyone"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["~", "OpenReview.net/Support"], "tcdate": 1601308008205, "tmdate": 1614984599368, "id": "ICLR.cc/2021/Conference/-/Blind_Submission"}}, "tauthor": "OpenReview.net"}, {"id": "XhCUvYymvMW", "original": null, "number": 1, "cdate": 1610040471669, "ddate": null, "tcdate": 1610040471669, "tmdate": 1610474075768, "tddate": null, "forum": "FmMKSO4e8JK", "replyto": "FmMKSO4e8JK", "invitation": "ICLR.cc/2021/Conference/Paper2157/-/Decision", "content": {"title": "Final Decision", "decision": "Accept (Poster)", "comment": "This work proposes a model-based optimization using an approximated normalized maximum likelihood (NML). It is an interesting idea and has the advantage of scaling to large datasets. The reviewers are generally positive and are satisfied with authors' response.  "}, "signatures": ["ICLR.cc/2021/Conference/Program_Chairs"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference/Program_Chairs"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Offline Model-Based Optimization via Normalized Maximum Likelihood Estimation", "authorids": ["~Justin_Fu1", "~Sergey_Levine1"], "authors": ["Justin Fu", "Sergey Levine"], "keywords": ["model-based optimization", "normalized maximum likelihood"], "abstract": "In this work we consider data-driven optimization problems where one must maximize a function given only queries at a fixed set of points. This problem setting emerges in many domains where function evaluation is a complex and expensive process, such as in the design of materials, vehicles, or neural network architectures. Because the available data typically only covers a small manifold of the possible space of inputs, a principal challenge is to be able to construct algorithms that can reason about uncertainty and out-of-distribution values, since a naive optimizer can easily exploit an estimated model to return adversarial inputs. We propose to tackle the MBO problem by leveraging the normalized maximum-likelihood (NML) estimator, which provides a principled approach to handling uncertainty and out-of-distribution inputs. While in the standard formulation NML is intractable, we propose a tractable approximation that allows us to scale our method to high-capacity neural network models. We demonstrate that our method can effectively optimize high-dimensional design problems in a variety of disciplines such as chemistry, biology, and materials engineering.", "one-sentence_summary": "Offline, data-driven optimization using normalized maximum likelihood to produce robust function estimates.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "fu|offline_modelbased_optimization_via_normalized_maximum_likelihood_estimation", "pdf": "/pdf/4fc7d9a4093bc9bafddf46785cafda74e0be40ce.pdf", "venue": "ICLR 2021 Poster", "venueid": "ICLR.cc/2021/Conference", "_bibtex": "@inproceedings{\nfu2021offline,\ntitle={Offline Model-Based Optimization via Normalized Maximum Likelihood Estimation},\nauthor={Justin Fu and Sergey Levine},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=FmMKSO4e8JK}\n}"}, "tags": [], "invitation": {"reply": {"forum": "FmMKSO4e8JK", "replyto": "FmMKSO4e8JK", "readers": {"values": ["everyone"]}, "writers": {"values": ["ICLR.cc/2021/Conference/Program_Chairs"]}, "signatures": {"values": ["ICLR.cc/2021/Conference/Program_Chairs"]}, "content": {"title": {"value": "Final Decision"}, "decision": {"value-radio": ["Accept (Oral)", "Accept (Spotlight)", "Accept (Poster)", "Reject"]}, "comment": {"value-regex": "[\\S\\s]{0,50000}", "markdown": true}}}, "multiReply": false, "signatures": ["ICLR.cc/2021/Conference"], "readers": ["everyone"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Program_Chairs"], "tcdate": 1610040471655, "tmdate": 1610474075753, "id": "ICLR.cc/2021/Conference/Paper2157/-/Decision"}}}, {"id": "zubXksL0NPx", "original": null, "number": 3, "cdate": 1604101418356, "ddate": null, "tcdate": 1604101418356, "tmdate": 1606688659987, "tddate": null, "forum": "FmMKSO4e8JK", "replyto": "FmMKSO4e8JK", "invitation": "ICLR.cc/2021/Conference/Paper2157/-/Official_Review", "content": {"title": "Reviewer 2", "review": "Updated review\n----\n----\n\n# Summary\n\nThis work proposes an approach for model-based optimization based on learning a density function through an approximation of the normalized maximum likelihood (NML). This is done by discretizing the space and fitting distinct model parameters for each value. To lower the computational cost, the authors propose optimizing the candidates concurrently with the model parameters. Each model's distribution is encoded as a neural net outputting a scalar which is then encoded using a thermometer approach using a series of shifted sigmoid. Candidates are optimized based on the average value of the scalar of each model evaluated using parameters obtained from an exponentially weighted average of its most recent parameters.\n\n# Reason for score\n\nThis work proposes a reasonable approximation to an interesting estimator and demonstrate it is capable of achieving good consistent performance. This is likely to be of interest to the community and, as far as I'm aware, is sufficiently novel. Given that I see no noteworthy issues and all of my major concerns have been addressed, I don't see any reason for rejection. I strongly support acceptance.\n\n# Pros\n\n* Using estimates of the NML for model-based optimization is an interesting idea.\n* This work shows that the NML can be successfully approximated with a relatively coarse discretization and that both the optimization of the candidate and the various model parameters can be optimized in tandem. This suggests that this type of approach is viable and possibly warrants further investigation.\n\n\nInitial review\n----\n----\n\n# Summary\n\nThis work proposes an approach for model-based optimization based on learning a density function through an approximation of the normalized maximum likelihood (NML). This is done by discretizing the space and fitting distinct model parameters for each value. To lower the computational cost, the authors propose optimizing the candidates concurrently with the model parameters. Each model's distribution is encoded as a neural net outputting a scalar which is then encoded using a thermometer approach using a series of shifted sigmoid. Candidates are optimized based on the average value of the scalar of each model evaluated using parameters obtained from an exponentially weighted average of its most recent parameters.\n\n# Reason for score\n\nThere are a lot of typos and issues with the notation which make this paper unfit for publication in its current state. Otherwise, the work seems interesting but I find the experiments don't provide much insight. Though the comparison with the selected method is favorable, it's hard to consider them significant when there is a notable difference in only one of the three datasets of an unpublished benchmark. Additionally, the fact that the reported results only cover half the datasets from this benchmark raises some questions. Despite the negative tone of this paragraph, I want to note that the severity of some of these issues is subjective while others can be easily fixed. My mind isn't made up and I hope the authors can clarify anything I might have missed.\n\n# Pros\n\n* Using estimates of the NML for model-based optimization is an interesting idea.\n* This work shows that the NML can be successfully approximated with a relatively coarse discretization and that both the optimization of the candidate and the various model parameters can be optimized in tandem. This suggests that this type of approach is viable and possibly warrants further investigation.\n\n# Cons\n\n* The current notation is often confusing and even ambiguous at times. This will probably transpire in some of my other comments, but I do consider these issues to be superficial and easily fixed. I've provided some suggestions below for how to improve the notation. I understand that notation preference is a very subjective thing so the authors should feel free to opt for something different, but I do think the notation needs to be improved.\n* The \"thermometer encoding\" of the output seems like an odd choice, especially given how it is done here. If I understood the approach correctly, this seems to be a hacky way of using the output of the NN, $o_{int}$, as parameters to a logistic distributions. Why not treat it this way directly? My interpretation of this approach is that the $o^k_{int}$s are parameters for logistic distributions and the mean is optimized through the unnormalized probs by optimizing each $o^k_{int}$ directly. Would this be a fair description of the approach? I was expecting the discretization to be used directly to approximate the integral in eq. (2). \n* The experimental results aren't very conclusive, only showing a clear benefit in a single case. Without additional results, it is difficult to say much about the behavior and properties of this method. A visualization of the distribution of the value of the candidates might help convey some additional information in favor of this method. It's possible that I am missing some context to appreciate these results. If that is the case, it would help if the authors could provide the context I need to appreciate these results.\n\n# Questions\n\n* I don't think I understand what makes the appendix results an ablation study. From what I understand, these results only compare with the case where there is no learning of the model parameters. What are the models initialized to? Where does the data come into play?\n* Have the authors considered using points selected from some fixed quadrature method instead of a uniform grid?\n* A common theme for the comparison methods is the idea of not diverging too much from the data. Was the validity of the outputs of this method evaluated in any way? How can I know that the method isn't just exploiting some quirk in the learned models used to evaluate it while some of the other methods avoid doing this?\n* Were comparisons with a simple approaches Bayesian optimization tried, e.g., Gaussian process?\n* What happens when doing more iterations on the log likelihood before updating $x$? How much do we lose when only doing a single update? Does using a more accurate approximation of the NLM improve/worsen performance? (I was hoping this would be part of the ablation study)\n* How do the run times compare?\n* Were the other datasets from the Design-bench benchmark tried?\n\n# Misc and typos\n\n* page 2, \"in that it has shown to be\", missing word?\n* page 2, \"to discuss how approximate this intractable\", missing word?\n* page 3, when $p_{NML}$ is formally written, the meaning of $y$ is ambiguous since it is on the LHS and also being redefined by $\\max_y$ in the RHS.\n* page 3, \"The notation $D \\cup (x, y)$ refers to an augmented dataset $D \\cup (x_{N+1}, y_{N+1})$\", this wasn't very informative and felt a bit tautological. I would recommend sticking with one of the two notations.\n* page 3, \"where $D$ is fixed to the given offline dataset, and $\\theta_{D \\cup (x,y)}$ [...]\", this sentence is a bit confusing as a whole. The start of the sentence talks only about $D$ so the $\\theta$ mention is unexpected when reading.\n* page 3, right after eq. (2), $(x, y)$ is on the LHS but then also part of the expectation on the RHS. What is the expectation being taken over? Are $x$ and $y$ being redefined?\n* page 4, \"for y in 1 ... K do\", is $y$ I don't believe that $y$ is assumed to be an integer. \n* page 4, algorithm 4?\n* page 4, \u00a0\"this would produce a distribution over output values $p(y|x)$\", this doesn't \"type check\" for me. If I understood correctly, $p$ or $p(\\bullet | x)$ represent distributions and $y$ are output values. Also, it might be good to reuse the \"$\\hat p_{NML}$\" notation to get the following sentence: \"this would produce a conditional distribution, $\\hat p_{NML}(\\bullet | x_t)$, \u00a0over output values.\n* page 4, \"we can optimize $x_t$ with respect to some evaluation function $g(y)$ of this distribution, such as the\nmean\", this is confusing since algorithm 1 has $\\mathbb{E}[ g(y)]$. What does it mean for the evaluation function $g$ to be the mean in this context? How should I interpret the expectation of mean(y)? Also, I assumed that what was meant is that $g$ is the evaluation function, not $g(y)$, or is $g$ meant to return a function given a $y$?\n* page 6, \"a straightforward choice for the evaluation function g is the identity function $g(x) = x$\", it might be best to stick to a consistent variable name, e.g., $g(y) = y$, to avoid confusion about what the domain of $g$ is.\n* Proof of thm 4.1, equation under \"using these two facts, we can show:\", $q$ should be replaced with $p_{NML}$ in the RHS.\n* Proof of thm 4.1, going from TV to KL, looking up the bound returns a $1/2$ factor inside the root rather than a $2$. I could have missed a detail but thought worth mentioning in case I haven't.\n* Proof of thm 4.1, missing a \"]\" when bounding the KL divergence.\n* Algorithm 2, there is some undefined superscript $k$ and $y$ in the loop over $x^m_t$.\n\n# Notation suggestions\n\n* When writing expectations, I would strongly recommend making it explicit over which variables they are, e.g., $\\mathbb{E}\\_{y \\sim p(\\bullet | x, \\theta)}$. Introducing some shorthand notation might help make this more concise, e.g., $p_{x, \\theta}(y) := p(y | x, \\theta)$.\n* When referring to a function, only mention its name/symbol and reserve the form that includes inputs to refer to the output of the function given those inputs, e.g., a function $g$, an evaluation score $g(y)$.\n* Avoid relying on the readers pattern matching abilities for assigning meaning to variables and make sure variables, e.g., $\\mathbf{x}$ and $y$, are always explicitly defined. By explicitly defined, I include defining $y$ compactly with something like $\\max_{y \\in \\mathcal{Y}} g(y)$, for example. There is not need to be overly verbose but it should never leave room for interpretation. This is related to the point about expectation notation.\n* I usually prefer explicit domains, e.g., $\\sum_{y \\in \\mathcal{Y}}$ instead of $\\sum_y$, but I consider it fine to omit it if variables names are always reserved to the same domain when reused. This was not the case for $x$ in this paper.\n* When writing pseudocode, either loop over integer indices or over elements of a set, it is confusing to use \"for y in 1 ... K\" when $y$ isn't an integer. Additionally, using both makes it difficult to tell that $k$ is associated with $y$ inside a loop.", "rating": "8: Top 50% of accepted papers, clear accept", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["ICLR.cc/2021/Conference/Paper2157/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2157/AnonReviewer2"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Offline Model-Based Optimization via Normalized Maximum Likelihood Estimation", "authorids": ["~Justin_Fu1", "~Sergey_Levine1"], "authors": ["Justin Fu", "Sergey Levine"], "keywords": ["model-based optimization", "normalized maximum likelihood"], "abstract": "In this work we consider data-driven optimization problems where one must maximize a function given only queries at a fixed set of points. This problem setting emerges in many domains where function evaluation is a complex and expensive process, such as in the design of materials, vehicles, or neural network architectures. Because the available data typically only covers a small manifold of the possible space of inputs, a principal challenge is to be able to construct algorithms that can reason about uncertainty and out-of-distribution values, since a naive optimizer can easily exploit an estimated model to return adversarial inputs. We propose to tackle the MBO problem by leveraging the normalized maximum-likelihood (NML) estimator, which provides a principled approach to handling uncertainty and out-of-distribution inputs. While in the standard formulation NML is intractable, we propose a tractable approximation that allows us to scale our method to high-capacity neural network models. We demonstrate that our method can effectively optimize high-dimensional design problems in a variety of disciplines such as chemistry, biology, and materials engineering.", "one-sentence_summary": "Offline, data-driven optimization using normalized maximum likelihood to produce robust function estimates.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "fu|offline_modelbased_optimization_via_normalized_maximum_likelihood_estimation", "pdf": "/pdf/4fc7d9a4093bc9bafddf46785cafda74e0be40ce.pdf", "venue": "ICLR 2021 Poster", "venueid": "ICLR.cc/2021/Conference", "_bibtex": "@inproceedings{\nfu2021offline,\ntitle={Offline Model-Based Optimization via Normalized Maximum Likelihood Estimation},\nauthor={Justin Fu and Sergey Levine},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=FmMKSO4e8JK}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq . ***Please remember to file the Code-of-Ethics report. Once you submitted the review, a link to the report will be visible in the bottom right corner of your review.***", "required": true, "markdown": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}, "forum": "FmMKSO4e8JK", "replyto": "FmMKSO4e8JK", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"], "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper2157/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1607428800000, "duedate": 1606752000000, "multiReply": false, "readers": ["everyone"], "tcdate": 1602538102750, "tmdate": 1606915792479, "super": "ICLR.cc/2021/Conference/-/Official_Review", "signatures": ["OpenReview.net"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Paper2157/Reviewers", "OpenReview.net/Support"], "id": "ICLR.cc/2021/Conference/Paper2157/-/Official_Review"}}}, {"id": "fpGZAusvPdJ", "original": null, "number": 1, "cdate": 1603894671826, "ddate": null, "tcdate": 1603894671826, "tmdate": 1606144624058, "tddate": null, "forum": "FmMKSO4e8JK", "replyto": "FmMKSO4e8JK", "invitation": "ICLR.cc/2021/Conference/Paper2157/-/Official_Review", "content": {"title": "Utilizing normalized maximum-likelihood for better estimation of model uncertainty for offline data-driven optimization", "review": "Summary: The paper proposes an approximation method, called NEMO (Normalized maximum likelihood Estimation for model-based optimization)  to compute the conditional normalized maximum log-likelihood of a query data point as a way to quantify the uncertainty in a forward prediction model in offline model-based optimization problems. The main idea is to construct a conditional NML (CNML) distribution that maps the high-dimensional inputs to a distribution over output variables. In addition, the paper provides a theoretical motivation that estimating the true function with the CNML is close to the best possible expert even if the test label is chosen adversarially, which is a great challenge for an optimizer to exploit the model. By using this CNML on three offline optimization benchmark datasets (Superconductor, GFP, MoleculeActivity) with gradient ascent-based optimization, the NEMO outputs all the other four baselines on the Superconductor dataset by almost 1.4x to 1.7x, the generate comparable results as the other four baselines method on the GFP and MoleculeActivity datasets.   \n\nTypo: \nIn section 4, \u201cWe outline the high-level pseudocode in Algorithm 4\u201d -> \u201c\u2026. in Algorithm 1\u201d\n\nQuestions: \n1. When sampling a batch of data points at each step of algorithm 1, is the sampling performed with or without replacements?  \n2. What\u2019s the variance across the 16 random runs? Is the score of the best algorithm in the average performance across 16 random runs significantly different from the baseline algorithms?\n3. When estimating the CNML, what is the number of models in the experiments? Are the number of models differ from dataset to dataset? How to choose the number of models in practice?\n4. Since the output y needs to be discretized in the NEMO algorithm, how difficult for the algorithm to scale when y is multivariate?\n\n------------------------------------------------------------------------------------------------------------\nUpdate: \nI think the authors did a great job of addressing my concerns, I'm happy to increase my score to 6\n", "rating": "6: Marginally above acceptance threshold", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "signatures": ["ICLR.cc/2021/Conference/Paper2157/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2157/AnonReviewer3"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Offline Model-Based Optimization via Normalized Maximum Likelihood Estimation", "authorids": ["~Justin_Fu1", "~Sergey_Levine1"], "authors": ["Justin Fu", "Sergey Levine"], "keywords": ["model-based optimization", "normalized maximum likelihood"], "abstract": "In this work we consider data-driven optimization problems where one must maximize a function given only queries at a fixed set of points. This problem setting emerges in many domains where function evaluation is a complex and expensive process, such as in the design of materials, vehicles, or neural network architectures. Because the available data typically only covers a small manifold of the possible space of inputs, a principal challenge is to be able to construct algorithms that can reason about uncertainty and out-of-distribution values, since a naive optimizer can easily exploit an estimated model to return adversarial inputs. We propose to tackle the MBO problem by leveraging the normalized maximum-likelihood (NML) estimator, which provides a principled approach to handling uncertainty and out-of-distribution inputs. While in the standard formulation NML is intractable, we propose a tractable approximation that allows us to scale our method to high-capacity neural network models. We demonstrate that our method can effectively optimize high-dimensional design problems in a variety of disciplines such as chemistry, biology, and materials engineering.", "one-sentence_summary": "Offline, data-driven optimization using normalized maximum likelihood to produce robust function estimates.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "fu|offline_modelbased_optimization_via_normalized_maximum_likelihood_estimation", "pdf": "/pdf/4fc7d9a4093bc9bafddf46785cafda74e0be40ce.pdf", "venue": "ICLR 2021 Poster", "venueid": "ICLR.cc/2021/Conference", "_bibtex": "@inproceedings{\nfu2021offline,\ntitle={Offline Model-Based Optimization via Normalized Maximum Likelihood Estimation},\nauthor={Justin Fu and Sergey Levine},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=FmMKSO4e8JK}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq . ***Please remember to file the Code-of-Ethics report. Once you submitted the review, a link to the report will be visible in the bottom right corner of your review.***", "required": true, "markdown": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}, "forum": "FmMKSO4e8JK", "replyto": "FmMKSO4e8JK", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"], "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper2157/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1607428800000, "duedate": 1606752000000, "multiReply": false, "readers": ["everyone"], "tcdate": 1602538102750, "tmdate": 1606915792479, "super": "ICLR.cc/2021/Conference/-/Official_Review", "signatures": ["OpenReview.net"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Paper2157/Reviewers", "OpenReview.net/Support"], "id": "ICLR.cc/2021/Conference/Paper2157/-/Official_Review"}}}, {"id": "TBhMYJxLjnG", "original": null, "number": 2, "cdate": 1603903168399, "ddate": null, "tcdate": 1603903168399, "tmdate": 1606137591909, "tddate": null, "forum": "FmMKSO4e8JK", "replyto": "FmMKSO4e8JK", "invitation": "ICLR.cc/2021/Conference/Paper2157/-/Official_Review", "content": {"title": "Official Blind Review #1 ", "review": "# summary\n\nThis paper proposed a method based on NML and provided a principled approach\nto estimate the uncertainty for OOD data.\n\n\n# pros\n\n1.  The method proposed in this work is a principled way to handle uncertainty\n    for novel points out of the original dataset compared with, for example,\n    deep ensemble.\n2.  One clear advantage of ths proposed approach is this method can scale to\n    large dataset, compared with GP, which scales cubically.\n\n\n# cons\n\n1.  The authors claim using a supervised approach is brittle and prone to\n    failure as the uncertainty of inputs outside of training data is\n    uncontroled. However, this is not true and uncertainty can be well\n    controlled depending on the model, which can be non-parametric or\n    parametric, distribution-free or distribution-dependent. For example, to\n    measure uncertainty on novel point, GP could be viewed as the ground truth\n    under some conditions. My question is why not directly compare your\n    approach with a GP approach, then combine the posterior with an acquisition\n    function, such as EI. The offline MBO problem presented in this work is\n    similiar to an online MBO, except we have only one online sample, and\n    we are tying to optimize this point. Comparing eq(1) of this paper with the\n    formula of EI, it is easy to see eq(1) is exactly EI, if we assume there\n    exists (x\\*,y\\*) such that y\\* is larger than objective values in the training\n    data set. Thus the problem presented in this work can be effectively solved\n    through **one step** of conventional BO. Given the datasets used in the\n    experiments of this work is are not of large scale, I think comparing with\n    a GP-based BO is necessary.\n2.  In Figure 3, although not a major concern, I don't think the comparison\n    with the ensemble is fair. Although this work uses bootstrap and ensemble,\n    MSE cannot capture uncertainty, thus it is not an ideal metric in this\n    setting. For example, to obtain a similar uncertainty estimation compared\n    with NML (middle column), we can use a deep ensemble, which optimizes NLL\n    instead of MSE.\n3.  The experimental results, in my opinion, are not sufficient and there is\n    only one table presenting empirical results. I don't want to judge\n    sufficiency by the quantity of tables or figures, but considering the\n    theoretical analysis is not strong enough, I think more empirical study\n    should be performed.\n4.  The uncertainty estimation seems too conservative, and this could make the\n    estimated uncertainty less useful, especially for high-dimensional\n    problems.\n\n\n# questions\n\nThe approach proposed in this paper seems very similiar with conformal\nprediction. In conformal prediction, the target value y\\* for a novel point x\\*\n(adversarial input) is chosen so that y\\* is compatible with the original\ndataset. As I am not familiar with the evaluation protocol in Brookles2019 and\nFannjiang2020, the metric used in Table 1 is not clear to me. Can the authors\nsay more about that?\n\nupdate:\n\n---\nOverall speaking, the added GP-BO results address my  concerns, and I've updated the score from 5->6. A final update will be given later.", "rating": "6: Marginally above acceptance threshold", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["ICLR.cc/2021/Conference/Paper2157/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2157/AnonReviewer1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Offline Model-Based Optimization via Normalized Maximum Likelihood Estimation", "authorids": ["~Justin_Fu1", "~Sergey_Levine1"], "authors": ["Justin Fu", "Sergey Levine"], "keywords": ["model-based optimization", "normalized maximum likelihood"], "abstract": "In this work we consider data-driven optimization problems where one must maximize a function given only queries at a fixed set of points. This problem setting emerges in many domains where function evaluation is a complex and expensive process, such as in the design of materials, vehicles, or neural network architectures. Because the available data typically only covers a small manifold of the possible space of inputs, a principal challenge is to be able to construct algorithms that can reason about uncertainty and out-of-distribution values, since a naive optimizer can easily exploit an estimated model to return adversarial inputs. We propose to tackle the MBO problem by leveraging the normalized maximum-likelihood (NML) estimator, which provides a principled approach to handling uncertainty and out-of-distribution inputs. While in the standard formulation NML is intractable, we propose a tractable approximation that allows us to scale our method to high-capacity neural network models. We demonstrate that our method can effectively optimize high-dimensional design problems in a variety of disciplines such as chemistry, biology, and materials engineering.", "one-sentence_summary": "Offline, data-driven optimization using normalized maximum likelihood to produce robust function estimates.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "fu|offline_modelbased_optimization_via_normalized_maximum_likelihood_estimation", "pdf": "/pdf/4fc7d9a4093bc9bafddf46785cafda74e0be40ce.pdf", "venue": "ICLR 2021 Poster", "venueid": "ICLR.cc/2021/Conference", "_bibtex": "@inproceedings{\nfu2021offline,\ntitle={Offline Model-Based Optimization via Normalized Maximum Likelihood Estimation},\nauthor={Justin Fu and Sergey Levine},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=FmMKSO4e8JK}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq . ***Please remember to file the Code-of-Ethics report. Once you submitted the review, a link to the report will be visible in the bottom right corner of your review.***", "required": true, "markdown": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}, "forum": "FmMKSO4e8JK", "replyto": "FmMKSO4e8JK", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"], "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper2157/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1607428800000, "duedate": 1606752000000, "multiReply": false, "readers": ["everyone"], "tcdate": 1602538102750, "tmdate": 1606915792479, "super": "ICLR.cc/2021/Conference/-/Official_Review", "signatures": ["OpenReview.net"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Paper2157/Reviewers", "OpenReview.net/Support"], "id": "ICLR.cc/2021/Conference/Paper2157/-/Official_Review"}}}, {"id": "J5wHCifLcmX", "original": null, "number": 11, "cdate": 1605908821090, "ddate": null, "tcdate": 1605908821090, "tmdate": 1605908821090, "tddate": null, "forum": "FmMKSO4e8JK", "replyto": "yKO8leLOtal", "invitation": "ICLR.cc/2021/Conference/Paper2157/-/Official_Comment", "content": {"title": "Follow-up", "comment": "Hello, we were wondering if there were any additional concerns you had, and we would be happy to clarify them. Thank you!\n"}, "signatures": ["ICLR.cc/2021/Conference/Paper2157/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2157/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Offline Model-Based Optimization via Normalized Maximum Likelihood Estimation", "authorids": ["~Justin_Fu1", "~Sergey_Levine1"], "authors": ["Justin Fu", "Sergey Levine"], "keywords": ["model-based optimization", "normalized maximum likelihood"], "abstract": "In this work we consider data-driven optimization problems where one must maximize a function given only queries at a fixed set of points. This problem setting emerges in many domains where function evaluation is a complex and expensive process, such as in the design of materials, vehicles, or neural network architectures. Because the available data typically only covers a small manifold of the possible space of inputs, a principal challenge is to be able to construct algorithms that can reason about uncertainty and out-of-distribution values, since a naive optimizer can easily exploit an estimated model to return adversarial inputs. We propose to tackle the MBO problem by leveraging the normalized maximum-likelihood (NML) estimator, which provides a principled approach to handling uncertainty and out-of-distribution inputs. While in the standard formulation NML is intractable, we propose a tractable approximation that allows us to scale our method to high-capacity neural network models. We demonstrate that our method can effectively optimize high-dimensional design problems in a variety of disciplines such as chemistry, biology, and materials engineering.", "one-sentence_summary": "Offline, data-driven optimization using normalized maximum likelihood to produce robust function estimates.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "fu|offline_modelbased_optimization_via_normalized_maximum_likelihood_estimation", "pdf": "/pdf/4fc7d9a4093bc9bafddf46785cafda74e0be40ce.pdf", "venue": "ICLR 2021 Poster", "venueid": "ICLR.cc/2021/Conference", "_bibtex": "@inproceedings{\nfu2021offline,\ntitle={Offline Model-Based Optimization via Normalized Maximum Likelihood Estimation},\nauthor={Justin Fu and Sergey Levine},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=FmMKSO4e8JK}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "FmMKSO4e8JK", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper2157/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper2157/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper2157/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper2157/Authors|ICLR.cc/2021/Conference/Paper2157/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2157/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923851599, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper2157/-/Official_Comment"}}}, {"id": "TzK0uFSFu7i", "original": null, "number": 10, "cdate": 1605908789465, "ddate": null, "tcdate": 1605908789465, "tmdate": 1605908789465, "tddate": null, "forum": "FmMKSO4e8JK", "replyto": "ptAfxVd8fsD", "invitation": "ICLR.cc/2021/Conference/Paper2157/-/Official_Comment", "content": {"title": "Additional concerns?", "comment": "Again, we appreciate the constructive feedback on the paper. We are wondering if there are any outstanding issues you think should be addressed, or if the current presentation is satisfactory. Thank you.\n"}, "signatures": ["ICLR.cc/2021/Conference/Paper2157/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2157/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Offline Model-Based Optimization via Normalized Maximum Likelihood Estimation", "authorids": ["~Justin_Fu1", "~Sergey_Levine1"], "authors": ["Justin Fu", "Sergey Levine"], "keywords": ["model-based optimization", "normalized maximum likelihood"], "abstract": "In this work we consider data-driven optimization problems where one must maximize a function given only queries at a fixed set of points. This problem setting emerges in many domains where function evaluation is a complex and expensive process, such as in the design of materials, vehicles, or neural network architectures. Because the available data typically only covers a small manifold of the possible space of inputs, a principal challenge is to be able to construct algorithms that can reason about uncertainty and out-of-distribution values, since a naive optimizer can easily exploit an estimated model to return adversarial inputs. We propose to tackle the MBO problem by leveraging the normalized maximum-likelihood (NML) estimator, which provides a principled approach to handling uncertainty and out-of-distribution inputs. While in the standard formulation NML is intractable, we propose a tractable approximation that allows us to scale our method to high-capacity neural network models. We demonstrate that our method can effectively optimize high-dimensional design problems in a variety of disciplines such as chemistry, biology, and materials engineering.", "one-sentence_summary": "Offline, data-driven optimization using normalized maximum likelihood to produce robust function estimates.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "fu|offline_modelbased_optimization_via_normalized_maximum_likelihood_estimation", "pdf": "/pdf/4fc7d9a4093bc9bafddf46785cafda74e0be40ce.pdf", "venue": "ICLR 2021 Poster", "venueid": "ICLR.cc/2021/Conference", "_bibtex": "@inproceedings{\nfu2021offline,\ntitle={Offline Model-Based Optimization via Normalized Maximum Likelihood Estimation},\nauthor={Justin Fu and Sergey Levine},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=FmMKSO4e8JK}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "FmMKSO4e8JK", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper2157/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper2157/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper2157/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper2157/Authors|ICLR.cc/2021/Conference/Paper2157/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2157/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923851599, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper2157/-/Official_Comment"}}}, {"id": "kXngjR2X2sk", "original": null, "number": 9, "cdate": 1605821664217, "ddate": null, "tcdate": 1605821664217, "tmdate": 1605821664217, "tddate": null, "forum": "FmMKSO4e8JK", "replyto": "5ckGtAKKEjM", "invitation": "ICLR.cc/2021/Conference/Paper2157/-/Official_Comment", "content": {"title": "A happy reviewer", "comment": "The new presentation for the discretization looks good! Since new results showing # NLM steps vs performance seem to suggest that better approximations improve performance, I wonder how big of an effect a more powerful numerical integral approximation scheme, e.g., a fixed Bayesian quadrature approach, would have. Maybe the authors are equally curious to know and my curiosity will be satisfied in follow up work :)\n\n### How do the run times compare?\n\nThose are a bit better than I expected. Given the setting, runtime isn't all that important unless it starts to get prohibitively expensive but I wanted to do my due diligence and make sure nothing was swept under rug. It might be useful to add a few words with describing the \"order of\" what to expect in case a reader has the same concern, but that is far from necessary. I'm sure we can think of small things to add/change until the end of time and I don't want the authors to think they need to indulge me at this point! I think the authors have already done enough.\n\n### Design-bench benchmark ~omitted~\n\nUgh, I can't believe I missed that! That makes my comment quite silly...\n\n### Closing thoughts\n\nI am quite happy with how the paper has progressed. The authors have addressed all my concerns and have considerably improved the overall quality of this paper. At this point, I believe this paper is ready for publication and I consider it clearly above the novelty and quality threshold for acceptance at ICLR. I will wait until later in the reviewer discussion phase before updating my review but I think it is reasonable for the authors to expect a notably improved score from me after my revision."}, "signatures": ["ICLR.cc/2021/Conference/Paper2157/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2157/AnonReviewer2"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Offline Model-Based Optimization via Normalized Maximum Likelihood Estimation", "authorids": ["~Justin_Fu1", "~Sergey_Levine1"], "authors": ["Justin Fu", "Sergey Levine"], "keywords": ["model-based optimization", "normalized maximum likelihood"], "abstract": "In this work we consider data-driven optimization problems where one must maximize a function given only queries at a fixed set of points. This problem setting emerges in many domains where function evaluation is a complex and expensive process, such as in the design of materials, vehicles, or neural network architectures. Because the available data typically only covers a small manifold of the possible space of inputs, a principal challenge is to be able to construct algorithms that can reason about uncertainty and out-of-distribution values, since a naive optimizer can easily exploit an estimated model to return adversarial inputs. We propose to tackle the MBO problem by leveraging the normalized maximum-likelihood (NML) estimator, which provides a principled approach to handling uncertainty and out-of-distribution inputs. While in the standard formulation NML is intractable, we propose a tractable approximation that allows us to scale our method to high-capacity neural network models. We demonstrate that our method can effectively optimize high-dimensional design problems in a variety of disciplines such as chemistry, biology, and materials engineering.", "one-sentence_summary": "Offline, data-driven optimization using normalized maximum likelihood to produce robust function estimates.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "fu|offline_modelbased_optimization_via_normalized_maximum_likelihood_estimation", "pdf": "/pdf/4fc7d9a4093bc9bafddf46785cafda74e0be40ce.pdf", "venue": "ICLR 2021 Poster", "venueid": "ICLR.cc/2021/Conference", "_bibtex": "@inproceedings{\nfu2021offline,\ntitle={Offline Model-Based Optimization via Normalized Maximum Likelihood Estimation},\nauthor={Justin Fu and Sergey Levine},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=FmMKSO4e8JK}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "FmMKSO4e8JK", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper2157/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper2157/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper2157/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper2157/Authors|ICLR.cc/2021/Conference/Paper2157/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2157/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923851599, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper2157/-/Official_Comment"}}}, {"id": "5ckGtAKKEjM", "original": null, "number": 8, "cdate": 1605818827470, "ddate": null, "tcdate": 1605818827470, "tmdate": 1605818827470, "tddate": null, "forum": "FmMKSO4e8JK", "replyto": "-DQb-BnTgsd", "invitation": "ICLR.cc/2021/Conference/Paper2157/-/Official_Comment", "content": {"title": "Architecture presentation updated", "comment": "On the thermometer encoding:\n\nThank you for the clarifications. The quadrature + logistic distribution interpretation does seem to be a cleaner way to interpret the method, and we\u2019ve updated Section 4.2 to use this interpretation rather than the original thermometer encoding. The implementation of the method itself remains unchanged. This should better motivate the use of quantization as an approximation scheme to computing a full integral, and as you mentioned, shed some light into potential future ways to improve the method.\n\n> \u201cHow do the run times compare?\u201d\n\nTo provide some concrete runtime numbers, here are runtimes we obtained on AWS c5.large instances for the Superconductor task.\n\nOptimizing a forward ensemble of 40 networks directly took on average 0.11s / gradient step on x. Adding 5 steps of NML model optimization (this was the setting used in our results reported in Table 1 & 2) brings this cost up to 0.35s / gradient step. So, when using equivalent neural network architectures and ensemble sizes, NEMO takes roughly 3x longer due to the cost of additional model training per iteration. In total, we ran our experiments for 50k gradient steps, which took a bit under 5 hours for NEMO on the Superconductor task, although 50k steps was more than the number of steps we needed to reach convergence.\n\n> \u201cWhy were some of the Design-bench benchmark omitted? With the new results, I don't think the authors need to add them but I think the question is still relevant.\u201d\n\nWith the inclusion of the robotics tasks, all 6 tasks in the Design-bench benchmark are now included in Table 1 & 2.\n\nOverall, thank you for the numerous suggestions. We think the paper has been greatly improved by your (and other reviewer\u2019s) feedback.\n"}, "signatures": ["ICLR.cc/2021/Conference/Paper2157/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2157/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Offline Model-Based Optimization via Normalized Maximum Likelihood Estimation", "authorids": ["~Justin_Fu1", "~Sergey_Levine1"], "authors": ["Justin Fu", "Sergey Levine"], "keywords": ["model-based optimization", "normalized maximum likelihood"], "abstract": "In this work we consider data-driven optimization problems where one must maximize a function given only queries at a fixed set of points. This problem setting emerges in many domains where function evaluation is a complex and expensive process, such as in the design of materials, vehicles, or neural network architectures. Because the available data typically only covers a small manifold of the possible space of inputs, a principal challenge is to be able to construct algorithms that can reason about uncertainty and out-of-distribution values, since a naive optimizer can easily exploit an estimated model to return adversarial inputs. We propose to tackle the MBO problem by leveraging the normalized maximum-likelihood (NML) estimator, which provides a principled approach to handling uncertainty and out-of-distribution inputs. While in the standard formulation NML is intractable, we propose a tractable approximation that allows us to scale our method to high-capacity neural network models. We demonstrate that our method can effectively optimize high-dimensional design problems in a variety of disciplines such as chemistry, biology, and materials engineering.", "one-sentence_summary": "Offline, data-driven optimization using normalized maximum likelihood to produce robust function estimates.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "fu|offline_modelbased_optimization_via_normalized_maximum_likelihood_estimation", "pdf": "/pdf/4fc7d9a4093bc9bafddf46785cafda74e0be40ce.pdf", "venue": "ICLR 2021 Poster", "venueid": "ICLR.cc/2021/Conference", "_bibtex": "@inproceedings{\nfu2021offline,\ntitle={Offline Model-Based Optimization via Normalized Maximum Likelihood Estimation},\nauthor={Justin Fu and Sergey Levine},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=FmMKSO4e8JK}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "FmMKSO4e8JK", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper2157/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper2157/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper2157/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper2157/Authors|ICLR.cc/2021/Conference/Paper2157/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2157/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923851599, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper2157/-/Official_Comment"}}}, {"id": "-DQb-BnTgsd", "original": null, "number": 7, "cdate": 1605658727005, "ddate": null, "tcdate": 1605658727005, "tmdate": 1605659347204, "tddate": null, "forum": "FmMKSO4e8JK", "replyto": "ywD5v8EmqXc", "invitation": "ICLR.cc/2021/Conference/Paper2157/-/Official_Comment", "content": {"title": "Response follow up", "comment": "The detailed clarifications, the updated notation and additional results have made this a significantly stronger submission. I am pleased to see that authors appear to have invested a notable amount effort polishing this paper.\n\n### Notation\n\nNotation is significantly improved and makes the paper much easier to read. There doesn't appear to be any noteworthy notation issues remaining.\n\n### New experimental results\n\u00a0\n* The addition of GP-BO complement well the previous results and help appreciate previous results. \n* The addition of the mujoco results cover what I considered a major blind spot in the previous draft. These new results serve as a useful reference point which makes me more confident about the significance of the previous results. Furthermore, the mujoco results appears to support the claim that NEMO performs consistently well across tasks while other methods don't exhibit the same level of consistency. (The authors might want to render their best policy for hopper at some point. While it doesn't always payoff, the quirks of the mujoco simulator can be a great source of comical videos for talks, especially with a good optimization algorithm that can exploit them!)\n* I appreciate that the authors have added more ablation results. As a general statement, I find results like these to be much more likely to inspire future research ideas or other minor conceptual breakthroughs, even if these results don't necessarily fit nicely into the \"story\".\n\n### Thermometer\n\nFirst, I'd like to apologize for my choice of words which made my comment about thermometer encoding unconstructive at best. I should have caught that before submitting my initial review. What I should have said is that I was surprised by its introduction. I also believe I did a poor job expressing why so I will give it another go.\n\nGiven the presentation up until that point in the paper, I expected that the conditional probability density would be approximated by a family of parametric probability density functions where the parameters would come from the output of some NN, and the denominator of (2) would then be approximated using a discrete set of points covering Y, i.e., a form of quadrature approximation of the integral. What tripped me up was just how similar the proposed approach was to what I expected but derived using the ideas of discretization and thermometer encoding.\n\nThe authors should correct me if I'm wrong, but I believe that up until their assumption that $g(y) = y$ and other simplifications, the proposed method is equivalent to what I described when using a family of parametric logistic distribution with $\\sigma = 1$. I think what I found \"odd\" was more the motivation/derivation of the method than the resulting method itself.\n\nAlso, while I appreciate the addition of the softmax results, it was not my intention to suggest approximating that probability density with a softmax categorical distribution. I think the overall approach proposed by the authors is good and thought provoking. I appreciate papers that make you wonder what various extensions or generalization would look like and this was the case for me here.\n\nIf my claim that the proposed method is equivalent (or almost) to using a parametric probability density and taking a quadrature approximation of the integral, the authors might want to consider using those concepts to introduce their method. I believe it would make the presentation more intuitive for many readers as well as allow the use of theory and ideas from quadrature methods in follow up work.\n\nTo be clear, I'm writing this simply because I think it could improve this paper (provided I didn't misunderstand something, of course). The authors should feel free to opt for keeping the presentation as is. I consider the thermometer motivation to be sufficient and I don't believe changing it is necessary for publication.\n\n### Remaining questions\n\n* How do the run times compare?\n* Why were some of the Design-bench benchmark omitted? With the new results, I don't think the authors need to add them but I think the question is still relevant.\n\n### Misc comments and typo\n\n* Algorithm 2, \"for $x_t^m$ in $1 ... M$\", should this be 'for $m$ in $1 ... M$'? Given the other changes to the notation, I suspect this might be an accidental omission."}, "signatures": ["ICLR.cc/2021/Conference/Paper2157/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2157/AnonReviewer2"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Offline Model-Based Optimization via Normalized Maximum Likelihood Estimation", "authorids": ["~Justin_Fu1", "~Sergey_Levine1"], "authors": ["Justin Fu", "Sergey Levine"], "keywords": ["model-based optimization", "normalized maximum likelihood"], "abstract": "In this work we consider data-driven optimization problems where one must maximize a function given only queries at a fixed set of points. This problem setting emerges in many domains where function evaluation is a complex and expensive process, such as in the design of materials, vehicles, or neural network architectures. Because the available data typically only covers a small manifold of the possible space of inputs, a principal challenge is to be able to construct algorithms that can reason about uncertainty and out-of-distribution values, since a naive optimizer can easily exploit an estimated model to return adversarial inputs. We propose to tackle the MBO problem by leveraging the normalized maximum-likelihood (NML) estimator, which provides a principled approach to handling uncertainty and out-of-distribution inputs. While in the standard formulation NML is intractable, we propose a tractable approximation that allows us to scale our method to high-capacity neural network models. We demonstrate that our method can effectively optimize high-dimensional design problems in a variety of disciplines such as chemistry, biology, and materials engineering.", "one-sentence_summary": "Offline, data-driven optimization using normalized maximum likelihood to produce robust function estimates.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "fu|offline_modelbased_optimization_via_normalized_maximum_likelihood_estimation", "pdf": "/pdf/4fc7d9a4093bc9bafddf46785cafda74e0be40ce.pdf", "venue": "ICLR 2021 Poster", "venueid": "ICLR.cc/2021/Conference", "_bibtex": "@inproceedings{\nfu2021offline,\ntitle={Offline Model-Based Optimization via Normalized Maximum Likelihood Estimation},\nauthor={Justin Fu and Sergey Levine},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=FmMKSO4e8JK}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "FmMKSO4e8JK", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper2157/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper2157/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper2157/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper2157/Authors|ICLR.cc/2021/Conference/Paper2157/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2157/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923851599, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper2157/-/Official_Comment"}}}, {"id": "yKO8leLOtal", "original": null, "number": 6, "cdate": 1605586342967, "ddate": null, "tcdate": 1605586342967, "tmdate": 1605586342967, "tddate": null, "forum": "FmMKSO4e8JK", "replyto": "fpGZAusvPdJ", "invitation": "ICLR.cc/2021/Conference/Paper2157/-/Official_Comment", "content": {"title": "Author response to reviewer 3", "comment": "Thank you for your comments. We have clarified several points below, and please let us know if this addresses your concerns.\n\n> \u201cWhen sampling a batch of data points at each step of algorithm 1, is the sampling performed with or without replacements?\u201d\n\nSampling is done with replacement. The model training step is identical to minibatch optimization methods used in standard supervised learning.\n\n> \u201cWhat\u2019s the variance across the 16 random runs? Is the score of the best algorithm in the average performance across 16 random runs significantly different from the baseline algorithms?\u201d\n\nWe have updated Table 1 with standard deviations for all methods. The average score for NEMO is significantly higher than baselines for the Superconductor and newly added HopperController tasks, and is still competitive with state-of-the-art methods for the other tasks.\n\n> \u201cWhen estimating the CNML, what is the number of models in the experiments? Are the number of models differ from dataset to dataset? How to choose the number of models in practice?\u201d\n\nWe use one model per discretization bin. These values are reported in Appendix A.2.2. In practice, we found a value of 20-40 to perform quite well for the problems we tried, and we did not need to tune this hyperparameter.\n\n> \u201cSince the output y needs to be discretized in the NEMO algorithm, how difficult for the algorithm to scale when y is multivariate?\u201d\n\nBecause standard optimization problems generally deal with scalar valued objectives, we don\u2019t foresee the need to consider the case when y is multivariate in the context of optimization. However, multi-objective optimization would be a great direction to explore for future work, and it would interesting to see how NML could fit into the analysis of a Pareto frontier.\n"}, "signatures": ["ICLR.cc/2021/Conference/Paper2157/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2157/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Offline Model-Based Optimization via Normalized Maximum Likelihood Estimation", "authorids": ["~Justin_Fu1", "~Sergey_Levine1"], "authors": ["Justin Fu", "Sergey Levine"], "keywords": ["model-based optimization", "normalized maximum likelihood"], "abstract": "In this work we consider data-driven optimization problems where one must maximize a function given only queries at a fixed set of points. This problem setting emerges in many domains where function evaluation is a complex and expensive process, such as in the design of materials, vehicles, or neural network architectures. Because the available data typically only covers a small manifold of the possible space of inputs, a principal challenge is to be able to construct algorithms that can reason about uncertainty and out-of-distribution values, since a naive optimizer can easily exploit an estimated model to return adversarial inputs. We propose to tackle the MBO problem by leveraging the normalized maximum-likelihood (NML) estimator, which provides a principled approach to handling uncertainty and out-of-distribution inputs. While in the standard formulation NML is intractable, we propose a tractable approximation that allows us to scale our method to high-capacity neural network models. We demonstrate that our method can effectively optimize high-dimensional design problems in a variety of disciplines such as chemistry, biology, and materials engineering.", "one-sentence_summary": "Offline, data-driven optimization using normalized maximum likelihood to produce robust function estimates.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "fu|offline_modelbased_optimization_via_normalized_maximum_likelihood_estimation", "pdf": "/pdf/4fc7d9a4093bc9bafddf46785cafda74e0be40ce.pdf", "venue": "ICLR 2021 Poster", "venueid": "ICLR.cc/2021/Conference", "_bibtex": "@inproceedings{\nfu2021offline,\ntitle={Offline Model-Based Optimization via Normalized Maximum Likelihood Estimation},\nauthor={Justin Fu and Sergey Levine},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=FmMKSO4e8JK}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "FmMKSO4e8JK", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper2157/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper2157/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper2157/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper2157/Authors|ICLR.cc/2021/Conference/Paper2157/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2157/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923851599, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper2157/-/Official_Comment"}}}, {"id": "ywD5v8EmqXc", "original": null, "number": 5, "cdate": 1605586222365, "ddate": null, "tcdate": 1605586222365, "tmdate": 1605586222365, "tddate": null, "forum": "FmMKSO4e8JK", "replyto": "zubXksL0NPx", "invitation": "ICLR.cc/2021/Conference/Paper2157/-/Official_Comment", "content": {"title": "Author response to reviewer 2", "comment": "Thank you for your detailed feedback. We believe your main concerns are with the depth of empirical study and writing/notational issues in the paper. We have significantly expanded the experimental evaluation with additional ablation studies on the architecture choice and optimization parameters, as well as including BO baseline, and additional benchmarking tasks. Additionally, we have corrected typos and updated the writing in the paper using many of your suggestions. Please let us know if this addresses your concerns.\n\n> \"The current notation is often confusing and even ambiguous at times... I understand that notation preference is a very subjective thing so the authors should feel free to opt for something different, but I do think the notation needs to be improved.\"\n\nWe have clarified ambiguous notation regarding expectations, loop indices in the pseudocode, and functions in the updated paper according to your suggestions. X and Y now always refer to the input and output variables, each expectation is now explicitly defined with the variable it is taken over, and summations are defined with the domain. \n\n> \"Were comparisons with a simple approaches Bayesian optimization tried, e.g., Gaussian process?\"\n\nWe have included an additional Bayesian optimization baseline based on maximizing expected improvement on a Gaussian process posterior. We use an RBF kernel for the Superconductor task, and a dot-product kernel for the discrete GFP/Molecule tasks. \n\n> \"The \"thermometer encoding\" of the output seems like an odd choice, especially given how it is done here...  the o_int_ks are parameters for logistic distributions and the mean is optimized through the unnormalized probs by optimizing each o_int_k directly. Would this be a fair description of the approach? \"\n\nYour description is accurate - therefore we justified optimizing o_int_k directly by making a monotonicity argument, and optimizing the o_int_k simplifies the algorithm. However, we don\u2019t consider this an \u201codd\u201d choice since similar ideas have been applied previously - for example, the \u201cdiscretized logistic\u201d is used in works such as PixelCNN to convert a single scalar value into a categorical distribution.\n\nWe have included an additional ablation study regarding the architecture choice in Appendix A.3.2, comparing the \u201cthermometer\u201d approach to the perhaps more straightforward method of training a model to predict discretized values directly. The results overall favor the thermometer architecture choice in performance and reliability. However, note that this is largely an architectural implementation detail -- a discretization design would be nicer, it's often the case that getting good results with deep neural networks requires careful design decisions, and we wanted to describe our decisions in detail for the sake of reproducibility.\n\n> \"I don't think I understand what makes the appendix results an ablation study. From what I understand, these results only compare with the case where there is no learning of the model parameters. What are the models initialized to? Where does the data come into play?\"\n\nThe purpose of this ablation study was to measure the effect of using NML during optimization compared to optimizing a forward model directly.The models are initialized by pretraining on the dataset. Therefore, the difference between the two results is due to additional NML training. We have clarified this point in the appendix.\n\n> \"How can I know that the method isn't just exploiting some quirk in the learned models used to evaluate it while some of the other methods avoid doing this?\"\n\nIn order to provide a \u201cgrounded\u201d result, we have included additional results in the robotics domain from the Design-Bench benchmark. The designs in these tasks are evaluated in the MuJoCo simulator, and therefore high scores can be trusted to correspond to valid outputs. We find that the similar trends still hold true on these tasks - NEMO scores consistently high on each task.\n\nUnfortunately, it is difficult to gauge the validity of results on the material and molecule design tasks without synthesizing the outputs in real life. As discussed in Brookes et. al. 2019, the model class of the ground truth is a random forest and therefore belongs to a very different model class from the estimated function, and our model is trained on ground-truth values and not on the output of the random forest. Therefore, it is still a nontrivial problem to achieve high scores on these problems.\n\n> \"What happens when doing more iterations on the log likelihood before updating x?\"\n\nWe have included a more detailed study in the Appendix A.3.3, comparing the ratio of NML model learning steps to optimization steps on x. When the model learning rate is small, taking additional steps appears to strictly improve the convergence speed of the method (as measured by overall algorithm steps). However, as somewhat expected, taking too many steps with a large learning rate can cause some instabilities.\n"}, "signatures": ["ICLR.cc/2021/Conference/Paper2157/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2157/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Offline Model-Based Optimization via Normalized Maximum Likelihood Estimation", "authorids": ["~Justin_Fu1", "~Sergey_Levine1"], "authors": ["Justin Fu", "Sergey Levine"], "keywords": ["model-based optimization", "normalized maximum likelihood"], "abstract": "In this work we consider data-driven optimization problems where one must maximize a function given only queries at a fixed set of points. This problem setting emerges in many domains where function evaluation is a complex and expensive process, such as in the design of materials, vehicles, or neural network architectures. Because the available data typically only covers a small manifold of the possible space of inputs, a principal challenge is to be able to construct algorithms that can reason about uncertainty and out-of-distribution values, since a naive optimizer can easily exploit an estimated model to return adversarial inputs. We propose to tackle the MBO problem by leveraging the normalized maximum-likelihood (NML) estimator, which provides a principled approach to handling uncertainty and out-of-distribution inputs. While in the standard formulation NML is intractable, we propose a tractable approximation that allows us to scale our method to high-capacity neural network models. We demonstrate that our method can effectively optimize high-dimensional design problems in a variety of disciplines such as chemistry, biology, and materials engineering.", "one-sentence_summary": "Offline, data-driven optimization using normalized maximum likelihood to produce robust function estimates.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "fu|offline_modelbased_optimization_via_normalized_maximum_likelihood_estimation", "pdf": "/pdf/4fc7d9a4093bc9bafddf46785cafda74e0be40ce.pdf", "venue": "ICLR 2021 Poster", "venueid": "ICLR.cc/2021/Conference", "_bibtex": "@inproceedings{\nfu2021offline,\ntitle={Offline Model-Based Optimization via Normalized Maximum Likelihood Estimation},\nauthor={Justin Fu and Sergey Levine},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=FmMKSO4e8JK}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "FmMKSO4e8JK", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper2157/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper2157/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper2157/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper2157/Authors|ICLR.cc/2021/Conference/Paper2157/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2157/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923851599, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper2157/-/Official_Comment"}}}, {"id": "ptAfxVd8fsD", "original": null, "number": 4, "cdate": 1605585674847, "ddate": null, "tcdate": 1605585674847, "tmdate": 1605585674847, "tddate": null, "forum": "FmMKSO4e8JK", "replyto": "TBhMYJxLjnG", "invitation": "ICLR.cc/2021/Conference/Paper2157/-/Official_Comment", "content": {"title": "Author response to reviewer 1", "comment": "Thank you for the comments and feedback. Our overall impression from your review is that while the method is promising, the empirical study is not thorough enough to back our claims. Therefore, we have significantly expanded our evaluations according to your suggestions, and included a GP-based baseline, additional evaluations on new tasks, and ablation studies for justifying our design choices. Please let us know if this addresses your concerns, or if there are any further modifications you would like us to make.\n\n> \u201cMy question is why not directly compare your approach with a GP approach\u2026 Thus the problem presented in this work can be effectively solved through one step of conventional BO.\u201d\n\nYou are correct in that a Bayesian method such as a GP can be used to accurately measure uncertainty on out-of-distribution inputs in some cases (especially in low-dimensional tasks) and that one step of a method such as BO can be used to solve the offline MBO problem. We have included results for a GP-based method by selecting the design maximizing the expected improvement acquisition function. We use an RBF kernel for the continuous Superconductor task, and a dot-product kernel for the GFP and MoleculeActivity tasks, since they are discrete. \n\n> \u201cThe experimental results, in my opinion, are not sufficient and there is only one table presenting empirical results. I don't want to judge sufficiency by the quantity of tables or figures, but considering the theoretical analysis is not strong enough, I think more empirical study should be performed.\u201d\n\nIn order to strengthen the empirical analysis, we have included additional experimental results on a 3 robotics domains from the design-bench, where we see similar experimental trends hold true: NEMO consistently ranks among the top performing algorithms and on the HopperController task significantly outperforms prior methods. An additional benefit for these tasks are evaluated in the MuJoCo robotics simulator, and therefore we can be confident the designs are valid.\n\nTo justify our design choices, we have also included additional ablation studies on the choice of architecture (thermometer architecture vs standard feedforward architecture) and hyperparameter settings such as learning rates and number of optimization steps, included in Appendix A.3.\n\n> \u201cThe approach proposed in this paper seems very similiar with conformal prediction. In conformal prediction, the target value y* for a novel point x* (adversarial input) is chosen so that y* is compatible with the original dataset. \u201c\n\nThe connection with conformal prediction is an interesting one we were not aware of. It does seem like conformal prediction could be used in a similar manner to CNML, by providing per-instance confidence intervals that could prevent model exploitation. Additionally, the NML regret may have connections to conformity measures, as they both provide a measure of you close a datapoint is to the rest of the dataset. We think this could be an interesting connection to explore in future work, and could reveal additional theoretical insights on the algorithm. We have added a brief discussion of this to the related work (Section 2).\n\n> \u201cAs I am not familiar with the evaluation protocol in Brookles2019 and Fannjiang2020, the metric used in Table 1 is not clear to me. Can the authors say more about that?\u201d\n\nRegarding the metric in Table 1, we report max/median ground truth scores across a batch of 128 candidate designs output by the algorithm. The max score corresponds to what would commonly be done in practice - one would synthesize a batch of candidate designs and use the best performing one. We report the median to verify that most designs perform decently well, because some algorithms may get lucky on scoring a single high-performing design. In terms of physical units, the Superconductor task is reported in Kelvin, the Molecule task in IC50 scores, the GFP in log-fluorescence scores (see Sarkisyan et. al. 2016), and the remaining robotics task in rewards (derived via velocity) from the underlying reinforcement learning MDP.\n\n> \u201cIn Figure 3, although not a major concern, I don't think the comparison with the ensemble is fair\u2026 For example, to obtain a similar uncertainty estimation compared with NML (middle column), we can use a deep ensemble, which optimizes NLL instead of MSE.\u201d\n\nWe are indeed using NLL for both methods to keep the comparison fair. To be more specific, we discretized the output values, and the ensemble method predicts these using a softmax cross-entropy loss. We have updated Section 5.1 to clarify this.\n"}, "signatures": ["ICLR.cc/2021/Conference/Paper2157/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2157/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Offline Model-Based Optimization via Normalized Maximum Likelihood Estimation", "authorids": ["~Justin_Fu1", "~Sergey_Levine1"], "authors": ["Justin Fu", "Sergey Levine"], "keywords": ["model-based optimization", "normalized maximum likelihood"], "abstract": "In this work we consider data-driven optimization problems where one must maximize a function given only queries at a fixed set of points. This problem setting emerges in many domains where function evaluation is a complex and expensive process, such as in the design of materials, vehicles, or neural network architectures. Because the available data typically only covers a small manifold of the possible space of inputs, a principal challenge is to be able to construct algorithms that can reason about uncertainty and out-of-distribution values, since a naive optimizer can easily exploit an estimated model to return adversarial inputs. We propose to tackle the MBO problem by leveraging the normalized maximum-likelihood (NML) estimator, which provides a principled approach to handling uncertainty and out-of-distribution inputs. While in the standard formulation NML is intractable, we propose a tractable approximation that allows us to scale our method to high-capacity neural network models. We demonstrate that our method can effectively optimize high-dimensional design problems in a variety of disciplines such as chemistry, biology, and materials engineering.", "one-sentence_summary": "Offline, data-driven optimization using normalized maximum likelihood to produce robust function estimates.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "fu|offline_modelbased_optimization_via_normalized_maximum_likelihood_estimation", "pdf": "/pdf/4fc7d9a4093bc9bafddf46785cafda74e0be40ce.pdf", "venue": "ICLR 2021 Poster", "venueid": "ICLR.cc/2021/Conference", "_bibtex": "@inproceedings{\nfu2021offline,\ntitle={Offline Model-Based Optimization via Normalized Maximum Likelihood Estimation},\nauthor={Justin Fu and Sergey Levine},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=FmMKSO4e8JK}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "FmMKSO4e8JK", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper2157/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper2157/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper2157/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper2157/Authors|ICLR.cc/2021/Conference/Paper2157/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2157/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923851599, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper2157/-/Official_Comment"}}}], "count": 13}