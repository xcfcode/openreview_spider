{"notes": [{"id": "S1feL-4gr4", "original": "rklx8ZNxrE", "number": 1, "cdate": 1549971784409, "ddate": null, "tcdate": 1549971784409, "tmdate": 1562082110847, "tddate": null, "forum": "S1feL-4gr4", "replyto": null, "invitation": "ICLR.cc/2019/Workshop/LLD/-/Blind_Submission", "content": {"title": "Prototypical Metric Transfer Learning for Continuous Speech Keyword Spotting With Limited Training Data", "authors": ["Harshita Seth", "Pulkit Kumar", "Muktabh Mayank Srivastava"], "authorids": ["harshita@paralleldots.com", "pulkit@paralleldots.com", "muktabh@paralleldots.com"], "keywords": ["Audio keyword detection", "prototypical Metric Loss", "Few-shot", "Transfer Learning"], "abstract": "Continuous Speech Keyword Spotting (CSKS) is the problem of spotting keywords in recorded conversations, when a small number of instances of keywords are available in training data. Unlike the more common Keyword Spotting, where an algorithm needs to detect lone keywords or short phrases like \"Alexa\u201d, \u201cCortana\", \u201cHi Alexa!\u201d,  \u201c`Whatsup Octavia?\u201d etc. in speech, CSKS needs to filter out embedded words from a continuous flow of speech, ie. spot \u201cAnna\u201d and \u201cgithub\u201d in \u201cI know a developer named Anna who can look into this github issue.\u201d Apart from the issue of limited training data availability, CSKS is an extremely imbalanced classification problem. We address the limitations of simple keyword spotting baselines for both aforementioned challenges by using a novel combination of loss functions (Prototypical networks\u2019 loss and metric loss) and transfer learning. Our method improves F1 score by over 10%. ", "pdf": "/pdf/812d2b2c106ff7f4bb580dbeb03c2143d5dca114.pdf", "paperhash": "seth|prototypical_metric_transfer_learning_for_continuous_speech_keyword_spotting_with_limited_training_data"}, "signatures": ["ICLR.cc/2019/Workshop/LLD"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Workshop/LLD"], "details": {"replyCount": 3, "writable": false, "overwriting": [], "revisions": false, "tags": [], "invitation": {"id": "ICLR.cc/2019/Workshop/LLD/-/Blind_Submission", "cdate": 1548689671889, "reply": {"forum": null, "replyto": null, "readers": {"values-regex": ".*"}, "writers": {"values": ["ICLR.cc/2019/Workshop/LLD"]}, "signatures": {"values": ["ICLR.cc/2019/Workshop/LLD"]}, "content": {"authors": {"values-regex": ".*"}, "authorids": {"values-regex": ".*"}}}, "tcdate": 1548689671889, "tmdate": 1557933709646, "readers": ["everyone"], "writers": ["ICLR.cc/2019/Workshop/LLD"], "invitees": ["~"], "signatures": ["ICLR.cc/2019/Workshop/LLD"], "details": {"writable": true}}}, "tauthor": "ICLR.cc/2019/Workshop/LLD"}, {"id": "S1eDX4jC_E", "original": null, "number": 1, "cdate": 1554064415303, "ddate": null, "tcdate": 1554064415303, "tmdate": 1555512028757, "tddate": null, "forum": "S1feL-4gr4", "replyto": "S1feL-4gr4", "invitation": "ICLR.cc/2019/Workshop/LLD/-/Paper1/Official_Review", "content": {"title": "Reject", "review": "Summary:\nThe authors propose a method for detecting keywords in continuous speech given a limited number of training examples (120 for each keyword). A pre-trained ASR model is finetuned with a prototypical loss in conjunction with a metric loss. They find that their training method yields improved accuracy on an internal dataset.\n\nPros:\nConsidering the impact of continuous speech on keyword spotting is very important; I would go so far as to say that recognizing words spoken in isolation is not really keyword spotting. It's good to see that this is being considered in this paper.\n\nCons:\nThe claim that \"since the HMM techniques use Viterbi algorithms (computationally expensive) a faster approach is required\" is not well founded. This depends entirely on how many HMM states there are and how many possible states you can transition into. For example, Apple's \"Hey Siri\" detector runs the Viterbi algorithm on the outputs of a neural network for a super simple HMM where there are a small number of states and transitions are only allowed between the current phoneme and the next phoneme. They point out in their article about it that this part requires very little computation and almost all the computation is performed running the neural net (https://machinelearning.apple.com/2017/10/01/hey-siri.html).\n\nThe paper has a lot of stylistic bugs; consider the very second sentence: \"These spotted keyword frequencies can then be used to analyze theme of communication, creating temporal visualizations and word clouds clouds (2019).\" This type of thing happens all through the paper.\n\nWeird, unnecessary details like \"the python code of the model was taken from the open source repository of Convolutional Neural Networks for Keyword Spotting\" are included. Unless you plan to release your code (?), this isn't really relevant.\n\nThe experiments are run only on an internal dataset, so it's impossible to replicate this paper.", "rating": "1: Strong rejection", "confidence": "2: The reviewer is fairly confident that the evaluation is correct"}, "signatures": ["ICLR.cc/2019/Workshop/LLD/Paper1/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Workshop/LLD/Paper1/AnonReviewer2"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Prototypical Metric Transfer Learning for Continuous Speech Keyword Spotting With Limited Training Data", "authors": ["Harshita Seth", "Pulkit Kumar", "Muktabh Mayank Srivastava"], "authorids": ["harshita@paralleldots.com", "pulkit@paralleldots.com", "muktabh@paralleldots.com"], "keywords": ["Audio keyword detection", "prototypical Metric Loss", "Few-shot", "Transfer Learning"], "abstract": "Continuous Speech Keyword Spotting (CSKS) is the problem of spotting keywords in recorded conversations, when a small number of instances of keywords are available in training data. Unlike the more common Keyword Spotting, where an algorithm needs to detect lone keywords or short phrases like \"Alexa\u201d, \u201cCortana\", \u201cHi Alexa!\u201d,  \u201c`Whatsup Octavia?\u201d etc. in speech, CSKS needs to filter out embedded words from a continuous flow of speech, ie. spot \u201cAnna\u201d and \u201cgithub\u201d in \u201cI know a developer named Anna who can look into this github issue.\u201d Apart from the issue of limited training data availability, CSKS is an extremely imbalanced classification problem. We address the limitations of simple keyword spotting baselines for both aforementioned challenges by using a novel combination of loss functions (Prototypical networks\u2019 loss and metric loss) and transfer learning. Our method improves F1 score by over 10%. ", "pdf": "/pdf/812d2b2c106ff7f4bb580dbeb03c2143d5dca114.pdf", "paperhash": "seth|prototypical_metric_transfer_learning_for_continuous_speech_keyword_spotting_with_limited_training_data"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Workshop/LLD/-/Paper1/Official_Review", "cdate": 1553713422555, "expdate": 1555718400000, "duedate": 1554681600000, "reply": {"forum": "S1feL-4gr4", "replyto": "S1feL-4gr4", "writers": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2019/Workshop/LLD/Paper1/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2019/Workshop/LLD/Paper1/AnonReviewer[0-9]+"}, "readers": {"values": ["everyone"], "description": "The users who will be allowed to read the above content."}, "content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "required": true}, "rating": {"order": 3, "value-dropdown": ["5: Top 15% of accepted papers, strong accept", "4: Top 50% of accepted papers, clear accept", "3: Marginally above acceptance threshold", "2: Marginally below acceptance threshold", "1: Strong rejection"], "required": true}, "confidence": {"order": 4, "value-radio": ["3: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "2: The reviewer is fairly confident that the evaluation is correct", "1: The reviewer's evaluation is an educated guess"], "required": true}}}, "tcdate": 1553713422555, "tmdate": 1555511820159, "readers": ["everyone"], "writers": ["ICLR.cc/2019/Workshop/LLD"], "invitees": ["ICLR.cc/2019/Workshop/LLD/Paper1/Reviewers"], "signatures": ["ICLR.cc/2019/Workshop/LLD"]}}}, {"id": "Skl5UDd_tV", "original": null, "number": 2, "cdate": 1554708305700, "ddate": null, "tcdate": 1554708305700, "tmdate": 1555511884043, "tddate": null, "forum": "S1feL-4gr4", "replyto": "S1feL-4gr4", "invitation": "ICLR.cc/2019/Workshop/LLD/-/Paper1/Official_Review", "content": {"title": "Good starting point, but needs more clarification", "review": "The task and method used for this paper seem quite promising, and the general task has broad applications as discussed in the paper and background sections. However, the paper seemed to trail off quickly after the first page, and the experiments section ended suddently. With some restructuring of the focus of the text to highlight the actual experiments and results, this paper could be much improved.\n\nDetails on the experiments were fairly limited - more discussion of the feature based frontend (were there standard delta and double delta with the mel, or only base mel?) and even some of the examples of the keywords in context would improve the work.\n\nRebalancing this work to include a more detailed analysis of the experiments, and reducing or minimizing the first page or so of content would be very helpful. As it stands, the experimental section is basically just the table, having more discussion of that result, and less of the surrounding description of the models, architecture and background would have been better in this 4 page format. \n\nIf the results are the focus of the paper, there should also be some testing done on standard benchmarks rather than only demonstrations on this custom dataset. If the focus is on the new dataset, there should be more discussion of the dataset structure, keywords, and some more exploratory analysis of the overall setting in order to motivate why the dataset is special, or different from standard benchmarks.\n", "rating": "2: Marginally below acceptance threshold", "confidence": "3: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}, "signatures": ["ICLR.cc/2019/Workshop/LLD/Paper1/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Workshop/LLD/Paper1/AnonReviewer1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Prototypical Metric Transfer Learning for Continuous Speech Keyword Spotting With Limited Training Data", "authors": ["Harshita Seth", "Pulkit Kumar", "Muktabh Mayank Srivastava"], "authorids": ["harshita@paralleldots.com", "pulkit@paralleldots.com", "muktabh@paralleldots.com"], "keywords": ["Audio keyword detection", "prototypical Metric Loss", "Few-shot", "Transfer Learning"], "abstract": "Continuous Speech Keyword Spotting (CSKS) is the problem of spotting keywords in recorded conversations, when a small number of instances of keywords are available in training data. Unlike the more common Keyword Spotting, where an algorithm needs to detect lone keywords or short phrases like \"Alexa\u201d, \u201cCortana\", \u201cHi Alexa!\u201d,  \u201c`Whatsup Octavia?\u201d etc. in speech, CSKS needs to filter out embedded words from a continuous flow of speech, ie. spot \u201cAnna\u201d and \u201cgithub\u201d in \u201cI know a developer named Anna who can look into this github issue.\u201d Apart from the issue of limited training data availability, CSKS is an extremely imbalanced classification problem. We address the limitations of simple keyword spotting baselines for both aforementioned challenges by using a novel combination of loss functions (Prototypical networks\u2019 loss and metric loss) and transfer learning. Our method improves F1 score by over 10%. ", "pdf": "/pdf/812d2b2c106ff7f4bb580dbeb03c2143d5dca114.pdf", "paperhash": "seth|prototypical_metric_transfer_learning_for_continuous_speech_keyword_spotting_with_limited_training_data"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Workshop/LLD/-/Paper1/Official_Review", "cdate": 1553713422555, "expdate": 1555718400000, "duedate": 1554681600000, "reply": {"forum": "S1feL-4gr4", "replyto": "S1feL-4gr4", "writers": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2019/Workshop/LLD/Paper1/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2019/Workshop/LLD/Paper1/AnonReviewer[0-9]+"}, "readers": {"values": ["everyone"], "description": "The users who will be allowed to read the above content."}, "content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "required": true}, "rating": {"order": 3, "value-dropdown": ["5: Top 15% of accepted papers, strong accept", "4: Top 50% of accepted papers, clear accept", "3: Marginally above acceptance threshold", "2: Marginally below acceptance threshold", "1: Strong rejection"], "required": true}, "confidence": {"order": 4, "value-radio": ["3: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "2: The reviewer is fairly confident that the evaluation is correct", "1: The reviewer's evaluation is an educated guess"], "required": true}}}, "tcdate": 1553713422555, "tmdate": 1555511820159, "readers": ["everyone"], "writers": ["ICLR.cc/2019/Workshop/LLD"], "invitees": ["ICLR.cc/2019/Workshop/LLD/Paper1/Reviewers"], "signatures": ["ICLR.cc/2019/Workshop/LLD"]}}}, {"id": "rJx9fSJtYE", "original": null, "number": 1, "cdate": 1554736402365, "ddate": null, "tcdate": 1554736402365, "tmdate": 1555510988469, "tddate": null, "forum": "S1feL-4gr4", "replyto": "S1feL-4gr4", "invitation": "ICLR.cc/2019/Workshop/LLD/-/Paper1/Decision", "content": {"title": "Acceptance Decision", "decision": "Reject"}, "signatures": ["ICLR.cc/2019/Workshop/LLD/Program_Chairs"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Workshop/LLD/Program_Chairs"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Prototypical Metric Transfer Learning for Continuous Speech Keyword Spotting With Limited Training Data", "authors": ["Harshita Seth", "Pulkit Kumar", "Muktabh Mayank Srivastava"], "authorids": ["harshita@paralleldots.com", "pulkit@paralleldots.com", "muktabh@paralleldots.com"], "keywords": ["Audio keyword detection", "prototypical Metric Loss", "Few-shot", "Transfer Learning"], "abstract": "Continuous Speech Keyword Spotting (CSKS) is the problem of spotting keywords in recorded conversations, when a small number of instances of keywords are available in training data. Unlike the more common Keyword Spotting, where an algorithm needs to detect lone keywords or short phrases like \"Alexa\u201d, \u201cCortana\", \u201cHi Alexa!\u201d,  \u201c`Whatsup Octavia?\u201d etc. in speech, CSKS needs to filter out embedded words from a continuous flow of speech, ie. spot \u201cAnna\u201d and \u201cgithub\u201d in \u201cI know a developer named Anna who can look into this github issue.\u201d Apart from the issue of limited training data availability, CSKS is an extremely imbalanced classification problem. We address the limitations of simple keyword spotting baselines for both aforementioned challenges by using a novel combination of loss functions (Prototypical networks\u2019 loss and metric loss) and transfer learning. Our method improves F1 score by over 10%. ", "pdf": "/pdf/812d2b2c106ff7f4bb580dbeb03c2143d5dca114.pdf", "paperhash": "seth|prototypical_metric_transfer_learning_for_continuous_speech_keyword_spotting_with_limited_training_data"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Workshop/LLD/-/Paper1/Decision", "cdate": 1554736071445, "reply": {"forum": "S1feL-4gr4", "replyto": "S1feL-4gr4", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-regex": ["ICLR.cc/2019/Workshop/LLD/Program_Chairs"], "description": "How your identity will be displayed."}, "signatures": {"values": ["ICLR.cc/2019/Workshop/LLD/Program_Chairs"], "description": "How your identity will be displayed."}, "content": {"title": {"order": 1, "required": true, "value": "Acceptance Decision"}, "decision": {"order": 2, "required": true, "value-radio": ["Accept", "Reject"], "description": "Acceptance decision"}, "comment": {"order": 3, "required": false, "value-regex": "[\\S\\s]{0,5000}", "description": ""}}}, "tcdate": 1554736071445, "tmdate": 1555510967369, "readers": ["everyone"], "writers": ["ICLR.cc/2019/Workshop/LLD"], "invitees": ["ICLR.cc/2019/Workshop/LLD/Program_Chairs"], "signatures": ["ICLR.cc/2019/Workshop/LLD"]}}}], "count": 4}