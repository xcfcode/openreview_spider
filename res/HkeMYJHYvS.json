{"notes": [{"id": "HkeMYJHYvS", "original": "B1eFVNAuvS", "number": 1833, "cdate": 1569439610190, "ddate": null, "tcdate": 1569439610190, "tmdate": 1577168257065, "tddate": null, "forum": "HkeMYJHYvS", "replyto": null, "invitation": "ICLR.cc/2020/Conference/-/Blind_Submission", "content": {"authorids": ["vsr.veera@gmail.com", "deepak.mittal@verisk.com", "abhishek.goel@verisk.com", "maneesh.singh@verisk.com"], "title": "High-Frequency guided Curriculum Learning for Class-specific Object Boundary Detection", "authors": ["VSR Veeravasarapu", "Deepak Mittal", "Abhishek Goel", "Maneesh Singh"], "pdf": "/pdf/1392ab62dba3286d645f05ff6c47d2d174807612.pdf", "TL;DR": "This work proposes a novel ConvNet architecture and a two-stage training scheme for class-specific object boundary estimation with improved performance levels.", "abstract": "This work addresses class-specific object boundary extraction, i.e., retrieving boundary pixels that belong to a class of objects in the given image. Although recent ConvNet-based approaches demonstrate impressive results, we notice that they produce several false-alarms and misdetections when used in real-world applications. We hypothesize that although boundary detection is simple at some pixels that are rooted in identifiable high-frequency locations, other pixels pose a higher level of difficulties, for instance, region pixels with an appearance similar to the boundaries; or boundary pixels with insignificant edge strengths. Therefore, the training process needs to account for different levels of learning complexity in different regions to overcome false alarms. In this work, we devise a curriculum-learning-based training process for object boundary detection. This multi-stage training process first trains the network at simpler pixels (with sufficient edge strengths) and then at harder pixels in the later stages of the curriculum.  We also propose a novel system for object boundary detection that relies on a fully convolutional neural network (FCN) and wavelet decomposition of image frequencies.  This system uses high-frequency bands from the wavelet pyramid and augments them to conv features from different layers of FCN. Our ablation studies with contourMNIST dataset, a simulated digit contours from MNIST, demonstrate that this explicit high-frequency augmentation helps the model to converge faster. Our model trained by the proposed curriculum scheme outperforms a state-of-the-art object boundary detection method by a significant margin on a challenging aerial image dataset.  \n", "keywords": ["Computer Vision", "Object Contour Detection", "Curriculum Learning", "Wavelets", "Aerial Imagery"], "paperhash": "veeravasarapu|highfrequency_guided_curriculum_learning_for_classspecific_object_boundary_detection", "original_pdf": "/attachment/1392ab62dba3286d645f05ff6c47d2d174807612.pdf", "_bibtex": "@misc{\nveeravasarapu2020highfrequency,\ntitle={High-Frequency guided Curriculum Learning for Class-specific Object Boundary Detection},\nauthor={VSR Veeravasarapu and Deepak Mittal and Abhishek Goel and Maneesh Singh},\nyear={2020},\nurl={https://openreview.net/forum?id=HkeMYJHYvS}\n}"}, "signatures": ["ICLR.cc/2020/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference"], "details": {"replyCount": 4, "writable": false, "overwriting": [], "revisions": false, "tags": [], "invitation": {"reply": {"readers": {"values-regex": ".*"}, "writers": {"values": ["ICLR.cc/2020/Conference"]}, "signatures": {"values": ["ICLR.cc/2020/Conference"]}, "content": {"spotlight_video": {"value-regex": ".*"}, "full_presentation_video": {"value-regex": ".*"}, "original_pdf": {"required": false, "description": "Upload a PDF file that ends with .pdf", "value-regex": ".*"}, "appendix": {"value-regex": ".*"}, "authorids": {"values-regex": ".*"}, "poster": {"value-regex": ".*"}, "authors": {"values": ["Anonymous"]}, "slides": {"value-regex": ".*"}}}, "final": [], "signatures": ["ICLR.cc/2020/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference"], "noninvitees": [], "tcdate": 1569271260237, "tmdate": 1593459412141, "id": "ICLR.cc/2020/Conference/-/Blind_Submission"}}, "tauthor": "OpenReview.net"}, {"id": "UAfCAtXDUk", "original": null, "number": 1, "cdate": 1576798733614, "ddate": null, "tcdate": 1576798733614, "tmdate": 1576800902819, "tddate": null, "forum": "HkeMYJHYvS", "replyto": "HkeMYJHYvS", "invitation": "ICLR.cc/2020/Conference/Paper1833/-/Decision", "content": {"decision": "Reject", "comment": "This paper received all negative reviewers, and the scores were kept after the rebuttal. The authors are encouraged to submit their work to a computer vision conference where this kind of work may be more appreciated. Furthermore, including stronger baselines such as Acuna et al is recommended.", "title": "Paper Decision"}, "signatures": ["ICLR.cc/2020/Conference/Program_Chairs"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Program_Chairs"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["vsr.veera@gmail.com", "deepak.mittal@verisk.com", "abhishek.goel@verisk.com", "maneesh.singh@verisk.com"], "title": "High-Frequency guided Curriculum Learning for Class-specific Object Boundary Detection", "authors": ["VSR Veeravasarapu", "Deepak Mittal", "Abhishek Goel", "Maneesh Singh"], "pdf": "/pdf/1392ab62dba3286d645f05ff6c47d2d174807612.pdf", "TL;DR": "This work proposes a novel ConvNet architecture and a two-stage training scheme for class-specific object boundary estimation with improved performance levels.", "abstract": "This work addresses class-specific object boundary extraction, i.e., retrieving boundary pixels that belong to a class of objects in the given image. Although recent ConvNet-based approaches demonstrate impressive results, we notice that they produce several false-alarms and misdetections when used in real-world applications. We hypothesize that although boundary detection is simple at some pixels that are rooted in identifiable high-frequency locations, other pixels pose a higher level of difficulties, for instance, region pixels with an appearance similar to the boundaries; or boundary pixels with insignificant edge strengths. Therefore, the training process needs to account for different levels of learning complexity in different regions to overcome false alarms. In this work, we devise a curriculum-learning-based training process for object boundary detection. This multi-stage training process first trains the network at simpler pixels (with sufficient edge strengths) and then at harder pixels in the later stages of the curriculum.  We also propose a novel system for object boundary detection that relies on a fully convolutional neural network (FCN) and wavelet decomposition of image frequencies.  This system uses high-frequency bands from the wavelet pyramid and augments them to conv features from different layers of FCN. Our ablation studies with contourMNIST dataset, a simulated digit contours from MNIST, demonstrate that this explicit high-frequency augmentation helps the model to converge faster. Our model trained by the proposed curriculum scheme outperforms a state-of-the-art object boundary detection method by a significant margin on a challenging aerial image dataset.  \n", "keywords": ["Computer Vision", "Object Contour Detection", "Curriculum Learning", "Wavelets", "Aerial Imagery"], "paperhash": "veeravasarapu|highfrequency_guided_curriculum_learning_for_classspecific_object_boundary_detection", "original_pdf": "/attachment/1392ab62dba3286d645f05ff6c47d2d174807612.pdf", "_bibtex": "@misc{\nveeravasarapu2020highfrequency,\ntitle={High-Frequency guided Curriculum Learning for Class-specific Object Boundary Detection},\nauthor={VSR Veeravasarapu and Deepak Mittal and Abhishek Goel and Maneesh Singh},\nyear={2020},\nurl={https://openreview.net/forum?id=HkeMYJHYvS}\n}"}, "tags": [], "invitation": {"reply": {"writers": {"description": "How your identity will be displayed.", "values-regex": ["ICLR.cc/2020/Conference/Program_Chairs"]}, "signatures": {"values": ["ICLR.cc/2020/Conference/Program_Chairs"], "description": "How your identity will be displayed."}, "content": {"decision": {"value-radio": ["Accept (Spotlight)", "Accept (Talk)", "Accept (Poster)", "Reject"], "description": "Decision", "required": true, "order": 2}, "title": {"value": "Paper Decision", "required": true, "order": 1}, "comment": {"value-regex": "[\\S\\s]{0,5000}", "description": "", "required": false, "order": 3}}, "forum": "HkeMYJHYvS", "replyto": "HkeMYJHYvS", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}}, "expdate": 1576854540000, "duedate": 1576853940000, "multiReply": false, "readers": ["everyone"], "invitees": ["ICLR.cc/2020/Conference/Program_Chairs"], "tcdate": 1576795726106, "tmdate": 1576800278160, "super": "ICLR.cc/2020/Conference/-/Decision", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper1833/-/Decision"}}}, {"id": "rkgtgQXRYB", "original": null, "number": 1, "cdate": 1571857137149, "ddate": null, "tcdate": 1571857137149, "tmdate": 1572972417820, "tddate": null, "forum": "HkeMYJHYvS", "replyto": "HkeMYJHYvS", "invitation": "ICLR.cc/2020/Conference/Paper1833/-/Official_Review", "content": {"experience_assessment": "I have published one or two papers in this area.", "rating": "1: Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #2", "review_assessment:_checking_correctness_of_derivations_and_theory": "N/A", "review": "Summary: The suggest two improvements to boundary detection models: (1) a curriculum learning approach, and (2) augmenting CNNs with features derived from a wavelet transform. For (1), they train half of the epochs with a target boundary that is the intersection between a Canny edge filter and the dilated groundtruth. The second half of epochs is with the normal groundtruth. For (2), they compute multiscale wavelet transforms, and combine it with each scale of CNN features. They find on a toy MNIST example that the wavelet transform doesn\u2019t impact results very much and curriculum learning seems to provide some gains. On the Aerial Road Contours dataset, they find an improvement of ~15% mAP over the prior baseline (CASENet).\n\nI have several concerns with this work:\n* The idea of using wavelet transforms to augment CNNs has been more thoroughly explored in prior work (e.g., see [1]).\n* No comparison to existing SOTA segmentation models (e.g., [2]). These semantic / instance segmentation models can easily be adapted to the task of boundary detection. I suspect the baseline here is weak.\n* Section 6 is severely unfinished. The explanation is sparse and there are no quantitative results -- just the output of the model overlaid on one example.\n* The choice of curriculum learning task is arbitrary, and there are no ablations explaining why this is a reasonable task. For example, what about random subsets of pixels? At the moment, it offers no insight for practitioners.\n* There are no ablations for the Aerial Road Contours experiments. This seems necessary because it is the only realistic dataset evaluated in this work. The MNIST experimental results appear qualitatively different from the Contours experiment. For example, they show that wavelet features do not make much of a difference, but does it make a difference for Contours?\n\nAltogether, this work unfortunately offers few insights to vision practitioners, let alone general practitioners. Substantial work needs to be devoted to expanding experimental coverage. \n\n[1] Wavelet Convolutional Neural Networks. Shin Fujieda, Kohei Takayama, Toshiya Hachisuka\n[2] TensorMask: A Foundation for Dense Object Segmentation. Xinlei Chen, Ross Girshick, Kaiming He, Piotr Doll\u00e1r"}, "signatures": ["ICLR.cc/2020/Conference/Paper1833/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1833/AnonReviewer2"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["vsr.veera@gmail.com", "deepak.mittal@verisk.com", "abhishek.goel@verisk.com", "maneesh.singh@verisk.com"], "title": "High-Frequency guided Curriculum Learning for Class-specific Object Boundary Detection", "authors": ["VSR Veeravasarapu", "Deepak Mittal", "Abhishek Goel", "Maneesh Singh"], "pdf": "/pdf/1392ab62dba3286d645f05ff6c47d2d174807612.pdf", "TL;DR": "This work proposes a novel ConvNet architecture and a two-stage training scheme for class-specific object boundary estimation with improved performance levels.", "abstract": "This work addresses class-specific object boundary extraction, i.e., retrieving boundary pixels that belong to a class of objects in the given image. Although recent ConvNet-based approaches demonstrate impressive results, we notice that they produce several false-alarms and misdetections when used in real-world applications. We hypothesize that although boundary detection is simple at some pixels that are rooted in identifiable high-frequency locations, other pixels pose a higher level of difficulties, for instance, region pixels with an appearance similar to the boundaries; or boundary pixels with insignificant edge strengths. Therefore, the training process needs to account for different levels of learning complexity in different regions to overcome false alarms. In this work, we devise a curriculum-learning-based training process for object boundary detection. This multi-stage training process first trains the network at simpler pixels (with sufficient edge strengths) and then at harder pixels in the later stages of the curriculum.  We also propose a novel system for object boundary detection that relies on a fully convolutional neural network (FCN) and wavelet decomposition of image frequencies.  This system uses high-frequency bands from the wavelet pyramid and augments them to conv features from different layers of FCN. Our ablation studies with contourMNIST dataset, a simulated digit contours from MNIST, demonstrate that this explicit high-frequency augmentation helps the model to converge faster. Our model trained by the proposed curriculum scheme outperforms a state-of-the-art object boundary detection method by a significant margin on a challenging aerial image dataset.  \n", "keywords": ["Computer Vision", "Object Contour Detection", "Curriculum Learning", "Wavelets", "Aerial Imagery"], "paperhash": "veeravasarapu|highfrequency_guided_curriculum_learning_for_classspecific_object_boundary_detection", "original_pdf": "/attachment/1392ab62dba3286d645f05ff6c47d2d174807612.pdf", "_bibtex": "@misc{\nveeravasarapu2020highfrequency,\ntitle={High-Frequency guided Curriculum Learning for Class-specific Object Boundary Detection},\nauthor={VSR Veeravasarapu and Deepak Mittal and Abhishek Goel and Maneesh Singh},\nyear={2020},\nurl={https://openreview.net/forum?id=HkeMYJHYvS}\n}"}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "HkeMYJHYvS", "replyto": "HkeMYJHYvS", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper1833/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper1833/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1575333459404, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper1833/Reviewers"], "noninvitees": [], "tcdate": 1570237731645, "tmdate": 1575333459415, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper1833/-/Official_Review"}}}, {"id": "Bkx3Oy1VqB", "original": null, "number": 2, "cdate": 1572233076355, "ddate": null, "tcdate": 1572233076355, "tmdate": 1572972417776, "tddate": null, "forum": "HkeMYJHYvS", "replyto": "HkeMYJHYvS", "invitation": "ICLR.cc/2020/Conference/Paper1833/-/Official_Review", "content": {"experience_assessment": "I have published in this field for several years.", "rating": "1: Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #1", "review_assessment:_checking_correctness_of_derivations_and_theory": "I carefully checked the derivations and theory.", "review": "The main idea of the paper is adding a curriculum learning-based extension to CASEnet, a boundary detection method from 2017. In the first phase, the loss emphasizes easier examples with high gradient in the image, and in the second phase, the method is trained on all boundary pixels. This change seems to improve edge detection performance on a toy MNIST and an aerial dataset. \n\nA second innovation claimed by the authors is adding Wavelet decomposition-based processing into the net. Unfortunately, this mostly only speeds up learning, as the ablation does not show meaningful improvements relative to the error bounds in later stages of training. Furthermore, the paper lacks a discussion of related work on incorporating wavelet ideas into neural networks. For example: \n-- Generic Deep Networks with Wavelet Scattering, by Ouyallon et al. \n-- Invariant scattering convolution networks, by Bruna et al \nand multiple more recent ones. Without either clear performance gains or more in-depth discussion of this novelty, it is not clear how to take it into account. \n\nWhen reading the paper, it appears that \"boundary detection\" for the cases that the authors are exploring is very directly related to 2-class semantic segmentation (road / non-road), the only difference being that the edge boundaries are weighted much higher in the cross-entropy loss. As such, there is a lot more recent net architecture work for semantic segmentation that should be directly applicable, and should perform much better than CaseNet when adapted to the task. As a result, the experiments and the significance of this paper are rather marginal. \n\nIn experimental results, the authors threshold prediction with 0.5, which is suboptimal. The resulting metric, which is just \"accuracy\" is called incorrectly \"average precision\". Instead, true definition of average precision should be used, that is not dependent on potentially suboptimal fixed thresholding but on the area under precision-recall curve instead. Finally, it would be helpful to do ablation and confidence bounds also on the main aerial road results, as the 15% gain is significantly more than the gain that appears in the toy dataset. "}, "signatures": ["ICLR.cc/2020/Conference/Paper1833/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1833/AnonReviewer1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["vsr.veera@gmail.com", "deepak.mittal@verisk.com", "abhishek.goel@verisk.com", "maneesh.singh@verisk.com"], "title": "High-Frequency guided Curriculum Learning for Class-specific Object Boundary Detection", "authors": ["VSR Veeravasarapu", "Deepak Mittal", "Abhishek Goel", "Maneesh Singh"], "pdf": "/pdf/1392ab62dba3286d645f05ff6c47d2d174807612.pdf", "TL;DR": "This work proposes a novel ConvNet architecture and a two-stage training scheme for class-specific object boundary estimation with improved performance levels.", "abstract": "This work addresses class-specific object boundary extraction, i.e., retrieving boundary pixels that belong to a class of objects in the given image. Although recent ConvNet-based approaches demonstrate impressive results, we notice that they produce several false-alarms and misdetections when used in real-world applications. We hypothesize that although boundary detection is simple at some pixels that are rooted in identifiable high-frequency locations, other pixels pose a higher level of difficulties, for instance, region pixels with an appearance similar to the boundaries; or boundary pixels with insignificant edge strengths. Therefore, the training process needs to account for different levels of learning complexity in different regions to overcome false alarms. In this work, we devise a curriculum-learning-based training process for object boundary detection. This multi-stage training process first trains the network at simpler pixels (with sufficient edge strengths) and then at harder pixels in the later stages of the curriculum.  We also propose a novel system for object boundary detection that relies on a fully convolutional neural network (FCN) and wavelet decomposition of image frequencies.  This system uses high-frequency bands from the wavelet pyramid and augments them to conv features from different layers of FCN. Our ablation studies with contourMNIST dataset, a simulated digit contours from MNIST, demonstrate that this explicit high-frequency augmentation helps the model to converge faster. Our model trained by the proposed curriculum scheme outperforms a state-of-the-art object boundary detection method by a significant margin on a challenging aerial image dataset.  \n", "keywords": ["Computer Vision", "Object Contour Detection", "Curriculum Learning", "Wavelets", "Aerial Imagery"], "paperhash": "veeravasarapu|highfrequency_guided_curriculum_learning_for_classspecific_object_boundary_detection", "original_pdf": "/attachment/1392ab62dba3286d645f05ff6c47d2d174807612.pdf", "_bibtex": "@misc{\nveeravasarapu2020highfrequency,\ntitle={High-Frequency guided Curriculum Learning for Class-specific Object Boundary Detection},\nauthor={VSR Veeravasarapu and Deepak Mittal and Abhishek Goel and Maneesh Singh},\nyear={2020},\nurl={https://openreview.net/forum?id=HkeMYJHYvS}\n}"}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "HkeMYJHYvS", "replyto": "HkeMYJHYvS", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper1833/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper1833/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1575333459404, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper1833/Reviewers"], "noninvitees": [], "tcdate": 1570237731645, "tmdate": 1575333459415, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper1833/-/Official_Review"}}}, {"id": "r1grXbxL5H", "original": null, "number": 3, "cdate": 1572368669003, "ddate": null, "tcdate": 1572368669003, "tmdate": 1572972417730, "tddate": null, "forum": "HkeMYJHYvS", "replyto": "HkeMYJHYvS", "invitation": "ICLR.cc/2020/Conference/Paper1833/-/Official_Review", "content": {"experience_assessment": "I have read many papers in this area.", "rating": "3: Weak Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #3", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "The paper shows the efficiency of curriculum learning and using problem specific features for contour detection.\n\nThe authors consider a network trained for class-specific edge detection (e.g. outlining edges of roads in an image). They propose two problem domain tricks to improve the performance:\n- use curriculum learning by training the network to first detect the \"easy\" edges, i.e. edges found also using the Canny edge detector\n- add high frequency wavelet coefficients as additional feature maps to the convnet.\n\nThe two techniques prove important on two tasks:\n- modified MNIST edge detection\n- road boundary detection in aerial imaginery.\n\nMaybe the most important aspect of the paper is that shows that with little data (the real world aerial imaginary dataset had only 11 labeled tiles) manual feature engineering and smart cost function selection are still relevant. \nSince this is a common pattern in many application domains, such as specialized medical image processing where labeled data is scarce, the paper is important. However, it is not clear if the proposed chanes are needed when more labeled data is available and how much do they overfit to the small test set.\n\nThe paper could be strengthened by analysing the impact of the proposed problem-dependent CL and features versus the amount of available training data. Are they still relevant with 100 labeled images?\nThese experiments could be even run on the artificial MNIST set.\n\nMoreover, some analysis of result significance is needed. On the real-world dataset there is only 1 test case!! How much was the network tuned to properly work on it? Maybe the authors can run a  cross-validation to show that the results don't overfit to this one test image?\n\nMinor remarks: You refer to Stephane's Mallat book as Stephane 1999, this is wrong, his first name is Stephane and last is Mallat, please fix the bibliography and use Mallat 1999.\n"}, "signatures": ["ICLR.cc/2020/Conference/Paper1833/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1833/AnonReviewer3"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["vsr.veera@gmail.com", "deepak.mittal@verisk.com", "abhishek.goel@verisk.com", "maneesh.singh@verisk.com"], "title": "High-Frequency guided Curriculum Learning for Class-specific Object Boundary Detection", "authors": ["VSR Veeravasarapu", "Deepak Mittal", "Abhishek Goel", "Maneesh Singh"], "pdf": "/pdf/1392ab62dba3286d645f05ff6c47d2d174807612.pdf", "TL;DR": "This work proposes a novel ConvNet architecture and a two-stage training scheme for class-specific object boundary estimation with improved performance levels.", "abstract": "This work addresses class-specific object boundary extraction, i.e., retrieving boundary pixels that belong to a class of objects in the given image. Although recent ConvNet-based approaches demonstrate impressive results, we notice that they produce several false-alarms and misdetections when used in real-world applications. We hypothesize that although boundary detection is simple at some pixels that are rooted in identifiable high-frequency locations, other pixels pose a higher level of difficulties, for instance, region pixels with an appearance similar to the boundaries; or boundary pixels with insignificant edge strengths. Therefore, the training process needs to account for different levels of learning complexity in different regions to overcome false alarms. In this work, we devise a curriculum-learning-based training process for object boundary detection. This multi-stage training process first trains the network at simpler pixels (with sufficient edge strengths) and then at harder pixels in the later stages of the curriculum.  We also propose a novel system for object boundary detection that relies on a fully convolutional neural network (FCN) and wavelet decomposition of image frequencies.  This system uses high-frequency bands from the wavelet pyramid and augments them to conv features from different layers of FCN. Our ablation studies with contourMNIST dataset, a simulated digit contours from MNIST, demonstrate that this explicit high-frequency augmentation helps the model to converge faster. Our model trained by the proposed curriculum scheme outperforms a state-of-the-art object boundary detection method by a significant margin on a challenging aerial image dataset.  \n", "keywords": ["Computer Vision", "Object Contour Detection", "Curriculum Learning", "Wavelets", "Aerial Imagery"], "paperhash": "veeravasarapu|highfrequency_guided_curriculum_learning_for_classspecific_object_boundary_detection", "original_pdf": "/attachment/1392ab62dba3286d645f05ff6c47d2d174807612.pdf", "_bibtex": "@misc{\nveeravasarapu2020highfrequency,\ntitle={High-Frequency guided Curriculum Learning for Class-specific Object Boundary Detection},\nauthor={VSR Veeravasarapu and Deepak Mittal and Abhishek Goel and Maneesh Singh},\nyear={2020},\nurl={https://openreview.net/forum?id=HkeMYJHYvS}\n}"}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "HkeMYJHYvS", "replyto": "HkeMYJHYvS", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper1833/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper1833/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1575333459404, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper1833/Reviewers"], "noninvitees": [], "tcdate": 1570237731645, "tmdate": 1575333459415, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper1833/-/Official_Review"}}}], "count": 5}