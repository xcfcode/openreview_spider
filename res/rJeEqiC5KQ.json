{"notes": [{"id": "rJeEqiC5KQ", "original": "S1ermRS9FX", "number": 526, "cdate": 1538087820096, "ddate": null, "tcdate": 1538087820096, "tmdate": 1545355403628, "tddate": null, "forum": "rJeEqiC5KQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "ON THE USE OF CONVOLUTIONAL AUTO-ENCODER FOR INCREMENTAL CLASSIFIER LEARNING IN CONTEXT AWARE ADVERTISEMENT", "abstract": "Context Aware Advertisement (CAA) is a type of advertisement\nappearing on websites or mobile apps. The advertisement is targeted\non specific group of users and/or the content displayed on the\nwebsites or apps. This paper focuses on classifying images displayed\non the websites by incremental learning classifier with Deep\nConvolutional Neural Network (DCNN) especially for Context Aware\nAdvertisement (CAA) framework. Incrementally learning new knowledge\nwith DCNN leads to catastrophic forgetting as previously stored\ninformation is replaced with new information. To prevent\ncatastrophic forgetting, part of previously learned knowledge should\nbe stored for the life time of incremental classifier. Storing\ninformation for life time involves privacy and legal concerns\nespecially in context aware advertising framework. Here, we propose\nan incremental classifier learning method which addresses privacy\nand legal concerns while taking care of catastrophic forgetting\nproblem. We conduct experiments on different datasets including\nCIFAR-100. Experimental results show that proposed system achieves\nrelatively high performance compared to the state-of-the-art\nincremental learning methods.", "keywords": ["Incremental learning", "deep learning", "autoencoder", "privacy", "convolutional neural network"], "authorids": ["tlnma@i2r.a-star.edu.sg", "xie_shudong@i2r.a-star.edu.sg", "e0267605@u.nus.edu", "yqli@i2r.a-star.edu.sg", "joohwee@i2r.a-star.edu.sg"], "authors": ["Tin Lay Nwe", "Shudong Xie", "Balaji Nataraj", "Yiqun Li", "Joo-Hwee Lim"], "TL;DR": "Human brain inspired incremental learning system", "pdf": "/pdf/de32809720997cc7dbd94749cc66085c1f425415.pdf", "paperhash": "nwe|on_the_use_of_convolutional_autoencoder_for_incremental_classifier_learning_in_context_aware_advertisement", "_bibtex": "@misc{\nnwe2019on,\ntitle={{ON} {THE} {USE} {OF} {CONVOLUTIONAL} {AUTO}-{ENCODER} {FOR} {INCREMENTAL} {CLASSIFIER} {LEARNING} {IN} {CONTEXT} {AWARE} {ADVERTISEMENT}},\nauthor={Tin Lay Nwe and Shudong Xie and Balaji Nataraj and Yiqun Li and Joo-Hwee Lim},\nyear={2019},\nurl={https://openreview.net/forum?id=rJeEqiC5KQ},\n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"replyCount": 4, "writable": false, "overwriting": [], "revisions": false, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Blind_Submission", "rdate": null, "ddate": null, "expdate": null, "duedate": 1538085600000, "tmdate": 1538142958393, "tddate": null, "super": null, "final": null, "reply": {"signatures": {"values": ["ICLR.cc/2019/Conference"]}, "forum": null, "readers": {"values": ["everyone"]}, "replyto": null, "content": {"authorids": {"values-regex": ".*"}, "authors": {"values": ["Anonymous"]}}, "writers": {"values": ["ICLR.cc/2019/Conference"]}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["~"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": null, "taskCompletionCount": null, "transform": null, "cdate": 1538142958393}}, "tauthor": "OpenReview.net"}, {"id": "Bkxmf4flgE", "original": null, "number": 1, "cdate": 1544721418828, "ddate": null, "tcdate": 1544721418828, "tmdate": 1545354509365, "tddate": null, "forum": "rJeEqiC5KQ", "replyto": "rJeEqiC5KQ", "invitation": "ICLR.cc/2019/Conference/-/Paper526/Meta_Review", "content": {"metareview": "1. Describe the strengths of the paper.  As pointed out by the reviewers and based on your expert opinion.\n \nThe paper tackles an interesting and relevant problem for ICLR: incremental classifier learning applied to image data streams.\n\n2. Describe the weaknesses of the paper. As pointed out by the reviewers and based on your expert opinion. Be sure to indicate which weaknesses are seen as salient for the decision (i.e., potential critical flaws), as opposed to weaknesses that the authors can likely fix in a revision.\n\n- The proposed method is not clearly explained and not reproducible. In particular the contribution on top of the baseline iCaRL method is unclear. It seems to be mainly the use of CAE which is a minor change.\n- The experimental comparisons are incomplete. For example, in Table 4 the authors don't discuss the storage requirements of GAN and FearNet baselines.\n- The authors state that one of their main contributions is fullfilling privacy and legal requirements. They claim this is done by using CAEs which generate image embeddings that they store rather than the original images. However it's quite well known that a lot of data about the original images can be recovered from such embeddings (e.g. Dosovitskiy & Brox. \"Inverting visual representations with convolutional networks.\" CVPR 2016.).\nThese concerns all impacted the final decision.\n\n3. Discuss any major points of contention. As raised by the authors or reviewers in the discussion, and how these might have influenced the decision. If the authors provide a rebuttal to a potential reviewer concern, it\u2019s a good idea to acknowledge this and note whether it influenced the final decision or not. This makes sure that author responses are addressed adequately.\n\nThere were no major points of contention and no author feedback.\n \n4. If consensus was reached, say so. Otherwise, explain what the source of reviewer disagreement was and why the decision on the paper aligns with one set of reviewers or another.\n\nThe reviewers reached a consensus that the paper should be rejected.\n", "confidence": "4: The area chair is confident but not absolutely certain", "recommendation": "Reject", "title": "interesting problem, but contribution is hard to assess due to lack of details and clarity"}, "signatures": ["ICLR.cc/2019/Conference/Paper526/Area_Chair1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference/Paper526/Area_Chair1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "ON THE USE OF CONVOLUTIONAL AUTO-ENCODER FOR INCREMENTAL CLASSIFIER LEARNING IN CONTEXT AWARE ADVERTISEMENT", "abstract": "Context Aware Advertisement (CAA) is a type of advertisement\nappearing on websites or mobile apps. The advertisement is targeted\non specific group of users and/or the content displayed on the\nwebsites or apps. This paper focuses on classifying images displayed\non the websites by incremental learning classifier with Deep\nConvolutional Neural Network (DCNN) especially for Context Aware\nAdvertisement (CAA) framework. Incrementally learning new knowledge\nwith DCNN leads to catastrophic forgetting as previously stored\ninformation is replaced with new information. To prevent\ncatastrophic forgetting, part of previously learned knowledge should\nbe stored for the life time of incremental classifier. Storing\ninformation for life time involves privacy and legal concerns\nespecially in context aware advertising framework. Here, we propose\nan incremental classifier learning method which addresses privacy\nand legal concerns while taking care of catastrophic forgetting\nproblem. We conduct experiments on different datasets including\nCIFAR-100. Experimental results show that proposed system achieves\nrelatively high performance compared to the state-of-the-art\nincremental learning methods.", "keywords": ["Incremental learning", "deep learning", "autoencoder", "privacy", "convolutional neural network"], "authorids": ["tlnma@i2r.a-star.edu.sg", "xie_shudong@i2r.a-star.edu.sg", "e0267605@u.nus.edu", "yqli@i2r.a-star.edu.sg", "joohwee@i2r.a-star.edu.sg"], "authors": ["Tin Lay Nwe", "Shudong Xie", "Balaji Nataraj", "Yiqun Li", "Joo-Hwee Lim"], "TL;DR": "Human brain inspired incremental learning system", "pdf": "/pdf/de32809720997cc7dbd94749cc66085c1f425415.pdf", "paperhash": "nwe|on_the_use_of_convolutional_autoencoder_for_incremental_classifier_learning_in_context_aware_advertisement", "_bibtex": "@misc{\nnwe2019on,\ntitle={{ON} {THE} {USE} {OF} {CONVOLUTIONAL} {AUTO}-{ENCODER} {FOR} {INCREMENTAL} {CLASSIFIER} {LEARNING} {IN} {CONTEXT} {AWARE} {ADVERTISEMENT}},\nauthor={Tin Lay Nwe and Shudong Xie and Balaji Nataraj and Yiqun Li and Joo-Hwee Lim},\nyear={2019},\nurl={https://openreview.net/forum?id=rJeEqiC5KQ},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper526/Meta_Review", "rdate": null, "ddate": null, "expdate": null, "duedate": 1541548800000, "tmdate": 1545353184709, "tddate": null, "super": null, "final": null, "reply": {"forum": "rJeEqiC5KQ", "replyto": "rJeEqiC5KQ", "readers": {"description": "Select all user groups that should be able to read this comment. Selecting 'All Users' will allow paper authors, reviewers, area chairs, and program chairs to view this comment.", "values": ["everyone"]}, "signatures": {"description": "How your identity will be displayed with the above content.", "values-regex": "ICLR.cc/2019/Conference/Paper526/Area_Chair[0-9]+"}, "writers": {"description": "Users that may modify this record.", "values-regex": "ICLR.cc/2019/Conference/Paper526/Area_Chair[0-9]+"}, "content": {"title": {"order": 1, "value-regex": ".{1,500}", "description": "Brief summary of your review.", "required": true}, "metareview": {"order": 2, "value-regex": "[\\S\\s]{1,5000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "required": true}, "recommendation": {"order": 3, "value-dropdown": ["Accept (Oral)", "Accept (Poster)", "Reject"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The area chair is absolutely certain", "4: The area chair is confident but not absolutely certain", "3: The area chair is somewhat confident", "2: The area chair is not sure", "1: The area chair's evaluation is an educated guess"], "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper526/Area_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": false, "taskCompletionCount": null, "transform": null, "cdate": 1545353184709}}}, {"id": "SkeZ6rW62Q", "original": null, "number": 3, "cdate": 1541375417117, "ddate": null, "tcdate": 1541375417117, "tmdate": 1541533919669, "tddate": null, "forum": "rJeEqiC5KQ", "replyto": "rJeEqiC5KQ", "invitation": "ICLR.cc/2019/Conference/-/Paper526/Official_Review", "content": {"title": "The paper deals with a significant topic, that of incremental classifier learning, but has a limited novelty and many unclear points", "review": "The paper extends an existing incremental learning method, mainly introducing the latent representations of an autoencoder instead of the original images. It includes a lot of hype in that it simulates the human brain -  because it is based on the iCaRL & Fear Net formulation - and that it fulfils the privacy and legal requirements - because it stores and uses the auto-encoder representations instead of the images.\n\nSpecific comments:\n\n- The title of the paper defines its topic to be context aware advertisement, whereas the main results and all comparisons are made on the CIFAR dataset. Only the last Table (5) provides the performance on the IMDB-CAA dataset, without any detailed analysis of the experiments.\n\n- The results in Table 3 are quite strange: the presented approach starts by outperforming iCaRL method, but then deteriorates very fast wrt size and is much lower than the original method, with no justification on this. Some improvement is shown in size 16.6% without, again, any logical explanation provided.\n\n- Section 4.2 does not provide any detail of the integration resulting in the presented system; Fig.2 does not provide a clear description either.\n\n- Language improvement is required in the experimental sections.\n\n-  ", "rating": "5: Marginally below acceptance threshold", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}, "signatures": ["ICLR.cc/2019/Conference/Paper526/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "ON THE USE OF CONVOLUTIONAL AUTO-ENCODER FOR INCREMENTAL CLASSIFIER LEARNING IN CONTEXT AWARE ADVERTISEMENT", "abstract": "Context Aware Advertisement (CAA) is a type of advertisement\nappearing on websites or mobile apps. The advertisement is targeted\non specific group of users and/or the content displayed on the\nwebsites or apps. This paper focuses on classifying images displayed\non the websites by incremental learning classifier with Deep\nConvolutional Neural Network (DCNN) especially for Context Aware\nAdvertisement (CAA) framework. Incrementally learning new knowledge\nwith DCNN leads to catastrophic forgetting as previously stored\ninformation is replaced with new information. To prevent\ncatastrophic forgetting, part of previously learned knowledge should\nbe stored for the life time of incremental classifier. Storing\ninformation for life time involves privacy and legal concerns\nespecially in context aware advertising framework. Here, we propose\nan incremental classifier learning method which addresses privacy\nand legal concerns while taking care of catastrophic forgetting\nproblem. We conduct experiments on different datasets including\nCIFAR-100. Experimental results show that proposed system achieves\nrelatively high performance compared to the state-of-the-art\nincremental learning methods.", "keywords": ["Incremental learning", "deep learning", "autoencoder", "privacy", "convolutional neural network"], "authorids": ["tlnma@i2r.a-star.edu.sg", "xie_shudong@i2r.a-star.edu.sg", "e0267605@u.nus.edu", "yqli@i2r.a-star.edu.sg", "joohwee@i2r.a-star.edu.sg"], "authors": ["Tin Lay Nwe", "Shudong Xie", "Balaji Nataraj", "Yiqun Li", "Joo-Hwee Lim"], "TL;DR": "Human brain inspired incremental learning system", "pdf": "/pdf/de32809720997cc7dbd94749cc66085c1f425415.pdf", "paperhash": "nwe|on_the_use_of_convolutional_autoencoder_for_incremental_classifier_learning_in_context_aware_advertisement", "_bibtex": "@misc{\nnwe2019on,\ntitle={{ON} {THE} {USE} {OF} {CONVOLUTIONAL} {AUTO}-{ENCODER} {FOR} {INCREMENTAL} {CLASSIFIER} {LEARNING} {IN} {CONTEXT} {AWARE} {ADVERTISEMENT}},\nauthor={Tin Lay Nwe and Shudong Xie and Balaji Nataraj and Yiqun Li and Joo-Hwee Lim},\nyear={2019},\nurl={https://openreview.net/forum?id=rJeEqiC5KQ},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper526/Official_Review", "cdate": 1542234441258, "expdate": 1552335264000, "duedate": 1541196000000, "reply": {"forum": "rJeEqiC5KQ", "replyto": "rJeEqiC5KQ", "readers": {"description": "The users who will be allowed to read the reply content.", "values": ["everyone"]}, "nonreaders": {"values": []}, "signatures": {"description": "How your identity will be displayed with the above content.", "values-regex": "ICLR.cc/2019/Conference/Paper526/AnonReviewer[0-9]+"}, "writers": {"description": "Users that may modify this record.", "values": ["ICLR.cc/2019/Conference"]}, "content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "required": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}}, "multiReply": false, "tcdate": 1552335744334, "tmdate": 1552335744334, "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "invitees": ["ICLR.cc/2019/Conference/Paper526/Reviewers"], "noninvitees": [], "signatures": ["ICLR.cc/2019/Conference"]}}}, {"id": "r1g92X3qnX", "original": null, "number": 2, "cdate": 1541223346147, "ddate": null, "tcdate": 1541223346147, "tmdate": 1541533919463, "tddate": null, "forum": "rJeEqiC5KQ", "replyto": "rJeEqiC5KQ", "invitation": "ICLR.cc/2019/Conference/-/Paper526/Official_Review", "content": {"title": "Several misleading claims", "review": "This paper describes a system for classifying  images  displayed  on  the  websites  by  using an incremental  learning  classifier with Deep Convolutional Neural Network to be used in context aware advertisement.\n\nThis is more of an application paper which is not the focus of a venue like ICLR. Further the paper makes several misleading claims. They claim that their system is inspired by the human brain while providing scant evidence to prove that claim (Unless we take it in a very broad sense to mean that neural networks resemble the human brain). Also they propose a convolutional autoencoder as a kind of an encryption method to store images to alleviate privacy and legal concerns. This is not a good idea because encoding an image using a convnet is not a substitute for encryption. In fact any image hence encoded can be decoded easily to reveal the original contents of the image. Overall this paper is not appropriate for ICLR in its current form.", "rating": "4: Ok but not good enough - rejection", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["ICLR.cc/2019/Conference/Paper526/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "ON THE USE OF CONVOLUTIONAL AUTO-ENCODER FOR INCREMENTAL CLASSIFIER LEARNING IN CONTEXT AWARE ADVERTISEMENT", "abstract": "Context Aware Advertisement (CAA) is a type of advertisement\nappearing on websites or mobile apps. The advertisement is targeted\non specific group of users and/or the content displayed on the\nwebsites or apps. This paper focuses on classifying images displayed\non the websites by incremental learning classifier with Deep\nConvolutional Neural Network (DCNN) especially for Context Aware\nAdvertisement (CAA) framework. Incrementally learning new knowledge\nwith DCNN leads to catastrophic forgetting as previously stored\ninformation is replaced with new information. To prevent\ncatastrophic forgetting, part of previously learned knowledge should\nbe stored for the life time of incremental classifier. Storing\ninformation for life time involves privacy and legal concerns\nespecially in context aware advertising framework. Here, we propose\nan incremental classifier learning method which addresses privacy\nand legal concerns while taking care of catastrophic forgetting\nproblem. We conduct experiments on different datasets including\nCIFAR-100. Experimental results show that proposed system achieves\nrelatively high performance compared to the state-of-the-art\nincremental learning methods.", "keywords": ["Incremental learning", "deep learning", "autoencoder", "privacy", "convolutional neural network"], "authorids": ["tlnma@i2r.a-star.edu.sg", "xie_shudong@i2r.a-star.edu.sg", "e0267605@u.nus.edu", "yqli@i2r.a-star.edu.sg", "joohwee@i2r.a-star.edu.sg"], "authors": ["Tin Lay Nwe", "Shudong Xie", "Balaji Nataraj", "Yiqun Li", "Joo-Hwee Lim"], "TL;DR": "Human brain inspired incremental learning system", "pdf": "/pdf/de32809720997cc7dbd94749cc66085c1f425415.pdf", "paperhash": "nwe|on_the_use_of_convolutional_autoencoder_for_incremental_classifier_learning_in_context_aware_advertisement", "_bibtex": "@misc{\nnwe2019on,\ntitle={{ON} {THE} {USE} {OF} {CONVOLUTIONAL} {AUTO}-{ENCODER} {FOR} {INCREMENTAL} {CLASSIFIER} {LEARNING} {IN} {CONTEXT} {AWARE} {ADVERTISEMENT}},\nauthor={Tin Lay Nwe and Shudong Xie and Balaji Nataraj and Yiqun Li and Joo-Hwee Lim},\nyear={2019},\nurl={https://openreview.net/forum?id=rJeEqiC5KQ},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper526/Official_Review", "cdate": 1542234441258, "expdate": 1552335264000, "duedate": 1541196000000, "reply": {"forum": "rJeEqiC5KQ", "replyto": "rJeEqiC5KQ", "readers": {"description": "The users who will be allowed to read the reply content.", "values": ["everyone"]}, "nonreaders": {"values": []}, "signatures": {"description": "How your identity will be displayed with the above content.", "values-regex": "ICLR.cc/2019/Conference/Paper526/AnonReviewer[0-9]+"}, "writers": {"description": "Users that may modify this record.", "values": ["ICLR.cc/2019/Conference"]}, "content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "required": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}}, "multiReply": false, "tcdate": 1552335744334, "tmdate": 1552335744334, "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "invitees": ["ICLR.cc/2019/Conference/Paper526/Reviewers"], "noninvitees": [], "signatures": ["ICLR.cc/2019/Conference"]}}}, {"id": "r1xDx2y537", "original": null, "number": 1, "cdate": 1541172206605, "ddate": null, "tcdate": 1541172206605, "tmdate": 1541533919257, "tddate": null, "forum": "rJeEqiC5KQ", "replyto": "rJeEqiC5KQ", "invitation": "ICLR.cc/2019/Conference/-/Paper526/Official_Review", "content": {"title": "The paper adresses the problem of incremental learning when data from new classes are available as a stream and one wants to be able to update to learn new observed classes without forgetting the older ones.  This is a relevant problem but the paper strongly lacks precision about the proposed method that looks like an incremental work with limited innovation but that the reader can only try to guess.", "review": "The paper adresses the problem of incremental learning when data from new classes are available as a stream and one wants to be able to update to learn new observed classes without forgetting the older ones. There is a budget issue here and one does not want to just keep the whole training set of all known previously observed classes but rather one wants to consider a maximum memory budget allowed to store what is necessary for an optimal incremental learning (typical examples, statistics etc). There is also a privacy issue preventing from storing original training samples.\n\nThis is a relevant problem that is has gain interest in the last few years. It is related to topics such as few shot learning and meta few shot learning (with respect ti the number of examples per class that are kept, which is limited) and somehow to budget learning . Yet these topics and associated references are surprisingly not evoked in the text.\n\nThe paper is rather well written but it strongly lacks precision about the proposed method. A description of the ICARL state of the art method is missing and would have been mandatory since the proposed work appears to build on iCARL method. Actually the description of the method is very short since the dedicated section (\u00a74) is mainly used to describe a rather standard convolutional auto encoder architecture. At the end one tries to guess what the proposed method consists in. As far as i understand it is based on iCARL method where selected examples of past observed classes are not stored as is but in their encoded form (by the convolutional autoencoder). At the end my understanding of the proposed approach is that it consists in an incremental progress of a state of the art method, then an incremental work with limited innovation.\n\nBy the way i am not sure of the meaning of pseudo exemplar as used in the proposed method. Are these drawn following a distribution computed on training samples ? Or are these pseudo exemplar because you use reconstructed samples from encodings (by the CAE).  \n\nWhen looking at experimental results the proposed method seem to bring some benefit but it does not look fully convincing. As written in the paper the proposed system outperforms iCARL in case the examples are encoded in the same dimension as original examples (hence no benefit on the storage side) but reaches similar performance when using less storage capacity. ", "rating": "3: Clear rejection", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["ICLR.cc/2019/Conference/Paper526/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "ON THE USE OF CONVOLUTIONAL AUTO-ENCODER FOR INCREMENTAL CLASSIFIER LEARNING IN CONTEXT AWARE ADVERTISEMENT", "abstract": "Context Aware Advertisement (CAA) is a type of advertisement\nappearing on websites or mobile apps. The advertisement is targeted\non specific group of users and/or the content displayed on the\nwebsites or apps. This paper focuses on classifying images displayed\non the websites by incremental learning classifier with Deep\nConvolutional Neural Network (DCNN) especially for Context Aware\nAdvertisement (CAA) framework. Incrementally learning new knowledge\nwith DCNN leads to catastrophic forgetting as previously stored\ninformation is replaced with new information. To prevent\ncatastrophic forgetting, part of previously learned knowledge should\nbe stored for the life time of incremental classifier. Storing\ninformation for life time involves privacy and legal concerns\nespecially in context aware advertising framework. Here, we propose\nan incremental classifier learning method which addresses privacy\nand legal concerns while taking care of catastrophic forgetting\nproblem. We conduct experiments on different datasets including\nCIFAR-100. Experimental results show that proposed system achieves\nrelatively high performance compared to the state-of-the-art\nincremental learning methods.", "keywords": ["Incremental learning", "deep learning", "autoencoder", "privacy", "convolutional neural network"], "authorids": ["tlnma@i2r.a-star.edu.sg", "xie_shudong@i2r.a-star.edu.sg", "e0267605@u.nus.edu", "yqli@i2r.a-star.edu.sg", "joohwee@i2r.a-star.edu.sg"], "authors": ["Tin Lay Nwe", "Shudong Xie", "Balaji Nataraj", "Yiqun Li", "Joo-Hwee Lim"], "TL;DR": "Human brain inspired incremental learning system", "pdf": "/pdf/de32809720997cc7dbd94749cc66085c1f425415.pdf", "paperhash": "nwe|on_the_use_of_convolutional_autoencoder_for_incremental_classifier_learning_in_context_aware_advertisement", "_bibtex": "@misc{\nnwe2019on,\ntitle={{ON} {THE} {USE} {OF} {CONVOLUTIONAL} {AUTO}-{ENCODER} {FOR} {INCREMENTAL} {CLASSIFIER} {LEARNING} {IN} {CONTEXT} {AWARE} {ADVERTISEMENT}},\nauthor={Tin Lay Nwe and Shudong Xie and Balaji Nataraj and Yiqun Li and Joo-Hwee Lim},\nyear={2019},\nurl={https://openreview.net/forum?id=rJeEqiC5KQ},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper526/Official_Review", "cdate": 1542234441258, "expdate": 1552335264000, "duedate": 1541196000000, "reply": {"forum": "rJeEqiC5KQ", "replyto": "rJeEqiC5KQ", "readers": {"description": "The users who will be allowed to read the reply content.", "values": ["everyone"]}, "nonreaders": {"values": []}, "signatures": {"description": "How your identity will be displayed with the above content.", "values-regex": "ICLR.cc/2019/Conference/Paper526/AnonReviewer[0-9]+"}, "writers": {"description": "Users that may modify this record.", "values": ["ICLR.cc/2019/Conference"]}, "content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "required": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}}, "multiReply": false, "tcdate": 1552335744334, "tmdate": 1552335744334, "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "invitees": ["ICLR.cc/2019/Conference/Paper526/Reviewers"], "noninvitees": [], "signatures": ["ICLR.cc/2019/Conference"]}}}], "count": 5}