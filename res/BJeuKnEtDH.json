{"notes": [{"id": "BJeuKnEtDH", "original": "SJlbh5c38r", "number": 85, "cdate": 1569438848482, "ddate": null, "tcdate": 1569438848482, "tmdate": 1577168293138, "tddate": null, "forum": "BJeuKnEtDH", "replyto": null, "invitation": "ICLR.cc/2020/Conference/-/Blind_Submission", "content": {"title": "Cascade Style Transfer", "authors": ["Zhizhong Wang", "Lei Zhao", "Qihang Mo", "Sihuan Lin", "Zhiwen Zuo", "Wei Xing", "Dongming Lu"], "authorids": ["endywon@zju.edu.cn", "cszhl@zju.edu.cn", "moqihang@zju.edu.cn", "linsh@zju.edu.cn", "zzwcs@zju.edu.cn", "wxing@zju.edu.cn", "ldm@zju.edu.cn"], "keywords": ["style transfer", "cascade", "quality", "flexibility", "domain-independent", "serial", "parallel"], "abstract": "Recent studies have made tremendous progress in style transfer for specific domains, e.g., artistic, semantic and photo-realistic. However, existing approaches have limited flexibility in extending to other domains, as different style representations are often specific to particular domains. This also limits the stylistic quality. To address these limitations, we propose Cascade Style Transfer, a simple yet effective framework that can improve the quality and flexibility of style transfer by combining multiple existing approaches directly. Our cascade framework contains two architectures, i.e., Serial Style Transfer (SST) and Parallel Style Transfer (PST). The SST takes the stylized output of one method as the input content of the others. This could help improve the stylistic quality. The PST uses a shared backbone and a loss module to optimize the loss functions of different methods in parallel. This could help improve the quality and flexibility, and guide us to find domain-independent approaches. Our experiments are conducted on three major style transfer domains: artistic, semantic and photo-realistic. In all these domains, our methods have shown superiority over the state-of-the-art methods.", "pdf": "/pdf/24cfbd5a63d1e261855cfab0a7f1de9caa2f31b4.pdf", "paperhash": "wang|cascade_style_transfer", "original_pdf": "/attachment/24cfbd5a63d1e261855cfab0a7f1de9caa2f31b4.pdf", "_bibtex": "@misc{\nwang2020cascade,\ntitle={Cascade Style Transfer},\nauthor={Zhizhong Wang and Lei Zhao and Qihang Mo and Sihuan Lin and Zhiwen Zuo and Wei Xing and Dongming Lu},\nyear={2020},\nurl={https://openreview.net/forum?id=BJeuKnEtDH}\n}"}, "signatures": ["ICLR.cc/2020/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference"], "details": {"replyCount": 4, "writable": false, "overwriting": [], "revisions": false, "tags": [], "invitation": {"reply": {"readers": {"values-regex": ".*"}, "writers": {"values": ["ICLR.cc/2020/Conference"]}, "signatures": {"values": ["ICLR.cc/2020/Conference"]}, "content": {"spotlight_video": {"value-regex": ".*"}, "full_presentation_video": {"value-regex": ".*"}, "original_pdf": {"required": false, "description": "Upload a PDF file that ends with .pdf", "value-regex": ".*"}, "appendix": {"value-regex": ".*"}, "authorids": {"values-regex": ".*"}, "poster": {"value-regex": ".*"}, "authors": {"values": ["Anonymous"]}, "slides": {"value-regex": ".*"}}}, "final": [], "signatures": ["ICLR.cc/2020/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference"], "noninvitees": [], "tcdate": 1569271260237, "tmdate": 1593459412141, "id": "ICLR.cc/2020/Conference/-/Blind_Submission"}}, "tauthor": "OpenReview.net"}, {"id": "o3iKFU8Xu", "original": null, "number": 1, "cdate": 1576798687044, "ddate": null, "tcdate": 1576798687044, "tmdate": 1576800948029, "tddate": null, "forum": "BJeuKnEtDH", "replyto": "BJeuKnEtDH", "invitation": "ICLR.cc/2020/Conference/Paper85/-/Decision", "content": {"decision": "Reject", "comment": "This work combines style transfer approaches either in a serial or parallel fashion, and shows that the combination of methods is more powerful than isolated methods.\nThe novelty in this work is extremely limited and not offset by insightful analysis or very thorough experiments, given that most results are qualitative. Authors have not provided a public response.\nTherefore, we recommend rejection.", "title": "Paper Decision"}, "signatures": ["ICLR.cc/2020/Conference/Program_Chairs"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Program_Chairs"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Cascade Style Transfer", "authors": ["Zhizhong Wang", "Lei Zhao", "Qihang Mo", "Sihuan Lin", "Zhiwen Zuo", "Wei Xing", "Dongming Lu"], "authorids": ["endywon@zju.edu.cn", "cszhl@zju.edu.cn", "moqihang@zju.edu.cn", "linsh@zju.edu.cn", "zzwcs@zju.edu.cn", "wxing@zju.edu.cn", "ldm@zju.edu.cn"], "keywords": ["style transfer", "cascade", "quality", "flexibility", "domain-independent", "serial", "parallel"], "abstract": "Recent studies have made tremendous progress in style transfer for specific domains, e.g., artistic, semantic and photo-realistic. However, existing approaches have limited flexibility in extending to other domains, as different style representations are often specific to particular domains. This also limits the stylistic quality. To address these limitations, we propose Cascade Style Transfer, a simple yet effective framework that can improve the quality and flexibility of style transfer by combining multiple existing approaches directly. Our cascade framework contains two architectures, i.e., Serial Style Transfer (SST) and Parallel Style Transfer (PST). The SST takes the stylized output of one method as the input content of the others. This could help improve the stylistic quality. The PST uses a shared backbone and a loss module to optimize the loss functions of different methods in parallel. This could help improve the quality and flexibility, and guide us to find domain-independent approaches. Our experiments are conducted on three major style transfer domains: artistic, semantic and photo-realistic. In all these domains, our methods have shown superiority over the state-of-the-art methods.", "pdf": "/pdf/24cfbd5a63d1e261855cfab0a7f1de9caa2f31b4.pdf", "paperhash": "wang|cascade_style_transfer", "original_pdf": "/attachment/24cfbd5a63d1e261855cfab0a7f1de9caa2f31b4.pdf", "_bibtex": "@misc{\nwang2020cascade,\ntitle={Cascade Style Transfer},\nauthor={Zhizhong Wang and Lei Zhao and Qihang Mo and Sihuan Lin and Zhiwen Zuo and Wei Xing and Dongming Lu},\nyear={2020},\nurl={https://openreview.net/forum?id=BJeuKnEtDH}\n}"}, "tags": [], "invitation": {"reply": {"writers": {"description": "How your identity will be displayed.", "values-regex": ["ICLR.cc/2020/Conference/Program_Chairs"]}, "signatures": {"values": ["ICLR.cc/2020/Conference/Program_Chairs"], "description": "How your identity will be displayed."}, "content": {"decision": {"value-radio": ["Accept (Spotlight)", "Accept (Talk)", "Accept (Poster)", "Reject"], "description": "Decision", "required": true, "order": 2}, "title": {"value": "Paper Decision", "required": true, "order": 1}, "comment": {"value-regex": "[\\S\\s]{0,5000}", "description": "", "required": false, "order": 3}}, "forum": "BJeuKnEtDH", "replyto": "BJeuKnEtDH", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}}, "expdate": 1576854540000, "duedate": 1576853940000, "multiReply": false, "readers": ["everyone"], "invitees": ["ICLR.cc/2020/Conference/Program_Chairs"], "tcdate": 1576795730460, "tmdate": 1576800283259, "super": "ICLR.cc/2020/Conference/-/Decision", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper85/-/Decision"}}}, {"id": "SkxhgEzMtB", "original": null, "number": 1, "cdate": 1571066867701, "ddate": null, "tcdate": 1571066867701, "tmdate": 1572972640541, "tddate": null, "forum": "BJeuKnEtDH", "replyto": "BJeuKnEtDH", "invitation": "ICLR.cc/2020/Conference/Paper85/-/Official_Review", "content": {"rating": "1: Reject", "experience_assessment": "I have published one or two papers in this area.", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #1", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review": "Summary:\nIn this study, the authors propose a new method for performing artistic style transfer for  arbitrary image and styles. The new method employs a cascade/serial architecture for performing the style transfer. The authors test their method using human preference studies.\n\nIn summary, I found the architecture choice to be minimally explored. More importantly, a vast majority of the results to demonstrate the relative merits of this method were qualitative. The minimal quantitative results were unconvincing and left many unanswered questions about how well one could trust these results.\n\nMajor Comments:\n\n1. No experiments to explore the architecture hyperparameters.\nA natural question might be how the quality of the method varies systematically as the number of methods N grows. Presumably, if N=1, this would recover previous methods. \n\n2. Authors are missing an important reference and point of comparison for arbitrary style transfer.\n  Exploring the structure of a real-time, arbitrary neural artistic stylization network\n  Golnaz Ghiasi, Honglak Lee, Manjunath Kudlur, Vincent Dumoulin, Jonathon Shlens\n  https://arxiv.org/abs/1705.06830\n  http://goo.gle/2oiDKaT \n\n3. Minimal quantitative analysis.\nA vast majority of the results (30 of 32 figures) are qualitative comparisons and the paper is sorely lacking an emphasis on quantitative comparisons. This is a large and notable problem in this paper and a quantitative comparison *should* constitute the primary thrust and central result of such a paper to convincingly demonstrate to a reader that the proposed method is indeed to superior to other techniques. I wish the authors dedicated more emphasis in this paper to a detailed quantitative comparison for these methods. As a starter, the analysis presented as the final two appendix figures (31 and 32) should be front and center in the result section of the paper.\n\n4. User study for quantitative comparison is incomplete and unconvincing.\nTable 1 and Appendix Figure 31 and 32 represent the primary result of this paper as these results and comprise the user studies to quantify how much better this method is to previous methods. These studies however are fairly unconvincing as lots of details are omitted and and I am concerned about the rigor of the human studies including but not limited to:\n  4a. How long did each human study each image? What controls were added to the study to ensure that all images were equally studied by humans? For instance, were any golden tests employed to ensure user engagement throughout the study?\n  4b. What was the repeatability of each measurement of preference? If a single human was presented the same image twice, how consistent were there ratings? For that matter, how consistent were the ratings across humans? I presume that some humans preferred some styles over others but how systematic was this?\n  4c. What types of user testing scenarios were explored to ensure minimal bias in the results? Were multi-choice, paired choice or force choice employed? What about minimal or maximal time limit enforcement?\n  4d. How can I have confidence that the authors did not cherry pick images and styles that favored their method? For that matter, I would expect that some methods work better on some styles or images. I would expect to see analysis accordingly to break down which styles/images work better on different slices of the data.\n  4e. The statistical significance of Figure 31 and Figure 32 is not provided. What would an error bar look like with resampling? "}, "signatures": ["ICLR.cc/2020/Conference/Paper85/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper85/AnonReviewer1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Cascade Style Transfer", "authors": ["Zhizhong Wang", "Lei Zhao", "Qihang Mo", "Sihuan Lin", "Zhiwen Zuo", "Wei Xing", "Dongming Lu"], "authorids": ["endywon@zju.edu.cn", "cszhl@zju.edu.cn", "moqihang@zju.edu.cn", "linsh@zju.edu.cn", "zzwcs@zju.edu.cn", "wxing@zju.edu.cn", "ldm@zju.edu.cn"], "keywords": ["style transfer", "cascade", "quality", "flexibility", "domain-independent", "serial", "parallel"], "abstract": "Recent studies have made tremendous progress in style transfer for specific domains, e.g., artistic, semantic and photo-realistic. However, existing approaches have limited flexibility in extending to other domains, as different style representations are often specific to particular domains. This also limits the stylistic quality. To address these limitations, we propose Cascade Style Transfer, a simple yet effective framework that can improve the quality and flexibility of style transfer by combining multiple existing approaches directly. Our cascade framework contains two architectures, i.e., Serial Style Transfer (SST) and Parallel Style Transfer (PST). The SST takes the stylized output of one method as the input content of the others. This could help improve the stylistic quality. The PST uses a shared backbone and a loss module to optimize the loss functions of different methods in parallel. This could help improve the quality and flexibility, and guide us to find domain-independent approaches. Our experiments are conducted on three major style transfer domains: artistic, semantic and photo-realistic. In all these domains, our methods have shown superiority over the state-of-the-art methods.", "pdf": "/pdf/24cfbd5a63d1e261855cfab0a7f1de9caa2f31b4.pdf", "paperhash": "wang|cascade_style_transfer", "original_pdf": "/attachment/24cfbd5a63d1e261855cfab0a7f1de9caa2f31b4.pdf", "_bibtex": "@misc{\nwang2020cascade,\ntitle={Cascade Style Transfer},\nauthor={Zhizhong Wang and Lei Zhao and Qihang Mo and Sihuan Lin and Zhiwen Zuo and Wei Xing and Dongming Lu},\nyear={2020},\nurl={https://openreview.net/forum?id=BJeuKnEtDH}\n}"}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "BJeuKnEtDH", "replyto": "BJeuKnEtDH", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper85/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper85/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1575864062612, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper85/Reviewers"], "noninvitees": [], "tcdate": 1570237757298, "tmdate": 1575864062625, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper85/-/Official_Review"}}}, {"id": "HyeCd0d_cS", "original": null, "number": 2, "cdate": 1572535925943, "ddate": null, "tcdate": 1572535925943, "tmdate": 1572972640506, "tddate": null, "forum": "BJeuKnEtDH", "replyto": "BJeuKnEtDH", "invitation": "ICLR.cc/2020/Conference/Paper85/-/Official_Review", "content": {"rating": "1: Reject", "experience_assessment": "I have read many papers in this area.", "review_assessment:_checking_correctness_of_derivations_and_theory": "I carefully checked the derivations and theory.", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #2", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review": "The authors proposed to mix together multiple styles by proposing two frameworks: 1) serial style transfer (SST), which combines style transfer methods in series; and 2) parallel style transfer (PST), which combines style transfer methods in parallel.\n\nThe paper is clearly presented. It is interesting to see work on mixing up different styles, since it is not extensive studied so far. Though not much studied, this topic is not new [ref 1], [ref 2]. The authors didn't provide a thorough literature review on mixing multiple styles in the related work or anywhere else in the submission.\n\nIn terms of the methodology, the novelty is quite limited. The proposed SST and PST are simple frameworks to mix different styles, which, by the way, are fully based on existing style transfer methods. At some point, PST is similar to [ref 2], and the difference is minor. PST linearly combines the losses for different styles to construct the final loss, while [ref 2] linearly combines together the features for different styles.\n\nAbout experiments, it is not clear about how the predefined parameters (e.g. \\alpha, w_1, w_2, etc.) are determined. They were just empirically set and mentioned in the experiment section.\n\nIt is appreciated to see more results in the Appendix, as well as the user study. However, due to lack of novelty, I think this submission may not be qualified for acceptance at this moment.\n\nMinor:\nI think the authors should give their proposed framework another name instead of using \"cascade,\" which has a similar meaning of \"series.\"\n\n\n[ref 1] Google's arty filters one-up Prisma by mixing various styles. https://www.engadget.com/2016/10/27/google-style-transfer-tech/\n[ref 2] Pegios, et al. Style Decomposition for Improved Neural Style Transfer. ArXiv, 2018."}, "signatures": ["ICLR.cc/2020/Conference/Paper85/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper85/AnonReviewer2"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Cascade Style Transfer", "authors": ["Zhizhong Wang", "Lei Zhao", "Qihang Mo", "Sihuan Lin", "Zhiwen Zuo", "Wei Xing", "Dongming Lu"], "authorids": ["endywon@zju.edu.cn", "cszhl@zju.edu.cn", "moqihang@zju.edu.cn", "linsh@zju.edu.cn", "zzwcs@zju.edu.cn", "wxing@zju.edu.cn", "ldm@zju.edu.cn"], "keywords": ["style transfer", "cascade", "quality", "flexibility", "domain-independent", "serial", "parallel"], "abstract": "Recent studies have made tremendous progress in style transfer for specific domains, e.g., artistic, semantic and photo-realistic. However, existing approaches have limited flexibility in extending to other domains, as different style representations are often specific to particular domains. This also limits the stylistic quality. To address these limitations, we propose Cascade Style Transfer, a simple yet effective framework that can improve the quality and flexibility of style transfer by combining multiple existing approaches directly. Our cascade framework contains two architectures, i.e., Serial Style Transfer (SST) and Parallel Style Transfer (PST). The SST takes the stylized output of one method as the input content of the others. This could help improve the stylistic quality. The PST uses a shared backbone and a loss module to optimize the loss functions of different methods in parallel. This could help improve the quality and flexibility, and guide us to find domain-independent approaches. Our experiments are conducted on three major style transfer domains: artistic, semantic and photo-realistic. In all these domains, our methods have shown superiority over the state-of-the-art methods.", "pdf": "/pdf/24cfbd5a63d1e261855cfab0a7f1de9caa2f31b4.pdf", "paperhash": "wang|cascade_style_transfer", "original_pdf": "/attachment/24cfbd5a63d1e261855cfab0a7f1de9caa2f31b4.pdf", "_bibtex": "@misc{\nwang2020cascade,\ntitle={Cascade Style Transfer},\nauthor={Zhizhong Wang and Lei Zhao and Qihang Mo and Sihuan Lin and Zhiwen Zuo and Wei Xing and Dongming Lu},\nyear={2020},\nurl={https://openreview.net/forum?id=BJeuKnEtDH}\n}"}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "BJeuKnEtDH", "replyto": "BJeuKnEtDH", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper85/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper85/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1575864062612, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper85/Reviewers"], "noninvitees": [], "tcdate": 1570237757298, "tmdate": 1575864062625, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper85/-/Official_Review"}}}, {"id": "HkgZ0-Ah9H", "original": null, "number": 3, "cdate": 1572819401385, "ddate": null, "tcdate": 1572819401385, "tmdate": 1572972640462, "tddate": null, "forum": "BJeuKnEtDH", "replyto": "BJeuKnEtDH", "invitation": "ICLR.cc/2020/Conference/Paper85/-/Official_Review", "content": {"rating": "1: Reject", "experience_assessment": "I have published in this field for several years.", "review_assessment:_checking_correctness_of_derivations_and_theory": "I carefully checked the derivations and theory.", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #4", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review": "This paper proposes two ways to aggregate existing style transfer methods and shows improvements on quality and flexibility. However, the proposed method does not solve the limitations of any previous methods. Instead, it is as simple as an easy combination: the proposed SST is a sequential combination and the proposed PST has no difference with running each single method separately. To me this is more like an engineering effort rather than a research work. \n\n(1) For SST, it just connects N existing methods, using the output of method 1 as the input of method 2. The quality of results might be improved but there is little novelty. I agree combing methods can be a contribution only when there are principle designs and in-depth analysis. \n\n(2) For PST, I do not see its difference with running single method separately. Putting all previous methods altogether cannot be called being more flexible. As said in the paper, when for photorealistic transfer, the proposed PST set the loss weight of other methods except Luan et al. as 0. Then is it the same with running the single method of Luan et al.?\n\nIn general, I do not encourage such a way of exploring research. Authors should focus more on the unsolved issues in style transfer, e.g., how to do geometric style transfer (shape)."}, "signatures": ["ICLR.cc/2020/Conference/Paper85/AnonReviewer4"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper85/AnonReviewer4"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Cascade Style Transfer", "authors": ["Zhizhong Wang", "Lei Zhao", "Qihang Mo", "Sihuan Lin", "Zhiwen Zuo", "Wei Xing", "Dongming Lu"], "authorids": ["endywon@zju.edu.cn", "cszhl@zju.edu.cn", "moqihang@zju.edu.cn", "linsh@zju.edu.cn", "zzwcs@zju.edu.cn", "wxing@zju.edu.cn", "ldm@zju.edu.cn"], "keywords": ["style transfer", "cascade", "quality", "flexibility", "domain-independent", "serial", "parallel"], "abstract": "Recent studies have made tremendous progress in style transfer for specific domains, e.g., artistic, semantic and photo-realistic. However, existing approaches have limited flexibility in extending to other domains, as different style representations are often specific to particular domains. This also limits the stylistic quality. To address these limitations, we propose Cascade Style Transfer, a simple yet effective framework that can improve the quality and flexibility of style transfer by combining multiple existing approaches directly. Our cascade framework contains two architectures, i.e., Serial Style Transfer (SST) and Parallel Style Transfer (PST). The SST takes the stylized output of one method as the input content of the others. This could help improve the stylistic quality. The PST uses a shared backbone and a loss module to optimize the loss functions of different methods in parallel. This could help improve the quality and flexibility, and guide us to find domain-independent approaches. Our experiments are conducted on three major style transfer domains: artistic, semantic and photo-realistic. In all these domains, our methods have shown superiority over the state-of-the-art methods.", "pdf": "/pdf/24cfbd5a63d1e261855cfab0a7f1de9caa2f31b4.pdf", "paperhash": "wang|cascade_style_transfer", "original_pdf": "/attachment/24cfbd5a63d1e261855cfab0a7f1de9caa2f31b4.pdf", "_bibtex": "@misc{\nwang2020cascade,\ntitle={Cascade Style Transfer},\nauthor={Zhizhong Wang and Lei Zhao and Qihang Mo and Sihuan Lin and Zhiwen Zuo and Wei Xing and Dongming Lu},\nyear={2020},\nurl={https://openreview.net/forum?id=BJeuKnEtDH}\n}"}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "BJeuKnEtDH", "replyto": "BJeuKnEtDH", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper85/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper85/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1575864062612, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper85/Reviewers"], "noninvitees": [], "tcdate": 1570237757298, "tmdate": 1575864062625, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper85/-/Official_Review"}}}], "count": 5}