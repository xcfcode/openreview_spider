{"notes": [{"id": "ln6AzgMbKBC", "original": "DRR12DYKBXG", "number": 23, "cdate": 1615225933378, "ddate": null, "tcdate": 1615225933378, "tmdate": 1615967302751, "tddate": null, "forum": "ln6AzgMbKBC", "replyto": null, "invitation": "ICLR.cc/2021/Workshop/GTRL/-/Blind_Submission", "content": {"title": "Recovering Barab\u00e1si-Albert Parameters of Graphs through Disentanglement", "authorids": ["ICLR.cc/2021/Workshop/GTRL/Paper23/Authors"], "authors": ["Anonymous"], "keywords": ["disentanglement", "disentangled graph representations", "graph neural networks", "graph generation", "Barab\u00e1si-Albert"], "TL;DR": "Recovering the generative parameters of the Barab\u00e1si-Albert sequential graph generator model with beta-VAEs and graph neural networks.", "abstract": "Classical graph modeling approaches such as Erd\u0151s-R\u00e9nyi random graphs (ER graphs) or Barab\u00e1si Albert graphs (BA graphs), here referred to as stylized models, aim to reproduce properties of real-world graphs in an interpretable way. While useful, graph generation with stylized models requires domain knowledge and iterative trial and error simulation. Stoehr et al. (2019) suggest addressing these issues by learning the generation process from graph data, using a disentanglement-focused deep autoencoding framework, more specifically, a $\\beta$-Variational Autoencoder ($\\beta$-VAE). While they successfully recover the generative parameters of ER graphs through the model's latent variables, their model performs badly on sequentially generated graphs such as BA graphs, due to their oversimplified decoder. We focus on recovering the generative parameters of BA graphs by replacing the decoder in Stoehr et al. (2019)'s $\\beta$-VAE with a sequential one. We first learn the generative BA parameters in a supervised fashion using a Graph Neural Network (GNN) and a Random Forest Regressor, by minimizing the squared loss between the true generative parameters and the latent variables. Next, we train a $\\beta$-VAE model, combining the GNN encoder from the previous step with an LSTM-based decoder with a customized loss.", "pdf": "/pdf/958cc982883164de7414131c4d39d315be10c685.pdf", "paperhash": "anonymous|recovering_barab\u00e1sialbert_parameters_of_graphs_through_disentanglement", "_bibtex": "@inproceedings{\nanonymous2021recovering,\ntitle={Recovering Barab{\\'a}si-Albert Parameters of Graphs through Disentanglement},\nauthor={Anonymous},\nbooktitle={Submitted to ICLR 2021 Workshop on Geometrical and Topological Representation Learning},\nyear={2021},\nurl={https://openreview.net/forum?id=ln6AzgMbKBC},\nnote={under review}\n}"}, "signatures": ["ICLR.cc/2021/Workshop/GTRL"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Workshop/GTRL"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "tags": [], "invitation": {"reply": {"readers": {"values-regex": ".*"}, "writers": {"values": ["ICLR.cc/2021/Workshop/GTRL"]}, "signatures": {"values": ["ICLR.cc/2021/Workshop/GTRL"]}, "content": {"authors": {"values": ["Anonymous"]}, "authorids": {"values-regex": ".*"}}}, "signatures": ["ICLR.cc/2021/Workshop/GTRL"], "readers": ["everyone"], "writers": ["ICLR.cc/2021/Workshop/GTRL"], "invitees": ["~", "OpenReview.net/Support"], "tcdate": 1615225929161, "tmdate": 1615967298665, "id": "ICLR.cc/2021/Workshop/GTRL/-/Blind_Submission"}}, "tauthor": "~Super_User1"}], "count": 1}