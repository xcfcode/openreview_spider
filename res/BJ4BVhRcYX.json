{"notes": [{"id": "BJ4BVhRcYX", "original": "ryxWWNRctm", "number": 1450, "cdate": 1538087981470, "ddate": null, "tcdate": 1538087981470, "tmdate": 1545355426058, "tddate": null, "forum": "BJ4BVhRcYX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "INTERPRETABLE CONVOLUTIONAL FILTER PRUNING", "abstract": "The sophisticated structure of Convolutional Neural Network (CNN) allows for\noutstanding performance, but at the cost of intensive computation. As significant\nredundancies inevitably present in such a structure, many works have been proposed\nto prune the convolutional filters for computation cost reduction. Although\nextremely effective, most works are based only on quantitative characteristics of\nthe convolutional filters, and highly overlook the qualitative interpretation of individual\nfilter\u2019s specific functionality. In this work, we interpreted the functionality\nand redundancy of the convolutional filters from different perspectives, and proposed\na functionality-oriented filter pruning method. With extensive experiment\nresults, we proved the convolutional filters\u2019 qualitative significance regardless of\nmagnitude, demonstrated significant neural network redundancy due to repetitive\nfilter functions, and analyzed the filter functionality defection under inappropriate\nretraining process. Such an interpretable pruning approach not only offers outstanding\ncomputation cost optimization over previous filter pruning methods, but\nalso interprets filter pruning process.", "keywords": [], "authorids": ["zqin@gmu.edu", "fyu2@gmu.edu", "chliu@clarkson.edu", "xchen26@gmu.edu"], "authors": ["Zhuwei Qin", "Fuxun Yu", "Chenchen Liu", "Xiang Chen"], "pdf": "/pdf/3365464c9f60f06eb097a49f5a0d9eaea5c969f1.pdf", "paperhash": "qin|interpretable_convolutional_filter_pruning", "_bibtex": "@misc{\nqin2019interpretable,\ntitle={{INTERPRETABLE} {CONVOLUTIONAL} {FILTER} {PRUNING}},\nauthor={Zhuwei Qin and Fuxun Yu and Chenchen Liu and Xiang Chen},\nyear={2019},\nurl={https://openreview.net/forum?id=BJ4BVhRcYX},\n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"replyCount": 20, "writable": false, "overwriting": [], "revisions": false, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Blind_Submission", "rdate": null, "ddate": null, "expdate": null, "duedate": 1538085600000, "tmdate": 1538142958393, "tddate": null, "super": null, "final": null, "reply": {"signatures": {"values": ["ICLR.cc/2019/Conference"]}, "forum": null, "readers": {"values": ["everyone"]}, "replyto": null, "content": {"authorids": {"values-regex": ".*"}, "authors": {"values": ["Anonymous"]}}, "writers": {"values": ["ICLR.cc/2019/Conference"]}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["~"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": null, "taskCompletionCount": null, "transform": null, "cdate": 1538142958393}}, "tauthor": "OpenReview.net"}, {"id": "ByxA1fAme4", "original": null, "number": 1, "cdate": 1544966629919, "ddate": null, "tcdate": 1544966629919, "tmdate": 1545354489749, "tddate": null, "forum": "BJ4BVhRcYX", "replyto": "BJ4BVhRcYX", "invitation": "ICLR.cc/2019/Conference/-/Paper1450/Meta_Review", "content": {"metareview": "The current version of the paper receives a unanimous rejection from reviewers, as the final proposal. ", "confidence": "4: The area chair is confident but not absolutely certain", "recommendation": "Reject", "title": "Unanimous rejection."}, "signatures": ["ICLR.cc/2019/Conference/Paper1450/Area_Chair1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference/Paper1450/Area_Chair1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "INTERPRETABLE CONVOLUTIONAL FILTER PRUNING", "abstract": "The sophisticated structure of Convolutional Neural Network (CNN) allows for\noutstanding performance, but at the cost of intensive computation. As significant\nredundancies inevitably present in such a structure, many works have been proposed\nto prune the convolutional filters for computation cost reduction. Although\nextremely effective, most works are based only on quantitative characteristics of\nthe convolutional filters, and highly overlook the qualitative interpretation of individual\nfilter\u2019s specific functionality. In this work, we interpreted the functionality\nand redundancy of the convolutional filters from different perspectives, and proposed\na functionality-oriented filter pruning method. With extensive experiment\nresults, we proved the convolutional filters\u2019 qualitative significance regardless of\nmagnitude, demonstrated significant neural network redundancy due to repetitive\nfilter functions, and analyzed the filter functionality defection under inappropriate\nretraining process. Such an interpretable pruning approach not only offers outstanding\ncomputation cost optimization over previous filter pruning methods, but\nalso interprets filter pruning process.", "keywords": [], "authorids": ["zqin@gmu.edu", "fyu2@gmu.edu", "chliu@clarkson.edu", "xchen26@gmu.edu"], "authors": ["Zhuwei Qin", "Fuxun Yu", "Chenchen Liu", "Xiang Chen"], "pdf": "/pdf/3365464c9f60f06eb097a49f5a0d9eaea5c969f1.pdf", "paperhash": "qin|interpretable_convolutional_filter_pruning", "_bibtex": "@misc{\nqin2019interpretable,\ntitle={{INTERPRETABLE} {CONVOLUTIONAL} {FILTER} {PRUNING}},\nauthor={Zhuwei Qin and Fuxun Yu and Chenchen Liu and Xiang Chen},\nyear={2019},\nurl={https://openreview.net/forum?id=BJ4BVhRcYX},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper1450/Meta_Review", "rdate": null, "ddate": null, "expdate": null, "duedate": 1541548800000, "tmdate": 1545352833768, "tddate": null, "super": null, "final": null, "reply": {"forum": "BJ4BVhRcYX", "replyto": "BJ4BVhRcYX", "readers": {"description": "Select all user groups that should be able to read this comment. Selecting 'All Users' will allow paper authors, reviewers, area chairs, and program chairs to view this comment.", "values": ["everyone"]}, "signatures": {"description": "How your identity will be displayed with the above content.", "values-regex": "ICLR.cc/2019/Conference/Paper1450/Area_Chair[0-9]+"}, "writers": {"description": "Users that may modify this record.", "values-regex": "ICLR.cc/2019/Conference/Paper1450/Area_Chair[0-9]+"}, "content": {"title": {"order": 1, "value-regex": ".{1,500}", "description": "Brief summary of your review.", "required": true}, "metareview": {"order": 2, "value-regex": "[\\S\\s]{1,5000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "required": true}, "recommendation": {"order": 3, "value-dropdown": ["Accept (Oral)", "Accept (Poster)", "Reject"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The area chair is absolutely certain", "4: The area chair is confident but not absolutely certain", "3: The area chair is somewhat confident", "2: The area chair is not sure", "1: The area chair's evaluation is an educated guess"], "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper1450/Area_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": false, "taskCompletionCount": null, "transform": null, "cdate": 1545352833768}}}, {"id": "ryg2HGdc27", "original": null, "number": 3, "cdate": 1541206596502, "ddate": null, "tcdate": 1541206596502, "tmdate": 1541533123021, "tddate": null, "forum": "BJ4BVhRcYX", "replyto": "BJ4BVhRcYX", "invitation": "ICLR.cc/2019/Conference/-/Paper1450/Official_Review", "content": {"title": "I think the method proposed in this paper might be reasonable. But I do not suggest acceptance, unless the author can improve the writing and include more experimental results.", "review": "In this paper, the authors propose a method for pruning the convolutional filters. This method first separates the filters into clusters based on similarities defined with both Activation Maximization (AM) and back-propagation gradients. Then pruning is conducted based on the clustering results, and the contribution index that is calculated based on backward-propagation gradients. The proposed method is compared with a baseline method in the experiments. \n\nI consider the proposed method as novel, since I do not know any filter pruning methods that adopt a similar strategy. Based on my understanding of the proposed method, it might be useful in convolutional filter pruning.\n\nIt seems that \"interpretable\" might not be the most proper word to summarize the method. It looks like that the key concept of this paper, including smilarity defined in Equation (3), and the contribution index defined in Equation (7) are not directly relevant to interpretability. Therefore, I would consider change the title of the paper, for example, to \"Convolutional Filter Pruning Based on Functionality \". \n\nIn terms of writing, I have difficulty understanding some details about the method. \n\nIn filter clustering, how can one run k-means based on pair-wise similarity matrix $S_D$? Do you run kernel k-means, or you  apply PCA to $S_D$ before k-means? What is the criterion of choosing the number of clusters in the process of grid search? \n\nAre filter level pruning, are cluster level pruning and layer level pruning three pruning strategies in the algorithm? It seems to me that you just apply one pruning strategy based on the clusters and contribution index, as shown in Figure 3. \n\nIn the subsubsection \"Cluster Level Pruning\", by \"cluster volume size\", denoted with$length(C^l_c)$, do you mean the size of cluster, i.e., the number of elements in each cluster? This is the first time I see the term \"volume size\". I assume the adaptive pruning rate, denoted by $R_{clt}^{(c,l)}$, is a fraction. But it looks to me that $length(C^l_c)$ is an integer. So how can it be true that $R_{clt}^{(c,l)} = length(C^l_c)$?\n\nIn the subsubsection \"Layer Level Pruning\", how is the value of $r$ determined?\n\nThe authors have conducted several experiments. These experiments help me understand the advantages of the proposed method. However, in the experiments, the proposed method is compared to only one baseline method. In recent years, a large number of convolutional filter pruning methods have been proposed, as mentioned in the related work section. I am not convinced that the proposed method is one of the best methods among all these existing methods. I would suggest the authors provide more experimental comparison, or explain why comparing with these existing methods is irrelevant. \n\nSince the proposed method is heuristic, I would also like the authors to illustrate that each component of the method is important, via experiment. How would the performance of the proposed method be affected, if we define the similarity $S_D$ in Equation (3) using only $V$ or $\\gamma$, rather than both $V$ and $\\gamma$? How would the performance of the proposed method be affected, if we prune randomly, rather than prune based on the contribution index?\n\nIn summary, I think the method proposed in this paper might be reasonable. But I do not suggest acceptance, unless the author can improve the writing and include more experimental results.\n\n", "rating": "4: Ok but not good enough - rejection", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["ICLR.cc/2019/Conference/Paper1450/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "INTERPRETABLE CONVOLUTIONAL FILTER PRUNING", "abstract": "The sophisticated structure of Convolutional Neural Network (CNN) allows for\noutstanding performance, but at the cost of intensive computation. As significant\nredundancies inevitably present in such a structure, many works have been proposed\nto prune the convolutional filters for computation cost reduction. Although\nextremely effective, most works are based only on quantitative characteristics of\nthe convolutional filters, and highly overlook the qualitative interpretation of individual\nfilter\u2019s specific functionality. In this work, we interpreted the functionality\nand redundancy of the convolutional filters from different perspectives, and proposed\na functionality-oriented filter pruning method. With extensive experiment\nresults, we proved the convolutional filters\u2019 qualitative significance regardless of\nmagnitude, demonstrated significant neural network redundancy due to repetitive\nfilter functions, and analyzed the filter functionality defection under inappropriate\nretraining process. Such an interpretable pruning approach not only offers outstanding\ncomputation cost optimization over previous filter pruning methods, but\nalso interprets filter pruning process.", "keywords": [], "authorids": ["zqin@gmu.edu", "fyu2@gmu.edu", "chliu@clarkson.edu", "xchen26@gmu.edu"], "authors": ["Zhuwei Qin", "Fuxun Yu", "Chenchen Liu", "Xiang Chen"], "pdf": "/pdf/3365464c9f60f06eb097a49f5a0d9eaea5c969f1.pdf", "paperhash": "qin|interpretable_convolutional_filter_pruning", "_bibtex": "@misc{\nqin2019interpretable,\ntitle={{INTERPRETABLE} {CONVOLUTIONAL} {FILTER} {PRUNING}},\nauthor={Zhuwei Qin and Fuxun Yu and Chenchen Liu and Xiang Chen},\nyear={2019},\nurl={https://openreview.net/forum?id=BJ4BVhRcYX},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper1450/Official_Review", "cdate": 1542234226915, "expdate": 1552335264000, "duedate": 1541196000000, "reply": {"forum": "BJ4BVhRcYX", "replyto": "BJ4BVhRcYX", "readers": {"description": "The users who will be allowed to read the reply content.", "values": ["everyone"]}, "nonreaders": {"values": []}, "signatures": {"description": "How your identity will be displayed with the above content.", "values-regex": "ICLR.cc/2019/Conference/Paper1450/AnonReviewer[0-9]+"}, "writers": {"description": "Users that may modify this record.", "values": ["ICLR.cc/2019/Conference"]}, "content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "required": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}}, "multiReply": false, "tcdate": 1552335949503, "tmdate": 1552335949503, "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "invitees": ["ICLR.cc/2019/Conference/Paper1450/Reviewers"], "noninvitees": [], "signatures": ["ICLR.cc/2019/Conference"]}}}, {"id": "rkx77wMth7", "original": null, "number": 2, "cdate": 1541117723162, "ddate": null, "tcdate": 1541117723162, "tmdate": 1541533122780, "tddate": null, "forum": "BJ4BVhRcYX", "replyto": "BJ4BVhRcYX", "invitation": "ICLR.cc/2019/Conference/-/Paper1450/Official_Review", "content": {"title": "Good idea, but needs some improvements.", "review": "This paper proposes a new method to prune filters of convolutional nets based on a metric which consider functional similarities between filters. Those similarities are computed based on Activation Maximization and gradient information. The proposed method is better than L1 and activation-based methods in terms of accuracy after pruning at the same pruning ratio. The visualization of pruned filters (Fig. 3) shows the effectiveness of the method intuitively. \n\nOverall, the idea in the paper is pretty intuitive and makes sense. The experimental results support the ideas. I think this paper could be accepted if it is improved on the followings:\n\n1. The paper is not very easy to read although the idea is simple.  \n\nThe equations could be updated and simplified. For example, I'm not sure if S_D in Eq. (3) wants to take V(F_i^(c,l)) and V(F_k^(c,l)) as the arguments. Layer L_l could be just l. \n\nAlgorithm 1 is hard to read. At least, one line should correspond to one processing. k is not initialized. It is difficult to understand what each variable represents.\n\nThe terms used in Section 4.2 may not be very accurate. First of all, I'm not sure if it is a hierarchical method. It does not perform pruning at multiple levels such as filters, clusters, and layers. Rather, it considers information from multiple levels to determine if a filter should be pruned or not. In that sense, everything is filter level pruning and distinguishing (filter|cluster|layer) level pruning just confuse readers. I'd recommend to simplify the section and describe simply what you do.\n\n2. Comparisons with more recent papers\n\nThe proposed method was compared with methods from 2015 and 2016. Model compression is an active area of research and there are a lot of papers. Probably, it makes sense to compare the proposed method against some state-of-the-art methods. Especially, it is interesting to see comparisons against methods with direct optimization of loss function such as (Liu et al. ICCV 2017). We might not need to even consider functionality with such methods.\n\nLiu et al. ICCV 2017: https://arxiv.org/pdf/1708.06519.pdf\n\n\n* Some other thoughts\n\n** If you look at Figure 3 (a), it looks that there are still a lot of redundant filters. Actually, except the last row, I'm not sure if we can visually find any important difference between (a) and (b). I wonder if the most important thing is that you do not prune unique filters (ones which are not clustered with others). It might be interesting to see a result of the L1-based pruning which does not prunes such filters. If you see an interesting result from that, it could add some value to the paper.\n\n** I'd recommend another proofread.", "rating": "4: Ok but not good enough - rejection", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "signatures": ["ICLR.cc/2019/Conference/Paper1450/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "INTERPRETABLE CONVOLUTIONAL FILTER PRUNING", "abstract": "The sophisticated structure of Convolutional Neural Network (CNN) allows for\noutstanding performance, but at the cost of intensive computation. As significant\nredundancies inevitably present in such a structure, many works have been proposed\nto prune the convolutional filters for computation cost reduction. Although\nextremely effective, most works are based only on quantitative characteristics of\nthe convolutional filters, and highly overlook the qualitative interpretation of individual\nfilter\u2019s specific functionality. In this work, we interpreted the functionality\nand redundancy of the convolutional filters from different perspectives, and proposed\na functionality-oriented filter pruning method. With extensive experiment\nresults, we proved the convolutional filters\u2019 qualitative significance regardless of\nmagnitude, demonstrated significant neural network redundancy due to repetitive\nfilter functions, and analyzed the filter functionality defection under inappropriate\nretraining process. Such an interpretable pruning approach not only offers outstanding\ncomputation cost optimization over previous filter pruning methods, but\nalso interprets filter pruning process.", "keywords": [], "authorids": ["zqin@gmu.edu", "fyu2@gmu.edu", "chliu@clarkson.edu", "xchen26@gmu.edu"], "authors": ["Zhuwei Qin", "Fuxun Yu", "Chenchen Liu", "Xiang Chen"], "pdf": "/pdf/3365464c9f60f06eb097a49f5a0d9eaea5c969f1.pdf", "paperhash": "qin|interpretable_convolutional_filter_pruning", "_bibtex": "@misc{\nqin2019interpretable,\ntitle={{INTERPRETABLE} {CONVOLUTIONAL} {FILTER} {PRUNING}},\nauthor={Zhuwei Qin and Fuxun Yu and Chenchen Liu and Xiang Chen},\nyear={2019},\nurl={https://openreview.net/forum?id=BJ4BVhRcYX},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper1450/Official_Review", "cdate": 1542234226915, "expdate": 1552335264000, "duedate": 1541196000000, "reply": {"forum": "BJ4BVhRcYX", "replyto": "BJ4BVhRcYX", "readers": {"description": "The users who will be allowed to read the reply content.", "values": ["everyone"]}, "nonreaders": {"values": []}, "signatures": {"description": "How your identity will be displayed with the above content.", "values-regex": "ICLR.cc/2019/Conference/Paper1450/AnonReviewer[0-9]+"}, "writers": {"description": "Users that may modify this record.", "values": ["ICLR.cc/2019/Conference"]}, "content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "required": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}}, "multiReply": false, "tcdate": 1552335949503, "tmdate": 1552335949503, "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "invitees": ["ICLR.cc/2019/Conference/Paper1450/Reviewers"], "noninvitees": [], "signatures": ["ICLR.cc/2019/Conference"]}}}, {"id": "SylR62qQ3Q", "original": null, "number": 1, "cdate": 1540758726259, "ddate": null, "tcdate": 1540758726259, "tmdate": 1541533122572, "tddate": null, "forum": "BJ4BVhRcYX", "replyto": "BJ4BVhRcYX", "invitation": "ICLR.cc/2019/Conference/-/Paper1450/Official_Review", "content": {"title": "No comparisons and claiming something known make it hard to accept this paper", "review": "This paper claims to have shown some insights about the filters in a neural network. However, it has little contributions that are justifiable to be published and it missed way too many references.\n\nThe visualization of filters is hardly any contribution over [1]. The claim that AM is the best visualization tool is a weird statement given that there are many recent references on visualization, such as [2-4], which the authors all missed.\n\nThe proposed filter pruning is a simplistic approach that bears little technical novelty, and there has been zero comparison against any filter pruning approach/network compression approach, among the cited references and numerous references that the paper didn't cite, e.g. [5-6]. In this form I cannot accept this paper.\n\n[1] D Bau, B Zhou, A Khosla, A Oliva, and A Torralba. Network Dissection: Quantifying the Intepretability of Deep Visual Representations. In CVPR 2017.\n[2] Ramprasaath R. Selvaraju, Michael Cogswell, Abhishek Das, Ramakrishna Vedantam, Devi Parikh Dhruv Batra. Grad-CAM: Visual Explanations from Deep Networks via Gradient-based Localization. ICCV 2017\n[3] Jianming Zhang, Zhe Lin, Jonathan Brandt, Xiaohui Shen, Stan Sclaroff. Top-down Neural Attention by Excitation Backprop. ECCV 2016\n[4] Ruth Fong and Andrea Vedaldi. Interpretable Explanations of Black Box Algorithms by Meaningful Perturbation. ICCV 2017\n[5] Y. Guo, A. Yao and Y. Chen. Dynamic Network Surgery for Efficient DNNs. NIPS 2016\n[6] T.-J. Yang, Y.-H. Chen, V. Sze. Designing Energy-Efficient Convolutional Neural Networks using Energy-Aware Pruning. CVPR 2017", "rating": "3: Clear rejection", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["ICLR.cc/2019/Conference/Paper1450/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "INTERPRETABLE CONVOLUTIONAL FILTER PRUNING", "abstract": "The sophisticated structure of Convolutional Neural Network (CNN) allows for\noutstanding performance, but at the cost of intensive computation. As significant\nredundancies inevitably present in such a structure, many works have been proposed\nto prune the convolutional filters for computation cost reduction. Although\nextremely effective, most works are based only on quantitative characteristics of\nthe convolutional filters, and highly overlook the qualitative interpretation of individual\nfilter\u2019s specific functionality. In this work, we interpreted the functionality\nand redundancy of the convolutional filters from different perspectives, and proposed\na functionality-oriented filter pruning method. With extensive experiment\nresults, we proved the convolutional filters\u2019 qualitative significance regardless of\nmagnitude, demonstrated significant neural network redundancy due to repetitive\nfilter functions, and analyzed the filter functionality defection under inappropriate\nretraining process. Such an interpretable pruning approach not only offers outstanding\ncomputation cost optimization over previous filter pruning methods, but\nalso interprets filter pruning process.", "keywords": [], "authorids": ["zqin@gmu.edu", "fyu2@gmu.edu", "chliu@clarkson.edu", "xchen26@gmu.edu"], "authors": ["Zhuwei Qin", "Fuxun Yu", "Chenchen Liu", "Xiang Chen"], "pdf": "/pdf/3365464c9f60f06eb097a49f5a0d9eaea5c969f1.pdf", "paperhash": "qin|interpretable_convolutional_filter_pruning", "_bibtex": "@misc{\nqin2019interpretable,\ntitle={{INTERPRETABLE} {CONVOLUTIONAL} {FILTER} {PRUNING}},\nauthor={Zhuwei Qin and Fuxun Yu and Chenchen Liu and Xiang Chen},\nyear={2019},\nurl={https://openreview.net/forum?id=BJ4BVhRcYX},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper1450/Official_Review", "cdate": 1542234226915, "expdate": 1552335264000, "duedate": 1541196000000, "reply": {"forum": "BJ4BVhRcYX", "replyto": "BJ4BVhRcYX", "readers": {"description": "The users who will be allowed to read the reply content.", "values": ["everyone"]}, "nonreaders": {"values": []}, "signatures": {"description": "How your identity will be displayed with the above content.", "values-regex": "ICLR.cc/2019/Conference/Paper1450/AnonReviewer[0-9]+"}, "writers": {"description": "Users that may modify this record.", "values": ["ICLR.cc/2019/Conference"]}, "content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "required": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}}, "multiReply": false, "tcdate": 1552335949503, "tmdate": 1552335949503, "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "invitees": ["ICLR.cc/2019/Conference/Paper1450/Reviewers"], "noninvitees": [], "signatures": ["ICLR.cc/2019/Conference"]}}}, {"id": "rkgsMoynhQ", "original": null, "number": 11, "cdate": 1541303058881, "ddate": null, "tcdate": 1541303058881, "tmdate": 1541303231178, "tddate": null, "forum": "BJ4BVhRcYX", "replyto": "BJ4BVhRcYX", "invitation": "ICLR.cc/2019/Conference/-/Paper1450/Public_Comment", "content": {"comment": "I appreciate the efforts authors made to address the comments by others. I think since some comments below are very aggressive and annoying,  so I suggest that all reviewers should judge this paper fairly and independently. Thank you for your understanding.", "title": "Comments are just comments, not reviews."}, "signatures": ["(anonymous)"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper1450/Reviewers/Unsubmitted"], "writers": ["(anonymous)", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "INTERPRETABLE CONVOLUTIONAL FILTER PRUNING", "abstract": "The sophisticated structure of Convolutional Neural Network (CNN) allows for\noutstanding performance, but at the cost of intensive computation. As significant\nredundancies inevitably present in such a structure, many works have been proposed\nto prune the convolutional filters for computation cost reduction. Although\nextremely effective, most works are based only on quantitative characteristics of\nthe convolutional filters, and highly overlook the qualitative interpretation of individual\nfilter\u2019s specific functionality. In this work, we interpreted the functionality\nand redundancy of the convolutional filters from different perspectives, and proposed\na functionality-oriented filter pruning method. With extensive experiment\nresults, we proved the convolutional filters\u2019 qualitative significance regardless of\nmagnitude, demonstrated significant neural network redundancy due to repetitive\nfilter functions, and analyzed the filter functionality defection under inappropriate\nretraining process. Such an interpretable pruning approach not only offers outstanding\ncomputation cost optimization over previous filter pruning methods, but\nalso interprets filter pruning process.", "keywords": [], "authorids": ["zqin@gmu.edu", "fyu2@gmu.edu", "chliu@clarkson.edu", "xchen26@gmu.edu"], "authors": ["Zhuwei Qin", "Fuxun Yu", "Chenchen Liu", "Xiang Chen"], "pdf": "/pdf/3365464c9f60f06eb097a49f5a0d9eaea5c969f1.pdf", "paperhash": "qin|interpretable_convolutional_filter_pruning", "_bibtex": "@misc{\nqin2019interpretable,\ntitle={{INTERPRETABLE} {CONVOLUTIONAL} {FILTER} {PRUNING}},\nauthor={Zhuwei Qin and Fuxun Yu and Chenchen Liu and Xiang Chen},\nyear={2019},\nurl={https://openreview.net/forum?id=BJ4BVhRcYX},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper1450/Public_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1542311594529, "tddate": null, "super": null, "final": null, "reply": {"signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed."}, "nonreaders": {"values": []}, "forum": "BJ4BVhRcYX", "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper1450/Authors", "ICLR.cc/2019/Conference/Paper1450/Reviewers", "ICLR.cc/2019/Conference/Paper1450/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "replyto": null, "content": {"comment": {"value-regex": "[\\S\\s]{1,5000}", "required": true, "order": 1, "description": "Your comment or reply (max 5000 characters)."}, "title": {"value-regex": ".{1,500}", "required": true, "order": 0, "description": "Brief summary of your comment."}}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["~"], "noninvitees": ["ICLR.cc/2019/Conference/Paper1450/Authors", "ICLR.cc/2019/Conference/Paper1450/Reviewers", "ICLR.cc/2019/Conference/Paper1450/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1542311594529}}}, {"id": "ByeoB1kn37", "original": null, "number": 7, "cdate": 1541300034631, "ddate": null, "tcdate": 1541300034631, "tmdate": 1541300611764, "tddate": null, "forum": "BJ4BVhRcYX", "replyto": "ryeOJfJ92Q", "invitation": "ICLR.cc/2019/Conference/-/Paper1450/Official_Comment", "content": {"title": "To All Reviewers from Authors", "comment": "Dear Reviewers:\n\nWe have done our best to clarify our works to the original poster.\nIf you are looking for answers regarding the question of \"problem settings of pruning trained models\" and \"baseline selection\", please refer to the below replies. \n\nWe are still very open to other questions, and we will do our best to reply to those constructive ones.\nHowever, we hope future reviewers could fully read our paper and fairly review our contributions without being influenced by some very aggressive comments below.\n\nAuthors.\n"}, "signatures": ["ICLR.cc/2019/Conference/Paper1450/Authors"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper1450/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper1450/Authors", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "INTERPRETABLE CONVOLUTIONAL FILTER PRUNING", "abstract": "The sophisticated structure of Convolutional Neural Network (CNN) allows for\noutstanding performance, but at the cost of intensive computation. As significant\nredundancies inevitably present in such a structure, many works have been proposed\nto prune the convolutional filters for computation cost reduction. Although\nextremely effective, most works are based only on quantitative characteristics of\nthe convolutional filters, and highly overlook the qualitative interpretation of individual\nfilter\u2019s specific functionality. In this work, we interpreted the functionality\nand redundancy of the convolutional filters from different perspectives, and proposed\na functionality-oriented filter pruning method. With extensive experiment\nresults, we proved the convolutional filters\u2019 qualitative significance regardless of\nmagnitude, demonstrated significant neural network redundancy due to repetitive\nfilter functions, and analyzed the filter functionality defection under inappropriate\nretraining process. Such an interpretable pruning approach not only offers outstanding\ncomputation cost optimization over previous filter pruning methods, but\nalso interprets filter pruning process.", "keywords": [], "authorids": ["zqin@gmu.edu", "fyu2@gmu.edu", "chliu@clarkson.edu", "xchen26@gmu.edu"], "authors": ["Zhuwei Qin", "Fuxun Yu", "Chenchen Liu", "Xiang Chen"], "pdf": "/pdf/3365464c9f60f06eb097a49f5a0d9eaea5c969f1.pdf", "paperhash": "qin|interpretable_convolutional_filter_pruning", "_bibtex": "@misc{\nqin2019interpretable,\ntitle={{INTERPRETABLE} {CONVOLUTIONAL} {FILTER} {PRUNING}},\nauthor={Zhuwei Qin and Fuxun Yu and Chenchen Liu and Xiang Chen},\nyear={2019},\nurl={https://openreview.net/forum?id=BJ4BVhRcYX},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper1450/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621626464, "tddate": null, "super": null, "final": null, "reply": {"forum": "BJ4BVhRcYX", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper1450/Authors", "ICLR.cc/2019/Conference/Paper1450/Reviewers", "ICLR.cc/2019/Conference/Paper1450/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper1450/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper1450/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper1450/Authors|ICLR.cc/2019/Conference/Paper1450/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper1450/Reviewers", "ICLR.cc/2019/Conference/Paper1450/Authors", "ICLR.cc/2019/Conference/Paper1450/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621626464}}}, {"id": "ryeWpT0j3Q", "original": null, "number": 6, "cdate": 1541299640955, "ddate": null, "tcdate": 1541299640955, "tmdate": 1541299640955, "tddate": null, "forum": "BJ4BVhRcYX", "replyto": "Hkxjz3Kin7", "invitation": "ICLR.cc/2019/Conference/-/Paper1450/Official_Comment", "content": {"title": "Reply to \"some thoughts\" from Authors ", "comment": "Dear Reviewer,\n\nThanks for your comment.\n\n1. The \u201cpruning with regularization during training\u201d and \u201cpruning post normal training\u201d are clearly divided into two different categories and have been well discussed in [1]. Post design optimization is a well-recognized concept in many research areas. And there are also many excellent works emerging for such a pruning approach [2][3]. For more details, we recommend reviewers to refer to these papers. Overall, rather than judging which is better, these are two complementary approaches.\n\n2. We hope the reviewer can broaden the understanding of pruning. As we mentioned in our first reply, different pruning methods are just approaching the minimal network size [4][5]. It\u2019s more important to understand the neural network with pruning. Our contribution in this work is not only pruning, but also interpreting the source of network redundancy. And based on this analysis, we proposed the method to effectively and precisely reduce the functionality redundancy.\n\nAuthors.\n\n[1] Auto-balanced Filter Pruning for Efficient Convolutional neural networks. Ding et al., AAAI 2018.\n[2] NetAdapt: Platform-Aware Neural Network Adaptation for Mobile Applications. Yang et al., ECCV 2018.\n[3] ThiNet: A Filter Level Pruning Method for Deep Neural Network Compression. Luo et al. ICCV, 2017.\n[4] Rethinking the Value of Network Pruning. Liu et al., https://arxiv.org/abs/1810.05270\n[5] Learning Efficient Convolutional Networks through Network Slimming. Liu et al., ICCV 2017.\n"}, "signatures": ["ICLR.cc/2019/Conference/Paper1450/Authors"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper1450/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper1450/Authors", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "INTERPRETABLE CONVOLUTIONAL FILTER PRUNING", "abstract": "The sophisticated structure of Convolutional Neural Network (CNN) allows for\noutstanding performance, but at the cost of intensive computation. As significant\nredundancies inevitably present in such a structure, many works have been proposed\nto prune the convolutional filters for computation cost reduction. Although\nextremely effective, most works are based only on quantitative characteristics of\nthe convolutional filters, and highly overlook the qualitative interpretation of individual\nfilter\u2019s specific functionality. In this work, we interpreted the functionality\nand redundancy of the convolutional filters from different perspectives, and proposed\na functionality-oriented filter pruning method. With extensive experiment\nresults, we proved the convolutional filters\u2019 qualitative significance regardless of\nmagnitude, demonstrated significant neural network redundancy due to repetitive\nfilter functions, and analyzed the filter functionality defection under inappropriate\nretraining process. Such an interpretable pruning approach not only offers outstanding\ncomputation cost optimization over previous filter pruning methods, but\nalso interprets filter pruning process.", "keywords": [], "authorids": ["zqin@gmu.edu", "fyu2@gmu.edu", "chliu@clarkson.edu", "xchen26@gmu.edu"], "authors": ["Zhuwei Qin", "Fuxun Yu", "Chenchen Liu", "Xiang Chen"], "pdf": "/pdf/3365464c9f60f06eb097a49f5a0d9eaea5c969f1.pdf", "paperhash": "qin|interpretable_convolutional_filter_pruning", "_bibtex": "@misc{\nqin2019interpretable,\ntitle={{INTERPRETABLE} {CONVOLUTIONAL} {FILTER} {PRUNING}},\nauthor={Zhuwei Qin and Fuxun Yu and Chenchen Liu and Xiang Chen},\nyear={2019},\nurl={https://openreview.net/forum?id=BJ4BVhRcYX},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper1450/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621626464, "tddate": null, "super": null, "final": null, "reply": {"forum": "BJ4BVhRcYX", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper1450/Authors", "ICLR.cc/2019/Conference/Paper1450/Reviewers", "ICLR.cc/2019/Conference/Paper1450/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper1450/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper1450/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper1450/Authors|ICLR.cc/2019/Conference/Paper1450/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper1450/Reviewers", "ICLR.cc/2019/Conference/Paper1450/Authors", "ICLR.cc/2019/Conference/Paper1450/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621626464}}}, {"id": "S1eXcT8927", "original": null, "number": 2, "cdate": 1541201291471, "ddate": null, "tcdate": 1541201291471, "tmdate": 1541295191331, "tddate": null, "forum": "BJ4BVhRcYX", "replyto": "ryeOJfJ92Q", "invitation": "ICLR.cc/2019/Conference/-/Paper1450/Official_Comment", "content": {"title": "Reply to \"Sloppy Baseline\" from Authors", "comment": "Dear Reviewer:\n\n1. The comment ignores the problem setup and the contribution details.\nOur work is addressing a totally different situation compared to [1][2].\nIn [1][2], they apply sparse constraint during the \u201ctraining\u201d phase, while our work is to interpret the redundancy of a normally \u201ctrained\u201d neural network and propose the functionality oriented pruning method to explore the interpretable neural network optimization. More importantly, our work is proposing a functionality analysis approach with different methods cross-validating each other. We hope such an approach could also be adopted by other compression works to have a better result analysis. Also, the filter L1-ranking based pruning method [3] we are comparing is a well-established work published after [2] in the top conference ICLR 2017, if the authors ignore the problem setup and only chase the final results, we also suggest the reviewer have a discussion with these authors.\n\n2. Also, we don\u2019t think the reviewer should consider the random pruning as a trick. If the reviewer follows the recent papers closely, you may find that many papers [4][5] discussing the significant redundancy inside neural networks, and different pruning methods (even random pruning) could achieve effectiveness eventually as long as the network is keeping retraining. In other words, there might be a certain optimal network size for a neural network\u2019s functionality, and different pruning methods are just approaching this size. However, the questions of how to interpret the redundancy and what the retraining is doing are rarely addressed. In this work, we interpreted the functionality redundancy in a trained neural network. And our work could effectively and precisely reduce the functionality redundancy with the minimum help of the retraining process. Definitely, we understand why the reviewer favors random pruning so much, in this work we also proved that, functionality wise, the filter L1-ranking based pruning is also a kind of random pruning. Overall, \"claiming redundancy\" is easy, but \"analyzing redundancy\" is hard; \"random with retraining\" is easy, but \"precise without retraining\" is hard.\n\nAuthors.\n\n[1] Structured Bayesian Pruning via Log-Normal Multiplicative Noise. Neklyudov et al., NIPS 2017.\n[2] Learning Structured Sparsity in Deep Neural Networks. Wen et al., NIPS 2016.\n[3] Pruning Filters for Efficient ConvNets. Li et al., ICLR 2017.\n[4] Rethinking the Value of Network Pruning. Liu et al., https://arxiv.org/abs/1810.05270\n[5] Recovering from Random Pruning: On the Plasticity of Deep Convolutional Neural Networks. Mittal et al., WACV 2018.\n"}, "signatures": ["ICLR.cc/2019/Conference/Paper1450/Authors"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper1450/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper1450/Authors", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "INTERPRETABLE CONVOLUTIONAL FILTER PRUNING", "abstract": "The sophisticated structure of Convolutional Neural Network (CNN) allows for\noutstanding performance, but at the cost of intensive computation. As significant\nredundancies inevitably present in such a structure, many works have been proposed\nto prune the convolutional filters for computation cost reduction. Although\nextremely effective, most works are based only on quantitative characteristics of\nthe convolutional filters, and highly overlook the qualitative interpretation of individual\nfilter\u2019s specific functionality. In this work, we interpreted the functionality\nand redundancy of the convolutional filters from different perspectives, and proposed\na functionality-oriented filter pruning method. With extensive experiment\nresults, we proved the convolutional filters\u2019 qualitative significance regardless of\nmagnitude, demonstrated significant neural network redundancy due to repetitive\nfilter functions, and analyzed the filter functionality defection under inappropriate\nretraining process. Such an interpretable pruning approach not only offers outstanding\ncomputation cost optimization over previous filter pruning methods, but\nalso interprets filter pruning process.", "keywords": [], "authorids": ["zqin@gmu.edu", "fyu2@gmu.edu", "chliu@clarkson.edu", "xchen26@gmu.edu"], "authors": ["Zhuwei Qin", "Fuxun Yu", "Chenchen Liu", "Xiang Chen"], "pdf": "/pdf/3365464c9f60f06eb097a49f5a0d9eaea5c969f1.pdf", "paperhash": "qin|interpretable_convolutional_filter_pruning", "_bibtex": "@misc{\nqin2019interpretable,\ntitle={{INTERPRETABLE} {CONVOLUTIONAL} {FILTER} {PRUNING}},\nauthor={Zhuwei Qin and Fuxun Yu and Chenchen Liu and Xiang Chen},\nyear={2019},\nurl={https://openreview.net/forum?id=BJ4BVhRcYX},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper1450/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621626464, "tddate": null, "super": null, "final": null, "reply": {"forum": "BJ4BVhRcYX", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper1450/Authors", "ICLR.cc/2019/Conference/Paper1450/Reviewers", "ICLR.cc/2019/Conference/Paper1450/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper1450/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper1450/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper1450/Authors|ICLR.cc/2019/Conference/Paper1450/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper1450/Reviewers", "ICLR.cc/2019/Conference/Paper1450/Authors", "ICLR.cc/2019/Conference/Paper1450/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621626464}}}, {"id": "Hkxjz3Kin7", "original": null, "number": 10, "cdate": 1541278739042, "ddate": null, "tcdate": 1541278739042, "tmdate": 1541278739042, "tddate": null, "forum": "BJ4BVhRcYX", "replyto": "B1g5pnOjh7", "invitation": "ICLR.cc/2019/Conference/-/Paper1450/Public_Comment", "content": {"comment": "Hi Authors,\n\nThanks for the continuing effort on clarifying your paper. In the end, unfortunately I don't feel the argument you gave regarding \u201cpruning with regularization during training\u201d and \u201cpruning post normal training\u201d is convincing. As the person pointed out, if the goal is to prune the network, and accelerate the network, I do not see there is any reason people do not go for the approach that achieves the best results regardless if it falls into the category of pruning with regularization during training or pruning post normal training. In other words, it would be helpful if you can explain your approach addresses some of the limitations/issues of [1] despite being less accurate. Hope this makes some sense.\n\n\n\n[1] 3. Learning Efficient Convolutional Networks through Network Slimming.\n", "title": "some thoughts"}, "signatures": ["(anonymous)"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper1450/Reviewers/Unsubmitted"], "writers": ["(anonymous)", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "INTERPRETABLE CONVOLUTIONAL FILTER PRUNING", "abstract": "The sophisticated structure of Convolutional Neural Network (CNN) allows for\noutstanding performance, but at the cost of intensive computation. As significant\nredundancies inevitably present in such a structure, many works have been proposed\nto prune the convolutional filters for computation cost reduction. Although\nextremely effective, most works are based only on quantitative characteristics of\nthe convolutional filters, and highly overlook the qualitative interpretation of individual\nfilter\u2019s specific functionality. In this work, we interpreted the functionality\nand redundancy of the convolutional filters from different perspectives, and proposed\na functionality-oriented filter pruning method. With extensive experiment\nresults, we proved the convolutional filters\u2019 qualitative significance regardless of\nmagnitude, demonstrated significant neural network redundancy due to repetitive\nfilter functions, and analyzed the filter functionality defection under inappropriate\nretraining process. Such an interpretable pruning approach not only offers outstanding\ncomputation cost optimization over previous filter pruning methods, but\nalso interprets filter pruning process.", "keywords": [], "authorids": ["zqin@gmu.edu", "fyu2@gmu.edu", "chliu@clarkson.edu", "xchen26@gmu.edu"], "authors": ["Zhuwei Qin", "Fuxun Yu", "Chenchen Liu", "Xiang Chen"], "pdf": "/pdf/3365464c9f60f06eb097a49f5a0d9eaea5c969f1.pdf", "paperhash": "qin|interpretable_convolutional_filter_pruning", "_bibtex": "@misc{\nqin2019interpretable,\ntitle={{INTERPRETABLE} {CONVOLUTIONAL} {FILTER} {PRUNING}},\nauthor={Zhuwei Qin and Fuxun Yu and Chenchen Liu and Xiang Chen},\nyear={2019},\nurl={https://openreview.net/forum?id=BJ4BVhRcYX},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper1450/Public_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1542311594529, "tddate": null, "super": null, "final": null, "reply": {"signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed."}, "nonreaders": {"values": []}, "forum": "BJ4BVhRcYX", "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper1450/Authors", "ICLR.cc/2019/Conference/Paper1450/Reviewers", "ICLR.cc/2019/Conference/Paper1450/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "replyto": null, "content": {"comment": {"value-regex": "[\\S\\s]{1,5000}", "required": true, "order": 1, "description": "Your comment or reply (max 5000 characters)."}, "title": {"value-regex": ".{1,500}", "required": true, "order": 0, "description": "Brief summary of your comment."}}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["~"], "noninvitees": ["ICLR.cc/2019/Conference/Paper1450/Authors", "ICLR.cc/2019/Conference/Paper1450/Reviewers", "ICLR.cc/2019/Conference/Paper1450/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1542311594529}}}, {"id": "BkxAhzti37", "original": null, "number": 9, "cdate": 1541276341771, "ddate": null, "tcdate": 1541276341771, "tmdate": 1541276341771, "tddate": null, "forum": "BJ4BVhRcYX", "replyto": "B1g5pnOjh7", "invitation": "ICLR.cc/2019/Conference/-/Paper1450/Public_Comment", "content": {"comment": "I appreciate the efforts authors made to address the comments by others. I think since some commenter and authors are not on the same page,  reviewers should not be influenced by these comments and judge on their own. Thank you.", "title": "Thank you for the reply"}, "signatures": ["(anonymous)"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper1450/Reviewers/Unsubmitted"], "writers": ["(anonymous)", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "INTERPRETABLE CONVOLUTIONAL FILTER PRUNING", "abstract": "The sophisticated structure of Convolutional Neural Network (CNN) allows for\noutstanding performance, but at the cost of intensive computation. As significant\nredundancies inevitably present in such a structure, many works have been proposed\nto prune the convolutional filters for computation cost reduction. Although\nextremely effective, most works are based only on quantitative characteristics of\nthe convolutional filters, and highly overlook the qualitative interpretation of individual\nfilter\u2019s specific functionality. In this work, we interpreted the functionality\nand redundancy of the convolutional filters from different perspectives, and proposed\na functionality-oriented filter pruning method. With extensive experiment\nresults, we proved the convolutional filters\u2019 qualitative significance regardless of\nmagnitude, demonstrated significant neural network redundancy due to repetitive\nfilter functions, and analyzed the filter functionality defection under inappropriate\nretraining process. Such an interpretable pruning approach not only offers outstanding\ncomputation cost optimization over previous filter pruning methods, but\nalso interprets filter pruning process.", "keywords": [], "authorids": ["zqin@gmu.edu", "fyu2@gmu.edu", "chliu@clarkson.edu", "xchen26@gmu.edu"], "authors": ["Zhuwei Qin", "Fuxun Yu", "Chenchen Liu", "Xiang Chen"], "pdf": "/pdf/3365464c9f60f06eb097a49f5a0d9eaea5c969f1.pdf", "paperhash": "qin|interpretable_convolutional_filter_pruning", "_bibtex": "@misc{\nqin2019interpretable,\ntitle={{INTERPRETABLE} {CONVOLUTIONAL} {FILTER} {PRUNING}},\nauthor={Zhuwei Qin and Fuxun Yu and Chenchen Liu and Xiang Chen},\nyear={2019},\nurl={https://openreview.net/forum?id=BJ4BVhRcYX},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper1450/Public_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1542311594529, "tddate": null, "super": null, "final": null, "reply": {"signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed."}, "nonreaders": {"values": []}, "forum": "BJ4BVhRcYX", "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper1450/Authors", "ICLR.cc/2019/Conference/Paper1450/Reviewers", "ICLR.cc/2019/Conference/Paper1450/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "replyto": null, "content": {"comment": {"value-regex": "[\\S\\s]{1,5000}", "required": true, "order": 1, "description": "Your comment or reply (max 5000 characters)."}, "title": {"value-regex": ".{1,500}", "required": true, "order": 0, "description": "Brief summary of your comment."}}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["~"], "noninvitees": ["ICLR.cc/2019/Conference/Paper1450/Authors", "ICLR.cc/2019/Conference/Paper1450/Reviewers", "ICLR.cc/2019/Conference/Paper1450/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1542311594529}}}, {"id": "B1g5pnOjh7", "original": null, "number": 5, "cdate": 1541274818447, "ddate": null, "tcdate": 1541274818447, "tmdate": 1541275048912, "tddate": null, "forum": "BJ4BVhRcYX", "replyto": "Byx5Nt_s2X", "invitation": "ICLR.cc/2019/Conference/-/Paper1450/Official_Comment", "content": {"title": "Reply to \"Sloppy Baseline\" from Authors", "comment": "Dear Reviewer:\n\nFirst of all, we think we have already answered the problem setting. \u201cpruning with regularization during training\u201d and \u201cpruning post normal training\u201d are the most intuitive explanation we can provide. For more details, please refer to the paper [1], which is published in AAAI 2018.\n \nSecondly, here is the answer regarding the baseline difference. It\u2019s common that the baseline variance of the same model exists between different works [1][2][3], since people usually train published models from scratch for convenience. We did the same in our work.\nHowever, we didn\u2019t put much effort into chasing the highest performance of the original method, since that\u2019s not the major focus of our work. And this difference actually doesn\u2019t defect our findings of filter functionality analysis, functionality redundancy elimination, retraining analysis, etc. However, we can definitely improve the baseline in a future version.\n\nAgain, we sincerely ask the reviewer to pay more attention to our methods and contributions in our work and other referenced ones, rather than chasing results regardless of problem settings and perfecting baselines. Otherwise, this is an issue of our research philosophy difference, which can\u2019t be well resolved.\n\nAuthors.\n\n[1] Auto-balanced Filter Pruning for Efficient Convolutional neural networks. Ding et al., AAAI 2018.\n[2] Pruning Filters for Efficient ConvNets. Li et al., ICLR 2017.\n[3] Learning to Prune Filters in Convolutional Neural Networks. Huang et al., WAVC2018.\n"}, "signatures": ["ICLR.cc/2019/Conference/Paper1450/Authors"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper1450/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper1450/Authors", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "INTERPRETABLE CONVOLUTIONAL FILTER PRUNING", "abstract": "The sophisticated structure of Convolutional Neural Network (CNN) allows for\noutstanding performance, but at the cost of intensive computation. As significant\nredundancies inevitably present in such a structure, many works have been proposed\nto prune the convolutional filters for computation cost reduction. Although\nextremely effective, most works are based only on quantitative characteristics of\nthe convolutional filters, and highly overlook the qualitative interpretation of individual\nfilter\u2019s specific functionality. In this work, we interpreted the functionality\nand redundancy of the convolutional filters from different perspectives, and proposed\na functionality-oriented filter pruning method. With extensive experiment\nresults, we proved the convolutional filters\u2019 qualitative significance regardless of\nmagnitude, demonstrated significant neural network redundancy due to repetitive\nfilter functions, and analyzed the filter functionality defection under inappropriate\nretraining process. Such an interpretable pruning approach not only offers outstanding\ncomputation cost optimization over previous filter pruning methods, but\nalso interprets filter pruning process.", "keywords": [], "authorids": ["zqin@gmu.edu", "fyu2@gmu.edu", "chliu@clarkson.edu", "xchen26@gmu.edu"], "authors": ["Zhuwei Qin", "Fuxun Yu", "Chenchen Liu", "Xiang Chen"], "pdf": "/pdf/3365464c9f60f06eb097a49f5a0d9eaea5c969f1.pdf", "paperhash": "qin|interpretable_convolutional_filter_pruning", "_bibtex": "@misc{\nqin2019interpretable,\ntitle={{INTERPRETABLE} {CONVOLUTIONAL} {FILTER} {PRUNING}},\nauthor={Zhuwei Qin and Fuxun Yu and Chenchen Liu and Xiang Chen},\nyear={2019},\nurl={https://openreview.net/forum?id=BJ4BVhRcYX},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper1450/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621626464, "tddate": null, "super": null, "final": null, "reply": {"forum": "BJ4BVhRcYX", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper1450/Authors", "ICLR.cc/2019/Conference/Paper1450/Reviewers", "ICLR.cc/2019/Conference/Paper1450/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper1450/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper1450/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper1450/Authors|ICLR.cc/2019/Conference/Paper1450/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper1450/Reviewers", "ICLR.cc/2019/Conference/Paper1450/Authors", "ICLR.cc/2019/Conference/Paper1450/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621626464}}}, {"id": "Byx5Nt_s2X", "original": null, "number": 8, "cdate": 1541273906235, "ddate": null, "tcdate": 1541273906235, "tmdate": 1541273906235, "tddate": null, "forum": "BJ4BVhRcYX", "replyto": "H1g9VAPjn7", "invitation": "ICLR.cc/2019/Conference/-/Paper1450/Public_Comment", "content": {"comment": "1. \"Long Live TIME: Improving Lifetime for Training-In-Memory\nEngines by Structured Gradient Sparsification\".    This paper shows 92.5%\n2. Online Filter Clustering and Pruning for Efficient Convnets\n This paper shows 93.25%.\n3. Learning Efficient Convolutional Networks through Network Slimming.\nThis paper shows 93.66%\n\nNow I show the baseline is much better than the baseline you choose as 90.2%. So consider changing the conclusion of your paper?", "title": "See concrete paper about real cifar10 accuracy by vgg16"}, "signatures": ["(anonymous)"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper1450/Reviewers/Unsubmitted"], "writers": ["(anonymous)", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "INTERPRETABLE CONVOLUTIONAL FILTER PRUNING", "abstract": "The sophisticated structure of Convolutional Neural Network (CNN) allows for\noutstanding performance, but at the cost of intensive computation. As significant\nredundancies inevitably present in such a structure, many works have been proposed\nto prune the convolutional filters for computation cost reduction. Although\nextremely effective, most works are based only on quantitative characteristics of\nthe convolutional filters, and highly overlook the qualitative interpretation of individual\nfilter\u2019s specific functionality. In this work, we interpreted the functionality\nand redundancy of the convolutional filters from different perspectives, and proposed\na functionality-oriented filter pruning method. With extensive experiment\nresults, we proved the convolutional filters\u2019 qualitative significance regardless of\nmagnitude, demonstrated significant neural network redundancy due to repetitive\nfilter functions, and analyzed the filter functionality defection under inappropriate\nretraining process. Such an interpretable pruning approach not only offers outstanding\ncomputation cost optimization over previous filter pruning methods, but\nalso interprets filter pruning process.", "keywords": [], "authorids": ["zqin@gmu.edu", "fyu2@gmu.edu", "chliu@clarkson.edu", "xchen26@gmu.edu"], "authors": ["Zhuwei Qin", "Fuxun Yu", "Chenchen Liu", "Xiang Chen"], "pdf": "/pdf/3365464c9f60f06eb097a49f5a0d9eaea5c969f1.pdf", "paperhash": "qin|interpretable_convolutional_filter_pruning", "_bibtex": "@misc{\nqin2019interpretable,\ntitle={{INTERPRETABLE} {CONVOLUTIONAL} {FILTER} {PRUNING}},\nauthor={Zhuwei Qin and Fuxun Yu and Chenchen Liu and Xiang Chen},\nyear={2019},\nurl={https://openreview.net/forum?id=BJ4BVhRcYX},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper1450/Public_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1542311594529, "tddate": null, "super": null, "final": null, "reply": {"signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed."}, "nonreaders": {"values": []}, "forum": "BJ4BVhRcYX", "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper1450/Authors", "ICLR.cc/2019/Conference/Paper1450/Reviewers", "ICLR.cc/2019/Conference/Paper1450/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "replyto": null, "content": {"comment": {"value-regex": "[\\S\\s]{1,5000}", "required": true, "order": 1, "description": "Your comment or reply (max 5000 characters)."}, "title": {"value-regex": ".{1,500}", "required": true, "order": 0, "description": "Brief summary of your comment."}}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["~"], "noninvitees": ["ICLR.cc/2019/Conference/Paper1450/Authors", "ICLR.cc/2019/Conference/Paper1450/Reviewers", "ICLR.cc/2019/Conference/Paper1450/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1542311594529}}}, {"id": "SJeJqGOsnX", "original": null, "number": 4, "cdate": 1541272199446, "ddate": null, "tcdate": 1541272199446, "tmdate": 1541272199446, "tddate": null, "forum": "BJ4BVhRcYX", "replyto": "SyeCQ2ri3m", "invitation": "ICLR.cc/2019/Conference/-/Paper1450/Official_Comment", "content": {"title": "Reply to \"OP May not be a reviewer\" from Authors", "comment": "Dear Another Reviewer in this thread:\n\nThank you so much for your fair comment in this thread.\n\nWe are trying to collect all the feedback and interact with all the readers since we are taking the OpenReview as a very serious academic society rather social medium.  That's why we are doing our best to reply to the OP with detailed explanation and references. \n\nTherefore, we also agree with you to some extent, since we are always hoping the OP can raise more constructive questions and help us to improve.\n\nAgain, thank you so much for your support.\n\nAuthors\n"}, "signatures": ["ICLR.cc/2019/Conference/Paper1450/Authors"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper1450/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper1450/Authors", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "INTERPRETABLE CONVOLUTIONAL FILTER PRUNING", "abstract": "The sophisticated structure of Convolutional Neural Network (CNN) allows for\noutstanding performance, but at the cost of intensive computation. As significant\nredundancies inevitably present in such a structure, many works have been proposed\nto prune the convolutional filters for computation cost reduction. Although\nextremely effective, most works are based only on quantitative characteristics of\nthe convolutional filters, and highly overlook the qualitative interpretation of individual\nfilter\u2019s specific functionality. In this work, we interpreted the functionality\nand redundancy of the convolutional filters from different perspectives, and proposed\na functionality-oriented filter pruning method. With extensive experiment\nresults, we proved the convolutional filters\u2019 qualitative significance regardless of\nmagnitude, demonstrated significant neural network redundancy due to repetitive\nfilter functions, and analyzed the filter functionality defection under inappropriate\nretraining process. Such an interpretable pruning approach not only offers outstanding\ncomputation cost optimization over previous filter pruning methods, but\nalso interprets filter pruning process.", "keywords": [], "authorids": ["zqin@gmu.edu", "fyu2@gmu.edu", "chliu@clarkson.edu", "xchen26@gmu.edu"], "authors": ["Zhuwei Qin", "Fuxun Yu", "Chenchen Liu", "Xiang Chen"], "pdf": "/pdf/3365464c9f60f06eb097a49f5a0d9eaea5c969f1.pdf", "paperhash": "qin|interpretable_convolutional_filter_pruning", "_bibtex": "@misc{\nqin2019interpretable,\ntitle={{INTERPRETABLE} {CONVOLUTIONAL} {FILTER} {PRUNING}},\nauthor={Zhuwei Qin and Fuxun Yu and Chenchen Liu and Xiang Chen},\nyear={2019},\nurl={https://openreview.net/forum?id=BJ4BVhRcYX},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper1450/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621626464, "tddate": null, "super": null, "final": null, "reply": {"forum": "BJ4BVhRcYX", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper1450/Authors", "ICLR.cc/2019/Conference/Paper1450/Reviewers", "ICLR.cc/2019/Conference/Paper1450/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper1450/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper1450/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper1450/Authors|ICLR.cc/2019/Conference/Paper1450/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper1450/Reviewers", "ICLR.cc/2019/Conference/Paper1450/Authors", "ICLR.cc/2019/Conference/Paper1450/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621626464}}}, {"id": "H1g9VAPjn7", "original": null, "number": 6, "cdate": 1541271089532, "ddate": null, "tcdate": 1541271089532, "tmdate": 1541271923903, "tddate": null, "forum": "BJ4BVhRcYX", "replyto": "Syggr2Ushm", "invitation": "ICLR.cc/2019/Conference/-/Paper1450/Public_Comment", "content": {"comment": "I am not an author of this work and I am not an expert in this field. But I really dislike your tone when you comment on others' work. Your comments are really unconvincing.\nFirstly, you mention there are good results from others publication, but you don't list any publications to support your argument, whereas the response of the authors referred some of the literature.\nSecondly, the link you mention to achieve 93% accuracy did not work. You should check that and give concrete papers.\nThirdly, Please avoid using questions like ' how do you explain this' and so 'why you still claim there are different'. These are very offensive, this is not social media but an academic venue.\nFinally, I recommend that the program committees of the ICLR conference should consider restricting the comments from non-reviewers. The authors have to waste much unnecessary time responding to low-quality comments here. Thank you very much.", "title": "Please watch your tone when commenting others work"}, "signatures": ["(anonymous)"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper1450/Reviewers/Unsubmitted"], "writers": ["(anonymous)", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "INTERPRETABLE CONVOLUTIONAL FILTER PRUNING", "abstract": "The sophisticated structure of Convolutional Neural Network (CNN) allows for\noutstanding performance, but at the cost of intensive computation. As significant\nredundancies inevitably present in such a structure, many works have been proposed\nto prune the convolutional filters for computation cost reduction. Although\nextremely effective, most works are based only on quantitative characteristics of\nthe convolutional filters, and highly overlook the qualitative interpretation of individual\nfilter\u2019s specific functionality. In this work, we interpreted the functionality\nand redundancy of the convolutional filters from different perspectives, and proposed\na functionality-oriented filter pruning method. With extensive experiment\nresults, we proved the convolutional filters\u2019 qualitative significance regardless of\nmagnitude, demonstrated significant neural network redundancy due to repetitive\nfilter functions, and analyzed the filter functionality defection under inappropriate\nretraining process. Such an interpretable pruning approach not only offers outstanding\ncomputation cost optimization over previous filter pruning methods, but\nalso interprets filter pruning process.", "keywords": [], "authorids": ["zqin@gmu.edu", "fyu2@gmu.edu", "chliu@clarkson.edu", "xchen26@gmu.edu"], "authors": ["Zhuwei Qin", "Fuxun Yu", "Chenchen Liu", "Xiang Chen"], "pdf": "/pdf/3365464c9f60f06eb097a49f5a0d9eaea5c969f1.pdf", "paperhash": "qin|interpretable_convolutional_filter_pruning", "_bibtex": "@misc{\nqin2019interpretable,\ntitle={{INTERPRETABLE} {CONVOLUTIONAL} {FILTER} {PRUNING}},\nauthor={Zhuwei Qin and Fuxun Yu and Chenchen Liu and Xiang Chen},\nyear={2019},\nurl={https://openreview.net/forum?id=BJ4BVhRcYX},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper1450/Public_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1542311594529, "tddate": null, "super": null, "final": null, "reply": {"signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed."}, "nonreaders": {"values": []}, "forum": "BJ4BVhRcYX", "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper1450/Authors", "ICLR.cc/2019/Conference/Paper1450/Reviewers", "ICLR.cc/2019/Conference/Paper1450/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "replyto": null, "content": {"comment": {"value-regex": "[\\S\\s]{1,5000}", "required": true, "order": 1, "description": "Your comment or reply (max 5000 characters)."}, "title": {"value-regex": ".{1,500}", "required": true, "order": 0, "description": "Brief summary of your comment."}}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["~"], "noninvitees": ["ICLR.cc/2019/Conference/Paper1450/Authors", "ICLR.cc/2019/Conference/Paper1450/Reviewers", "ICLR.cc/2019/Conference/Paper1450/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1542311594529}}}, {"id": "HyezvMrohm", "original": null, "number": 3, "cdate": 1541259866045, "ddate": null, "tcdate": 1541259866045, "tmdate": 1541267503418, "tddate": null, "forum": "BJ4BVhRcYX", "replyto": "r1e7sGdqnQ", "invitation": "ICLR.cc/2019/Conference/-/Paper1450/Official_Comment", "content": {"title": "Reply to \"Sloppy Baseline\" from Authors", "comment": "Dear Reviewer:\n\nWe appreciate that you admitted the novelty of our work. However, we\u2019d like to remind the reviewer again: Firstly, not all the papers with \u201cpruning\u201d in its title have a similar problem setting, \u201cpruning with regularization during training\u201d and \u201cpruning post normal training\u201d are different, and each of them has dedicated publications [1][2]. And we also hope people can explore more settings in different perspectives. Secondly, when we are comparing our research to others, we have already clearly shown our advantage over the baselines, and hope you can also carefully read our advantage in the retraining part.\n\nAuthors.\n\n[1] Fast convnets using group-wise brain damage. Lebedev et al., CVPR 2016.\n[2] Network trimming: A data-driven neuron pruning approach towards efficient deep architectures. Hu et al., 2016. https://arxiv.org/abs/1607.03250\n"}, "signatures": ["ICLR.cc/2019/Conference/Paper1450/Authors"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper1450/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper1450/Authors", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "INTERPRETABLE CONVOLUTIONAL FILTER PRUNING", "abstract": "The sophisticated structure of Convolutional Neural Network (CNN) allows for\noutstanding performance, but at the cost of intensive computation. As significant\nredundancies inevitably present in such a structure, many works have been proposed\nto prune the convolutional filters for computation cost reduction. Although\nextremely effective, most works are based only on quantitative characteristics of\nthe convolutional filters, and highly overlook the qualitative interpretation of individual\nfilter\u2019s specific functionality. In this work, we interpreted the functionality\nand redundancy of the convolutional filters from different perspectives, and proposed\na functionality-oriented filter pruning method. With extensive experiment\nresults, we proved the convolutional filters\u2019 qualitative significance regardless of\nmagnitude, demonstrated significant neural network redundancy due to repetitive\nfilter functions, and analyzed the filter functionality defection under inappropriate\nretraining process. Such an interpretable pruning approach not only offers outstanding\ncomputation cost optimization over previous filter pruning methods, but\nalso interprets filter pruning process.", "keywords": [], "authorids": ["zqin@gmu.edu", "fyu2@gmu.edu", "chliu@clarkson.edu", "xchen26@gmu.edu"], "authors": ["Zhuwei Qin", "Fuxun Yu", "Chenchen Liu", "Xiang Chen"], "pdf": "/pdf/3365464c9f60f06eb097a49f5a0d9eaea5c969f1.pdf", "paperhash": "qin|interpretable_convolutional_filter_pruning", "_bibtex": "@misc{\nqin2019interpretable,\ntitle={{INTERPRETABLE} {CONVOLUTIONAL} {FILTER} {PRUNING}},\nauthor={Zhuwei Qin and Fuxun Yu and Chenchen Liu and Xiang Chen},\nyear={2019},\nurl={https://openreview.net/forum?id=BJ4BVhRcYX},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper1450/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621626464, "tddate": null, "super": null, "final": null, "reply": {"forum": "BJ4BVhRcYX", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper1450/Authors", "ICLR.cc/2019/Conference/Paper1450/Reviewers", "ICLR.cc/2019/Conference/Paper1450/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper1450/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper1450/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper1450/Authors|ICLR.cc/2019/Conference/Paper1450/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper1450/Reviewers", "ICLR.cc/2019/Conference/Paper1450/Authors", "ICLR.cc/2019/Conference/Paper1450/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621626464}}}, {"id": "Syggr2Ushm", "original": null, "number": 5, "cdate": 1541266487959, "ddate": null, "tcdate": 1541266487959, "tmdate": 1541266487959, "tddate": null, "forum": "BJ4BVhRcYX", "replyto": "HyezvMrohm", "invitation": "ICLR.cc/2019/Conference/-/Paper1450/Public_Comment", "content": {"comment": "First of all, you didn't compare with previous published showing good results and didn't explain why you don't compare with them. In addition, you didn't explain the difference between them. Since \u201cpruning with regularization during training\u201d and \u201cpruning post normal training\u201d is different, and why people choose to do this, and what is reason behind them. If the final goal is to prune the network, and accelerate the network, so why you still claim there are different?\nSecond, you claim baseline accuracy of cifar10 under Vgg16 is 90.2%, and you got 90.3%, then I am telling you the baseline is around 93%. I don't have to search a lot, just randomly search on github, https://github.com/geifmany/cifar-vgg. And they got 93%, how do you explain this. From this way, your accuracy has decreased 3% and lots of papers do the pruning without the accuracy decrease, so how can you explain the advantage of your method.", "title": "Still Not Answer My Question"}, "signatures": ["(anonymous)"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper1450/Reviewers/Unsubmitted"], "writers": ["(anonymous)", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "INTERPRETABLE CONVOLUTIONAL FILTER PRUNING", "abstract": "The sophisticated structure of Convolutional Neural Network (CNN) allows for\noutstanding performance, but at the cost of intensive computation. As significant\nredundancies inevitably present in such a structure, many works have been proposed\nto prune the convolutional filters for computation cost reduction. Although\nextremely effective, most works are based only on quantitative characteristics of\nthe convolutional filters, and highly overlook the qualitative interpretation of individual\nfilter\u2019s specific functionality. In this work, we interpreted the functionality\nand redundancy of the convolutional filters from different perspectives, and proposed\na functionality-oriented filter pruning method. With extensive experiment\nresults, we proved the convolutional filters\u2019 qualitative significance regardless of\nmagnitude, demonstrated significant neural network redundancy due to repetitive\nfilter functions, and analyzed the filter functionality defection under inappropriate\nretraining process. Such an interpretable pruning approach not only offers outstanding\ncomputation cost optimization over previous filter pruning methods, but\nalso interprets filter pruning process.", "keywords": [], "authorids": ["zqin@gmu.edu", "fyu2@gmu.edu", "chliu@clarkson.edu", "xchen26@gmu.edu"], "authors": ["Zhuwei Qin", "Fuxun Yu", "Chenchen Liu", "Xiang Chen"], "pdf": "/pdf/3365464c9f60f06eb097a49f5a0d9eaea5c969f1.pdf", "paperhash": "qin|interpretable_convolutional_filter_pruning", "_bibtex": "@misc{\nqin2019interpretable,\ntitle={{INTERPRETABLE} {CONVOLUTIONAL} {FILTER} {PRUNING}},\nauthor={Zhuwei Qin and Fuxun Yu and Chenchen Liu and Xiang Chen},\nyear={2019},\nurl={https://openreview.net/forum?id=BJ4BVhRcYX},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper1450/Public_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1542311594529, "tddate": null, "super": null, "final": null, "reply": {"signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed."}, "nonreaders": {"values": []}, "forum": "BJ4BVhRcYX", "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper1450/Authors", "ICLR.cc/2019/Conference/Paper1450/Reviewers", "ICLR.cc/2019/Conference/Paper1450/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "replyto": null, "content": {"comment": {"value-regex": "[\\S\\s]{1,5000}", "required": true, "order": 1, "description": "Your comment or reply (max 5000 characters)."}, "title": {"value-regex": ".{1,500}", "required": true, "order": 0, "description": "Brief summary of your comment."}}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["~"], "noninvitees": ["ICLR.cc/2019/Conference/Paper1450/Authors", "ICLR.cc/2019/Conference/Paper1450/Reviewers", "ICLR.cc/2019/Conference/Paper1450/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1542311594529}}}, {"id": "SyeCQ2ri3m", "original": null, "number": 4, "cdate": 1541262374053, "ddate": null, "tcdate": 1541262374053, "tmdate": 1541263276698, "tddate": null, "forum": "BJ4BVhRcYX", "replyto": "HyezvMrohm", "invitation": "ICLR.cc/2019/Conference/-/Paper1450/Public_Comment", "content": {"comment": " It is very likely that the OP for this thread is not a reviewer.\n\n Bare in mind anyone can sign as anonymous, whilst reviewers have been signing as anonreviewer\\d+ .  \n\n Furthermore the comments that the OP has written are very hard to parse, there was little effort put in to proof-checking the grammar.  If OP is indeed a reviewer then they should probably conform to the standards and sign as anonreviewer\\d+ . \n\n Openreview should probably restrict the comments from non-reviewers. I feel this is creating a lot of clutter and turning this process/platform in to some form of social medium.", "title": "Reply to \"Sloppy Baseline\"  (OP May not be a reviewer)"}, "signatures": ["(anonymous)"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper1450/Reviewers/Unsubmitted"], "writers": ["(anonymous)", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "INTERPRETABLE CONVOLUTIONAL FILTER PRUNING", "abstract": "The sophisticated structure of Convolutional Neural Network (CNN) allows for\noutstanding performance, but at the cost of intensive computation. As significant\nredundancies inevitably present in such a structure, many works have been proposed\nto prune the convolutional filters for computation cost reduction. Although\nextremely effective, most works are based only on quantitative characteristics of\nthe convolutional filters, and highly overlook the qualitative interpretation of individual\nfilter\u2019s specific functionality. In this work, we interpreted the functionality\nand redundancy of the convolutional filters from different perspectives, and proposed\na functionality-oriented filter pruning method. With extensive experiment\nresults, we proved the convolutional filters\u2019 qualitative significance regardless of\nmagnitude, demonstrated significant neural network redundancy due to repetitive\nfilter functions, and analyzed the filter functionality defection under inappropriate\nretraining process. Such an interpretable pruning approach not only offers outstanding\ncomputation cost optimization over previous filter pruning methods, but\nalso interprets filter pruning process.", "keywords": [], "authorids": ["zqin@gmu.edu", "fyu2@gmu.edu", "chliu@clarkson.edu", "xchen26@gmu.edu"], "authors": ["Zhuwei Qin", "Fuxun Yu", "Chenchen Liu", "Xiang Chen"], "pdf": "/pdf/3365464c9f60f06eb097a49f5a0d9eaea5c969f1.pdf", "paperhash": "qin|interpretable_convolutional_filter_pruning", "_bibtex": "@misc{\nqin2019interpretable,\ntitle={{INTERPRETABLE} {CONVOLUTIONAL} {FILTER} {PRUNING}},\nauthor={Zhuwei Qin and Fuxun Yu and Chenchen Liu and Xiang Chen},\nyear={2019},\nurl={https://openreview.net/forum?id=BJ4BVhRcYX},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper1450/Public_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1542311594529, "tddate": null, "super": null, "final": null, "reply": {"signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed."}, "nonreaders": {"values": []}, "forum": "BJ4BVhRcYX", "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper1450/Authors", "ICLR.cc/2019/Conference/Paper1450/Reviewers", "ICLR.cc/2019/Conference/Paper1450/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "replyto": null, "content": {"comment": {"value-regex": "[\\S\\s]{1,5000}", "required": true, "order": 1, "description": "Your comment or reply (max 5000 characters)."}, "title": {"value-regex": ".{1,500}", "required": true, "order": 0, "description": "Brief summary of your comment."}}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["~"], "noninvitees": ["ICLR.cc/2019/Conference/Paper1450/Authors", "ICLR.cc/2019/Conference/Paper1450/Reviewers", "ICLR.cc/2019/Conference/Paper1450/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1542311594529}}}, {"id": "r1e7sGdqnQ", "original": null, "number": 3, "cdate": 1541206683328, "ddate": null, "tcdate": 1541206683328, "tmdate": 1541206683328, "tddate": null, "forum": "BJ4BVhRcYX", "replyto": "S1eXcT8927", "invitation": "ICLR.cc/2019/Conference/-/Paper1450/Public_Comment", "content": {"comment": "I don't it is a different problem setup. You would like to prune the network and finally get your result. Via the method you said why you can prune, is that correct?\nHowever, in Structured Bayesian Pruning via Log-Normal Multiplicative Noise, they explain why it can be pruned in the Bayesian method, so how can you say it is different problem setting. \nIn addition, you claim your method is better than previous results and you cannot beat other papers. Even you got a new method, then what is the meaning for that. \nAgain, why don't do a comprehensive comparison and then conclude since you claim \"Such an interpretable pruning approach not only offers outstanding computation cost optimization over previous filter pruning methods\". I didn't see it offers outstanding computation cost optimization over previous filter pruning methods", "title": "Not Answer question"}, "signatures": ["(anonymous)"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper1450/Reviewers/Unsubmitted"], "writers": ["(anonymous)", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "INTERPRETABLE CONVOLUTIONAL FILTER PRUNING", "abstract": "The sophisticated structure of Convolutional Neural Network (CNN) allows for\noutstanding performance, but at the cost of intensive computation. As significant\nredundancies inevitably present in such a structure, many works have been proposed\nto prune the convolutional filters for computation cost reduction. Although\nextremely effective, most works are based only on quantitative characteristics of\nthe convolutional filters, and highly overlook the qualitative interpretation of individual\nfilter\u2019s specific functionality. In this work, we interpreted the functionality\nand redundancy of the convolutional filters from different perspectives, and proposed\na functionality-oriented filter pruning method. With extensive experiment\nresults, we proved the convolutional filters\u2019 qualitative significance regardless of\nmagnitude, demonstrated significant neural network redundancy due to repetitive\nfilter functions, and analyzed the filter functionality defection under inappropriate\nretraining process. Such an interpretable pruning approach not only offers outstanding\ncomputation cost optimization over previous filter pruning methods, but\nalso interprets filter pruning process.", "keywords": [], "authorids": ["zqin@gmu.edu", "fyu2@gmu.edu", "chliu@clarkson.edu", "xchen26@gmu.edu"], "authors": ["Zhuwei Qin", "Fuxun Yu", "Chenchen Liu", "Xiang Chen"], "pdf": "/pdf/3365464c9f60f06eb097a49f5a0d9eaea5c969f1.pdf", "paperhash": "qin|interpretable_convolutional_filter_pruning", "_bibtex": "@misc{\nqin2019interpretable,\ntitle={{INTERPRETABLE} {CONVOLUTIONAL} {FILTER} {PRUNING}},\nauthor={Zhuwei Qin and Fuxun Yu and Chenchen Liu and Xiang Chen},\nyear={2019},\nurl={https://openreview.net/forum?id=BJ4BVhRcYX},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper1450/Public_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1542311594529, "tddate": null, "super": null, "final": null, "reply": {"signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed."}, "nonreaders": {"values": []}, "forum": "BJ4BVhRcYX", "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper1450/Authors", "ICLR.cc/2019/Conference/Paper1450/Reviewers", "ICLR.cc/2019/Conference/Paper1450/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "replyto": null, "content": {"comment": {"value-regex": "[\\S\\s]{1,5000}", "required": true, "order": 1, "description": "Your comment or reply (max 5000 characters)."}, "title": {"value-regex": ".{1,500}", "required": true, "order": 0, "description": "Brief summary of your comment."}}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["~"], "noninvitees": ["ICLR.cc/2019/Conference/Paper1450/Authors", "ICLR.cc/2019/Conference/Paper1450/Reviewers", "ICLR.cc/2019/Conference/Paper1450/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1542311594529}}}, {"id": "ryeOJfJ92Q", "original": null, "number": 2, "cdate": 1541169631704, "ddate": null, "tcdate": 1541169631704, "tmdate": 1541169631704, "tddate": null, "forum": "BJ4BVhRcYX", "replyto": "BJ4BVhRcYX", "invitation": "ICLR.cc/2019/Conference/-/Paper1450/Public_Comment", "content": {"comment": "Hi there,\n     Filter prune belongs to the structure prune, and you claim in the paper your results are better than previous papers.\nHowever, I don't think so. Lot of papers are shown better performance than yours. \nSee \"Structured Bayesian Pruning via Log-Normal Multiplicative Noise\", and \"Learning structured sparsity in deep\nneural networks\".  And there are a lot other papers showing better results than yours.\n     From this point, your conclusion is wrong and I don't recommend it for publication since you cannot say you get a new method and then publish. To tell you some tricks, even though at the beginning training stage, I randomly cut some filters and retrain the model, it can say still show better results. ", "title": "Sloppy Baseline"}, "signatures": ["(anonymous)"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper1450/Reviewers/Unsubmitted"], "writers": ["(anonymous)", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "INTERPRETABLE CONVOLUTIONAL FILTER PRUNING", "abstract": "The sophisticated structure of Convolutional Neural Network (CNN) allows for\noutstanding performance, but at the cost of intensive computation. As significant\nredundancies inevitably present in such a structure, many works have been proposed\nto prune the convolutional filters for computation cost reduction. Although\nextremely effective, most works are based only on quantitative characteristics of\nthe convolutional filters, and highly overlook the qualitative interpretation of individual\nfilter\u2019s specific functionality. In this work, we interpreted the functionality\nand redundancy of the convolutional filters from different perspectives, and proposed\na functionality-oriented filter pruning method. With extensive experiment\nresults, we proved the convolutional filters\u2019 qualitative significance regardless of\nmagnitude, demonstrated significant neural network redundancy due to repetitive\nfilter functions, and analyzed the filter functionality defection under inappropriate\nretraining process. Such an interpretable pruning approach not only offers outstanding\ncomputation cost optimization over previous filter pruning methods, but\nalso interprets filter pruning process.", "keywords": [], "authorids": ["zqin@gmu.edu", "fyu2@gmu.edu", "chliu@clarkson.edu", "xchen26@gmu.edu"], "authors": ["Zhuwei Qin", "Fuxun Yu", "Chenchen Liu", "Xiang Chen"], "pdf": "/pdf/3365464c9f60f06eb097a49f5a0d9eaea5c969f1.pdf", "paperhash": "qin|interpretable_convolutional_filter_pruning", "_bibtex": "@misc{\nqin2019interpretable,\ntitle={{INTERPRETABLE} {CONVOLUTIONAL} {FILTER} {PRUNING}},\nauthor={Zhuwei Qin and Fuxun Yu and Chenchen Liu and Xiang Chen},\nyear={2019},\nurl={https://openreview.net/forum?id=BJ4BVhRcYX},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper1450/Public_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1542311594529, "tddate": null, "super": null, "final": null, "reply": {"signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed."}, "nonreaders": {"values": []}, "forum": "BJ4BVhRcYX", "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper1450/Authors", "ICLR.cc/2019/Conference/Paper1450/Reviewers", "ICLR.cc/2019/Conference/Paper1450/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "replyto": null, "content": {"comment": {"value-regex": "[\\S\\s]{1,5000}", "required": true, "order": 1, "description": "Your comment or reply (max 5000 characters)."}, "title": {"value-regex": ".{1,500}", "required": true, "order": 0, "description": "Brief summary of your comment."}}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["~"], "noninvitees": ["ICLR.cc/2019/Conference/Paper1450/Authors", "ICLR.cc/2019/Conference/Paper1450/Reviewers", "ICLR.cc/2019/Conference/Paper1450/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1542311594529}}}, {"id": "S1x2SfVL3Q", "original": null, "number": 1, "cdate": 1540928067736, "ddate": null, "tcdate": 1540928067736, "tmdate": 1540930064888, "tddate": null, "forum": "BJ4BVhRcYX", "replyto": "HJguZtwHnm", "invitation": "ICLR.cc/2019/Conference/-/Paper1450/Official_Comment", "content": {"title": "Reply to \"Randomly pruning filters in a CNN\"", "comment": "Thank you very much for your comments. \n\n1) We fully understand your concern that the random pruning can obtain the comparable performance as the L1-norm based method. \nIn our experiment, we also noted that sometimes random pruning filters even performs better than the filter L1-norm based method when the pruning rate is small. However, the accuracy drop of random pruning is always larger than the L1-norm based method when the network is pruned aggressively.\n\n2) Furthermore, different from previous works, we examined the pruning process and identified the real network redundancy in terms of filter functionality. Our method can precisely select functionality redundant filters to prune which causes much less accuracy drop. \n\n3) In our paper, we also demonstrated that, without considering the filter functionality, the retraining phase actually reconstructs the filter functionality rather than filter functionality fine-tuning. That\u2019s the reason why the retraining phase of the L1-norm based method or random pruning can compensate the network accuracy drop. However, with a more precisely network redundancy identification, the retraining phase could be unnecessary.\n\n4) Actually, I think your work is also pretty related to this paper \u201cRethinking the Value of Network Pruning\u201d. The authors demonstrated that training a small pruned model from scratch gives comparable accuracy to the standard pruning and retraining method. \nThrough an extensive set of experiments, the pruning method does not really matter. \nTo some degree, I think the retraining with inherited weights from the randomly pruned model is just like training the network from scratch with random initialization. What do you think?\n\nAgain, thank you for your interest in our work! \n"}, "signatures": ["ICLR.cc/2019/Conference/Paper1450/Authors"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper1450/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper1450/Authors", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "INTERPRETABLE CONVOLUTIONAL FILTER PRUNING", "abstract": "The sophisticated structure of Convolutional Neural Network (CNN) allows for\noutstanding performance, but at the cost of intensive computation. As significant\nredundancies inevitably present in such a structure, many works have been proposed\nto prune the convolutional filters for computation cost reduction. Although\nextremely effective, most works are based only on quantitative characteristics of\nthe convolutional filters, and highly overlook the qualitative interpretation of individual\nfilter\u2019s specific functionality. In this work, we interpreted the functionality\nand redundancy of the convolutional filters from different perspectives, and proposed\na functionality-oriented filter pruning method. With extensive experiment\nresults, we proved the convolutional filters\u2019 qualitative significance regardless of\nmagnitude, demonstrated significant neural network redundancy due to repetitive\nfilter functions, and analyzed the filter functionality defection under inappropriate\nretraining process. Such an interpretable pruning approach not only offers outstanding\ncomputation cost optimization over previous filter pruning methods, but\nalso interprets filter pruning process.", "keywords": [], "authorids": ["zqin@gmu.edu", "fyu2@gmu.edu", "chliu@clarkson.edu", "xchen26@gmu.edu"], "authors": ["Zhuwei Qin", "Fuxun Yu", "Chenchen Liu", "Xiang Chen"], "pdf": "/pdf/3365464c9f60f06eb097a49f5a0d9eaea5c969f1.pdf", "paperhash": "qin|interpretable_convolutional_filter_pruning", "_bibtex": "@misc{\nqin2019interpretable,\ntitle={{INTERPRETABLE} {CONVOLUTIONAL} {FILTER} {PRUNING}},\nauthor={Zhuwei Qin and Fuxun Yu and Chenchen Liu and Xiang Chen},\nyear={2019},\nurl={https://openreview.net/forum?id=BJ4BVhRcYX},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper1450/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621626464, "tddate": null, "super": null, "final": null, "reply": {"forum": "BJ4BVhRcYX", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper1450/Authors", "ICLR.cc/2019/Conference/Paper1450/Reviewers", "ICLR.cc/2019/Conference/Paper1450/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper1450/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper1450/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper1450/Authors|ICLR.cc/2019/Conference/Paper1450/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper1450/Reviewers", "ICLR.cc/2019/Conference/Paper1450/Authors", "ICLR.cc/2019/Conference/Paper1450/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621626464}}}], "count": 21}