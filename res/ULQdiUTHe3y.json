{"notes": [{"id": "ULQdiUTHe3y", "original": "FDINFIgvMVZ", "number": 3522, "cdate": 1601308390909, "ddate": null, "tcdate": 1601308390909, "tmdate": 1616066705495, "tddate": null, "forum": "ULQdiUTHe3y", "replyto": null, "invitation": "ICLR.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Collective Robustness Certificates: Exploiting Interdependence in Graph Neural Networks", "authorids": ["~Jan_Schuchardt1", "~Aleksandar_Bojchevski1", "~Johannes_Klicpera1", "~Stephan_G\u00fcnnemann1"], "authors": ["Jan Schuchardt", "Aleksandar Bojchevski", "Johannes Klicpera", "Stephan G\u00fcnnemann"], "keywords": ["Robustness certificates", "Adversarial robustness", "Graph neural networks"], "abstract": "In tasks like node classification, image segmentation, and named-entity recognition we have a classifier that simultaneously outputs multiple predictions (a vector of labels) based on a single input, i.e. a single graph, image, or document respectively. Existing adversarial robustness certificates consider each prediction independently and are thus overly pessimistic for such tasks. They implicitly assume that an adversary can use different perturbed inputs to attack different predictions, ignoring the fact that we have a single shared input. We propose the first collective robustness certificate which computes the number of predictions that are simultaneously guaranteed to remain stable under perturbation, i.e. cannot be attacked. We focus on Graph Neural Networks and leverage their locality property - perturbations only affect the predictions in a close neighborhood - to fuse multiple single-node certificates into a drastically stronger collective certificate. For example, on the Citeseer dataset our collective certificate for node classification increases the average number of certifiable feature perturbations from $7$ to $351$.\n", "one-sentence_summary": "We fuse multiple single-prediction certificates into a drastically stronger collective certificate leveraging the locality property of Graph Neural Networks.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "schuchardt|collective_robustness_certificates_exploiting_interdependence_in_graph_neural_networks", "supplementary_material": "/attachment/18d6bdec136d663476c8307266c752beb4a432cb.zip", "pdf": "/pdf/23b393f2d9e53b0dd38356295f14b0980ac27b18.pdf", "venue": "ICLR 2021 Poster", "venueid": "ICLR.cc/2021/Conference", "_bibtex": "@inproceedings{\nschuchardt2021collective,\ntitle={Collective Robustness Certificates: Exploiting Interdependence in Graph Neural Networks},\nauthor={Jan Schuchardt and Aleksandar Bojchevski and Johannes Klicpera and Stephan G{\\\"u}nnemann},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=ULQdiUTHe3y}\n}"}, "signatures": ["ICLR.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference"], "details": {"replyCount": 10, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"reply": {"readers": {"values-regex": ".*"}, "writers": {"values": ["ICLR.cc/2021/Conference"]}, "signatures": {"values": ["ICLR.cc/2021/Conference"]}, "content": {"authors": {"values": ["Anonymous"]}, "authorids": {"values-regex": ".*"}, "reviewed_version_(pdf)": {"required": false, "description": "Upload a PDF file that ends with .pdf", "value-regex": ".*"}}}, "signatures": ["ICLR.cc/2021/Conference"], "readers": ["everyone"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["~", "OpenReview.net/Support"], "tcdate": 1601308008205, "tmdate": 1614984599368, "id": "ICLR.cc/2021/Conference/-/Blind_Submission"}}, "tauthor": "OpenReview.net"}, {"id": "Y0QD2cUcrR_", "original": null, "number": 1, "cdate": 1610040482876, "ddate": null, "tcdate": 1610040482876, "tmdate": 1610474088037, "tddate": null, "forum": "ULQdiUTHe3y", "replyto": "ULQdiUTHe3y", "invitation": "ICLR.cc/2021/Conference/Paper3522/-/Decision", "content": {"title": "Final Decision", "decision": "Accept (Poster)", "comment": "This paper considers a new setting of robustness, where multiple predictions are simultaneously made based on a single input. Different from existing robustness certificates which independently consider perturbation of each prediction, the authors propose collective robustness certificate that computes the number of predictions which are simultaneously guaranteed to remain stable under perturbation. This yields more optimistic results. Most reviewers think this is a very interesting work and the authors present an effective method to combine individual certificate. The experimental results are convincing. I recommend accept."}, "signatures": ["ICLR.cc/2021/Conference/Program_Chairs"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference/Program_Chairs"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Collective Robustness Certificates: Exploiting Interdependence in Graph Neural Networks", "authorids": ["~Jan_Schuchardt1", "~Aleksandar_Bojchevski1", "~Johannes_Klicpera1", "~Stephan_G\u00fcnnemann1"], "authors": ["Jan Schuchardt", "Aleksandar Bojchevski", "Johannes Klicpera", "Stephan G\u00fcnnemann"], "keywords": ["Robustness certificates", "Adversarial robustness", "Graph neural networks"], "abstract": "In tasks like node classification, image segmentation, and named-entity recognition we have a classifier that simultaneously outputs multiple predictions (a vector of labels) based on a single input, i.e. a single graph, image, or document respectively. Existing adversarial robustness certificates consider each prediction independently and are thus overly pessimistic for such tasks. They implicitly assume that an adversary can use different perturbed inputs to attack different predictions, ignoring the fact that we have a single shared input. We propose the first collective robustness certificate which computes the number of predictions that are simultaneously guaranteed to remain stable under perturbation, i.e. cannot be attacked. We focus on Graph Neural Networks and leverage their locality property - perturbations only affect the predictions in a close neighborhood - to fuse multiple single-node certificates into a drastically stronger collective certificate. For example, on the Citeseer dataset our collective certificate for node classification increases the average number of certifiable feature perturbations from $7$ to $351$.\n", "one-sentence_summary": "We fuse multiple single-prediction certificates into a drastically stronger collective certificate leveraging the locality property of Graph Neural Networks.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "schuchardt|collective_robustness_certificates_exploiting_interdependence_in_graph_neural_networks", "supplementary_material": "/attachment/18d6bdec136d663476c8307266c752beb4a432cb.zip", "pdf": "/pdf/23b393f2d9e53b0dd38356295f14b0980ac27b18.pdf", "venue": "ICLR 2021 Poster", "venueid": "ICLR.cc/2021/Conference", "_bibtex": "@inproceedings{\nschuchardt2021collective,\ntitle={Collective Robustness Certificates: Exploiting Interdependence in Graph Neural Networks},\nauthor={Jan Schuchardt and Aleksandar Bojchevski and Johannes Klicpera and Stephan G{\\\"u}nnemann},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=ULQdiUTHe3y}\n}"}, "tags": [], "invitation": {"reply": {"forum": "ULQdiUTHe3y", "replyto": "ULQdiUTHe3y", "readers": {"values": ["everyone"]}, "writers": {"values": ["ICLR.cc/2021/Conference/Program_Chairs"]}, "signatures": {"values": ["ICLR.cc/2021/Conference/Program_Chairs"]}, "content": {"title": {"value": "Final Decision"}, "decision": {"value-radio": ["Accept (Oral)", "Accept (Spotlight)", "Accept (Poster)", "Reject"]}, "comment": {"value-regex": "[\\S\\s]{0,50000}", "markdown": true}}}, "multiReply": false, "signatures": ["ICLR.cc/2021/Conference"], "readers": ["everyone"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Program_Chairs"], "tcdate": 1610040482862, "tmdate": 1610474088020, "id": "ICLR.cc/2021/Conference/Paper3522/-/Decision"}}}, {"id": "OQdINjSLlrE", "original": null, "number": 1, "cdate": 1603802980350, "ddate": null, "tcdate": 1603802980350, "tmdate": 1606339861861, "tddate": null, "forum": "ULQdiUTHe3y", "replyto": "ULQdiUTHe3y", "invitation": "ICLR.cc/2021/Conference/Paper3522/-/Official_Review", "content": {"title": "great work but some comparisons could be missing.", "review": "Summary\n-------------\nCurrent methods on adversarial robustness certificates consider data points independently which are highly pessimistic for structured data. This work proposes the first collective robustness certificate that considers the structure of the graph by modeling locality in order to derive stronger guarantees  that the predictions remain stable under perturbations.\n\nThis work focuses on Graph Neural Networks comparing between a Naive collective certificate (baseline) and a proposed collective certificate that combines single-node certificates effectively. \n\nThe experiments compares these two methods against certified ratio vs. attribute and edge perturbations on the datasets Cora-ML, Citeseer, and PubMed.\n\nPros\n------\n- The paper is well-written and easy to follow.\n- The paper tries to address a very common problem of adversarial attacks where data points are structured. Although it is a common problem, it was not explored with respect to collective robustness certificates before this work.\n- The paper shows a novel, effective way of combining individual certificates by incorporating locality.\n- The paper presents an LP-relaxation method that allows us to solve the certificate fast for large graphs where mixed-integer problems are prohibitively costly.\n- The paper shows strong theory and experiments to illustrate the efficacy of the proposed collective certificate.\n- The experiments show run-time and uncertainty measures with multiple runs for statistical significance.\n\nQuestions\n--------------\n- Is there a reason why [1] was not discussed in the paper? it is highly relevant as it also studies adversarial robustness for structural attacks. \n- How does the proposed method apply to robust Associative Markov Networks (AMN) in [1]?\n- Did you try running the proposed method on WebKB and Reuters which are present in this work [1]?\n- How does the linear relaxation in this work differ from the one provided in [1]?\n- How would the proposed method compare against robust AMN [1]?\n- Can the findings be used to come up with robust methods outside classification, like segmentation and scene understanding?\n\nIn summary, I like the novelty of this method and the through experiments that were conducted that illustrate the efficacy of the proposed collective certificate, thus I recommend an accept.\n\n[1] Kai Zhou, Yevgeniy Vorobeychik. Robust Collective Classification against Structural Attacks. UAI 2020. \n\n------- Post rebuttal\nI am satisfied with most of the rebuttal the authors have provided, and I have raised my score to an 8. \n", "rating": "8: Top 50% of accepted papers, clear accept", "confidence": "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper"}, "signatures": ["ICLR.cc/2021/Conference/Paper3522/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper3522/AnonReviewer1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Collective Robustness Certificates: Exploiting Interdependence in Graph Neural Networks", "authorids": ["~Jan_Schuchardt1", "~Aleksandar_Bojchevski1", "~Johannes_Klicpera1", "~Stephan_G\u00fcnnemann1"], "authors": ["Jan Schuchardt", "Aleksandar Bojchevski", "Johannes Klicpera", "Stephan G\u00fcnnemann"], "keywords": ["Robustness certificates", "Adversarial robustness", "Graph neural networks"], "abstract": "In tasks like node classification, image segmentation, and named-entity recognition we have a classifier that simultaneously outputs multiple predictions (a vector of labels) based on a single input, i.e. a single graph, image, or document respectively. Existing adversarial robustness certificates consider each prediction independently and are thus overly pessimistic for such tasks. They implicitly assume that an adversary can use different perturbed inputs to attack different predictions, ignoring the fact that we have a single shared input. We propose the first collective robustness certificate which computes the number of predictions that are simultaneously guaranteed to remain stable under perturbation, i.e. cannot be attacked. We focus on Graph Neural Networks and leverage their locality property - perturbations only affect the predictions in a close neighborhood - to fuse multiple single-node certificates into a drastically stronger collective certificate. For example, on the Citeseer dataset our collective certificate for node classification increases the average number of certifiable feature perturbations from $7$ to $351$.\n", "one-sentence_summary": "We fuse multiple single-prediction certificates into a drastically stronger collective certificate leveraging the locality property of Graph Neural Networks.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "schuchardt|collective_robustness_certificates_exploiting_interdependence_in_graph_neural_networks", "supplementary_material": "/attachment/18d6bdec136d663476c8307266c752beb4a432cb.zip", "pdf": "/pdf/23b393f2d9e53b0dd38356295f14b0980ac27b18.pdf", "venue": "ICLR 2021 Poster", "venueid": "ICLR.cc/2021/Conference", "_bibtex": "@inproceedings{\nschuchardt2021collective,\ntitle={Collective Robustness Certificates: Exploiting Interdependence in Graph Neural Networks},\nauthor={Jan Schuchardt and Aleksandar Bojchevski and Johannes Klicpera and Stephan G{\\\"u}nnemann},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=ULQdiUTHe3y}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq . ***Please remember to file the Code-of-Ethics report. Once you submitted the review, a link to the report will be visible in the bottom right corner of your review.***", "required": true, "markdown": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}, "forum": "ULQdiUTHe3y", "replyto": "ULQdiUTHe3y", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"], "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper3522/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1607428800000, "duedate": 1606752000000, "multiReply": false, "readers": ["everyone"], "tcdate": 1602538074391, "tmdate": 1606915795551, "super": "ICLR.cc/2021/Conference/-/Official_Review", "signatures": ["OpenReview.net"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Paper3522/Reviewers", "OpenReview.net/Support"], "id": "ICLR.cc/2021/Conference/Paper3522/-/Official_Review"}}}, {"id": "wHQEEyOf0e7", "original": null, "number": 6, "cdate": 1605710716917, "ddate": null, "tcdate": 1605710716917, "tmdate": 1605713350679, "tddate": null, "forum": "ULQdiUTHe3y", "replyto": "ULQdiUTHe3y", "invitation": "ICLR.cc/2021/Conference/Paper3522/-/Official_Comment", "content": {"title": "Summary / Changelog", "comment": "This post serves as a summary of updates since the initial submission of our manuscript.\n\nWe have replied to all reviewers and made the following changes in response to their comments:  \n* Reviewer 1:  \n  * Add overview over different heuristic defenses for collective tasks  \n  * Add experiments on WebKB and Reuters dataset (Appendix A)  \n* Reviewer 3:  \n  * Correct typos in Eq.2 and Eq.7  \n\nWe have further made the following minor changes:  \n* correct caption of Fig. 8 (Cora, Citeseer, Pubmed -> WebKB, Reuters)\n* remove unnecessary \"through\" at end of second paragraph\n* correct indentation in Algorithm 2  \n* correct arXiv references (bibliography style does not support eprint field)  \n* increase x-lim and y-lim on Fig. 3  \n* correct indexing in Eq. 75 and Eq. 76 (h_n instead of h)  \n"}, "signatures": ["ICLR.cc/2021/Conference/Paper3522/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper3522/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Collective Robustness Certificates: Exploiting Interdependence in Graph Neural Networks", "authorids": ["~Jan_Schuchardt1", "~Aleksandar_Bojchevski1", "~Johannes_Klicpera1", "~Stephan_G\u00fcnnemann1"], "authors": ["Jan Schuchardt", "Aleksandar Bojchevski", "Johannes Klicpera", "Stephan G\u00fcnnemann"], "keywords": ["Robustness certificates", "Adversarial robustness", "Graph neural networks"], "abstract": "In tasks like node classification, image segmentation, and named-entity recognition we have a classifier that simultaneously outputs multiple predictions (a vector of labels) based on a single input, i.e. a single graph, image, or document respectively. Existing adversarial robustness certificates consider each prediction independently and are thus overly pessimistic for such tasks. They implicitly assume that an adversary can use different perturbed inputs to attack different predictions, ignoring the fact that we have a single shared input. We propose the first collective robustness certificate which computes the number of predictions that are simultaneously guaranteed to remain stable under perturbation, i.e. cannot be attacked. We focus on Graph Neural Networks and leverage their locality property - perturbations only affect the predictions in a close neighborhood - to fuse multiple single-node certificates into a drastically stronger collective certificate. For example, on the Citeseer dataset our collective certificate for node classification increases the average number of certifiable feature perturbations from $7$ to $351$.\n", "one-sentence_summary": "We fuse multiple single-prediction certificates into a drastically stronger collective certificate leveraging the locality property of Graph Neural Networks.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "schuchardt|collective_robustness_certificates_exploiting_interdependence_in_graph_neural_networks", "supplementary_material": "/attachment/18d6bdec136d663476c8307266c752beb4a432cb.zip", "pdf": "/pdf/23b393f2d9e53b0dd38356295f14b0980ac27b18.pdf", "venue": "ICLR 2021 Poster", "venueid": "ICLR.cc/2021/Conference", "_bibtex": "@inproceedings{\nschuchardt2021collective,\ntitle={Collective Robustness Certificates: Exploiting Interdependence in Graph Neural Networks},\nauthor={Jan Schuchardt and Aleksandar Bojchevski and Johannes Klicpera and Stephan G{\\\"u}nnemann},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=ULQdiUTHe3y}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "ULQdiUTHe3y", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper3522/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper3522/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper3522/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper3522/Authors|ICLR.cc/2021/Conference/Paper3522/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper3522/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923836694, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper3522/-/Official_Comment"}}}, {"id": "sr4wM_mrkqR", "original": null, "number": 5, "cdate": 1605710234261, "ddate": null, "tcdate": 1605710234261, "tmdate": 1605713036851, "tddate": null, "forum": "ULQdiUTHe3y", "replyto": "OQdINjSLlrE", "invitation": "ICLR.cc/2021/Conference/Paper3522/-/Official_Comment", "content": {"title": "Response - Reviewer 1", "comment": "Thank you for your review!\n\nBefore responding to your questions, let us briefly summarize the mentioned paper ([1]) for other readers. The paper deals with the adversarial robustness of pairwise associative Markov networks (AMN), a type of probabilistic graphical model for node classification. The authors propose a robust loss function that maximizes the margin between the likelihood of the ground-truth labels and that of all other possible labels under adversarial perturbation.\n\n### Responses\n**Is there a reason why [1] was not discussed in the paper?**  \nThe robust loss function in [1] is not a robustness certificate. While it compares favorably to standard training under different adversarial attacks, it does not provide any provable guarantees. In our original submission we simply refer to a survey paper of non-provable defenses that have subsequently been broken by novel adversarial attacks. Based on your review we have updated our manuscript to include an overview of different adversarial defenses (including [1]) , which will hopefully allow for a better differentiation between robustness certificates and defenses that do not provide provable guarantees.\n\n**How does the proposed method apply to robust Associative Markov Networks (AMN) in [1]?**  \nThe proposed method can in principle be applied to AMNs. All that is needed is some base certification procedure that can guarantee the robustness of individual predictions to adversarial attacks. The many base certificates can then be combined into a collective certificate using our method.\n\n**Did you try running the proposed method on WebKB and Reuters which are present in this work [1]?**  \nBased on your comment, we have run additional experiments on graphs constructed from the WebKB and Reuters corpora (see Fig. 8). Since we could not find an official reference implementation, the constructed graphs might be slightly different from those in [1] due to random sampling, tie-breaking among nodes with equal cosine similarity, etc.\nFurther note that the multiple classes are not merged into two super-classes. Repeating the experiment with binary class labels as done in [1] yielded results even slightly better than the multi-class results shown on Fig. 8.\n\n**How does the linear relaxation in this work differ from the one provided in [1]?**  \nThis work and [1] propose two different mixed-integer programs, one minimizing the number of robust predictions, the other one minimizing a likelihood margin. In both cases the integer variables are relaxed to real-valued variables. Furthermore both mixed-integer programs involve boolean logic that is expressed using linear constraints. Quoting section 3.2 of [1], these are \u201cstandard techniques\u201d and not the core contribution of either paper.\n\n**How would the proposed method compare against robust AMN [1]?**  \nAs discussed in the response to the first question, the proposed method is a robustness certificate that provides provable guarantees while the method from [1] is not.\nWhile robustness certificates can be evaluated based on their certified ratio, evaluating other defenses requires powerful adversarial attacks that are specifically adapted to break them.\n\n**Can the findings be used to come up with robust methods outside classification, like segmentation and scene understanding?**  \nThe proposed method can in principle be applied to any task in which many labels are predicted for a single shared input, including segmentation and scene understanding. The performance gain over the naive certificate will depend on the degree of locality of the classifier architecture.\n\n\n\n[1] Kai Zhou, Yevgeniy Vorobeychik. Robust Collective Classification against Structural Attacks. UAI 2020."}, "signatures": ["ICLR.cc/2021/Conference/Paper3522/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper3522/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Collective Robustness Certificates: Exploiting Interdependence in Graph Neural Networks", "authorids": ["~Jan_Schuchardt1", "~Aleksandar_Bojchevski1", "~Johannes_Klicpera1", "~Stephan_G\u00fcnnemann1"], "authors": ["Jan Schuchardt", "Aleksandar Bojchevski", "Johannes Klicpera", "Stephan G\u00fcnnemann"], "keywords": ["Robustness certificates", "Adversarial robustness", "Graph neural networks"], "abstract": "In tasks like node classification, image segmentation, and named-entity recognition we have a classifier that simultaneously outputs multiple predictions (a vector of labels) based on a single input, i.e. a single graph, image, or document respectively. Existing adversarial robustness certificates consider each prediction independently and are thus overly pessimistic for such tasks. They implicitly assume that an adversary can use different perturbed inputs to attack different predictions, ignoring the fact that we have a single shared input. We propose the first collective robustness certificate which computes the number of predictions that are simultaneously guaranteed to remain stable under perturbation, i.e. cannot be attacked. We focus on Graph Neural Networks and leverage their locality property - perturbations only affect the predictions in a close neighborhood - to fuse multiple single-node certificates into a drastically stronger collective certificate. For example, on the Citeseer dataset our collective certificate for node classification increases the average number of certifiable feature perturbations from $7$ to $351$.\n", "one-sentence_summary": "We fuse multiple single-prediction certificates into a drastically stronger collective certificate leveraging the locality property of Graph Neural Networks.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "schuchardt|collective_robustness_certificates_exploiting_interdependence_in_graph_neural_networks", "supplementary_material": "/attachment/18d6bdec136d663476c8307266c752beb4a432cb.zip", "pdf": "/pdf/23b393f2d9e53b0dd38356295f14b0980ac27b18.pdf", "venue": "ICLR 2021 Poster", "venueid": "ICLR.cc/2021/Conference", "_bibtex": "@inproceedings{\nschuchardt2021collective,\ntitle={Collective Robustness Certificates: Exploiting Interdependence in Graph Neural Networks},\nauthor={Jan Schuchardt and Aleksandar Bojchevski and Johannes Klicpera and Stephan G{\\\"u}nnemann},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=ULQdiUTHe3y}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "ULQdiUTHe3y", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper3522/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper3522/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper3522/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper3522/Authors|ICLR.cc/2021/Conference/Paper3522/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper3522/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923836694, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper3522/-/Official_Comment"}}}, {"id": "CYLsAx5t9wd", "original": null, "number": 4, "cdate": 1605709952732, "ddate": null, "tcdate": 1605709952732, "tmdate": 1605713028640, "tddate": null, "forum": "ULQdiUTHe3y", "replyto": "lqtzTmNj6Ms", "invitation": "ICLR.cc/2021/Conference/Paper3522/-/Official_Comment", "content": {"title": "Response - Reviewer 2", "comment": "Thank you for your review!  \n\nWe are pleased to hear that you did not find any notable weaknesses and that you are convinced by the overall quality of the paper\u2019s writing and content.\n"}, "signatures": ["ICLR.cc/2021/Conference/Paper3522/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper3522/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Collective Robustness Certificates: Exploiting Interdependence in Graph Neural Networks", "authorids": ["~Jan_Schuchardt1", "~Aleksandar_Bojchevski1", "~Johannes_Klicpera1", "~Stephan_G\u00fcnnemann1"], "authors": ["Jan Schuchardt", "Aleksandar Bojchevski", "Johannes Klicpera", "Stephan G\u00fcnnemann"], "keywords": ["Robustness certificates", "Adversarial robustness", "Graph neural networks"], "abstract": "In tasks like node classification, image segmentation, and named-entity recognition we have a classifier that simultaneously outputs multiple predictions (a vector of labels) based on a single input, i.e. a single graph, image, or document respectively. Existing adversarial robustness certificates consider each prediction independently and are thus overly pessimistic for such tasks. They implicitly assume that an adversary can use different perturbed inputs to attack different predictions, ignoring the fact that we have a single shared input. We propose the first collective robustness certificate which computes the number of predictions that are simultaneously guaranteed to remain stable under perturbation, i.e. cannot be attacked. We focus on Graph Neural Networks and leverage their locality property - perturbations only affect the predictions in a close neighborhood - to fuse multiple single-node certificates into a drastically stronger collective certificate. For example, on the Citeseer dataset our collective certificate for node classification increases the average number of certifiable feature perturbations from $7$ to $351$.\n", "one-sentence_summary": "We fuse multiple single-prediction certificates into a drastically stronger collective certificate leveraging the locality property of Graph Neural Networks.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "schuchardt|collective_robustness_certificates_exploiting_interdependence_in_graph_neural_networks", "supplementary_material": "/attachment/18d6bdec136d663476c8307266c752beb4a432cb.zip", "pdf": "/pdf/23b393f2d9e53b0dd38356295f14b0980ac27b18.pdf", "venue": "ICLR 2021 Poster", "venueid": "ICLR.cc/2021/Conference", "_bibtex": "@inproceedings{\nschuchardt2021collective,\ntitle={Collective Robustness Certificates: Exploiting Interdependence in Graph Neural Networks},\nauthor={Jan Schuchardt and Aleksandar Bojchevski and Johannes Klicpera and Stephan G{\\\"u}nnemann},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=ULQdiUTHe3y}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "ULQdiUTHe3y", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper3522/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper3522/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper3522/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper3522/Authors|ICLR.cc/2021/Conference/Paper3522/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper3522/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923836694, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper3522/-/Official_Comment"}}}, {"id": "I36iuweguqe", "original": null, "number": 3, "cdate": 1605709906838, "ddate": null, "tcdate": 1605709906838, "tmdate": 1605713018619, "tddate": null, "forum": "ULQdiUTHe3y", "replyto": "c5YLnE9omq", "invitation": "ICLR.cc/2021/Conference/Paper3522/-/Official_Comment", "content": {"title": "Response - Reviewer 3", "comment": "Thank you for your review!\n\nWe are glad to know that you found the paper well-written, the work well-motivated and the results convincing.  \nWe have corrected the two typos you pointed out in the updated version of the manuscript.\n"}, "signatures": ["ICLR.cc/2021/Conference/Paper3522/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper3522/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Collective Robustness Certificates: Exploiting Interdependence in Graph Neural Networks", "authorids": ["~Jan_Schuchardt1", "~Aleksandar_Bojchevski1", "~Johannes_Klicpera1", "~Stephan_G\u00fcnnemann1"], "authors": ["Jan Schuchardt", "Aleksandar Bojchevski", "Johannes Klicpera", "Stephan G\u00fcnnemann"], "keywords": ["Robustness certificates", "Adversarial robustness", "Graph neural networks"], "abstract": "In tasks like node classification, image segmentation, and named-entity recognition we have a classifier that simultaneously outputs multiple predictions (a vector of labels) based on a single input, i.e. a single graph, image, or document respectively. Existing adversarial robustness certificates consider each prediction independently and are thus overly pessimistic for such tasks. They implicitly assume that an adversary can use different perturbed inputs to attack different predictions, ignoring the fact that we have a single shared input. We propose the first collective robustness certificate which computes the number of predictions that are simultaneously guaranteed to remain stable under perturbation, i.e. cannot be attacked. We focus on Graph Neural Networks and leverage their locality property - perturbations only affect the predictions in a close neighborhood - to fuse multiple single-node certificates into a drastically stronger collective certificate. For example, on the Citeseer dataset our collective certificate for node classification increases the average number of certifiable feature perturbations from $7$ to $351$.\n", "one-sentence_summary": "We fuse multiple single-prediction certificates into a drastically stronger collective certificate leveraging the locality property of Graph Neural Networks.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "schuchardt|collective_robustness_certificates_exploiting_interdependence_in_graph_neural_networks", "supplementary_material": "/attachment/18d6bdec136d663476c8307266c752beb4a432cb.zip", "pdf": "/pdf/23b393f2d9e53b0dd38356295f14b0980ac27b18.pdf", "venue": "ICLR 2021 Poster", "venueid": "ICLR.cc/2021/Conference", "_bibtex": "@inproceedings{\nschuchardt2021collective,\ntitle={Collective Robustness Certificates: Exploiting Interdependence in Graph Neural Networks},\nauthor={Jan Schuchardt and Aleksandar Bojchevski and Johannes Klicpera and Stephan G{\\\"u}nnemann},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=ULQdiUTHe3y}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "ULQdiUTHe3y", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper3522/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper3522/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper3522/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper3522/Authors|ICLR.cc/2021/Conference/Paper3522/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper3522/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923836694, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper3522/-/Official_Comment"}}}, {"id": "Lft3TtcKDb7", "original": null, "number": 2, "cdate": 1605709845156, "ddate": null, "tcdate": 1605709845156, "tmdate": 1605713007715, "tddate": null, "forum": "ULQdiUTHe3y", "replyto": "Z8FbJxzBmOj", "invitation": "ICLR.cc/2021/Conference/Paper3522/-/Official_Comment", "content": {"title": "Response - Reviewer 4", "comment": "Thank you for your review!\n\n**Concerning 1.):**  \nAs you correctly pointed out, the locality assumption is made transparent to the reader -- the manuscript includes an entire section dedicated to discussing the limitations. Nonetheless, popular GNN architectures satisfy locality in practice, which results in a significant increase in the certified ratio using our method, as shown in our experiments. This limitation can be alleviated in future work but that is is out of scope for this paper.\n\n**Concerning 2.):**  \nWe believe that the paper is sufficiently self-contained and provides all preliminaries needed to understand the research problem. However, if you have any specific questions we would be glad to answer them and adapt the manuscript to resolve any unclarities."}, "signatures": ["ICLR.cc/2021/Conference/Paper3522/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper3522/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Collective Robustness Certificates: Exploiting Interdependence in Graph Neural Networks", "authorids": ["~Jan_Schuchardt1", "~Aleksandar_Bojchevski1", "~Johannes_Klicpera1", "~Stephan_G\u00fcnnemann1"], "authors": ["Jan Schuchardt", "Aleksandar Bojchevski", "Johannes Klicpera", "Stephan G\u00fcnnemann"], "keywords": ["Robustness certificates", "Adversarial robustness", "Graph neural networks"], "abstract": "In tasks like node classification, image segmentation, and named-entity recognition we have a classifier that simultaneously outputs multiple predictions (a vector of labels) based on a single input, i.e. a single graph, image, or document respectively. Existing adversarial robustness certificates consider each prediction independently and are thus overly pessimistic for such tasks. They implicitly assume that an adversary can use different perturbed inputs to attack different predictions, ignoring the fact that we have a single shared input. We propose the first collective robustness certificate which computes the number of predictions that are simultaneously guaranteed to remain stable under perturbation, i.e. cannot be attacked. We focus on Graph Neural Networks and leverage their locality property - perturbations only affect the predictions in a close neighborhood - to fuse multiple single-node certificates into a drastically stronger collective certificate. For example, on the Citeseer dataset our collective certificate for node classification increases the average number of certifiable feature perturbations from $7$ to $351$.\n", "one-sentence_summary": "We fuse multiple single-prediction certificates into a drastically stronger collective certificate leveraging the locality property of Graph Neural Networks.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "schuchardt|collective_robustness_certificates_exploiting_interdependence_in_graph_neural_networks", "supplementary_material": "/attachment/18d6bdec136d663476c8307266c752beb4a432cb.zip", "pdf": "/pdf/23b393f2d9e53b0dd38356295f14b0980ac27b18.pdf", "venue": "ICLR 2021 Poster", "venueid": "ICLR.cc/2021/Conference", "_bibtex": "@inproceedings{\nschuchardt2021collective,\ntitle={Collective Robustness Certificates: Exploiting Interdependence in Graph Neural Networks},\nauthor={Jan Schuchardt and Aleksandar Bojchevski and Johannes Klicpera and Stephan G{\\\"u}nnemann},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=ULQdiUTHe3y}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "ULQdiUTHe3y", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper3522/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper3522/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper3522/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper3522/Authors|ICLR.cc/2021/Conference/Paper3522/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper3522/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923836694, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper3522/-/Official_Comment"}}}, {"id": "c5YLnE9omq", "original": null, "number": 3, "cdate": 1603883070560, "ddate": null, "tcdate": 1603883070560, "tmdate": 1605023986062, "tddate": null, "forum": "ULQdiUTHe3y", "replyto": "ULQdiUTHe3y", "invitation": "ICLR.cc/2021/Conference/Paper3522/-/Official_Review", "content": {"title": "Interesting paper. Well-motivated. Good results", "review": "** Summary:\nIn the context of structured prediction, where multiple predictions are simultaneously made based on a single input, this works argue that existing robustness certificates independently operating on each node prediction end up with overly pessimistic results. Rather than that, this work advocates to collectively certify the overall accuracy using a single perturbed graph at a time. Starting from the building-blocks of base certificates, the authors formulate a global optimization problem, which is made tractable via a number of relaxation steps resulting in a final mixed-integer linear programming (MILP). Experimental results demonstrate clear advantage of the proposed certificates over base ones, with reasonable computational overheads coming from solving the MILP.\n\nThe paper is well-motivated, well-written and easy to follow. I think this is a valid method to assess robustness of classifier satisfying locality like GCN.\n\n** Strength:\n - This work is well-motivated. The arguments are valid on the limitations of independent based certificates for collective tasks. Experimental results convincingly show how such certificates are pessimistic in the addressed context.\n - The writing is clear and well-structured, easy to understand and follow. \n - Nice discussion on the limitations\n \n** Limitations:\n - Typos:\n \t+ Eqn. (2): $f_n(\\boldsymbol {X}^{'}, \\boldsymbol{A}^{'}) = f_n(\\boldsymbol{X}^{''}, \\boldsymbol{A}^{ \\textcolor{red}{''}})$\n\n \t+ Eqn. (7): $\\boldsymbol {X}^{''}_{i,d} = \\psi_i^{(n)}\\boldsymbol {\\textcolor{red}{X}}^{'}_{i,d} + (1-\\psi_i^{(n)})\\boldsymbol {\\textcolor{red}{X}}_{i,d}$\n \n \n\n** Justification of rating: overall this is an interesting paper. The motivation, arguments and results are convincing.", "rating": "7: Good paper, accept", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "signatures": ["ICLR.cc/2021/Conference/Paper3522/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper3522/AnonReviewer3"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Collective Robustness Certificates: Exploiting Interdependence in Graph Neural Networks", "authorids": ["~Jan_Schuchardt1", "~Aleksandar_Bojchevski1", "~Johannes_Klicpera1", "~Stephan_G\u00fcnnemann1"], "authors": ["Jan Schuchardt", "Aleksandar Bojchevski", "Johannes Klicpera", "Stephan G\u00fcnnemann"], "keywords": ["Robustness certificates", "Adversarial robustness", "Graph neural networks"], "abstract": "In tasks like node classification, image segmentation, and named-entity recognition we have a classifier that simultaneously outputs multiple predictions (a vector of labels) based on a single input, i.e. a single graph, image, or document respectively. Existing adversarial robustness certificates consider each prediction independently and are thus overly pessimistic for such tasks. They implicitly assume that an adversary can use different perturbed inputs to attack different predictions, ignoring the fact that we have a single shared input. We propose the first collective robustness certificate which computes the number of predictions that are simultaneously guaranteed to remain stable under perturbation, i.e. cannot be attacked. We focus on Graph Neural Networks and leverage their locality property - perturbations only affect the predictions in a close neighborhood - to fuse multiple single-node certificates into a drastically stronger collective certificate. For example, on the Citeseer dataset our collective certificate for node classification increases the average number of certifiable feature perturbations from $7$ to $351$.\n", "one-sentence_summary": "We fuse multiple single-prediction certificates into a drastically stronger collective certificate leveraging the locality property of Graph Neural Networks.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "schuchardt|collective_robustness_certificates_exploiting_interdependence_in_graph_neural_networks", "supplementary_material": "/attachment/18d6bdec136d663476c8307266c752beb4a432cb.zip", "pdf": "/pdf/23b393f2d9e53b0dd38356295f14b0980ac27b18.pdf", "venue": "ICLR 2021 Poster", "venueid": "ICLR.cc/2021/Conference", "_bibtex": "@inproceedings{\nschuchardt2021collective,\ntitle={Collective Robustness Certificates: Exploiting Interdependence in Graph Neural Networks},\nauthor={Jan Schuchardt and Aleksandar Bojchevski and Johannes Klicpera and Stephan G{\\\"u}nnemann},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=ULQdiUTHe3y}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq . ***Please remember to file the Code-of-Ethics report. Once you submitted the review, a link to the report will be visible in the bottom right corner of your review.***", "required": true, "markdown": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}, "forum": "ULQdiUTHe3y", "replyto": "ULQdiUTHe3y", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"], "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper3522/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1607428800000, "duedate": 1606752000000, "multiReply": false, "readers": ["everyone"], "tcdate": 1602538074391, "tmdate": 1606915795551, "super": "ICLR.cc/2021/Conference/-/Official_Review", "signatures": ["OpenReview.net"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Paper3522/Reviewers", "OpenReview.net/Support"], "id": "ICLR.cc/2021/Conference/Paper3522/-/Official_Review"}}}, {"id": "Z8FbJxzBmOj", "original": null, "number": 4, "cdate": 1603937220322, "ddate": null, "tcdate": 1603937220322, "tmdate": 1605023985998, "tddate": null, "forum": "ULQdiUTHe3y", "replyto": "ULQdiUTHe3y", "invitation": "ICLR.cc/2021/Conference/Paper3522/-/Official_Review", "content": {"title": "This paper proposes a new concept called \u201ccollective robustness certificate\u201d that computes the number of predictions which are simultaneously guaranteed to remain stable under perturbation. ", "review": "This paper studies classifiers that collectively output many predictions based on a single input. Existing adversarial robustness certificates assume that an adversary can use different perturbed inputs to attack different predictions, and ignore the fact of a single shared input, thereby being overly pessimistic. This paper proposes a collective certificate that computes the number of simultaneously certifiable nodes for which the predictions can be guaranteed to be stable (not change). It is conducted basically by fusing individual certificates into a provably stronger certificate through explicitly modeling locality. \nPros: This is the first effort that considers collective robustness certificate. \nCons: \n1.\tAs discussed in the paper, the proposed approach is designed to exploit locality. Without locality, it is equivalent to a na\u00efve combination of base certificates that sums over perturbations in the entire graph. \n2.\tThe writing of the paper can be improved. The abstract seems to be unfinished. It appears to be hard to include sufficient preliminaries to clearly describe the research problem in a conference paper. It\u2019s probably better to have a longer version as a journal paper.  \n", "rating": "5: Marginally below acceptance threshold", "confidence": "1: The reviewer's evaluation is an educated guess"}, "signatures": ["ICLR.cc/2021/Conference/Paper3522/AnonReviewer4"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper3522/AnonReviewer4"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Collective Robustness Certificates: Exploiting Interdependence in Graph Neural Networks", "authorids": ["~Jan_Schuchardt1", "~Aleksandar_Bojchevski1", "~Johannes_Klicpera1", "~Stephan_G\u00fcnnemann1"], "authors": ["Jan Schuchardt", "Aleksandar Bojchevski", "Johannes Klicpera", "Stephan G\u00fcnnemann"], "keywords": ["Robustness certificates", "Adversarial robustness", "Graph neural networks"], "abstract": "In tasks like node classification, image segmentation, and named-entity recognition we have a classifier that simultaneously outputs multiple predictions (a vector of labels) based on a single input, i.e. a single graph, image, or document respectively. Existing adversarial robustness certificates consider each prediction independently and are thus overly pessimistic for such tasks. They implicitly assume that an adversary can use different perturbed inputs to attack different predictions, ignoring the fact that we have a single shared input. We propose the first collective robustness certificate which computes the number of predictions that are simultaneously guaranteed to remain stable under perturbation, i.e. cannot be attacked. We focus on Graph Neural Networks and leverage their locality property - perturbations only affect the predictions in a close neighborhood - to fuse multiple single-node certificates into a drastically stronger collective certificate. For example, on the Citeseer dataset our collective certificate for node classification increases the average number of certifiable feature perturbations from $7$ to $351$.\n", "one-sentence_summary": "We fuse multiple single-prediction certificates into a drastically stronger collective certificate leveraging the locality property of Graph Neural Networks.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "schuchardt|collective_robustness_certificates_exploiting_interdependence_in_graph_neural_networks", "supplementary_material": "/attachment/18d6bdec136d663476c8307266c752beb4a432cb.zip", "pdf": "/pdf/23b393f2d9e53b0dd38356295f14b0980ac27b18.pdf", "venue": "ICLR 2021 Poster", "venueid": "ICLR.cc/2021/Conference", "_bibtex": "@inproceedings{\nschuchardt2021collective,\ntitle={Collective Robustness Certificates: Exploiting Interdependence in Graph Neural Networks},\nauthor={Jan Schuchardt and Aleksandar Bojchevski and Johannes Klicpera and Stephan G{\\\"u}nnemann},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=ULQdiUTHe3y}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq . ***Please remember to file the Code-of-Ethics report. Once you submitted the review, a link to the report will be visible in the bottom right corner of your review.***", "required": true, "markdown": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}, "forum": "ULQdiUTHe3y", "replyto": "ULQdiUTHe3y", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"], "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper3522/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1607428800000, "duedate": 1606752000000, "multiReply": false, "readers": ["everyone"], "tcdate": 1602538074391, "tmdate": 1606915795551, "super": "ICLR.cc/2021/Conference/-/Official_Review", "signatures": ["OpenReview.net"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Paper3522/Reviewers", "OpenReview.net/Support"], "id": "ICLR.cc/2021/Conference/Paper3522/-/Official_Review"}}}, {"id": "lqtzTmNj6Ms", "original": null, "number": 2, "cdate": 1603803672445, "ddate": null, "tcdate": 1603803672445, "tmdate": 1605023985928, "tddate": null, "forum": "ULQdiUTHe3y", "replyto": "ULQdiUTHe3y", "invitation": "ICLR.cc/2021/Conference/Paper3522/-/Official_Review", "content": {"title": "This paper first proposes a collective robustness certificate by fusing individual certificates into a provably stronger one, which significantly outperforms existing adversial certificates. Thus, I vote for accepantance.", "review": "This paper addresses the limitation of the existing adversarial robustness certificates that ignores that a single shared input is present, and thus assumes an adversary can use different perturbed inputs to attack different predictions. A novel collective certificate fusing single certificates into a stronger one, is proposed by explicitly modeling local structure of input data using graph convolution node classifiers. In terms of certified ratio, the collective certificate significantly improve the results compared with existing individual certificates. \n\n-quality: the technical quality is sound.\n\n-clarity: the input data, problem formulation and method are clearly described.\n\n-originality & significance: it is the first attempt in considering collective robust certificates (CRCs) by fusing individual adversarial certificate. As shown in the experiments, the certified ratio of the CRC is significantly improved over existing adversarial one. I think the collective robust certificate has some impacts for robust graph node classifications.\n\nPros: The paper is well motivated. The problem and the method are both clearly presented. The improvements of the collective robust certificate over the existing ones is sufficiently high in terms of certified ratios.\n\nCons: I do not find any notable weaknesses.", "rating": "6: Marginally above acceptance threshold", "confidence": "1: The reviewer's evaluation is an educated guess"}, "signatures": ["ICLR.cc/2021/Conference/Paper3522/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper3522/AnonReviewer2"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Collective Robustness Certificates: Exploiting Interdependence in Graph Neural Networks", "authorids": ["~Jan_Schuchardt1", "~Aleksandar_Bojchevski1", "~Johannes_Klicpera1", "~Stephan_G\u00fcnnemann1"], "authors": ["Jan Schuchardt", "Aleksandar Bojchevski", "Johannes Klicpera", "Stephan G\u00fcnnemann"], "keywords": ["Robustness certificates", "Adversarial robustness", "Graph neural networks"], "abstract": "In tasks like node classification, image segmentation, and named-entity recognition we have a classifier that simultaneously outputs multiple predictions (a vector of labels) based on a single input, i.e. a single graph, image, or document respectively. Existing adversarial robustness certificates consider each prediction independently and are thus overly pessimistic for such tasks. They implicitly assume that an adversary can use different perturbed inputs to attack different predictions, ignoring the fact that we have a single shared input. We propose the first collective robustness certificate which computes the number of predictions that are simultaneously guaranteed to remain stable under perturbation, i.e. cannot be attacked. We focus on Graph Neural Networks and leverage their locality property - perturbations only affect the predictions in a close neighborhood - to fuse multiple single-node certificates into a drastically stronger collective certificate. For example, on the Citeseer dataset our collective certificate for node classification increases the average number of certifiable feature perturbations from $7$ to $351$.\n", "one-sentence_summary": "We fuse multiple single-prediction certificates into a drastically stronger collective certificate leveraging the locality property of Graph Neural Networks.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "schuchardt|collective_robustness_certificates_exploiting_interdependence_in_graph_neural_networks", "supplementary_material": "/attachment/18d6bdec136d663476c8307266c752beb4a432cb.zip", "pdf": "/pdf/23b393f2d9e53b0dd38356295f14b0980ac27b18.pdf", "venue": "ICLR 2021 Poster", "venueid": "ICLR.cc/2021/Conference", "_bibtex": "@inproceedings{\nschuchardt2021collective,\ntitle={Collective Robustness Certificates: Exploiting Interdependence in Graph Neural Networks},\nauthor={Jan Schuchardt and Aleksandar Bojchevski and Johannes Klicpera and Stephan G{\\\"u}nnemann},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=ULQdiUTHe3y}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq . ***Please remember to file the Code-of-Ethics report. Once you submitted the review, a link to the report will be visible in the bottom right corner of your review.***", "required": true, "markdown": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}, "forum": "ULQdiUTHe3y", "replyto": "ULQdiUTHe3y", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"], "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper3522/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1607428800000, "duedate": 1606752000000, "multiReply": false, "readers": ["everyone"], "tcdate": 1602538074391, "tmdate": 1606915795551, "super": "ICLR.cc/2021/Conference/-/Official_Review", "signatures": ["OpenReview.net"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Paper3522/Reviewers", "OpenReview.net/Support"], "id": "ICLR.cc/2021/Conference/Paper3522/-/Official_Review"}}}], "count": 11}