{"notes": [{"id": "gV3wdEOGy_V", "original": "cEEgHmnEXuG", "number": 1026, "cdate": 1601308115957, "ddate": null, "tcdate": 1601308115957, "tmdate": 1615714313660, "tddate": null, "forum": "gV3wdEOGy_V", "replyto": null, "invitation": "ICLR.cc/2021/Conference/-/Blind_Submission", "content": {"title": "MiCE: Mixture of Contrastive Experts for Unsupervised Image Clustering", "authorids": ["~Tsung_Wei_Tsai1", "~Chongxuan_Li1", "~Jun_Zhu2"], "authors": ["Tsung Wei Tsai", "Chongxuan Li", "Jun Zhu"], "keywords": ["unsupervised learning", "clustering", "self supervised learning", "mixture of experts"], "abstract": "We present Mixture of Contrastive Experts (MiCE), a unified probabilistic clustering framework that simultaneously exploits the discriminative representations learned by contrastive learning and the semantic structures captured by a latent mixture model. Motivated by the mixture of experts, MiCE employs a gating function to partition an unlabeled dataset into subsets according to the latent semantics and multiple experts to discriminate distinct subsets of instances assigned to them in a contrastive learning manner. To solve the nontrivial inference and learning problems caused by the latent variables, we further develop a scalable variant of the Expectation-Maximization (EM) algorithm for MiCE and provide proof of the convergence. Empirically, we evaluate the clustering performance of MiCE on four widely adopted natural image datasets. MiCE achieves significantly better results than various previous methods and a strong contrastive learning baseline.", "one-sentence_summary": "A principled probabilistic clustering method that exploits the discriminative representations learned by contrastive learning and the semantic structures captured by a latent mixture model in a unified framework.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "tsai|mice_mixture_of_contrastive_experts_for_unsupervised_image_clustering", "supplementary_material": "/attachment/da5bbf9cc7c9924b9dfc826926abb1b2df647f96.zip", "pdf": "/pdf/44a32c550457ebb4f9a6863753563e1f3b2740db.pdf", "venue": "ICLR 2021 Poster", "venueid": "ICLR.cc/2021/Conference", "_bibtex": "@inproceedings{\ntsai2021mice,\ntitle={Mi{\\{}CE{\\}}: Mixture of Contrastive Experts for Unsupervised Image Clustering},\nauthor={Tsung Wei Tsai and Chongxuan Li and Jun Zhu},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=gV3wdEOGy_V}\n}"}, "signatures": ["ICLR.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference"], "details": {"replyCount": 16, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"reply": {"readers": {"values-regex": ".*"}, "writers": {"values": ["ICLR.cc/2021/Conference"]}, "signatures": {"values": ["ICLR.cc/2021/Conference"]}, "content": {"authors": {"values": ["Anonymous"]}, "authorids": {"values-regex": ".*"}, "reviewed_version_(pdf)": {"required": false, "description": "Upload a PDF file that ends with .pdf", "value-regex": ".*"}}}, "signatures": ["ICLR.cc/2021/Conference"], "readers": ["everyone"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["~", "OpenReview.net/Support"], "tcdate": 1601308008205, "tmdate": 1614984599368, "id": "ICLR.cc/2021/Conference/-/Blind_Submission"}}, "tauthor": "OpenReview.net"}, {"id": "UJlAt9eSayw", "original": null, "number": 1, "cdate": 1610040456797, "ddate": null, "tcdate": 1610040456797, "tmdate": 1610474059509, "tddate": null, "forum": "gV3wdEOGy_V", "replyto": "gV3wdEOGy_V", "invitation": "ICLR.cc/2021/Conference/Paper1026/-/Decision", "content": {"title": "Final Decision", "decision": "Accept (Poster)", "comment": "Thanks for your submission to ICLR!\n\nThis paper considers a novel unsupervised image clustering framework based on a mixture of contrastive experts framework.  Most of the reviewers were overall positive about the paper.  On the positive side, they noted that the paper had an interesting idea, was well motivated, written well, and had solid results.  Also, the authors provided detailed and useful responses to the reviews, which further strengthened the case for accepting the paper.  On the negative side, one reviewer felt that the paper seemed a bit preliminary and its presentation could improve.  Also, there was some concern about missing comparisons / discussion to previous work (including from a public comment) or data sets (e.g. ImageNet-10).  Again, the authors responded well to these concerns.\n\nGiven that the overall response was quite positive with the paper, I'm happy to recommend accepting it.\n\n"}, "signatures": ["ICLR.cc/2021/Conference/Program_Chairs"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference/Program_Chairs"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "MiCE: Mixture of Contrastive Experts for Unsupervised Image Clustering", "authorids": ["~Tsung_Wei_Tsai1", "~Chongxuan_Li1", "~Jun_Zhu2"], "authors": ["Tsung Wei Tsai", "Chongxuan Li", "Jun Zhu"], "keywords": ["unsupervised learning", "clustering", "self supervised learning", "mixture of experts"], "abstract": "We present Mixture of Contrastive Experts (MiCE), a unified probabilistic clustering framework that simultaneously exploits the discriminative representations learned by contrastive learning and the semantic structures captured by a latent mixture model. Motivated by the mixture of experts, MiCE employs a gating function to partition an unlabeled dataset into subsets according to the latent semantics and multiple experts to discriminate distinct subsets of instances assigned to them in a contrastive learning manner. To solve the nontrivial inference and learning problems caused by the latent variables, we further develop a scalable variant of the Expectation-Maximization (EM) algorithm for MiCE and provide proof of the convergence. Empirically, we evaluate the clustering performance of MiCE on four widely adopted natural image datasets. MiCE achieves significantly better results than various previous methods and a strong contrastive learning baseline.", "one-sentence_summary": "A principled probabilistic clustering method that exploits the discriminative representations learned by contrastive learning and the semantic structures captured by a latent mixture model in a unified framework.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "tsai|mice_mixture_of_contrastive_experts_for_unsupervised_image_clustering", "supplementary_material": "/attachment/da5bbf9cc7c9924b9dfc826926abb1b2df647f96.zip", "pdf": "/pdf/44a32c550457ebb4f9a6863753563e1f3b2740db.pdf", "venue": "ICLR 2021 Poster", "venueid": "ICLR.cc/2021/Conference", "_bibtex": "@inproceedings{\ntsai2021mice,\ntitle={Mi{\\{}CE{\\}}: Mixture of Contrastive Experts for Unsupervised Image Clustering},\nauthor={Tsung Wei Tsai and Chongxuan Li and Jun Zhu},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=gV3wdEOGy_V}\n}"}, "tags": [], "invitation": {"reply": {"forum": "gV3wdEOGy_V", "replyto": "gV3wdEOGy_V", "readers": {"values": ["everyone"]}, "writers": {"values": ["ICLR.cc/2021/Conference/Program_Chairs"]}, "signatures": {"values": ["ICLR.cc/2021/Conference/Program_Chairs"]}, "content": {"title": {"value": "Final Decision"}, "decision": {"value-radio": ["Accept (Oral)", "Accept (Spotlight)", "Accept (Poster)", "Reject"]}, "comment": {"value-regex": "[\\S\\s]{0,50000}", "markdown": true}}}, "multiReply": false, "signatures": ["ICLR.cc/2021/Conference"], "readers": ["everyone"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Program_Chairs"], "tcdate": 1610040456784, "tmdate": 1610474059491, "id": "ICLR.cc/2021/Conference/Paper1026/-/Decision"}}}, {"id": "y6ae8EP3Q4a", "original": null, "number": 1, "cdate": 1603462431674, "ddate": null, "tcdate": 1603462431674, "tmdate": 1606740089132, "tddate": null, "forum": "gV3wdEOGy_V", "replyto": "gV3wdEOGy_V", "invitation": "ICLR.cc/2021/Conference/Paper1026/-/Official_Review", "content": {"title": "An extension of the MoCo idea in the form of a mixture of MoCo experts for image clustering  ", "review": "The paper presents an image clustering methodology based on Mixture of Experts (MoE) for image clustering. \nAlthough MoE has been proposed for supervised learning problems, the authors exploit the instance discrimination framwork to apply the MoE idea for image clustering. \n\nThis is a novel aspect of the proposed method.\n\nThe MoCo framework (unsupervised) for contrastive learning of image representations is employed to define a mixture of MoCo experts model where each expert additionally includes a cluster prototype vector to facilitate clustering.\n\nThis unified approach for simultaneous MoCo-based representation learning and clustering seems to provide better results that the two-stage approach of first applying MoCo and then using k-means clustering on the obtained representations.\n\nA probabilistic formulation of the method is presented, along with a training approach based on EM algorithm for likelihood maximization.\n\nThere are several concerns related to presentation and clarity.\n\nComments to be addressed:\n1) It would be easier to understand the contribution of the paper, if the MoCo approach were initially described and then the proposed method was presented as a mixture of MoCo experts. The paper in its current form (section 3) is difficult to follow, since several MoCo ideas are mentioned (eg. student and teacher network,  EMA, etc) without been intuitively explained.\n2) In section 3 that describes the method, there is no reference about image augmentation, although it is a critical aspect of the approach. Use of image augmentation is only mentioned at the end of the Appendix.\n3) A pseudocode descibing the exact steps of the proposed method is imperative.\n4) Due to some approximations made, is it possible to prove convergence of the proposed EM procedure?\n5) Gating prototypes \\omega remain fixed during training. It is important to provide more details on the MMD method used to specify them.\n6) It seems strange that, while \\omega are specified using embeddings from the the initial network g(x), they are not involved during training.\n7) A bad specification of \\omega is expected to have strong negative influence on the results that cannot be recovered.\n8) What is the size of minibatch B? (eq. (10)).       \n", "rating": "6: Marginally above acceptance threshold", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}, "signatures": ["ICLR.cc/2021/Conference/Paper1026/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1026/AnonReviewer1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "MiCE: Mixture of Contrastive Experts for Unsupervised Image Clustering", "authorids": ["~Tsung_Wei_Tsai1", "~Chongxuan_Li1", "~Jun_Zhu2"], "authors": ["Tsung Wei Tsai", "Chongxuan Li", "Jun Zhu"], "keywords": ["unsupervised learning", "clustering", "self supervised learning", "mixture of experts"], "abstract": "We present Mixture of Contrastive Experts (MiCE), a unified probabilistic clustering framework that simultaneously exploits the discriminative representations learned by contrastive learning and the semantic structures captured by a latent mixture model. Motivated by the mixture of experts, MiCE employs a gating function to partition an unlabeled dataset into subsets according to the latent semantics and multiple experts to discriminate distinct subsets of instances assigned to them in a contrastive learning manner. To solve the nontrivial inference and learning problems caused by the latent variables, we further develop a scalable variant of the Expectation-Maximization (EM) algorithm for MiCE and provide proof of the convergence. Empirically, we evaluate the clustering performance of MiCE on four widely adopted natural image datasets. MiCE achieves significantly better results than various previous methods and a strong contrastive learning baseline.", "one-sentence_summary": "A principled probabilistic clustering method that exploits the discriminative representations learned by contrastive learning and the semantic structures captured by a latent mixture model in a unified framework.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "tsai|mice_mixture_of_contrastive_experts_for_unsupervised_image_clustering", "supplementary_material": "/attachment/da5bbf9cc7c9924b9dfc826926abb1b2df647f96.zip", "pdf": "/pdf/44a32c550457ebb4f9a6863753563e1f3b2740db.pdf", "venue": "ICLR 2021 Poster", "venueid": "ICLR.cc/2021/Conference", "_bibtex": "@inproceedings{\ntsai2021mice,\ntitle={Mi{\\{}CE{\\}}: Mixture of Contrastive Experts for Unsupervised Image Clustering},\nauthor={Tsung Wei Tsai and Chongxuan Li and Jun Zhu},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=gV3wdEOGy_V}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq . ***Please remember to file the Code-of-Ethics report. Once you submitted the review, a link to the report will be visible in the bottom right corner of your review.***", "required": true, "markdown": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}, "forum": "gV3wdEOGy_V", "replyto": "gV3wdEOGy_V", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"], "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper1026/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1607428800000, "duedate": 1606752000000, "multiReply": false, "readers": ["everyone"], "tcdate": 1602538128888, "tmdate": 1606915788579, "super": "ICLR.cc/2021/Conference/-/Official_Review", "signatures": ["OpenReview.net"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Paper1026/Reviewers", "OpenReview.net/Support"], "id": "ICLR.cc/2021/Conference/Paper1026/-/Official_Review"}}}, {"id": "3vGvW2pRSk", "original": null, "number": 11, "cdate": 1605949902677, "ddate": null, "tcdate": 1605949902677, "tmdate": 1606200711529, "tddate": null, "forum": "gV3wdEOGy_V", "replyto": "gV3wdEOGy_V", "invitation": "ICLR.cc/2021/Conference/Paper1026/-/Official_Comment", "content": {"title": "Thank you for the valuable comments. Looking forward to further feedback.", "comment": "Dear Area Chairs and Reviewers,\n\nWe would like to thank the reviewers again for their constructive and insightful comments, which help us a lot in improving the submission. We have uploaded the revised version and responded to all the reviewers in detail. We believe that the quality of the paper is improved and the contributions are solid. In particular, we would like to highlight some key materials we added:\n\n1.\tPytorch-like pseudocode of MiCE \n2.\tSeveral t-SNE visualizations of the embeddings learned by MiCE and MoCo\n3.\tProof on the convergence of the EM algorithm under the approximation\n4.\tAlgorithm on generating the expert prototypes $\\boldsymbol{\\omega}$ using MMD\n5.\tA preliminary section on contrastive learning to make the paper easier to follow\n\nBesides, we also added extra experiments and discussions regarding the experiment settings, relevant baselines, and ablation studies in Appendix D, E, and F for your reference. \n\nWe understand that reviewers are busy during the response period, we would greatly appreciate it if the reviewers can kindly advise if our responses solve their concerns. If there are any other suggestions/questions, we will try our best to provide satisfactory answers.  We are looking forward to any further discussion with the reviewers. Thank you for your time. \n\n\nBest regards,\n\nThe authors\n\n"}, "signatures": ["ICLR.cc/2021/Conference/Paper1026/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1026/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "MiCE: Mixture of Contrastive Experts for Unsupervised Image Clustering", "authorids": ["~Tsung_Wei_Tsai1", "~Chongxuan_Li1", "~Jun_Zhu2"], "authors": ["Tsung Wei Tsai", "Chongxuan Li", "Jun Zhu"], "keywords": ["unsupervised learning", "clustering", "self supervised learning", "mixture of experts"], "abstract": "We present Mixture of Contrastive Experts (MiCE), a unified probabilistic clustering framework that simultaneously exploits the discriminative representations learned by contrastive learning and the semantic structures captured by a latent mixture model. Motivated by the mixture of experts, MiCE employs a gating function to partition an unlabeled dataset into subsets according to the latent semantics and multiple experts to discriminate distinct subsets of instances assigned to them in a contrastive learning manner. To solve the nontrivial inference and learning problems caused by the latent variables, we further develop a scalable variant of the Expectation-Maximization (EM) algorithm for MiCE and provide proof of the convergence. Empirically, we evaluate the clustering performance of MiCE on four widely adopted natural image datasets. MiCE achieves significantly better results than various previous methods and a strong contrastive learning baseline.", "one-sentence_summary": "A principled probabilistic clustering method that exploits the discriminative representations learned by contrastive learning and the semantic structures captured by a latent mixture model in a unified framework.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "tsai|mice_mixture_of_contrastive_experts_for_unsupervised_image_clustering", "supplementary_material": "/attachment/da5bbf9cc7c9924b9dfc826926abb1b2df647f96.zip", "pdf": "/pdf/44a32c550457ebb4f9a6863753563e1f3b2740db.pdf", "venue": "ICLR 2021 Poster", "venueid": "ICLR.cc/2021/Conference", "_bibtex": "@inproceedings{\ntsai2021mice,\ntitle={Mi{\\{}CE{\\}}: Mixture of Contrastive Experts for Unsupervised Image Clustering},\nauthor={Tsung Wei Tsai and Chongxuan Li and Jun Zhu},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=gV3wdEOGy_V}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "gV3wdEOGy_V", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper1026/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper1026/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper1026/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper1026/Authors|ICLR.cc/2021/Conference/Paper1026/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1026/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923864530, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper1026/-/Official_Comment"}}}, {"id": "1NEWQLTjQ4w", "original": null, "number": 6, "cdate": 1605706272398, "ddate": null, "tcdate": 1605706272398, "tmdate": 1606200521443, "tddate": null, "forum": "gV3wdEOGy_V", "replyto": "ZUdbytSlref", "invitation": "ICLR.cc/2021/Conference/Paper1026/-/Official_Comment", "content": {"title": "Response to Reviewer#2 (3/3)", "comment": "#### Minor comment 1: What does NMI and ARI of > 1 mean? Don\u2019t they have to be in the range of [0,1]?\nYes, both have to be in the range of [0, 1]. In the experiment section, we show the percentage (%) of NMI, ACC, and ARI obtained by each of the methods. We have updated it in Sec. 6 of the revised version to clarify it. Thank you for your concern. \n\n\n\n*Lastly, we would like to express our **utmost appreciation for the constructive and positive comments** the reviewer provided again, which help us in improving the paper.*\n\n\n\n\n====================================================================================\n\n\n[1] Jianlong Wu, Keyu Long, Fei Wang, Chen Qian, Cheng Li, Zhouchen Lin, and Hongbin Zha. Deep comprehensive correlation mining for image clustering. In Proceedings of the IEEE International Conference on Computer Vision, pp. 8150\u20138159, 2019.\n\n[2] Jianlong Chang, Lingfeng Wang, Gaofeng Meng, Shiming Xiang, and Chunhong Pan. Deep adaptive image clustering. In Proceedings of the IEEE international conference on computer vision, pp. 5879\u20135887, 2017.\n\n[3] Mang Ye, Xu Zhang, Pong C Yuen, and Shih-Fu Chang. Unsupervised embedding learning via invariant and spreading instance feature. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 6210\u20136219, 2019.\n\n[4] Zhirong Wu, Yuanjun Xiong, Stella X Yu, and Dahua Lin. Unsupervised feature learning via nonparametric instance discrimination. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 3733\u20133742, 2018.\n\n[5] Ting Chen, Simon Kornblith, Mohammad Norouzi, and Geoffrey Hinton. A simple framework for contrastive learning of visual representations. arXiv preprint arXiv:2002.05709, 2020.\n\n[6] https://github.com/mangye16/Unsupervised_Embedding_Learning\n\n[7] https://github.com/zhirongw/lemniscate.pytorch\n\n[8] Huang, Jiabo, et al. \"Deep Semantic Clustering by Partition Confidence Maximisation.\" (2020): 8846-8855.\n\n[9] Wouter, Van Gansbeke, et al. \"Learning To Classify Images Without Labels.\" (2020).\n\n[10] Xu Ji, Joao F Henriques, and Andrea Vedaldi. Invariant information clustering for unsupervised \u02dc image classification and segmentation. In Proceedings of the IEEE International Conference on Computer Vision, pp. 9865\u20139874, 2019.\n\n[11] https://openaccess.thecvf.com/content_ICCV_2019/supplemental/Ji_Invariant_Information_Clustering_ICCV_2019_supplemental.pdf\n\n[12] Peter J. Rousseeuw (1987). \u201cSilhouettes: a Graphical Aid to the Interpretation and Validation of Cluster Analysis\u201d. Computational and Applied Mathematics 20: 53\u201365. doi:10.1016/0377-0427(87)90125-7.\n\n[13] McLachlan, Geoffrey J., and David Peel. Finite mixture models. John Wiley & Sons, 2004.\n\n[14] Smyth, Padhraic. \"Model selection for probabilistic clustering using cross-validated likelihood.\" Statistics and computing 10.1 (2000): 63-72.\n\n\n"}, "signatures": ["ICLR.cc/2021/Conference/Paper1026/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1026/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "MiCE: Mixture of Contrastive Experts for Unsupervised Image Clustering", "authorids": ["~Tsung_Wei_Tsai1", "~Chongxuan_Li1", "~Jun_Zhu2"], "authors": ["Tsung Wei Tsai", "Chongxuan Li", "Jun Zhu"], "keywords": ["unsupervised learning", "clustering", "self supervised learning", "mixture of experts"], "abstract": "We present Mixture of Contrastive Experts (MiCE), a unified probabilistic clustering framework that simultaneously exploits the discriminative representations learned by contrastive learning and the semantic structures captured by a latent mixture model. Motivated by the mixture of experts, MiCE employs a gating function to partition an unlabeled dataset into subsets according to the latent semantics and multiple experts to discriminate distinct subsets of instances assigned to them in a contrastive learning manner. To solve the nontrivial inference and learning problems caused by the latent variables, we further develop a scalable variant of the Expectation-Maximization (EM) algorithm for MiCE and provide proof of the convergence. Empirically, we evaluate the clustering performance of MiCE on four widely adopted natural image datasets. MiCE achieves significantly better results than various previous methods and a strong contrastive learning baseline.", "one-sentence_summary": "A principled probabilistic clustering method that exploits the discriminative representations learned by contrastive learning and the semantic structures captured by a latent mixture model in a unified framework.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "tsai|mice_mixture_of_contrastive_experts_for_unsupervised_image_clustering", "supplementary_material": "/attachment/da5bbf9cc7c9924b9dfc826926abb1b2df647f96.zip", "pdf": "/pdf/44a32c550457ebb4f9a6863753563e1f3b2740db.pdf", "venue": "ICLR 2021 Poster", "venueid": "ICLR.cc/2021/Conference", "_bibtex": "@inproceedings{\ntsai2021mice,\ntitle={Mi{\\{}CE{\\}}: Mixture of Contrastive Experts for Unsupervised Image Clustering},\nauthor={Tsung Wei Tsai and Chongxuan Li and Jun Zhu},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=gV3wdEOGy_V}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "gV3wdEOGy_V", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper1026/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper1026/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper1026/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper1026/Authors|ICLR.cc/2021/Conference/Paper1026/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1026/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923864530, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper1026/-/Official_Comment"}}}, {"id": "d_F-XYddXq9", "original": null, "number": 7, "cdate": 1605706466726, "ddate": null, "tcdate": 1605706466726, "tmdate": 1606200378460, "tddate": null, "forum": "gV3wdEOGy_V", "replyto": "Ae8ZpVmVTQ", "invitation": "ICLR.cc/2021/Conference/Paper1026/-/Official_Comment", "content": {"title": "Response to Reviewer#4 ", "comment": "We thank the reviewer for the positive comments and acknowledgment of our contribution. We revised the submission by providing extra experiments, visualizations, and pseudocodes in both the main text and the appendix. Please kindly find the detailed responses below.\n\n\n\n#### Q1: More visual results\nThank you for the advice. Following your suggestion, we included several new figures and visualizations to support our ideas in the revised version. For instance, we show the histogram of the posterior estimates of the dataset at the different training epochs. Also, we visualize the image embeddings and the prototypes with t-SNE to investigate whether MiCE capture the cluster structure that matches the latent semantics. \n\nPlease kindly refer to Sec.6.1 and Appendix E of the revision for the results.\n\n\n\n#### Q2: The performance on datasets with a larger amount of clusters\nThank you for your suggestion. We hypothesize that MiCE can perform well on datasets with a larger amount of clusters according to our current empirical results and analysis. This is a very interesting and important future work. We added the discussion in Sec. 7.\n\n\n\n*We would like to express our sincere gratitude and appreciation for the constructive and positive comments again, which help us to improve the quality of the paper.*\n\n\n"}, "signatures": ["ICLR.cc/2021/Conference/Paper1026/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1026/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "MiCE: Mixture of Contrastive Experts for Unsupervised Image Clustering", "authorids": ["~Tsung_Wei_Tsai1", "~Chongxuan_Li1", "~Jun_Zhu2"], "authors": ["Tsung Wei Tsai", "Chongxuan Li", "Jun Zhu"], "keywords": ["unsupervised learning", "clustering", "self supervised learning", "mixture of experts"], "abstract": "We present Mixture of Contrastive Experts (MiCE), a unified probabilistic clustering framework that simultaneously exploits the discriminative representations learned by contrastive learning and the semantic structures captured by a latent mixture model. Motivated by the mixture of experts, MiCE employs a gating function to partition an unlabeled dataset into subsets according to the latent semantics and multiple experts to discriminate distinct subsets of instances assigned to them in a contrastive learning manner. To solve the nontrivial inference and learning problems caused by the latent variables, we further develop a scalable variant of the Expectation-Maximization (EM) algorithm for MiCE and provide proof of the convergence. Empirically, we evaluate the clustering performance of MiCE on four widely adopted natural image datasets. MiCE achieves significantly better results than various previous methods and a strong contrastive learning baseline.", "one-sentence_summary": "A principled probabilistic clustering method that exploits the discriminative representations learned by contrastive learning and the semantic structures captured by a latent mixture model in a unified framework.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "tsai|mice_mixture_of_contrastive_experts_for_unsupervised_image_clustering", "supplementary_material": "/attachment/da5bbf9cc7c9924b9dfc826926abb1b2df647f96.zip", "pdf": "/pdf/44a32c550457ebb4f9a6863753563e1f3b2740db.pdf", "venue": "ICLR 2021 Poster", "venueid": "ICLR.cc/2021/Conference", "_bibtex": "@inproceedings{\ntsai2021mice,\ntitle={Mi{\\{}CE{\\}}: Mixture of Contrastive Experts for Unsupervised Image Clustering},\nauthor={Tsung Wei Tsai and Chongxuan Li and Jun Zhu},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=gV3wdEOGy_V}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "gV3wdEOGy_V", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper1026/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper1026/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper1026/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper1026/Authors|ICLR.cc/2021/Conference/Paper1026/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1026/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923864530, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper1026/-/Official_Comment"}}}, {"id": "4XDRwdhBR2y", "original": null, "number": 3, "cdate": 1605705397888, "ddate": null, "tcdate": 1605705397888, "tmdate": 1606199899250, "tddate": null, "forum": "gV3wdEOGy_V", "replyto": "UIp6Fn9KsOd", "invitation": "ICLR.cc/2021/Conference/Paper1026/-/Official_Comment", "content": {"title": "Response to Reviewer#3 (2/2)", "comment": "#### Q4: Omitting some of the prior works in experiments and need to justify the selection of baseline methods\nWe clarify that the experiment settings of the papers mentioned in the comments [5][6][7] and MiCE are **different in two aspects**. (1) We train the model **from scratch** without using a pre-trained model, following a large family of recent methods (IIC [8], MMDC [9], DCCM [10], etc.), while the papers the reviewer mentioned rely on pre-training. (2) We focus on a purely **unsupervised** setting. In contrast, VaDE [5] and DGG [7] use a **supervised pre-trained** model on ImageNet for STL-10. For fairness, in the original submission, we compared to many previous methods that use the same settings and did not include the papers the reviewer mentioned in the comment.\n \nIn the revision, we have discussed the relation with papers the reviewer mentioned in Appendix D and clarified that we select baselines that are **without pre-training** in the first paragraph of Sec. 6.\nFurthermore, we add preliminary experiments with **unsupervised pre-training** and MiCE obtains 89.3% accuracy on CIFAR10, which is much higher than 83.5% in Tab. 1 of the revision, showing that our proposal is orthogonal to the pre-training techniques. We will add more results and discussion in the camera-ready version.\n\n*Lastly, **we sincerely appreciate the reviewer for the insightful comments**, which indeed help us to improve the submission.*\n\n\n\n\n===================================================================================================================\n[1] Robert A Jacobs, Michael I Jordan, Steven J Nowlan, and Geoffrey E Hinton. Adaptive mixtures of local experts. Neural Computation, 3(1):79\u201387, 1991.\n\n[2] Yuksel, Seniha Esen, Joseph N. Wilson, and Paul D. Gader. \"Twenty years of mixture of experts.\" IEEE transactions on neural networks and learning systems 23.8 (2012): 1177-1193.\n\n[3] Chuang Niu, Jun Zhang, Ge Wang, and Jimin Liang. Gatcluster: Self-supervised gaussian-attention\nnetwork for image clustering. arXiv preprint arXiv:2002.11863, 2020.\n\n[4] Guy Shiran and Daphna Weinshall. Multi-modal deep clustering: Unsupervised partitioning of images. arXiv preprint arXiv:1912.02678, 2019.\n\n[5] Zhuxi Jiang, Yin Zheng, Huachun Tan, Bangsheng Tang, and Hanning Zhou. Variational deep embedding: An unsupervised and generative approach to clustering. arXiv preprint arXiv:1611.05148,\n2016.\n\n[6] Li, Xiaopeng, et al. \"Learning latent superstructures in variational autoencoders for deep multidimensional clustering.\" arXiv preprint arXiv:1803.05206 (2018).\n\n[7] Yang, Linxiao, et al. \"Deep clustering by gaussian mixture variational autoencoders with graph embedding.\" Proceedings of the IEEE International Conference on Computer Vision. 2019.\n\n[8] Xu Ji, Joao F Henriques, and Andrea Vedaldi. Invariant information clustering for unsupervised \u02dc image classification and segmentation. In Proceedings of the IEEE International Conference on Computer Vision, pp. 9865\u20139874, 2019.\n\n[9] Guy Shiran and Daphna Weinshall. Multi-modal deep clustering: Unsupervised partitioning of images. arXiv preprint arXiv:1912.02678, 2019.\n\n[10] Jianlong Wu, Keyu Long, Fei Wang, Chen Qian, Cheng Li, Zhouchen Lin, and Hongbin Zha. Deep comprehensive correlation mining for image clustering. In Proceedings of the IEEE International Conference on Computer Vision, pp. 8150\u20138159, 2019.\n\n[11] Kaiming He, Haoqi Fan, Yuxin Wu, Saining Xie, and Ross Girshick. Momentum contrast for unsupervised visual representation learning. arXiv preprint arXiv:1911.05722, 2019.\n\n"}, "signatures": ["ICLR.cc/2021/Conference/Paper1026/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1026/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "MiCE: Mixture of Contrastive Experts for Unsupervised Image Clustering", "authorids": ["~Tsung_Wei_Tsai1", "~Chongxuan_Li1", "~Jun_Zhu2"], "authors": ["Tsung Wei Tsai", "Chongxuan Li", "Jun Zhu"], "keywords": ["unsupervised learning", "clustering", "self supervised learning", "mixture of experts"], "abstract": "We present Mixture of Contrastive Experts (MiCE), a unified probabilistic clustering framework that simultaneously exploits the discriminative representations learned by contrastive learning and the semantic structures captured by a latent mixture model. Motivated by the mixture of experts, MiCE employs a gating function to partition an unlabeled dataset into subsets according to the latent semantics and multiple experts to discriminate distinct subsets of instances assigned to them in a contrastive learning manner. To solve the nontrivial inference and learning problems caused by the latent variables, we further develop a scalable variant of the Expectation-Maximization (EM) algorithm for MiCE and provide proof of the convergence. Empirically, we evaluate the clustering performance of MiCE on four widely adopted natural image datasets. MiCE achieves significantly better results than various previous methods and a strong contrastive learning baseline.", "one-sentence_summary": "A principled probabilistic clustering method that exploits the discriminative representations learned by contrastive learning and the semantic structures captured by a latent mixture model in a unified framework.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "tsai|mice_mixture_of_contrastive_experts_for_unsupervised_image_clustering", "supplementary_material": "/attachment/da5bbf9cc7c9924b9dfc826926abb1b2df647f96.zip", "pdf": "/pdf/44a32c550457ebb4f9a6863753563e1f3b2740db.pdf", "venue": "ICLR 2021 Poster", "venueid": "ICLR.cc/2021/Conference", "_bibtex": "@inproceedings{\ntsai2021mice,\ntitle={Mi{\\{}CE{\\}}: Mixture of Contrastive Experts for Unsupervised Image Clustering},\nauthor={Tsung Wei Tsai and Chongxuan Li and Jun Zhu},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=gV3wdEOGy_V}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "gV3wdEOGy_V", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper1026/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper1026/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper1026/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper1026/Authors|ICLR.cc/2021/Conference/Paper1026/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1026/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923864530, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper1026/-/Official_Comment"}}}, {"id": "rIQGC9DvDDY", "original": null, "number": 9, "cdate": 1605706889407, "ddate": null, "tcdate": 1605706889407, "tmdate": 1606199728831, "tddate": null, "forum": "gV3wdEOGy_V", "replyto": "mN_zZ00mbkd", "invitation": "ICLR.cc/2021/Conference/Paper1026/-/Official_Comment", "content": {"title": "Response to Reviewer#1 (2/2)", "comment": "#### Q5: More details on MMD\nThank you for the advice. We have added the algorithm to generate the centers of MMD in Appendix B of the revision. The provided algorithm is conducted before training MiCE to prepare the $\\boldsymbol{\\omega}$. The centers we used are also provided in the original supplementary file we submitted. \n\n\n#### Q6: It seems strange that, while $\\boldsymbol{\\omega}$ are specified using embeddings from the initial network g(x), they are not involved during training.\nThere is a potential misunderstanding. The gating prototypes $\\boldsymbol{\\omega}$ are not specified using the embeddings from the gating network. We have another independent process to generate the means of MMD before training the model. Please kindly refer to Appendix B for the specific algorithm in the revision. Thank you for your concern.\n\n\n#### Q7: A bad specification of $\\boldsymbol{\\omega}$ is expected to have a strong negative influence on the results that cannot be recovered.\nThank you for your concern. This might be a potential misunderstanding. In Tab. 3 (right), we show that MiCE is not sensitive to the different treatments of the gating prototypes $\\boldsymbol{\\omega}$. As shown in Tab. 3 (b, c, d), they all can get a decent performance on CIFAR-100, while using MMD provides a slightly better result.\n\nAccording to the reviewer\u2019s comment, we suppose that the reviewer is referring to the result of the expert prototypes $\\boldsymbol{\\mu}$ that is shown in Tab. 3 (a). The bad specification of the expert prototypes can lead to bad results if **it is not properly handled**. We empirically verify *two principled methods that solve the issue*: (1) extra end-of-epoch training only on $\\boldsymbol{\\mu}$  with stochastic gradient ascent or (2) using Eq. (11). The first method would require a much longer training time, therefore, we are currently using Eq. (11) to prevent the bad specification of $\\boldsymbol{\\mu}$ during training. We have updated the submission to include the discussion and details in Appendix E for your reference.\n\n\n#### Q8: The size of the mini-batch B\nThank you for your reminder. The batch size is set to 256 for all experiments on the four datasets. We updated the submission to include the number in Sec.6.\n\n\n\n\n*Lastly, **we would like to express our sincere appreciation for the insightful comments the reviewer provided again**, which indeed help us to improve the submission.*\n\n\n\n\n\n========================================================================================\n\n\n[1] Zhirong Wu, Yuanjun Xiong, Stella X Yu, and Dahua Lin. Unsupervised feature learning via nonparametric\ninstance discrimination. In Proceedings of the IEEE Conference on Computer Vision\nand Pattern Recognition, pp. 3733\u20133742, 2018.\n\n[2] Kaiming He, Haoqi Fan, Yuxin Wu, Saining Xie, and Ross Girshick. Momentum contrast for unsupervised visual representation learning. arXiv preprint arXiv:1911.05722, 2019.\n\n[3] Ting Chen, Simon Kornblith, Mohammad Norouzi, and Geoffrey Hinton. A simple framework for contrastive learning of visual representations. arXiv preprint arXiv:2002.05709, 2020.\n\n[4] Tianyu Pang, Kun Xu, Yinpeng Dong, Chao Du, Ning Chen, and Jun Zhu. Rethinking softmax cross-entropy loss for adversarial robustness. arXiv preprint arXiv:1905.10626, 2019.\n\n\n\n\n"}, "signatures": ["ICLR.cc/2021/Conference/Paper1026/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1026/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "MiCE: Mixture of Contrastive Experts for Unsupervised Image Clustering", "authorids": ["~Tsung_Wei_Tsai1", "~Chongxuan_Li1", "~Jun_Zhu2"], "authors": ["Tsung Wei Tsai", "Chongxuan Li", "Jun Zhu"], "keywords": ["unsupervised learning", "clustering", "self supervised learning", "mixture of experts"], "abstract": "We present Mixture of Contrastive Experts (MiCE), a unified probabilistic clustering framework that simultaneously exploits the discriminative representations learned by contrastive learning and the semantic structures captured by a latent mixture model. Motivated by the mixture of experts, MiCE employs a gating function to partition an unlabeled dataset into subsets according to the latent semantics and multiple experts to discriminate distinct subsets of instances assigned to them in a contrastive learning manner. To solve the nontrivial inference and learning problems caused by the latent variables, we further develop a scalable variant of the Expectation-Maximization (EM) algorithm for MiCE and provide proof of the convergence. Empirically, we evaluate the clustering performance of MiCE on four widely adopted natural image datasets. MiCE achieves significantly better results than various previous methods and a strong contrastive learning baseline.", "one-sentence_summary": "A principled probabilistic clustering method that exploits the discriminative representations learned by contrastive learning and the semantic structures captured by a latent mixture model in a unified framework.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "tsai|mice_mixture_of_contrastive_experts_for_unsupervised_image_clustering", "supplementary_material": "/attachment/da5bbf9cc7c9924b9dfc826926abb1b2df647f96.zip", "pdf": "/pdf/44a32c550457ebb4f9a6863753563e1f3b2740db.pdf", "venue": "ICLR 2021 Poster", "venueid": "ICLR.cc/2021/Conference", "_bibtex": "@inproceedings{\ntsai2021mice,\ntitle={Mi{\\{}CE{\\}}: Mixture of Contrastive Experts for Unsupervised Image Clustering},\nauthor={Tsung Wei Tsai and Chongxuan Li and Jun Zhu},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=gV3wdEOGy_V}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "gV3wdEOGy_V", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper1026/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper1026/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper1026/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper1026/Authors|ICLR.cc/2021/Conference/Paper1026/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1026/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923864530, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper1026/-/Official_Comment"}}}, {"id": "mN_zZ00mbkd", "original": null, "number": 8, "cdate": 1605706680631, "ddate": null, "tcdate": 1605706680631, "tmdate": 1605947790928, "tddate": null, "forum": "gV3wdEOGy_V", "replyto": "y6ae8EP3Q4a", "invitation": "ICLR.cc/2021/Conference/Paper1026/-/Official_Comment", "content": {"title": "Response to Reviewer#1 (1/2)", "comment": "We thank the reviewer for the constructive comments and acknowledgment of our novelty. We updated the submission accordingly. In particular, we formally proved the convergence and provided extra pseudocodes and experiments for clarity. Please kindly find the detailed responses below.\n\n\n#### Q1: To introduce MoCo first \nThank you for the concrete advice. Following the reviewer\u2019s suggestion, we added a preliminary section to introduce contrastive learning, especially MoCo, before introducing MiCE in the revised version to make the paper easier to follow. In the preliminary section, we explained the use of the student and teacher networks, EMA, and data augmentation.\n\nCurrently, our writing seems to tie up MiCE and MoCo [2], while we think MiCE is a general framework that can construct the expert model based on different contrastive learning methods such as InstDisc [1] and SimCLR [3] (with some minor adaptations needed). We have also clarified it in Sec.3&4 of the revised version.\n\n\n#### Q2: Reference to data augmentation\nThank you for pointing out. We updated the submission to mention data augmentation in the preliminary and Sec.6 of the revised version.  For your convenience, we use the standard augmentation as in MoCo [2].\n\n\n#### Q3: Pseudocode\nThank you for the advice. We added a Pytorch-like pseudocode in Appendix A.3 to show the implementation and exact steps of the proposed method, which follows MoCo [2]. \n\n\n#### Q4: Convergence of EM \n\nThank you for your concern. We formally proved the convergence of MiCE in Appendix A.4. The proof spirit is highly similar to the original EM\u2019s.\n\nIn particular, we first rewrite the approximate ELBO used in MiCE as a sum of the original ELBO and a log-ratio between two normalization constants. We found that the log ratio has a constant upper bound. Therefore, by assuming that the log conditional likelihood of the incomplete data has an upper bound, similarly to the original proof in EM, we can upper bound the approximate ELBO. Since the approximated ELBO will not decrease in expectation, MiCE is convergent in expectation as well. \n\n\n\n"}, "signatures": ["ICLR.cc/2021/Conference/Paper1026/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1026/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "MiCE: Mixture of Contrastive Experts for Unsupervised Image Clustering", "authorids": ["~Tsung_Wei_Tsai1", "~Chongxuan_Li1", "~Jun_Zhu2"], "authors": ["Tsung Wei Tsai", "Chongxuan Li", "Jun Zhu"], "keywords": ["unsupervised learning", "clustering", "self supervised learning", "mixture of experts"], "abstract": "We present Mixture of Contrastive Experts (MiCE), a unified probabilistic clustering framework that simultaneously exploits the discriminative representations learned by contrastive learning and the semantic structures captured by a latent mixture model. Motivated by the mixture of experts, MiCE employs a gating function to partition an unlabeled dataset into subsets according to the latent semantics and multiple experts to discriminate distinct subsets of instances assigned to them in a contrastive learning manner. To solve the nontrivial inference and learning problems caused by the latent variables, we further develop a scalable variant of the Expectation-Maximization (EM) algorithm for MiCE and provide proof of the convergence. Empirically, we evaluate the clustering performance of MiCE on four widely adopted natural image datasets. MiCE achieves significantly better results than various previous methods and a strong contrastive learning baseline.", "one-sentence_summary": "A principled probabilistic clustering method that exploits the discriminative representations learned by contrastive learning and the semantic structures captured by a latent mixture model in a unified framework.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "tsai|mice_mixture_of_contrastive_experts_for_unsupervised_image_clustering", "supplementary_material": "/attachment/da5bbf9cc7c9924b9dfc826926abb1b2df647f96.zip", "pdf": "/pdf/44a32c550457ebb4f9a6863753563e1f3b2740db.pdf", "venue": "ICLR 2021 Poster", "venueid": "ICLR.cc/2021/Conference", "_bibtex": "@inproceedings{\ntsai2021mice,\ntitle={Mi{\\{}CE{\\}}: Mixture of Contrastive Experts for Unsupervised Image Clustering},\nauthor={Tsung Wei Tsai and Chongxuan Li and Jun Zhu},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=gV3wdEOGy_V}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "gV3wdEOGy_V", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper1026/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper1026/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper1026/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper1026/Authors|ICLR.cc/2021/Conference/Paper1026/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1026/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923864530, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper1026/-/Official_Comment"}}}, {"id": "ZUdbytSlref", "original": null, "number": 5, "cdate": 1605706136289, "ddate": null, "tcdate": 1605706136289, "tmdate": 1605945890678, "tddate": null, "forum": "gV3wdEOGy_V", "replyto": "M38Hb9ZSLyn", "invitation": "ICLR.cc/2021/Conference/Paper1026/-/Official_Comment", "content": {"title": "Response to Reviewer#2 (2/3) ", "comment": "#### Q5: Computational complexity\nWe find the training time of MiCE and MoCo to be comparable. It takes around 17 hours to train MoCo and 30 hours to train MiCE for 1000 epochs, respectively. We ran the experiments on a single GPU (NVIDIA GeForce GTX 1080 Ti). We have updated the submission to include the training time of MoCE and MiCE on CIFAR-10 in Appendix E.\n\nComparing to MoCo, the additional training time of MiCE is mainly because of the mixture formulation and an extra forward pass of the mini-batch data. Please kindly refer to Appendix A.3 for the newly added Pytorch-like pseudocode for details. \n\n\n#### Q6: Will $\\boldsymbol{\\mu}$ and $\\boldsymbol{\\omega}$ be similar, and their correspondence \nWe do not expect the two prototypes to be similar even though their dimensions are the same. In fact, they have different aims: the gating ones aim to divide the datasets into simpler subtasks for the experts, while the expert ones help the expert to solve the instance discrimination subtasks by introducing the class-level information. Therefore, the derived ELBO objective does not encourage the two sets of prototypes to be similar or maintaining a clear correspondence between them.\n\nEmpirically, we calculate the cosine similarity between any pair of $\\boldsymbol{\\mu}$ and $\\boldsymbol{\\omega}$. The absolute values we get are less than 0.25, which showed that they are not similar. If we force them to be similar during training, the performance may be negatively affected due to the lack of flexibility.\n\nWe added the discussion in Appendix F of the revised version.\n\n\n#### Q7: Usage and effect of MMD\n\nThank you for your concern. We use the centers of MMD as the gating prototypes that are always fixed during training and testing. To clarify the usage of MMD, we have provided the algorithm for generating the centers of MMD (Appendix B) and a Pytorch-like pseudocode of MiCE (Appendix A.3) in the revised version for your reference.\n\nAs MMD provides the optimal inter-cluster dispersion, it can encourage embeddings of the gating network to be well-separated and can avoid the potential drawbacks when we have some of the gating prototypes crowded together. Specifically, compared to using gating prototypes that are samples from a uniform distribution, we find that using MMD can slightly improve the results by 1% ACC, as shown in Tab.3 of the original submission. \n\n\n#### Q8: Max-pooling layer\nSeveral contrastive learning methods [3][4][5] remove the first max-pooling layer when training on CIFAR-10 and CIFAR-100. We follow their implementations closely. Please kindly refer to [6][7] where we include the link to their code for your convenience. We ran an extra experiment with the max-pooling layer and get 83.6% ACC on CIFAR-10. The result is on par with the 83.5% we reported in Tab.1 of the revision. We have clarified it in Appendix D as well.\n\n"}, "signatures": ["ICLR.cc/2021/Conference/Paper1026/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1026/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "MiCE: Mixture of Contrastive Experts for Unsupervised Image Clustering", "authorids": ["~Tsung_Wei_Tsai1", "~Chongxuan_Li1", "~Jun_Zhu2"], "authors": ["Tsung Wei Tsai", "Chongxuan Li", "Jun Zhu"], "keywords": ["unsupervised learning", "clustering", "self supervised learning", "mixture of experts"], "abstract": "We present Mixture of Contrastive Experts (MiCE), a unified probabilistic clustering framework that simultaneously exploits the discriminative representations learned by contrastive learning and the semantic structures captured by a latent mixture model. Motivated by the mixture of experts, MiCE employs a gating function to partition an unlabeled dataset into subsets according to the latent semantics and multiple experts to discriminate distinct subsets of instances assigned to them in a contrastive learning manner. To solve the nontrivial inference and learning problems caused by the latent variables, we further develop a scalable variant of the Expectation-Maximization (EM) algorithm for MiCE and provide proof of the convergence. Empirically, we evaluate the clustering performance of MiCE on four widely adopted natural image datasets. MiCE achieves significantly better results than various previous methods and a strong contrastive learning baseline.", "one-sentence_summary": "A principled probabilistic clustering method that exploits the discriminative representations learned by contrastive learning and the semantic structures captured by a latent mixture model in a unified framework.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "tsai|mice_mixture_of_contrastive_experts_for_unsupervised_image_clustering", "supplementary_material": "/attachment/da5bbf9cc7c9924b9dfc826926abb1b2df647f96.zip", "pdf": "/pdf/44a32c550457ebb4f9a6863753563e1f3b2740db.pdf", "venue": "ICLR 2021 Poster", "venueid": "ICLR.cc/2021/Conference", "_bibtex": "@inproceedings{\ntsai2021mice,\ntitle={Mi{\\{}CE{\\}}: Mixture of Contrastive Experts for Unsupervised Image Clustering},\nauthor={Tsung Wei Tsai and Chongxuan Li and Jun Zhu},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=gV3wdEOGy_V}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "gV3wdEOGy_V", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper1026/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper1026/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper1026/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper1026/Authors|ICLR.cc/2021/Conference/Paper1026/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1026/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923864530, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper1026/-/Official_Comment"}}}, {"id": "M38Hb9ZSLyn", "original": null, "number": 4, "cdate": 1605705843130, "ddate": null, "tcdate": 1605705843130, "tmdate": 1605945808504, "tddate": null, "forum": "gV3wdEOGy_V", "replyto": "7tmry5-AJSk", "invitation": "ICLR.cc/2021/Conference/Paper1026/-/Official_Comment", "content": {"title": "Response to Reviewer#2 (1/3) ", "comment": "We thank the reviewer for the positive comments and acknowledgment of our novelty. In the revision, we addressed all comments. In particular, we clarified the experiment settings and included the algorithm on the usage of MMD and extra experiments. Please kindly find the detailed responses below.\n\n\n#### Q1: Results on ImageNet-10\nWe have started running experiments on the ImageNet-10. Given the limited time of the response period, we plan to include the results in the camera-ready version if possible. Besides, ImageNet-Dog results in the submission can also verify the effectiveness of MiCE on complex datasets. \n\nAlso, we added the results from the paper mentioned in the comment with the title \u201cDeep Semantic Clustering by Partition Confidence Maximisation\u201d [8] as one of the baseline methods to Tab.1 of the revised version.\n\n\n#### Q2: The use of other contrastive learning backbones\nThank you for your concern. The proposed framework is general and can be derived based on different contrastive methods. Indeed, for any contrastive learning methods that can define the model $p(Y|X)$, we can formulate the mixture model by introducing the latent variables as the cluster labels. Incorporating other possible contrastive learning backbones like SimCLR would be interesting future work. \n\nAs the current writing seems to be tied up with MoCo, we added a preliminary section (Sec.3 in the revised version) to introduce the contrastive learning before introducing MiCE and clarify their relations as discussed above.\n\n\n#### Q3: Why were images in ImageNet-Dog resized to 96 x 96 x3?\nFor a fair comparison, the ImageNet-Dog is resized to 96x96x3 following the previous methods, including DCCM[1] and DAC [2]. We have included the references about the image size in Sec.6 of the revised version. \n\n\n#### Q4: The number of experts and overclustering\nThank you for your concern. In the cases where the number of the experts L differs from the number of ground-truth clusters K, the model will partition the datasets into L subsets instead of K. Even though the number of experts is currently tied with K, *it is not a drawback and does not prevent us from applying to the common clustering settings*. Also, MiCE does not use additional knowledge comparing to the baseline methods. If the ground-truth K is not known, we may treat K as a hyper-parameter and decide K following the methods described in [13][14], which is worth investigating in the future.\n\nThe overclustering technique [10] is orthogonal to our methods and can be applied with minor adaptations. However, it may require additional hyper-parameter tuning to ensure overclustering improves the results. From the supplementary [11] provided by IIC [10], we see that the numbers of clusters (for overclustering) are set differently for different datasets. Despite overclustering is an interesting technique, we would like to **highlight the simplicity** of the current version of MiCE.  \n\nWe provide a possible implementation in the following for your further reference: To perform overclustering (of M clusters), we could add another (M+1) output layers and another gating and expert prototypes with M embeddings each. Therefore, on top of the original objective function with K experts, we can add another objective with M experts, where the possible values of the latent variables are in {1, 2, \u2026, K} and {1, 2, \u2026, M} respectively.\n\nWe included the above discussion in Appendix F of the revision.\n"}, "signatures": ["ICLR.cc/2021/Conference/Paper1026/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1026/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "MiCE: Mixture of Contrastive Experts for Unsupervised Image Clustering", "authorids": ["~Tsung_Wei_Tsai1", "~Chongxuan_Li1", "~Jun_Zhu2"], "authors": ["Tsung Wei Tsai", "Chongxuan Li", "Jun Zhu"], "keywords": ["unsupervised learning", "clustering", "self supervised learning", "mixture of experts"], "abstract": "We present Mixture of Contrastive Experts (MiCE), a unified probabilistic clustering framework that simultaneously exploits the discriminative representations learned by contrastive learning and the semantic structures captured by a latent mixture model. Motivated by the mixture of experts, MiCE employs a gating function to partition an unlabeled dataset into subsets according to the latent semantics and multiple experts to discriminate distinct subsets of instances assigned to them in a contrastive learning manner. To solve the nontrivial inference and learning problems caused by the latent variables, we further develop a scalable variant of the Expectation-Maximization (EM) algorithm for MiCE and provide proof of the convergence. Empirically, we evaluate the clustering performance of MiCE on four widely adopted natural image datasets. MiCE achieves significantly better results than various previous methods and a strong contrastive learning baseline.", "one-sentence_summary": "A principled probabilistic clustering method that exploits the discriminative representations learned by contrastive learning and the semantic structures captured by a latent mixture model in a unified framework.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "tsai|mice_mixture_of_contrastive_experts_for_unsupervised_image_clustering", "supplementary_material": "/attachment/da5bbf9cc7c9924b9dfc826926abb1b2df647f96.zip", "pdf": "/pdf/44a32c550457ebb4f9a6863753563e1f3b2740db.pdf", "venue": "ICLR 2021 Poster", "venueid": "ICLR.cc/2021/Conference", "_bibtex": "@inproceedings{\ntsai2021mice,\ntitle={Mi{\\{}CE{\\}}: Mixture of Contrastive Experts for Unsupervised Image Clustering},\nauthor={Tsung Wei Tsai and Chongxuan Li and Jun Zhu},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=gV3wdEOGy_V}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "gV3wdEOGy_V", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper1026/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper1026/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper1026/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper1026/Authors|ICLR.cc/2021/Conference/Paper1026/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1026/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923864530, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper1026/-/Official_Comment"}}}, {"id": "UIp6Fn9KsOd", "original": null, "number": 2, "cdate": 1605705326297, "ddate": null, "tcdate": 1605705326297, "tmdate": 1605945385997, "tddate": null, "forum": "gV3wdEOGy_V", "replyto": "1ChMTRII-Nw", "invitation": "ICLR.cc/2021/Conference/Paper1026/-/Official_Comment", "content": {"title": "Response to Reviewer#3 (1/2)", "comment": "We thank the reviewer for the valuable and constructive comments and we have updated the submission accordingly. In particular, we clarified the main concerns on the technical details and selection of baselines. Please kindly find the detailed responses below.\n\n\n#### Q1: Concerns about the probability p(Y, Z|X)\nThank you for pointing out the issue. The number of the equation seems to be missing in the comment the reviewer provided. As the reviewer mentioned $p(Y, Z|X)$, we suppose that the reviewer is referring to  Eq.(3) in the revision (which was Eq. (1) in the first/original submission) and will discuss it below. Please kindly let us know if the reviewer is referring to a different equation.\n\nThere was a typo where the probability p(y_n, z_n=k | x_n=k) shall have an indicator function \\mathds{1}(z_n = k) as its exponent. The correct Eq. (3) is: \np(Y, Z |X) = \\prod_{n=1}^N \\prod_{k=1}^K p(y_n, z_n = k |x_n)^{ \\mathds{1} (z_n = k)} = \\prod_{n=1}^N \\prod_{k=1}^K p(z_n = k | x_n )^{ \\mathds{1} (z_n = k)} p(y_n | x_n, z_n = k)^{ \\mathds{1} (z_n = k)}. The gating function p(z_n|x_n) is modeled as a categorical distribution and allows soft weighting on the predictions from the $z_n$-th expert. The formulation follows the Mixture of Experts (MoE) [1][2] closely. \n\nWe have revised the submission accordingly. Please kindly refer to Eq.(3) in the revision for details. We also double-check the other equations and the algorithm, which remain correct.\n\n#### Q2: The student and teacher embeddings are used before Equation 4 but have not been explained until a later part of the paper.\nThank you for the advice. We have added  *Preliminary* section to introduce contrastive learning methods, especially MoCo, before introducing MiCE to make the paper easier to follow. The technical details of MoCo, including the student and teacher embeddings, and the use of EMA are discussed in the Preliminary section. Please kindly refer to Sec.3 of the revision for more details. \n\n#### Q3: It is also unclear why an instance discrimination approach would lead to a better clustering performance\nAs mentioned in the second paragraph of Sec.1 and the experiment section of the original submission, the instance discrimination task leads to discriminative representations [11], which are useful for clustering. In fact, improved representations can lead to better clustering results as shown in the clustering literature [3][4].\n\nEmpirically, with instance discrimination, we can get a substantial improvement even with a simple clustering algorithm such as spherical k-means, as shown in Tab.1 in the revision. Further, with a unified framework, MiCE can improve the results by considering the semantic structure explicitly (also see Tab. 1). \n\nWe added the above discussion in Sec. 1 of the revised version to make the motivation of using instance discrimination clearer.\n\n"}, "signatures": ["ICLR.cc/2021/Conference/Paper1026/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1026/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "MiCE: Mixture of Contrastive Experts for Unsupervised Image Clustering", "authorids": ["~Tsung_Wei_Tsai1", "~Chongxuan_Li1", "~Jun_Zhu2"], "authors": ["Tsung Wei Tsai", "Chongxuan Li", "Jun Zhu"], "keywords": ["unsupervised learning", "clustering", "self supervised learning", "mixture of experts"], "abstract": "We present Mixture of Contrastive Experts (MiCE), a unified probabilistic clustering framework that simultaneously exploits the discriminative representations learned by contrastive learning and the semantic structures captured by a latent mixture model. Motivated by the mixture of experts, MiCE employs a gating function to partition an unlabeled dataset into subsets according to the latent semantics and multiple experts to discriminate distinct subsets of instances assigned to them in a contrastive learning manner. To solve the nontrivial inference and learning problems caused by the latent variables, we further develop a scalable variant of the Expectation-Maximization (EM) algorithm for MiCE and provide proof of the convergence. Empirically, we evaluate the clustering performance of MiCE on four widely adopted natural image datasets. MiCE achieves significantly better results than various previous methods and a strong contrastive learning baseline.", "one-sentence_summary": "A principled probabilistic clustering method that exploits the discriminative representations learned by contrastive learning and the semantic structures captured by a latent mixture model in a unified framework.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "tsai|mice_mixture_of_contrastive_experts_for_unsupervised_image_clustering", "supplementary_material": "/attachment/da5bbf9cc7c9924b9dfc826926abb1b2df647f96.zip", "pdf": "/pdf/44a32c550457ebb4f9a6863753563e1f3b2740db.pdf", "venue": "ICLR 2021 Poster", "venueid": "ICLR.cc/2021/Conference", "_bibtex": "@inproceedings{\ntsai2021mice,\ntitle={Mi{\\{}CE{\\}}: Mixture of Contrastive Experts for Unsupervised Image Clustering},\nauthor={Tsung Wei Tsai and Chongxuan Li and Jun Zhu},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=gV3wdEOGy_V}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "gV3wdEOGy_V", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper1026/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper1026/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper1026/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper1026/Authors|ICLR.cc/2021/Conference/Paper1026/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1026/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923864530, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper1026/-/Official_Comment"}}}, {"id": "tsGQ9ejnuB", "original": null, "number": 10, "cdate": 1605709196493, "ddate": null, "tcdate": 1605709196493, "tmdate": 1605945058530, "tddate": null, "forum": "gV3wdEOGy_V", "replyto": "5TbJtJEVvzt", "invitation": "ICLR.cc/2021/Conference/Paper1026/-/Official_Comment", "content": {"title": "Response to the public comment by Wouter Van Gansbeke", "comment": "Thank you for the constructive comment. We find your paper inspiring and will include the comparisons with the proposed method in the revision. \n\nIn the experiment section, we are mainly comparing to recent methods that do not involve pre-training. As far as we know, only DHOG [1] is still under review and all the other baseline methods are published. DHOG is included as it is also a relevant probabilistic clustering approach. \n\nWe provide additional experiment results to compare with the method \u201cSCAN\u201d mentioned in the public comment fairly. As SCAN adopts a *three-step* training procedure, we think that it will provide additional insights by comparing MiCE/MoCo to SCAN at each step on CIFAR-10. \n\n\n#### 1st step:\nWe find that the two-stage baseline results (MoCo+spherical $k$-means) are better than the SimCLR baseline results reported in your paper, despite MoCo and SimCLR performs similarly on ImageNet.  We suppose that using the spherical k-means as the output embeddings are L2-normalized, or setting the temperature to 1 may be able to improve the SimCLR baseline.\n\n\n#### 2nd step:\n**MiCE without pre-training outperforms SCAN with two steps of training**. SCAN obtains 78.7% and 81.8% on CIFAR-10 with the SimCLR augmentation and RandAugment respectively. In contrast, MiCE is able to get 83.4% despite we are using a weaker augmentation strategy following MoCo [3] and InstDisc [1]. \n\n\n#### 3rd step:\nBy fine-tuning the MiCE model with the same training protocol (except the learning rate can be smaller), *MiCE can obtain higher results comparing to SCAN*. After the self-labeling step, SCAN gets **10.0%** and **87.6%** ACC when training with the SimCLR augmentation and RandAugment respectively. While for MiCE, the results we obtain are as follows:\n\n1.\tMiCE pre-training + MiCE                                                      89.3%\n2.\tMiCE pre-training + MiCE (RandAugment)                        88.3%\n3.\tMiCE pre-training + MiCE (SimCLR augmentation)        **90.3%**\n\nTo be specific, in the fine-tuning stage, we load the network parameters from the pre-trained model and use a smaller initial learning rate of 0.1 with all the other settings remain the same. We show the augmentation strategy in the parenthesis if we use a different one from the pre-training stage. For the RandAugment, we follow the implementation (and hyper-parameters) based on the link you provided. As mentioned in your paper, the self-labeling stage requires a shift in the augmentation, otherwise, it will lead to a degenerated solution. **In contrast, MiCE with pre-training is not prone to degeneracy and can get comparable or better performance than SCAN regardless of the choice of the augmentation strategy.** \n\nBesides, the self-labeling stage seems to be orthogonal to our approach and it can further improve MiCE as long as it is a general technique that is not sensitive to the difference in the previous stages. \n\nWe included the above discussion in Appendix E of the revision. \n\n\n=========================================================================================================\n\n[1] Luke Nicholas Darlow and Amos Storkey. Dhog: Deep hierarchical object grouping. arXiv preprint arXiv:2003.08821, 2020.\n\n[2] Zhirong Wu, Yuanjun Xiong, Stella X Yu, and Dahua Lin. Unsupervised feature learning via nonparametric\ninstance discrimination. In Proceedings of the IEEE Conference on Computer Vision\nand Pattern Recognition, pp. 3733\u20133742, 2018.\n\n[3] Kaiming He, Haoqi Fan, Yuxin Wu, Saining Xie, and Ross Girshick. Momentum contrast for unsupervised visual representation learning. arXiv preprint arXiv:1911.05722, 2019.\n\n"}, "signatures": ["ICLR.cc/2021/Conference/Paper1026/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1026/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "MiCE: Mixture of Contrastive Experts for Unsupervised Image Clustering", "authorids": ["~Tsung_Wei_Tsai1", "~Chongxuan_Li1", "~Jun_Zhu2"], "authors": ["Tsung Wei Tsai", "Chongxuan Li", "Jun Zhu"], "keywords": ["unsupervised learning", "clustering", "self supervised learning", "mixture of experts"], "abstract": "We present Mixture of Contrastive Experts (MiCE), a unified probabilistic clustering framework that simultaneously exploits the discriminative representations learned by contrastive learning and the semantic structures captured by a latent mixture model. Motivated by the mixture of experts, MiCE employs a gating function to partition an unlabeled dataset into subsets according to the latent semantics and multiple experts to discriminate distinct subsets of instances assigned to them in a contrastive learning manner. To solve the nontrivial inference and learning problems caused by the latent variables, we further develop a scalable variant of the Expectation-Maximization (EM) algorithm for MiCE and provide proof of the convergence. Empirically, we evaluate the clustering performance of MiCE on four widely adopted natural image datasets. MiCE achieves significantly better results than various previous methods and a strong contrastive learning baseline.", "one-sentence_summary": "A principled probabilistic clustering method that exploits the discriminative representations learned by contrastive learning and the semantic structures captured by a latent mixture model in a unified framework.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "tsai|mice_mixture_of_contrastive_experts_for_unsupervised_image_clustering", "supplementary_material": "/attachment/da5bbf9cc7c9924b9dfc826926abb1b2df647f96.zip", "pdf": "/pdf/44a32c550457ebb4f9a6863753563e1f3b2740db.pdf", "venue": "ICLR 2021 Poster", "venueid": "ICLR.cc/2021/Conference", "_bibtex": "@inproceedings{\ntsai2021mice,\ntitle={Mi{\\{}CE{\\}}: Mixture of Contrastive Experts for Unsupervised Image Clustering},\nauthor={Tsung Wei Tsai and Chongxuan Li and Jun Zhu},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=gV3wdEOGy_V}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "gV3wdEOGy_V", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper1026/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper1026/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper1026/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper1026/Authors|ICLR.cc/2021/Conference/Paper1026/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1026/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923864530, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper1026/-/Official_Comment"}}}, {"id": "5TbJtJEVvzt", "original": null, "number": 1, "cdate": 1605037706230, "ddate": null, "tcdate": 1605037706230, "tmdate": 1605037706230, "tddate": null, "forum": "gV3wdEOGy_V", "replyto": "gV3wdEOGy_V", "invitation": "ICLR.cc/2021/Conference/Paper1026/-/Public_Comment", "content": {"title": "Missing relevant prior work", "comment": "Dear authors and reviewers,\n\nWe believe there is an important competing method omitted from both the related work section and the state-of-the-art comparison. In particular, the ECCV\u201920 paper \u2018SCAN: Learning To Classify Images Without Labels\u2019 is the current state-of-the-art in unsupervised image classification on CIFAR10, CIFAR100, STL-10, and ImageNet (1000 classes). Moreover the code of this paper was made publicly available, and can also be found on the relevant leaderboards of the well-known \u2018Papers With Code\u2019 platform (https://paperswithcode.com/task/unsupervised-image-classification).\n\nGiven these circumstances, we find it unfortunate that the state-of-the-art comparison failed to include the referred work. In particular, because the table does mention other works that are still under review, and report lower performance. We are looking forward to any future discussions.\n"}, "signatures": ["~Wouter_Van_Gansbeke1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "~Wouter_Van_Gansbeke1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "MiCE: Mixture of Contrastive Experts for Unsupervised Image Clustering", "authorids": ["~Tsung_Wei_Tsai1", "~Chongxuan_Li1", "~Jun_Zhu2"], "authors": ["Tsung Wei Tsai", "Chongxuan Li", "Jun Zhu"], "keywords": ["unsupervised learning", "clustering", "self supervised learning", "mixture of experts"], "abstract": "We present Mixture of Contrastive Experts (MiCE), a unified probabilistic clustering framework that simultaneously exploits the discriminative representations learned by contrastive learning and the semantic structures captured by a latent mixture model. Motivated by the mixture of experts, MiCE employs a gating function to partition an unlabeled dataset into subsets according to the latent semantics and multiple experts to discriminate distinct subsets of instances assigned to them in a contrastive learning manner. To solve the nontrivial inference and learning problems caused by the latent variables, we further develop a scalable variant of the Expectation-Maximization (EM) algorithm for MiCE and provide proof of the convergence. Empirically, we evaluate the clustering performance of MiCE on four widely adopted natural image datasets. MiCE achieves significantly better results than various previous methods and a strong contrastive learning baseline.", "one-sentence_summary": "A principled probabilistic clustering method that exploits the discriminative representations learned by contrastive learning and the semantic structures captured by a latent mixture model in a unified framework.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "tsai|mice_mixture_of_contrastive_experts_for_unsupervised_image_clustering", "supplementary_material": "/attachment/da5bbf9cc7c9924b9dfc826926abb1b2df647f96.zip", "pdf": "/pdf/44a32c550457ebb4f9a6863753563e1f3b2740db.pdf", "venue": "ICLR 2021 Poster", "venueid": "ICLR.cc/2021/Conference", "_bibtex": "@inproceedings{\ntsai2021mice,\ntitle={Mi{\\{}CE{\\}}: Mixture of Contrastive Experts for Unsupervised Image Clustering},\nauthor={Tsung Wei Tsai and Chongxuan Li and Jun Zhu},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=gV3wdEOGy_V}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "gV3wdEOGy_V", "readers": {"description": "User groups that will be able to read this comment.", "values": ["everyone"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "~.*", "description": "How your identity will be displayed."}}, "expdate": 1605630600000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["everyone"], "noninvitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1026/Authors", "ICLR.cc/2021/Conference/Paper1026/Reviewers", "ICLR.cc/2021/Conference/Paper1026/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs"], "tcdate": 1605024976572, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper1026/-/Public_Comment"}}}, {"id": "Ae8ZpVmVTQ", "original": null, "number": 2, "cdate": 1603872011933, "ddate": null, "tcdate": 1603872011933, "tmdate": 1605024548809, "tddate": null, "forum": "gV3wdEOGy_V", "replyto": "gV3wdEOGy_V", "invitation": "ICLR.cc/2021/Conference/Paper1026/-/Official_Review", "content": {"title": "  ", "review": "Summary and Contributions: Inspired by the mixture of experts, authors propose an image clustering algorithm using a mixture of contrastive experts where, each of the conditional models is an expert in discriminating a subset of instances based on contrastive learning.  To this end they  use a gating function to partition an unlabeled dataset into subsets according to the latent semantics and discriminative distinct, where the gating function performs a soft partitioning of the dataset\nbased on the cosine similarity between the image embeddings and the gating prototypes. The authors carry out experiments on four widely adopted natural image datasets to evaluate the performance of the method in these tasks and compare it to competing methods and baselines.\n\n\nCorrectness and Clarity: The paper is well-written, with informative figures and tables. The paper presents the idea in a clear and straight-forward manner, and is solidly built on top of the current literature. Authors convincingly tested the method with multiple SOTA and baseline and the results look correct to me.  \n\nReproducibility: The details of the experiments, implementation, and the public datasets are included in the paper. Thanks also for sharing the code.\n\nAdditional Feedback and Suggestions:  Since the goal of the paper is image clustering, providing some visual results is appreciated. Also, I am curious to see the performance of the method when we have large number of clusters in our dataset e.g. ImageNet. \n\nDecision: The idea of using  a scalable variant of the Expectation-Maximization (EM) algorithm to help with the nontrivial inference and learning problems caused by the latent variables seems interesting to me.  And overall, the technical novelty together with the fine evaluation are good enough for ICLR, in my opinion.\n", "rating": "8: Top 50% of accepted papers, clear accept", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "signatures": ["ICLR.cc/2021/Conference/Paper1026/AnonReviewer4"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1026/AnonReviewer4"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "MiCE: Mixture of Contrastive Experts for Unsupervised Image Clustering", "authorids": ["~Tsung_Wei_Tsai1", "~Chongxuan_Li1", "~Jun_Zhu2"], "authors": ["Tsung Wei Tsai", "Chongxuan Li", "Jun Zhu"], "keywords": ["unsupervised learning", "clustering", "self supervised learning", "mixture of experts"], "abstract": "We present Mixture of Contrastive Experts (MiCE), a unified probabilistic clustering framework that simultaneously exploits the discriminative representations learned by contrastive learning and the semantic structures captured by a latent mixture model. Motivated by the mixture of experts, MiCE employs a gating function to partition an unlabeled dataset into subsets according to the latent semantics and multiple experts to discriminate distinct subsets of instances assigned to them in a contrastive learning manner. To solve the nontrivial inference and learning problems caused by the latent variables, we further develop a scalable variant of the Expectation-Maximization (EM) algorithm for MiCE and provide proof of the convergence. Empirically, we evaluate the clustering performance of MiCE on four widely adopted natural image datasets. MiCE achieves significantly better results than various previous methods and a strong contrastive learning baseline.", "one-sentence_summary": "A principled probabilistic clustering method that exploits the discriminative representations learned by contrastive learning and the semantic structures captured by a latent mixture model in a unified framework.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "tsai|mice_mixture_of_contrastive_experts_for_unsupervised_image_clustering", "supplementary_material": "/attachment/da5bbf9cc7c9924b9dfc826926abb1b2df647f96.zip", "pdf": "/pdf/44a32c550457ebb4f9a6863753563e1f3b2740db.pdf", "venue": "ICLR 2021 Poster", "venueid": "ICLR.cc/2021/Conference", "_bibtex": "@inproceedings{\ntsai2021mice,\ntitle={Mi{\\{}CE{\\}}: Mixture of Contrastive Experts for Unsupervised Image Clustering},\nauthor={Tsung Wei Tsai and Chongxuan Li and Jun Zhu},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=gV3wdEOGy_V}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq . ***Please remember to file the Code-of-Ethics report. Once you submitted the review, a link to the report will be visible in the bottom right corner of your review.***", "required": true, "markdown": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}, "forum": "gV3wdEOGy_V", "replyto": "gV3wdEOGy_V", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"], "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper1026/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1607428800000, "duedate": 1606752000000, "multiReply": false, "readers": ["everyone"], "tcdate": 1602538128888, "tmdate": 1606915788579, "super": "ICLR.cc/2021/Conference/-/Official_Review", "signatures": ["OpenReview.net"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Paper1026/Reviewers", "OpenReview.net/Support"], "id": "ICLR.cc/2021/Conference/Paper1026/-/Official_Review"}}}, {"id": "7tmry5-AJSk", "original": null, "number": 3, "cdate": 1603946614322, "ddate": null, "tcdate": 1603946614322, "tmdate": 1605024548748, "tddate": null, "forum": "gV3wdEOGy_V", "replyto": "gV3wdEOGy_V", "invitation": "ICLR.cc/2021/Conference/Paper1026/-/Official_Review", "content": {"title": "Novel methodology to solve a clustering problem with scope of improvement in the paper", "review": "Summary: Authors present \u201cmixture of experts\u201d type of method to solve a clustering with unsupervised learning problem. Method is called as Mixture of Contrastive Experts (MiCE) which uses contrastive learning as a base module and combines it with latent mixture models. Authors develop a scalable algorithm for MiCE and empirically evaluate the proposed method for image clustering. \n\nRecommendation: I am tending towards accepting the paper (rating 6). Reason for the acceptance is the novel method supported by empirical evidence. Reason for score not being too high are some weaknesses mentioned in the details later. \nStrengths: \n1) Authors address an image clustering algorithm given number of clusters. Submission is clear, technically correct and present novel findings. \n2) The proposed approach is well motivated. \n\nWeakness/Questions:\n1) All recent papers have ImageNet-10 as one of the five common datasets [1-2]. Why was it omitted in the current paper? \n2) It looks like method is very tied up with MoCo and developed on top of it. Is there an easy/quick way to use other backbones like SimCLR instead of MoCo and still preserve all the steps in the method?\n3) Why were images in ImageNet-Dog resized to 96 x 96 x3?\n4) Almost all prior methods and proposed method MiCE assume that a number of clusters are known (which shouldn\u2019t ideally be the case). But it looks like the proposed method MiCE uses the information in a better way by assuming number of experts = number of clusters. Can one use more or less number of experts (than number of clusters K) and still partition the sample data into K clusters? Can one easily use over clustering as presented in IIC? \n5) How does the proposed method MiCE fare in terms of computation complexity when compared to MoCo? \n6) How do \\mu, w (the expert and gating prototypes) differ during the training? Since the prediction value is the sum of the expert probability weighted by the gating function, one would expect the gating prototypes and expert prototypes to be similar? Is this true? How is consistency maintained (is there a clear correspondence, prototype 1 in expert matches to prototype 2 in gating function)?\n7) Can authors elaborate more about the usage of Max-Mahalanobis distribution (MMD) and how exactly does it solve the issue of \u201cunnecessary difficulties in partitioning the dataset if some of them are crowded together.\u201d\n8) \u201cSince the images of CIFAR-10 and CIFAR-100 are smaller than ImageNet images, following (Chen et al., 2020), we replace the first 7x7 Conv of stride 2 with a 3x3 Conv of stride 1 for all experiments on CIFAR-10 and CIFAR-100. The first max-pooling operation is removed as well. For fair comparisons\u201d: Is removing  first max-pooling operation standard practice? Is there any performance loss when max pooling is not removed? \n\nMinor:\n1) What does NMI and ARI of > 1 mean? Don\u2019t they have to be in the range of [0,1]? \n\n\n[1] Huang, Jiabo, Shaogang Gong, and Xiatian Zhu. \"Deep Semantic Clustering by Partition Confidence Maximisation.\" In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pp. 8849-8858. 2020.\n[2] Wu, Jianlong, Keyu Long, Fei Wang, Chen Qian, Cheng Li, Zhouchen Lin, and Hongbin Zha. \"Deep comprehensive correlation mining for image clustering.\" In Proceedings of the IEEE International Conference on Computer Vision, pp. 8150-8159. 2019. \n\n\n", "rating": "6: Marginally above acceptance threshold", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}, "signatures": ["ICLR.cc/2021/Conference/Paper1026/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1026/AnonReviewer2"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "MiCE: Mixture of Contrastive Experts for Unsupervised Image Clustering", "authorids": ["~Tsung_Wei_Tsai1", "~Chongxuan_Li1", "~Jun_Zhu2"], "authors": ["Tsung Wei Tsai", "Chongxuan Li", "Jun Zhu"], "keywords": ["unsupervised learning", "clustering", "self supervised learning", "mixture of experts"], "abstract": "We present Mixture of Contrastive Experts (MiCE), a unified probabilistic clustering framework that simultaneously exploits the discriminative representations learned by contrastive learning and the semantic structures captured by a latent mixture model. Motivated by the mixture of experts, MiCE employs a gating function to partition an unlabeled dataset into subsets according to the latent semantics and multiple experts to discriminate distinct subsets of instances assigned to them in a contrastive learning manner. To solve the nontrivial inference and learning problems caused by the latent variables, we further develop a scalable variant of the Expectation-Maximization (EM) algorithm for MiCE and provide proof of the convergence. Empirically, we evaluate the clustering performance of MiCE on four widely adopted natural image datasets. MiCE achieves significantly better results than various previous methods and a strong contrastive learning baseline.", "one-sentence_summary": "A principled probabilistic clustering method that exploits the discriminative representations learned by contrastive learning and the semantic structures captured by a latent mixture model in a unified framework.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "tsai|mice_mixture_of_contrastive_experts_for_unsupervised_image_clustering", "supplementary_material": "/attachment/da5bbf9cc7c9924b9dfc826926abb1b2df647f96.zip", "pdf": "/pdf/44a32c550457ebb4f9a6863753563e1f3b2740db.pdf", "venue": "ICLR 2021 Poster", "venueid": "ICLR.cc/2021/Conference", "_bibtex": "@inproceedings{\ntsai2021mice,\ntitle={Mi{\\{}CE{\\}}: Mixture of Contrastive Experts for Unsupervised Image Clustering},\nauthor={Tsung Wei Tsai and Chongxuan Li and Jun Zhu},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=gV3wdEOGy_V}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq . ***Please remember to file the Code-of-Ethics report. Once you submitted the review, a link to the report will be visible in the bottom right corner of your review.***", "required": true, "markdown": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}, "forum": "gV3wdEOGy_V", "replyto": "gV3wdEOGy_V", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"], "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper1026/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1607428800000, "duedate": 1606752000000, "multiReply": false, "readers": ["everyone"], "tcdate": 1602538128888, "tmdate": 1606915788579, "super": "ICLR.cc/2021/Conference/-/Official_Review", "signatures": ["OpenReview.net"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Paper1026/Reviewers", "OpenReview.net/Support"], "id": "ICLR.cc/2021/Conference/Paper1026/-/Official_Review"}}}, {"id": "1ChMTRII-Nw", "original": null, "number": 4, "cdate": 1604039352598, "ddate": null, "tcdate": 1604039352598, "tmdate": 1605024548687, "tddate": null, "forum": "gV3wdEOGy_V", "replyto": "gV3wdEOGy_V", "invitation": "ICLR.cc/2021/Conference/Paper1026/-/Official_Review", "content": {"title": "Combination of existing ideas with concerns on technical details and experimental results", "review": "The paper proposes to use mixture of experts for image clustering.  The individual expert for each cluster adopts an instance discrimination approach for training.  The proposed method has shown superior clustering performance compared to an extensive number of clustering methods on a reasonable collection of data sets.\n\nThough the overall idea of the proposed method is clear, the paper does not seem to explain some technical details clear enough.  In Equation, the probability P(Y,Z|X) does not seem to be correct. The product term over k appears to be valid only when it uses a hard assignment, i.e. P(z_n|x_n) = 1 for exactly one of the clusters.  The student and teacher embeddings are used before Equation 4 but have not been explained until a later part of the paper.  It is also unclear why an instance discrimination approach would lead to a better clustering performance.\n\nAlthough an extensive number of clustering methods have been included in the experiments, it has omitted some strong competitors including Variational Deep Embedding (Jiang et al. 2016), Latent Tree Variational Autoencoder (Li et al. 2019), Deep clustering via a Gaussian mixture VAE with Graph embedding (Yang et al. 2019), etc.  Those methods appear to perform better on some of the data sets.  For example, those methods have been reported to yield over 85% of accuracy on the STL-10 data set but the proposed method yields only 75% on the same data set.  It would be better if the paper could include those methods in the experiments or justify the selection of baseline methods.\n\nOverall, the proposed method appears to be an interesting combination of some existing methods.  However, the technical details need better clarity and the experiments should include more relevant methods.", "rating": "5: Marginally below acceptance threshold", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["ICLR.cc/2021/Conference/Paper1026/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1026/AnonReviewer3"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "MiCE: Mixture of Contrastive Experts for Unsupervised Image Clustering", "authorids": ["~Tsung_Wei_Tsai1", "~Chongxuan_Li1", "~Jun_Zhu2"], "authors": ["Tsung Wei Tsai", "Chongxuan Li", "Jun Zhu"], "keywords": ["unsupervised learning", "clustering", "self supervised learning", "mixture of experts"], "abstract": "We present Mixture of Contrastive Experts (MiCE), a unified probabilistic clustering framework that simultaneously exploits the discriminative representations learned by contrastive learning and the semantic structures captured by a latent mixture model. Motivated by the mixture of experts, MiCE employs a gating function to partition an unlabeled dataset into subsets according to the latent semantics and multiple experts to discriminate distinct subsets of instances assigned to them in a contrastive learning manner. To solve the nontrivial inference and learning problems caused by the latent variables, we further develop a scalable variant of the Expectation-Maximization (EM) algorithm for MiCE and provide proof of the convergence. Empirically, we evaluate the clustering performance of MiCE on four widely adopted natural image datasets. MiCE achieves significantly better results than various previous methods and a strong contrastive learning baseline.", "one-sentence_summary": "A principled probabilistic clustering method that exploits the discriminative representations learned by contrastive learning and the semantic structures captured by a latent mixture model in a unified framework.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "tsai|mice_mixture_of_contrastive_experts_for_unsupervised_image_clustering", "supplementary_material": "/attachment/da5bbf9cc7c9924b9dfc826926abb1b2df647f96.zip", "pdf": "/pdf/44a32c550457ebb4f9a6863753563e1f3b2740db.pdf", "venue": "ICLR 2021 Poster", "venueid": "ICLR.cc/2021/Conference", "_bibtex": "@inproceedings{\ntsai2021mice,\ntitle={Mi{\\{}CE{\\}}: Mixture of Contrastive Experts for Unsupervised Image Clustering},\nauthor={Tsung Wei Tsai and Chongxuan Li and Jun Zhu},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=gV3wdEOGy_V}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq . ***Please remember to file the Code-of-Ethics report. Once you submitted the review, a link to the report will be visible in the bottom right corner of your review.***", "required": true, "markdown": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}, "forum": "gV3wdEOGy_V", "replyto": "gV3wdEOGy_V", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"], "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper1026/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1607428800000, "duedate": 1606752000000, "multiReply": false, "readers": ["everyone"], "tcdate": 1602538128888, "tmdate": 1606915788579, "super": "ICLR.cc/2021/Conference/-/Official_Review", "signatures": ["OpenReview.net"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Paper1026/Reviewers", "OpenReview.net/Support"], "id": "ICLR.cc/2021/Conference/Paper1026/-/Official_Review"}}}], "count": 17}