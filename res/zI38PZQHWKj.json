{"notes": [{"id": "zI38PZQHWKj", "original": "PEKGzjDjfTq", "number": 390, "cdate": 1601308050901, "ddate": null, "tcdate": 1601308050901, "tmdate": 1614985684677, "tddate": null, "forum": "zI38PZQHWKj", "replyto": null, "invitation": "ICLR.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Feature-Robust Optimal Transport for High-Dimensional Data", "authorids": ["mathis.petrovich@gmail.com", "cs.chaoliang@zju.edu.cn", "~Ryoma_Sato1", "~Yanbin_Liu1", "~Yao-Hung_Hubert_Tsai1", "~Linchao_Zhu1", "~Yi_Yang4", "~Ruslan_Salakhutdinov1", "~Makoto_Yamada3"], "authors": ["Mathis Petrovich", "Chao Liang", "Ryoma Sato", "Yanbin Liu", "Yao-Hung Hubert Tsai", "Linchao Zhu", "Yi Yang", "Ruslan Salakhutdinov", "Makoto Yamada"], "keywords": ["Optimal Transport", "feature selection", "semantic correspondence"], "abstract": "Optimal transport is a machine learning problem with applications including distribution comparison, feature selection, and generative adversarial networks. In this paper, we propose feature-robust optimal transport (FROT) for high-dimensional data, which solves high-dimensional OT problems using feature selection to avoid the curse of dimensionality. Specifically, we find a transport plan with discriminative features. To this end, we formulate the FROT problem as a min--max optimization problem. We then propose a convex formulation of the FROT problem and solve it using a Frank--Wolfe-based optimization algorithm, whereby the subproblem can be efficiently solved using the Sinkhorn algorithm. Since FROT finds the transport plan from selected features, it is robust to noise features. To show the effectiveness of FROT, we propose using the FROT algorithm for the layer selection problem in deep neural networks for semantic correspondence. By conducting synthetic and benchmark experiments, we demonstrate that the proposed method can find a strong correspondence by determining important layers. We show that the FROT algorithm achieves state-of-the-art performance in real-world semantic correspondence datasets.", "one-sentence_summary": "We propose an optimal transport method for high-dimensional data and applied it to semantic correspondence problems. ", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "petrovich|featurerobust_optimal_transport_for_highdimensional_data", "supplementary_material": "/attachment/0587ff89918c2e09261523f5bee41868c2a5eac6.zip", "pdf": "/pdf/e3cd4ae10b6a27e4d902914fcb6f609f1c2f3de6.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=1Hx7jmwFJa", "_bibtex": "@misc{\npetrovich2021featurerobust,\ntitle={Feature-Robust Optimal Transport for High-Dimensional Data},\nauthor={Mathis Petrovich and Chao Liang and Ryoma Sato and Yanbin Liu and Yao-Hung Hubert Tsai and Linchao Zhu and Yi Yang and Ruslan Salakhutdinov and Makoto Yamada},\nyear={2021},\nurl={https://openreview.net/forum?id=zI38PZQHWKj}\n}"}, "signatures": ["ICLR.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference"], "details": {"replyCount": 9, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"reply": {"readers": {"values-regex": ".*"}, "writers": {"values": ["ICLR.cc/2021/Conference"]}, "signatures": {"values": ["ICLR.cc/2021/Conference"]}, "content": {"authors": {"values": ["Anonymous"]}, "authorids": {"values-regex": ".*"}, "reviewed_version_(pdf)": {"required": false, "description": "Upload a PDF file that ends with .pdf", "value-regex": ".*"}}}, "signatures": ["ICLR.cc/2021/Conference"], "readers": ["everyone"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["~", "OpenReview.net/Support"], "tcdate": 1601308008205, "tmdate": 1614984599368, "id": "ICLR.cc/2021/Conference/-/Blind_Submission"}}, "tauthor": "OpenReview.net"}, {"id": "s5sLmlmauUh", "original": null, "number": 1, "cdate": 1610040467006, "ddate": null, "tcdate": 1610040467006, "tmdate": 1610474070636, "tddate": null, "forum": "zI38PZQHWKj", "replyto": "zI38PZQHWKj", "invitation": "ICLR.cc/2021/Conference/Paper390/-/Decision", "content": {"title": "Final Decision", "decision": "Reject", "comment": "Motivated by (1) the problem of scaling up optimal transport to high-dimensional problems and (2) being able to tolerate noisy features, this paper introduces a new optimization problem that they call feature-robust optimal transport where they find a transport plan with discriminative features. They show that the min-max optimization problem admits a convex formulation and solve it using a Frank-Wolfe method. Finally they apply it to the layer selection problem and show that it achieves state-of-the-art performance for semantic correspondence datasets. \n\nThe reviews were mixed for this paper. The main negative, which was brought up in all the reviews, is the lack of novelty compared to earlier methods like SRW which already combine dimensionality reduction and optimal transport. The new method in this paper still does have value since it can scale up to larger dimensional problems. It would have been nice to have a wider range of experiments, which would present a more compelling case for its applicability. Another reviewer brought up a correctness issue, however it is not clear if this is actually a bug or merely a misunderstanding about how the pieces in the overall proof fit together. In any case, the reviewers pointed out various places where the writing could be improved. "}, "signatures": ["ICLR.cc/2021/Conference/Program_Chairs"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference/Program_Chairs"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Feature-Robust Optimal Transport for High-Dimensional Data", "authorids": ["mathis.petrovich@gmail.com", "cs.chaoliang@zju.edu.cn", "~Ryoma_Sato1", "~Yanbin_Liu1", "~Yao-Hung_Hubert_Tsai1", "~Linchao_Zhu1", "~Yi_Yang4", "~Ruslan_Salakhutdinov1", "~Makoto_Yamada3"], "authors": ["Mathis Petrovich", "Chao Liang", "Ryoma Sato", "Yanbin Liu", "Yao-Hung Hubert Tsai", "Linchao Zhu", "Yi Yang", "Ruslan Salakhutdinov", "Makoto Yamada"], "keywords": ["Optimal Transport", "feature selection", "semantic correspondence"], "abstract": "Optimal transport is a machine learning problem with applications including distribution comparison, feature selection, and generative adversarial networks. In this paper, we propose feature-robust optimal transport (FROT) for high-dimensional data, which solves high-dimensional OT problems using feature selection to avoid the curse of dimensionality. Specifically, we find a transport plan with discriminative features. To this end, we formulate the FROT problem as a min--max optimization problem. We then propose a convex formulation of the FROT problem and solve it using a Frank--Wolfe-based optimization algorithm, whereby the subproblem can be efficiently solved using the Sinkhorn algorithm. Since FROT finds the transport plan from selected features, it is robust to noise features. To show the effectiveness of FROT, we propose using the FROT algorithm for the layer selection problem in deep neural networks for semantic correspondence. By conducting synthetic and benchmark experiments, we demonstrate that the proposed method can find a strong correspondence by determining important layers. We show that the FROT algorithm achieves state-of-the-art performance in real-world semantic correspondence datasets.", "one-sentence_summary": "We propose an optimal transport method for high-dimensional data and applied it to semantic correspondence problems. ", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "petrovich|featurerobust_optimal_transport_for_highdimensional_data", "supplementary_material": "/attachment/0587ff89918c2e09261523f5bee41868c2a5eac6.zip", "pdf": "/pdf/e3cd4ae10b6a27e4d902914fcb6f609f1c2f3de6.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=1Hx7jmwFJa", "_bibtex": "@misc{\npetrovich2021featurerobust,\ntitle={Feature-Robust Optimal Transport for High-Dimensional Data},\nauthor={Mathis Petrovich and Chao Liang and Ryoma Sato and Yanbin Liu and Yao-Hung Hubert Tsai and Linchao Zhu and Yi Yang and Ruslan Salakhutdinov and Makoto Yamada},\nyear={2021},\nurl={https://openreview.net/forum?id=zI38PZQHWKj}\n}"}, "tags": [], "invitation": {"reply": {"forum": "zI38PZQHWKj", "replyto": "zI38PZQHWKj", "readers": {"values": ["everyone"]}, "writers": {"values": ["ICLR.cc/2021/Conference/Program_Chairs"]}, "signatures": {"values": ["ICLR.cc/2021/Conference/Program_Chairs"]}, "content": {"title": {"value": "Final Decision"}, "decision": {"value-radio": ["Accept (Oral)", "Accept (Spotlight)", "Accept (Poster)", "Reject"]}, "comment": {"value-regex": "[\\S\\s]{0,50000}", "markdown": true}}}, "multiReply": false, "signatures": ["ICLR.cc/2021/Conference"], "readers": ["everyone"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Program_Chairs"], "tcdate": 1610040466988, "tmdate": 1610474070620, "id": "ICLR.cc/2021/Conference/Paper390/-/Decision"}}}, {"id": "85VCwtROxIG", "original": null, "number": 2, "cdate": 1603693494588, "ddate": null, "tcdate": 1603693494588, "tmdate": 1606803152952, "tddate": null, "forum": "zI38PZQHWKj", "replyto": "zI38PZQHWKj", "invitation": "ICLR.cc/2021/Conference/Paper390/-/Official_Review", "content": {"title": "FROT -- feature-robust optimal transport", "review": "The proposed framework FROT - feature-robust optimal transport - seeks to select feature groups to both speed up OT computation for high-dimensional data and make it more robust to noise. The exposition is generally clear. My main concerns are limited novelty and lack of extensive experiments.\n\nThe paper draws the contrast between prior work SRW that yields a discriminative subspace via dimensionality reduction, and offers a dual perspective to use feature selection instead. A thorough discussion on the pros and cons of feature selection vs feature dimensionality reduction would add insight. \n\nTraditional entropy-regularized OT regularizes using the entropy of the transport plan $\\Pi$, whereas FROT regularizes using the probability distribution $\\alpha$. One expects a discussion on the effect of this choice.\n \nCurrently, the optimization for the group selection is done independently of optimization that produces the features, for instance by the choice of a pretrained network in the semantic correspondence application. It's worthwhile to explore joint optimization of feature generation and selection for downstream tasks.\n\nFor the claim of robustness to noise, experiments on data of dimension higher than 10 would be desirable.\n\nThere should be more extensive experiments applying FROT to more tasks and compared with additional baselines. Figure 3 compares the objective scores of FW-EMD, FW-Sinkhorn with that of exact OT, there are many other OT algorithms, such as tree-based methods, as referenced in the paper, that can be compared with. These plots should also include variations of the metric across trials. Similarly for the semantic correspondence results in Table 1. \n\nThank you authors for your response.", "rating": "4: Ok but not good enough - rejection", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["ICLR.cc/2021/Conference/Paper390/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper390/AnonReviewer3"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Feature-Robust Optimal Transport for High-Dimensional Data", "authorids": ["mathis.petrovich@gmail.com", "cs.chaoliang@zju.edu.cn", "~Ryoma_Sato1", "~Yanbin_Liu1", "~Yao-Hung_Hubert_Tsai1", "~Linchao_Zhu1", "~Yi_Yang4", "~Ruslan_Salakhutdinov1", "~Makoto_Yamada3"], "authors": ["Mathis Petrovich", "Chao Liang", "Ryoma Sato", "Yanbin Liu", "Yao-Hung Hubert Tsai", "Linchao Zhu", "Yi Yang", "Ruslan Salakhutdinov", "Makoto Yamada"], "keywords": ["Optimal Transport", "feature selection", "semantic correspondence"], "abstract": "Optimal transport is a machine learning problem with applications including distribution comparison, feature selection, and generative adversarial networks. In this paper, we propose feature-robust optimal transport (FROT) for high-dimensional data, which solves high-dimensional OT problems using feature selection to avoid the curse of dimensionality. Specifically, we find a transport plan with discriminative features. To this end, we formulate the FROT problem as a min--max optimization problem. We then propose a convex formulation of the FROT problem and solve it using a Frank--Wolfe-based optimization algorithm, whereby the subproblem can be efficiently solved using the Sinkhorn algorithm. Since FROT finds the transport plan from selected features, it is robust to noise features. To show the effectiveness of FROT, we propose using the FROT algorithm for the layer selection problem in deep neural networks for semantic correspondence. By conducting synthetic and benchmark experiments, we demonstrate that the proposed method can find a strong correspondence by determining important layers. We show that the FROT algorithm achieves state-of-the-art performance in real-world semantic correspondence datasets.", "one-sentence_summary": "We propose an optimal transport method for high-dimensional data and applied it to semantic correspondence problems. ", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "petrovich|featurerobust_optimal_transport_for_highdimensional_data", "supplementary_material": "/attachment/0587ff89918c2e09261523f5bee41868c2a5eac6.zip", "pdf": "/pdf/e3cd4ae10b6a27e4d902914fcb6f609f1c2f3de6.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=1Hx7jmwFJa", "_bibtex": "@misc{\npetrovich2021featurerobust,\ntitle={Feature-Robust Optimal Transport for High-Dimensional Data},\nauthor={Mathis Petrovich and Chao Liang and Ryoma Sato and Yanbin Liu and Yao-Hung Hubert Tsai and Linchao Zhu and Yi Yang and Ruslan Salakhutdinov and Makoto Yamada},\nyear={2021},\nurl={https://openreview.net/forum?id=zI38PZQHWKj}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq . ***Please remember to file the Code-of-Ethics report. Once you submitted the review, a link to the report will be visible in the bottom right corner of your review.***", "required": true, "markdown": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}, "forum": "zI38PZQHWKj", "replyto": "zI38PZQHWKj", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"], "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper390/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1607428800000, "duedate": 1606752000000, "multiReply": false, "readers": ["everyone"], "tcdate": 1602538144266, "tmdate": 1606915791239, "super": "ICLR.cc/2021/Conference/-/Official_Review", "signatures": ["OpenReview.net"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Paper390/Reviewers", "OpenReview.net/Support"], "id": "ICLR.cc/2021/Conference/Paper390/-/Official_Review"}}}, {"id": "eDnPxbSAV7n", "original": null, "number": 7, "cdate": 1605856173302, "ddate": null, "tcdate": 1605856173302, "tmdate": 1605856173302, "tddate": null, "forum": "zI38PZQHWKj", "replyto": "WoDWNNRyTm-", "invitation": "ICLR.cc/2021/Conference/Paper390/-/Official_Comment", "content": {"title": "Thank you for your feedback", "comment": "Thank you for your valuable comments.\n\n**Given SRW and other robust/min-max OT works, and multitude of feature-selection/group-lasso works, the novelty seems restricted. Even in terms of optimization, it seems a straight-forward application of FW. This seems to restrict the technical contribution.**\n\nWe agree that the formulation itself is similar to SRW. However, in our paper, our final goal is to solve the high-dimensional OT problems, where it has not been well studied. As clearly shown in the semantic correspondence experiments, SRW cannot directly be applied to such s high-dimensional data (d > 30,000). \n\nMoreover, we derive a new convex optimization problem Eq. (5). Thus, we believe the optimization researchers, who are in particular working for FW, can further improve and/or analyze the optimization of Eq. (5) by using newly developed FW methods. \n\n**In section 5.2, I am assuming for FROT, all layers were used as input; whereas for SRW, only few are used. Is this the case? If so, perhaps a case of FROT which uses exactly same input as SRW must be included for a fair comparison (along with the FROT with all layers). The authors do seem to agree that the improvement is more because of this skew in inputs. It is will nice to clarify this.**\n\nWe have added the experiments in Table 1 (blue). As you can see, FROT compares favorably with SRW with the same set of layers. Therefore, we expect that SRW can achieve similar results of FROT by increasing the number of layers. However, at this point, the training of SRW for ultra high-dimensional data (i.e., all layers with d > 30,000) is infeasible. \n\n**Why is that T is set in an adhoc manner? for example T=10 in synthetic and T=3 in real-world? why not fix or validate ? Also, convergence plots showing obj vs T as well as accuracy vs T might be insightful when included.**\n\n For the semantic correspondence tasks, since it converges with T=3, we simply set it to T = 3. For the revised manuscript, we have added T = 10 (See Table 1, red). As you can see, the performances of T = 3 and T = 10 are almost identical. \n\n**It may also be insightful to visually see some critical examples of image/pairs that highlight why FROT may work better than SRW etc. (more like fig5 in appendix)**\n\nWe added more empirical results in Figure 7 (supplementary)."}, "signatures": ["ICLR.cc/2021/Conference/Paper390/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper390/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Feature-Robust Optimal Transport for High-Dimensional Data", "authorids": ["mathis.petrovich@gmail.com", "cs.chaoliang@zju.edu.cn", "~Ryoma_Sato1", "~Yanbin_Liu1", "~Yao-Hung_Hubert_Tsai1", "~Linchao_Zhu1", "~Yi_Yang4", "~Ruslan_Salakhutdinov1", "~Makoto_Yamada3"], "authors": ["Mathis Petrovich", "Chao Liang", "Ryoma Sato", "Yanbin Liu", "Yao-Hung Hubert Tsai", "Linchao Zhu", "Yi Yang", "Ruslan Salakhutdinov", "Makoto Yamada"], "keywords": ["Optimal Transport", "feature selection", "semantic correspondence"], "abstract": "Optimal transport is a machine learning problem with applications including distribution comparison, feature selection, and generative adversarial networks. In this paper, we propose feature-robust optimal transport (FROT) for high-dimensional data, which solves high-dimensional OT problems using feature selection to avoid the curse of dimensionality. Specifically, we find a transport plan with discriminative features. To this end, we formulate the FROT problem as a min--max optimization problem. We then propose a convex formulation of the FROT problem and solve it using a Frank--Wolfe-based optimization algorithm, whereby the subproblem can be efficiently solved using the Sinkhorn algorithm. Since FROT finds the transport plan from selected features, it is robust to noise features. To show the effectiveness of FROT, we propose using the FROT algorithm for the layer selection problem in deep neural networks for semantic correspondence. By conducting synthetic and benchmark experiments, we demonstrate that the proposed method can find a strong correspondence by determining important layers. We show that the FROT algorithm achieves state-of-the-art performance in real-world semantic correspondence datasets.", "one-sentence_summary": "We propose an optimal transport method for high-dimensional data and applied it to semantic correspondence problems. ", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "petrovich|featurerobust_optimal_transport_for_highdimensional_data", "supplementary_material": "/attachment/0587ff89918c2e09261523f5bee41868c2a5eac6.zip", "pdf": "/pdf/e3cd4ae10b6a27e4d902914fcb6f609f1c2f3de6.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=1Hx7jmwFJa", "_bibtex": "@misc{\npetrovich2021featurerobust,\ntitle={Feature-Robust Optimal Transport for High-Dimensional Data},\nauthor={Mathis Petrovich and Chao Liang and Ryoma Sato and Yanbin Liu and Yao-Hung Hubert Tsai and Linchao Zhu and Yi Yang and Ruslan Salakhutdinov and Makoto Yamada},\nyear={2021},\nurl={https://openreview.net/forum?id=zI38PZQHWKj}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "zI38PZQHWKj", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper390/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper390/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper390/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper390/Authors|ICLR.cc/2021/Conference/Paper390/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper390/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923871511, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper390/-/Official_Comment"}}}, {"id": "P9uzEKblYX", "original": null, "number": 4, "cdate": 1605169410279, "ddate": null, "tcdate": 1605169410279, "tmdate": 1605836477201, "tddate": null, "forum": "zI38PZQHWKj", "replyto": "WddFG3GiRK", "invitation": "ICLR.cc/2021/Conference/Paper390/-/Official_Comment", "content": {"title": "We would like to correct your misunderstanding.", "comment": "(Improved the readability of reply)\n\nThank you for your time to review our paper. We will revise based on your comments. For now, we would like to correct your misunderstandings based on the current submission. \n\n**Section 3.1 is very confusing, and it seems to me that the authors fail to establish the correct convergence guarantee.**\n\nWe would like to correct your misunderstanding. First, our optimization methods (Frank-Wolfe and Linear programming)  is not a two-step approach. More specifically, we optimize Eq. (5) for Frank-Wolfe and it does not include alpha parameter optimization thanks to Lemma 2. Based on Proposition 3, we can show Eq. (5) is convex with respect to \\Pi, and thus we can directly use the Frank-Wolfe algorithm and its analysis (Frank & Wolfe, 1956; Jaggi, 2013),  \n\n**What are the other potential applications of FROT? While Semantic Correpondance is an interesting application, I find it hard to convince myself that FROT is better than Liu's 2020-CVPR work (requiring validation dataset is not a big problem - you can always to train-val split). With its similarity to group lasso, FROT might have more interesting applications.**\n\nThank you for the suggestion. We included the FROT using validation (Table 1 FROT(\\eta= 0.2,  \\epsilon= 0.4)). Using the validation set, we could get \\eta = 0.2 and \\epsilon = 0.4, respectively. For the semantic correspondence experiments, FROT got the state-of-the-art performance (34.7), while the current state-of-the-art is Liu\u2019s 2020-CVPR work (33.9). \n\nMoreover, due to the space limitation, we could not include the feature selection experiments in the main paper (it is in the supplementary material). For feature selection tasks, FROT compares favorably with Wasserstein distance-based feature selection algorithm in performance. Moreover, FROT is about two orders of magnitude faster than the Wasserstein distance and is also faster than Maximum Mean Discrepancy (MMD). We will include the feature selection experiments in the main paper. \n\nWe are considering using our method of biological data because the group lasso is heavily used in the biological domain. We believe this is an interesting direction.\n\n**Presentation of the introduction can be improved. I find it hard to parse the introduction until I almost finished reading the entire paper. Putting figure 1 to page 2 only creates more questions in my head instead of offering intuitions. Also, it would be helpful if the author can list their contributions in a more organized way.**\n\nThank you for your suggestion. We will include the contribution statement in the revised manuscript as follows.\n\n - We propose a feature robust optimal transport (FROT) problem and derive a simple and efficient Frank--Wolfe based algorithm. Furthermore, we propose a feature-robust Wasserstein distance (FRWD).\n- We apply FROT to a high-dimensional feature selection problem and show that FROT is consistent with the Wasserstein distance-based feature selection algorithm with less computational cost than the original algorithm.\n- We used FROT for the layer selection problem in a semantic correspondence problem and showed that the proposed algorithm outperforms existing baseline algorithms.\n\n**I didn't quite get the high dimensional part. While 'high-dimensional' appears in the abstract, introduction, and conclusion section, I didn't find the correspondence in the main text.**\n\nThe semantic correspondence data is indeed high-dimensional data. The dimension is d = 32, 576, while the number of samples for each image is a couple of hundred (i.e., d >> n).  Also, in the feature selection experiments in the supplementary material, we used high-dimensional data (see Table 2). \n\n**I didn't get the robust part, other than the empirical performance in the evaluation section.**\n\nIn Figure 1, we evaluated FROT and the OT (Cuturi 2013). FROT can get very similar transport plans (Figure 1(c))  to the one obtained by OT from clean data (Figure 1(a)), while OT with noisy data (Figure 1(b)) is different from the OT with clean data (Figure 1(a)). "}, "signatures": ["ICLR.cc/2021/Conference/Paper390/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper390/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Feature-Robust Optimal Transport for High-Dimensional Data", "authorids": ["mathis.petrovich@gmail.com", "cs.chaoliang@zju.edu.cn", "~Ryoma_Sato1", "~Yanbin_Liu1", "~Yao-Hung_Hubert_Tsai1", "~Linchao_Zhu1", "~Yi_Yang4", "~Ruslan_Salakhutdinov1", "~Makoto_Yamada3"], "authors": ["Mathis Petrovich", "Chao Liang", "Ryoma Sato", "Yanbin Liu", "Yao-Hung Hubert Tsai", "Linchao Zhu", "Yi Yang", "Ruslan Salakhutdinov", "Makoto Yamada"], "keywords": ["Optimal Transport", "feature selection", "semantic correspondence"], "abstract": "Optimal transport is a machine learning problem with applications including distribution comparison, feature selection, and generative adversarial networks. In this paper, we propose feature-robust optimal transport (FROT) for high-dimensional data, which solves high-dimensional OT problems using feature selection to avoid the curse of dimensionality. Specifically, we find a transport plan with discriminative features. To this end, we formulate the FROT problem as a min--max optimization problem. We then propose a convex formulation of the FROT problem and solve it using a Frank--Wolfe-based optimization algorithm, whereby the subproblem can be efficiently solved using the Sinkhorn algorithm. Since FROT finds the transport plan from selected features, it is robust to noise features. To show the effectiveness of FROT, we propose using the FROT algorithm for the layer selection problem in deep neural networks for semantic correspondence. By conducting synthetic and benchmark experiments, we demonstrate that the proposed method can find a strong correspondence by determining important layers. We show that the FROT algorithm achieves state-of-the-art performance in real-world semantic correspondence datasets.", "one-sentence_summary": "We propose an optimal transport method for high-dimensional data and applied it to semantic correspondence problems. ", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "petrovich|featurerobust_optimal_transport_for_highdimensional_data", "supplementary_material": "/attachment/0587ff89918c2e09261523f5bee41868c2a5eac6.zip", "pdf": "/pdf/e3cd4ae10b6a27e4d902914fcb6f609f1c2f3de6.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=1Hx7jmwFJa", "_bibtex": "@misc{\npetrovich2021featurerobust,\ntitle={Feature-Robust Optimal Transport for High-Dimensional Data},\nauthor={Mathis Petrovich and Chao Liang and Ryoma Sato and Yanbin Liu and Yao-Hung Hubert Tsai and Linchao Zhu and Yi Yang and Ruslan Salakhutdinov and Makoto Yamada},\nyear={2021},\nurl={https://openreview.net/forum?id=zI38PZQHWKj}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "zI38PZQHWKj", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper390/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper390/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper390/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper390/Authors|ICLR.cc/2021/Conference/Paper390/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper390/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923871511, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper390/-/Official_Comment"}}}, {"id": "-H_jma7KSCe", "original": null, "number": 6, "cdate": 1605772776341, "ddate": null, "tcdate": 1605772776341, "tmdate": 1605772776341, "tddate": null, "forum": "zI38PZQHWKj", "replyto": "LB9KCWXwzQh", "invitation": "ICLR.cc/2021/Conference/Paper390/-/Official_Comment", "content": {"title": "Thank you for your feedback!", "comment": "Thank you for your encouraging comments!\nWe have not compared the proposed algorithm to your algorithm. Thus, we are not sure whether your algorithm really suffers the convergence issue in practice. \n\nAccording to your ICML paper, \n\n\"Empirically, we observed that even the approximate solutions obtained by solving the entropy regularized formulation of the optimal transport problem ensure the convergence\u201d\n\nyour optimization technique also empirically works in practice. So, the empirical performance should not be that different from ours.\n\nNote that one of the advantages of the FW based algorithm proposed in our paper is that we can theoretically show the convergence of the algorithm using the regularized OT solvers. "}, "signatures": ["ICLR.cc/2021/Conference/Paper390/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper390/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Feature-Robust Optimal Transport for High-Dimensional Data", "authorids": ["mathis.petrovich@gmail.com", "cs.chaoliang@zju.edu.cn", "~Ryoma_Sato1", "~Yanbin_Liu1", "~Yao-Hung_Hubert_Tsai1", "~Linchao_Zhu1", "~Yi_Yang4", "~Ruslan_Salakhutdinov1", "~Makoto_Yamada3"], "authors": ["Mathis Petrovich", "Chao Liang", "Ryoma Sato", "Yanbin Liu", "Yao-Hung Hubert Tsai", "Linchao Zhu", "Yi Yang", "Ruslan Salakhutdinov", "Makoto Yamada"], "keywords": ["Optimal Transport", "feature selection", "semantic correspondence"], "abstract": "Optimal transport is a machine learning problem with applications including distribution comparison, feature selection, and generative adversarial networks. In this paper, we propose feature-robust optimal transport (FROT) for high-dimensional data, which solves high-dimensional OT problems using feature selection to avoid the curse of dimensionality. Specifically, we find a transport plan with discriminative features. To this end, we formulate the FROT problem as a min--max optimization problem. We then propose a convex formulation of the FROT problem and solve it using a Frank--Wolfe-based optimization algorithm, whereby the subproblem can be efficiently solved using the Sinkhorn algorithm. Since FROT finds the transport plan from selected features, it is robust to noise features. To show the effectiveness of FROT, we propose using the FROT algorithm for the layer selection problem in deep neural networks for semantic correspondence. By conducting synthetic and benchmark experiments, we demonstrate that the proposed method can find a strong correspondence by determining important layers. We show that the FROT algorithm achieves state-of-the-art performance in real-world semantic correspondence datasets.", "one-sentence_summary": "We propose an optimal transport method for high-dimensional data and applied it to semantic correspondence problems. ", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "petrovich|featurerobust_optimal_transport_for_highdimensional_data", "supplementary_material": "/attachment/0587ff89918c2e09261523f5bee41868c2a5eac6.zip", "pdf": "/pdf/e3cd4ae10b6a27e4d902914fcb6f609f1c2f3de6.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=1Hx7jmwFJa", "_bibtex": "@misc{\npetrovich2021featurerobust,\ntitle={Feature-Robust Optimal Transport for High-Dimensional Data},\nauthor={Mathis Petrovich and Chao Liang and Ryoma Sato and Yanbin Liu and Yao-Hung Hubert Tsai and Linchao Zhu and Yi Yang and Ruslan Salakhutdinov and Makoto Yamada},\nyear={2021},\nurl={https://openreview.net/forum?id=zI38PZQHWKj}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "zI38PZQHWKj", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper390/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper390/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper390/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper390/Authors|ICLR.cc/2021/Conference/Paper390/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper390/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923871511, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper390/-/Official_Comment"}}}, {"id": "LB9KCWXwzQh", "original": null, "number": 1, "cdate": 1605605344590, "ddate": null, "tcdate": 1605605344590, "tmdate": 1605605356390, "tddate": null, "forum": "zI38PZQHWKj", "replyto": "zI38PZQHWKj", "invitation": "ICLR.cc/2021/Conference/Paper390/-/Public_Comment", "content": {"title": "Clarification on Dhouib et al. ICML'20", "comment": "Great work! I have a question: when you say that our algorithm from Dhouib et al. ICML'20 may not converge for regularized optimal transport, do you mean the case where the transport matrix is initialized on the vertices? "}, "signatures": ["~Ievgen_Redko2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "~Ievgen_Redko2"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Feature-Robust Optimal Transport for High-Dimensional Data", "authorids": ["mathis.petrovich@gmail.com", "cs.chaoliang@zju.edu.cn", "~Ryoma_Sato1", "~Yanbin_Liu1", "~Yao-Hung_Hubert_Tsai1", "~Linchao_Zhu1", "~Yi_Yang4", "~Ruslan_Salakhutdinov1", "~Makoto_Yamada3"], "authors": ["Mathis Petrovich", "Chao Liang", "Ryoma Sato", "Yanbin Liu", "Yao-Hung Hubert Tsai", "Linchao Zhu", "Yi Yang", "Ruslan Salakhutdinov", "Makoto Yamada"], "keywords": ["Optimal Transport", "feature selection", "semantic correspondence"], "abstract": "Optimal transport is a machine learning problem with applications including distribution comparison, feature selection, and generative adversarial networks. In this paper, we propose feature-robust optimal transport (FROT) for high-dimensional data, which solves high-dimensional OT problems using feature selection to avoid the curse of dimensionality. Specifically, we find a transport plan with discriminative features. To this end, we formulate the FROT problem as a min--max optimization problem. We then propose a convex formulation of the FROT problem and solve it using a Frank--Wolfe-based optimization algorithm, whereby the subproblem can be efficiently solved using the Sinkhorn algorithm. Since FROT finds the transport plan from selected features, it is robust to noise features. To show the effectiveness of FROT, we propose using the FROT algorithm for the layer selection problem in deep neural networks for semantic correspondence. By conducting synthetic and benchmark experiments, we demonstrate that the proposed method can find a strong correspondence by determining important layers. We show that the FROT algorithm achieves state-of-the-art performance in real-world semantic correspondence datasets.", "one-sentence_summary": "We propose an optimal transport method for high-dimensional data and applied it to semantic correspondence problems. ", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "petrovich|featurerobust_optimal_transport_for_highdimensional_data", "supplementary_material": "/attachment/0587ff89918c2e09261523f5bee41868c2a5eac6.zip", "pdf": "/pdf/e3cd4ae10b6a27e4d902914fcb6f609f1c2f3de6.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=1Hx7jmwFJa", "_bibtex": "@misc{\npetrovich2021featurerobust,\ntitle={Feature-Robust Optimal Transport for High-Dimensional Data},\nauthor={Mathis Petrovich and Chao Liang and Ryoma Sato and Yanbin Liu and Yao-Hung Hubert Tsai and Linchao Zhu and Yi Yang and Ruslan Salakhutdinov and Makoto Yamada},\nyear={2021},\nurl={https://openreview.net/forum?id=zI38PZQHWKj}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "zI38PZQHWKj", "readers": {"description": "User groups that will be able to read this comment.", "values": ["everyone"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "~.*", "description": "How your identity will be displayed."}}, "expdate": 1605630600000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["everyone"], "noninvitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper390/Authors", "ICLR.cc/2021/Conference/Paper390/Reviewers", "ICLR.cc/2021/Conference/Paper390/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs"], "tcdate": 1605024982699, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper390/-/Public_Comment"}}}, {"id": "Rtj5ykMxdXi", "original": null, "number": 5, "cdate": 1605244606684, "ddate": null, "tcdate": 1605244606684, "tmdate": 1605244606684, "tddate": null, "forum": "zI38PZQHWKj", "replyto": "85VCwtROxIG", "invitation": "ICLR.cc/2021/Conference/Paper390/-/Official_Comment", "content": {"title": "Thank you for the review. ", "comment": "Thank you for your feedback.\n\n**Traditional entropy-regularized OT regularizes using the entropy of the transport plan \u03a0, whereas FROT regularizes using the probability distribution \u03b1. One expects a discussion on the effect of this choice.**\n\nIn our paper, we regularize both \\Pi and \\alpha. Specifically, if we regularize \\alpha and solve the optimization problem for \\alpha, we can get Eq. (5). To optimize Eq. (5), we can update the transport plan by solving linear programming (EMD) or Sinkhorn algorithm (regularized version).\n\n**Currently, the optimization for the group selection is done independently of optimization that produces the features, for instance by the choice of a pretrained network in the semantic correspondence application. It's worthwhile to explore joint optimization of feature generation and selection for downstream tasks.**\n\nThank you for your valuable feedback. Learning the network parameter would be an interesting idea. In this paper, we focus on proposing a new optimal transport method. And, the joint training of OT and DNN models is actually a new method and we would like to work on this direction as future work.\n\n**For the claim of robustness to noise, experiments on data of dimension higher than 10 would be desirable.**\n\nThe dimension of the semantic correspondence dataset is d = 32, 576 as described in the submitted paper. We will add more synthetic experiments.\n\n**There should be more extensive experiments applying FROT to more tasks and compared with additional baselines. Figure 3 compares the objective scores of FW-EMD, FW-Sinkhorn with that of exact OT, there are many other OT algorithms, such as tree-based methods, as referenced in the paper, that can be compared with. These plots should also include variations of the metric across trials. Similarly for the semantic correspondence results in Table 1.**\n\nWe would like to emphasize that the Sinkhorn algorithm (Liu CVPR 2020) is a state-of-the-art method for the semantic corresponding task, and the SRW variant is also not reported anywhere.  Moreover, to our knowledge, the state-of-the-art Robust OT method is SRW and could not find any Robust counterparts at the time of submission. Note that the tree-Wasserstein is a method for computing the Wasserstein distance on tree, and it can compute the Wasserstein distance in linear time. However, it is not a robust OT method and the performance of tree-Wasserstein is in general comparable to OT with Sinkhorn algorithm. Of course, if the main contribution is the computational time, we should compare FROT with the tree-Wasserstein. However, this is out of the scope of our paper. \n"}, "signatures": ["ICLR.cc/2021/Conference/Paper390/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper390/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Feature-Robust Optimal Transport for High-Dimensional Data", "authorids": ["mathis.petrovich@gmail.com", "cs.chaoliang@zju.edu.cn", "~Ryoma_Sato1", "~Yanbin_Liu1", "~Yao-Hung_Hubert_Tsai1", "~Linchao_Zhu1", "~Yi_Yang4", "~Ruslan_Salakhutdinov1", "~Makoto_Yamada3"], "authors": ["Mathis Petrovich", "Chao Liang", "Ryoma Sato", "Yanbin Liu", "Yao-Hung Hubert Tsai", "Linchao Zhu", "Yi Yang", "Ruslan Salakhutdinov", "Makoto Yamada"], "keywords": ["Optimal Transport", "feature selection", "semantic correspondence"], "abstract": "Optimal transport is a machine learning problem with applications including distribution comparison, feature selection, and generative adversarial networks. In this paper, we propose feature-robust optimal transport (FROT) for high-dimensional data, which solves high-dimensional OT problems using feature selection to avoid the curse of dimensionality. Specifically, we find a transport plan with discriminative features. To this end, we formulate the FROT problem as a min--max optimization problem. We then propose a convex formulation of the FROT problem and solve it using a Frank--Wolfe-based optimization algorithm, whereby the subproblem can be efficiently solved using the Sinkhorn algorithm. Since FROT finds the transport plan from selected features, it is robust to noise features. To show the effectiveness of FROT, we propose using the FROT algorithm for the layer selection problem in deep neural networks for semantic correspondence. By conducting synthetic and benchmark experiments, we demonstrate that the proposed method can find a strong correspondence by determining important layers. We show that the FROT algorithm achieves state-of-the-art performance in real-world semantic correspondence datasets.", "one-sentence_summary": "We propose an optimal transport method for high-dimensional data and applied it to semantic correspondence problems. ", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "petrovich|featurerobust_optimal_transport_for_highdimensional_data", "supplementary_material": "/attachment/0587ff89918c2e09261523f5bee41868c2a5eac6.zip", "pdf": "/pdf/e3cd4ae10b6a27e4d902914fcb6f609f1c2f3de6.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=1Hx7jmwFJa", "_bibtex": "@misc{\npetrovich2021featurerobust,\ntitle={Feature-Robust Optimal Transport for High-Dimensional Data},\nauthor={Mathis Petrovich and Chao Liang and Ryoma Sato and Yanbin Liu and Yao-Hung Hubert Tsai and Linchao Zhu and Yi Yang and Ruslan Salakhutdinov and Makoto Yamada},\nyear={2021},\nurl={https://openreview.net/forum?id=zI38PZQHWKj}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "zI38PZQHWKj", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper390/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper390/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper390/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper390/Authors|ICLR.cc/2021/Conference/Paper390/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper390/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923871511, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper390/-/Official_Comment"}}}, {"id": "WddFG3GiRK", "original": null, "number": 1, "cdate": 1603522946689, "ddate": null, "tcdate": 1603522946689, "tmdate": 1605024700272, "tddate": null, "forum": "zI38PZQHWKj", "replyto": "zI38PZQHWKj", "invitation": "ICLR.cc/2021/Conference/Paper390/-/Official_Review", "content": {"title": "FROT is interesting but the analysis is suspicious", "review": "*Summary*:\nThe authors try to solve a special kind of high-dimensional optimal transport problem. Specifically, they consider the cases when features are grouped and the grouping is known a-priori. The authors formulate the problem into the feature-robust optimal transport (FROT) problem.\nThe authors propose two solving algorithms, one based on the Frank-Wolfe method, and one based on linear programming.\n\n*Pros*:\nThe connection to the feature group sounds interesting to me, as it has a natural connection to the structure of deep learning models.\nThe presentation (other than the introduction) is easy to follow.\n\n*Cons*:\nNote that the first point is the main contributing factor for my rating.\n\n1. Section 3.1 is very confusing, and it seems to me that the authors fail to establish the correct convergence guarantee.\nAs in page 4, the target is $min_{\\pi} max_{\\alpha} J(\\Pi, \\alpha)$ \nIf we fix $\\pi$, we can solve for the optimal $\\alpha$. Plug this optimal $\\alpha$ back in and we obtain $G(\\Pi)$.\nIntuitively one may choose to solve for $\\alpha$ and $\\pi$ alternatingly.\nHowever the convergence of $G(\\Pi)$ says nothing more than, in a fixed iteration, one can solve exactly for the optimal $\\alpha$ and up to $\\epsilon$ accuracy for $\\Pi$.\nWe still don't know if the solution of the algorithm indeed minimizes the said loss.\nI checked the proof of proposition 4. It just invokes the standard FW-convergence analysis from Jaggi 2013, and argue nothing about the alternative part. Note that, even though the two subproblems (for $\\alpha$ and for $\\pi$) can be solved almost exactly, it could be non-trivial to set up the convergence of the entire alternating algorithm.\nAlternatively, maybe the authors want to argue that solving $min_{\\pi} max_{\\alpha} J(\\Pi, \\alpha)$ is equivalent to solving $\\max_{\\pi} G(\\Pi)$. However, this is also not obviously true for me.\n\n2.  What are the other potential applications of FROT? While Semantic Correpondance is an interesting application, I find it hard to convince myself that FROT is better than Liu's 2020-CVPR work (requiring validation dataset is not a big problem - you can always to train-val split). With its similarity to group lasso, FROT might have more interesting applications.\n\n3. Presentation of the introduction can be improved. I find it hard to parse the introduction until I almost finished reading the entire paper. Putting figure 1 to page 2 only creates more questions in my head instead of offering intuitions. Also, it would be helpful if the author can list their contributions in a more organized way.\n\n4. I didn't quite get the high dimensional part. While 'high-dimensional' appears in the abstract, introduction, and conclusion section, I didn't find the correspondence in the main text.\n\n5. I didn't get the robust part, other than the empirical performance in the evaluation section.\n", "rating": "3: Clear rejection", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "signatures": ["ICLR.cc/2021/Conference/Paper390/AnonReviewer4"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper390/AnonReviewer4"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Feature-Robust Optimal Transport for High-Dimensional Data", "authorids": ["mathis.petrovich@gmail.com", "cs.chaoliang@zju.edu.cn", "~Ryoma_Sato1", "~Yanbin_Liu1", "~Yao-Hung_Hubert_Tsai1", "~Linchao_Zhu1", "~Yi_Yang4", "~Ruslan_Salakhutdinov1", "~Makoto_Yamada3"], "authors": ["Mathis Petrovich", "Chao Liang", "Ryoma Sato", "Yanbin Liu", "Yao-Hung Hubert Tsai", "Linchao Zhu", "Yi Yang", "Ruslan Salakhutdinov", "Makoto Yamada"], "keywords": ["Optimal Transport", "feature selection", "semantic correspondence"], "abstract": "Optimal transport is a machine learning problem with applications including distribution comparison, feature selection, and generative adversarial networks. In this paper, we propose feature-robust optimal transport (FROT) for high-dimensional data, which solves high-dimensional OT problems using feature selection to avoid the curse of dimensionality. Specifically, we find a transport plan with discriminative features. To this end, we formulate the FROT problem as a min--max optimization problem. We then propose a convex formulation of the FROT problem and solve it using a Frank--Wolfe-based optimization algorithm, whereby the subproblem can be efficiently solved using the Sinkhorn algorithm. Since FROT finds the transport plan from selected features, it is robust to noise features. To show the effectiveness of FROT, we propose using the FROT algorithm for the layer selection problem in deep neural networks for semantic correspondence. By conducting synthetic and benchmark experiments, we demonstrate that the proposed method can find a strong correspondence by determining important layers. We show that the FROT algorithm achieves state-of-the-art performance in real-world semantic correspondence datasets.", "one-sentence_summary": "We propose an optimal transport method for high-dimensional data and applied it to semantic correspondence problems. ", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "petrovich|featurerobust_optimal_transport_for_highdimensional_data", "supplementary_material": "/attachment/0587ff89918c2e09261523f5bee41868c2a5eac6.zip", "pdf": "/pdf/e3cd4ae10b6a27e4d902914fcb6f609f1c2f3de6.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=1Hx7jmwFJa", "_bibtex": "@misc{\npetrovich2021featurerobust,\ntitle={Feature-Robust Optimal Transport for High-Dimensional Data},\nauthor={Mathis Petrovich and Chao Liang and Ryoma Sato and Yanbin Liu and Yao-Hung Hubert Tsai and Linchao Zhu and Yi Yang and Ruslan Salakhutdinov and Makoto Yamada},\nyear={2021},\nurl={https://openreview.net/forum?id=zI38PZQHWKj}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq . ***Please remember to file the Code-of-Ethics report. Once you submitted the review, a link to the report will be visible in the bottom right corner of your review.***", "required": true, "markdown": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}, "forum": "zI38PZQHWKj", "replyto": "zI38PZQHWKj", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"], "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper390/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1607428800000, "duedate": 1606752000000, "multiReply": false, "readers": ["everyone"], "tcdate": 1602538144266, "tmdate": 1606915791239, "super": "ICLR.cc/2021/Conference/-/Official_Review", "signatures": ["OpenReview.net"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Paper390/Reviewers", "OpenReview.net/Support"], "id": "ICLR.cc/2021/Conference/Paper390/-/Official_Review"}}}, {"id": "WoDWNNRyTm-", "original": null, "number": 3, "cdate": 1603869877854, "ddate": null, "tcdate": 1603869877854, "tmdate": 1605024700156, "tddate": null, "forum": "zI38PZQHWKj", "replyto": "zI38PZQHWKj", "invitation": "ICLR.cc/2021/Conference/Paper390/-/Official_Review", "content": {"title": "Seems a bit incremental in terms of novelty and contribution, but well-written overall.", "review": "This work proposes variants of robust OT/p-wasserstein-dist (3)/(4), where the ground cost is in some sense the maximum over costs with (prefixed) groups of features. The motivation is similar to that for feature selection: where perhaps only few of these groups of features are critical/sufficient for OT purposes. So it can also be understood as joint feature-group selection with OT. The resulting convex problem is proposed to be solved using FW, whose details are presented (including convergence).\n\nPros:\n1. Though similar in spirit to SRW, the proposed formulation has few advantages: a) allows any cost, b) convex c) FW leads to scalable solver etc.\n2. Overall, the paper is very well-written, with nice organization and sufficient details.\n\nCons:\n1. Pre-fixed groups, more importantly, non-overlapping groups seems restrictive, especially because feature selection with overlapping groups is well-studied. (e.g., https://hal.inria.fr/inria-00628498/document , https://papers.nips.cc/paper/4275-efficient-methods-for-overlapping-group-lasso.pdf ) among others.\n\nMajor Comments:\n1. Given SRW and other robust/min-max OT works, and multitude of feature-selection/group-lasso works, the novelty seems restricted. Even in terms of optimization, it seems a straight-forward application of FW. This seems to restrict the technical contribution. \n2. In section 5.2, I am assuming for FROT, all layers were used as input; whereas for SRW, only few are used. Is this the case? If so, perhaps a case of FROT which uses exactly same input as SRW must be included for a fair comparison (along with the FROT with all layers). The authors do seem to agree that the improvement is more because of this skew in inputs. It is will nice to clarify this.\n3. Why is that T is set in an adhoc manner? for example T=10 in synthetic and T=3 in real-world? why not fix or validate ? Also, convergence plots showing obj vs T as well as accuracy vs T might be insightful when included.\n4. It may also be insightful to visually see some critical examples of image/pairs that highlight why FROT may work better than SRW etc. (more like fig5 in appendix)", "rating": "6: Marginally above acceptance threshold", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["ICLR.cc/2021/Conference/Paper390/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper390/AnonReviewer2"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Feature-Robust Optimal Transport for High-Dimensional Data", "authorids": ["mathis.petrovich@gmail.com", "cs.chaoliang@zju.edu.cn", "~Ryoma_Sato1", "~Yanbin_Liu1", "~Yao-Hung_Hubert_Tsai1", "~Linchao_Zhu1", "~Yi_Yang4", "~Ruslan_Salakhutdinov1", "~Makoto_Yamada3"], "authors": ["Mathis Petrovich", "Chao Liang", "Ryoma Sato", "Yanbin Liu", "Yao-Hung Hubert Tsai", "Linchao Zhu", "Yi Yang", "Ruslan Salakhutdinov", "Makoto Yamada"], "keywords": ["Optimal Transport", "feature selection", "semantic correspondence"], "abstract": "Optimal transport is a machine learning problem with applications including distribution comparison, feature selection, and generative adversarial networks. In this paper, we propose feature-robust optimal transport (FROT) for high-dimensional data, which solves high-dimensional OT problems using feature selection to avoid the curse of dimensionality. Specifically, we find a transport plan with discriminative features. To this end, we formulate the FROT problem as a min--max optimization problem. We then propose a convex formulation of the FROT problem and solve it using a Frank--Wolfe-based optimization algorithm, whereby the subproblem can be efficiently solved using the Sinkhorn algorithm. Since FROT finds the transport plan from selected features, it is robust to noise features. To show the effectiveness of FROT, we propose using the FROT algorithm for the layer selection problem in deep neural networks for semantic correspondence. By conducting synthetic and benchmark experiments, we demonstrate that the proposed method can find a strong correspondence by determining important layers. We show that the FROT algorithm achieves state-of-the-art performance in real-world semantic correspondence datasets.", "one-sentence_summary": "We propose an optimal transport method for high-dimensional data and applied it to semantic correspondence problems. ", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "petrovich|featurerobust_optimal_transport_for_highdimensional_data", "supplementary_material": "/attachment/0587ff89918c2e09261523f5bee41868c2a5eac6.zip", "pdf": "/pdf/e3cd4ae10b6a27e4d902914fcb6f609f1c2f3de6.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=1Hx7jmwFJa", "_bibtex": "@misc{\npetrovich2021featurerobust,\ntitle={Feature-Robust Optimal Transport for High-Dimensional Data},\nauthor={Mathis Petrovich and Chao Liang and Ryoma Sato and Yanbin Liu and Yao-Hung Hubert Tsai and Linchao Zhu and Yi Yang and Ruslan Salakhutdinov and Makoto Yamada},\nyear={2021},\nurl={https://openreview.net/forum?id=zI38PZQHWKj}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq . ***Please remember to file the Code-of-Ethics report. Once you submitted the review, a link to the report will be visible in the bottom right corner of your review.***", "required": true, "markdown": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}, "forum": "zI38PZQHWKj", "replyto": "zI38PZQHWKj", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"], "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper390/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1607428800000, "duedate": 1606752000000, "multiReply": false, "readers": ["everyone"], "tcdate": 1602538144266, "tmdate": 1606915791239, "super": "ICLR.cc/2021/Conference/-/Official_Review", "signatures": ["OpenReview.net"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Paper390/Reviewers", "OpenReview.net/Support"], "id": "ICLR.cc/2021/Conference/Paper390/-/Official_Review"}}}], "count": 10}