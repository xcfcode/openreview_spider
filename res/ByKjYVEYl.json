{"notes": [{"tddate": null, "ddate": null, "cdate": null, "original": null, "tmdate": 1490028581619, "tcdate": 1490028581619, "number": 1, "id": "Hk0QuY6je", "invitation": "ICLR.cc/2017/workshop/-/paper71/acceptance", "forum": "ByKjYVEYl", "replyto": "ByKjYVEYl", "signatures": ["ICLR.cc/2017/pcs"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/pcs"], "content": {"decision": "Reject", "title": "ICLR committee final decision"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Weak Adversarial Boosting", "abstract": "The \"adversarial training\" methods have recently been emerging as a promising avenue of research. Broadly speaking these methods achieve efficient training as well as boosted performance via an adversarial choice of data, features, or models. However, since the inception of the Generative Adversarial Nets (GAN),\nmuch of the attention is focussed on adversarial \"models\", i.e., machines learning by pursuing competing goals. \nIn this note we investigate the\neffectiveness of several (weak) sources of adversarial \"data\" and \"features\".  In particular we demonstrate:\n(a) low precision classifiers can be used as a source of adversarial data-sample closer to the decision boundary\n(b) training on these adversarial data-sample  can give significant boost to the precision and recall compared to the non-adversarial sample.\nWe also document the use of these methods for improving the performance of classifiers when only limited (and sometimes no) labeled data is available.", "pdf": "/pdf/26910c48736a0753226f5245608c05f5c8d4f367.pdf", "TL;DR": "Training on adversarial data generated via low-precision classifiers can boost performance with only small labeled data.", "paperhash": "deepakreddy|weak_adversarial_boosting", "keywords": ["Semi-Supervised Learning"], "conflicts": ["-"], "authors": ["Sreekalyan Deepakreddy", "Raghav Kulkarni"], "authorids": ["ssajjala@linkedin.com", "kulraghav@gmail.com"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "tmdate": 1490028582133, "id": "ICLR.cc/2017/workshop/-/paper71/acceptance", "writers": ["ICLR.cc/2017/workshop"], "signatures": ["ICLR.cc/2017/workshop"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/pcs"], "noninvitees": ["ICLR.cc/2017/pcs"], "reply": {"forum": "ByKjYVEYl", "replyto": "ByKjYVEYl", "writers": {"values-regex": "ICLR.cc/2017/pcs"}, "signatures": {"values-regex": "ICLR.cc/2017/pcs", "description": "Your displayed identity associated with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your decision.", "value": "ICLR committee final decision"}, "decision": {"required": true, "order": 3, "value-radio": ["Accept", "Reject"]}}}, "nonreaders": [], "cdate": 1490028582133}}}, {"tddate": null, "tmdate": 1489381384140, "tcdate": 1489381384140, "number": 2, "id": "ryxMdi7oe", "invitation": "ICLR.cc/2017/workshop/-/paper71/official/review", "forum": "ByKjYVEYl", "replyto": "ByKjYVEYl", "signatures": ["ICLR.cc/2017/workshop/paper71/AnonReviewer1"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/workshop/paper71/AnonReviewer1"], "content": {"title": "Confusing description of methods and insufficient experiments", "rating": "2: Strong rejection", "review": "This work proposes using a weak classifier to produce data to augment a supervised classifier. The way it does is poorly explained and seems similar to existing work on hard negative mining.\n\nIn section 3.1, does 'randomly sample outside B' mean sampling from A - B? Does A \u2229 B mean the set of examples which were positively labeled by A and B? If this is the case I don't see how that would raise the precision of B to that of A, especially since the negatives that are being used to train B come from the positive set of A. This method of training seems very close to that described in section 3.2.\n\nIn particular in section 3.2, it is very unclear why using A \u2229 B as the positive labels would increase the recall of B. Using the intersection would reduce the number of positive labels and seems like it would reduce the recall compared to the original.\n\nThe experimental results are also very weak. There is no description of 'correlated classifier' and no clear definition of what it means to be correlated. The authors also describe training on a random 1000 samples but 1000 samples of what? Since there are only 1000 labels, what are the results of training directly on the 1000 labeled examples? Are the 1000 positives from the low-precision classifier just examples from unlabelled data?\n\nI also wouldn't describe these techniques as 'adversarial'. Adversarial is normally taken to mean something which intentionally exploits a weakness of the model. None of the described methods intentionally exploit any weakness.\n\n", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Weak Adversarial Boosting", "abstract": "The \"adversarial training\" methods have recently been emerging as a promising avenue of research. Broadly speaking these methods achieve efficient training as well as boosted performance via an adversarial choice of data, features, or models. However, since the inception of the Generative Adversarial Nets (GAN),\nmuch of the attention is focussed on adversarial \"models\", i.e., machines learning by pursuing competing goals. \nIn this note we investigate the\neffectiveness of several (weak) sources of adversarial \"data\" and \"features\".  In particular we demonstrate:\n(a) low precision classifiers can be used as a source of adversarial data-sample closer to the decision boundary\n(b) training on these adversarial data-sample  can give significant boost to the precision and recall compared to the non-adversarial sample.\nWe also document the use of these methods for improving the performance of classifiers when only limited (and sometimes no) labeled data is available.", "pdf": "/pdf/26910c48736a0753226f5245608c05f5c8d4f367.pdf", "TL;DR": "Training on adversarial data generated via low-precision classifiers can boost performance with only small labeled data.", "paperhash": "deepakreddy|weak_adversarial_boosting", "keywords": ["Semi-Supervised Learning"], "conflicts": ["-"], "authors": ["Sreekalyan Deepakreddy", "Raghav Kulkarni"], "authorids": ["ssajjala@linkedin.com", "kulraghav@gmail.com"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1489183200000, "tmdate": 1489381384873, "id": "ICLR.cc/2017/workshop/-/paper71/official/review", "writers": ["ICLR.cc/2017/workshop"], "signatures": ["ICLR.cc/2017/workshop"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/workshop/paper71/reviewers"], "noninvitees": ["ICLR.cc/2017/workshop/paper71/AnonReviewer2", "ICLR.cc/2017/workshop/paper71/AnonReviewer1"], "reply": {"forum": "ByKjYVEYl", "replyto": "ByKjYVEYl", "writers": {"values-regex": "ICLR.cc/2017/workshop/paper71/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/workshop/paper71/AnonReviewer[0-9]+"}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "value-regex": "[\\S\\s]{1,5000}"}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1496959200000, "cdate": 1489381384873}}}, {"tddate": null, "tmdate": 1488234150730, "tcdate": 1488234150730, "number": 1, "id": "HJ1hUXMcx", "invitation": "ICLR.cc/2017/workshop/-/paper71/official/review", "forum": "ByKjYVEYl", "replyto": "ByKjYVEYl", "signatures": ["ICLR.cc/2017/workshop/paper71/AnonReviewer2"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/workshop/paper71/AnonReviewer2"], "content": {"title": "Official review For Weak Adversarial Boosting", "rating": "2: Strong rejection", "review": "The authors describe recent work where employing adversarial sample data can give significant improvement.\n\nThe authors work is not a generative adversarial network (GAN) nor training with adversarial examples, hence I would have difficulty labeling this paper as 'weak adversarial boosting'. In particular, note that adversarial examples are examples generated via gradient propagation in the model that perceptually indistinguishable to humans but are misclassified by the machine learning system. The data the authors describe are instead more like 'hard negatives' as humans judge that the algorithm incorrectly classified these examples.\n\nThe authors show that by employing these hard negatives and committee of experts they could improve the quality of the classifier. Both techniques of employing hard negatives and a committee of classifiers are known to be useful for training all sorts of machine learning systems and I do not see what is new in this work.\n\nAdditional issues:\n- Authors have almost no references to prior work including but not limited to GAN's, adversarial examples, boosting, security issues, hard negative mining.\n- Results based on non-publicly available data so not reproducible.\n- Results are minimal on one data set and two experiments. ", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Weak Adversarial Boosting", "abstract": "The \"adversarial training\" methods have recently been emerging as a promising avenue of research. Broadly speaking these methods achieve efficient training as well as boosted performance via an adversarial choice of data, features, or models. However, since the inception of the Generative Adversarial Nets (GAN),\nmuch of the attention is focussed on adversarial \"models\", i.e., machines learning by pursuing competing goals. \nIn this note we investigate the\neffectiveness of several (weak) sources of adversarial \"data\" and \"features\".  In particular we demonstrate:\n(a) low precision classifiers can be used as a source of adversarial data-sample closer to the decision boundary\n(b) training on these adversarial data-sample  can give significant boost to the precision and recall compared to the non-adversarial sample.\nWe also document the use of these methods for improving the performance of classifiers when only limited (and sometimes no) labeled data is available.", "pdf": "/pdf/26910c48736a0753226f5245608c05f5c8d4f367.pdf", "TL;DR": "Training on adversarial data generated via low-precision classifiers can boost performance with only small labeled data.", "paperhash": "deepakreddy|weak_adversarial_boosting", "keywords": ["Semi-Supervised Learning"], "conflicts": ["-"], "authors": ["Sreekalyan Deepakreddy", "Raghav Kulkarni"], "authorids": ["ssajjala@linkedin.com", "kulraghav@gmail.com"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1489183200000, "tmdate": 1489381384873, "id": "ICLR.cc/2017/workshop/-/paper71/official/review", "writers": ["ICLR.cc/2017/workshop"], "signatures": ["ICLR.cc/2017/workshop"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/workshop/paper71/reviewers"], "noninvitees": ["ICLR.cc/2017/workshop/paper71/AnonReviewer2", "ICLR.cc/2017/workshop/paper71/AnonReviewer1"], "reply": {"forum": "ByKjYVEYl", "replyto": "ByKjYVEYl", "writers": {"values-regex": "ICLR.cc/2017/workshop/paper71/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/workshop/paper71/AnonReviewer[0-9]+"}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "value-regex": "[\\S\\s]{1,5000}"}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1496959200000, "cdate": 1489381384873}}}, {"tddate": null, "replyto": null, "ddate": null, "tmdate": 1487321505104, "tcdate": 1487321505104, "number": 71, "id": "ByKjYVEYl", "invitation": "ICLR.cc/2017/workshop/-/submission", "forum": "ByKjYVEYl", "signatures": ["~Raghav_Kulkarni1"], "readers": ["everyone"], "content": {"title": "Weak Adversarial Boosting", "abstract": "The \"adversarial training\" methods have recently been emerging as a promising avenue of research. Broadly speaking these methods achieve efficient training as well as boosted performance via an adversarial choice of data, features, or models. However, since the inception of the Generative Adversarial Nets (GAN),\nmuch of the attention is focussed on adversarial \"models\", i.e., machines learning by pursuing competing goals. \nIn this note we investigate the\neffectiveness of several (weak) sources of adversarial \"data\" and \"features\".  In particular we demonstrate:\n(a) low precision classifiers can be used as a source of adversarial data-sample closer to the decision boundary\n(b) training on these adversarial data-sample  can give significant boost to the precision and recall compared to the non-adversarial sample.\nWe also document the use of these methods for improving the performance of classifiers when only limited (and sometimes no) labeled data is available.", "pdf": "/pdf/26910c48736a0753226f5245608c05f5c8d4f367.pdf", "TL;DR": "Training on adversarial data generated via low-precision classifiers can boost performance with only small labeled data.", "paperhash": "deepakreddy|weak_adversarial_boosting", "keywords": ["Semi-Supervised Learning"], "conflicts": ["-"], "authors": ["Sreekalyan Deepakreddy", "Raghav Kulkarni"], "authorids": ["ssajjala@linkedin.com", "kulraghav@gmail.com"]}, "writers": [], "nonreaders": [], "details": {"replyCount": 3, "writable": false, "overwriting": [], "revisions": false, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1487690420000, "tmdate": 1484242559574, "id": "ICLR.cc/2017/workshop/-/submission", "writers": ["ICLR.cc/2017/workshop"], "signatures": ["ICLR.cc/2017/pcs"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": null, "replyto": null, "writers": {"values-regex": "~.*"}, "signatures": {"values-regex": "~.*", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"pdf": {"required": true, "order": 5, "description": "Either upload a PDF file or provide a direct link to your PDF on ArXiv (link must begin with http(s) and end with .pdf)", "value-regex": "upload|(http|https):\\/\\/.+\\.pdf"}, "title": {"required": true, "order": 1, "description": "Title of paper.", "value-regex": ".{1,250}"}, "abstract": {"required": true, "order": 4, "description": "Abstract of paper.", "value-regex": "[\\S\\s]{1,5000}"}, "authors": {"required": true, "order": 2, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of author names, as they appear in the paper."}, "conflicts": {"required": true, "order": 100, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of email domains of people who would have a conflict of interest in reviewing this paper, (e.g., cs.umass.edu;google.com, etc.)."}, "keywords": {"order": 6, "description": "Comma separated list of keywords.", "values-dropdown": ["Theory", "Computer vision", "Speech", "Natural language processing", "Deep learning", "Unsupervised Learning", "Supervised Learning", "Semi-Supervised Learning", "Reinforcement Learning", "Transfer Learning", "Multi-modal learning", "Applications", "Optimization", "Structured prediction", "Games"]}, "TL;DR": {"required": false, "order": 3, "description": "\"Too Long; Didn't Read\": a short sentence describing your paper", "value-regex": "[^\\n]{0,250}"}, "authorids": {"required": true, "order": 3, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of author email addresses, in the same order as above."}}}, "nonreaders": [], "noninvitees": [], "expdate": 1495466420000, "cdate": 1484242559574}}}], "count": 4}