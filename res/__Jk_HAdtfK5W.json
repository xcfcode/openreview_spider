{"notes": [{"ddate": null, "legacy_migration": true, "tmdate": 1392130020000, "tcdate": 1392130020000, "number": 4, "id": "55DTZ7VOi9sAR", "invitation": "ICLR.cc/2014/-/submission/conference/review", "forum": "__Jk_HAdtfK5W", "replyto": "__Jk_HAdtfK5W", "signatures": ["kishore reddy"], "readers": ["everyone"], "writers": ["anonymous"], "content": {"title": "", "review": "We thank all the reviewers for their valuable comments. We uploaded a new version of the paper with some of the suggested modifications."}, "nonreaders": [], "details": {"replyCount": 0, "overwriting": [], "revisions": false, "forumContent": {"title": "Learning to encode motion using spatio-temporal synchrony", "decision": "submitted, no decision", "abstract": "We consider the task of learning to extract motion from videos. To this end, we show that the detection of spatial transformations can be viewed as the detection of synchrony between the image sequence and a sequence of features undergoing the motion we wish to detect. We show that learning about synchrony is possible using very fast, local learning rules, by introducing multiplicative 'gating' interactions between hidden units across frames. This makes it possible to achieve competitive performance in a wide variety of motion estimation tasks, using a small fraction of the time required to learn features, and to outperform hand-crafted spatio-temporal features by a large margin. We also show how learning about synchrony can be viewed as performing greedy parameter estimation in the well-known motion energy model.", "pdf": "https://arxiv.org/abs/1306.3162", "paperhash": "konda|learning_to_encode_motion_using_spatiotemporal_synchrony", "keywords": [], "conflicts": [], "authors": ["Kishore Reddy Konda", "Roland Memisevic", "Vincent Michalski"], "authorids": ["konda@informatik.uni-frankfurt.de", "roland.memisevic@gmail.com", "vmichals@rz.uni-frankfurt.de"]}, "tags": [], "invitation": {}}}, {"ddate": null, "legacy_migration": true, "tmdate": 1392129720000, "tcdate": 1392129720000, "number": 1, "id": "6m_xmeudQa47M", "invitation": "ICLR.cc/2014/-/submission/conference/reply", "forum": "__Jk_HAdtfK5W", "replyto": "nOAHIb1E0y2d-", "signatures": ["kishore reddy"], "readers": ["everyone"], "writers": ["anonymous"], "content": {"title": "", "reply": "- The formula (20) looks remarkably similar the paper you reference (and that beats your performance) - sec 3.1 of 'Learning hierarchical spatio-temporal features for action recognition with independent subspace analysis'. The only difference is mainly that you use sigmoid nonlinearity and they use square root. \r\n\r\nThere is an additional difference: Inside the sigmoid there is a square, whereas it is a sum over squares in Le et al. In other words, for them, learning of features is done in the presence of a pooling layer, whereas here, learning is done greedily, layer-by-layer. Running the code published by Le et al., incidentally, yields the same performance as our approach. Our method is significantly faster because it is a type of Kmeans.  \r\n\r\n- 4.2 - which auto encoder you are comparing to - there is a large number of them. In particular what if you just used k-means on concatenated frames?  That would also detect 'coincidence' between frames. It would also train extremely quickly (and then use smoother version during inference as in Coates et al). \r\n\r\nWe now report the K-means result on concatenated frames in the newest version. It shows a significantly lower performance. As for the autoencoder, it was a contractive autoencoder, also with detailed result now in the newest version."}, "nonreaders": [], "details": {"replyCount": 0, "overwriting": [], "revisions": false, "forumContent": {"title": "Learning to encode motion using spatio-temporal synchrony", "decision": "submitted, no decision", "abstract": "We consider the task of learning to extract motion from videos. To this end, we show that the detection of spatial transformations can be viewed as the detection of synchrony between the image sequence and a sequence of features undergoing the motion we wish to detect. We show that learning about synchrony is possible using very fast, local learning rules, by introducing multiplicative 'gating' interactions between hidden units across frames. This makes it possible to achieve competitive performance in a wide variety of motion estimation tasks, using a small fraction of the time required to learn features, and to outperform hand-crafted spatio-temporal features by a large margin. We also show how learning about synchrony can be viewed as performing greedy parameter estimation in the well-known motion energy model.", "pdf": "https://arxiv.org/abs/1306.3162", "paperhash": "konda|learning_to_encode_motion_using_spatiotemporal_synchrony", "keywords": [], "conflicts": [], "authors": ["Kishore Reddy Konda", "Roland Memisevic", "Vincent Michalski"], "authorids": ["konda@informatik.uni-frankfurt.de", "roland.memisevic@gmail.com", "vmichals@rz.uni-frankfurt.de"]}, "tags": [], "invitation": {}}}, {"ddate": null, "legacy_migration": true, "tmdate": 1392129600000, "tcdate": 1392129600000, "number": 1, "id": "8W5tCE6_t08Gz", "invitation": "ICLR.cc/2014/-/submission/conference/reply", "forum": "__Jk_HAdtfK5W", "replyto": "WUNsa6OJq07iF", "signatures": ["kishore reddy"], "readers": ["everyone"], "writers": ["anonymous"], "content": {"title": "", "reply": "- I would explain the resulting model as simply 'squared spatio-temporal Gabor filters followed by k-means pooling.'\r\n\r\nWe also show that, unlike for still images, one does not get Gabor features, unless squaring activations are used in the hidden units during learning (which is equivalent to using linear coefficients for computing reconstructions during learning). This also explains why some variants of ICA and energy models (like ISA) can work on videos, but standard autoencoders or K-means do not. \r\n\r\n- Olshausen 2003, Learning Sparse, Overcomplete Representations of Time-Varying Natural Images \r\n\r\nWe included this reference in the newest version. We also extended the introduction to discuss this and related papers (3rd and following paragraph in the introduction). \r\n\r\n- confused about some details on the model architecture used for SAE and SK-means\r\n\r\nWe rewrote the paper to make this clearer. SAE is now discussed in a separate appendix, and SKmeans in the main text. \r\n\r\n-You argue for even-symmetric non-linearities, but couldn't a rectified linear unit also produce the desired effect? ; however it would not associate the contrast reversal, which may be the better inductive bias. \r\n\r\nWe agree. \r\n\r\n-In the current form I remain uncertain what the benefit is of the proposed approach over the motion energy approach or ISA. K-means does pool over more than 2 features, but this is to be expected given the architecture. Can you show that 2-d subspaces are sub-optimal in terms of performance? You do show that the covAE underperforms, why? Is the Le et al. 2011 pipeline giving the major benefit? \r\n\r\nWe did find that the covAE underperforms also in a simple motion direction classification task. We believe this is due to the learning criterion, which forces the model to learn invariances that may be good for reconstruction but not necessarily good for the subsequent classification task. The convolutional pipeline provides around 3% accuracy over a simple bag-of-words pipeline. In case of covAE it does not provide such a benefit. \r\n\r\n-In my opinion, the most novel contribution of the paper is the 'synchrony k-means' algorithm. As far as I am aware this is a nice extension of the fast convergence results shown by Coates et al.. This general framework appears promising for the related problems of 'relating images.' Therefore it could be the focus of the paper, with the SAE algorithm used merely as a control or motivation. \r\n\r\nWe agree, see previous comment.  \r\n\r\n-I am also skeptical about performance measurements of activity recognition as proxy for motion encoding. These datasets likely suffer from various confounds not related to motion encoding. Maybe a simpler test would be beneficial, scientifically?\r\n\r\nWe agree that activity recognition, and a fixed pipeline to plug in learned features, may not be a perfect proxy for the quality of a motion encoding, but recognition performance is probably correlated with it. And it does nicely demonstrate possible practical benefits of this work, because our features learn much faster than existing models, and speed is increasingly important due to the sheer size of video datasets."}, "nonreaders": [], "details": {"replyCount": 0, "overwriting": [], "revisions": false, "forumContent": {"title": "Learning to encode motion using spatio-temporal synchrony", "decision": "submitted, no decision", "abstract": "We consider the task of learning to extract motion from videos. To this end, we show that the detection of spatial transformations can be viewed as the detection of synchrony between the image sequence and a sequence of features undergoing the motion we wish to detect. We show that learning about synchrony is possible using very fast, local learning rules, by introducing multiplicative 'gating' interactions between hidden units across frames. This makes it possible to achieve competitive performance in a wide variety of motion estimation tasks, using a small fraction of the time required to learn features, and to outperform hand-crafted spatio-temporal features by a large margin. We also show how learning about synchrony can be viewed as performing greedy parameter estimation in the well-known motion energy model.", "pdf": "https://arxiv.org/abs/1306.3162", "paperhash": "konda|learning_to_encode_motion_using_spatiotemporal_synchrony", "keywords": [], "conflicts": [], "authors": ["Kishore Reddy Konda", "Roland Memisevic", "Vincent Michalski"], "authorids": ["konda@informatik.uni-frankfurt.de", "roland.memisevic@gmail.com", "vmichals@rz.uni-frankfurt.de"]}, "tags": [], "invitation": {}}}, {"ddate": null, "legacy_migration": true, "tmdate": 1392129120000, "tcdate": 1392129120000, "number": 1, "id": "EEWiEwC6o3TY4", "invitation": "ICLR.cc/2014/-/submission/conference/reply", "forum": "__Jk_HAdtfK5W", "replyto": "G3BpoZVjqn3jE", "signatures": ["kishore reddy"], "readers": ["everyone"], "writers": ["anonymous"], "content": {"title": "", "reply": "-When discussing multiplicative (2.3), isn't this saying we should be working with additive but in the log space? log space is very frequently used in image analysis.\r\n\r\nYes, that's true. Unfortunately, for learning, one would need to undo any log-transforms to compute reconstructions, so this relationship does not immediately translate into a practical algorithm. \r\n\r\n-Does it make sense to report results for optical flow standard sets?\r\n\r\nYes, it may make sense, though it would require a clean-up stage (like an MRF) to be competitive in benchmarks. The model is more general than optical flow, in that it allows pixels to have multiple target positions (like in expansions or transparency, for example). Though is likely to hurt not help in an optical flow benchmark."}, "nonreaders": [], "details": {"replyCount": 0, "overwriting": [], "revisions": false, "forumContent": {"title": "Learning to encode motion using spatio-temporal synchrony", "decision": "submitted, no decision", "abstract": "We consider the task of learning to extract motion from videos. To this end, we show that the detection of spatial transformations can be viewed as the detection of synchrony between the image sequence and a sequence of features undergoing the motion we wish to detect. We show that learning about synchrony is possible using very fast, local learning rules, by introducing multiplicative 'gating' interactions between hidden units across frames. This makes it possible to achieve competitive performance in a wide variety of motion estimation tasks, using a small fraction of the time required to learn features, and to outperform hand-crafted spatio-temporal features by a large margin. We also show how learning about synchrony can be viewed as performing greedy parameter estimation in the well-known motion energy model.", "pdf": "https://arxiv.org/abs/1306.3162", "paperhash": "konda|learning_to_encode_motion_using_spatiotemporal_synchrony", "keywords": [], "conflicts": [], "authors": ["Kishore Reddy Konda", "Roland Memisevic", "Vincent Michalski"], "authorids": ["konda@informatik.uni-frankfurt.de", "roland.memisevic@gmail.com", "vmichals@rz.uni-frankfurt.de"]}, "tags": [], "invitation": {}}}, {"ddate": null, "legacy_migration": true, "tmdate": 1391867580000, "tcdate": 1391867580000, "number": 3, "id": "nOAHIb1E0y2d-", "invitation": "ICLR.cc/2014/-/submission/conference/review", "forum": "__Jk_HAdtfK5W", "replyto": "__Jk_HAdtfK5W", "signatures": ["anonymous reviewer 4272"], "readers": ["everyone"], "writers": ["anonymous"], "content": {"title": "review of Learning to encode motion using spatio-temporal synchrony", "review": "The paper introduces an algorithm to learn to detect motion from video data using coincidence of features between consecutive frames. While there are novel elements, the basic ideas are similar to papers of the same authors and the algorithm by other authors referenced in this paper. \r\n\r\nDetails:\r\n- The formula (20) looks remarkably similar the paper you reference (and that beats your performance) - sec 3.1 of 'Learning hierarchical spatio-temporal features for action recognition with independent subspace analysis'. The only difference is mainly that you use sigmoid nonlinearity and they use square root. \r\n\r\n- 4.2 - which auto encoder you are comparing to - there is a large number of them. In particular what if you just used k-means on concatenated frames? That would also detect 'coincidence' between frames. It would also train extremely quickly (and then use smoother version during inference as in Coates et al).\r\n\r\n- In table 1 - is this on sequence of frames or pairs? (3.1,3.2 vs 3.3?)"}, "nonreaders": [], "details": {"replyCount": 0, "overwriting": [], "revisions": false, "forumContent": {"title": "Learning to encode motion using spatio-temporal synchrony", "decision": "submitted, no decision", "abstract": "We consider the task of learning to extract motion from videos. To this end, we show that the detection of spatial transformations can be viewed as the detection of synchrony between the image sequence and a sequence of features undergoing the motion we wish to detect. We show that learning about synchrony is possible using very fast, local learning rules, by introducing multiplicative 'gating' interactions between hidden units across frames. This makes it possible to achieve competitive performance in a wide variety of motion estimation tasks, using a small fraction of the time required to learn features, and to outperform hand-crafted spatio-temporal features by a large margin. We also show how learning about synchrony can be viewed as performing greedy parameter estimation in the well-known motion energy model.", "pdf": "https://arxiv.org/abs/1306.3162", "paperhash": "konda|learning_to_encode_motion_using_spatiotemporal_synchrony", "keywords": [], "conflicts": [], "authors": ["Kishore Reddy Konda", "Roland Memisevic", "Vincent Michalski"], "authorids": ["konda@informatik.uni-frankfurt.de", "roland.memisevic@gmail.com", "vmichals@rz.uni-frankfurt.de"]}, "tags": [], "invitation": {}}}, {"ddate": null, "legacy_migration": true, "tmdate": 1391111880000, "tcdate": 1391111880000, "number": 2, "id": "WUNsa6OJq07iF", "invitation": "ICLR.cc/2014/-/submission/conference/review", "forum": "__Jk_HAdtfK5W", "replyto": "__Jk_HAdtfK5W", "signatures": ["anonymous reviewer 951b"], "readers": ["everyone"], "writers": ["anonymous"], "content": {"title": "review of Learning to encode motion using spatio-temporal synchrony", "review": "The paper introduces a variation of common mathematical forms for encoding motion.  The basic approach is to encode first-order motion information through a multiplication of two filter outputs.  This approach is closely related to the motion-energy model and the cross-correlation model.\r\n\r\nThere is a lot of math leading up to a rather simple transform (after learning).  I would explain the resulting model as simply 'squared spatio-temporal Gabor filters followed by k-means pooling.'  The squared outputs are the components of the energy-based model (quadrature pair squared spatio-temporal Gabor filters are added in the energy based model) and k-means is used to pool first-order motion selective responses.\r\n\r\nThe more general problem of motion encoding needs to address the goal of motion selectivity and form or pattern invariance/tolerance.  As the authors point out, their squared outputs do not solve the motion encoding problem and the following pooling layer is intended to provide the solution.  The simplest next step would be to combine (add) two outputs to increase form invariance (this is the motion energy model).  Slightly more complex would be to group multiple squared outputs (these are the ISA models applied to spatio-temporal input).  The authors propose to use k-means for the pooling operation.\r\n\r\nThe results are validated on common action recognition computer vision databases.  I do not find the results surprising.  Given the very close similarities of the proposed algorithm to the Le et al. ISA algorithm it is not at all surprising that the results are nearly identical.  The training time improvements are also not surprising given the results from Coates et al. 2011.\r\n\r\nThis paper should probably be cited in regards to the learned filters:\r\nOlshausen 2003, Learning Sparse, Overcomplete Representations of Time-Varying Natural Images\r\nThere are other results in the ICA community that should be cited, as they give similar results.\r\n\r\nI am confused about some details on the model architecture used for SAE and SK-means.  The beginning of section 4 appears to only describe the SAE architecture.  What about the Sk-means architecture?  and how does the k-means in section 3.4 relate to the models evaluated in section 4?  My apologies if this is discussed somewhere in the text, I just can't find it in the places I expect.\r\n\r\nHere are some suggestions/comments:\r\nThe exposition is useful for bringing together many of motion models in the literature.\r\n\r\nYou argue for even-symmetric non-linearities, but couldn't a rectified linear unit also produce the desired effect? ; however it would not associate the contrast reversal, which may be the better inductive bias.\r\n\r\nIn the current form I remain uncertain what the benefit is of the proposed approach over the motion energy approach or ISA.  K-means does pool over more than 2 features, but this is to be expected given the architecture.  Can you show that 2-d subspaces are sub-optimal in terms of performance?  You do show that the covAE underperforms, why?  Is the Le et al. 2011 pipeline giving the major benefit?\r\n\r\nIn my opinion, the most novel contribution of the paper is the 'synchrony k-means' algorithm.  As far as I am aware this is a nice extension of the fast convergence results shown by Coates et al..  This general framework appears promising for the related problems of 'relating images.'  Therefore it could be the focus of the paper, with the SAE algorithm used merely as a control or motivation.\r\n\r\nI am also skeptical about performance measurements of activity recognition as proxy for motion encoding.  These datasets likely suffer from various confounds not related to motion encoding.  Maybe a simpler test would be beneficial, scientifically?"}, "nonreaders": [], "details": {"replyCount": 0, "overwriting": [], "revisions": false, "forumContent": {"title": "Learning to encode motion using spatio-temporal synchrony", "decision": "submitted, no decision", "abstract": "We consider the task of learning to extract motion from videos. To this end, we show that the detection of spatial transformations can be viewed as the detection of synchrony between the image sequence and a sequence of features undergoing the motion we wish to detect. We show that learning about synchrony is possible using very fast, local learning rules, by introducing multiplicative 'gating' interactions between hidden units across frames. This makes it possible to achieve competitive performance in a wide variety of motion estimation tasks, using a small fraction of the time required to learn features, and to outperform hand-crafted spatio-temporal features by a large margin. We also show how learning about synchrony can be viewed as performing greedy parameter estimation in the well-known motion energy model.", "pdf": "https://arxiv.org/abs/1306.3162", "paperhash": "konda|learning_to_encode_motion_using_spatiotemporal_synchrony", "keywords": [], "conflicts": [], "authors": ["Kishore Reddy Konda", "Roland Memisevic", "Vincent Michalski"], "authorids": ["konda@informatik.uni-frankfurt.de", "roland.memisevic@gmail.com", "vmichals@rz.uni-frankfurt.de"]}, "tags": [], "invitation": {}}}, {"ddate": null, "legacy_migration": true, "tmdate": 1390089480000, "tcdate": 1390089480000, "number": 1, "id": "G3BpoZVjqn3jE", "invitation": "ICLR.cc/2014/-/submission/conference/review", "forum": "__Jk_HAdtfK5W", "replyto": "__Jk_HAdtfK5W", "signatures": ["anonymous reviewer 21fc"], "readers": ["everyone"], "writers": ["anonymous"], "content": {"title": "review of Learning to encode motion using spatio-temporal synchrony", "review": "One might think that everything has been said about motion estimation and motion energies, though refreshing ideas are always welcome even in subjects with thousands (ten of thousands?) papers. \r\n\r\nThe paper overall presentation and discussion are very clear and friendly.\r\n\r\nWhen discussing multiplicative (2.3), isn't this saying we should be working with additive but in the log space? log space is very frequently used in image analysis.\r\n\r\nThe locality property is very interesting and as the authors claim, very powerful for computation. I believe is worth investigating for other applications and models.\r\n\r\nNot all the mentioned results are the state-of-the-art for the used datasets, but this is not critical.\r\n\r\nDoes it make sense to report results for optical flow standard sets?\r\n\r\nWhile I don't believe the paper is revolutionary, it is nice to read and has some interesting insights."}, "nonreaders": [], "details": {"replyCount": 0, "overwriting": [], "revisions": false, "forumContent": {"title": "Learning to encode motion using spatio-temporal synchrony", "decision": "submitted, no decision", "abstract": "We consider the task of learning to extract motion from videos. To this end, we show that the detection of spatial transformations can be viewed as the detection of synchrony between the image sequence and a sequence of features undergoing the motion we wish to detect. We show that learning about synchrony is possible using very fast, local learning rules, by introducing multiplicative 'gating' interactions between hidden units across frames. This makes it possible to achieve competitive performance in a wide variety of motion estimation tasks, using a small fraction of the time required to learn features, and to outperform hand-crafted spatio-temporal features by a large margin. We also show how learning about synchrony can be viewed as performing greedy parameter estimation in the well-known motion energy model.", "pdf": "https://arxiv.org/abs/1306.3162", "paperhash": "konda|learning_to_encode_motion_using_spatiotemporal_synchrony", "keywords": [], "conflicts": [], "authors": ["Kishore Reddy Konda", "Roland Memisevic", "Vincent Michalski"], "authorids": ["konda@informatik.uni-frankfurt.de", "roland.memisevic@gmail.com", "vmichals@rz.uni-frankfurt.de"]}, "tags": [], "invitation": {}}}, {"replyto": null, "ddate": null, "legacy_migration": true, "tmdate": 1387381560000, "tcdate": 1387381560000, "number": 5, "id": "__Jk_HAdtfK5W", "invitation": "ICLR.cc/2014/conference/-/submission", "forum": "__Jk_HAdtfK5W", "signatures": ["konda@informatik.uni-frankfurt.de"], "readers": ["everyone"], "content": {"title": "Learning to encode motion using spatio-temporal synchrony", "decision": "submitted, no decision", "abstract": "We consider the task of learning to extract motion from videos. To this end, we show that the detection of spatial transformations can be viewed as the detection of synchrony between the image sequence and a sequence of features undergoing the motion we wish to detect. We show that learning about synchrony is possible using very fast, local learning rules, by introducing multiplicative 'gating' interactions between hidden units across frames. This makes it possible to achieve competitive performance in a wide variety of motion estimation tasks, using a small fraction of the time required to learn features, and to outperform hand-crafted spatio-temporal features by a large margin. We also show how learning about synchrony can be viewed as performing greedy parameter estimation in the well-known motion energy model.", "pdf": "https://arxiv.org/abs/1306.3162", "paperhash": "konda|learning_to_encode_motion_using_spatiotemporal_synchrony", "keywords": [], "conflicts": [], "authors": ["Kishore Reddy Konda", "Roland Memisevic", "Vincent Michalski"], "authorids": ["konda@informatik.uni-frankfurt.de", "roland.memisevic@gmail.com", "vmichals@rz.uni-frankfurt.de"]}, "writers": [], "details": {"replyCount": 7, "writable": false, "overwriting": [], "revisions": false, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1369422751717, "tmdate": 1496674357195, "id": "ICLR.cc/2014/conference/-/submission", "writers": ["ICLR.cc/2014"], "signatures": ["OpenReview.net"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": null, "replyto": null, "writers": {"values-regex": "~.*"}, "signatures": {"values-regex": "~.*", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"pdf": {"required": true, "order": 5, "description": "Either upload a PDF file or provide a direct link to your PDF on ArXiv (link must begin with http(s) and end with .pdf)", "value-regex": "upload|(http|https):\\/\\/.+\\.pdf"}, "title": {"required": true, "order": 1, "description": "Title of paper.", "value-regex": ".{1,250}"}, "abstract": {"required": true, "order": 4, "description": "Abstract of paper.", "value-regex": "[\\S\\s]{1,5000}"}, "authors": {"required": true, "order": 2, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of author names, as they appear in the paper."}, "conflicts": {"required": true, "order": 100, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of email domains of people who would have a conflict of interest in reviewing this paper, (e.g., cs.umass.edu;google.com, etc.)."}, "keywords": {"order": 6, "description": "Comma separated list of keywords.", "values-dropdown": []}, "authorids": {"required": true, "order": 3, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of author email addresses, in the same order as above."}}}, "nonreaders": [], "noninvitees": [], "expdate": 1377198751717, "cdate": 1496674357195}}}], "count": 8}