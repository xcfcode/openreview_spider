{"notes": [{"tddate": null, "ddate": null, "cdate": null, "original": null, "tmdate": 1490028573426, "tcdate": 1490028573426, "number": 1, "id": "SygHXOtaoe", "invitation": "ICLR.cc/2017/workshop/-/paper55/acceptance", "forum": "HkO-PCmYl", "replyto": "HkO-PCmYl", "signatures": ["ICLR.cc/2017/pcs"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/pcs"], "content": {"decision": "Accept", "title": "ICLR committee final decision"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Shake-Shake regularization of 3-branch residual networks", "abstract": "The method introduced in this paper aims at helping computer vision practitioners faced with an overfit problem. The idea is to replace, in a 3-branch ResNet, the standard summation of residual branches by a stochastic affine combination. The largest tested model improves on the best single shot published result on CIFAR-10 by reaching 2.86% test error. Code is available at https://github.com/xgastaldi/shake-shake", "pdf": "/pdf/36d73244aa7b4ade7fde8144ed70cb702fda128b.pdf", "TL;DR": "Reduce overfit by replacing, in a 3-branch ResNet, the standard summation of residual branches by a stochastic affine combination", "paperhash": "gastaldi|shakeshake_regularization_of_3branch_residual_networks", "conflicts": ["n/a"], "authors": ["Xavier Gastaldi"], "authorids": ["xgastaldi.mba2011@london.edu"], "keywords": ["Computer vision", "Deep learning", "Supervised Learning"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "tmdate": 1490028573946, "id": "ICLR.cc/2017/workshop/-/paper55/acceptance", "writers": ["ICLR.cc/2017/workshop"], "signatures": ["ICLR.cc/2017/workshop"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/pcs"], "noninvitees": ["ICLR.cc/2017/pcs"], "reply": {"forum": "HkO-PCmYl", "replyto": "HkO-PCmYl", "writers": {"values-regex": "ICLR.cc/2017/pcs"}, "signatures": {"values-regex": "ICLR.cc/2017/pcs", "description": "Your displayed identity associated with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your decision.", "value": "ICLR committee final decision"}, "decision": {"required": true, "order": 3, "value-radio": ["Accept", "Reject"]}}}, "nonreaders": [], "cdate": 1490028573946}}}, {"tddate": null, "nonreaders": null, "tmdate": 1489772563407, "tcdate": 1489767228558, "number": 20, "id": "SJHSoFFoe", "invitation": "ICLR.cc/2017/workshop/-/paper55/public/comment", "forum": "HkO-PCmYl", "replyto": "H1UCZH_ol", "signatures": ["~Xavier_Gastaldi1"], "readers": ["everyone"], "writers": ["~Xavier_Gastaldi1"], "content": {"title": "Table 1 - Missing 2x64d models", "comment": "The tests of 2 out of the 4 missing models are completed and you will find the results below (error rates at the last epoch):\n26 2x64d S-K-B: 3.62%\n26 2x64d E-S-I: 4.07%\nThese results should be compared to a 26 2x64d E-E-B which obtains 3.76%.\nWith the caveat that these are single tests, we can see a confirmation that Even-Shake doesn't work and that Shake-Keep produces a small improvement."}, "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Shake-Shake regularization of 3-branch residual networks", "abstract": "The method introduced in this paper aims at helping computer vision practitioners faced with an overfit problem. The idea is to replace, in a 3-branch ResNet, the standard summation of residual branches by a stochastic affine combination. The largest tested model improves on the best single shot published result on CIFAR-10 by reaching 2.86% test error. Code is available at https://github.com/xgastaldi/shake-shake", "pdf": "/pdf/36d73244aa7b4ade7fde8144ed70cb702fda128b.pdf", "TL;DR": "Reduce overfit by replacing, in a 3-branch ResNet, the standard summation of residual branches by a stochastic affine combination", "paperhash": "gastaldi|shakeshake_regularization_of_3branch_residual_networks", "conflicts": ["n/a"], "authors": ["Xavier Gastaldi"], "authorids": ["xgastaldi.mba2011@london.edu"], "keywords": ["Computer vision", "Deep learning", "Supervised Learning"]}, "tags": [], "invitation": {"tddate": null, "tmdate": 1487296256855, "tcdate": 1487296256855, "id": "ICLR.cc/2017/workshop/-/paper55/public/comment", "writers": ["ICLR.cc/2017/workshop"], "signatures": ["ICLR.cc/2017/workshop"], "readers": ["everyone"], "invitees": ["~"], "noninvitees": ["ICLR.cc/2017/workshop/paper55/reviewers"], "reply": {"forum": "HkO-PCmYl", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/workshop/reviewers", "ICLR.cc/2017/pcs"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,5000}"}}}, "nonreaders": [], "cdate": 1487296256855}}}, {"tddate": null, "tmdate": 1489682893874, "tcdate": 1489682893874, "number": 19, "id": "H1UCZH_ol", "invitation": "ICLR.cc/2017/workshop/-/paper55/public/comment", "forum": "HkO-PCmYl", "replyto": "S1qjrYIse", "signatures": ["~Xavier_Gastaldi1"], "readers": ["everyone"], "writers": ["~Xavier_Gastaldi1"], "content": {"title": "Re: Re: Re: Good results, but the explanation is lacking", "comment": "I thought about this for a while and ran the following test:\n\nFor each residual block, forward x_i through the residual branch 1 (ReLU-Conv3x3-BN-ReLU-Conv3x3-BN-Mul(0.5)) and store the output tensor in b1_i. Do the same for residual branch 2 and store the output in b2_i. Flatten these 2 tensors into vectors flat1_i and flat2_i. Calculate the covariance between each corresponding item in the 2 vectors using an online version of the covariance algorithm (see the last algorithm on this page https://en.wikipedia.org/wiki/Algorithms_for_calculating_variance#Covariance). Repeat until all the images in the test set have been forwarded.\n\nThe results can be found here:\nhttp://bit.ly/2nwaIiI\n\nAs you can see it looks like the covariance between the same activations on the 2 residual branches increases with regularization.\n\nI did this quickly so a mistake in my implementation is not impossible. If you want to take a look at the code, you can find it here.\nhttp://bit.ly/2myxMwe"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Shake-Shake regularization of 3-branch residual networks", "abstract": "The method introduced in this paper aims at helping computer vision practitioners faced with an overfit problem. The idea is to replace, in a 3-branch ResNet, the standard summation of residual branches by a stochastic affine combination. The largest tested model improves on the best single shot published result on CIFAR-10 by reaching 2.86% test error. Code is available at https://github.com/xgastaldi/shake-shake", "pdf": "/pdf/36d73244aa7b4ade7fde8144ed70cb702fda128b.pdf", "TL;DR": "Reduce overfit by replacing, in a 3-branch ResNet, the standard summation of residual branches by a stochastic affine combination", "paperhash": "gastaldi|shakeshake_regularization_of_3branch_residual_networks", "conflicts": ["n/a"], "authors": ["Xavier Gastaldi"], "authorids": ["xgastaldi.mba2011@london.edu"], "keywords": ["Computer vision", "Deep learning", "Supervised Learning"]}, "tags": [], "invitation": {"tddate": null, "tmdate": 1487296256855, "tcdate": 1487296256855, "id": "ICLR.cc/2017/workshop/-/paper55/public/comment", "writers": ["ICLR.cc/2017/workshop"], "signatures": ["ICLR.cc/2017/workshop"], "readers": ["everyone"], "invitees": ["~"], "noninvitees": ["ICLR.cc/2017/workshop/paper55/reviewers"], "reply": {"forum": "HkO-PCmYl", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/workshop/reviewers", "ICLR.cc/2017/pcs"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,5000}"}}}, "nonreaders": [], "cdate": 1487296256855}}}, {"tddate": null, "tmdate": 1489666011401, "tcdate": 1489666011401, "number": 18, "id": "HJQygWOjl", "invitation": "ICLR.cc/2017/workshop/-/paper55/public/comment", "forum": "HkO-PCmYl", "replyto": "S1k_e3xsx", "signatures": ["~Xavier_Gastaldi1"], "readers": ["everyone"], "writers": ["~Xavier_Gastaldi1"], "content": {"title": "Re: Review", "comment": "Thank you for your review.\nI hope that the motivation section I added alleviates some of your concerns."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Shake-Shake regularization of 3-branch residual networks", "abstract": "The method introduced in this paper aims at helping computer vision practitioners faced with an overfit problem. The idea is to replace, in a 3-branch ResNet, the standard summation of residual branches by a stochastic affine combination. The largest tested model improves on the best single shot published result on CIFAR-10 by reaching 2.86% test error. Code is available at https://github.com/xgastaldi/shake-shake", "pdf": "/pdf/36d73244aa7b4ade7fde8144ed70cb702fda128b.pdf", "TL;DR": "Reduce overfit by replacing, in a 3-branch ResNet, the standard summation of residual branches by a stochastic affine combination", "paperhash": "gastaldi|shakeshake_regularization_of_3branch_residual_networks", "conflicts": ["n/a"], "authors": ["Xavier Gastaldi"], "authorids": ["xgastaldi.mba2011@london.edu"], "keywords": ["Computer vision", "Deep learning", "Supervised Learning"]}, "tags": [], "invitation": {"tddate": null, "tmdate": 1487296256855, "tcdate": 1487296256855, "id": "ICLR.cc/2017/workshop/-/paper55/public/comment", "writers": ["ICLR.cc/2017/workshop"], "signatures": ["ICLR.cc/2017/workshop"], "readers": ["everyone"], "invitees": ["~"], "noninvitees": ["ICLR.cc/2017/workshop/paper55/reviewers"], "reply": {"forum": "HkO-PCmYl", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/workshop/reviewers", "ICLR.cc/2017/pcs"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,5000}"}}}, "nonreaders": [], "cdate": 1487296256855}}}, {"tddate": null, "nonreaders": null, "tmdate": 1489664126065, "tcdate": 1489663817161, "number": 17, "id": "B1WUweOje", "invitation": "ICLR.cc/2017/workshop/-/paper55/public/comment", "forum": "HkO-PCmYl", "replyto": "Byrdq4Bjl", "signatures": ["~Xavier_Gastaldi1"], "readers": ["everyone"], "writers": ["~Xavier_Gastaldi1"], "content": {"title": "Additional tests", "comment": "As mentioned in my previous comment, you will find below a couple of additional tests results.\nAll tests below were performed on 26 2x32d models at the Image level and are compared to a 26 2x32d Shake-Keep-Image model.\n\nThe first test (method 1) is to set beta_i_j = 1 - alpha_i_j. As you can see in this figure, the effect is quite drastic and the training error stays really high. Something seems to prevent the network from converging.\nhttp://bit.ly/2mM85tm\n\nThe 4 tests below were designed to understand why Method 1 has such a strong effect.\nMethod 2: If alpha_i_j < 0.5, beta_i_j = rand(0,1)*alpha_i_j. If alpha_i_j >= 0.5, beta_i_j = rand(0,1)*(1-alpha_i_j) + alpha_i_j\nmethod 3: If alpha_i_j < 0.5, beta_i_j = rand(0,1)*(0.5-alpha_i_j) + alpha_i_j. If alpha_i_j >= 0.5, beta_i_j = rand(0,1)*(alpha_i_j-0.5) + 0.5\nMethod 4: If alpha_i_j < 0.5, beta_i_j = rand(0,1)*(0.5-alpha_i_j) + 0.5. If alpha_i_j >= 0.5, beta_i_j = rand(0,1)*(0.5 - (1-alpha_i_j)) + (1 - alpha_i_j)\nmethod 5: If alpha_i_j < 0.5, beta_i_j = rand(0,1)*alpha_i_j + (1-alpha_i_j). If alpha_i_j >= 0.5, beta_i_j = rand(0,1)*(1-alpha_i_j)\n\nA graphical illustration is probably easier to understand and you can find one here:\nhttp://bit.ly/2mSb8S9\n\nYou can find the training curves here:\nhttp://bit.ly/2ndeFf2\n\nAs well as a focus on the lower section here:\nhttp://bit.ly/2m4mgfY\n\nJust as in the paper, training curves use a dark shade and test curves use a light shade\n\nWhat can be seen is that:\n1. The regularization effect seems to be linked to the relative position of beta_i_j compared to alpha_i_j\n2. The further away beta_i_j is from alpha_i_j, the stronger the regularization effect\n3. There seems to be a jump in regularization strength when 0.5 is crossed\n4. Even if the training curves of Method 2 and of a S-K-I model are different, their test curves overlap perfectly. The training curves actually reach zero around the same time. The training curve of Method 3 is lower for a long time but reaches 0 later which in turn produces a better test error. It would be interesting to understand what leads to this inversion.\n\nI find this new information interesting as it could help adjust the strength of the effect and perhaps improve the error rate further."}, "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Shake-Shake regularization of 3-branch residual networks", "abstract": "The method introduced in this paper aims at helping computer vision practitioners faced with an overfit problem. The idea is to replace, in a 3-branch ResNet, the standard summation of residual branches by a stochastic affine combination. The largest tested model improves on the best single shot published result on CIFAR-10 by reaching 2.86% test error. Code is available at https://github.com/xgastaldi/shake-shake", "pdf": "/pdf/36d73244aa7b4ade7fde8144ed70cb702fda128b.pdf", "TL;DR": "Reduce overfit by replacing, in a 3-branch ResNet, the standard summation of residual branches by a stochastic affine combination", "paperhash": "gastaldi|shakeshake_regularization_of_3branch_residual_networks", "conflicts": ["n/a"], "authors": ["Xavier Gastaldi"], "authorids": ["xgastaldi.mba2011@london.edu"], "keywords": ["Computer vision", "Deep learning", "Supervised Learning"]}, "tags": [], "invitation": {"tddate": null, "tmdate": 1487296256855, "tcdate": 1487296256855, "id": "ICLR.cc/2017/workshop/-/paper55/public/comment", "writers": ["ICLR.cc/2017/workshop"], "signatures": ["ICLR.cc/2017/workshop"], "readers": ["everyone"], "invitees": ["~"], "noninvitees": ["ICLR.cc/2017/workshop/paper55/reviewers"], "reply": {"forum": "HkO-PCmYl", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/workshop/reviewers", "ICLR.cc/2017/pcs"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,5000}"}}}, "nonreaders": [], "cdate": 1487296256855}}}, {"tddate": null, "replyto": null, "nonreaders": null, "ddate": null, "tmdate": 1489579029602, "tcdate": 1487296256045, "number": 55, "id": "HkO-PCmYl", "invitation": "ICLR.cc/2017/workshop/-/submission", "forum": "HkO-PCmYl", "signatures": ["~Xavier_Gastaldi1"], "readers": ["everyone"], "content": {"title": "Shake-Shake regularization of 3-branch residual networks", "abstract": "The method introduced in this paper aims at helping computer vision practitioners faced with an overfit problem. The idea is to replace, in a 3-branch ResNet, the standard summation of residual branches by a stochastic affine combination. The largest tested model improves on the best single shot published result on CIFAR-10 by reaching 2.86% test error. Code is available at https://github.com/xgastaldi/shake-shake", "pdf": "/pdf/36d73244aa7b4ade7fde8144ed70cb702fda128b.pdf", "TL;DR": "Reduce overfit by replacing, in a 3-branch ResNet, the standard summation of residual branches by a stochastic affine combination", "paperhash": "gastaldi|shakeshake_regularization_of_3branch_residual_networks", "conflicts": ["n/a"], "authors": ["Xavier Gastaldi"], "authorids": ["xgastaldi.mba2011@london.edu"], "keywords": ["Computer vision", "Deep learning", "Supervised Learning"]}, "writers": [], "details": {"replyCount": 24, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1487690420000, "tmdate": 1484242559574, "id": "ICLR.cc/2017/workshop/-/submission", "writers": ["ICLR.cc/2017/workshop"], "signatures": ["ICLR.cc/2017/pcs"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": null, "replyto": null, "writers": {"values-regex": "~.*"}, "signatures": {"values-regex": "~.*", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"pdf": {"required": true, "order": 5, "description": "Either upload a PDF file or provide a direct link to your PDF on ArXiv (link must begin with http(s) and end with .pdf)", "value-regex": "upload|(http|https):\\/\\/.+\\.pdf"}, "title": {"required": true, "order": 1, "description": "Title of paper.", "value-regex": ".{1,250}"}, "abstract": {"required": true, "order": 4, "description": "Abstract of paper.", "value-regex": "[\\S\\s]{1,5000}"}, "authors": {"required": true, "order": 2, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of author names, as they appear in the paper."}, "conflicts": {"required": true, "order": 100, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of email domains of people who would have a conflict of interest in reviewing this paper, (e.g., cs.umass.edu;google.com, etc.)."}, "keywords": {"order": 6, "description": "Comma separated list of keywords.", "values-dropdown": ["Theory", "Computer vision", "Speech", "Natural language processing", "Deep learning", "Unsupervised Learning", "Supervised Learning", "Semi-Supervised Learning", "Reinforcement Learning", "Transfer Learning", "Multi-modal learning", "Applications", "Optimization", "Structured prediction", "Games"]}, "TL;DR": {"required": false, "order": 3, "description": "\"Too Long; Didn't Read\": a short sentence describing your paper", "value-regex": "[^\\n]{0,250}"}, "authorids": {"required": true, "order": 3, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of author email addresses, in the same order as above."}}}, "nonreaders": [], "noninvitees": [], "expdate": 1495466420000, "cdate": 1484242559574}}}, {"tddate": null, "tmdate": 1489569186465, "tcdate": 1489569186465, "number": 16, "id": "S1qjrYIse", "invitation": "ICLR.cc/2017/workshop/-/paper55/public/comment", "forum": "HkO-PCmYl", "replyto": "H1Cwd3Ssl", "signatures": ["~Xavier_Gastaldi1"], "readers": ["everyone"], "writers": ["~Xavier_Gastaldi1"], "content": {"title": "Re: Re: Re: Good results, but the explanation is lacking", "comment": "Thank you for your help and advice. I will try to measure this before the Friday deadline."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Shake-Shake regularization of 3-branch residual networks", "abstract": "The method introduced in this paper aims at helping computer vision practitioners faced with an overfit problem. The idea is to replace, in a 3-branch ResNet, the standard summation of residual branches by a stochastic affine combination. The largest tested model improves on the best single shot published result on CIFAR-10 by reaching 2.86% test error. Code is available at https://github.com/xgastaldi/shake-shake", "pdf": "/pdf/36d73244aa7b4ade7fde8144ed70cb702fda128b.pdf", "TL;DR": "Reduce overfit by replacing, in a 3-branch ResNet, the standard summation of residual branches by a stochastic affine combination", "paperhash": "gastaldi|shakeshake_regularization_of_3branch_residual_networks", "conflicts": ["n/a"], "authors": ["Xavier Gastaldi"], "authorids": ["xgastaldi.mba2011@london.edu"], "keywords": ["Computer vision", "Deep learning", "Supervised Learning"]}, "tags": [], "invitation": {"tddate": null, "tmdate": 1487296256855, "tcdate": 1487296256855, "id": "ICLR.cc/2017/workshop/-/paper55/public/comment", "writers": ["ICLR.cc/2017/workshop"], "signatures": ["ICLR.cc/2017/workshop"], "readers": ["everyone"], "invitees": ["~"], "noninvitees": ["ICLR.cc/2017/workshop/paper55/reviewers"], "reply": {"forum": "HkO-PCmYl", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/workshop/reviewers", "ICLR.cc/2017/pcs"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,5000}"}}}, "nonreaders": [], "cdate": 1487296256855}}}, {"tddate": null, "tmdate": 1489516645595, "tcdate": 1489516645595, "number": 1, "id": "H1Cwd3Ssl", "invitation": "ICLR.cc/2017/workshop/-/paper55/official/comment", "forum": "HkO-PCmYl", "replyto": "SkDXsNBjl", "signatures": ["ICLR.cc/2017/workshop/paper55/AnonReviewer1"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/workshop/paper55/AnonReviewer1"], "content": {"title": "Re: Re: Good results, but the explanation is lacking", "comment": "Thanks for this reply, the effort generally applied to this work, and your honesty!\n\nI don't think the proposed experiment is a good measure of redundancy between representations. It could just be that adding stochasticity encourages larger weights (and thus larger MSE). Furthermore, a matching problem needs to be solved before it even makes sense to compare weights across different networks (see https://arxiv.org/pdf/1511.07543.pdf). I think covariance between pairs of neurons in a layer estimated on a sufficiently large dataset (1000 is probably enough) is a reasonable measure of the redundancy in one hidden representation. This is also nice because covariance can be compared between networks."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Shake-Shake regularization of 3-branch residual networks", "abstract": "The method introduced in this paper aims at helping computer vision practitioners faced with an overfit problem. The idea is to replace, in a 3-branch ResNet, the standard summation of residual branches by a stochastic affine combination. The largest tested model improves on the best single shot published result on CIFAR-10 by reaching 2.86% test error. Code is available at https://github.com/xgastaldi/shake-shake", "pdf": "/pdf/36d73244aa7b4ade7fde8144ed70cb702fda128b.pdf", "TL;DR": "Reduce overfit by replacing, in a 3-branch ResNet, the standard summation of residual branches by a stochastic affine combination", "paperhash": "gastaldi|shakeshake_regularization_of_3branch_residual_networks", "conflicts": ["n/a"], "authors": ["Xavier Gastaldi"], "authorids": ["xgastaldi.mba2011@london.edu"], "keywords": ["Computer vision", "Deep learning", "Supervised Learning"]}, "tags": [], "invitation": {"tddate": null, "tmdate": 1487296256870, "tcdate": 1487296256870, "id": "ICLR.cc/2017/workshop/-/paper55/official/comment", "writers": ["ICLR.cc/2017/workshop"], "signatures": ["ICLR.cc/2017/workshop"], "readers": ["everyone"], "reply": {"forum": "HkO-PCmYl", "writers": {"values-regex": "ICLR.cc/2017/workshop/paper55/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/workshop/paper55/AnonReviewer[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/workshop/reviewers", "ICLR.cc/2017/pcs"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,5000}"}}}, "nonreaders": [], "noninvitees": [], "invitees": ["ICLR.cc/2017/workshop/paper55/reviewers", "ICLR.cc/2017/workshop/paper55/areachairs"], "cdate": 1487296256870}}}, {"tddate": null, "tmdate": 1489504772010, "tcdate": 1489504772010, "number": 15, "id": "Bk3ZctHol", "invitation": "ICLR.cc/2017/workshop/-/paper55/public/comment", "forum": "HkO-PCmYl", "replyto": "HJQvs4Ssx", "signatures": ["(anonymous)"], "readers": ["everyone"], "writers": ["(anonymous)"], "content": {"title": "Thanks", "comment": "Thanks for your confirmation! It is good to fix the problem before it propagates. \nAs I said, the paper is great for the workshop."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Shake-Shake regularization of 3-branch residual networks", "abstract": "The method introduced in this paper aims at helping computer vision practitioners faced with an overfit problem. The idea is to replace, in a 3-branch ResNet, the standard summation of residual branches by a stochastic affine combination. The largest tested model improves on the best single shot published result on CIFAR-10 by reaching 2.86% test error. Code is available at https://github.com/xgastaldi/shake-shake", "pdf": "/pdf/36d73244aa7b4ade7fde8144ed70cb702fda128b.pdf", "TL;DR": "Reduce overfit by replacing, in a 3-branch ResNet, the standard summation of residual branches by a stochastic affine combination", "paperhash": "gastaldi|shakeshake_regularization_of_3branch_residual_networks", "conflicts": ["n/a"], "authors": ["Xavier Gastaldi"], "authorids": ["xgastaldi.mba2011@london.edu"], "keywords": ["Computer vision", "Deep learning", "Supervised Learning"]}, "tags": [], "invitation": {"tddate": null, "tmdate": 1487296256855, "tcdate": 1487296256855, "id": "ICLR.cc/2017/workshop/-/paper55/public/comment", "writers": ["ICLR.cc/2017/workshop"], "signatures": ["ICLR.cc/2017/workshop"], "readers": ["everyone"], "invitees": ["~"], "noninvitees": ["ICLR.cc/2017/workshop/paper55/reviewers"], "reply": {"forum": "HkO-PCmYl", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/workshop/reviewers", "ICLR.cc/2017/pcs"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,5000}"}}}, "nonreaders": [], "cdate": 1487296256855}}}, {"tddate": null, "nonreaders": null, "tmdate": 1489491528953, "tcdate": 1489484574823, "number": 13, "id": "SkDXsNBjl", "invitation": "ICLR.cc/2017/workshop/-/paper55/public/comment", "forum": "HkO-PCmYl", "replyto": "SkGgS3gsx", "signatures": ["~Xavier_Gastaldi1"], "readers": ["everyone"], "writers": ["~Xavier_Gastaldi1"], "content": {"title": "Re: Good results, but the explanation is lacking", "comment": "Redundancy:\nYou will find below the link to a table presenting the Mean Square Error between the weights of a convolutional layer in one branch and the weights of the same convolutional layer in the other branch. For readability, the MSEs were multiplied by 10E4. These results are for 2x32d E-E-B and 2x32d S-S-I models. As you can see the redundancy between the 2 branches is reduced by the introduced stochasticity.\nhttp://bit.ly/2nzjDyZ\n\nTable 1:\nIf time allows, I propose to run 1 instance of each of the missing 2x64d models to make sure that there is no trend change. I will share them in this thread when available."}, "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Shake-Shake regularization of 3-branch residual networks", "abstract": "The method introduced in this paper aims at helping computer vision practitioners faced with an overfit problem. The idea is to replace, in a 3-branch ResNet, the standard summation of residual branches by a stochastic affine combination. The largest tested model improves on the best single shot published result on CIFAR-10 by reaching 2.86% test error. Code is available at https://github.com/xgastaldi/shake-shake", "pdf": "/pdf/36d73244aa7b4ade7fde8144ed70cb702fda128b.pdf", "TL;DR": "Reduce overfit by replacing, in a 3-branch ResNet, the standard summation of residual branches by a stochastic affine combination", "paperhash": "gastaldi|shakeshake_regularization_of_3branch_residual_networks", "conflicts": ["n/a"], "authors": ["Xavier Gastaldi"], "authorids": ["xgastaldi.mba2011@london.edu"], "keywords": ["Computer vision", "Deep learning", "Supervised Learning"]}, "tags": [], "invitation": {"tddate": null, "tmdate": 1487296256855, "tcdate": 1487296256855, "id": "ICLR.cc/2017/workshop/-/paper55/public/comment", "writers": ["ICLR.cc/2017/workshop"], "signatures": ["ICLR.cc/2017/workshop"], "readers": ["everyone"], "invitees": ["~"], "noninvitees": ["ICLR.cc/2017/workshop/paper55/reviewers"], "reply": {"forum": "HkO-PCmYl", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/workshop/reviewers", "ICLR.cc/2017/pcs"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,5000}"}}}, "nonreaders": [], "cdate": 1487296256855}}}, {"tddate": null, "tmdate": 1489484635423, "tcdate": 1489484635423, "number": 14, "id": "HJQvs4Ssx", "invitation": "ICLR.cc/2017/workshop/-/paper55/public/comment", "forum": "HkO-PCmYl", "replyto": "rJaR2S4jg", "signatures": ["~Xavier_Gastaldi1"], "readers": ["everyone"], "writers": ["~Xavier_Gastaldi1"], "content": {"title": "Re: Top 1 error or best top 1 error?", "comment": "Thank you for spotting this. You are right, this line of code is from fb.resnet.torch and since fb.resnet.torch is the official ResNet implementation, I (wrongly) thought that this was the way it was calculated in the ResNet papers. I think that this section of the code was designed for the Imagenet experiments not the CIFAR ones. Changing from the best error rate to the last error rate moves the average of the 2x96d S-S-I models from 2.72% to 2.86%. It also moves the average of the 2x96d E-E-B models from 3.44% to 3.58%. The delta between the largest S-S-I and E-E-B models stays at 0.72%. I will update all the numbers in Table 1 in the next couple of days."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Shake-Shake regularization of 3-branch residual networks", "abstract": "The method introduced in this paper aims at helping computer vision practitioners faced with an overfit problem. The idea is to replace, in a 3-branch ResNet, the standard summation of residual branches by a stochastic affine combination. The largest tested model improves on the best single shot published result on CIFAR-10 by reaching 2.86% test error. Code is available at https://github.com/xgastaldi/shake-shake", "pdf": "/pdf/36d73244aa7b4ade7fde8144ed70cb702fda128b.pdf", "TL;DR": "Reduce overfit by replacing, in a 3-branch ResNet, the standard summation of residual branches by a stochastic affine combination", "paperhash": "gastaldi|shakeshake_regularization_of_3branch_residual_networks", "conflicts": ["n/a"], "authors": ["Xavier Gastaldi"], "authorids": ["xgastaldi.mba2011@london.edu"], "keywords": ["Computer vision", "Deep learning", "Supervised Learning"]}, "tags": [], "invitation": {"tddate": null, "tmdate": 1487296256855, "tcdate": 1487296256855, "id": "ICLR.cc/2017/workshop/-/paper55/public/comment", "writers": ["ICLR.cc/2017/workshop"], "signatures": ["ICLR.cc/2017/workshop"], "readers": ["everyone"], "invitees": ["~"], "noninvitees": ["ICLR.cc/2017/workshop/paper55/reviewers"], "reply": {"forum": "HkO-PCmYl", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/workshop/reviewers", "ICLR.cc/2017/pcs"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,5000}"}}}, "nonreaders": [], "cdate": 1487296256855}}}, {"tddate": null, "tmdate": 1489484396638, "tcdate": 1489484396638, "number": 12, "id": "Byrdq4Bjl", "invitation": "ICLR.cc/2017/workshop/-/paper55/public/comment", "forum": "HkO-PCmYl", "replyto": "HkO-PCmYl", "signatures": ["~Xavier_Gastaldi1"], "readers": ["everyone"], "writers": ["~Xavier_Gastaldi1"], "content": {"title": "Motivation and additional references", "comment": "Dear Reviewers,\n\nThank you for your comments. I updated the paper and made the following changes:\n1. Added a reference to the papers mentioned by Reviewer1\n2. Moved the implementation details to the appendix\n3. Added a section on motivation\n\nIf you wonder why these 3 papers were not included, the simple answer is that I did not know about them when I wrote the extended abstract. With hindsight, I understand why someone would draw a parallel to noise injection, but since I was looking for a more global effect (by global I mean \u201cImage level\u201d perturbations vs noise which is more local as it creates individual weight or feature perturbations), I never really explored the extensive dropout literature as much as I probably should have\u2026 \n\nThe absence of a motivation section was simply due to the 3p constraint. I hope that moving the implementation details to the appendix is an acceptable fix.\n\nFor your information, I am currently running a couple of tests that should provide further hints as to what is happening under the hood. They should be completed within the next 48 hours."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Shake-Shake regularization of 3-branch residual networks", "abstract": "The method introduced in this paper aims at helping computer vision practitioners faced with an overfit problem. The idea is to replace, in a 3-branch ResNet, the standard summation of residual branches by a stochastic affine combination. The largest tested model improves on the best single shot published result on CIFAR-10 by reaching 2.86% test error. Code is available at https://github.com/xgastaldi/shake-shake", "pdf": "/pdf/36d73244aa7b4ade7fde8144ed70cb702fda128b.pdf", "TL;DR": "Reduce overfit by replacing, in a 3-branch ResNet, the standard summation of residual branches by a stochastic affine combination", "paperhash": "gastaldi|shakeshake_regularization_of_3branch_residual_networks", "conflicts": ["n/a"], "authors": ["Xavier Gastaldi"], "authorids": ["xgastaldi.mba2011@london.edu"], "keywords": ["Computer vision", "Deep learning", "Supervised Learning"]}, "tags": [], "invitation": {"tddate": null, "tmdate": 1487296256855, "tcdate": 1487296256855, "id": "ICLR.cc/2017/workshop/-/paper55/public/comment", "writers": ["ICLR.cc/2017/workshop"], "signatures": ["ICLR.cc/2017/workshop"], "readers": ["everyone"], "invitees": ["~"], "noninvitees": ["ICLR.cc/2017/workshop/paper55/reviewers"], "reply": {"forum": "HkO-PCmYl", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/workshop/reviewers", "ICLR.cc/2017/pcs"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,5000}"}}}, "nonreaders": [], "cdate": 1487296256855}}}, {"tddate": null, "tmdate": 1489423573540, "tcdate": 1489423573540, "number": 11, "id": "rJaR2S4jg", "invitation": "ICLR.cc/2017/workshop/-/paper55/public/comment", "forum": "HkO-PCmYl", "replyto": "HkO-PCmYl", "signatures": ["(anonymous)"], "readers": ["everyone"], "writers": ["(anonymous)"], "content": {"title": "Top 1 error or best top 1 error?", "comment": "Please clarify whether the results given in Table 1 correspond to Top 1 of the last epoch or best top 1 error.\nThe reason why I am asking is \nprint(string.format(' * Finished top1: %6.3f  top5: %6.3f', bestTop1, bestTop5)) \nin the end of the main.lua file\nThe difference between the two can be in order of 0.2% or so. \nThe best top 1 error cannot be used because one cannot select networks based on the *test* set.\n\nIf it is the case, then the camera-ready version should fix it.\nI believe that the paper is the best fit for the workshop track."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Shake-Shake regularization of 3-branch residual networks", "abstract": "The method introduced in this paper aims at helping computer vision practitioners faced with an overfit problem. The idea is to replace, in a 3-branch ResNet, the standard summation of residual branches by a stochastic affine combination. The largest tested model improves on the best single shot published result on CIFAR-10 by reaching 2.86% test error. Code is available at https://github.com/xgastaldi/shake-shake", "pdf": "/pdf/36d73244aa7b4ade7fde8144ed70cb702fda128b.pdf", "TL;DR": "Reduce overfit by replacing, in a 3-branch ResNet, the standard summation of residual branches by a stochastic affine combination", "paperhash": "gastaldi|shakeshake_regularization_of_3branch_residual_networks", "conflicts": ["n/a"], "authors": ["Xavier Gastaldi"], "authorids": ["xgastaldi.mba2011@london.edu"], "keywords": ["Computer vision", "Deep learning", "Supervised Learning"]}, "tags": [], "invitation": {"tddate": null, "tmdate": 1487296256855, "tcdate": 1487296256855, "id": "ICLR.cc/2017/workshop/-/paper55/public/comment", "writers": ["ICLR.cc/2017/workshop"], "signatures": ["ICLR.cc/2017/workshop"], "readers": ["everyone"], "invitees": ["~"], "noninvitees": ["ICLR.cc/2017/workshop/paper55/reviewers"], "reply": {"forum": "HkO-PCmYl", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/workshop/reviewers", "ICLR.cc/2017/pcs"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,5000}"}}}, "nonreaders": [], "cdate": 1487296256855}}}, {"tddate": null, "tmdate": 1489188074065, "tcdate": 1489188074065, "number": 2, "id": "SkGgS3gsx", "invitation": "ICLR.cc/2017/workshop/-/paper55/official/review", "forum": "HkO-PCmYl", "replyto": "HkO-PCmYl", "signatures": ["ICLR.cc/2017/workshop/paper55/AnonReviewer1"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/workshop/paper55/AnonReviewer1"], "content": {"title": "Good results, but the explanation is lacking", "rating": "6: Marginally above acceptance threshold", "review": "This paper introduces a particular type of randomness into ResNets activations and shows that this simple modification achieves state of the art performance on CIFAR-10. The idea is to replace each residual function with two residual functions then take a random convex combination of these representations.  Doing this for each image during both the forward and the backward stages (using a newly sampled combination of representations for the backward stage) leads to a fairly small ResNet (26 layers) which achieves 2.71% error on CIFAR-10 and reduces the gap between train and test performance.\n\nThe idea is simple and produces nice, though somewhat incomplete results on CIFAR-10 (it would be nice to see Table 1 filled in completely). However, the motivation for this particular type of stochasticity is not well explained. It is related to similar work like Shakeout and Dropout, but it also leaves out other work which has generally shown that adding noise to activations or weights reduces overfitting [1, 2, 3]. Why should this particular type of noise be better than alternatives?\n\nOn one hand, it is good to continue the discussion about noise injection given novel performance. This paper adds one particularly effective instance of noise injection to that discussion, but it is not well motivated or understood. The ICLR workshop is a good opportunity to discuss reasons for this method's success.\n\nAdditional question:\n\n* How redundant are the two residual representations? Is redundancy increased or decreased by the additional stocasticity?\n\n\n[1] An, Guozhong. \"The effects of adding noise during backpropagation training on a generalization performance.\" Neural computation 8.3 (1996): 643-674.\n\n[2] Blundell, Charles, et al. \"Weight Uncertainty in Neural Network.\" Proceedings of The 32nd International Conference on Machine Learning. 2015.\n\n[3] Neelakantan, Arvind, et al. \"Adding gradient noise improves learning for very deep networks.\" arXiv preprint arXiv:1511.06807 (2015).\n", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Shake-Shake regularization of 3-branch residual networks", "abstract": "The method introduced in this paper aims at helping computer vision practitioners faced with an overfit problem. The idea is to replace, in a 3-branch ResNet, the standard summation of residual branches by a stochastic affine combination. The largest tested model improves on the best single shot published result on CIFAR-10 by reaching 2.86% test error. Code is available at https://github.com/xgastaldi/shake-shake", "pdf": "/pdf/36d73244aa7b4ade7fde8144ed70cb702fda128b.pdf", "TL;DR": "Reduce overfit by replacing, in a 3-branch ResNet, the standard summation of residual branches by a stochastic affine combination", "paperhash": "gastaldi|shakeshake_regularization_of_3branch_residual_networks", "conflicts": ["n/a"], "authors": ["Xavier Gastaldi"], "authorids": ["xgastaldi.mba2011@london.edu"], "keywords": ["Computer vision", "Deep learning", "Supervised Learning"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1489183200000, "tmdate": 1489188074823, "id": "ICLR.cc/2017/workshop/-/paper55/official/review", "writers": ["ICLR.cc/2017/workshop"], "signatures": ["ICLR.cc/2017/workshop"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/workshop/paper55/reviewers"], "noninvitees": ["ICLR.cc/2017/workshop/paper55/AnonReviewer2", "ICLR.cc/2017/workshop/paper55/AnonReviewer1"], "reply": {"forum": "HkO-PCmYl", "replyto": "HkO-PCmYl", "writers": {"values-regex": "ICLR.cc/2017/workshop/paper55/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/workshop/paper55/AnonReviewer[0-9]+"}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "value-regex": "[\\S\\s]{1,5000}"}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1496959200000, "cdate": 1489188074823}}}, {"tddate": null, "tmdate": 1489186918980, "tcdate": 1489186918980, "number": 1, "id": "S1k_e3xsx", "invitation": "ICLR.cc/2017/workshop/-/paper55/official/review", "forum": "HkO-PCmYl", "replyto": "HkO-PCmYl", "signatures": ["ICLR.cc/2017/workshop/paper55/AnonReviewer2"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/workshop/paper55/AnonReviewer2"], "content": {"title": "Review", "rating": "6: Marginally above acceptance threshold", "review": "Approach: Have two residual pathways instead of one, and randomly average them. Backproping through them can use a different mixing coefficient. \n\nPros:\n+ Code is available\n+ Very strong results for CIFAR-10. However, I'm unsure if getting SOTA on CIFAR-10 means anything anymore.\n\nCons:\n- Unclear motivation, other than the desire to add noise. Especially with regards to the different backprop procedure (Shake-Shake)\n- The method is not too novel, and just feels like another variation on Resnets.\n\nI think the results are good, but I'm hesitant to strongly endorse it because of the lack of motivation and minimal novelty.", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Shake-Shake regularization of 3-branch residual networks", "abstract": "The method introduced in this paper aims at helping computer vision practitioners faced with an overfit problem. The idea is to replace, in a 3-branch ResNet, the standard summation of residual branches by a stochastic affine combination. The largest tested model improves on the best single shot published result on CIFAR-10 by reaching 2.86% test error. Code is available at https://github.com/xgastaldi/shake-shake", "pdf": "/pdf/36d73244aa7b4ade7fde8144ed70cb702fda128b.pdf", "TL;DR": "Reduce overfit by replacing, in a 3-branch ResNet, the standard summation of residual branches by a stochastic affine combination", "paperhash": "gastaldi|shakeshake_regularization_of_3branch_residual_networks", "conflicts": ["n/a"], "authors": ["Xavier Gastaldi"], "authorids": ["xgastaldi.mba2011@london.edu"], "keywords": ["Computer vision", "Deep learning", "Supervised Learning"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1489183200000, "tmdate": 1489188074823, "id": "ICLR.cc/2017/workshop/-/paper55/official/review", "writers": ["ICLR.cc/2017/workshop"], "signatures": ["ICLR.cc/2017/workshop"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/workshop/paper55/reviewers"], "noninvitees": ["ICLR.cc/2017/workshop/paper55/AnonReviewer2", "ICLR.cc/2017/workshop/paper55/AnonReviewer1"], "reply": {"forum": "HkO-PCmYl", "replyto": "HkO-PCmYl", "writers": {"values-regex": "ICLR.cc/2017/workshop/paper55/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/workshop/paper55/AnonReviewer[0-9]+"}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "value-regex": "[\\S\\s]{1,5000}"}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1496959200000, "cdate": 1489188074823}}}, {"tddate": null, "tmdate": 1488664737365, "tcdate": 1488664737365, "number": 10, "id": "BkKoO3_qg", "invitation": "ICLR.cc/2017/workshop/-/paper55/public/comment", "forum": "HkO-PCmYl", "replyto": "BJUpXfu9l", "signatures": ["~Xavier_Gastaldi1"], "readers": ["everyone"], "writers": ["~Xavier_Gastaldi1"], "content": {"title": "Re:", "comment": "It has been argued that residual blocks refine/improve on their inputs (\"Highway and Residual Networks learn Unrolled Iterative Estimation\" Greff et al. (2016)). I like this view and my feeling is that the residual blocks provide \"light touches\" rather than \"heavy duty corrections\". If this idea is correct, then altering residual branches will only have a small impact (if done properly).  If alpha_i = 0.3, the output is not the same as if alpha_i = 0.5 but it is probably not too far off and the network is still able to learn. \nIt looks like the same concept applies for the backward pass. By that I mean that the gradients are slightly modified but are still \"plausible\" gradients.\nWrt other regularization techniques, someone would simply have to try."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Shake-Shake regularization of 3-branch residual networks", "abstract": "The method introduced in this paper aims at helping computer vision practitioners faced with an overfit problem. The idea is to replace, in a 3-branch ResNet, the standard summation of residual branches by a stochastic affine combination. The largest tested model improves on the best single shot published result on CIFAR-10 by reaching 2.86% test error. Code is available at https://github.com/xgastaldi/shake-shake", "pdf": "/pdf/36d73244aa7b4ade7fde8144ed70cb702fda128b.pdf", "TL;DR": "Reduce overfit by replacing, in a 3-branch ResNet, the standard summation of residual branches by a stochastic affine combination", "paperhash": "gastaldi|shakeshake_regularization_of_3branch_residual_networks", "conflicts": ["n/a"], "authors": ["Xavier Gastaldi"], "authorids": ["xgastaldi.mba2011@london.edu"], "keywords": ["Computer vision", "Deep learning", "Supervised Learning"]}, "tags": [], "invitation": {"tddate": null, "tmdate": 1487296256855, "tcdate": 1487296256855, "id": "ICLR.cc/2017/workshop/-/paper55/public/comment", "writers": ["ICLR.cc/2017/workshop"], "signatures": ["ICLR.cc/2017/workshop"], "readers": ["everyone"], "invitees": ["~"], "noninvitees": ["ICLR.cc/2017/workshop/paper55/reviewers"], "reply": {"forum": "HkO-PCmYl", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/workshop/reviewers", "ICLR.cc/2017/pcs"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,5000}"}}}, "nonreaders": [], "cdate": 1487296256855}}}, {"tddate": null, "nonreaders": null, "tmdate": 1488622625655, "tcdate": 1488622525901, "number": 9, "id": "BJUpXfu9l", "invitation": "ICLR.cc/2017/workshop/-/paper55/public/comment", "forum": "HkO-PCmYl", "replyto": "ByLYmqf9e", "signatures": ["~Raanan_Hadar1"], "readers": ["everyone"], "writers": ["~Raanan_Hadar1"], "content": {"title": "My comment exactly", "comment": "Thank you for addressing this. This will make the paper much more viable, as this is a common point one would ask.\n\nI still do want to ask if you have any explanation as to why choosing different probabilities for the backward pass (shake shake) results in better performance than the shake-keep setting. If this is the case, shouldn't we attempt to apply this technique on other 'pseudo ensemble' techniques such as classic dropout, stochastic depth and expect improved performance as well?"}, "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Shake-Shake regularization of 3-branch residual networks", "abstract": "The method introduced in this paper aims at helping computer vision practitioners faced with an overfit problem. The idea is to replace, in a 3-branch ResNet, the standard summation of residual branches by a stochastic affine combination. The largest tested model improves on the best single shot published result on CIFAR-10 by reaching 2.86% test error. Code is available at https://github.com/xgastaldi/shake-shake", "pdf": "/pdf/36d73244aa7b4ade7fde8144ed70cb702fda128b.pdf", "TL;DR": "Reduce overfit by replacing, in a 3-branch ResNet, the standard summation of residual branches by a stochastic affine combination", "paperhash": "gastaldi|shakeshake_regularization_of_3branch_residual_networks", "conflicts": ["n/a"], "authors": ["Xavier Gastaldi"], "authorids": ["xgastaldi.mba2011@london.edu"], "keywords": ["Computer vision", "Deep learning", "Supervised Learning"]}, "tags": [], "invitation": {"tddate": null, "tmdate": 1487296256855, "tcdate": 1487296256855, "id": "ICLR.cc/2017/workshop/-/paper55/public/comment", "writers": ["ICLR.cc/2017/workshop"], "signatures": ["ICLR.cc/2017/workshop"], "readers": ["everyone"], "invitees": ["~"], "noninvitees": ["ICLR.cc/2017/workshop/paper55/reviewers"], "reply": {"forum": "HkO-PCmYl", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/workshop/reviewers", "ICLR.cc/2017/pcs"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,5000}"}}}, "nonreaders": [], "cdate": 1487296256855}}}, {"tddate": null, "tmdate": 1488469049791, "tcdate": 1488469049791, "number": 8, "id": "SyfBn3Hqg", "invitation": "ICLR.cc/2017/workshop/-/paper55/public/comment", "forum": "HkO-PCmYl", "replyto": "HkO-PCmYl", "signatures": ["~Xavier_Gastaldi1"], "readers": ["everyone"], "writers": ["~Xavier_Gastaldi1"], "content": {"title": "Updated document", "comment": "The extended abstract was updated following the comments received. I added a placeholder for the other Image level tests. They should be completed within the next 2 weeks."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Shake-Shake regularization of 3-branch residual networks", "abstract": "The method introduced in this paper aims at helping computer vision practitioners faced with an overfit problem. The idea is to replace, in a 3-branch ResNet, the standard summation of residual branches by a stochastic affine combination. The largest tested model improves on the best single shot published result on CIFAR-10 by reaching 2.86% test error. Code is available at https://github.com/xgastaldi/shake-shake", "pdf": "/pdf/36d73244aa7b4ade7fde8144ed70cb702fda128b.pdf", "TL;DR": "Reduce overfit by replacing, in a 3-branch ResNet, the standard summation of residual branches by a stochastic affine combination", "paperhash": "gastaldi|shakeshake_regularization_of_3branch_residual_networks", "conflicts": ["n/a"], "authors": ["Xavier Gastaldi"], "authorids": ["xgastaldi.mba2011@london.edu"], "keywords": ["Computer vision", "Deep learning", "Supervised Learning"]}, "tags": [], "invitation": {"tddate": null, "tmdate": 1487296256855, "tcdate": 1487296256855, "id": "ICLR.cc/2017/workshop/-/paper55/public/comment", "writers": ["ICLR.cc/2017/workshop"], "signatures": ["ICLR.cc/2017/workshop"], "readers": ["everyone"], "invitees": ["~"], "noninvitees": ["ICLR.cc/2017/workshop/paper55/reviewers"], "reply": {"forum": "HkO-PCmYl", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/workshop/reviewers", "ICLR.cc/2017/pcs"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,5000}"}}}, "nonreaders": [], "cdate": 1487296256855}}}, {"tddate": null, "tmdate": 1488320299117, "tcdate": 1488320299117, "number": 7, "id": "SyXEvdQql", "invitation": "ICLR.cc/2017/workshop/-/paper55/public/comment", "forum": "HkO-PCmYl", "replyto": "ByLYmqf9e", "signatures": ["~Xavier_Gastaldi1"], "readers": ["everyone"], "writers": ["~Xavier_Gastaldi1"], "content": {"title": "26 2x32d S-K-I", "comment": "I tested one 26 2x32d \"Shake-Keep-Image\" and the error rate for this model is 4.06%. This is basically the same as for a 26 2x32d \"Shake-Keep-Batch\". \nLinks to the training curves:\n26 2x32d S-K-I vs 26 2x32d S-K-B: http://bit.ly/S-K-I_vs_S-K-B\n26 2x32d S-K-I vs 26 2x32d S-S-I: http://bit.ly/S-K-I_vs_S-S-I\n\nI will update the paper once the other 2 runs are complete.\n"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Shake-Shake regularization of 3-branch residual networks", "abstract": "The method introduced in this paper aims at helping computer vision practitioners faced with an overfit problem. The idea is to replace, in a 3-branch ResNet, the standard summation of residual branches by a stochastic affine combination. The largest tested model improves on the best single shot published result on CIFAR-10 by reaching 2.86% test error. Code is available at https://github.com/xgastaldi/shake-shake", "pdf": "/pdf/36d73244aa7b4ade7fde8144ed70cb702fda128b.pdf", "TL;DR": "Reduce overfit by replacing, in a 3-branch ResNet, the standard summation of residual branches by a stochastic affine combination", "paperhash": "gastaldi|shakeshake_regularization_of_3branch_residual_networks", "conflicts": ["n/a"], "authors": ["Xavier Gastaldi"], "authorids": ["xgastaldi.mba2011@london.edu"], "keywords": ["Computer vision", "Deep learning", "Supervised Learning"]}, "tags": [], "invitation": {"tddate": null, "tmdate": 1487296256855, "tcdate": 1487296256855, "id": "ICLR.cc/2017/workshop/-/paper55/public/comment", "writers": ["ICLR.cc/2017/workshop"], "signatures": ["ICLR.cc/2017/workshop"], "readers": ["everyone"], "invitees": ["~"], "noninvitees": ["ICLR.cc/2017/workshop/paper55/reviewers"], "reply": {"forum": "HkO-PCmYl", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/workshop/reviewers", "ICLR.cc/2017/pcs"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,5000}"}}}, "nonreaders": [], "cdate": 1487296256855}}}, {"tddate": null, "tmdate": 1488262014137, "tcdate": 1488262014137, "number": 6, "id": "ByLYmqf9e", "invitation": "ICLR.cc/2017/workshop/-/paper55/public/comment", "forum": "HkO-PCmYl", "replyto": "S176mJG9e", "signatures": ["~Xavier_Gastaldi1"], "readers": ["everyone"], "writers": ["~Xavier_Gastaldi1"], "content": {"title": "Re: Shake - Keep - Image?", "comment": "Thank you for your interest. I will definitely add these experiments.\nI would have liked to duplicate all the tests done at the Batch level before the submission deadline but the idea to apply this method at the Image level occured to me too late for that."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Shake-Shake regularization of 3-branch residual networks", "abstract": "The method introduced in this paper aims at helping computer vision practitioners faced with an overfit problem. The idea is to replace, in a 3-branch ResNet, the standard summation of residual branches by a stochastic affine combination. The largest tested model improves on the best single shot published result on CIFAR-10 by reaching 2.86% test error. Code is available at https://github.com/xgastaldi/shake-shake", "pdf": "/pdf/36d73244aa7b4ade7fde8144ed70cb702fda128b.pdf", "TL;DR": "Reduce overfit by replacing, in a 3-branch ResNet, the standard summation of residual branches by a stochastic affine combination", "paperhash": "gastaldi|shakeshake_regularization_of_3branch_residual_networks", "conflicts": ["n/a"], "authors": ["Xavier Gastaldi"], "authorids": ["xgastaldi.mba2011@london.edu"], "keywords": ["Computer vision", "Deep learning", "Supervised Learning"]}, "tags": [], "invitation": {"tddate": null, "tmdate": 1487296256855, "tcdate": 1487296256855, "id": "ICLR.cc/2017/workshop/-/paper55/public/comment", "writers": ["ICLR.cc/2017/workshop"], "signatures": ["ICLR.cc/2017/workshop"], "readers": ["everyone"], "invitees": ["~"], "noninvitees": ["ICLR.cc/2017/workshop/paper55/reviewers"], "reply": {"forum": "HkO-PCmYl", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/workshop/reviewers", "ICLR.cc/2017/pcs"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,5000}"}}}, "nonreaders": [], "cdate": 1487296256855}}}, {"tddate": null, "tmdate": 1488217019176, "tcdate": 1488217019176, "number": 5, "id": "S176mJG9e", "invitation": "ICLR.cc/2017/workshop/-/paper55/public/comment", "forum": "HkO-PCmYl", "replyto": "HkO-PCmYl", "signatures": ["(anonymous)"], "readers": ["everyone"], "writers": ["(anonymous)"], "content": {"title": "Shake - Keep - Image?", "comment": "I would like to see numbers for the currently missing from the table 'Shake - Keep - Image' experiment, which is a natural one to include and would directly address one of the main claims of the paper, namely that resampling the gating variable is useful and necessary for the increased test error performance. "}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Shake-Shake regularization of 3-branch residual networks", "abstract": "The method introduced in this paper aims at helping computer vision practitioners faced with an overfit problem. The idea is to replace, in a 3-branch ResNet, the standard summation of residual branches by a stochastic affine combination. The largest tested model improves on the best single shot published result on CIFAR-10 by reaching 2.86% test error. Code is available at https://github.com/xgastaldi/shake-shake", "pdf": "/pdf/36d73244aa7b4ade7fde8144ed70cb702fda128b.pdf", "TL;DR": "Reduce overfit by replacing, in a 3-branch ResNet, the standard summation of residual branches by a stochastic affine combination", "paperhash": "gastaldi|shakeshake_regularization_of_3branch_residual_networks", "conflicts": ["n/a"], "authors": ["Xavier Gastaldi"], "authorids": ["xgastaldi.mba2011@london.edu"], "keywords": ["Computer vision", "Deep learning", "Supervised Learning"]}, "tags": [], "invitation": {"tddate": null, "tmdate": 1487296256855, "tcdate": 1487296256855, "id": "ICLR.cc/2017/workshop/-/paper55/public/comment", "writers": ["ICLR.cc/2017/workshop"], "signatures": ["ICLR.cc/2017/workshop"], "readers": ["everyone"], "invitees": ["~"], "noninvitees": ["ICLR.cc/2017/workshop/paper55/reviewers"], "reply": {"forum": "HkO-PCmYl", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/workshop/reviewers", "ICLR.cc/2017/pcs"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,5000}"}}}, "nonreaders": [], "cdate": 1487296256855}}}, {"tddate": null, "nonreaders": null, "tmdate": 1488197130355, "tcdate": 1488197106419, "number": 4, "id": "BJqlLcZ9g", "invitation": "ICLR.cc/2017/workshop/-/paper55/public/comment", "forum": "HkO-PCmYl", "replyto": "BJYsCOb9l", "signatures": ["~Xavier_Gastaldi1"], "readers": ["everyone"], "writers": ["~Xavier_Gastaldi1"], "content": {"title": " Re:", "comment": "Thank you! I will do that."}, "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Shake-Shake regularization of 3-branch residual networks", "abstract": "The method introduced in this paper aims at helping computer vision practitioners faced with an overfit problem. The idea is to replace, in a 3-branch ResNet, the standard summation of residual branches by a stochastic affine combination. The largest tested model improves on the best single shot published result on CIFAR-10 by reaching 2.86% test error. Code is available at https://github.com/xgastaldi/shake-shake", "pdf": "/pdf/36d73244aa7b4ade7fde8144ed70cb702fda128b.pdf", "TL;DR": "Reduce overfit by replacing, in a 3-branch ResNet, the standard summation of residual branches by a stochastic affine combination", "paperhash": "gastaldi|shakeshake_regularization_of_3branch_residual_networks", "conflicts": ["n/a"], "authors": ["Xavier Gastaldi"], "authorids": ["xgastaldi.mba2011@london.edu"], "keywords": ["Computer vision", "Deep learning", "Supervised Learning"]}, "tags": [], "invitation": {"tddate": null, "tmdate": 1487296256855, "tcdate": 1487296256855, "id": "ICLR.cc/2017/workshop/-/paper55/public/comment", "writers": ["ICLR.cc/2017/workshop"], "signatures": ["ICLR.cc/2017/workshop"], "readers": ["everyone"], "invitees": ["~"], "noninvitees": ["ICLR.cc/2017/workshop/paper55/reviewers"], "reply": {"forum": "HkO-PCmYl", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/workshop/reviewers", "ICLR.cc/2017/pcs"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,5000}"}}}, "nonreaders": [], "cdate": 1487296256855}}}, {"tddate": null, "tmdate": 1488191137000, "tcdate": 1488191137000, "number": 3, "id": "BJYsCOb9l", "invitation": "ICLR.cc/2017/workshop/-/paper55/public/comment", "forum": "HkO-PCmYl", "replyto": "rkAlp4Ctl", "signatures": ["(anonymous)"], "readers": ["everyone"], "writers": ["(anonymous)"], "content": {"title": "Re: ", "comment": "I am not assigned to this paper but I would suggest to mention the Shakeout work in one line/sentence and refer to the appendix where differences/similarities with the Shakeout are analysed."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Shake-Shake regularization of 3-branch residual networks", "abstract": "The method introduced in this paper aims at helping computer vision practitioners faced with an overfit problem. The idea is to replace, in a 3-branch ResNet, the standard summation of residual branches by a stochastic affine combination. The largest tested model improves on the best single shot published result on CIFAR-10 by reaching 2.86% test error. Code is available at https://github.com/xgastaldi/shake-shake", "pdf": "/pdf/36d73244aa7b4ade7fde8144ed70cb702fda128b.pdf", "TL;DR": "Reduce overfit by replacing, in a 3-branch ResNet, the standard summation of residual branches by a stochastic affine combination", "paperhash": "gastaldi|shakeshake_regularization_of_3branch_residual_networks", "conflicts": ["n/a"], "authors": ["Xavier Gastaldi"], "authorids": ["xgastaldi.mba2011@london.edu"], "keywords": ["Computer vision", "Deep learning", "Supervised Learning"]}, "tags": [], "invitation": {"tddate": null, "tmdate": 1487296256855, "tcdate": 1487296256855, "id": "ICLR.cc/2017/workshop/-/paper55/public/comment", "writers": ["ICLR.cc/2017/workshop"], "signatures": ["ICLR.cc/2017/workshop"], "readers": ["everyone"], "invitees": ["~"], "noninvitees": ["ICLR.cc/2017/workshop/paper55/reviewers"], "reply": {"forum": "HkO-PCmYl", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/workshop/reviewers", "ICLR.cc/2017/pcs"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,5000}"}}}, "nonreaders": [], "cdate": 1487296256855}}}, {"tddate": null, "nonreaders": null, "tmdate": 1488028542377, "tcdate": 1487977717857, "number": 2, "id": "rkAlp4Ctl", "invitation": "ICLR.cc/2017/workshop/-/paper55/public/comment", "forum": "HkO-PCmYl", "replyto": "BJsmmYaKg", "signatures": ["~Xavier_Gastaldi1"], "readers": ["everyone"], "writers": ["~Xavier_Gastaldi1"], "content": {"title": "Shake-Shake vs Shakeout", "comment": "It is probably a fair question given that paper\u2019s name :).\n\nSimilarities:\nBoth methods use the idea of replacing 0s and 1s by scaling coefficients. \n\nDifferences: \n1. Starting points: The starting point for Shakeout is Dropout while the starting point for Shake-Shake is a mix of FractalNet drop-path and stochastic depth (if you imagine applying drop-path to a 3 branch ResNet where the skip connection is never dropped). Dropping a path is equivalent to setting alpha_i to 0 or 1 in the Shake-Shake paper.\n2. Multiplications: Both Dropout and Shakeout perform an element-wise multiplication between 2 tensors. In the case of Dropout, the usual steps are to: 1. Create a tensor (let\u2019s call it self.noise) of the same size as the input tensor. 2. Fill self.noise with 0s or 1s taken from a Bernoulli distribution. 3. Perform an element-wise multiplication between self.noise and the original input (see https://github.com/torch/nn/blob/master/Dropout.lua Lns 25 26 and 30). In the case of Shakeout the Bernoulli distribution is replaced by eq (1) in the Shakeout paper. Shake-Shake, on the other hand, multiplies the whole mini-batch tensor with just one scalar alpha_i (or 1-alpha_i). Applying Shake-Shake regularization at the \u00ab\u00a0Image\u00a0\u00bb level is slightly more complex but follows the same logic. Let\u2019s imagine that the original input mini-batch is a 128x3x32x32 tensor. The first dimension \u00ab\u00a0stacks\u00a0\u00bb 128 images of dimensions 3x32x32. Inside the second stage of a 26 2x32d model, this tensor has been transformed into a 128x64x16x16 tensor. Applying Shake-Shake regularization at the \u00ab\u00a0Image\u00a0\u00bb level means slicing this tensor along the first dimension and, for each of the 128 slices, multiplying the jth slice (of dimensions 64x16x16) with a scalar alpha_i_j (or 1-alpha_i_j).\n3. Forward - Backward: Shakeout keeps the same coefficients between the Forward and Backward passes whereas Shake-Shake updates them before each pass (Forward and Backward)\n4. Number of flows: Shake-Shake regularization works by summing up 2 residual flows plus a skip connection whereas Shakeout only needs one flow\n\nQuestion for the reviewer:\nI found out about Shakeout after submitting the extended abstract. If possible, I would like to ask the reviewer for his opinion on whether this paper must be added to the relevant work section. While I think it shares the idea of replacing bernoulli variables with scaling coefficients, the challenge I have is simply that the 3 pages limit makes it very difficult to add new information without removing text somewhere else..."}, "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Shake-Shake regularization of 3-branch residual networks", "abstract": "The method introduced in this paper aims at helping computer vision practitioners faced with an overfit problem. The idea is to replace, in a 3-branch ResNet, the standard summation of residual branches by a stochastic affine combination. The largest tested model improves on the best single shot published result on CIFAR-10 by reaching 2.86% test error. Code is available at https://github.com/xgastaldi/shake-shake", "pdf": "/pdf/36d73244aa7b4ade7fde8144ed70cb702fda128b.pdf", "TL;DR": "Reduce overfit by replacing, in a 3-branch ResNet, the standard summation of residual branches by a stochastic affine combination", "paperhash": "gastaldi|shakeshake_regularization_of_3branch_residual_networks", "conflicts": ["n/a"], "authors": ["Xavier Gastaldi"], "authorids": ["xgastaldi.mba2011@london.edu"], "keywords": ["Computer vision", "Deep learning", "Supervised Learning"]}, "tags": [], "invitation": {"tddate": null, "tmdate": 1487296256855, "tcdate": 1487296256855, "id": "ICLR.cc/2017/workshop/-/paper55/public/comment", "writers": ["ICLR.cc/2017/workshop"], "signatures": ["ICLR.cc/2017/workshop"], "readers": ["everyone"], "invitees": ["~"], "noninvitees": ["ICLR.cc/2017/workshop/paper55/reviewers"], "reply": {"forum": "HkO-PCmYl", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/workshop/reviewers", "ICLR.cc/2017/pcs"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,5000}"}}}, "nonreaders": [], "cdate": 1487296256855}}}, {"tddate": null, "tmdate": 1487930147254, "tcdate": 1487930147254, "number": 1, "id": "BJsmmYaKg", "invitation": "ICLR.cc/2017/workshop/-/paper55/public/comment", "forum": "HkO-PCmYl", "replyto": "HkO-PCmYl", "signatures": ["(anonymous)"], "readers": ["everyone"], "writers": ["(anonymous)"], "content": {"title": "Shakeout", "comment": "The results are impressive!\nPlease discuss how the proposed approach is similar/different to \n\"Shakeout: A New Regularized Deep Neural Network Training Scheme\", AAAI-2016, by Guoliang Kang, Jun Li, Dacheng Tao\nhttp://www.aaai.org/ocs/index.php/AAAI/AAAI16/paper/view/11840/11800 "}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Shake-Shake regularization of 3-branch residual networks", "abstract": "The method introduced in this paper aims at helping computer vision practitioners faced with an overfit problem. The idea is to replace, in a 3-branch ResNet, the standard summation of residual branches by a stochastic affine combination. The largest tested model improves on the best single shot published result on CIFAR-10 by reaching 2.86% test error. Code is available at https://github.com/xgastaldi/shake-shake", "pdf": "/pdf/36d73244aa7b4ade7fde8144ed70cb702fda128b.pdf", "TL;DR": "Reduce overfit by replacing, in a 3-branch ResNet, the standard summation of residual branches by a stochastic affine combination", "paperhash": "gastaldi|shakeshake_regularization_of_3branch_residual_networks", "conflicts": ["n/a"], "authors": ["Xavier Gastaldi"], "authorids": ["xgastaldi.mba2011@london.edu"], "keywords": ["Computer vision", "Deep learning", "Supervised Learning"]}, "tags": [], "invitation": {"tddate": null, "tmdate": 1487296256855, "tcdate": 1487296256855, "id": "ICLR.cc/2017/workshop/-/paper55/public/comment", "writers": ["ICLR.cc/2017/workshop"], "signatures": ["ICLR.cc/2017/workshop"], "readers": ["everyone"], "invitees": ["~"], "noninvitees": ["ICLR.cc/2017/workshop/paper55/reviewers"], "reply": {"forum": "HkO-PCmYl", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/workshop/reviewers", "ICLR.cc/2017/pcs"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,5000}"}}}, "nonreaders": [], "cdate": 1487296256855}}}], "count": 25}