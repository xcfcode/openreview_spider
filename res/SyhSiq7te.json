{"notes": [{"tddate": null, "ddate": null, "cdate": null, "original": null, "tmdate": 1490028569405, "tcdate": 1490028569405, "number": 1, "id": "HkWmuK6og", "invitation": "ICLR.cc/2017/workshop/-/paper47/acceptance", "forum": "SyhSiq7te", "replyto": "SyhSiq7te", "signatures": ["ICLR.cc/2017/pcs"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/pcs"], "content": {"decision": "Reject", "title": "ICLR committee final decision"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Class-based Prediction Errors to Categorize Text with Out-of-vocabulary Words", "abstract": "Common approaches to text categorization essentially rely either on n-gram counts or on word embeddings. This presents important difficulties in highly dynamic or quickly-interacting environments, where the appearance of new words and/or varied misspellings is the norm. To better deal with these issues, we propose to use the error signal of class-based language models as input to text classification algorithms. In particular, we train a next-character prediction model for any given class, and then exploit the error of such class-based models to inform a neural network classifier. This way, we shift from the 'ability to describe' seen documents to the 'ability to predict' unseen content. Preliminary studies using out-of-vocabulary splits from abusive tweet data show promising results, outperforming competitive text categorization strategies by 4-11%.", "pdf": "/pdf/7a90f84736274cb85df19fd6e113a3141a311047.pdf", "TL;DR": "Using class-based prediction errors is a promising strategy to classify text with out-of-vocabulary words", "paperhash": "serr\u00e0|classbased_prediction_errors_to_categorize_text_with_outofvocabulary_words", "keywords": ["Natural language processing", "Applications"], "conflicts": ["telefonica.com", "auth.gr", "ucl.ac.uk"], "authors": ["Joan Serr\u00e0", "Ilias Leontiadis", "Dimitris Spathis", "Gianluca Stringhini", "Jeremy Blackburn"], "authorids": ["joan.serra@telefonica.com", "ilias.leontiadis@telefonica.com", "sdimitris@csd.auth.gr", "g.stringhini@ucl.ac.uk", "jeremy.blackburn@telefonica.com"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "tmdate": 1490028569951, "id": "ICLR.cc/2017/workshop/-/paper47/acceptance", "writers": ["ICLR.cc/2017/workshop"], "signatures": ["ICLR.cc/2017/workshop"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/pcs"], "noninvitees": ["ICLR.cc/2017/pcs"], "reply": {"forum": "SyhSiq7te", "replyto": "SyhSiq7te", "writers": {"values-regex": "ICLR.cc/2017/pcs"}, "signatures": {"values-regex": "ICLR.cc/2017/pcs", "description": "Your displayed identity associated with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your decision.", "value": "ICLR committee final decision"}, "decision": {"required": true, "order": 3, "value-radio": ["Accept", "Reject"]}}}, "nonreaders": [], "cdate": 1490028569951}}}, {"tddate": null, "tmdate": 1489659270688, "tcdate": 1489659270688, "number": 2, "id": "rJJ9HJ_jx", "invitation": "ICLR.cc/2017/workshop/-/paper47/public/comment", "forum": "SyhSiq7te", "replyto": "HJ1B2tSsg", "signatures": ["~Joan_Serr\u00e01"], "readers": ["everyone"], "writers": ["~Joan_Serr\u00e01"], "content": {"title": "Answer to \"review\"", "comment": "Thanks for your answer and the \"pros\" mentioned. We now contrast the \"cons\".\n\n1) We did not run that test, but it is not clear why we need a single LM in the first place. Our intuition is that we would see much less discrimination capability with a single LM trained on the whole corpus.\n\n2) The number of OOV words in the two classes in the Hard data set is similar by construction of the data set. We would be very grateful if the reviewer could point us to such aforementioned baselines that take into account OOV words.\n\n3) We need at least one layer of an another neural network to form the binary classification (after the language model we have as many errors as characters). A second layer is added to allow the model to perform nonlinear classification based on the error sequences. Regarding normalization, our initial experiments involved no normalization and the performance was much poorer, to the level of the considered alternatives or slightly below.\n\n4) We would be very grateful if the reviewer could point us to such well-established benchmark task explicitly involving OOV words."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Class-based Prediction Errors to Categorize Text with Out-of-vocabulary Words", "abstract": "Common approaches to text categorization essentially rely either on n-gram counts or on word embeddings. This presents important difficulties in highly dynamic or quickly-interacting environments, where the appearance of new words and/or varied misspellings is the norm. To better deal with these issues, we propose to use the error signal of class-based language models as input to text classification algorithms. In particular, we train a next-character prediction model for any given class, and then exploit the error of such class-based models to inform a neural network classifier. This way, we shift from the 'ability to describe' seen documents to the 'ability to predict' unseen content. Preliminary studies using out-of-vocabulary splits from abusive tweet data show promising results, outperforming competitive text categorization strategies by 4-11%.", "pdf": "/pdf/7a90f84736274cb85df19fd6e113a3141a311047.pdf", "TL;DR": "Using class-based prediction errors is a promising strategy to classify text with out-of-vocabulary words", "paperhash": "serr\u00e0|classbased_prediction_errors_to_categorize_text_with_outofvocabulary_words", "keywords": ["Natural language processing", "Applications"], "conflicts": ["telefonica.com", "auth.gr", "ucl.ac.uk"], "authors": ["Joan Serr\u00e0", "Ilias Leontiadis", "Dimitris Spathis", "Gianluca Stringhini", "Jeremy Blackburn"], "authorids": ["joan.serra@telefonica.com", "ilias.leontiadis@telefonica.com", "sdimitris@csd.auth.gr", "g.stringhini@ucl.ac.uk", "jeremy.blackburn@telefonica.com"]}, "tags": [], "invitation": {"tddate": null, "tmdate": 1487280964500, "tcdate": 1487280964500, "id": "ICLR.cc/2017/workshop/-/paper47/public/comment", "writers": ["ICLR.cc/2017/workshop"], "signatures": ["ICLR.cc/2017/workshop"], "readers": ["everyone"], "invitees": ["~"], "noninvitees": ["ICLR.cc/2017/workshop/paper47/reviewers"], "reply": {"forum": "SyhSiq7te", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/workshop/reviewers", "ICLR.cc/2017/pcs"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,5000}"}}}, "nonreaders": [], "cdate": 1487280964500}}}, {"tddate": null, "tmdate": 1489505335083, "tcdate": 1489505335083, "number": 2, "id": "HJ1B2tSsg", "invitation": "ICLR.cc/2017/workshop/-/paper47/official/review", "forum": "SyhSiq7te", "replyto": "SyhSiq7te", "signatures": ["ICLR.cc/2017/workshop/paper47/AnonReviewer1"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/workshop/paper47/AnonReviewer1"], "content": {"title": "review", "rating": "4: Ok but not good enough - rejection", "review": "This paper proposes to use character-level language model errors as features for text categorization tasks. While the paper is well-written and the experiments show gains over baseline methods on an abusive language detection task, I don't think this paper fits within the goals of the workshop: it does not contain anything novel on the ML side, and the task is more of interest to the NLP community. I hope the authors can apply their method to different tasks in future versions of the paper, and also try to better motivate their architecture design decisions.\n\npros:\n- good result on abusive language detection task compared to baseline models\n- the paper is well-written, it is clear what the task is and how the model architecture is designed\n\ncons:\n- not clear why you need a language model for each class, how does this compare to just training a single LM over the entire dataset and using its error as a feature?\n- how does this method compare to just counting the number of unknown words per example and using that as a feature? i don't think the current experiments compare the proposed method against appropriate baselines, you need baselines that take into account OOV words\n- the \"instance normalization\" is not well-motivated, why use it over just the raw error vector? and why further pass it through another neural network? \n- the task is very specific and not a standard text categorization problem. it would be nice to demonstrate the method's effectiveness on a variety of well-established benchmark tasks.", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Class-based Prediction Errors to Categorize Text with Out-of-vocabulary Words", "abstract": "Common approaches to text categorization essentially rely either on n-gram counts or on word embeddings. This presents important difficulties in highly dynamic or quickly-interacting environments, where the appearance of new words and/or varied misspellings is the norm. To better deal with these issues, we propose to use the error signal of class-based language models as input to text classification algorithms. In particular, we train a next-character prediction model for any given class, and then exploit the error of such class-based models to inform a neural network classifier. This way, we shift from the 'ability to describe' seen documents to the 'ability to predict' unseen content. Preliminary studies using out-of-vocabulary splits from abusive tweet data show promising results, outperforming competitive text categorization strategies by 4-11%.", "pdf": "/pdf/7a90f84736274cb85df19fd6e113a3141a311047.pdf", "TL;DR": "Using class-based prediction errors is a promising strategy to classify text with out-of-vocabulary words", "paperhash": "serr\u00e0|classbased_prediction_errors_to_categorize_text_with_outofvocabulary_words", "keywords": ["Natural language processing", "Applications"], "conflicts": ["telefonica.com", "auth.gr", "ucl.ac.uk"], "authors": ["Joan Serr\u00e0", "Ilias Leontiadis", "Dimitris Spathis", "Gianluca Stringhini", "Jeremy Blackburn"], "authorids": ["joan.serra@telefonica.com", "ilias.leontiadis@telefonica.com", "sdimitris@csd.auth.gr", "g.stringhini@ucl.ac.uk", "jeremy.blackburn@telefonica.com"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1489183200000, "tmdate": 1489505335834, "id": "ICLR.cc/2017/workshop/-/paper47/official/review", "writers": ["ICLR.cc/2017/workshop"], "signatures": ["ICLR.cc/2017/workshop"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/workshop/paper47/reviewers"], "noninvitees": ["ICLR.cc/2017/workshop/paper47/AnonReviewer2", "ICLR.cc/2017/workshop/paper47/AnonReviewer1"], "reply": {"forum": "SyhSiq7te", "replyto": "SyhSiq7te", "writers": {"values-regex": "ICLR.cc/2017/workshop/paper47/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/workshop/paper47/AnonReviewer[0-9]+"}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "value-regex": "[\\S\\s]{1,5000}"}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1496959200000, "cdate": 1489505335834}}}, {"tddate": null, "tmdate": 1488811992369, "tcdate": 1488811992369, "number": 1, "id": "Bye1uljcx", "invitation": "ICLR.cc/2017/workshop/-/paper47/public/comment", "forum": "SyhSiq7te", "replyto": "BJOLIjF9e", "signatures": ["~Joan_Serr\u00e01"], "readers": ["everyone"], "writers": ["~Joan_Serr\u00e01"], "content": {"title": "Answer to \"Borderline\"", "comment": "Thanks for your comments and your time in reviewing the paper. We now answer to the two specific questions and also relate to the cons above.\n\n1) We believe that the idea of training class-based prediction models and using their predictions as part of other networks and tasks is very novel. We decided not to submit the paper to an NLP workshop because the proposed strategy can be relevant across disciplines and not restricted to NLP. Also the out-of-vocabulary problem (which, to the best of our knowledge, has no standard benchmark data sets yet) may present analogies in other domains. We here use data from an important real problem (detecting abusive tweets) and show that the approach is worth using in practice (\"easy\" data set), outperforming well-known baselines.\n\n2) We considered the use of the aforementioned PReLU from the very beginning. Our intuition was that it could not harm the performance of the model, as a linear (non-altering) transform can in principle be learned if that is the real best option. Otherwise, we can only gain performance by learning the non-linearity. If needed, we can re-run the experiments without it and quantitatively evaluate the difference."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Class-based Prediction Errors to Categorize Text with Out-of-vocabulary Words", "abstract": "Common approaches to text categorization essentially rely either on n-gram counts or on word embeddings. This presents important difficulties in highly dynamic or quickly-interacting environments, where the appearance of new words and/or varied misspellings is the norm. To better deal with these issues, we propose to use the error signal of class-based language models as input to text classification algorithms. In particular, we train a next-character prediction model for any given class, and then exploit the error of such class-based models to inform a neural network classifier. This way, we shift from the 'ability to describe' seen documents to the 'ability to predict' unseen content. Preliminary studies using out-of-vocabulary splits from abusive tweet data show promising results, outperforming competitive text categorization strategies by 4-11%.", "pdf": "/pdf/7a90f84736274cb85df19fd6e113a3141a311047.pdf", "TL;DR": "Using class-based prediction errors is a promising strategy to classify text with out-of-vocabulary words", "paperhash": "serr\u00e0|classbased_prediction_errors_to_categorize_text_with_outofvocabulary_words", "keywords": ["Natural language processing", "Applications"], "conflicts": ["telefonica.com", "auth.gr", "ucl.ac.uk"], "authors": ["Joan Serr\u00e0", "Ilias Leontiadis", "Dimitris Spathis", "Gianluca Stringhini", "Jeremy Blackburn"], "authorids": ["joan.serra@telefonica.com", "ilias.leontiadis@telefonica.com", "sdimitris@csd.auth.gr", "g.stringhini@ucl.ac.uk", "jeremy.blackburn@telefonica.com"]}, "tags": [], "invitation": {"tddate": null, "tmdate": 1487280964500, "tcdate": 1487280964500, "id": "ICLR.cc/2017/workshop/-/paper47/public/comment", "writers": ["ICLR.cc/2017/workshop"], "signatures": ["ICLR.cc/2017/workshop"], "readers": ["everyone"], "invitees": ["~"], "noninvitees": ["ICLR.cc/2017/workshop/paper47/reviewers"], "reply": {"forum": "SyhSiq7te", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/workshop/reviewers", "ICLR.cc/2017/pcs"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,5000}"}}}, "nonreaders": [], "cdate": 1487280964500}}}, {"tddate": null, "tmdate": 1488725584111, "tcdate": 1488725584111, "number": 1, "id": "BJOLIjF9e", "invitation": "ICLR.cc/2017/workshop/-/paper47/official/review", "forum": "SyhSiq7te", "replyto": "SyhSiq7te", "signatures": ["ICLR.cc/2017/workshop/paper47/AnonReviewer2"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/workshop/paper47/AnonReviewer2"], "content": {"title": "Borderline", "rating": "5: Marginally below acceptance threshold", "review": "This paper proposes to do short-text classification by training a character-level RNN language model on each class, and to then use the error rates of each language model in predicting the next character in a test string as a source of features for use when classifying that string.\n\nPros:\n\u2013 Empirical results on abusive tweet detection are strong. \n\nCons:\n\u2013 It's not clear why this technique works, and with an evaluation on only one somewhat marginal NLP task, it's hard to know if when (if ever) this technique is worth using in practice.\n\u2013 This work seems a bit too narrow in scope to count as exciting late-breaking work. I think this idea would be best presented as a short paper at an NLP workshop, or fleshed out on a broader range of tasks, analyzed a bit, and presented as a regular long paper.\n\nQuestions:\n\u2013 High-level: Could you comment on how this fits with the stated goals of the workshop?\n\u2013 Detail: If I understand correctly, the input words are embedded, and the embeddings are then fed through a PReLU before being used in the class-conditional GRU RNNs. This seems like an odd use for a nonlinearity\u2014did adding the PReLU help?\n\n", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Class-based Prediction Errors to Categorize Text with Out-of-vocabulary Words", "abstract": "Common approaches to text categorization essentially rely either on n-gram counts or on word embeddings. This presents important difficulties in highly dynamic or quickly-interacting environments, where the appearance of new words and/or varied misspellings is the norm. To better deal with these issues, we propose to use the error signal of class-based language models as input to text classification algorithms. In particular, we train a next-character prediction model for any given class, and then exploit the error of such class-based models to inform a neural network classifier. This way, we shift from the 'ability to describe' seen documents to the 'ability to predict' unseen content. Preliminary studies using out-of-vocabulary splits from abusive tweet data show promising results, outperforming competitive text categorization strategies by 4-11%.", "pdf": "/pdf/7a90f84736274cb85df19fd6e113a3141a311047.pdf", "TL;DR": "Using class-based prediction errors is a promising strategy to classify text with out-of-vocabulary words", "paperhash": "serr\u00e0|classbased_prediction_errors_to_categorize_text_with_outofvocabulary_words", "keywords": ["Natural language processing", "Applications"], "conflicts": ["telefonica.com", "auth.gr", "ucl.ac.uk"], "authors": ["Joan Serr\u00e0", "Ilias Leontiadis", "Dimitris Spathis", "Gianluca Stringhini", "Jeremy Blackburn"], "authorids": ["joan.serra@telefonica.com", "ilias.leontiadis@telefonica.com", "sdimitris@csd.auth.gr", "g.stringhini@ucl.ac.uk", "jeremy.blackburn@telefonica.com"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1489183200000, "tmdate": 1489505335834, "id": "ICLR.cc/2017/workshop/-/paper47/official/review", "writers": ["ICLR.cc/2017/workshop"], "signatures": ["ICLR.cc/2017/workshop"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/workshop/paper47/reviewers"], "noninvitees": ["ICLR.cc/2017/workshop/paper47/AnonReviewer2", "ICLR.cc/2017/workshop/paper47/AnonReviewer1"], "reply": {"forum": "SyhSiq7te", "replyto": "SyhSiq7te", "writers": {"values-regex": "ICLR.cc/2017/workshop/paper47/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/workshop/paper47/AnonReviewer[0-9]+"}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "value-regex": "[\\S\\s]{1,5000}"}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1496959200000, "cdate": 1489505335834}}}, {"tddate": null, "replyto": null, "nonreaders": null, "ddate": null, "tmdate": 1487336048961, "tcdate": 1487280963748, "number": 47, "id": "SyhSiq7te", "invitation": "ICLR.cc/2017/workshop/-/submission", "forum": "SyhSiq7te", "signatures": ["~Joan_Serr\u00e01"], "readers": ["everyone"], "content": {"title": "Class-based Prediction Errors to Categorize Text with Out-of-vocabulary Words", "abstract": "Common approaches to text categorization essentially rely either on n-gram counts or on word embeddings. This presents important difficulties in highly dynamic or quickly-interacting environments, where the appearance of new words and/or varied misspellings is the norm. To better deal with these issues, we propose to use the error signal of class-based language models as input to text classification algorithms. In particular, we train a next-character prediction model for any given class, and then exploit the error of such class-based models to inform a neural network classifier. This way, we shift from the 'ability to describe' seen documents to the 'ability to predict' unseen content. Preliminary studies using out-of-vocabulary splits from abusive tweet data show promising results, outperforming competitive text categorization strategies by 4-11%.", "pdf": "/pdf/7a90f84736274cb85df19fd6e113a3141a311047.pdf", "TL;DR": "Using class-based prediction errors is a promising strategy to classify text with out-of-vocabulary words", "paperhash": "serr\u00e0|classbased_prediction_errors_to_categorize_text_with_outofvocabulary_words", "keywords": ["Natural language processing", "Applications"], "conflicts": ["telefonica.com", "auth.gr", "ucl.ac.uk"], "authors": ["Joan Serr\u00e0", "Ilias Leontiadis", "Dimitris Spathis", "Gianluca Stringhini", "Jeremy Blackburn"], "authorids": ["joan.serra@telefonica.com", "ilias.leontiadis@telefonica.com", "sdimitris@csd.auth.gr", "g.stringhini@ucl.ac.uk", "jeremy.blackburn@telefonica.com"]}, "writers": [], "details": {"replyCount": 5, "writable": false, "overwriting": [], "revisions": false, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1487690420000, "tmdate": 1484242559574, "id": "ICLR.cc/2017/workshop/-/submission", "writers": ["ICLR.cc/2017/workshop"], "signatures": ["ICLR.cc/2017/pcs"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": null, "replyto": null, "writers": {"values-regex": "~.*"}, "signatures": {"values-regex": "~.*", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"pdf": {"required": true, "order": 5, "description": "Either upload a PDF file or provide a direct link to your PDF on ArXiv (link must begin with http(s) and end with .pdf)", "value-regex": "upload|(http|https):\\/\\/.+\\.pdf"}, "title": {"required": true, "order": 1, "description": "Title of paper.", "value-regex": ".{1,250}"}, "abstract": {"required": true, "order": 4, "description": "Abstract of paper.", "value-regex": "[\\S\\s]{1,5000}"}, "authors": {"required": true, "order": 2, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of author names, as they appear in the paper."}, "conflicts": {"required": true, "order": 100, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of email domains of people who would have a conflict of interest in reviewing this paper, (e.g., cs.umass.edu;google.com, etc.)."}, "keywords": {"order": 6, "description": "Comma separated list of keywords.", "values-dropdown": ["Theory", "Computer vision", "Speech", "Natural language processing", "Deep learning", "Unsupervised Learning", "Supervised Learning", "Semi-Supervised Learning", "Reinforcement Learning", "Transfer Learning", "Multi-modal learning", "Applications", "Optimization", "Structured prediction", "Games"]}, "TL;DR": {"required": false, "order": 3, "description": "\"Too Long; Didn't Read\": a short sentence describing your paper", "value-regex": "[^\\n]{0,250}"}, "authorids": {"required": true, "order": 3, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of author email addresses, in the same order as above."}}}, "nonreaders": [], "noninvitees": [], "expdate": 1495466420000, "cdate": 1484242559574}}}], "count": 6}