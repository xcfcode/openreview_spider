{"notes": [{"id": "SkgE8sRcK7", "original": "Bkgut0kct7", "number": 164, "cdate": 1538087755642, "ddate": null, "tcdate": 1538087755642, "tmdate": 1545355385727, "tddate": null, "forum": "SkgE8sRcK7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Sample Efficient Deep Neuroevolution in Low Dimensional Latent Space", "abstract": "Current deep neuroevolution models are usually trained in a large parameter search space for complex learning tasks, e.g. playing video games, which needs billions of samples and thousands of search steps to obtain significant performance. This raises a question of whether we can make use of sequential data generated during evolution, encode input samples, and evolve in low dimensional parameter space with latent state input in a fast and efficient manner. Here we give an affirmative answer: we train a VAE to encode input samples, then an RNN to model environment dynamics and handle temporal information, and last evolve our low dimensional policy network in latent space. We demonstrate that this approach is surprisingly efficient: our experiments on Atari games show that within 10M frames and 30 evolution steps of training, our algorithm could achieve competitive result compared with ES, A3C, and DQN which need billions of frames.", "keywords": ["Neuroevolution", "Reinforcement Learning"], "authorids": ["bin.zhou@u.nus.edu", "elefjia@u.nus.edu"], "authors": ["Bin Zhou", "Jiashi Feng"], "pdf": "/pdf/56396e3ca3b58a8f300427f463aba9f2236e97c7.pdf", "paperhash": "zhou|sample_efficient_deep_neuroevolution_in_low_dimensional_latent_space", "_bibtex": "@misc{\nzhou2019sample,\ntitle={Sample Efficient Deep Neuroevolution in Low Dimensional Latent Space},\nauthor={Bin Zhou and Jiashi Feng},\nyear={2019},\nurl={https://openreview.net/forum?id=SkgE8sRcK7},\n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"replyCount": 4, "writable": false, "overwriting": [], "revisions": false, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Blind_Submission", "rdate": null, "ddate": null, "expdate": null, "duedate": 1538085600000, "tmdate": 1538142958393, "tddate": null, "super": null, "final": null, "reply": {"signatures": {"values": ["ICLR.cc/2019/Conference"]}, "forum": null, "readers": {"values": ["everyone"]}, "replyto": null, "content": {"authorids": {"values-regex": ".*"}, "authors": {"values": ["Anonymous"]}}, "writers": {"values": ["ICLR.cc/2019/Conference"]}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["~"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": null, "taskCompletionCount": null, "transform": null, "cdate": 1538142958393}}, "tauthor": "OpenReview.net"}, {"id": "rJevyofbxE", "original": null, "number": 1, "cdate": 1544788702528, "ddate": null, "tcdate": 1544788702528, "tmdate": 1545354524514, "tddate": null, "forum": "SkgE8sRcK7", "replyto": "SkgE8sRcK7", "invitation": "ICLR.cc/2019/Conference/-/Paper164/Meta_Review", "content": {"metareview": "Pros:\n- compelling idea to use VAEs to reduce the dimensionality of the space in which to run evolution\n- non-trivial benchmark results\n- clearly written, solid background\n\nCons:\n- moderate novelty (as compared to [1])\n- performance results are sup-par\n- no rebuttal, despite constructive and detailed review comments (and an explicit willingness to raise scores by multiple points!)\n\nThe reviewers agree that the paper should be rejected in its current form, but would plausibly have been willing to reassess their scores for a major revision -- which did not materialize.", "confidence": "5: The area chair is absolutely certain", "recommendation": "Reject", "title": "Meta-review"}, "signatures": ["ICLR.cc/2019/Conference/Paper164/Area_Chair1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference/Paper164/Area_Chair1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Sample Efficient Deep Neuroevolution in Low Dimensional Latent Space", "abstract": "Current deep neuroevolution models are usually trained in a large parameter search space for complex learning tasks, e.g. playing video games, which needs billions of samples and thousands of search steps to obtain significant performance. This raises a question of whether we can make use of sequential data generated during evolution, encode input samples, and evolve in low dimensional parameter space with latent state input in a fast and efficient manner. Here we give an affirmative answer: we train a VAE to encode input samples, then an RNN to model environment dynamics and handle temporal information, and last evolve our low dimensional policy network in latent space. We demonstrate that this approach is surprisingly efficient: our experiments on Atari games show that within 10M frames and 30 evolution steps of training, our algorithm could achieve competitive result compared with ES, A3C, and DQN which need billions of frames.", "keywords": ["Neuroevolution", "Reinforcement Learning"], "authorids": ["bin.zhou@u.nus.edu", "elefjia@u.nus.edu"], "authors": ["Bin Zhou", "Jiashi Feng"], "pdf": "/pdf/56396e3ca3b58a8f300427f463aba9f2236e97c7.pdf", "paperhash": "zhou|sample_efficient_deep_neuroevolution_in_low_dimensional_latent_space", "_bibtex": "@misc{\nzhou2019sample,\ntitle={Sample Efficient Deep Neuroevolution in Low Dimensional Latent Space},\nauthor={Bin Zhou and Jiashi Feng},\nyear={2019},\nurl={https://openreview.net/forum?id=SkgE8sRcK7},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper164/Meta_Review", "rdate": null, "ddate": null, "expdate": null, "duedate": 1541548800000, "tmdate": 1545353313654, "tddate": null, "super": null, "final": null, "reply": {"forum": "SkgE8sRcK7", "replyto": "SkgE8sRcK7", "readers": {"description": "Select all user groups that should be able to read this comment. Selecting 'All Users' will allow paper authors, reviewers, area chairs, and program chairs to view this comment.", "values": ["everyone"]}, "signatures": {"description": "How your identity will be displayed with the above content.", "values-regex": "ICLR.cc/2019/Conference/Paper164/Area_Chair[0-9]+"}, "writers": {"description": "Users that may modify this record.", "values-regex": "ICLR.cc/2019/Conference/Paper164/Area_Chair[0-9]+"}, "content": {"title": {"order": 1, "value-regex": ".{1,500}", "description": "Brief summary of your review.", "required": true}, "metareview": {"order": 2, "value-regex": "[\\S\\s]{1,5000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "required": true}, "recommendation": {"order": 3, "value-dropdown": ["Accept (Oral)", "Accept (Poster)", "Reject"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The area chair is absolutely certain", "4: The area chair is confident but not absolutely certain", "3: The area chair is somewhat confident", "2: The area chair is not sure", "1: The area chair's evaluation is an educated guess"], "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper164/Area_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": false, "taskCompletionCount": null, "transform": null, "cdate": 1545353313654}}}, {"id": "rkeSEvPo3m", "original": null, "number": 3, "cdate": 1541269293431, "ddate": null, "tcdate": 1541269293431, "tmdate": 1541763008793, "tddate": null, "forum": "SkgE8sRcK7", "replyto": "SkgE8sRcK7", "invitation": "ICLR.cc/2019/Conference/-/Paper164/Official_Review", "content": {"title": "Interesting but not good enough for now", "review": "This paper proposes a combination of Evolutionary methods and variational representation learning to improve the sample efficiency of RL methods.\nThey train a VAE on environment frames, as well as an action-conditioned Dynamics model to predict the next frames, and these form the representations fed into a policy network which is trained through ES.\n\nOverall, I find the problem setting interesting, and they try to tackle Atari games instead of simpler domains.\nThe use of CMA-ES instead of NES is a good improvement, and the way they motivate using VAE representations to obtain manageable representation sizes is well put forward.\n[Edit: as mentioned by the other reviewers, this extension isn't as novel, given Ha et al's work, hence that reduces my confidence about accepting this paper further...]\n\nHowever, this paper suffers from several issues in its current state:\n1.\tIts presentation is overly detailed about known literature. Section 2 goes in low-level details which are not necessary. It covers ES methods even though a citation to Salimans et al. 2017 would have been sufficient. Section 2.1 is a really complete coverage of CMA-ES, which should really just be a citation of the actual paper again or should be in the Appendix, this doesn\u2019t warrant 1.5 pages of the main text.\n2.\tThe actual model presentation is too succinct and split into Section 2.2 and Section 3 (network architectures and parameters). It is never clear how many parameters are optimized by CMA-ES (I counted ~8200 parameters if the MLP of size 256 x 32 x n_a is used). Algorithm 3 however was extremely clear and helpful to fully understand the method.\n3.\tThere is no clear evaluation of the performance of the VAE representations and of the RNN dynamics model. Did they actually learn to represent anything at all? Figure 4 is not sufficient in providing evidence supporting this. \u2028Compare this to Higgins et al. 2017, which used VAEs which represented enough information to perform at the same performance as non-variational representations.\n4.\tThis feeds into the biggest issue with the current results:\u2028The proposed method works rather badly, obtaining worst performance than ES on 35 out of 51 games (68%). On most of these games, the proposed method does not seem to be able to get off the ground at all. \u2028Why is that the case? Obviously if the VAE+RNN do not represent the games well enough, the performance will be bad. Did the policy learning with CMA-ES converge well? (seeing learning curves might help)\u2028The fact that no gradients are passed back from the Policy to the VAE/RNN clearly emphasises that issue (The policy only affect the data on which the representations are periodically retrained on).\n\nIn conclusion, even though I feel this paper tries to tackle an interesting problem, the results are not sufficient to support them as of now.\n\nTypos:\n-\t\u201cDonates\u201d instead of \u201cdenotes\u201d in a few places.\n\nReferences:\n-\tHiggins et al., 2017: https://arxiv.org/abs/1707.08475 \n", "rating": "4: Ok but not good enough - rejection", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["ICLR.cc/2019/Conference/Paper164/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": true, "forumContent": {"title": "Sample Efficient Deep Neuroevolution in Low Dimensional Latent Space", "abstract": "Current deep neuroevolution models are usually trained in a large parameter search space for complex learning tasks, e.g. playing video games, which needs billions of samples and thousands of search steps to obtain significant performance. This raises a question of whether we can make use of sequential data generated during evolution, encode input samples, and evolve in low dimensional parameter space with latent state input in a fast and efficient manner. Here we give an affirmative answer: we train a VAE to encode input samples, then an RNN to model environment dynamics and handle temporal information, and last evolve our low dimensional policy network in latent space. We demonstrate that this approach is surprisingly efficient: our experiments on Atari games show that within 10M frames and 30 evolution steps of training, our algorithm could achieve competitive result compared with ES, A3C, and DQN which need billions of frames.", "keywords": ["Neuroevolution", "Reinforcement Learning"], "authorids": ["bin.zhou@u.nus.edu", "elefjia@u.nus.edu"], "authors": ["Bin Zhou", "Jiashi Feng"], "pdf": "/pdf/56396e3ca3b58a8f300427f463aba9f2236e97c7.pdf", "paperhash": "zhou|sample_efficient_deep_neuroevolution_in_low_dimensional_latent_space", "_bibtex": "@misc{\nzhou2019sample,\ntitle={Sample Efficient Deep Neuroevolution in Low Dimensional Latent Space},\nauthor={Bin Zhou and Jiashi Feng},\nyear={2019},\nurl={https://openreview.net/forum?id=SkgE8sRcK7},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper164/Official_Review", "cdate": 1542234524147, "expdate": 1552335264000, "duedate": 1541196000000, "reply": {"forum": "SkgE8sRcK7", "replyto": "SkgE8sRcK7", "readers": {"description": "The users who will be allowed to read the reply content.", "values": ["everyone"]}, "nonreaders": {"values": []}, "signatures": {"description": "How your identity will be displayed with the above content.", "values-regex": "ICLR.cc/2019/Conference/Paper164/AnonReviewer[0-9]+"}, "writers": {"description": "Users that may modify this record.", "values": ["ICLR.cc/2019/Conference"]}, "content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "required": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}}, "multiReply": false, "tcdate": 1552335662902, "tmdate": 1552335662902, "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "invitees": ["ICLR.cc/2019/Conference/Paper164/Reviewers"], "noninvitees": [], "signatures": ["ICLR.cc/2019/Conference"]}}}, {"id": "B1ehYPDtn7", "original": null, "number": 2, "cdate": 1541138308340, "ddate": null, "tcdate": 1541138308340, "tmdate": 1541534229182, "tddate": null, "forum": "SkgE8sRcK7", "replyto": "SkgE8sRcK7", "invitation": "ICLR.cc/2019/Conference/-/Paper164/Official_Review", "content": {"title": "Review for \"Sample Efficient Deep Neuroevolution in Low Dimensional Latent Space\"", "review": "Summary: They propose \"Sample Efficient Deep Neuroevolution\" (SEDN) model and experiment on Atari games. In this model, they use a Variational Encoder (VAE) to encode state frames into a latent vector, and use an LSTM to encode the current latent vector and action to predict the next latent space. A policy network (trained using CMA-ES) takes the latent space, and hidden state of the RNN as an input, and outputs an action to execute.\n\nThe strengths of this paper is that it is clearly written. They even explain details of RL, background of evolution strategies, motivation of using CMA-ES (and also the algorithm itself, which is no small ordeal), so it might a good background review paper of the literature. The experimental setup is relatively easy to understand. I suggest putting Algorithm 3 before Table 1 since presenting the algorithm before results may be more natural.\n\nThat being said, there are issues with this work that needs to be addressed before publication. I will list the issues and some suggestions I have, in order to help make this work better, hopefully good enough for acceptance:\n\n1) The authors cited [1] a few times in the paper, but actually their approach of using a VAE to compress frames into a latent, an LSTM to predict the next latent, and a CMA-ES trained network for the policy is precisely what is proposed in [1] (which had experiments that trained on the actual environment, like in this work, and also the generated environment). This paper reads like they have proposed the setup, and lacks clarity as to which parts are their contribution, and which parts are prior work, which I believe is important for a paper submitted to an academic venue. Not to say at all that there's no contribution or originally in this work - there are many, but I feel they should list out which bits are their contribution, and which bits are prior work more clearly. Doing so will make this paper and their contributions stronger.\n\nIn my opinion, their contributions are: Expanding on the approach of [1] to study on a larger set of environments (the Atari suite), where they also incorporated an iterative training loop (described Algorithm 3) that was not used in [1]. Also, unlike [1], they used a multi-layer policy network, and also explained and rationalized the intuition behind the choice of CMA-ES. I think by listing out the contributions, and separating them from previous work, the paper will be much stronger.\n\n2) The results are not terribly strong. They achieved good results on 7 games out of 50 using 10M frames. To me, that's actually not a deal breaker, since research is not a SOTA game, but I would like to see a more detailed analysis of why the algorithm works, and when it fails so people know what future work needs to be done to address this. I'm also not convinced that using CMA-ES would have an advantage over A3C (with the same latent / hidden features going into A3C as inputs), so perhaps the author might achieve better results if A3C was used to train the policy network (or not, but would be nice to see this experiment). It would offer more insight if we know what kind of terminal scores can be achieved using this algorithm, if it were allowed to train for 1B frames like the other 2 setup. Finally, if the author was able to show that training inside a generated environment, even for pre-training before going back to the actual environment, helps sample efficiency, that would be a very interesting result to me.\n\nI'm assigning a preliminary score of 5 for this work for now, but if the author address point (1) to my satisfaction I will revise the score to +1 points, and if the author is able to achieve much better results, or address items in point (2) to my satisfaction, I will revise the score by +1 or potentially +2 points, so the final score of this work may lie in the range of 5 -> 8. I feel the author should be able to improve the paper to get a score of 6-7 in the end, at least from me. Good luck!\n\n[1] https://arxiv.org/abs/1803.10122", "rating": "5: Marginally below acceptance threshold", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}, "signatures": ["ICLR.cc/2019/Conference/Paper164/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Sample Efficient Deep Neuroevolution in Low Dimensional Latent Space", "abstract": "Current deep neuroevolution models are usually trained in a large parameter search space for complex learning tasks, e.g. playing video games, which needs billions of samples and thousands of search steps to obtain significant performance. This raises a question of whether we can make use of sequential data generated during evolution, encode input samples, and evolve in low dimensional parameter space with latent state input in a fast and efficient manner. Here we give an affirmative answer: we train a VAE to encode input samples, then an RNN to model environment dynamics and handle temporal information, and last evolve our low dimensional policy network in latent space. We demonstrate that this approach is surprisingly efficient: our experiments on Atari games show that within 10M frames and 30 evolution steps of training, our algorithm could achieve competitive result compared with ES, A3C, and DQN which need billions of frames.", "keywords": ["Neuroevolution", "Reinforcement Learning"], "authorids": ["bin.zhou@u.nus.edu", "elefjia@u.nus.edu"], "authors": ["Bin Zhou", "Jiashi Feng"], "pdf": "/pdf/56396e3ca3b58a8f300427f463aba9f2236e97c7.pdf", "paperhash": "zhou|sample_efficient_deep_neuroevolution_in_low_dimensional_latent_space", "_bibtex": "@misc{\nzhou2019sample,\ntitle={Sample Efficient Deep Neuroevolution in Low Dimensional Latent Space},\nauthor={Bin Zhou and Jiashi Feng},\nyear={2019},\nurl={https://openreview.net/forum?id=SkgE8sRcK7},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper164/Official_Review", "cdate": 1542234524147, "expdate": 1552335264000, "duedate": 1541196000000, "reply": {"forum": "SkgE8sRcK7", "replyto": "SkgE8sRcK7", "readers": {"description": "The users who will be allowed to read the reply content.", "values": ["everyone"]}, "nonreaders": {"values": []}, "signatures": {"description": "How your identity will be displayed with the above content.", "values-regex": "ICLR.cc/2019/Conference/Paper164/AnonReviewer[0-9]+"}, "writers": {"description": "Users that may modify this record.", "values": ["ICLR.cc/2019/Conference"]}, "content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "required": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}}, "multiReply": false, "tcdate": 1552335662902, "tmdate": 1552335662902, "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "invitees": ["ICLR.cc/2019/Conference/Paper164/Reviewers"], "noninvitees": [], "signatures": ["ICLR.cc/2019/Conference"]}}}, {"id": "ryesWWEY27", "original": null, "number": 1, "cdate": 1541124354666, "ddate": null, "tcdate": 1541124354666, "tmdate": 1541534228935, "tddate": null, "forum": "SkgE8sRcK7", "replyto": "SkgE8sRcK7", "invitation": "ICLR.cc/2019/Conference/-/Paper164/Official_Review", "content": {"title": "Contributions of this paper are unclear and not well evaluated", "review": "The main difficulty of neuroevolution---requiring a huge number of simulations for high dimensional problem---is addressed in this paper by introducing VAE to reduce the state space dimensionality and using a rather shallow controller network. This idea itself is very promising, however, it has been introduced in (Ha and Schmidhuber, 2018).  Still, there seems to be differences in how to gather histories and how to use them. Nevertheless, the differences are not well described in the text. The effect of the modification is not evaluated on experiments.", "rating": "4: Ok but not good enough - rejection", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["ICLR.cc/2019/Conference/Paper164/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Sample Efficient Deep Neuroevolution in Low Dimensional Latent Space", "abstract": "Current deep neuroevolution models are usually trained in a large parameter search space for complex learning tasks, e.g. playing video games, which needs billions of samples and thousands of search steps to obtain significant performance. This raises a question of whether we can make use of sequential data generated during evolution, encode input samples, and evolve in low dimensional parameter space with latent state input in a fast and efficient manner. Here we give an affirmative answer: we train a VAE to encode input samples, then an RNN to model environment dynamics and handle temporal information, and last evolve our low dimensional policy network in latent space. We demonstrate that this approach is surprisingly efficient: our experiments on Atari games show that within 10M frames and 30 evolution steps of training, our algorithm could achieve competitive result compared with ES, A3C, and DQN which need billions of frames.", "keywords": ["Neuroevolution", "Reinforcement Learning"], "authorids": ["bin.zhou@u.nus.edu", "elefjia@u.nus.edu"], "authors": ["Bin Zhou", "Jiashi Feng"], "pdf": "/pdf/56396e3ca3b58a8f300427f463aba9f2236e97c7.pdf", "paperhash": "zhou|sample_efficient_deep_neuroevolution_in_low_dimensional_latent_space", "_bibtex": "@misc{\nzhou2019sample,\ntitle={Sample Efficient Deep Neuroevolution in Low Dimensional Latent Space},\nauthor={Bin Zhou and Jiashi Feng},\nyear={2019},\nurl={https://openreview.net/forum?id=SkgE8sRcK7},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper164/Official_Review", "cdate": 1542234524147, "expdate": 1552335264000, "duedate": 1541196000000, "reply": {"forum": "SkgE8sRcK7", "replyto": "SkgE8sRcK7", "readers": {"description": "The users who will be allowed to read the reply content.", "values": ["everyone"]}, "nonreaders": {"values": []}, "signatures": {"description": "How your identity will be displayed with the above content.", "values-regex": "ICLR.cc/2019/Conference/Paper164/AnonReviewer[0-9]+"}, "writers": {"description": "Users that may modify this record.", "values": ["ICLR.cc/2019/Conference"]}, "content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "required": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}}, "multiReply": false, "tcdate": 1552335662902, "tmdate": 1552335662902, "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "invitees": ["ICLR.cc/2019/Conference/Paper164/Reviewers"], "noninvitees": [], "signatures": ["ICLR.cc/2019/Conference"]}}}], "count": 5}