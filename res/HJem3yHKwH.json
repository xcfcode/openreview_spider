{"notes": [{"id": "HJem3yHKwH", "original": "H1lNTgytwS", "number": 1946, "cdate": 1569439659098, "ddate": null, "tcdate": 1569439659098, "tmdate": 1583912022873, "tddate": null, "forum": "HJem3yHKwH", "replyto": null, "invitation": "ICLR.cc/2020/Conference/-/Blind_Submission", "content": {"title": "EMPIR: Ensembles of Mixed Precision Deep Networks for Increased Robustness Against Adversarial Attacks", "authors": ["Sanchari Sen", "Balaraman Ravindran", "Anand Raghunathan"], "authorids": ["sen9@purdue.edu", "ravi@cse.iitm.ac.in", "raghunathan@purdue.edu"], "keywords": ["ensembles", "mixed precision", "robustness", "adversarial attacks"], "TL;DR": "We propose ensembles of mixed-precision DNNs as a new form of defense against adversarial attacks", "abstract": "Ensuring robustness of Deep Neural Networks (DNNs) is crucial to their adoption in safety-critical applications such as self-driving cars, drones, and healthcare. Notably, DNNs are vulnerable to adversarial attacks in which small input perturbations can produce catastrophic misclassifications. In this work, we propose EMPIR, ensembles of quantized DNN models with different numerical precisions, as a new approach to increase robustness against adversarial attacks. EMPIR is based on the observation that quantized neural networks often demonstrate much higher robustness to adversarial attacks than full precision networks, but at the cost of a substantial loss in accuracy on the original (unperturbed) inputs. EMPIR overcomes this limitation to achieve the ``best of both worlds\", i.e., the higher unperturbed accuracies of the full precision models combined with the higher robustness of the low precision models, by composing them in an ensemble. Further, as low precision DNN models have significantly lower computational and storage requirements than full precision models, EMPIR models only incur modest compute and memory overheads compared to a single full-precision model (<25% in our evaluations). We evaluate EMPIR across a suite of DNNs for 3 different image recognition tasks (MNIST, CIFAR-10 and ImageNet) and under 4 different adversarial attacks. Our results indicate that EMPIR boosts the average adversarial accuracies by 42.6%, 15.2% and 10.5% for the DNN models trained on the MNIST, CIFAR-10 and ImageNet datasets respectively, when compared to single full-precision models, without sacrificing accuracy on the unperturbed inputs.", "pdf": "/pdf/abe3b71eab612c1ac73bcd543d40a277614b1d48.pdf", "paperhash": "sen|empir_ensembles_of_mixed_precision_deep_networks_for_increased_robustness_against_adversarial_attacks", "code": "https://github.com/sancharisen/EMPIR", "_bibtex": "@inproceedings{\nSen2020EMPIR:,\ntitle={EMPIR: Ensembles of Mixed Precision Deep Networks for Increased Robustness Against Adversarial Attacks},\nauthor={Sanchari Sen and Balaraman Ravindran and Anand Raghunathan},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=HJem3yHKwH}\n}", "full_presentation_video": "", "original_pdf": "/attachment/24752c0555dd6848ef8f7d45b1ead1004359f726.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "signatures": ["ICLR.cc/2020/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference"], "details": {"replyCount": 7, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"reply": {"readers": {"values-regex": ".*"}, "writers": {"values": ["ICLR.cc/2020/Conference"]}, "signatures": {"values": ["ICLR.cc/2020/Conference"]}, "content": {"spotlight_video": {"value-regex": ".*"}, "full_presentation_video": {"value-regex": ".*"}, "original_pdf": {"required": false, "description": "Upload a PDF file that ends with .pdf", "value-regex": ".*"}, "appendix": {"value-regex": ".*"}, "authorids": {"values-regex": ".*"}, "poster": {"value-regex": ".*"}, "authors": {"values": ["Anonymous"]}, "slides": {"value-regex": ".*"}}}, "final": [], "signatures": ["ICLR.cc/2020/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference"], "noninvitees": [], "tcdate": 1569271260237, "tmdate": 1593459412141, "id": "ICLR.cc/2020/Conference/-/Blind_Submission"}}, "tauthor": "ICLR.cc/2020/Conference"}, {"id": "xbVi20gvP", "original": null, "number": 1, "cdate": 1576798736639, "ddate": null, "tcdate": 1576798736639, "tmdate": 1576800899725, "tddate": null, "forum": "HJem3yHKwH", "replyto": "HJem3yHKwH", "invitation": "ICLR.cc/2020/Conference/Paper1946/-/Decision", "content": {"decision": "Accept (Poster)", "comment": "This paper proposed to apply emsembles of high precision deep networks and low precision ones to improve the robustness against adversarial attacks while not increase the cost in time and memory heavily.  Experiments on different tasks under various types of adversarial attacks show the proposed method improves the robustness of the models without sacrificing the accuracy on normal input.  The idea is simple and effective.  Some reviewers have had concerns on the novelty of the idea and the comparisons with related work but I think the authors give convincing answers to these questions.", "title": "Paper Decision"}, "signatures": ["ICLR.cc/2020/Conference/Program_Chairs"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Program_Chairs"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "EMPIR: Ensembles of Mixed Precision Deep Networks for Increased Robustness Against Adversarial Attacks", "authors": ["Sanchari Sen", "Balaraman Ravindran", "Anand Raghunathan"], "authorids": ["sen9@purdue.edu", "ravi@cse.iitm.ac.in", "raghunathan@purdue.edu"], "keywords": ["ensembles", "mixed precision", "robustness", "adversarial attacks"], "TL;DR": "We propose ensembles of mixed-precision DNNs as a new form of defense against adversarial attacks", "abstract": "Ensuring robustness of Deep Neural Networks (DNNs) is crucial to their adoption in safety-critical applications such as self-driving cars, drones, and healthcare. Notably, DNNs are vulnerable to adversarial attacks in which small input perturbations can produce catastrophic misclassifications. In this work, we propose EMPIR, ensembles of quantized DNN models with different numerical precisions, as a new approach to increase robustness against adversarial attacks. EMPIR is based on the observation that quantized neural networks often demonstrate much higher robustness to adversarial attacks than full precision networks, but at the cost of a substantial loss in accuracy on the original (unperturbed) inputs. EMPIR overcomes this limitation to achieve the ``best of both worlds\", i.e., the higher unperturbed accuracies of the full precision models combined with the higher robustness of the low precision models, by composing them in an ensemble. Further, as low precision DNN models have significantly lower computational and storage requirements than full precision models, EMPIR models only incur modest compute and memory overheads compared to a single full-precision model (<25% in our evaluations). We evaluate EMPIR across a suite of DNNs for 3 different image recognition tasks (MNIST, CIFAR-10 and ImageNet) and under 4 different adversarial attacks. Our results indicate that EMPIR boosts the average adversarial accuracies by 42.6%, 15.2% and 10.5% for the DNN models trained on the MNIST, CIFAR-10 and ImageNet datasets respectively, when compared to single full-precision models, without sacrificing accuracy on the unperturbed inputs.", "pdf": "/pdf/abe3b71eab612c1ac73bcd543d40a277614b1d48.pdf", "paperhash": "sen|empir_ensembles_of_mixed_precision_deep_networks_for_increased_robustness_against_adversarial_attacks", "code": "https://github.com/sancharisen/EMPIR", "_bibtex": "@inproceedings{\nSen2020EMPIR:,\ntitle={EMPIR: Ensembles of Mixed Precision Deep Networks for Increased Robustness Against Adversarial Attacks},\nauthor={Sanchari Sen and Balaraman Ravindran and Anand Raghunathan},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=HJem3yHKwH}\n}", "full_presentation_video": "", "original_pdf": "/attachment/24752c0555dd6848ef8f7d45b1ead1004359f726.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "tags": [], "invitation": {"reply": {"writers": {"description": "How your identity will be displayed.", "values-regex": ["ICLR.cc/2020/Conference/Program_Chairs"]}, "signatures": {"values": ["ICLR.cc/2020/Conference/Program_Chairs"], "description": "How your identity will be displayed."}, "content": {"decision": {"value-radio": ["Accept (Spotlight)", "Accept (Talk)", "Accept (Poster)", "Reject"], "description": "Decision", "required": true, "order": 2}, "title": {"value": "Paper Decision", "required": true, "order": 1}, "comment": {"value-regex": "[\\S\\s]{0,5000}", "description": "", "required": false, "order": 3}}, "forum": "HJem3yHKwH", "replyto": "HJem3yHKwH", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}}, "expdate": 1576854540000, "duedate": 1576853940000, "multiReply": false, "readers": ["everyone"], "invitees": ["ICLR.cc/2020/Conference/Program_Chairs"], "tcdate": 1576795719765, "tmdate": 1576800270471, "super": "ICLR.cc/2020/Conference/-/Decision", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper1946/-/Decision"}}}, {"id": "HklscZ5doS", "original": null, "number": 8, "cdate": 1573589395327, "ddate": null, "tcdate": 1573589395327, "tmdate": 1573589395327, "tddate": null, "forum": "HJem3yHKwH", "replyto": "H1xg6DlTFr", "invitation": "ICLR.cc/2020/Conference/Paper1946/-/Official_Comment", "content": {"title": "Response to Reviewer 3", "comment": "We thank the reviewer for their positive comments. As correctly pointed out by the reviewer, this work was intended to showcase an alternative low-cost approach to increasing the robustness of deep learning models through the use of low-precision models, without sacrificing accuracy on the original unperturbed examples. Also, as discussed in our response to reviewer 1, other defense strategies like adversarial training, input gradient regularization, defensive distillation and full-precision ensembles suffer from limitations of increased training time, increased model size or increased inference time. However, the development of several hardware platforms and software libraries supporting low-precision operations has decreased the training and inference times for low-precision models allowing us to achieve increased robustness with minimal training, inference and model size overheads. \n\nWe would like to clarify that the adversarial attacks on the low-precision models weren\u2019t performed at full-precision. The attacked model was a low precision model utilizing quantized weights and activations. However, the gradients used in the attack generation were not quantized, allowing the adversary to launch a stronger attack. We have updated the paper to include this clarification.\n"}, "signatures": ["ICLR.cc/2020/Conference/Paper1946/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1946/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "EMPIR: Ensembles of Mixed Precision Deep Networks for Increased Robustness Against Adversarial Attacks", "authors": ["Sanchari Sen", "Balaraman Ravindran", "Anand Raghunathan"], "authorids": ["sen9@purdue.edu", "ravi@cse.iitm.ac.in", "raghunathan@purdue.edu"], "keywords": ["ensembles", "mixed precision", "robustness", "adversarial attacks"], "TL;DR": "We propose ensembles of mixed-precision DNNs as a new form of defense against adversarial attacks", "abstract": "Ensuring robustness of Deep Neural Networks (DNNs) is crucial to their adoption in safety-critical applications such as self-driving cars, drones, and healthcare. Notably, DNNs are vulnerable to adversarial attacks in which small input perturbations can produce catastrophic misclassifications. In this work, we propose EMPIR, ensembles of quantized DNN models with different numerical precisions, as a new approach to increase robustness against adversarial attacks. EMPIR is based on the observation that quantized neural networks often demonstrate much higher robustness to adversarial attacks than full precision networks, but at the cost of a substantial loss in accuracy on the original (unperturbed) inputs. EMPIR overcomes this limitation to achieve the ``best of both worlds\", i.e., the higher unperturbed accuracies of the full precision models combined with the higher robustness of the low precision models, by composing them in an ensemble. Further, as low precision DNN models have significantly lower computational and storage requirements than full precision models, EMPIR models only incur modest compute and memory overheads compared to a single full-precision model (<25% in our evaluations). We evaluate EMPIR across a suite of DNNs for 3 different image recognition tasks (MNIST, CIFAR-10 and ImageNet) and under 4 different adversarial attacks. Our results indicate that EMPIR boosts the average adversarial accuracies by 42.6%, 15.2% and 10.5% for the DNN models trained on the MNIST, CIFAR-10 and ImageNet datasets respectively, when compared to single full-precision models, without sacrificing accuracy on the unperturbed inputs.", "pdf": "/pdf/abe3b71eab612c1ac73bcd543d40a277614b1d48.pdf", "paperhash": "sen|empir_ensembles_of_mixed_precision_deep_networks_for_increased_robustness_against_adversarial_attacks", "code": "https://github.com/sancharisen/EMPIR", "_bibtex": "@inproceedings{\nSen2020EMPIR:,\ntitle={EMPIR: Ensembles of Mixed Precision Deep Networks for Increased Robustness Against Adversarial Attacks},\nauthor={Sanchari Sen and Balaraman Ravindran and Anand Raghunathan},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=HJem3yHKwH}\n}", "full_presentation_video": "", "original_pdf": "/attachment/24752c0555dd6848ef8f7d45b1ead1004359f726.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "HJem3yHKwH", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper1946/Authors", "ICLR.cc/2020/Conference/Paper1946/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper1946/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper1946/Reviewers", "ICLR.cc/2020/Conference/Paper1946/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper1946/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper1946/Authors|ICLR.cc/2020/Conference/Paper1946/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504148570, "tmdate": 1576860558596, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper1946/Authors", "ICLR.cc/2020/Conference/Paper1946/Reviewers", "ICLR.cc/2020/Conference/Paper1946/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper1946/-/Official_Comment"}}}, {"id": "SJx1vWc_sr", "original": null, "number": 7, "cdate": 1573589335175, "ddate": null, "tcdate": 1573589335175, "tmdate": 1573589335175, "tddate": null, "forum": "HJem3yHKwH", "replyto": "BkgEnMcyqS", "invitation": "ICLR.cc/2020/Conference/Paper1946/-/Official_Comment", "content": {"title": "Response to Reviewer 1", "comment": "We thank the reviewer for their comments. Please find the detailed responses to the individual concerns below.\n\n\nSuitability for ICLR:\n\nWe believe that ICLR is the right venue for our paper for two main reasons. First, the high cost associated with ensemble models is often ignored by the machine learning community when considering its advantages in terms of increased performance and robustness. Their high memory and compute footprint can even be prohibitive on resource-constrained devices such as IoT edge devices and wearables. As an alternative, we propose mixed-precision ensembles and illustrate their advantages in terms of both higher robustness and low compute and memory overhead. Second, over the past few years, ICLR has published many papers on low precision networks [1][2]. This work builds on the existing works and demonstrates an additional advantage of these low precision networks.\n\n[1] Aojun Zhou et al. \u201cIncremental Network Quantization: Towards Lossless CNNs with Low-Precision Weights\u201d. ICLR 2017.\n[2] Angus Galloway et al. \u201cAttacking Binarized Neural Networks.\u201d ICLR 2018.\n \n\nAdditional baselines for benchmarks other than MNIST:\n\nWe did not present additional baselines for the CIFAR-10 and AlexNet benchmarks as they did not yield networks with higher adversarial accuracies and <5% drop in unperturbed accuracies compared to the full-precision baselines. To illustrate the point further, we present the results for CIFAR-10 with defensive distillation and input gradient regularization below. The distillation process was implemented with a softmax temperature of T = 100, the gradient regularization was realized with a regularization penalty of lambda = 200.\n\n+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\nDefense strategy  |  Unperturbed Accuracy |  CW   | FGSM   |   BIM  |  PGD  | Average Adversarial\n+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\nDefensive distill.   |          \t63.84                     |  31.4  |   14.4   |   5.83  |   4.08  |          13.93\nInp. Grad. Reg.      |          \t74.91                     | 12.58 |  10.06  | 12.72  | 10.43  |          11.45\n \n\nComparison with other mechanisms proposed as a defense for adversarial attacks:\n\nAmong the plethora of works on increasing robustness, we have chosen to compare our work with some of the most cited and popular defense strategies, namely, FGSM based adversarial training, defensive distillation and input gradient regularization, due to page restrictions and implementation efforts. However, as requested by Reviewer 4, we have also updated the paper to include the comparison with PGD-based adversarial training. We would like to highlight that our approach stands out from previous work in terms of drastically lower overheads. Adversarial training, input gradient regularization and defensive distillation all increase the overall training time significantly, while ensembling with full-precision models increase the overall model size and inference time several-fold. In contrast, with the development of hardware that natively supports low-precision operations and the development of libraries that can take advantage of these low precision computation engines (Ex: CUDA 10 on Turing GPUs https://devblogs.nvidia.com/cuda-10-features-revealed/), the training and inference times for low-precision models are decreasing remarkably (https://devblogs.nvidia.com/int4-for-ai-inference/). We exploit this advantage of low-precision models to achieve increased robustness with minimal increases in overall training and inference times (training and executing two low precision models in addition to one full-precision model)."}, "signatures": ["ICLR.cc/2020/Conference/Paper1946/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1946/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "EMPIR: Ensembles of Mixed Precision Deep Networks for Increased Robustness Against Adversarial Attacks", "authors": ["Sanchari Sen", "Balaraman Ravindran", "Anand Raghunathan"], "authorids": ["sen9@purdue.edu", "ravi@cse.iitm.ac.in", "raghunathan@purdue.edu"], "keywords": ["ensembles", "mixed precision", "robustness", "adversarial attacks"], "TL;DR": "We propose ensembles of mixed-precision DNNs as a new form of defense against adversarial attacks", "abstract": "Ensuring robustness of Deep Neural Networks (DNNs) is crucial to their adoption in safety-critical applications such as self-driving cars, drones, and healthcare. Notably, DNNs are vulnerable to adversarial attacks in which small input perturbations can produce catastrophic misclassifications. In this work, we propose EMPIR, ensembles of quantized DNN models with different numerical precisions, as a new approach to increase robustness against adversarial attacks. EMPIR is based on the observation that quantized neural networks often demonstrate much higher robustness to adversarial attacks than full precision networks, but at the cost of a substantial loss in accuracy on the original (unperturbed) inputs. EMPIR overcomes this limitation to achieve the ``best of both worlds\", i.e., the higher unperturbed accuracies of the full precision models combined with the higher robustness of the low precision models, by composing them in an ensemble. Further, as low precision DNN models have significantly lower computational and storage requirements than full precision models, EMPIR models only incur modest compute and memory overheads compared to a single full-precision model (<25% in our evaluations). We evaluate EMPIR across a suite of DNNs for 3 different image recognition tasks (MNIST, CIFAR-10 and ImageNet) and under 4 different adversarial attacks. Our results indicate that EMPIR boosts the average adversarial accuracies by 42.6%, 15.2% and 10.5% for the DNN models trained on the MNIST, CIFAR-10 and ImageNet datasets respectively, when compared to single full-precision models, without sacrificing accuracy on the unperturbed inputs.", "pdf": "/pdf/abe3b71eab612c1ac73bcd543d40a277614b1d48.pdf", "paperhash": "sen|empir_ensembles_of_mixed_precision_deep_networks_for_increased_robustness_against_adversarial_attacks", "code": "https://github.com/sancharisen/EMPIR", "_bibtex": "@inproceedings{\nSen2020EMPIR:,\ntitle={EMPIR: Ensembles of Mixed Precision Deep Networks for Increased Robustness Against Adversarial Attacks},\nauthor={Sanchari Sen and Balaraman Ravindran and Anand Raghunathan},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=HJem3yHKwH}\n}", "full_presentation_video": "", "original_pdf": "/attachment/24752c0555dd6848ef8f7d45b1ead1004359f726.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "HJem3yHKwH", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper1946/Authors", "ICLR.cc/2020/Conference/Paper1946/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper1946/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper1946/Reviewers", "ICLR.cc/2020/Conference/Paper1946/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper1946/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper1946/Authors|ICLR.cc/2020/Conference/Paper1946/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504148570, "tmdate": 1576860558596, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper1946/Authors", "ICLR.cc/2020/Conference/Paper1946/Reviewers", "ICLR.cc/2020/Conference/Paper1946/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper1946/-/Official_Comment"}}}, {"id": "B1x6WxqOoB", "original": null, "number": 6, "cdate": 1573588997292, "ddate": null, "tcdate": 1573588997292, "tmdate": 1573588997292, "tddate": null, "forum": "HJem3yHKwH", "replyto": "HJgE7loI5H", "invitation": "ICLR.cc/2020/Conference/Paper1946/-/Official_Comment", "content": {"title": "Response to Reviewer 4", "comment": "We thank the reviewer for their comments. Please find the detailed responses to the individual concerns below.\n\n\nRelated efforts on ensembles and unique contribution of this work:\n\nWe thank the reviewer for pointing out the additional related work; we have updated the related work section to include these works. However, we feel that our work makes a significant contribution above the previous work when it comes to computationally-efficient defenses. Previous approaches either increase the training time greatly (adversarial training, input gradient regularization and defensive distillation), or increase the inference memory and compute footprint several-fold (full-precision ensembles). As a result, these approaches are inapplicable to resource-constrained systems (like IoT edge devices and wearables). This is the problem addressed in our work.\n\nRecent years have seen a tremendous growth in efforts towards DNNs optimized for computational efficiency [1] [2]. Following the same motivation, this work demonstrates a computationally-efficient approach of utilizing mixed-precision ensembles to increase robustness while maintaining unperturbed accuracy. Advances in hardware that natively supports low-precision operations and software libraries that can take advantage of these low precision computation engines (Ex: CUDA 10 on Turing GPUs https://devblogs.nvidia.com/cuda-10-features-revealed/) infact allow low-precision models to execute much faster than their full-precision counterparts (https://devblogs.nvidia.com/int4-for-ai-inference/), thereby restricting the inference time overheads of EMPIR to <25%. Further, unlike other popular non-ensemble defense techniques like adversarial training, input gradient regularization and defensive distillation, our approach doesn\u2019t increase training time. The overall idea is simple, but effective. We believe that its successful implementation, as demonstrated in this paper, is an important step towards realizing computationally efficient and robust DNNs. \n\n[1]  A.G Howard et al. \u201cMobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications\u201d. ArXiv, abs/1704.04861 (2017).\n[2], Forrest N. Iandola et al. \u201cSqueezeNet: AlexNet-level accuracy with 50x fewer parameters and <1MB model size.\u201d ArXiv abs/1602.07360 (2017).\n\n\nComparison with PGD adversarial training:\n\nSince there is a plethora of efforts on increasing robustness, we restricted the comparisons to a few popular representative works due to space and time restrictions. FGSM adversarial training results were presented instead of PGD adversarial training because it converges faster. However, as requested by the reviewer, we have updated the paper to include the following results on PGD adversarial training [3], and we will include additional results in the final paper. The adversarial training was performed on adversarial examples generated with a maximum possible perturbation of epsilon = 0.3.\n\n++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\nNetwork       |         Approach       | Unperturbed Accuracy |    CW   |   FGSM   |   BIM   |  PGD  | Average Adversarial\n++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\nCIFARconv    | PGD Adv. Train      |                  73.55               |  12.62   |  12.45   |  10.97  |  8.52  |            11.14\nCIFARconv    | EMPIR                     |                   72.56              |   48.51  |   20.61  |  24.59  | 13.34 |             26.76\n\nAs evident from the above values, for the CIFARconv benchmark, EMPIR achieves a higher average adversarial accuracy than PGD adversarial training. EMPIR is able to achieve this improvement with zero training overhead, whereas PGD adversarial training increases the training time significantly because of the need to construct adversarial examples during training (One PGD adversarial training epoch is 22x slower than a clean training epoch on an RTX 2080 Ti GPU).  \n\n[3] A. Madry et al. \u201cTowards Deep Learning Models Resistant to Adversarial Attacks.\u201d ArXiv abs/1706.06083 (2017).\n"}, "signatures": ["ICLR.cc/2020/Conference/Paper1946/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1946/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "EMPIR: Ensembles of Mixed Precision Deep Networks for Increased Robustness Against Adversarial Attacks", "authors": ["Sanchari Sen", "Balaraman Ravindran", "Anand Raghunathan"], "authorids": ["sen9@purdue.edu", "ravi@cse.iitm.ac.in", "raghunathan@purdue.edu"], "keywords": ["ensembles", "mixed precision", "robustness", "adversarial attacks"], "TL;DR": "We propose ensembles of mixed-precision DNNs as a new form of defense against adversarial attacks", "abstract": "Ensuring robustness of Deep Neural Networks (DNNs) is crucial to their adoption in safety-critical applications such as self-driving cars, drones, and healthcare. Notably, DNNs are vulnerable to adversarial attacks in which small input perturbations can produce catastrophic misclassifications. In this work, we propose EMPIR, ensembles of quantized DNN models with different numerical precisions, as a new approach to increase robustness against adversarial attacks. EMPIR is based on the observation that quantized neural networks often demonstrate much higher robustness to adversarial attacks than full precision networks, but at the cost of a substantial loss in accuracy on the original (unperturbed) inputs. EMPIR overcomes this limitation to achieve the ``best of both worlds\", i.e., the higher unperturbed accuracies of the full precision models combined with the higher robustness of the low precision models, by composing them in an ensemble. Further, as low precision DNN models have significantly lower computational and storage requirements than full precision models, EMPIR models only incur modest compute and memory overheads compared to a single full-precision model (<25% in our evaluations). We evaluate EMPIR across a suite of DNNs for 3 different image recognition tasks (MNIST, CIFAR-10 and ImageNet) and under 4 different adversarial attacks. Our results indicate that EMPIR boosts the average adversarial accuracies by 42.6%, 15.2% and 10.5% for the DNN models trained on the MNIST, CIFAR-10 and ImageNet datasets respectively, when compared to single full-precision models, without sacrificing accuracy on the unperturbed inputs.", "pdf": "/pdf/abe3b71eab612c1ac73bcd543d40a277614b1d48.pdf", "paperhash": "sen|empir_ensembles_of_mixed_precision_deep_networks_for_increased_robustness_against_adversarial_attacks", "code": "https://github.com/sancharisen/EMPIR", "_bibtex": "@inproceedings{\nSen2020EMPIR:,\ntitle={EMPIR: Ensembles of Mixed Precision Deep Networks for Increased Robustness Against Adversarial Attacks},\nauthor={Sanchari Sen and Balaraman Ravindran and Anand Raghunathan},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=HJem3yHKwH}\n}", "full_presentation_video": "", "original_pdf": "/attachment/24752c0555dd6848ef8f7d45b1ead1004359f726.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "HJem3yHKwH", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper1946/Authors", "ICLR.cc/2020/Conference/Paper1946/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper1946/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper1946/Reviewers", "ICLR.cc/2020/Conference/Paper1946/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper1946/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper1946/Authors|ICLR.cc/2020/Conference/Paper1946/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504148570, "tmdate": 1576860558596, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper1946/Authors", "ICLR.cc/2020/Conference/Paper1946/Reviewers", "ICLR.cc/2020/Conference/Paper1946/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper1946/-/Official_Comment"}}}, {"id": "H1xg6DlTFr", "original": null, "number": 1, "cdate": 1571780536131, "ddate": null, "tcdate": 1571780536131, "tmdate": 1572972403177, "tddate": null, "forum": "HJem3yHKwH", "replyto": "HJem3yHKwH", "invitation": "ICLR.cc/2020/Conference/Paper1946/-/Official_Review", "content": {"experience_assessment": "I do not know much about this area.", "rating": "6: Weak Accept", "review_assessment:_thoroughness_in_paper_reading": "I made a quick assessment of this paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #3", "review_assessment:_checking_correctness_of_derivations_and_theory": "I did not assess the derivations or theory.", "review": "The authors propose an ensemble of low-precision networks as a solution to providing a neural network with solid adversarial robustness whilst also providing good accuracy.\n\nI found the paper easy to read with a high quality introduction and background, the results are very convincing and the idea is simple but intriguing. I think this will shift the community towards seriously considering low precision networks a partial solution to adversarial attacks (alongside adversarial training).\n\nI could not work out from the paper whether the adversarial attacks on the low-precision networks were performed at full precision. I.e. someone could clone the low-precision networks, cast them to full precision, perform an adversarial attack like FGSM and then evaluate on the quantized network. It would be good to clarify this (or make it clearer in the text how you handle this)."}, "signatures": ["ICLR.cc/2020/Conference/Paper1946/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1946/AnonReviewer3"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "EMPIR: Ensembles of Mixed Precision Deep Networks for Increased Robustness Against Adversarial Attacks", "authors": ["Sanchari Sen", "Balaraman Ravindran", "Anand Raghunathan"], "authorids": ["sen9@purdue.edu", "ravi@cse.iitm.ac.in", "raghunathan@purdue.edu"], "keywords": ["ensembles", "mixed precision", "robustness", "adversarial attacks"], "TL;DR": "We propose ensembles of mixed-precision DNNs as a new form of defense against adversarial attacks", "abstract": "Ensuring robustness of Deep Neural Networks (DNNs) is crucial to their adoption in safety-critical applications such as self-driving cars, drones, and healthcare. Notably, DNNs are vulnerable to adversarial attacks in which small input perturbations can produce catastrophic misclassifications. In this work, we propose EMPIR, ensembles of quantized DNN models with different numerical precisions, as a new approach to increase robustness against adversarial attacks. EMPIR is based on the observation that quantized neural networks often demonstrate much higher robustness to adversarial attacks than full precision networks, but at the cost of a substantial loss in accuracy on the original (unperturbed) inputs. EMPIR overcomes this limitation to achieve the ``best of both worlds\", i.e., the higher unperturbed accuracies of the full precision models combined with the higher robustness of the low precision models, by composing them in an ensemble. Further, as low precision DNN models have significantly lower computational and storage requirements than full precision models, EMPIR models only incur modest compute and memory overheads compared to a single full-precision model (<25% in our evaluations). We evaluate EMPIR across a suite of DNNs for 3 different image recognition tasks (MNIST, CIFAR-10 and ImageNet) and under 4 different adversarial attacks. Our results indicate that EMPIR boosts the average adversarial accuracies by 42.6%, 15.2% and 10.5% for the DNN models trained on the MNIST, CIFAR-10 and ImageNet datasets respectively, when compared to single full-precision models, without sacrificing accuracy on the unperturbed inputs.", "pdf": "/pdf/abe3b71eab612c1ac73bcd543d40a277614b1d48.pdf", "paperhash": "sen|empir_ensembles_of_mixed_precision_deep_networks_for_increased_robustness_against_adversarial_attacks", "code": "https://github.com/sancharisen/EMPIR", "_bibtex": "@inproceedings{\nSen2020EMPIR:,\ntitle={EMPIR: Ensembles of Mixed Precision Deep Networks for Increased Robustness Against Adversarial Attacks},\nauthor={Sanchari Sen and Balaraman Ravindran and Anand Raghunathan},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=HJem3yHKwH}\n}", "full_presentation_video": "", "original_pdf": "/attachment/24752c0555dd6848ef8f7d45b1ead1004359f726.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "HJem3yHKwH", "replyto": "HJem3yHKwH", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper1946/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper1946/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1575847141813, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper1946/Reviewers"], "noninvitees": [], "tcdate": 1570237729999, "tmdate": 1575847141827, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper1946/-/Official_Review"}}}, {"id": "BkgEnMcyqS", "original": null, "number": 2, "cdate": 1571951276231, "ddate": null, "tcdate": 1571951276231, "tmdate": 1572972403134, "tddate": null, "forum": "HJem3yHKwH", "replyto": "HJem3yHKwH", "invitation": "ICLR.cc/2020/Conference/Paper1946/-/Official_Review", "content": {"experience_assessment": "I have read many papers in this area.", "rating": "6: Weak Accept", "review_assessment:_thoroughness_in_paper_reading": "I made a quick assessment of this paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #1", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "I think the paper reads well. It proposes to use ensembles of full precision and low-precision models in order to boost up robustness to adversarial attacks. It relies on the fact that low precision models are known to be more robust to adversarial attacks though performing poorly, while ensembling generally boosting up performance. \n\nI think the premise of the paper is quite clear, and the results seem to be intuitive.  At a high level one worry that I have is if ICLR is the right conference for this work. \n\nI would have expected maybe a more thorough empirical exploration. E.g. using resnets for ImageNet rather than AlexNet. Providing more baselines for the larger (and more reliable datasets) rather than MNIST which might be a bit misleading. I think the work does a decent job at looking at different number of components in the ensemble and analyzing the proposed method, but maybe not enough comparing and exploring other mechanism proposed as a defense for adversarial attacks. \n\nHowever I think the message is clear, the results seem decent and I'm not aware of this being investigated in previous works. "}, "signatures": ["ICLR.cc/2020/Conference/Paper1946/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1946/AnonReviewer1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "EMPIR: Ensembles of Mixed Precision Deep Networks for Increased Robustness Against Adversarial Attacks", "authors": ["Sanchari Sen", "Balaraman Ravindran", "Anand Raghunathan"], "authorids": ["sen9@purdue.edu", "ravi@cse.iitm.ac.in", "raghunathan@purdue.edu"], "keywords": ["ensembles", "mixed precision", "robustness", "adversarial attacks"], "TL;DR": "We propose ensembles of mixed-precision DNNs as a new form of defense against adversarial attacks", "abstract": "Ensuring robustness of Deep Neural Networks (DNNs) is crucial to their adoption in safety-critical applications such as self-driving cars, drones, and healthcare. Notably, DNNs are vulnerable to adversarial attacks in which small input perturbations can produce catastrophic misclassifications. In this work, we propose EMPIR, ensembles of quantized DNN models with different numerical precisions, as a new approach to increase robustness against adversarial attacks. EMPIR is based on the observation that quantized neural networks often demonstrate much higher robustness to adversarial attacks than full precision networks, but at the cost of a substantial loss in accuracy on the original (unperturbed) inputs. EMPIR overcomes this limitation to achieve the ``best of both worlds\", i.e., the higher unperturbed accuracies of the full precision models combined with the higher robustness of the low precision models, by composing them in an ensemble. Further, as low precision DNN models have significantly lower computational and storage requirements than full precision models, EMPIR models only incur modest compute and memory overheads compared to a single full-precision model (<25% in our evaluations). We evaluate EMPIR across a suite of DNNs for 3 different image recognition tasks (MNIST, CIFAR-10 and ImageNet) and under 4 different adversarial attacks. Our results indicate that EMPIR boosts the average adversarial accuracies by 42.6%, 15.2% and 10.5% for the DNN models trained on the MNIST, CIFAR-10 and ImageNet datasets respectively, when compared to single full-precision models, without sacrificing accuracy on the unperturbed inputs.", "pdf": "/pdf/abe3b71eab612c1ac73bcd543d40a277614b1d48.pdf", "paperhash": "sen|empir_ensembles_of_mixed_precision_deep_networks_for_increased_robustness_against_adversarial_attacks", "code": "https://github.com/sancharisen/EMPIR", "_bibtex": "@inproceedings{\nSen2020EMPIR:,\ntitle={EMPIR: Ensembles of Mixed Precision Deep Networks for Increased Robustness Against Adversarial Attacks},\nauthor={Sanchari Sen and Balaraman Ravindran and Anand Raghunathan},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=HJem3yHKwH}\n}", "full_presentation_video": "", "original_pdf": "/attachment/24752c0555dd6848ef8f7d45b1ead1004359f726.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "HJem3yHKwH", "replyto": "HJem3yHKwH", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper1946/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper1946/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1575847141813, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper1946/Reviewers"], "noninvitees": [], "tcdate": 1570237729999, "tmdate": 1575847141827, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper1946/-/Official_Review"}}}, {"id": "HJgE7loI5H", "original": null, "number": 3, "cdate": 1572413468176, "ddate": null, "tcdate": 1572413468176, "tmdate": 1572972403088, "tddate": null, "forum": "HJem3yHKwH", "replyto": "HJem3yHKwH", "invitation": "ICLR.cc/2020/Conference/Paper1946/-/Official_Review", "content": {"experience_assessment": "I have published in this field for several years.", "rating": "1: Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #4", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "This paper suggests using ensemble of both full-precision and low-bits precision models to defense adversarial examples.\n\nFrom methodological point of view, this idea is quite straightforward and not novel, since there are already several works that applied ensemble methods to improve the robustness of NNs, including the Strauss et.al 2017 and (the following references are not included in the manuscript)\n\"Adversarial Example Defenses: Ensembles of Weak Defenses are not Strong\nWarren He, James Wei, Xinyun Chen, Nicholas Carlini, Dawn Song\" \n\"Ensemble Adversarial Training: Attacks and Defenses\nFlorian Tram\u00e8r, Alexey Kurakin, Nicolas Papernot, Ian Goodfellow, Dan Boneh, Patrick McDaniel\" .\n\"Improving Adversarial Robustness via Promoting Ensemble Diversity\nTianyu Pang, Kun Xu, Chao Du,  Ning Chen,  Jun Zhu \" ICML 2019\n\nThough these methods only considered combining full-precision models, the idea is the same in essence and let the low-bits networks involve into the ensemble is quite natural and straightforward. So I don't think the methodology contribution of this paper is enough for publication.\n\nWhen checking the empirical results, the compared baselines miss a very common-used and strong baseline PGD adversarial training. And also the performance of this ensemble is not significant. \n\nConsidering the weakness of the paper both in methodology development and empirical justification, this work does not merit publication from my point of view. "}, "signatures": ["ICLR.cc/2020/Conference/Paper1946/AnonReviewer4"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1946/AnonReviewer4"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "EMPIR: Ensembles of Mixed Precision Deep Networks for Increased Robustness Against Adversarial Attacks", "authors": ["Sanchari Sen", "Balaraman Ravindran", "Anand Raghunathan"], "authorids": ["sen9@purdue.edu", "ravi@cse.iitm.ac.in", "raghunathan@purdue.edu"], "keywords": ["ensembles", "mixed precision", "robustness", "adversarial attacks"], "TL;DR": "We propose ensembles of mixed-precision DNNs as a new form of defense against adversarial attacks", "abstract": "Ensuring robustness of Deep Neural Networks (DNNs) is crucial to their adoption in safety-critical applications such as self-driving cars, drones, and healthcare. Notably, DNNs are vulnerable to adversarial attacks in which small input perturbations can produce catastrophic misclassifications. In this work, we propose EMPIR, ensembles of quantized DNN models with different numerical precisions, as a new approach to increase robustness against adversarial attacks. EMPIR is based on the observation that quantized neural networks often demonstrate much higher robustness to adversarial attacks than full precision networks, but at the cost of a substantial loss in accuracy on the original (unperturbed) inputs. EMPIR overcomes this limitation to achieve the ``best of both worlds\", i.e., the higher unperturbed accuracies of the full precision models combined with the higher robustness of the low precision models, by composing them in an ensemble. Further, as low precision DNN models have significantly lower computational and storage requirements than full precision models, EMPIR models only incur modest compute and memory overheads compared to a single full-precision model (<25% in our evaluations). We evaluate EMPIR across a suite of DNNs for 3 different image recognition tasks (MNIST, CIFAR-10 and ImageNet) and under 4 different adversarial attacks. Our results indicate that EMPIR boosts the average adversarial accuracies by 42.6%, 15.2% and 10.5% for the DNN models trained on the MNIST, CIFAR-10 and ImageNet datasets respectively, when compared to single full-precision models, without sacrificing accuracy on the unperturbed inputs.", "pdf": "/pdf/abe3b71eab612c1ac73bcd543d40a277614b1d48.pdf", "paperhash": "sen|empir_ensembles_of_mixed_precision_deep_networks_for_increased_robustness_against_adversarial_attacks", "code": "https://github.com/sancharisen/EMPIR", "_bibtex": "@inproceedings{\nSen2020EMPIR:,\ntitle={EMPIR: Ensembles of Mixed Precision Deep Networks for Increased Robustness Against Adversarial Attacks},\nauthor={Sanchari Sen and Balaraman Ravindran and Anand Raghunathan},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=HJem3yHKwH}\n}", "full_presentation_video": "", "original_pdf": "/attachment/24752c0555dd6848ef8f7d45b1ead1004359f726.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "HJem3yHKwH", "replyto": "HJem3yHKwH", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper1946/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper1946/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1575847141813, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper1946/Reviewers"], "noninvitees": [], "tcdate": 1570237729999, "tmdate": 1575847141827, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper1946/-/Official_Review"}}}], "count": 8}