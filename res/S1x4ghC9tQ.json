{"notes": [{"id": "S1x4ghC9tQ", "original": "BJef8Ln9Y7", "number": 1067, "cdate": 1538087916133, "ddate": null, "tcdate": 1538087916133, "tmdate": 1553791866618, "tddate": null, "forum": "S1x4ghC9tQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Temporal Difference Variational Auto-Encoder", "abstract": "To act and plan in complex environments, we posit that agents should have a mental simulator of the world with three characteristics: (a) it should build an abstract state representing the condition of the world; (b) it should form a belief which represents uncertainty on the world; (c) it should go beyond simple step-by-step simulation, and exhibit temporal abstraction. Motivated by the absence of a model satisfying all these requirements, we propose TD-VAE, a generative sequence model that learns representations containing explicit beliefs about states several steps into the future, and that can be rolled out directly without single-step transitions. TD-VAE is trained on pairs of temporally separated time points, using an analogue of temporal difference learning used in reinforcement learning.", "keywords": ["generative models", "variational auto-encoders", "state space models", "temporal difference learning"], "authorids": ["karol.gregor@gmail.com", "g.papamakarios@ed.ac.uk", "fbesse@google.com", "lbuesing@google.com", "theophane@google.com"], "authors": ["Karol Gregor", "George Papamakarios", "Frederic Besse", "Lars Buesing", "Theophane Weber"], "TL;DR": "Generative model of temporal data, that builds online belief state, operates in latent space, does jumpy predictions and rollouts of states.", "pdf": "/pdf/d053a90cc9fd47dc7cabd4045f47d06afbf2cf49.pdf", "paperhash": "gregor|temporal_difference_variational_autoencoder", "_bibtex": "@inproceedings{\ngregor2018temporal,\ntitle={Temporal Difference Variational Auto-Encoder},\nauthor={Karol Gregor and George Papamakarios and Frederic Besse and Lars Buesing and Theophane Weber},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=S1x4ghC9tQ},\n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"replyCount": 8, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Blind_Submission", "rdate": null, "ddate": null, "expdate": null, "duedate": 1538085600000, "tmdate": 1538142958393, "tddate": null, "super": null, "final": null, "reply": {"signatures": {"values": ["ICLR.cc/2019/Conference"]}, "forum": null, "readers": {"values": ["everyone"]}, "replyto": null, "content": {"authorids": {"values-regex": ".*"}, "authors": {"values": ["Anonymous"]}}, "writers": {"values": ["ICLR.cc/2019/Conference"]}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["~"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": null, "taskCompletionCount": null, "transform": null, "cdate": 1538142958393}}, "tauthor": "OpenReview.net"}, {"id": "HJeFv1wBm4", "original": null, "number": 1, "cdate": 1548214112605, "ddate": null, "tcdate": 1548214112605, "tmdate": 1548214175129, "tddate": null, "forum": "S1x4ghC9tQ", "replyto": "S1x4ghC9tQ", "invitation": "ICLR.cc/2019/Conference/-/Paper1067/Public_Comment", "content": {"comment": "Thanks for your great work.\n\nI have one question about DeepMind Lab experiments in this paper.\nIn Appendix D, you mentioned that p_D(x_{t_2}) is Bernoulli distribution and the log-likelihood is calculated using the logits outputted by the network in MNIST experiments.\nIs it same in the DeepMind Lab experiments?\nI think Normal distribution with a fixed variance is often used as decoder distribution in such color image generation, so if you used a different setting for DeepMind Lab experiments, I hope the setting is clearly written in the paper.\n\nThank you.\n", "title": "About DeepMind Lab experiments"}, "signatures": ["(anonymous)"], "readers": ["everyone"], "nonreaders": [], "writers": ["(anonymous)", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Temporal Difference Variational Auto-Encoder", "abstract": "To act and plan in complex environments, we posit that agents should have a mental simulator of the world with three characteristics: (a) it should build an abstract state representing the condition of the world; (b) it should form a belief which represents uncertainty on the world; (c) it should go beyond simple step-by-step simulation, and exhibit temporal abstraction. Motivated by the absence of a model satisfying all these requirements, we propose TD-VAE, a generative sequence model that learns representations containing explicit beliefs about states several steps into the future, and that can be rolled out directly without single-step transitions. TD-VAE is trained on pairs of temporally separated time points, using an analogue of temporal difference learning used in reinforcement learning.", "keywords": ["generative models", "variational auto-encoders", "state space models", "temporal difference learning"], "authorids": ["karol.gregor@gmail.com", "g.papamakarios@ed.ac.uk", "fbesse@google.com", "lbuesing@google.com", "theophane@google.com"], "authors": ["Karol Gregor", "George Papamakarios", "Frederic Besse", "Lars Buesing", "Theophane Weber"], "TL;DR": "Generative model of temporal data, that builds online belief state, operates in latent space, does jumpy predictions and rollouts of states.", "pdf": "/pdf/d053a90cc9fd47dc7cabd4045f47d06afbf2cf49.pdf", "paperhash": "gregor|temporal_difference_variational_autoencoder", "_bibtex": "@inproceedings{\ngregor2018temporal,\ntitle={Temporal Difference Variational Auto-Encoder},\nauthor={Karol Gregor and George Papamakarios and Frederic Besse and Lars Buesing and Theophane Weber},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=S1x4ghC9tQ},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper1067/Public_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1542311686711, "tddate": null, "super": null, "final": null, "reply": {"signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed."}, "nonreaders": {"values": []}, "forum": "S1x4ghC9tQ", "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper1067/Authors", "ICLR.cc/2019/Conference/Paper1067/Reviewers", "ICLR.cc/2019/Conference/Paper1067/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "replyto": null, "content": {"comment": {"value-regex": "[\\S\\s]{1,5000}", "required": true, "order": 1, "description": "Your comment or reply (max 5000 characters)."}, "title": {"value-regex": ".{1,500}", "required": true, "order": 0, "description": "Brief summary of your comment."}}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["~"], "noninvitees": ["ICLR.cc/2019/Conference/Paper1067/Authors", "ICLR.cc/2019/Conference/Paper1067/Reviewers", "ICLR.cc/2019/Conference/Paper1067/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1542311686711}}}, {"id": "HkgMMeVZxN", "original": null, "number": 1, "cdate": 1544794121837, "ddate": null, "tcdate": 1544794121837, "tmdate": 1545354524914, "tddate": null, "forum": "S1x4ghC9tQ", "replyto": "S1x4ghC9tQ", "invitation": "ICLR.cc/2019/Conference/-/Paper1067/Meta_Review", "content": {"metareview": "The reviewers agree that this is a novel paper with a convincing evaluation.", "confidence": "4: The area chair is confident but not absolutely certain", "recommendation": "Accept (Oral)", "title": "Original paper"}, "signatures": ["ICLR.cc/2019/Conference/Paper1067/Area_Chair1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference/Paper1067/Area_Chair1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Temporal Difference Variational Auto-Encoder", "abstract": "To act and plan in complex environments, we posit that agents should have a mental simulator of the world with three characteristics: (a) it should build an abstract state representing the condition of the world; (b) it should form a belief which represents uncertainty on the world; (c) it should go beyond simple step-by-step simulation, and exhibit temporal abstraction. Motivated by the absence of a model satisfying all these requirements, we propose TD-VAE, a generative sequence model that learns representations containing explicit beliefs about states several steps into the future, and that can be rolled out directly without single-step transitions. TD-VAE is trained on pairs of temporally separated time points, using an analogue of temporal difference learning used in reinforcement learning.", "keywords": ["generative models", "variational auto-encoders", "state space models", "temporal difference learning"], "authorids": ["karol.gregor@gmail.com", "g.papamakarios@ed.ac.uk", "fbesse@google.com", "lbuesing@google.com", "theophane@google.com"], "authors": ["Karol Gregor", "George Papamakarios", "Frederic Besse", "Lars Buesing", "Theophane Weber"], "TL;DR": "Generative model of temporal data, that builds online belief state, operates in latent space, does jumpy predictions and rollouts of states.", "pdf": "/pdf/d053a90cc9fd47dc7cabd4045f47d06afbf2cf49.pdf", "paperhash": "gregor|temporal_difference_variational_autoencoder", "_bibtex": "@inproceedings{\ngregor2018temporal,\ntitle={Temporal Difference Variational Auto-Encoder},\nauthor={Karol Gregor and George Papamakarios and Frederic Besse and Lars Buesing and Theophane Weber},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=S1x4ghC9tQ},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper1067/Meta_Review", "rdate": null, "ddate": null, "expdate": null, "duedate": 1541548800000, "tmdate": 1545352979938, "tddate": null, "super": null, "final": null, "reply": {"forum": "S1x4ghC9tQ", "replyto": "S1x4ghC9tQ", "readers": {"description": "Select all user groups that should be able to read this comment. Selecting 'All Users' will allow paper authors, reviewers, area chairs, and program chairs to view this comment.", "values": ["everyone"]}, "signatures": {"description": "How your identity will be displayed with the above content.", "values-regex": "ICLR.cc/2019/Conference/Paper1067/Area_Chair[0-9]+"}, "writers": {"description": "Users that may modify this record.", "values-regex": "ICLR.cc/2019/Conference/Paper1067/Area_Chair[0-9]+"}, "content": {"title": {"order": 1, "value-regex": ".{1,500}", "description": "Brief summary of your review.", "required": true}, "metareview": {"order": 2, "value-regex": "[\\S\\s]{1,5000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "required": true}, "recommendation": {"order": 3, "value-dropdown": ["Accept (Oral)", "Accept (Poster)", "Reject"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The area chair is absolutely certain", "4: The area chair is confident but not absolutely certain", "3: The area chair is somewhat confident", "2: The area chair is not sure", "1: The area chair's evaluation is an educated guess"], "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper1067/Area_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": false, "taskCompletionCount": null, "transform": null, "cdate": 1545352979938}}}, {"id": "BJxUrnv_AQ", "original": null, "number": 4, "cdate": 1543171133588, "ddate": null, "tcdate": 1543171133588, "tmdate": 1543171133588, "tddate": null, "forum": "S1x4ghC9tQ", "replyto": "BkgnEnawnm", "invitation": "ICLR.cc/2019/Conference/-/Paper1067/Official_Comment", "content": {"title": "Re:", "comment": "Thank you for your review and comments. We clarified our intuitive derivation of the loss in section A. It is indeed difficult to compare the jumpy TD-VAE model to other models, as there is little work that studies such models. We updated the appendix to explain how a model similar to jumpy TD-VAE provides an approximate ELBO to the \u2018jumpy\u2019 log likelihood log p(x_{t_1}, x_{t_2}, .. x_{t_n}). As for comparison to published models, we did compare the sequential TD-VAE elbo on the simple mini-pacman dataset to classical state-space models; we also compared the belief state obtained by training a TD-VAE on the oscillator network to a more classical lstm in a recurrent classification setup. Following the line of the thinking, we believe an appropriate way to compare similar models will be through the comparison of the different belief states they learn. We highlighted this in the text."}, "signatures": ["ICLR.cc/2019/Conference/Paper1067/Authors"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper1067/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper1067/Authors", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Temporal Difference Variational Auto-Encoder", "abstract": "To act and plan in complex environments, we posit that agents should have a mental simulator of the world with three characteristics: (a) it should build an abstract state representing the condition of the world; (b) it should form a belief which represents uncertainty on the world; (c) it should go beyond simple step-by-step simulation, and exhibit temporal abstraction. Motivated by the absence of a model satisfying all these requirements, we propose TD-VAE, a generative sequence model that learns representations containing explicit beliefs about states several steps into the future, and that can be rolled out directly without single-step transitions. TD-VAE is trained on pairs of temporally separated time points, using an analogue of temporal difference learning used in reinforcement learning.", "keywords": ["generative models", "variational auto-encoders", "state space models", "temporal difference learning"], "authorids": ["karol.gregor@gmail.com", "g.papamakarios@ed.ac.uk", "fbesse@google.com", "lbuesing@google.com", "theophane@google.com"], "authors": ["Karol Gregor", "George Papamakarios", "Frederic Besse", "Lars Buesing", "Theophane Weber"], "TL;DR": "Generative model of temporal data, that builds online belief state, operates in latent space, does jumpy predictions and rollouts of states.", "pdf": "/pdf/d053a90cc9fd47dc7cabd4045f47d06afbf2cf49.pdf", "paperhash": "gregor|temporal_difference_variational_autoencoder", "_bibtex": "@inproceedings{\ngregor2018temporal,\ntitle={Temporal Difference Variational Auto-Encoder},\nauthor={Karol Gregor and George Papamakarios and Frederic Besse and Lars Buesing and Theophane Weber},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=S1x4ghC9tQ},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper1067/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621612936, "tddate": null, "super": null, "final": null, "reply": {"forum": "S1x4ghC9tQ", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper1067/Authors", "ICLR.cc/2019/Conference/Paper1067/Reviewers", "ICLR.cc/2019/Conference/Paper1067/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper1067/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper1067/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper1067/Authors|ICLR.cc/2019/Conference/Paper1067/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper1067/Reviewers", "ICLR.cc/2019/Conference/Paper1067/Authors", "ICLR.cc/2019/Conference/Paper1067/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621612936}}}, {"id": "SyxSfnP_0Q", "original": null, "number": 3, "cdate": 1543171085239, "ddate": null, "tcdate": 1543171085239, "tmdate": 1543171085239, "tddate": null, "forum": "S1x4ghC9tQ", "replyto": "rJeR1S-ThQ", "invitation": "ICLR.cc/2019/Conference/-/Paper1067/Official_Comment", "content": {"title": "Re:", "comment": "Thank you for the review and comments. \nThanks for the suggestion - we added missing experiment details, network specifications and hyperparameters in the appendix. \nYou are correct that q(z_{t-1}|z_t, b_{t-1}, b_t) does not need to depend on b_{t-1}, but it does not hurt to do so; we chose to do so in order to further facilitate the learning of b_{t-1}, but it may not have affected experiments.\nIf the model does not take the jump interval as input, the model has to represent the jump size by way of a multimodal distribution over possible future events. One could imagine that one of the latent variables could be learned to correspond to dt. \n\n"}, "signatures": ["ICLR.cc/2019/Conference/Paper1067/Authors"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper1067/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper1067/Authors", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Temporal Difference Variational Auto-Encoder", "abstract": "To act and plan in complex environments, we posit that agents should have a mental simulator of the world with three characteristics: (a) it should build an abstract state representing the condition of the world; (b) it should form a belief which represents uncertainty on the world; (c) it should go beyond simple step-by-step simulation, and exhibit temporal abstraction. Motivated by the absence of a model satisfying all these requirements, we propose TD-VAE, a generative sequence model that learns representations containing explicit beliefs about states several steps into the future, and that can be rolled out directly without single-step transitions. TD-VAE is trained on pairs of temporally separated time points, using an analogue of temporal difference learning used in reinforcement learning.", "keywords": ["generative models", "variational auto-encoders", "state space models", "temporal difference learning"], "authorids": ["karol.gregor@gmail.com", "g.papamakarios@ed.ac.uk", "fbesse@google.com", "lbuesing@google.com", "theophane@google.com"], "authors": ["Karol Gregor", "George Papamakarios", "Frederic Besse", "Lars Buesing", "Theophane Weber"], "TL;DR": "Generative model of temporal data, that builds online belief state, operates in latent space, does jumpy predictions and rollouts of states.", "pdf": "/pdf/d053a90cc9fd47dc7cabd4045f47d06afbf2cf49.pdf", "paperhash": "gregor|temporal_difference_variational_autoencoder", "_bibtex": "@inproceedings{\ngregor2018temporal,\ntitle={Temporal Difference Variational Auto-Encoder},\nauthor={Karol Gregor and George Papamakarios and Frederic Besse and Lars Buesing and Theophane Weber},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=S1x4ghC9tQ},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper1067/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621612936, "tddate": null, "super": null, "final": null, "reply": {"forum": "S1x4ghC9tQ", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper1067/Authors", "ICLR.cc/2019/Conference/Paper1067/Reviewers", "ICLR.cc/2019/Conference/Paper1067/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper1067/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper1067/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper1067/Authors|ICLR.cc/2019/Conference/Paper1067/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper1067/Reviewers", "ICLR.cc/2019/Conference/Paper1067/Authors", "ICLR.cc/2019/Conference/Paper1067/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621612936}}}, {"id": "BJgAOovOC7", "original": null, "number": 2, "cdate": 1543170933601, "ddate": null, "tcdate": 1543170933601, "tmdate": 1543170933601, "tddate": null, "forum": "S1x4ghC9tQ", "replyto": "rkeaQHUJam", "invitation": "ICLR.cc/2019/Conference/-/Paper1067/Official_Comment", "content": {"title": "Re:", "comment": "Thank you for your thoughtful review and comments.  \n\nThanks for noticing the typo - we will fix it.\nRegarding the exposure bias - TD-VAE may indeed reduce exposure bias by generating faraway futures in fewer steps of generation. But we have not explicitly investigated that issue in the paper.\nRegarding the distribution of (t_2-t_1), for the noisy harmonic oscillator experiment we use a mixture of two uniform distributions, one with support [1,T], the second with support [1,T\u2019], with T\u2019>T. Since shorter time steps are easy to model, this served as a form of \u2018curriculum\u2019 for the jumpy model; this enables us to learn the state representation, which in turns facilitates learning the \u2018jumpier\u2019 transitions from [1,T\u2019]. We clarify this in the text.  It is indeed likely that weighting [1,T'] more heavily would indeed improve the jumpier prediction.\nMore general strategies could be adopted, for instance choosing jump sizes which make the jump easy to predict (as is suggested in Neitz et al. and Jayaraman et al.), or hard to predict (a form of prioritized replay for model learning), or any other criterion. We reserve the investigation of which scheme leads to the best model to future work.\nAs for code, we will aim to release a simplified version of the code in the future.\n"}, "signatures": ["ICLR.cc/2019/Conference/Paper1067/Authors"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper1067/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper1067/Authors", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Temporal Difference Variational Auto-Encoder", "abstract": "To act and plan in complex environments, we posit that agents should have a mental simulator of the world with three characteristics: (a) it should build an abstract state representing the condition of the world; (b) it should form a belief which represents uncertainty on the world; (c) it should go beyond simple step-by-step simulation, and exhibit temporal abstraction. Motivated by the absence of a model satisfying all these requirements, we propose TD-VAE, a generative sequence model that learns representations containing explicit beliefs about states several steps into the future, and that can be rolled out directly without single-step transitions. TD-VAE is trained on pairs of temporally separated time points, using an analogue of temporal difference learning used in reinforcement learning.", "keywords": ["generative models", "variational auto-encoders", "state space models", "temporal difference learning"], "authorids": ["karol.gregor@gmail.com", "g.papamakarios@ed.ac.uk", "fbesse@google.com", "lbuesing@google.com", "theophane@google.com"], "authors": ["Karol Gregor", "George Papamakarios", "Frederic Besse", "Lars Buesing", "Theophane Weber"], "TL;DR": "Generative model of temporal data, that builds online belief state, operates in latent space, does jumpy predictions and rollouts of states.", "pdf": "/pdf/d053a90cc9fd47dc7cabd4045f47d06afbf2cf49.pdf", "paperhash": "gregor|temporal_difference_variational_autoencoder", "_bibtex": "@inproceedings{\ngregor2018temporal,\ntitle={Temporal Difference Variational Auto-Encoder},\nauthor={Karol Gregor and George Papamakarios and Frederic Besse and Lars Buesing and Theophane Weber},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=S1x4ghC9tQ},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper1067/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621612936, "tddate": null, "super": null, "final": null, "reply": {"forum": "S1x4ghC9tQ", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper1067/Authors", "ICLR.cc/2019/Conference/Paper1067/Reviewers", "ICLR.cc/2019/Conference/Paper1067/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper1067/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper1067/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper1067/Authors|ICLR.cc/2019/Conference/Paper1067/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper1067/Reviewers", "ICLR.cc/2019/Conference/Paper1067/Authors", "ICLR.cc/2019/Conference/Paper1067/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621612936}}}, {"id": "rkeaQHUJam", "original": null, "number": 3, "cdate": 1541526821395, "ddate": null, "tcdate": 1541526821395, "tmdate": 1541533451939, "tddate": null, "forum": "S1x4ghC9tQ", "replyto": "S1x4ghC9tQ", "invitation": "ICLR.cc/2019/Conference/-/Paper1067/Official_Review", "content": {"title": "Nice and novel idea", "review": "This paper proposes the temporal difference variational auto-encoder framework, a sequential general model following the intuition of temporal difference learning in reinforcement learning. The idea is nice and novel, and I vote for acceptance.\n1. The introduction of belief state in the sequential model is smart. How incorporate such technique in such an autoregressive model is not easy.\n2. Fig 1 clearly explained the VAE process.\n3. Four experiments demonstrated the main advantages of the proposed framework, including the effectiveness of proposed belief state construction and ability to jumpy rolling-out, \n\n\nOther Comments and Questions:\n1. Typo, p(s_{t_2}|s_{t_1}) in the caption of Fig 1.\n2. Can this framework partially solve the exposure bias?\n3. The author used uniform distribution for t_2 - t1, and from the ``NOISY HARMONIC OSCILLATOR`` we can indeed see larger interval will result in worse performance. However, the author also mentioned other distortion could be investigated, so I am wondering if the larger probability mass is put on larger dt, what the performance will become.\n4. The code should be released. I think that it is a fundamental framework deserving further development  by other researchers.", "rating": "8: Top 50% of accepted papers, clear accept", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["ICLR.cc/2019/Conference/Paper1067/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Temporal Difference Variational Auto-Encoder", "abstract": "To act and plan in complex environments, we posit that agents should have a mental simulator of the world with three characteristics: (a) it should build an abstract state representing the condition of the world; (b) it should form a belief which represents uncertainty on the world; (c) it should go beyond simple step-by-step simulation, and exhibit temporal abstraction. Motivated by the absence of a model satisfying all these requirements, we propose TD-VAE, a generative sequence model that learns representations containing explicit beliefs about states several steps into the future, and that can be rolled out directly without single-step transitions. TD-VAE is trained on pairs of temporally separated time points, using an analogue of temporal difference learning used in reinforcement learning.", "keywords": ["generative models", "variational auto-encoders", "state space models", "temporal difference learning"], "authorids": ["karol.gregor@gmail.com", "g.papamakarios@ed.ac.uk", "fbesse@google.com", "lbuesing@google.com", "theophane@google.com"], "authors": ["Karol Gregor", "George Papamakarios", "Frederic Besse", "Lars Buesing", "Theophane Weber"], "TL;DR": "Generative model of temporal data, that builds online belief state, operates in latent space, does jumpy predictions and rollouts of states.", "pdf": "/pdf/d053a90cc9fd47dc7cabd4045f47d06afbf2cf49.pdf", "paperhash": "gregor|temporal_difference_variational_autoencoder", "_bibtex": "@inproceedings{\ngregor2018temporal,\ntitle={Temporal Difference Variational Auto-Encoder},\nauthor={Karol Gregor and George Papamakarios and Frederic Besse and Lars Buesing and Theophane Weber},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=S1x4ghC9tQ},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper1067/Official_Review", "cdate": 1542234313544, "expdate": 1552335264000, "duedate": 1541196000000, "reply": {"forum": "S1x4ghC9tQ", "replyto": "S1x4ghC9tQ", "readers": {"description": "The users who will be allowed to read the reply content.", "values": ["everyone"]}, "nonreaders": {"values": []}, "signatures": {"description": "How your identity will be displayed with the above content.", "values-regex": "ICLR.cc/2019/Conference/Paper1067/AnonReviewer[0-9]+"}, "writers": {"description": "Users that may modify this record.", "values": ["ICLR.cc/2019/Conference"]}, "content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "required": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}}, "multiReply": false, "tcdate": 1552335865514, "tmdate": 1552335865514, "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "invitees": ["ICLR.cc/2019/Conference/Paper1067/Reviewers"], "noninvitees": [], "signatures": ["ICLR.cc/2019/Conference"]}}}, {"id": "rJeR1S-ThQ", "original": null, "number": 2, "cdate": 1541375205526, "ddate": null, "tcdate": 1541375205526, "tmdate": 1541533451734, "tddate": null, "forum": "S1x4ghC9tQ", "replyto": "S1x4ghC9tQ", "invitation": "ICLR.cc/2019/Conference/-/Paper1067/Official_Review", "content": {"title": "Very strong", "review": "The authors propose TD-VAE to solve an important problem in agent learning, simulating the future by doing jumpy-rollouts in abstract states with uncertainty. The authors first formulate the sequential TD-VAE and then generalize it for jumpy rollouts. The proposed method is well evaluated for four tasks including high dimensional complex task.\n\nPros.\n- Advancing a significant problem\n- Principled and quite original modeling based on variational inference\n- Rigorous experiments including complex high dimensional experiments\n- Clear and intuitive explanation (but can be improved further)\n\nCons. \n- Some details on the experiments are missing (due to page limit). It would be great to include these in the Appendix. \n- It is a complex model. For reproducibility, detail specification on the hyperparameters and architecture will be helpful.\n\nMinor comments\n- Why q(z_{t-1}|z_t, b_{t-1}, b_t) depends both  b_{t-1}, b_t, not only b_t?\n- The original model does not take the jump interval as input. Then, it is not clear how the jump interval is determined in p(z\u2019|z)?\n", "rating": "9: Top 15% of accepted papers, strong accept", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["ICLR.cc/2019/Conference/Paper1067/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Temporal Difference Variational Auto-Encoder", "abstract": "To act and plan in complex environments, we posit that agents should have a mental simulator of the world with three characteristics: (a) it should build an abstract state representing the condition of the world; (b) it should form a belief which represents uncertainty on the world; (c) it should go beyond simple step-by-step simulation, and exhibit temporal abstraction. Motivated by the absence of a model satisfying all these requirements, we propose TD-VAE, a generative sequence model that learns representations containing explicit beliefs about states several steps into the future, and that can be rolled out directly without single-step transitions. TD-VAE is trained on pairs of temporally separated time points, using an analogue of temporal difference learning used in reinforcement learning.", "keywords": ["generative models", "variational auto-encoders", "state space models", "temporal difference learning"], "authorids": ["karol.gregor@gmail.com", "g.papamakarios@ed.ac.uk", "fbesse@google.com", "lbuesing@google.com", "theophane@google.com"], "authors": ["Karol Gregor", "George Papamakarios", "Frederic Besse", "Lars Buesing", "Theophane Weber"], "TL;DR": "Generative model of temporal data, that builds online belief state, operates in latent space, does jumpy predictions and rollouts of states.", "pdf": "/pdf/d053a90cc9fd47dc7cabd4045f47d06afbf2cf49.pdf", "paperhash": "gregor|temporal_difference_variational_autoencoder", "_bibtex": "@inproceedings{\ngregor2018temporal,\ntitle={Temporal Difference Variational Auto-Encoder},\nauthor={Karol Gregor and George Papamakarios and Frederic Besse and Lars Buesing and Theophane Weber},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=S1x4ghC9tQ},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper1067/Official_Review", "cdate": 1542234313544, "expdate": 1552335264000, "duedate": 1541196000000, "reply": {"forum": "S1x4ghC9tQ", "replyto": "S1x4ghC9tQ", "readers": {"description": "The users who will be allowed to read the reply content.", "values": ["everyone"]}, "nonreaders": {"values": []}, "signatures": {"description": "How your identity will be displayed with the above content.", "values-regex": "ICLR.cc/2019/Conference/Paper1067/AnonReviewer[0-9]+"}, "writers": {"description": "Users that may modify this record.", "values": ["ICLR.cc/2019/Conference"]}, "content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "required": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}}, "multiReply": false, "tcdate": 1552335865514, "tmdate": 1552335865514, "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "invitees": ["ICLR.cc/2019/Conference/Paper1067/Reviewers"], "noninvitees": [], "signatures": ["ICLR.cc/2019/Conference"]}}}, {"id": "BkgnEnawnm", "original": null, "number": 1, "cdate": 1541033011572, "ddate": null, "tcdate": 1541033011572, "tmdate": 1541533451531, "tddate": null, "forum": "S1x4ghC9tQ", "replyto": "S1x4ghC9tQ", "invitation": "ICLR.cc/2019/Conference/-/Paper1067/Official_Review", "content": {"title": "TD-VAE", "review": "There are several ingredients in this paper that I really liked. For example, (1) the notion that an agent should build a deterministic function of the past which implicitly captures the belief (the uncertainty or probability distribution about the state), by opposition for example to sampling trajectories to capture uncertainty, (2) modelling the world's dynamic in a learned encoded state-space (by opposition to the sensor space), (3) instead of modeling next-step probabilities p(z(t+1)|z(t)), model 'jumpy transitions' p(z(t+delta)|z(t)) to avoid unrolling at the finest time scale.\n\nNow for the weak points:\n(a) the justification for the training loss was not completely clear to me, although I can see that it has a variational flavor\n(b) there is no discussion of the issue that we can't get a straightforward decomposition of the joint probability over the data sequence according to next-step probabilities via the chain rule of probabilities, so we don't have a clear way to compare the TD-VAE models with jumpy predictions against other more traditional models\n(c) none of the experiments make comparisons against previously published models and quantitative results (admittedly because of (b) this may not be easy).\n\nSo I believe that the authors are onto a great direction of investigation, but the execution of the paper could be improved.", "rating": "7: Good paper, accept", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}, "signatures": ["ICLR.cc/2019/Conference/Paper1067/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Temporal Difference Variational Auto-Encoder", "abstract": "To act and plan in complex environments, we posit that agents should have a mental simulator of the world with three characteristics: (a) it should build an abstract state representing the condition of the world; (b) it should form a belief which represents uncertainty on the world; (c) it should go beyond simple step-by-step simulation, and exhibit temporal abstraction. Motivated by the absence of a model satisfying all these requirements, we propose TD-VAE, a generative sequence model that learns representations containing explicit beliefs about states several steps into the future, and that can be rolled out directly without single-step transitions. TD-VAE is trained on pairs of temporally separated time points, using an analogue of temporal difference learning used in reinforcement learning.", "keywords": ["generative models", "variational auto-encoders", "state space models", "temporal difference learning"], "authorids": ["karol.gregor@gmail.com", "g.papamakarios@ed.ac.uk", "fbesse@google.com", "lbuesing@google.com", "theophane@google.com"], "authors": ["Karol Gregor", "George Papamakarios", "Frederic Besse", "Lars Buesing", "Theophane Weber"], "TL;DR": "Generative model of temporal data, that builds online belief state, operates in latent space, does jumpy predictions and rollouts of states.", "pdf": "/pdf/d053a90cc9fd47dc7cabd4045f47d06afbf2cf49.pdf", "paperhash": "gregor|temporal_difference_variational_autoencoder", "_bibtex": "@inproceedings{\ngregor2018temporal,\ntitle={Temporal Difference Variational Auto-Encoder},\nauthor={Karol Gregor and George Papamakarios and Frederic Besse and Lars Buesing and Theophane Weber},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=S1x4ghC9tQ},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper1067/Official_Review", "cdate": 1542234313544, "expdate": 1552335264000, "duedate": 1541196000000, "reply": {"forum": "S1x4ghC9tQ", "replyto": "S1x4ghC9tQ", "readers": {"description": "The users who will be allowed to read the reply content.", "values": ["everyone"]}, "nonreaders": {"values": []}, "signatures": {"description": "How your identity will be displayed with the above content.", "values-regex": "ICLR.cc/2019/Conference/Paper1067/AnonReviewer[0-9]+"}, "writers": {"description": "Users that may modify this record.", "values": ["ICLR.cc/2019/Conference"]}, "content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "required": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}}, "multiReply": false, "tcdate": 1552335865514, "tmdate": 1552335865514, "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "invitees": ["ICLR.cc/2019/Conference/Paper1067/Reviewers"], "noninvitees": [], "signatures": ["ICLR.cc/2019/Conference"]}}}], "count": 9}