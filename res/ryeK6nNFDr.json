{"notes": [{"id": "ryeK6nNFDr", "original": "BJesmPsXDr", "number": 235, "cdate": 1569438913167, "ddate": null, "tcdate": 1569438913167, "tmdate": 1577168272391, "tddate": null, "forum": "ryeK6nNFDr", "replyto": null, "invitation": "ICLR.cc/2020/Conference/-/Blind_Submission", "content": {"authorids": ["machengcheng2016@gmail.com", "wubaoyuan1987@gmail.com", "shibiao.xu@ia.ac.cn", "fanyanbo0124@gmail.com", "zhangyong201303@gmail.com", "xiaopeng.zhang@ia.ac.cn", "michaelzfli@tencent.com"], "title": "Effective and Robust Detection of Adversarial Examples via Benford-Fourier Coefficients", "authors": ["Chengcheng Ma", "Baoyuan Wu", "Shibiao Xu", "Yanbo Fan", "Yong Zhang", "Xiaopeng Zhang", "Zhifeng Li"], "pdf": "/pdf/8ba2e6bdf85037141dc90b95eb3607c53e112ee1.pdf", "abstract": "Adversarial examples have been well known as a serious threat to deep neural\nnetworks (DNNs). To ensure successful and safe operations of DNNs on realworld tasks, \nit is urgent to equip DNNs with effective defense strategies. In this\nwork, we study the detection of adversarial examples, based on the assumption\nthat the output and internal responses of one DNN model for both adversarial and\nbenign examples follow the generalized Gaussian distribution (GGD), but with\ndifferent parameters (i.e., shape factor, mean, and variance). GGD is a general\ndistribution family to cover many popular distributions (e.g., Laplacian, Gaussian,\nor uniform). It is more likely to approximate the intrinsic distributions of internal\nresponses than any specific distribution. Besides, since the shape factor is more\nrobust to different databases rather than the other two parameters, we propose\nto construct discriminative features via the shape factor for adversarial detection,\nemploying the magnitude of Benford-Fourier coefficients (MBF), which can be\neasily estimated using responses. Finally, a support vector machine is trained\nas the adversarial detector through leveraging the MBF features. Through the\nKolmogorov-Smirnov (KS) test, we empirically verify that: 1) the posterior vectors \nof both adversarial and benign examples follow GGD; 2) the extracted MBF features \nof adversarial and benign examples follow different distributions. Extensive \nexperiments in terms of image classification demonstrate that the proposed \ndetector is much more effective and robust on detecting adversarial examples \nof different crafting methods and different sources, in contrast to state-of-the-art \nadversarial detection methods.", "keywords": [], "paperhash": "ma|effective_and_robust_detection_of_adversarial_examples_via_benfordfourier_coefficients", "original_pdf": "/attachment/096dbd0e221aa0f7b867a8dcc75522740d5b0de4.pdf", "_bibtex": "@misc{\nma2020effective,\ntitle={Effective and Robust Detection of Adversarial Examples via Benford-Fourier Coefficients},\nauthor={Chengcheng Ma and Baoyuan Wu and Shibiao Xu and Yanbo Fan and Yong Zhang and Xiaopeng Zhang and Zhifeng Li},\nyear={2020},\nurl={https://openreview.net/forum?id=ryeK6nNFDr}\n}"}, "signatures": ["ICLR.cc/2020/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference"], "details": {"replyCount": 7, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"reply": {"readers": {"values-regex": ".*"}, "writers": {"values": ["ICLR.cc/2020/Conference"]}, "signatures": {"values": ["ICLR.cc/2020/Conference"]}, "content": {"spotlight_video": {"value-regex": ".*"}, "full_presentation_video": {"value-regex": ".*"}, "original_pdf": {"required": false, "description": "Upload a PDF file that ends with .pdf", "value-regex": ".*"}, "appendix": {"value-regex": ".*"}, "authorids": {"values-regex": ".*"}, "poster": {"value-regex": ".*"}, "authors": {"values": ["Anonymous"]}, "slides": {"value-regex": ".*"}}}, "final": [], "signatures": ["ICLR.cc/2020/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference"], "noninvitees": [], "tcdate": 1569271260237, "tmdate": 1593459412141, "id": "ICLR.cc/2020/Conference/-/Blind_Submission"}}, "tauthor": "OpenReview.net"}, {"id": "TG8eEFB3TH", "original": null, "number": 1, "cdate": 1576798691033, "ddate": null, "tcdate": 1576798691033, "tmdate": 1576800944198, "tddate": null, "forum": "ryeK6nNFDr", "replyto": "ryeK6nNFDr", "invitation": "ICLR.cc/2020/Conference/Paper235/-/Decision", "content": {"decision": "Reject", "comment": "This paper presents a new metric for adversarial attack's detection. The reviewers find the idea interesting, but the some part has not been clearly explained, and there are questions on the reproducibility issue of the experiments. ", "title": "Paper Decision"}, "signatures": ["ICLR.cc/2020/Conference/Program_Chairs"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Program_Chairs"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["machengcheng2016@gmail.com", "wubaoyuan1987@gmail.com", "shibiao.xu@ia.ac.cn", "fanyanbo0124@gmail.com", "zhangyong201303@gmail.com", "xiaopeng.zhang@ia.ac.cn", "michaelzfli@tencent.com"], "title": "Effective and Robust Detection of Adversarial Examples via Benford-Fourier Coefficients", "authors": ["Chengcheng Ma", "Baoyuan Wu", "Shibiao Xu", "Yanbo Fan", "Yong Zhang", "Xiaopeng Zhang", "Zhifeng Li"], "pdf": "/pdf/8ba2e6bdf85037141dc90b95eb3607c53e112ee1.pdf", "abstract": "Adversarial examples have been well known as a serious threat to deep neural\nnetworks (DNNs). To ensure successful and safe operations of DNNs on realworld tasks, \nit is urgent to equip DNNs with effective defense strategies. In this\nwork, we study the detection of adversarial examples, based on the assumption\nthat the output and internal responses of one DNN model for both adversarial and\nbenign examples follow the generalized Gaussian distribution (GGD), but with\ndifferent parameters (i.e., shape factor, mean, and variance). GGD is a general\ndistribution family to cover many popular distributions (e.g., Laplacian, Gaussian,\nor uniform). It is more likely to approximate the intrinsic distributions of internal\nresponses than any specific distribution. Besides, since the shape factor is more\nrobust to different databases rather than the other two parameters, we propose\nto construct discriminative features via the shape factor for adversarial detection,\nemploying the magnitude of Benford-Fourier coefficients (MBF), which can be\neasily estimated using responses. Finally, a support vector machine is trained\nas the adversarial detector through leveraging the MBF features. Through the\nKolmogorov-Smirnov (KS) test, we empirically verify that: 1) the posterior vectors \nof both adversarial and benign examples follow GGD; 2) the extracted MBF features \nof adversarial and benign examples follow different distributions. Extensive \nexperiments in terms of image classification demonstrate that the proposed \ndetector is much more effective and robust on detecting adversarial examples \nof different crafting methods and different sources, in contrast to state-of-the-art \nadversarial detection methods.", "keywords": [], "paperhash": "ma|effective_and_robust_detection_of_adversarial_examples_via_benfordfourier_coefficients", "original_pdf": "/attachment/096dbd0e221aa0f7b867a8dcc75522740d5b0de4.pdf", "_bibtex": "@misc{\nma2020effective,\ntitle={Effective and Robust Detection of Adversarial Examples via Benford-Fourier Coefficients},\nauthor={Chengcheng Ma and Baoyuan Wu and Shibiao Xu and Yanbo Fan and Yong Zhang and Xiaopeng Zhang and Zhifeng Li},\nyear={2020},\nurl={https://openreview.net/forum?id=ryeK6nNFDr}\n}"}, "tags": [], "invitation": {"reply": {"writers": {"description": "How your identity will be displayed.", "values-regex": ["ICLR.cc/2020/Conference/Program_Chairs"]}, "signatures": {"values": ["ICLR.cc/2020/Conference/Program_Chairs"], "description": "How your identity will be displayed."}, "content": {"decision": {"value-radio": ["Accept (Spotlight)", "Accept (Talk)", "Accept (Poster)", "Reject"], "description": "Decision", "required": true, "order": 2}, "title": {"value": "Paper Decision", "required": true, "order": 1}, "comment": {"value-regex": "[\\S\\s]{0,5000}", "description": "", "required": false, "order": 3}}, "forum": "ryeK6nNFDr", "replyto": "ryeK6nNFDr", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}}, "expdate": 1576854540000, "duedate": 1576853940000, "multiReply": false, "readers": ["everyone"], "invitees": ["ICLR.cc/2020/Conference/Program_Chairs"], "tcdate": 1576795715495, "tmdate": 1576800265418, "super": "ICLR.cc/2020/Conference/-/Decision", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper235/-/Decision"}}}, {"id": "HJxDgg2qsr", "original": null, "number": 3, "cdate": 1573728238660, "ddate": null, "tcdate": 1573728238660, "tmdate": 1573728238660, "tddate": null, "forum": "ryeK6nNFDr", "replyto": "Skx3wFCmcr", "invitation": "ICLR.cc/2020/Conference/Paper235/-/Official_Comment", "content": {"title": "Response to Reviewer #1", "comment": "We thank the reviewer for the comments and appreciation, and would like to answer the reviewer\u2019s questions as follows:\nMajor 1. \nYes, we indeed assume that \u201call the response entries of one layer as different samples on one certain GGD\u201d. However, it should be emphasized that, as demonstrated above Eq. (5), \u201cassume that x = {x1, \u2026, x_M} is a set of M i.i.d. points sampled from GGD with the same shape factor\u201d. It means that we only assume the shape factor of GGD is same, while the parameters mean and standard deviation could be different. Thus, we only extract the features of the magnitude of Benford-Fourier coefficient which could estimate the shape factor as the discriminative features between adversarial and benign examples. \nTo validate this assumption, we present hypothesis tests for both benign and adversarial examples, in Section 4.5. As shown in Table 6, the p-values under different attacks are all over 5%, that means the hypothesis H0 is accepted, i.e., the benign/adversarial responses follow GGD with the same shape factor. Thus, we can claim that this assumption is statistically true. Our experimental results also support this assumption.\nFinally, we try to clarify the rationale behind this assumption once again. 1) We believe the features (including the internal responses and the fully-connected features) of adversarial examples should also follow some distributions, similar to benign examples. If not that case, it is difficult to understand/explain why the adversarial examples (generated by different attack methods and on different benign examples) could be enforced to avoid the original class (untargeted attack) or to be predicted as one certain target class (targeted attack). 2) We don\u2019t believe that the features of adversarial and benign examples simply follow different Gaussian distributions, as the parameter mean and standard deviation of Gaussian distribution could vary significantly among different data sources and attack methods. These adversarial examples should be similar to each other and different to benign examples at some higher-level perspectives. Thus, we choose the GGD distribution, which is very general to cover many widely used distributions. And, the shape factor of GGD is more robust than the mean and standard deviation, across different data sources. This is why we propose such an assumption. \nHope above explanations could provide some informative messages to understand the proposed assumption.\n\nMajor 2.\nThanks for this helpful suggestion. We do a detailed statistics of all response layers on CIFAR-10. We find that although the mean parameters at most layers are close to 0, the mean parameters at a few layers could be large. Specifically, for each image and each layer, we compute one mean parameter. Then, for each layer, we compute the average and standard deviation of the mean parameters across the whole database. The average values of all layers range from 6e-3 to 6.9, and the standard deviation of all layers range from 0 to 4.3. However, in our experiments, the mean value is subtracted from each response entry when we extract the MBF features. Thus, the assumption that the mean parameter of GGD is always satisfied. This point has been clarified in the revised manuscript. \n\nMajor 3.\nThanks for this helpful suggestion. In experiments, we adopt the default parameter setting in Foolbox (v1.8.0). Specifically, the default parameters of each attack methods are:\n\u2018BIM\u2019(eps=0.3, stepsize=0.05, iterations=10); \u2018CarliniWagnerL2Attack\u2019(binary_search_steps=5, confidence=0, learning_rate=0.005, max_iterations=1000); \u2018DeepFoolAttack\u2019(max_steps=100); \u2018RandomPGD\u2019(epsilon=0.3, stepsize=0.01, iterations=40). These have been clarified in the revised manuscript. \n\nMinor 1.\nThanks. It has been corrected in the revised manuscript."}, "signatures": ["ICLR.cc/2020/Conference/Paper235/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper235/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["machengcheng2016@gmail.com", "wubaoyuan1987@gmail.com", "shibiao.xu@ia.ac.cn", "fanyanbo0124@gmail.com", "zhangyong201303@gmail.com", "xiaopeng.zhang@ia.ac.cn", "michaelzfli@tencent.com"], "title": "Effective and Robust Detection of Adversarial Examples via Benford-Fourier Coefficients", "authors": ["Chengcheng Ma", "Baoyuan Wu", "Shibiao Xu", "Yanbo Fan", "Yong Zhang", "Xiaopeng Zhang", "Zhifeng Li"], "pdf": "/pdf/8ba2e6bdf85037141dc90b95eb3607c53e112ee1.pdf", "abstract": "Adversarial examples have been well known as a serious threat to deep neural\nnetworks (DNNs). To ensure successful and safe operations of DNNs on realworld tasks, \nit is urgent to equip DNNs with effective defense strategies. In this\nwork, we study the detection of adversarial examples, based on the assumption\nthat the output and internal responses of one DNN model for both adversarial and\nbenign examples follow the generalized Gaussian distribution (GGD), but with\ndifferent parameters (i.e., shape factor, mean, and variance). GGD is a general\ndistribution family to cover many popular distributions (e.g., Laplacian, Gaussian,\nor uniform). It is more likely to approximate the intrinsic distributions of internal\nresponses than any specific distribution. Besides, since the shape factor is more\nrobust to different databases rather than the other two parameters, we propose\nto construct discriminative features via the shape factor for adversarial detection,\nemploying the magnitude of Benford-Fourier coefficients (MBF), which can be\neasily estimated using responses. Finally, a support vector machine is trained\nas the adversarial detector through leveraging the MBF features. Through the\nKolmogorov-Smirnov (KS) test, we empirically verify that: 1) the posterior vectors \nof both adversarial and benign examples follow GGD; 2) the extracted MBF features \nof adversarial and benign examples follow different distributions. Extensive \nexperiments in terms of image classification demonstrate that the proposed \ndetector is much more effective and robust on detecting adversarial examples \nof different crafting methods and different sources, in contrast to state-of-the-art \nadversarial detection methods.", "keywords": [], "paperhash": "ma|effective_and_robust_detection_of_adversarial_examples_via_benfordfourier_coefficients", "original_pdf": "/attachment/096dbd0e221aa0f7b867a8dcc75522740d5b0de4.pdf", "_bibtex": "@misc{\nma2020effective,\ntitle={Effective and Robust Detection of Adversarial Examples via Benford-Fourier Coefficients},\nauthor={Chengcheng Ma and Baoyuan Wu and Shibiao Xu and Yanbo Fan and Yong Zhang and Xiaopeng Zhang and Zhifeng Li},\nyear={2020},\nurl={https://openreview.net/forum?id=ryeK6nNFDr}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "ryeK6nNFDr", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper235/Authors", "ICLR.cc/2020/Conference/Paper235/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper235/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper235/Reviewers", "ICLR.cc/2020/Conference/Paper235/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper235/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper235/Authors|ICLR.cc/2020/Conference/Paper235/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504174387, "tmdate": 1576860538745, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper235/Authors", "ICLR.cc/2020/Conference/Paper235/Reviewers", "ICLR.cc/2020/Conference/Paper235/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper235/-/Official_Comment"}}}, {"id": "H1ghiCjqoB", "original": null, "number": 2, "cdate": 1573727908091, "ddate": null, "tcdate": 1573727908091, "tmdate": 1573727908091, "tddate": null, "forum": "ryeK6nNFDr", "replyto": "SyeSm3HiYr", "invitation": "ICLR.cc/2020/Conference/Paper235/-/Official_Comment", "content": {"title": "Response to Reviewer #3", "comment": "Thanks for the constructive comments.\n1)\tThe equation for computing the MBF feature, i.e., Eq. (8), may look \u201ccomplicated\u201d, since it involves sin and cosine function. But the truth is that it is rather simple, and the computational cost is only O(M_i^l) for the l-th layer of the i-th training image, with M_i^l being the number of entries in that layer. In contrast, the features computed in LID will utilize the responses of other training images, and its computation is more complicated than ours. \n2)\tHowever, the question that whether the complexity of features is important for an effective detector is very interesting. If we understand correctly, this sentence \u201cif we use the feature vectors of different layers in CNNs and combine them with a different non-linear function and feed into an SVM classifier, can we still obtain a hard-to-evade detector\u201d is asking that whether the discriminative features included in the responses could be approximated by one additional model (e.g., the neural network). The answer should be yes. As mentioned in the response to Reviewer 2 (see above), Defense-GAN actually do that. It is like to compare the hand-crafted features + shallow classifier (i.e., shallow learning) and the features learned together with the classifier (e.g., deep learning). Both our MBF method and LID belong to the same type, while Defense-GAN belongs to the second type. It is difficult to tell which type is better for adversarial detection. Both of them have advantages and limitations. The first type is computationally cheaper, as the features are computed following some fixed equations. In contrast, the second type has to train a new model, maybe for each database and each attack method, which is rather costly. Besides, the second type is likely to require much more training data than the first type to achieve satisfied performance, as there are much more parameters. At least on MNIST, as shown in the response to Reviewer 2, our MBF method performs much better than Defense-GAN. These discussions have been added into the revised manuscript. "}, "signatures": ["ICLR.cc/2020/Conference/Paper235/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper235/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["machengcheng2016@gmail.com", "wubaoyuan1987@gmail.com", "shibiao.xu@ia.ac.cn", "fanyanbo0124@gmail.com", "zhangyong201303@gmail.com", "xiaopeng.zhang@ia.ac.cn", "michaelzfli@tencent.com"], "title": "Effective and Robust Detection of Adversarial Examples via Benford-Fourier Coefficients", "authors": ["Chengcheng Ma", "Baoyuan Wu", "Shibiao Xu", "Yanbo Fan", "Yong Zhang", "Xiaopeng Zhang", "Zhifeng Li"], "pdf": "/pdf/8ba2e6bdf85037141dc90b95eb3607c53e112ee1.pdf", "abstract": "Adversarial examples have been well known as a serious threat to deep neural\nnetworks (DNNs). To ensure successful and safe operations of DNNs on realworld tasks, \nit is urgent to equip DNNs with effective defense strategies. In this\nwork, we study the detection of adversarial examples, based on the assumption\nthat the output and internal responses of one DNN model for both adversarial and\nbenign examples follow the generalized Gaussian distribution (GGD), but with\ndifferent parameters (i.e., shape factor, mean, and variance). GGD is a general\ndistribution family to cover many popular distributions (e.g., Laplacian, Gaussian,\nor uniform). It is more likely to approximate the intrinsic distributions of internal\nresponses than any specific distribution. Besides, since the shape factor is more\nrobust to different databases rather than the other two parameters, we propose\nto construct discriminative features via the shape factor for adversarial detection,\nemploying the magnitude of Benford-Fourier coefficients (MBF), which can be\neasily estimated using responses. Finally, a support vector machine is trained\nas the adversarial detector through leveraging the MBF features. Through the\nKolmogorov-Smirnov (KS) test, we empirically verify that: 1) the posterior vectors \nof both adversarial and benign examples follow GGD; 2) the extracted MBF features \nof adversarial and benign examples follow different distributions. Extensive \nexperiments in terms of image classification demonstrate that the proposed \ndetector is much more effective and robust on detecting adversarial examples \nof different crafting methods and different sources, in contrast to state-of-the-art \nadversarial detection methods.", "keywords": [], "paperhash": "ma|effective_and_robust_detection_of_adversarial_examples_via_benfordfourier_coefficients", "original_pdf": "/attachment/096dbd0e221aa0f7b867a8dcc75522740d5b0de4.pdf", "_bibtex": "@misc{\nma2020effective,\ntitle={Effective and Robust Detection of Adversarial Examples via Benford-Fourier Coefficients},\nauthor={Chengcheng Ma and Baoyuan Wu and Shibiao Xu and Yanbo Fan and Yong Zhang and Xiaopeng Zhang and Zhifeng Li},\nyear={2020},\nurl={https://openreview.net/forum?id=ryeK6nNFDr}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "ryeK6nNFDr", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper235/Authors", "ICLR.cc/2020/Conference/Paper235/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper235/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper235/Reviewers", "ICLR.cc/2020/Conference/Paper235/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper235/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper235/Authors|ICLR.cc/2020/Conference/Paper235/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504174387, "tmdate": 1576860538745, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper235/Authors", "ICLR.cc/2020/Conference/Paper235/Reviewers", "ICLR.cc/2020/Conference/Paper235/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper235/-/Official_Comment"}}}, {"id": "SklISRo9or", "original": null, "number": 1, "cdate": 1573727805850, "ddate": null, "tcdate": 1573727805850, "tmdate": 1573727805850, "tddate": null, "forum": "ryeK6nNFDr", "replyto": "SkeujiMl5H", "invitation": "ICLR.cc/2020/Conference/Paper235/-/Official_Comment", "content": {"title": "Response to Reviewer #2", "comment": "Thanks for the constructive comments. \n1)\tWe should clarify that the reason we choose LID as the baseline is not the cheap computation. The real reason is that LID can be seen one state-of-the-art adversarial detection methods, as it has been cited by 114 times since its publication at ICLR 2018, and it is compared in many recent works about adversarial detection. Our experimental results also show that LID is the most competitive among all compared methods. Another important reason is that LID and our MBF method share the similar idea that extracting discriminative features for detection from the responses, based on some assumptions. LID assumes that the features of adversarial and benign have different densities, while our MBF method assumes that they follow different GGDs. \n2)\tIn contrast, Defense-GAN is designed using a totally different philosophy with LID and our MBF method, i.e., approximating the adversarial noises using GAN. Since the official code of Defense-GAN only supports the three datasets of MNIST, Fashion-MNIST, and CelebA, we compare with Defense-GAN on MNIST, as shown below. There are two key hyper-parameters in Defense-GAN, including the iteration number in each GD run, and the total number of GD runs. After trying multiple settings of these two hyper-parameters, we report the best result (evaluated by AUROC score). Our MBF method show much better performance than Defense-GAN. The detailed comparisons with Defense-GAN have been added in the revised manuscript.\n__________________________________________________________________________________________________________\n Iteration number in each GD run | Number of GD runs |  BIM  | CW-L2 | DeepFool | R-PGD\n__________________________________________________________________________________________________________\n                             200                          |                 10                | 0.744 |  0.980  |     0.702     |  0.746\n__________________________________________________________________________________________________________\n                                                           MBF                                  | 1.000 |  0.991  |     1.000     |  1.000\n__________________________________________________________________________________________________________\n"}, "signatures": ["ICLR.cc/2020/Conference/Paper235/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper235/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["machengcheng2016@gmail.com", "wubaoyuan1987@gmail.com", "shibiao.xu@ia.ac.cn", "fanyanbo0124@gmail.com", "zhangyong201303@gmail.com", "xiaopeng.zhang@ia.ac.cn", "michaelzfli@tencent.com"], "title": "Effective and Robust Detection of Adversarial Examples via Benford-Fourier Coefficients", "authors": ["Chengcheng Ma", "Baoyuan Wu", "Shibiao Xu", "Yanbo Fan", "Yong Zhang", "Xiaopeng Zhang", "Zhifeng Li"], "pdf": "/pdf/8ba2e6bdf85037141dc90b95eb3607c53e112ee1.pdf", "abstract": "Adversarial examples have been well known as a serious threat to deep neural\nnetworks (DNNs). To ensure successful and safe operations of DNNs on realworld tasks, \nit is urgent to equip DNNs with effective defense strategies. In this\nwork, we study the detection of adversarial examples, based on the assumption\nthat the output and internal responses of one DNN model for both adversarial and\nbenign examples follow the generalized Gaussian distribution (GGD), but with\ndifferent parameters (i.e., shape factor, mean, and variance). GGD is a general\ndistribution family to cover many popular distributions (e.g., Laplacian, Gaussian,\nor uniform). It is more likely to approximate the intrinsic distributions of internal\nresponses than any specific distribution. Besides, since the shape factor is more\nrobust to different databases rather than the other two parameters, we propose\nto construct discriminative features via the shape factor for adversarial detection,\nemploying the magnitude of Benford-Fourier coefficients (MBF), which can be\neasily estimated using responses. Finally, a support vector machine is trained\nas the adversarial detector through leveraging the MBF features. Through the\nKolmogorov-Smirnov (KS) test, we empirically verify that: 1) the posterior vectors \nof both adversarial and benign examples follow GGD; 2) the extracted MBF features \nof adversarial and benign examples follow different distributions. Extensive \nexperiments in terms of image classification demonstrate that the proposed \ndetector is much more effective and robust on detecting adversarial examples \nof different crafting methods and different sources, in contrast to state-of-the-art \nadversarial detection methods.", "keywords": [], "paperhash": "ma|effective_and_robust_detection_of_adversarial_examples_via_benfordfourier_coefficients", "original_pdf": "/attachment/096dbd0e221aa0f7b867a8dcc75522740d5b0de4.pdf", "_bibtex": "@misc{\nma2020effective,\ntitle={Effective and Robust Detection of Adversarial Examples via Benford-Fourier Coefficients},\nauthor={Chengcheng Ma and Baoyuan Wu and Shibiao Xu and Yanbo Fan and Yong Zhang and Xiaopeng Zhang and Zhifeng Li},\nyear={2020},\nurl={https://openreview.net/forum?id=ryeK6nNFDr}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "ryeK6nNFDr", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper235/Authors", "ICLR.cc/2020/Conference/Paper235/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper235/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper235/Reviewers", "ICLR.cc/2020/Conference/Paper235/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper235/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper235/Authors|ICLR.cc/2020/Conference/Paper235/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504174387, "tmdate": 1576860538745, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper235/Authors", "ICLR.cc/2020/Conference/Paper235/Reviewers", "ICLR.cc/2020/Conference/Paper235/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper235/-/Official_Comment"}}}, {"id": "SyeSm3HiYr", "original": null, "number": 1, "cdate": 1571671069322, "ddate": null, "tcdate": 1571671069322, "tmdate": 1572972621463, "tddate": null, "forum": "ryeK6nNFDr", "replyto": "ryeK6nNFDr", "invitation": "ICLR.cc/2020/Conference/Paper235/-/Official_Review", "content": {"rating": "6: Weak Accept", "experience_assessment": "I have published in this field for several years.", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #3", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review": "This paper proposes an adversarial detection method via Fourier coefficients. The proposed method seems promising, and empirical evaluations are reasonable.\n\nHowever, I find that the proposed MBF detection metric is much more complicated to calculate than any of its baselines, e.g., LID or K-density. So I wonder if the good performance of MBF mainly comes from its \u2019complexity\u2018. I mean, if we use the feature vectors of different layers in CNNs and combine them with a different non-linear function and feed into an SVM classifier,  can we still obtain a hard-to-evade detector? I think a fair complexity is particularly important when you try to evade the detector by optimization-based adaptive attacks and claim superiority over other baselines."}, "signatures": ["ICLR.cc/2020/Conference/Paper235/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper235/AnonReviewer3"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["machengcheng2016@gmail.com", "wubaoyuan1987@gmail.com", "shibiao.xu@ia.ac.cn", "fanyanbo0124@gmail.com", "zhangyong201303@gmail.com", "xiaopeng.zhang@ia.ac.cn", "michaelzfli@tencent.com"], "title": "Effective and Robust Detection of Adversarial Examples via Benford-Fourier Coefficients", "authors": ["Chengcheng Ma", "Baoyuan Wu", "Shibiao Xu", "Yanbo Fan", "Yong Zhang", "Xiaopeng Zhang", "Zhifeng Li"], "pdf": "/pdf/8ba2e6bdf85037141dc90b95eb3607c53e112ee1.pdf", "abstract": "Adversarial examples have been well known as a serious threat to deep neural\nnetworks (DNNs). To ensure successful and safe operations of DNNs on realworld tasks, \nit is urgent to equip DNNs with effective defense strategies. In this\nwork, we study the detection of adversarial examples, based on the assumption\nthat the output and internal responses of one DNN model for both adversarial and\nbenign examples follow the generalized Gaussian distribution (GGD), but with\ndifferent parameters (i.e., shape factor, mean, and variance). GGD is a general\ndistribution family to cover many popular distributions (e.g., Laplacian, Gaussian,\nor uniform). It is more likely to approximate the intrinsic distributions of internal\nresponses than any specific distribution. Besides, since the shape factor is more\nrobust to different databases rather than the other two parameters, we propose\nto construct discriminative features via the shape factor for adversarial detection,\nemploying the magnitude of Benford-Fourier coefficients (MBF), which can be\neasily estimated using responses. Finally, a support vector machine is trained\nas the adversarial detector through leveraging the MBF features. Through the\nKolmogorov-Smirnov (KS) test, we empirically verify that: 1) the posterior vectors \nof both adversarial and benign examples follow GGD; 2) the extracted MBF features \nof adversarial and benign examples follow different distributions. Extensive \nexperiments in terms of image classification demonstrate that the proposed \ndetector is much more effective and robust on detecting adversarial examples \nof different crafting methods and different sources, in contrast to state-of-the-art \nadversarial detection methods.", "keywords": [], "paperhash": "ma|effective_and_robust_detection_of_adversarial_examples_via_benfordfourier_coefficients", "original_pdf": "/attachment/096dbd0e221aa0f7b867a8dcc75522740d5b0de4.pdf", "_bibtex": "@misc{\nma2020effective,\ntitle={Effective and Robust Detection of Adversarial Examples via Benford-Fourier Coefficients},\nauthor={Chengcheng Ma and Baoyuan Wu and Shibiao Xu and Yanbo Fan and Yong Zhang and Xiaopeng Zhang and Zhifeng Li},\nyear={2020},\nurl={https://openreview.net/forum?id=ryeK6nNFDr}\n}"}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "ryeK6nNFDr", "replyto": "ryeK6nNFDr", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper235/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper235/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1575862801275, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper235/Reviewers"], "noninvitees": [], "tcdate": 1570237755069, "tmdate": 1575862801290, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper235/-/Official_Review"}}}, {"id": "SkeujiMl5H", "original": null, "number": 2, "cdate": 1571986335671, "ddate": null, "tcdate": 1571986335671, "tmdate": 1572972621429, "tddate": null, "forum": "ryeK6nNFDr", "replyto": "ryeK6nNFDr", "invitation": "ICLR.cc/2020/Conference/Paper235/-/Official_Review", "content": {"experience_assessment": "I have read many papers in this area.", "rating": "6: Weak Accept", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #2", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "This paper proposes an approach to adversarial detection.  The approach first computes a representation of the activation layers using the Benford-Fourier coefficients.  One then generates a range of noisy instances, and trains an SVM using those noisy instances as supervised labels (e.g., noisy instances are adversarial).  The SVM uses the Benford-Fourier coefficients of the activation layer as the input features.  The results show good performance against some baselines such as LID.\n\nI'm not really an expert in this area, but I'm a bit surprised that LID is considered the baseline to beat.  I imagine that most adversarial defense approaches are for robust prediction, rather than detection.  It also seems the authors chose to compare with defenses that are computationally cheaper (so not RCE or Defense-GAN), but a study of computational trade-offs is absent in the paper."}, "signatures": ["ICLR.cc/2020/Conference/Paper235/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper235/AnonReviewer2"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["machengcheng2016@gmail.com", "wubaoyuan1987@gmail.com", "shibiao.xu@ia.ac.cn", "fanyanbo0124@gmail.com", "zhangyong201303@gmail.com", "xiaopeng.zhang@ia.ac.cn", "michaelzfli@tencent.com"], "title": "Effective and Robust Detection of Adversarial Examples via Benford-Fourier Coefficients", "authors": ["Chengcheng Ma", "Baoyuan Wu", "Shibiao Xu", "Yanbo Fan", "Yong Zhang", "Xiaopeng Zhang", "Zhifeng Li"], "pdf": "/pdf/8ba2e6bdf85037141dc90b95eb3607c53e112ee1.pdf", "abstract": "Adversarial examples have been well known as a serious threat to deep neural\nnetworks (DNNs). To ensure successful and safe operations of DNNs on realworld tasks, \nit is urgent to equip DNNs with effective defense strategies. In this\nwork, we study the detection of adversarial examples, based on the assumption\nthat the output and internal responses of one DNN model for both adversarial and\nbenign examples follow the generalized Gaussian distribution (GGD), but with\ndifferent parameters (i.e., shape factor, mean, and variance). GGD is a general\ndistribution family to cover many popular distributions (e.g., Laplacian, Gaussian,\nor uniform). It is more likely to approximate the intrinsic distributions of internal\nresponses than any specific distribution. Besides, since the shape factor is more\nrobust to different databases rather than the other two parameters, we propose\nto construct discriminative features via the shape factor for adversarial detection,\nemploying the magnitude of Benford-Fourier coefficients (MBF), which can be\neasily estimated using responses. Finally, a support vector machine is trained\nas the adversarial detector through leveraging the MBF features. Through the\nKolmogorov-Smirnov (KS) test, we empirically verify that: 1) the posterior vectors \nof both adversarial and benign examples follow GGD; 2) the extracted MBF features \nof adversarial and benign examples follow different distributions. Extensive \nexperiments in terms of image classification demonstrate that the proposed \ndetector is much more effective and robust on detecting adversarial examples \nof different crafting methods and different sources, in contrast to state-of-the-art \nadversarial detection methods.", "keywords": [], "paperhash": "ma|effective_and_robust_detection_of_adversarial_examples_via_benfordfourier_coefficients", "original_pdf": "/attachment/096dbd0e221aa0f7b867a8dcc75522740d5b0de4.pdf", "_bibtex": "@misc{\nma2020effective,\ntitle={Effective and Robust Detection of Adversarial Examples via Benford-Fourier Coefficients},\nauthor={Chengcheng Ma and Baoyuan Wu and Shibiao Xu and Yanbo Fan and Yong Zhang and Xiaopeng Zhang and Zhifeng Li},\nyear={2020},\nurl={https://openreview.net/forum?id=ryeK6nNFDr}\n}"}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "ryeK6nNFDr", "replyto": "ryeK6nNFDr", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper235/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper235/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1575862801275, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper235/Reviewers"], "noninvitees": [], "tcdate": 1570237755069, "tmdate": 1575862801290, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper235/-/Official_Review"}}}, {"id": "Skx3wFCmcr", "original": null, "number": 3, "cdate": 1572231524057, "ddate": null, "tcdate": 1572231524057, "tmdate": 1572972621384, "tddate": null, "forum": "ryeK6nNFDr", "replyto": "ryeK6nNFDr", "invitation": "ICLR.cc/2020/Conference/Paper235/-/Official_Review", "content": {"experience_assessment": "I have published in this field for several years.", "rating": "3: Weak Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #1", "review_assessment:_checking_correctness_of_derivations_and_theory": "I carefully checked the derivations and theory.", "review": "This paper presents a new discriminator metric for adversarial attack's detection by deriving the different properties of l-th neuron network layer on different adv/benign samples. This method can achieve good AUC score comparing to other start-of-art detection methods and also achieve good robustness under corresponding adaptive attack. The framework is clear and the experiment is solid.\n\nHowever, I have several concerns:\n\nMajor:\n1. It seems that the whole process assumes that there is difference for the parameters in the environment of GGD with adv/benign samples, and the goal is to search for the major components of it and use a classifier to detect. To extract the approximation of parameters,  the authors use the \"response entries\" of l-th layer for several observations => this means the authors regard all the \"response entries\" of one layer as different samples on one certain GGD. This makes me feel a bit tricky, and it would be great if you the authors can provide some evidence or explanation here.\n\n2. In the experiment's remark, the authors mentioned that the mean parameter of GGD is set to 0 and most of them are actually close to 0 (around 1e-2) so the assumption is right. However 1e-2 is not a value \"very close to zero\" and it would be great to show / explain the variance here.\n\n3. I can't find the parameter of your evaluated attack method (like confidence, eps, etc.) Please also provide experimental details for reproducibility. \n\nMinor:\n\nHere are some reference error (e.g. P6, \"For each database, as described in Section ??\"). Please fix that.\n\nOverall, this paper is a interesting based on the performance of detection. But the  assumptions made by the paper are a bit confusing and it would be good to clarify and provide clarification for them. Authors should explain the assumptions and give some extra experiment results if needed.\n"}, "signatures": ["ICLR.cc/2020/Conference/Paper235/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper235/AnonReviewer1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["machengcheng2016@gmail.com", "wubaoyuan1987@gmail.com", "shibiao.xu@ia.ac.cn", "fanyanbo0124@gmail.com", "zhangyong201303@gmail.com", "xiaopeng.zhang@ia.ac.cn", "michaelzfli@tencent.com"], "title": "Effective and Robust Detection of Adversarial Examples via Benford-Fourier Coefficients", "authors": ["Chengcheng Ma", "Baoyuan Wu", "Shibiao Xu", "Yanbo Fan", "Yong Zhang", "Xiaopeng Zhang", "Zhifeng Li"], "pdf": "/pdf/8ba2e6bdf85037141dc90b95eb3607c53e112ee1.pdf", "abstract": "Adversarial examples have been well known as a serious threat to deep neural\nnetworks (DNNs). To ensure successful and safe operations of DNNs on realworld tasks, \nit is urgent to equip DNNs with effective defense strategies. In this\nwork, we study the detection of adversarial examples, based on the assumption\nthat the output and internal responses of one DNN model for both adversarial and\nbenign examples follow the generalized Gaussian distribution (GGD), but with\ndifferent parameters (i.e., shape factor, mean, and variance). GGD is a general\ndistribution family to cover many popular distributions (e.g., Laplacian, Gaussian,\nor uniform). It is more likely to approximate the intrinsic distributions of internal\nresponses than any specific distribution. Besides, since the shape factor is more\nrobust to different databases rather than the other two parameters, we propose\nto construct discriminative features via the shape factor for adversarial detection,\nemploying the magnitude of Benford-Fourier coefficients (MBF), which can be\neasily estimated using responses. Finally, a support vector machine is trained\nas the adversarial detector through leveraging the MBF features. Through the\nKolmogorov-Smirnov (KS) test, we empirically verify that: 1) the posterior vectors \nof both adversarial and benign examples follow GGD; 2) the extracted MBF features \nof adversarial and benign examples follow different distributions. Extensive \nexperiments in terms of image classification demonstrate that the proposed \ndetector is much more effective and robust on detecting adversarial examples \nof different crafting methods and different sources, in contrast to state-of-the-art \nadversarial detection methods.", "keywords": [], "paperhash": "ma|effective_and_robust_detection_of_adversarial_examples_via_benfordfourier_coefficients", "original_pdf": "/attachment/096dbd0e221aa0f7b867a8dcc75522740d5b0de4.pdf", "_bibtex": "@misc{\nma2020effective,\ntitle={Effective and Robust Detection of Adversarial Examples via Benford-Fourier Coefficients},\nauthor={Chengcheng Ma and Baoyuan Wu and Shibiao Xu and Yanbo Fan and Yong Zhang and Xiaopeng Zhang and Zhifeng Li},\nyear={2020},\nurl={https://openreview.net/forum?id=ryeK6nNFDr}\n}"}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "ryeK6nNFDr", "replyto": "ryeK6nNFDr", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper235/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper235/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1575862801275, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper235/Reviewers"], "noninvitees": [], "tcdate": 1570237755069, "tmdate": 1575862801290, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper235/-/Official_Review"}}}], "count": 8}