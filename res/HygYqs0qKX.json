{"notes": [{"id": "HygYqs0qKX", "original": "BJgYVAI5KX", "number": 554, "cdate": 1538087825334, "ddate": null, "tcdate": 1538087825334, "tmdate": 1545355386522, "tddate": null, "forum": "HygYqs0qKX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Conscious Inference for Object Detection", "abstract": "Current Convolutional Neural Network (CNN)-based object detection models adopt strictly feedforward inference to predict the final detection results. However, the widely used one-way inference is agnostic to the global image context and the interplay between input image and task semantics. In this work, we present a general technique to improve off-the-shelf CNN-based object detection models in the inference stage without re-training, architecture modification or ground-truth requirements. We propose an iterative, bottom-up and top-down inference mechanism, which is named conscious inference, as it is inspired by prevalent models for human consciousness with top-down guidance and temporal persistence. While the downstream pass accumulates category-specific evidence over time, it subsequently affects the proposal calculation and the final detection. Feature activations are updated in line with no additional memory cost. Our approach advances the state of the art using popular detection models (Faster-RCNN, YOLOv2, YOLOv3) on 2D object detection and 6D object pose estimation.", "keywords": ["consciousness", "conscious inference", "object detection", "object pose estimation"], "authorids": ["zhoujh09@gmail.com", "nikolaos.karianakis@microsoft.com", "yingwu@eecs.northwestern.edu", "ganghua@gmail.com"], "authors": ["Jiahuan Zhou", "Nikolaos Karianakis", "Ying Wu", "Gang Hua"], "pdf": "/pdf/0f74b0628cab25f337fa905145d5566ad614179f.pdf", "paperhash": "zhou|conscious_inference_for_object_detection", "_bibtex": "@misc{\nzhou2019conscious,\ntitle={Conscious Inference for Object Detection},\nauthor={Jiahuan Zhou and Nikolaos Karianakis and Ying Wu and Gang Hua},\nyear={2019},\nurl={https://openreview.net/forum?id=HygYqs0qKX},\n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"replyCount": 7, "writable": false, "overwriting": [], "revisions": false, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Blind_Submission", "rdate": null, "ddate": null, "expdate": null, "duedate": 1538085600000, "tmdate": 1538142958393, "tddate": null, "super": null, "final": null, "reply": {"signatures": {"values": ["ICLR.cc/2019/Conference"]}, "forum": null, "readers": {"values": ["everyone"]}, "replyto": null, "content": {"authorids": {"values-regex": ".*"}, "authors": {"values": ["Anonymous"]}}, "writers": {"values": ["ICLR.cc/2019/Conference"]}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["~"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": null, "taskCompletionCount": null, "transform": null, "cdate": 1538142958393}}, "tauthor": "OpenReview.net"}, {"id": "ByexeLZ-eE", "original": null, "number": 1, "cdate": 1544783336441, "ddate": null, "tcdate": 1544783336441, "tmdate": 1545354523819, "tddate": null, "forum": "HygYqs0qKX", "replyto": "HygYqs0qKX", "invitation": "ICLR.cc/2019/Conference/-/Paper554/Meta_Review", "content": {"metareview": "The paper presents an interesting idea, but there are significant concerns about the presentation issues and experimental results (e.g., comparisons with baselines). Overall, it is not ready for publication. ", "confidence": "4: The area chair is confident but not absolutely certain", "recommendation": "Reject", "title": "decision"}, "signatures": ["ICLR.cc/2019/Conference/Paper554/Area_Chair1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference/Paper554/Area_Chair1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Conscious Inference for Object Detection", "abstract": "Current Convolutional Neural Network (CNN)-based object detection models adopt strictly feedforward inference to predict the final detection results. However, the widely used one-way inference is agnostic to the global image context and the interplay between input image and task semantics. In this work, we present a general technique to improve off-the-shelf CNN-based object detection models in the inference stage without re-training, architecture modification or ground-truth requirements. We propose an iterative, bottom-up and top-down inference mechanism, which is named conscious inference, as it is inspired by prevalent models for human consciousness with top-down guidance and temporal persistence. While the downstream pass accumulates category-specific evidence over time, it subsequently affects the proposal calculation and the final detection. Feature activations are updated in line with no additional memory cost. Our approach advances the state of the art using popular detection models (Faster-RCNN, YOLOv2, YOLOv3) on 2D object detection and 6D object pose estimation.", "keywords": ["consciousness", "conscious inference", "object detection", "object pose estimation"], "authorids": ["zhoujh09@gmail.com", "nikolaos.karianakis@microsoft.com", "yingwu@eecs.northwestern.edu", "ganghua@gmail.com"], "authors": ["Jiahuan Zhou", "Nikolaos Karianakis", "Ying Wu", "Gang Hua"], "pdf": "/pdf/0f74b0628cab25f337fa905145d5566ad614179f.pdf", "paperhash": "zhou|conscious_inference_for_object_detection", "_bibtex": "@misc{\nzhou2019conscious,\ntitle={Conscious Inference for Object Detection},\nauthor={Jiahuan Zhou and Nikolaos Karianakis and Ying Wu and Gang Hua},\nyear={2019},\nurl={https://openreview.net/forum?id=HygYqs0qKX},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper554/Meta_Review", "rdate": null, "ddate": null, "expdate": null, "duedate": 1541548800000, "tmdate": 1545353174212, "tddate": null, "super": null, "final": null, "reply": {"forum": "HygYqs0qKX", "replyto": "HygYqs0qKX", "readers": {"description": "Select all user groups that should be able to read this comment. Selecting 'All Users' will allow paper authors, reviewers, area chairs, and program chairs to view this comment.", "values": ["everyone"]}, "signatures": {"description": "How your identity will be displayed with the above content.", "values-regex": "ICLR.cc/2019/Conference/Paper554/Area_Chair[0-9]+"}, "writers": {"description": "Users that may modify this record.", "values-regex": "ICLR.cc/2019/Conference/Paper554/Area_Chair[0-9]+"}, "content": {"title": {"order": 1, "value-regex": ".{1,500}", "description": "Brief summary of your review.", "required": true}, "metareview": {"order": 2, "value-regex": "[\\S\\s]{1,5000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "required": true}, "recommendation": {"order": 3, "value-dropdown": ["Accept (Oral)", "Accept (Poster)", "Reject"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The area chair is absolutely certain", "4: The area chair is confident but not absolutely certain", "3: The area chair is somewhat confident", "2: The area chair is not sure", "1: The area chair's evaluation is an educated guess"], "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper554/Area_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": false, "taskCompletionCount": null, "transform": null, "cdate": 1545353174212}}}, {"id": "Hygbihk8CQ", "original": null, "number": 4, "cdate": 1543007385413, "ddate": null, "tcdate": 1543007385413, "tmdate": 1543007385413, "tddate": null, "forum": "HygYqs0qKX", "replyto": "H1lT0X4J6m", "invitation": "ICLR.cc/2019/Conference/-/Paper554/Official_Comment", "content": {"title": "Thanks a lot for your review!", "comment": "Thank you very much for your time and effort for reviewing our paper. We will keep working on refining our work according to your precise comments and suggestions."}, "signatures": ["ICLR.cc/2019/Conference/Paper554/Authors"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper554/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper554/Authors", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Conscious Inference for Object Detection", "abstract": "Current Convolutional Neural Network (CNN)-based object detection models adopt strictly feedforward inference to predict the final detection results. However, the widely used one-way inference is agnostic to the global image context and the interplay between input image and task semantics. In this work, we present a general technique to improve off-the-shelf CNN-based object detection models in the inference stage without re-training, architecture modification or ground-truth requirements. We propose an iterative, bottom-up and top-down inference mechanism, which is named conscious inference, as it is inspired by prevalent models for human consciousness with top-down guidance and temporal persistence. While the downstream pass accumulates category-specific evidence over time, it subsequently affects the proposal calculation and the final detection. Feature activations are updated in line with no additional memory cost. Our approach advances the state of the art using popular detection models (Faster-RCNN, YOLOv2, YOLOv3) on 2D object detection and 6D object pose estimation.", "keywords": ["consciousness", "conscious inference", "object detection", "object pose estimation"], "authorids": ["zhoujh09@gmail.com", "nikolaos.karianakis@microsoft.com", "yingwu@eecs.northwestern.edu", "ganghua@gmail.com"], "authors": ["Jiahuan Zhou", "Nikolaos Karianakis", "Ying Wu", "Gang Hua"], "pdf": "/pdf/0f74b0628cab25f337fa905145d5566ad614179f.pdf", "paperhash": "zhou|conscious_inference_for_object_detection", "_bibtex": "@misc{\nzhou2019conscious,\ntitle={Conscious Inference for Object Detection},\nauthor={Jiahuan Zhou and Nikolaos Karianakis and Ying Wu and Gang Hua},\nyear={2019},\nurl={https://openreview.net/forum?id=HygYqs0qKX},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper554/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621623904, "tddate": null, "super": null, "final": null, "reply": {"forum": "HygYqs0qKX", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper554/Authors", "ICLR.cc/2019/Conference/Paper554/Reviewers", "ICLR.cc/2019/Conference/Paper554/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper554/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper554/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper554/Authors|ICLR.cc/2019/Conference/Paper554/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper554/Reviewers", "ICLR.cc/2019/Conference/Paper554/Authors", "ICLR.cc/2019/Conference/Paper554/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621623904}}}, {"id": "S1gg5nyLRm", "original": null, "number": 3, "cdate": 1543007368206, "ddate": null, "tcdate": 1543007368206, "tmdate": 1543007368206, "tddate": null, "forum": "HygYqs0qKX", "replyto": "HylDrHuPhm", "invitation": "ICLR.cc/2019/Conference/-/Paper554/Official_Comment", "content": {"title": "Thanks a lot for your review!", "comment": "Thank you very much for your time and effort for reviewing our paper. We will keep working on refining our work according to your precise comments and suggestions."}, "signatures": ["ICLR.cc/2019/Conference/Paper554/Authors"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper554/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper554/Authors", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Conscious Inference for Object Detection", "abstract": "Current Convolutional Neural Network (CNN)-based object detection models adopt strictly feedforward inference to predict the final detection results. However, the widely used one-way inference is agnostic to the global image context and the interplay between input image and task semantics. In this work, we present a general technique to improve off-the-shelf CNN-based object detection models in the inference stage without re-training, architecture modification or ground-truth requirements. We propose an iterative, bottom-up and top-down inference mechanism, which is named conscious inference, as it is inspired by prevalent models for human consciousness with top-down guidance and temporal persistence. While the downstream pass accumulates category-specific evidence over time, it subsequently affects the proposal calculation and the final detection. Feature activations are updated in line with no additional memory cost. Our approach advances the state of the art using popular detection models (Faster-RCNN, YOLOv2, YOLOv3) on 2D object detection and 6D object pose estimation.", "keywords": ["consciousness", "conscious inference", "object detection", "object pose estimation"], "authorids": ["zhoujh09@gmail.com", "nikolaos.karianakis@microsoft.com", "yingwu@eecs.northwestern.edu", "ganghua@gmail.com"], "authors": ["Jiahuan Zhou", "Nikolaos Karianakis", "Ying Wu", "Gang Hua"], "pdf": "/pdf/0f74b0628cab25f337fa905145d5566ad614179f.pdf", "paperhash": "zhou|conscious_inference_for_object_detection", "_bibtex": "@misc{\nzhou2019conscious,\ntitle={Conscious Inference for Object Detection},\nauthor={Jiahuan Zhou and Nikolaos Karianakis and Ying Wu and Gang Hua},\nyear={2019},\nurl={https://openreview.net/forum?id=HygYqs0qKX},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper554/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621623904, "tddate": null, "super": null, "final": null, "reply": {"forum": "HygYqs0qKX", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper554/Authors", "ICLR.cc/2019/Conference/Paper554/Reviewers", "ICLR.cc/2019/Conference/Paper554/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper554/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper554/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper554/Authors|ICLR.cc/2019/Conference/Paper554/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper554/Reviewers", "ICLR.cc/2019/Conference/Paper554/Authors", "ICLR.cc/2019/Conference/Paper554/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621623904}}}, {"id": "SyxTd2y8R7", "original": null, "number": 2, "cdate": 1543007348672, "ddate": null, "tcdate": 1543007348672, "tmdate": 1543007348672, "tddate": null, "forum": "HygYqs0qKX", "replyto": "H1gAl_Vc3m", "invitation": "ICLR.cc/2019/Conference/-/Paper554/Official_Comment", "content": {"title": "Thanks a lot for your review!", "comment": "Thank you very much for your time and effort for reviewing our paper. We will keep working on refining our work according to your precise comments and suggestions."}, "signatures": ["ICLR.cc/2019/Conference/Paper554/Authors"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper554/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper554/Authors", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Conscious Inference for Object Detection", "abstract": "Current Convolutional Neural Network (CNN)-based object detection models adopt strictly feedforward inference to predict the final detection results. However, the widely used one-way inference is agnostic to the global image context and the interplay between input image and task semantics. In this work, we present a general technique to improve off-the-shelf CNN-based object detection models in the inference stage without re-training, architecture modification or ground-truth requirements. We propose an iterative, bottom-up and top-down inference mechanism, which is named conscious inference, as it is inspired by prevalent models for human consciousness with top-down guidance and temporal persistence. While the downstream pass accumulates category-specific evidence over time, it subsequently affects the proposal calculation and the final detection. Feature activations are updated in line with no additional memory cost. Our approach advances the state of the art using popular detection models (Faster-RCNN, YOLOv2, YOLOv3) on 2D object detection and 6D object pose estimation.", "keywords": ["consciousness", "conscious inference", "object detection", "object pose estimation"], "authorids": ["zhoujh09@gmail.com", "nikolaos.karianakis@microsoft.com", "yingwu@eecs.northwestern.edu", "ganghua@gmail.com"], "authors": ["Jiahuan Zhou", "Nikolaos Karianakis", "Ying Wu", "Gang Hua"], "pdf": "/pdf/0f74b0628cab25f337fa905145d5566ad614179f.pdf", "paperhash": "zhou|conscious_inference_for_object_detection", "_bibtex": "@misc{\nzhou2019conscious,\ntitle={Conscious Inference for Object Detection},\nauthor={Jiahuan Zhou and Nikolaos Karianakis and Ying Wu and Gang Hua},\nyear={2019},\nurl={https://openreview.net/forum?id=HygYqs0qKX},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper554/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621623904, "tddate": null, "super": null, "final": null, "reply": {"forum": "HygYqs0qKX", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper554/Authors", "ICLR.cc/2019/Conference/Paper554/Reviewers", "ICLR.cc/2019/Conference/Paper554/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper554/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper554/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper554/Authors|ICLR.cc/2019/Conference/Paper554/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper554/Reviewers", "ICLR.cc/2019/Conference/Paper554/Authors", "ICLR.cc/2019/Conference/Paper554/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621623904}}}, {"id": "H1lT0X4J6m", "original": null, "number": 3, "cdate": 1541518292944, "ddate": null, "tcdate": 1541518292944, "tmdate": 1541533895496, "tddate": null, "forum": "HygYqs0qKX", "replyto": "HygYqs0qKX", "invitation": "ICLR.cc/2019/Conference/-/Paper554/Official_Review", "content": {"title": "The authors propose a method to improve object detection accuracy at inference time without re-training, changing network architecture, and working for both one-shot and two-stages detectors.", "review": "The goal of the paper clearly motivated and well described. However, the notations and figures are more complicated than necessary; hence, it is a bit hard to follow the paper in detail. There are also some missing related works about domain adaptation for object detectors. For instance,\nChen et al. \"Domain Adaptive Faster R-CNN for Object Detection in the Wild\" In CVPR 2018.\nInoue et al. \"Cross-Domain Weakly-Supervised Object Detection through Progressive Domain Adaptation\" In CVPR 2018.\nThe authors should cite these papers and compare with their performance.\nFinally, the proposed method doesn't consistently improve the detection accuracy. \nThe proposed method also slows down the frame rate of the detector due to multiple iterations of feedforward/feedback inferences.", "rating": "4: Ok but not good enough - rejection", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["ICLR.cc/2019/Conference/Paper554/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Conscious Inference for Object Detection", "abstract": "Current Convolutional Neural Network (CNN)-based object detection models adopt strictly feedforward inference to predict the final detection results. However, the widely used one-way inference is agnostic to the global image context and the interplay between input image and task semantics. In this work, we present a general technique to improve off-the-shelf CNN-based object detection models in the inference stage without re-training, architecture modification or ground-truth requirements. We propose an iterative, bottom-up and top-down inference mechanism, which is named conscious inference, as it is inspired by prevalent models for human consciousness with top-down guidance and temporal persistence. While the downstream pass accumulates category-specific evidence over time, it subsequently affects the proposal calculation and the final detection. Feature activations are updated in line with no additional memory cost. Our approach advances the state of the art using popular detection models (Faster-RCNN, YOLOv2, YOLOv3) on 2D object detection and 6D object pose estimation.", "keywords": ["consciousness", "conscious inference", "object detection", "object pose estimation"], "authorids": ["zhoujh09@gmail.com", "nikolaos.karianakis@microsoft.com", "yingwu@eecs.northwestern.edu", "ganghua@gmail.com"], "authors": ["Jiahuan Zhou", "Nikolaos Karianakis", "Ying Wu", "Gang Hua"], "pdf": "/pdf/0f74b0628cab25f337fa905145d5566ad614179f.pdf", "paperhash": "zhou|conscious_inference_for_object_detection", "_bibtex": "@misc{\nzhou2019conscious,\ntitle={Conscious Inference for Object Detection},\nauthor={Jiahuan Zhou and Nikolaos Karianakis and Ying Wu and Gang Hua},\nyear={2019},\nurl={https://openreview.net/forum?id=HygYqs0qKX},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper554/Official_Review", "cdate": 1542234434891, "expdate": 1552335264000, "duedate": 1541196000000, "reply": {"forum": "HygYqs0qKX", "replyto": "HygYqs0qKX", "readers": {"description": "The users who will be allowed to read the reply content.", "values": ["everyone"]}, "nonreaders": {"values": []}, "signatures": {"description": "How your identity will be displayed with the above content.", "values-regex": "ICLR.cc/2019/Conference/Paper554/AnonReviewer[0-9]+"}, "writers": {"description": "Users that may modify this record.", "values": ["ICLR.cc/2019/Conference"]}, "content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "required": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}}, "multiReply": false, "tcdate": 1552335750723, "tmdate": 1552335750723, "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "invitees": ["ICLR.cc/2019/Conference/Paper554/Reviewers"], "noninvitees": [], "signatures": ["ICLR.cc/2019/Conference"]}}}, {"id": "H1gAl_Vc3m", "original": null, "number": 2, "cdate": 1541191669730, "ddate": null, "tcdate": 1541191669730, "tmdate": 1541533895293, "tddate": null, "forum": "HygYqs0qKX", "replyto": "HygYqs0qKX", "invitation": "ICLR.cc/2019/Conference/-/Paper554/Official_Review", "content": {"title": "The proposed approach is overall interesting but the overall gain seems a bit small given the iterative nature of the method that slows inference quite a bit down.", "review": "The paper proposes a method called cautious inference to improve inference accuracy for object detection models. The main idea is inspired by the previous work of Guided Perturbations, which is applied to fully convolutional networks to improve the segmentation/accuracy accuracy purely during inference time.  The original idea is to use the predicted labels of the network as pseudo ground truths (after making the predictions to be a one-hot vector), and then back propagate the error signals to the network input to get the gradients. And finally the gradients are added back to the original inputs to perform another round of prediction. Here the inputs can be either the original image, or some intermediate feature maps. Experiments are shown for both 2D and 6D object detections. \n\nComments:\n\n- I think overall it is an interesting idea to directly alter the input of the network in order to fit to the testing distribution. However, the motivation and story told in the introduction is a bit of an oversell compared to the experiment validation section. Most of the results shown are just doing training and testing of images drawn from the *same* distribution. Like coco train and test, or VOC train and test. It would be great to see if the cautious inference would work when the distribution is different. For example \"elephant in the room\" case, or new object categories are added during testing.\n\n- I am actually curious to see this method can be used to improve the AP on the *training* set as well, just to understand it better -- is it trying to recover the generalization error of the network, or it is doing some implicit context reasoning inference that can help training as well. \n\n- It might be better to compare/combine the method to other inference-only improvements for object detection. For example there is soft-NMS, \nBodla, Navaneeth, et al. \"Soft-nms\u2014improving object detection with one line of code.\" Computer Vision (ICCV), 2017 IEEE International Conference on. IEEE, 2017.\n\n - I am not sure I fully understand B-box part: I think it is easy to have B-obj and B-cls as one can just take the max of the class prediction and then use the inferred class label for one-hot vector construction, but I am confused about the box part as no ground-truth is given during testing. In Table 2 I also cannot find BP improving performance by itself in anyway.\n\n- For COCO, please report results on test-dev set, the minival set images are used only for validation. \n\n", "rating": "6: Marginally above acceptance threshold", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["ICLR.cc/2019/Conference/Paper554/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Conscious Inference for Object Detection", "abstract": "Current Convolutional Neural Network (CNN)-based object detection models adopt strictly feedforward inference to predict the final detection results. However, the widely used one-way inference is agnostic to the global image context and the interplay between input image and task semantics. In this work, we present a general technique to improve off-the-shelf CNN-based object detection models in the inference stage without re-training, architecture modification or ground-truth requirements. We propose an iterative, bottom-up and top-down inference mechanism, which is named conscious inference, as it is inspired by prevalent models for human consciousness with top-down guidance and temporal persistence. While the downstream pass accumulates category-specific evidence over time, it subsequently affects the proposal calculation and the final detection. Feature activations are updated in line with no additional memory cost. Our approach advances the state of the art using popular detection models (Faster-RCNN, YOLOv2, YOLOv3) on 2D object detection and 6D object pose estimation.", "keywords": ["consciousness", "conscious inference", "object detection", "object pose estimation"], "authorids": ["zhoujh09@gmail.com", "nikolaos.karianakis@microsoft.com", "yingwu@eecs.northwestern.edu", "ganghua@gmail.com"], "authors": ["Jiahuan Zhou", "Nikolaos Karianakis", "Ying Wu", "Gang Hua"], "pdf": "/pdf/0f74b0628cab25f337fa905145d5566ad614179f.pdf", "paperhash": "zhou|conscious_inference_for_object_detection", "_bibtex": "@misc{\nzhou2019conscious,\ntitle={Conscious Inference for Object Detection},\nauthor={Jiahuan Zhou and Nikolaos Karianakis and Ying Wu and Gang Hua},\nyear={2019},\nurl={https://openreview.net/forum?id=HygYqs0qKX},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper554/Official_Review", "cdate": 1542234434891, "expdate": 1552335264000, "duedate": 1541196000000, "reply": {"forum": "HygYqs0qKX", "replyto": "HygYqs0qKX", "readers": {"description": "The users who will be allowed to read the reply content.", "values": ["everyone"]}, "nonreaders": {"values": []}, "signatures": {"description": "How your identity will be displayed with the above content.", "values-regex": "ICLR.cc/2019/Conference/Paper554/AnonReviewer[0-9]+"}, "writers": {"description": "Users that may modify this record.", "values": ["ICLR.cc/2019/Conference"]}, "content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "required": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}}, "multiReply": false, "tcdate": 1552335750723, "tmdate": 1552335750723, "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "invitees": ["ICLR.cc/2019/Conference/Paper554/Reviewers"], "noninvitees": [], "signatures": ["ICLR.cc/2019/Conference"]}}}, {"id": "HylDrHuPhm", "original": null, "number": 1, "cdate": 1541010750733, "ddate": null, "tcdate": 1541010750733, "tmdate": 1541533895087, "tddate": null, "forum": "HygYqs0qKX", "replyto": "HygYqs0qKX", "invitation": "ICLR.cc/2019/Conference/-/Paper554/Official_Review", "content": {"title": "Paper review", "review": "The paper proposes a iterative approach at inference time to improve object detections. The work relies on updating the feature activations and perform new feed forward passes to obtain improved results. \n\nPros:\n(+) The idea of iterative inference is potentially effective\n(+) The paper is well written and clear\n(+) The authors show results on compelling benchmarks\nCons:\n(-) Reported improvements are very small\n(-) Important baselines are missing\n\n\nFirst, while the authors state correctly that their updates have no memory cost and no new parameters are added, they do require more FLOPs at test time. For N-stages, the approach requires xN more operations for forward passes  and xN for backward passes. This is a serious shortcoming as it adds compute time per image for the inference stage and cannot be parallelized. \n\nThe authors show small improvements for AP on COCO. From their analysis, it seems that the biggest gains come from N=1 stages, while the improvement added for N>1 are miniscule (Table 1). Note that the authors show results on COCO minival (5k images) and from my experience there, it's expected to see a +/- 0.2% AP between different trained models of the same architecture. The authors report a +0.46% gain. \n\nIn addition, the authors do not provide results for other baseline approaches that have similar FLOPs at test time, such as iterative bounding box regression and input scale augmentation. Note that both these approaches do not add any parameters and require no additional memory, but add to the FLOPs at test time. From my personal experience, test time augmentations can add +1.5% to the final performance. Concretely, look at Mask R-CNN arXiv Table 8 last two rows. Test time augmentations add 1.5% on top of an already enhanced model. Empirically, the better the model the harder it is to get gains from inference tricks! And still test time augmentations boost performance significantly.\n\nGiven the small gains and the lack of competing baselines, it is hard to make a case for accepting the paper. ", "rating": "4: Ok but not good enough - rejection", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}, "signatures": ["ICLR.cc/2019/Conference/Paper554/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Conscious Inference for Object Detection", "abstract": "Current Convolutional Neural Network (CNN)-based object detection models adopt strictly feedforward inference to predict the final detection results. However, the widely used one-way inference is agnostic to the global image context and the interplay between input image and task semantics. In this work, we present a general technique to improve off-the-shelf CNN-based object detection models in the inference stage without re-training, architecture modification or ground-truth requirements. We propose an iterative, bottom-up and top-down inference mechanism, which is named conscious inference, as it is inspired by prevalent models for human consciousness with top-down guidance and temporal persistence. While the downstream pass accumulates category-specific evidence over time, it subsequently affects the proposal calculation and the final detection. Feature activations are updated in line with no additional memory cost. Our approach advances the state of the art using popular detection models (Faster-RCNN, YOLOv2, YOLOv3) on 2D object detection and 6D object pose estimation.", "keywords": ["consciousness", "conscious inference", "object detection", "object pose estimation"], "authorids": ["zhoujh09@gmail.com", "nikolaos.karianakis@microsoft.com", "yingwu@eecs.northwestern.edu", "ganghua@gmail.com"], "authors": ["Jiahuan Zhou", "Nikolaos Karianakis", "Ying Wu", "Gang Hua"], "pdf": "/pdf/0f74b0628cab25f337fa905145d5566ad614179f.pdf", "paperhash": "zhou|conscious_inference_for_object_detection", "_bibtex": "@misc{\nzhou2019conscious,\ntitle={Conscious Inference for Object Detection},\nauthor={Jiahuan Zhou and Nikolaos Karianakis and Ying Wu and Gang Hua},\nyear={2019},\nurl={https://openreview.net/forum?id=HygYqs0qKX},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper554/Official_Review", "cdate": 1542234434891, "expdate": 1552335264000, "duedate": 1541196000000, "reply": {"forum": "HygYqs0qKX", "replyto": "HygYqs0qKX", "readers": {"description": "The users who will be allowed to read the reply content.", "values": ["everyone"]}, "nonreaders": {"values": []}, "signatures": {"description": "How your identity will be displayed with the above content.", "values-regex": "ICLR.cc/2019/Conference/Paper554/AnonReviewer[0-9]+"}, "writers": {"description": "Users that may modify this record.", "values": ["ICLR.cc/2019/Conference"]}, "content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "required": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}}, "multiReply": false, "tcdate": 1552335750723, "tmdate": 1552335750723, "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "invitees": ["ICLR.cc/2019/Conference/Paper554/Reviewers"], "noninvitees": [], "signatures": ["ICLR.cc/2019/Conference"]}}}], "count": 8}