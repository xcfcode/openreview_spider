{"notes": [{"tddate": null, "ddate": null, "cdate": null, "original": null, "tmdate": 1490028572685, "tcdate": 1490028572685, "number": 1, "id": "rJSX_K6ox", "invitation": "ICLR.cc/2017/workshop/-/paper54/acceptance", "forum": "rknkNR7Ke", "replyto": "rknkNR7Ke", "signatures": ["ICLR.cc/2017/pcs"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/pcs"], "content": {"decision": "Accept", "title": "ICLR committee final decision"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Trace Norm Regularised Deep Multi-Task Learning", "abstract": "We propose a framework for training multiple neural networks simultaneously. The parameters from all models are regularised by the tensor trace norm, so that each neural network is encouraged to reuse others' parameters if possible -- this is the main motivation behind multi-task learning. In contrast to many deep multi-task learning models, we do not predefine a parameter sharing strategy by specifying which layers have tied parameters. Instead, our framework considers sharing for all shareable layers, and the sharing strategy is learned in a data-driven way. ", "pdf": "/pdf/c38b8eda134dc736a15611296a1f6e2e0773c437.pdf", "TL;DR": "Extending the idea of trace norm regularised matrix-based multi-task learning to deep nets", "paperhash": "yang|trace_norm_regularised_deep_multitask_learning", "conflicts": ["qmul.ac.uk"], "authorids": ["yongxin.yang@qmul.ac.uk", "t.hospedales@qmul.ac.uk"], "keywords": [], "authors": ["Yongxin Yang", "Timothy M. Hospedales"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "tmdate": 1490028573227, "id": "ICLR.cc/2017/workshop/-/paper54/acceptance", "writers": ["ICLR.cc/2017/workshop"], "signatures": ["ICLR.cc/2017/workshop"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/pcs"], "noninvitees": ["ICLR.cc/2017/pcs"], "reply": {"forum": "rknkNR7Ke", "replyto": "rknkNR7Ke", "writers": {"values-regex": "ICLR.cc/2017/pcs"}, "signatures": {"values-regex": "ICLR.cc/2017/pcs", "description": "Your displayed identity associated with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your decision.", "value": "ICLR committee final decision"}, "decision": {"required": true, "order": 3, "value-radio": ["Accept", "Reject"]}}}, "nonreaders": [], "cdate": 1490028573227}}}, {"tddate": null, "tmdate": 1489628118951, "tcdate": 1489628118951, "number": 2, "id": "rkJy3vwsx", "invitation": "ICLR.cc/2017/workshop/-/paper54/official/review", "forum": "rknkNR7Ke", "replyto": "rknkNR7Ke", "signatures": ["ICLR.cc/2017/workshop/paper54/AnonReviewer2"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/workshop/paper54/AnonReviewer2"], "content": {"title": "Review", "rating": "6: Marginally above acceptance threshold", "review": "## Quality:\nThis is an interesting paper presenting a cute idea. It reads a bit like a \"this didn't work as well\"-alternative approach to its sister paper implementing the same idea with Tensor Factorisation, which is on ICLR main conference: https://openreview.net/pdf?id=SkhU2fcll\n## Clarity:\nVery clear, well-written.\n## Significance:\nThis seems the biggest problem. The results are quite weak, clearly inferior to the sister paper.\nMost importantly, why is the baseline omniglot STL accuracy around 0.34 while in the sister paper the accuracy for the same baseline appears to be around 0.65 in Fig4 top left? Am I missing something here?\nIn any case I believe that there should be a comparison against normal explicit sharing of the weights as baseline, which is easy to add in the plots.\nApart from that there is some smaller remarks that impact signficance:\n+ there must be a lot of computational overhead to compute an SVD on each weight layer, which I assume needs to be computed after every weight update? What was the additional compute time?\n+ The number of parameters is still the same as if these networks were trained independently, so parameter reduction is one advantage of hard explicit sharing which falls away here.\n\n## Other remarks:\nA relevant application of MTL is multilingual acoustic model training in speech.\nSee eg Scanzio et al 2008 (https://scholar.google.com/scholar?cites=2941155962830961778), which has all but the last layers shared, and Sercu et al 2015 (https://arxiv.org/abs/1509.08967) which is a CNN-based model and has multiple FC layers split.\n\nOverall, PRO: cute idea, novel, well-written paper. CON: a bit too similar to sister paper on main track, weak results (and please clarify the difference in baseline?)", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Trace Norm Regularised Deep Multi-Task Learning", "abstract": "We propose a framework for training multiple neural networks simultaneously. The parameters from all models are regularised by the tensor trace norm, so that each neural network is encouraged to reuse others' parameters if possible -- this is the main motivation behind multi-task learning. In contrast to many deep multi-task learning models, we do not predefine a parameter sharing strategy by specifying which layers have tied parameters. Instead, our framework considers sharing for all shareable layers, and the sharing strategy is learned in a data-driven way. ", "pdf": "/pdf/c38b8eda134dc736a15611296a1f6e2e0773c437.pdf", "TL;DR": "Extending the idea of trace norm regularised matrix-based multi-task learning to deep nets", "paperhash": "yang|trace_norm_regularised_deep_multitask_learning", "conflicts": ["qmul.ac.uk"], "authorids": ["yongxin.yang@qmul.ac.uk", "t.hospedales@qmul.ac.uk"], "keywords": [], "authors": ["Yongxin Yang", "Timothy M. Hospedales"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1489183200000, "tmdate": 1489628119676, "id": "ICLR.cc/2017/workshop/-/paper54/official/review", "writers": ["ICLR.cc/2017/workshop"], "signatures": ["ICLR.cc/2017/workshop"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/workshop/paper54/reviewers"], "noninvitees": ["ICLR.cc/2017/workshop/paper54/AnonReviewer1", "ICLR.cc/2017/workshop/paper54/AnonReviewer2"], "reply": {"forum": "rknkNR7Ke", "replyto": "rknkNR7Ke", "writers": {"values-regex": "ICLR.cc/2017/workshop/paper54/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/workshop/paper54/AnonReviewer[0-9]+"}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "value-regex": "[\\S\\s]{1,5000}"}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1496959200000, "cdate": 1489628119676}}}, {"tddate": null, "tmdate": 1489195707882, "tcdate": 1489195707882, "number": 1, "id": "S14afRlix", "invitation": "ICLR.cc/2017/workshop/-/paper54/official/review", "forum": "rknkNR7Ke", "replyto": "rknkNR7Ke", "signatures": ["ICLR.cc/2017/workshop/paper54/AnonReviewer1"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/workshop/paper54/AnonReviewer1"], "content": {"title": "Interesting idea but weak results (for now)", "rating": "7: Good paper, accept", "review": "The authors introduce the idea to train multi-task networks by constructing separate networks for different tasks and then putting a limit on the tensor-norm on shareable layers. In this ways it's not needed to explicitly design sharing (but different tasks still need to share the architecture). The proposed tensor losses are not differentiable, so to optimize them with SGD during training the author use sub-gradient descent. These are certainly interesting ideas which warrant acceptance. The presented results, improving accuracy on Omniglot from about 34% to about 36% are very weak though, considering that SOTA for deep learning (but using metric learning) is above 90% (e.g. from matching networks). Or is this not a fair comparison? In any case, the paper certainly warrants workshop acceptance.", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Trace Norm Regularised Deep Multi-Task Learning", "abstract": "We propose a framework for training multiple neural networks simultaneously. The parameters from all models are regularised by the tensor trace norm, so that each neural network is encouraged to reuse others' parameters if possible -- this is the main motivation behind multi-task learning. In contrast to many deep multi-task learning models, we do not predefine a parameter sharing strategy by specifying which layers have tied parameters. Instead, our framework considers sharing for all shareable layers, and the sharing strategy is learned in a data-driven way. ", "pdf": "/pdf/c38b8eda134dc736a15611296a1f6e2e0773c437.pdf", "TL;DR": "Extending the idea of trace norm regularised matrix-based multi-task learning to deep nets", "paperhash": "yang|trace_norm_regularised_deep_multitask_learning", "conflicts": ["qmul.ac.uk"], "authorids": ["yongxin.yang@qmul.ac.uk", "t.hospedales@qmul.ac.uk"], "keywords": [], "authors": ["Yongxin Yang", "Timothy M. Hospedales"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1489183200000, "tmdate": 1489628119676, "id": "ICLR.cc/2017/workshop/-/paper54/official/review", "writers": ["ICLR.cc/2017/workshop"], "signatures": ["ICLR.cc/2017/workshop"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/workshop/paper54/reviewers"], "noninvitees": ["ICLR.cc/2017/workshop/paper54/AnonReviewer1", "ICLR.cc/2017/workshop/paper54/AnonReviewer2"], "reply": {"forum": "rknkNR7Ke", "replyto": "rknkNR7Ke", "writers": {"values-regex": "ICLR.cc/2017/workshop/paper54/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/workshop/paper54/AnonReviewer[0-9]+"}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "value-regex": "[\\S\\s]{1,5000}"}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1496959200000, "cdate": 1489628119676}}}, {"tddate": null, "replyto": null, "ddate": null, "tmdate": 1487295459927, "tcdate": 1487295459927, "number": 54, "id": "rknkNR7Ke", "invitation": "ICLR.cc/2017/workshop/-/submission", "forum": "rknkNR7Ke", "signatures": ["~Yongxin_Yang1"], "readers": ["everyone"], "content": {"title": "Trace Norm Regularised Deep Multi-Task Learning", "abstract": "We propose a framework for training multiple neural networks simultaneously. The parameters from all models are regularised by the tensor trace norm, so that each neural network is encouraged to reuse others' parameters if possible -- this is the main motivation behind multi-task learning. In contrast to many deep multi-task learning models, we do not predefine a parameter sharing strategy by specifying which layers have tied parameters. Instead, our framework considers sharing for all shareable layers, and the sharing strategy is learned in a data-driven way. ", "pdf": "/pdf/c38b8eda134dc736a15611296a1f6e2e0773c437.pdf", "TL;DR": "Extending the idea of trace norm regularised matrix-based multi-task learning to deep nets", "paperhash": "yang|trace_norm_regularised_deep_multitask_learning", "conflicts": ["qmul.ac.uk"], "authorids": ["yongxin.yang@qmul.ac.uk", "t.hospedales@qmul.ac.uk"], "keywords": [], "authors": ["Yongxin Yang", "Timothy M. Hospedales"]}, "writers": [], "nonreaders": [], "details": {"replyCount": 3, "writable": false, "overwriting": [], "revisions": false, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1487690420000, "tmdate": 1484242559574, "id": "ICLR.cc/2017/workshop/-/submission", "writers": ["ICLR.cc/2017/workshop"], "signatures": ["ICLR.cc/2017/pcs"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": null, "replyto": null, "writers": {"values-regex": "~.*"}, "signatures": {"values-regex": "~.*", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"pdf": {"required": true, "order": 5, "description": "Either upload a PDF file or provide a direct link to your PDF on ArXiv (link must begin with http(s) and end with .pdf)", "value-regex": "upload|(http|https):\\/\\/.+\\.pdf"}, "title": {"required": true, "order": 1, "description": "Title of paper.", "value-regex": ".{1,250}"}, "abstract": {"required": true, "order": 4, "description": "Abstract of paper.", "value-regex": "[\\S\\s]{1,5000}"}, "authors": {"required": true, "order": 2, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of author names, as they appear in the paper."}, "conflicts": {"required": true, "order": 100, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of email domains of people who would have a conflict of interest in reviewing this paper, (e.g., cs.umass.edu;google.com, etc.)."}, "keywords": {"order": 6, "description": "Comma separated list of keywords.", "values-dropdown": ["Theory", "Computer vision", "Speech", "Natural language processing", "Deep learning", "Unsupervised Learning", "Supervised Learning", "Semi-Supervised Learning", "Reinforcement Learning", "Transfer Learning", "Multi-modal learning", "Applications", "Optimization", "Structured prediction", "Games"]}, "TL;DR": {"required": false, "order": 3, "description": "\"Too Long; Didn't Read\": a short sentence describing your paper", "value-regex": "[^\\n]{0,250}"}, "authorids": {"required": true, "order": 3, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of author email addresses, in the same order as above."}}}, "nonreaders": [], "noninvitees": [], "expdate": 1495466420000, "cdate": 1484242559574}}}], "count": 4}