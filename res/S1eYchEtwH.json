{"notes": [{"id": "S1eYchEtwH", "original": "rylpDJc1DH", "number": 122, "cdate": 1569438864760, "ddate": null, "tcdate": 1569438864760, "tmdate": 1577168272006, "tddate": null, "forum": "S1eYchEtwH", "replyto": null, "invitation": "ICLR.cc/2020/Conference/-/Blind_Submission", "content": {"authors": ["Nils Rottmann", "Tjasa Kunavar", "Jan Babic", "Jan Peters", "Elmar Rueckert"], "title": "Learning Human Postural Control with Hierarchical Acquisition Functions", "abstract": "Learning control policies in robotic tasks requires a large number of interactions due to small learning rates, bounds on the updates or unknown constraints. In contrast humans can infer protective and safe solutions after a single failure or unexpected observation. \nIn order to reach similar performance, we developed a hierarchical Bayesian optimization algorithm that replicates the cognitive inference and memorization process for avoiding failures in motor control tasks. A Gaussian Process implements the modeling and the sampling of the acquisition function. This enables rapid learning with large learning rates while a mental replay phase ensures that policy regions that led to failures are inhibited during the sampling process.    \nThe features of the hierarchical Bayesian optimization method are evaluated in a simulated and physiological humanoid postural balancing task. We quantitatively compare the human learning performance to our learning approach by evaluating the deviations of the center of mass during training. Our results show that we can reproduce the efficient learning of human subjects in postural control tasks which provides a testable model for future physiological motor control tasks. In these postural control tasks, our method outperforms standard Bayesian Optimization in the number of interactions to solve the task, in the computational demands and in the frequency of observed failures. ", "authorids": ["rottmann@rob.uni-luebeck.de", "tjasa.kunavar@ijs.si", "jan.babic@ijs.si", "mail@jan-peters.net", "rueckert@ai-lab.science"], "keywords": ["Human Postural Control Model", "Hierarchical Bayesian Optimization", "Acquisition Function"], "TL;DR": "This paper presents a computational model for efficient human postural control adaptation based on hierarchical acquisition functions with well-known features. ", "pdf": "/pdf/3a9f19aa365f2cdf846ca5e814bde62768052edc.pdf", "paperhash": "rottmann|learning_human_postural_control_with_hierarchical_acquisition_functions", "original_pdf": "/attachment/3a9f19aa365f2cdf846ca5e814bde62768052edc.pdf", "_bibtex": "@misc{\nrottmann2020learning,\ntitle={Learning Human Postural Control with Hierarchical Acquisition Functions},\nauthor={Nils Rottmann and Tjasa Kunavar and Jan Babic and Jan Peters and Elmar Rueckert},\nyear={2020},\nurl={https://openreview.net/forum?id=S1eYchEtwH}\n}"}, "signatures": ["ICLR.cc/2020/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference"], "details": {"replyCount": 6, "writable": false, "overwriting": [], "revisions": false, "tags": [], "invitation": {"reply": {"readers": {"values-regex": ".*"}, "writers": {"values": ["ICLR.cc/2020/Conference"]}, "signatures": {"values": ["ICLR.cc/2020/Conference"]}, "content": {"spotlight_video": {"value-regex": ".*"}, "full_presentation_video": {"value-regex": ".*"}, "original_pdf": {"required": false, "description": "Upload a PDF file that ends with .pdf", "value-regex": ".*"}, "appendix": {"value-regex": ".*"}, "authorids": {"values-regex": ".*"}, "poster": {"value-regex": ".*"}, "authors": {"values": ["Anonymous"]}, "slides": {"value-regex": ".*"}}}, "final": [], "signatures": ["ICLR.cc/2020/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference"], "noninvitees": [], "tcdate": 1569271260237, "tmdate": 1593459412141, "id": "ICLR.cc/2020/Conference/-/Blind_Submission"}}, "tauthor": "OpenReview.net"}, {"id": "CdVLFxjlSj", "original": null, "number": 1, "cdate": 1576798688032, "ddate": null, "tcdate": 1576798688032, "tmdate": 1576800947032, "tddate": null, "forum": "S1eYchEtwH", "replyto": "S1eYchEtwH", "invitation": "ICLR.cc/2020/Conference/Paper122/-/Decision", "content": {"decision": "Reject", "comment": "The paper proposes hierarchical Bayesian optimization (HiBO) for learning control policies from a small number of environment interaction and applies it to the postural control of a humanoid. Both reviewers raised issues with the clarity of presentation, as well as contribution and overall fit to this venue. The authors\u2019 response helped to clarify these issues only marginally. Therefore, primarily due to lack of clarity, I recommend rejecting this paper, but encourage the authors to improve the presentation as per the reviewers\u2019 suggestions and resubmitting.", "title": "Paper Decision"}, "signatures": ["ICLR.cc/2020/Conference/Program_Chairs"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Program_Chairs"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authors": ["Nils Rottmann", "Tjasa Kunavar", "Jan Babic", "Jan Peters", "Elmar Rueckert"], "title": "Learning Human Postural Control with Hierarchical Acquisition Functions", "abstract": "Learning control policies in robotic tasks requires a large number of interactions due to small learning rates, bounds on the updates or unknown constraints. In contrast humans can infer protective and safe solutions after a single failure or unexpected observation. \nIn order to reach similar performance, we developed a hierarchical Bayesian optimization algorithm that replicates the cognitive inference and memorization process for avoiding failures in motor control tasks. A Gaussian Process implements the modeling and the sampling of the acquisition function. This enables rapid learning with large learning rates while a mental replay phase ensures that policy regions that led to failures are inhibited during the sampling process.    \nThe features of the hierarchical Bayesian optimization method are evaluated in a simulated and physiological humanoid postural balancing task. We quantitatively compare the human learning performance to our learning approach by evaluating the deviations of the center of mass during training. Our results show that we can reproduce the efficient learning of human subjects in postural control tasks which provides a testable model for future physiological motor control tasks. In these postural control tasks, our method outperforms standard Bayesian Optimization in the number of interactions to solve the task, in the computational demands and in the frequency of observed failures. ", "authorids": ["rottmann@rob.uni-luebeck.de", "tjasa.kunavar@ijs.si", "jan.babic@ijs.si", "mail@jan-peters.net", "rueckert@ai-lab.science"], "keywords": ["Human Postural Control Model", "Hierarchical Bayesian Optimization", "Acquisition Function"], "TL;DR": "This paper presents a computational model for efficient human postural control adaptation based on hierarchical acquisition functions with well-known features. ", "pdf": "/pdf/3a9f19aa365f2cdf846ca5e814bde62768052edc.pdf", "paperhash": "rottmann|learning_human_postural_control_with_hierarchical_acquisition_functions", "original_pdf": "/attachment/3a9f19aa365f2cdf846ca5e814bde62768052edc.pdf", "_bibtex": "@misc{\nrottmann2020learning,\ntitle={Learning Human Postural Control with Hierarchical Acquisition Functions},\nauthor={Nils Rottmann and Tjasa Kunavar and Jan Babic and Jan Peters and Elmar Rueckert},\nyear={2020},\nurl={https://openreview.net/forum?id=S1eYchEtwH}\n}"}, "tags": [], "invitation": {"reply": {"writers": {"description": "How your identity will be displayed.", "values-regex": ["ICLR.cc/2020/Conference/Program_Chairs"]}, "signatures": {"values": ["ICLR.cc/2020/Conference/Program_Chairs"], "description": "How your identity will be displayed."}, "content": {"decision": {"value-radio": ["Accept (Spotlight)", "Accept (Talk)", "Accept (Poster)", "Reject"], "description": "Decision", "required": true, "order": 2}, "title": {"value": "Paper Decision", "required": true, "order": 1}, "comment": {"value-regex": "[\\S\\s]{0,5000}", "description": "", "required": false, "order": 3}}, "forum": "S1eYchEtwH", "replyto": "S1eYchEtwH", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}}, "expdate": 1576854540000, "duedate": 1576853940000, "multiReply": false, "readers": ["everyone"], "invitees": ["ICLR.cc/2020/Conference/Program_Chairs"], "tcdate": 1576795730387, "tmdate": 1576800283171, "super": "ICLR.cc/2020/Conference/-/Decision", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper122/-/Decision"}}}, {"id": "rkxtaO2mcr", "original": null, "number": 2, "cdate": 1572223168788, "ddate": null, "tcdate": 1572223168788, "tmdate": 1574740890425, "tddate": null, "forum": "S1eYchEtwH", "replyto": "S1eYchEtwH", "invitation": "ICLR.cc/2020/Conference/Paper122/-/Official_Review", "content": {"experience_assessment": "I have read many papers in this area.", "rating": "1: Reject", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "title": "Official Blind Review #2", "review": "After rebuttal:\n\nThank you to the authors for responding to my review.\n\n1) The title of the conference is \"... on Learning Representations\". As I stated in the review (\"no, e.g., neural networks are employed\"), neural networks are an *example* of, but do not subsume, all representation learning methods. Therefore, I agree that papers that do not cover neural networks are welcome at the conference. However, as I stated in the review, my evaluation of the method proposed in the submission is that it does not concern representation learning (\"The employed features in Table 3 are handcrafted\"). I believe this evaluation is defensible, but of course the final evaluation is up to the chairs. However, I note that the authors did not respond directly to my evaluation that the method is not engaging in representation learning.\n\n2-7) As the other reviewer notes, the paper lacks clarity in many places, and does not sufficiently discuss prior work, including in postural control (there is one citation in the references that is not mentioned in the main text), hierarchical Bayesian optimization within or without a Gaussian processes framework (https://scholar.google.com/scholar?hl=fr&as_sdt=0%2C5&q=hierarchical+bayesian+optimization&btnG=), or experience replay (https://scholar.google.com/scholar?hl=fr&as_sdt=0%2C5&q=replay+machine+learning&btnG=). Therefore, it is difficult to ascertain the research contribution.\n\nAs such, I stand by my evaluation that this submission is not ready for publication at ICLR.\n\n===========================\n\nBefore rebuttal:\n\nThe submission presents a hierarchical Bayesian optimization (HiBO) approach to solving a postural control task expressed as a proportional-derivative (PD) controller.\n\nStrengths:\n- The HiBO approach outperforms the non-hierarchical BO approach on the task of postural control.\n\nWeaknesses:\n- The paper does not make use of representation learning (no, e.g., neural networks are employed) and is therefore out-of-place at ICLR. The employed features in Table 3 are handcrafted.\n- The task (simulating human postural control) is not well-situated in the context of prior work using HiBO for robotics, so the contribution remains unclear.\n- It is not clear why this problem should be formulated as contextual policy search (i.e., to what the context variable refers).\n- Only one baseline (Bayesian optimization (BO)) is reported. This baseline corresponds to the ablation of the HiBO method (i.e., the omission of the context variable), and so does not represent, more broadly, an alternative approach.\n- The concept of \"mental replay\" is briefly introduced, but no reference is made to prior work in imagined rollouts, and no ablation study on the impact of this component is performed.\n\nMinor points:\n- It is unclear why the problem setting should be labeled as \"psychological\" postural control.\n- There are several missing references (\"?\") in the text.", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory."}, "signatures": ["ICLR.cc/2020/Conference/Paper122/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper122/AnonReviewer2"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authors": ["Nils Rottmann", "Tjasa Kunavar", "Jan Babic", "Jan Peters", "Elmar Rueckert"], "title": "Learning Human Postural Control with Hierarchical Acquisition Functions", "abstract": "Learning control policies in robotic tasks requires a large number of interactions due to small learning rates, bounds on the updates or unknown constraints. In contrast humans can infer protective and safe solutions after a single failure or unexpected observation. \nIn order to reach similar performance, we developed a hierarchical Bayesian optimization algorithm that replicates the cognitive inference and memorization process for avoiding failures in motor control tasks. A Gaussian Process implements the modeling and the sampling of the acquisition function. This enables rapid learning with large learning rates while a mental replay phase ensures that policy regions that led to failures are inhibited during the sampling process.    \nThe features of the hierarchical Bayesian optimization method are evaluated in a simulated and physiological humanoid postural balancing task. We quantitatively compare the human learning performance to our learning approach by evaluating the deviations of the center of mass during training. Our results show that we can reproduce the efficient learning of human subjects in postural control tasks which provides a testable model for future physiological motor control tasks. In these postural control tasks, our method outperforms standard Bayesian Optimization in the number of interactions to solve the task, in the computational demands and in the frequency of observed failures. ", "authorids": ["rottmann@rob.uni-luebeck.de", "tjasa.kunavar@ijs.si", "jan.babic@ijs.si", "mail@jan-peters.net", "rueckert@ai-lab.science"], "keywords": ["Human Postural Control Model", "Hierarchical Bayesian Optimization", "Acquisition Function"], "TL;DR": "This paper presents a computational model for efficient human postural control adaptation based on hierarchical acquisition functions with well-known features. ", "pdf": "/pdf/3a9f19aa365f2cdf846ca5e814bde62768052edc.pdf", "paperhash": "rottmann|learning_human_postural_control_with_hierarchical_acquisition_functions", "original_pdf": "/attachment/3a9f19aa365f2cdf846ca5e814bde62768052edc.pdf", "_bibtex": "@misc{\nrottmann2020learning,\ntitle={Learning Human Postural Control with Hierarchical Acquisition Functions},\nauthor={Nils Rottmann and Tjasa Kunavar and Jan Babic and Jan Peters and Elmar Rueckert},\nyear={2020},\nurl={https://openreview.net/forum?id=S1eYchEtwH}\n}"}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "S1eYchEtwH", "replyto": "S1eYchEtwH", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper122/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper122/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1575370842993, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper122/Reviewers"], "noninvitees": [], "tcdate": 1570237756745, "tmdate": 1575370843007, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper122/-/Official_Review"}}}, {"id": "BkxLPPgFiB", "original": null, "number": 8, "cdate": 1573615454278, "ddate": null, "tcdate": 1573615454278, "tmdate": 1573615454278, "tddate": null, "forum": "S1eYchEtwH", "replyto": "SJxH6hmPjr", "invitation": "ICLR.cc/2020/Conference/Paper122/-/Official_Comment", "content": {"title": "Reply", "comment": "1,2,3,4) Firstly, I apologize for using the word \"awfully\", which might give you a hard time. I respect your hard work, but reading the paper also gave me a hard time. \n\nThe problem is that the meanings of your jargons are not explained. \n\nFor example, the \"context\" vector $c$, if you look at Eq(1), how $c$ is used besides being conditioned by $\\theta$. But $\\theta$ is the parameter to be optimized, so what's the functionality of $c$? On the other hand, if you could have an example for the setup, it will make more sense. But even in the experiment section, I don't see what is the context \"c\".\n\nFurthermore, for what \"is well known in the reinforcement learning and machine learning community\", the notation $\\pi$ is used for: \"$\\pi(a|s)$ is the probability that action is $a$ if state is $s$\" (from Page 58, Richard Sutton's RL book). It took me a long time to figure out why do you have two actions \"\\theta\" and $u$.\n\n5) My novelty judgement is speculatively guess based on my experiences. I have stressed that it is based on \"my very limited understanding\". Because the proposed approach is mostly related to the context $c$ and the parameter $\\theta$, it will be hard to understand before understanding what is $c$. \n\n6) For the experiment section in the main article, it should be focused on evaluating the proposed method instead of talking about the experiment details. However, it is until Figure 5 that the proposed HIBO is compared to baselines. Although the experiment section has a lot of figures, useful figures are not much, that's why I gave the judgement. \n\n7) I don't know the literatures about \"perturbed mental replay\", please tell me if I was ignorant. On the other hand, if the method is existing, it should be cited when it is introduced. Otherwise, the reader will think that it is original.\n\nA1) I selected that because the paper doesn't really have derivations and theories. Before section 2.3, there are existing formulas. In section 2.3, the formulas aren't new. (I am not saying the method is not new, I am just saying the \"derivations\" are not new).\nA2) On the one hand, I spent a lot of time on this paper. This paper was the first one I read between all I need to review, because I thought it looked interesting. I read it twice or so but could not understand. On the time of writing reviews, I read it probably another once or twice. On the other hand, I am busy. I hope I can learn something from the reviewing process so that I don't waste my time on the reviewing. Unfortunately, I don't think I learnt much interesting stuff from reviewing this paper. \n\nOverall, the best thing happens when one reviewer enjoys the paper he is reading and the authors are glad with the high score from the reviewer. In the opposite, the worst thing happens."}, "signatures": ["ICLR.cc/2020/Conference/Paper122/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper122/AnonReviewer1", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authors": ["Nils Rottmann", "Tjasa Kunavar", "Jan Babic", "Jan Peters", "Elmar Rueckert"], "title": "Learning Human Postural Control with Hierarchical Acquisition Functions", "abstract": "Learning control policies in robotic tasks requires a large number of interactions due to small learning rates, bounds on the updates or unknown constraints. In contrast humans can infer protective and safe solutions after a single failure or unexpected observation. \nIn order to reach similar performance, we developed a hierarchical Bayesian optimization algorithm that replicates the cognitive inference and memorization process for avoiding failures in motor control tasks. A Gaussian Process implements the modeling and the sampling of the acquisition function. This enables rapid learning with large learning rates while a mental replay phase ensures that policy regions that led to failures are inhibited during the sampling process.    \nThe features of the hierarchical Bayesian optimization method are evaluated in a simulated and physiological humanoid postural balancing task. We quantitatively compare the human learning performance to our learning approach by evaluating the deviations of the center of mass during training. Our results show that we can reproduce the efficient learning of human subjects in postural control tasks which provides a testable model for future physiological motor control tasks. In these postural control tasks, our method outperforms standard Bayesian Optimization in the number of interactions to solve the task, in the computational demands and in the frequency of observed failures. ", "authorids": ["rottmann@rob.uni-luebeck.de", "tjasa.kunavar@ijs.si", "jan.babic@ijs.si", "mail@jan-peters.net", "rueckert@ai-lab.science"], "keywords": ["Human Postural Control Model", "Hierarchical Bayesian Optimization", "Acquisition Function"], "TL;DR": "This paper presents a computational model for efficient human postural control adaptation based on hierarchical acquisition functions with well-known features. ", "pdf": "/pdf/3a9f19aa365f2cdf846ca5e814bde62768052edc.pdf", "paperhash": "rottmann|learning_human_postural_control_with_hierarchical_acquisition_functions", "original_pdf": "/attachment/3a9f19aa365f2cdf846ca5e814bde62768052edc.pdf", "_bibtex": "@misc{\nrottmann2020learning,\ntitle={Learning Human Postural Control with Hierarchical Acquisition Functions},\nauthor={Nils Rottmann and Tjasa Kunavar and Jan Babic and Jan Peters and Elmar Rueckert},\nyear={2020},\nurl={https://openreview.net/forum?id=S1eYchEtwH}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "S1eYchEtwH", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper122/Authors", "ICLR.cc/2020/Conference/Paper122/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper122/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper122/Reviewers", "ICLR.cc/2020/Conference/Paper122/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper122/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper122/Authors|ICLR.cc/2020/Conference/Paper122/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504176083, "tmdate": 1576860538887, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper122/Authors", "ICLR.cc/2020/Conference/Paper122/Reviewers", "ICLR.cc/2020/Conference/Paper122/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper122/-/Official_Comment"}}}, {"id": "SJxH6hmPjr", "original": null, "number": 6, "cdate": 1573498044581, "ddate": null, "tcdate": 1573498044581, "tmdate": 1573498044581, "tddate": null, "forum": "S1eYchEtwH", "replyto": "rJlNlmY5tH", "invitation": "ICLR.cc/2020/Conference/Paper122/-/Official_Comment", "content": {"title": "Reply to the Official Blind Review #1", "comment": "Dear reviewer, \n\nthank you for taking a look at our paper. However, \n\n1) all variables used in the paper are clearly defined and listed (e.g., in Table 1). In page 7, after Equation 12, the concrete policy implementation for the task is discussed. \n\n2) \"1, The paper is awfully written.\u201d \nIt is not sufficient to publish such a statement without concrete references. If you refer to point 3) then we strongly disagree.\n\n3) \"I don't see anywhere explaining how the states x_t, commands u_t, \\theta, and feature \\phi are related? \u201c \nIn Equation 1, the mentioned variables are put in relation. Moreover, problem statements of our form are common in reinforcement learning and machine learning. Given your expertise (Experience Assessment: I have published one or two papers in this area.) this should be known. \n\n4) \"What is \\phi ? It is super wired why the feature parameter \\phi is jointly maximized with the policy parameter. Because I don't understand the formulation, I can hardly understand anything else.\u201d\nPlease see our answer to point 1). We discuss a standard optimization problem definition which is well known in the reinforcement learning and machine learning community. \n\n5) \"From my very limited understanding on the formulation, the proposed HIBO is trivial.\u201d \nCan you provide further details on that statement or is this speculative? \n\n6) \"The experiments are limited. The paper only conducts one experiment on the Humanoid control balancing. And they paper only compares with the EI acquisition, while the state-of-art acquisition MES should be also be compared with.\u201d\nWe evaluated our approach on a challenging non-linear postural control task. We compared to the most closely related approach that is Bayesian optimization and evaluated several acquisition functions and kernels (EI, UCB, EI+ARD, UCB+ARD). We did not observe any statistical significant difference and only reported the results for EI. However, we will add a summary statement to the results and details to a supplement.  \nIt is important to note that our proposed hierarchical acquisition function can be implemented with any acquisition function (EI, LCB, PI, MES, etc.). However, we thank the reviewer for the link to [1] and will also eval this acquisition function.   \n\n7) \"The proposed mental replay is not well justified, qualitatively or empirically.\u201d\nThe implemented mental replay is a common and well known practice in reinforcement learning. We will add references to related work. \n\nOur questions to the reviewer:\n\nA1) Your \"Review Assessment: Checking Correctness Of Derivations And Theory: N/A\u201d was selected because of your limited experience in the field? \n\nA2) How can we interpret your input on \"Review Assessment: Thoroughness In Paper Reading: N/A\u201d? You had limited time to review the paper?  \n\n\n[1] Wang, Zi, and Stefanie Jegelka. \"Max-value entropy search for efficient Bayesian optimization.\" Proceedings of the 34th International Conference on Machine Learning-Volume 70. JMLR. org, 2017."}, "signatures": ["ICLR.cc/2020/Conference/Paper122/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper122/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authors": ["Nils Rottmann", "Tjasa Kunavar", "Jan Babic", "Jan Peters", "Elmar Rueckert"], "title": "Learning Human Postural Control with Hierarchical Acquisition Functions", "abstract": "Learning control policies in robotic tasks requires a large number of interactions due to small learning rates, bounds on the updates or unknown constraints. In contrast humans can infer protective and safe solutions after a single failure or unexpected observation. \nIn order to reach similar performance, we developed a hierarchical Bayesian optimization algorithm that replicates the cognitive inference and memorization process for avoiding failures in motor control tasks. A Gaussian Process implements the modeling and the sampling of the acquisition function. This enables rapid learning with large learning rates while a mental replay phase ensures that policy regions that led to failures are inhibited during the sampling process.    \nThe features of the hierarchical Bayesian optimization method are evaluated in a simulated and physiological humanoid postural balancing task. We quantitatively compare the human learning performance to our learning approach by evaluating the deviations of the center of mass during training. Our results show that we can reproduce the efficient learning of human subjects in postural control tasks which provides a testable model for future physiological motor control tasks. In these postural control tasks, our method outperforms standard Bayesian Optimization in the number of interactions to solve the task, in the computational demands and in the frequency of observed failures. ", "authorids": ["rottmann@rob.uni-luebeck.de", "tjasa.kunavar@ijs.si", "jan.babic@ijs.si", "mail@jan-peters.net", "rueckert@ai-lab.science"], "keywords": ["Human Postural Control Model", "Hierarchical Bayesian Optimization", "Acquisition Function"], "TL;DR": "This paper presents a computational model for efficient human postural control adaptation based on hierarchical acquisition functions with well-known features. ", "pdf": "/pdf/3a9f19aa365f2cdf846ca5e814bde62768052edc.pdf", "paperhash": "rottmann|learning_human_postural_control_with_hierarchical_acquisition_functions", "original_pdf": "/attachment/3a9f19aa365f2cdf846ca5e814bde62768052edc.pdf", "_bibtex": "@misc{\nrottmann2020learning,\ntitle={Learning Human Postural Control with Hierarchical Acquisition Functions},\nauthor={Nils Rottmann and Tjasa Kunavar and Jan Babic and Jan Peters and Elmar Rueckert},\nyear={2020},\nurl={https://openreview.net/forum?id=S1eYchEtwH}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "S1eYchEtwH", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper122/Authors", "ICLR.cc/2020/Conference/Paper122/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper122/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper122/Reviewers", "ICLR.cc/2020/Conference/Paper122/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper122/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper122/Authors|ICLR.cc/2020/Conference/Paper122/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504176083, "tmdate": 1576860538887, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper122/Authors", "ICLR.cc/2020/Conference/Paper122/Reviewers", "ICLR.cc/2020/Conference/Paper122/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper122/-/Official_Comment"}}}, {"id": "B1gaVnmPjB", "original": null, "number": 5, "cdate": 1573497908856, "ddate": null, "tcdate": 1573497908856, "tmdate": 1573497908856, "tddate": null, "forum": "S1eYchEtwH", "replyto": "rkxtaO2mcr", "invitation": "ICLR.cc/2020/Conference/Paper122/-/Official_Comment", "content": {"title": "Reply to the Official Blind Review #2", "comment": "Dear reviewer, \n\nthank you for your review. However, we are a bit shocked about the quality of the review. In the following, we discuss your points of critics:  \n\n1) \"- The paper does not make use of representation learning (no, e.g., neural networks are employed) and is therefore out-of-place at ICLR. The employed features in Table 3 are handcrafted.\" \nICLR is not \"just about\" neural networks, as you can read here: https://iclr.cc/Conferences/2020/CallForPapers\n\n\"We consider a broad range of subject areas including feature learning, metric learning, compositional modeling, structured prediction, reinforcement learning, ...\" \n\nWe informed the program chairs about that issue. To discredit a paper due to an obviously wrong interpretation of  the conference topics is not acceptable. \n\n2) \"The task (simulating human postural control) is not well-situated in the context of prior work using HiBO for robotics, so the contribution remains unclear.\" \n\nHIBO was never published prior to this submission and no prior HIBO work exists. Further, postural control is considered as one of most challenging control problems in reinforcement learning and motor control.\n\n3) \" It is not clear why this problem should be formulated as contextual policy search (i.e., to what the context variable refers).\" \nThe mathematical framework of contextual policy search allows us to derive a general hierarchical model that can be applied to any other contextual policy search task. The context variables denote salient features of the motor skills that we intent to learn and can be adapted if needed. Therefore, they are referred as \"context variables\". However, we are open for suggestions of alternative mathematical representations if you provide details. \n \n4) \"Only one baseline (Bayesian optimization (BO)) is reported. This baseline corresponds to the ablation of the HiBO method (i.e., the omission of the context variable), and so does not represent, more broadly, an alternative approach.\" \nBO is a state of the art approach and most closely related. It is ideally suited to evaluate the benefits or drawbacks of an extension to hierarchical acquisition functions. Note that in most contextual policy search approaches the context is fixed and assumed to be known which is not the case in our approach. \n\n5) \"- The concept of \"mental replay\" is briefly introduced, but no reference is made to prior work in imagined rollouts, and no ablation study on the impact of this component is performed.\"\nAlthough that mental replay is a common and well known practice in reinforcement learning, we will add references to it. \n\n6) \"- It is unclear why the problem setting should be labeled as \"psychological\" postural control.\" \nThe term 'psychological' refers only to the experiment involving humans and is a standard terminology in human motor control. We will clarify that.  \n\n7) \"There are several missing references (\"?\") in the text.\"\nNo, there are not \"several\"  missing references (\"?\") in the text that we submitted! There is a singe missing ref \"?\" in page 5 to [1] due to a typo. We thank the reviewer for this comment. \n\n[1] Nakano, Eri, et al. \"Quantitative examinations of internal representations for arm trajectory planning: minimum commanded torque change model.\" Journal of Neurophysiology 81.5 (1999): 2140-2155.\n"}, "signatures": ["ICLR.cc/2020/Conference/Paper122/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper122/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authors": ["Nils Rottmann", "Tjasa Kunavar", "Jan Babic", "Jan Peters", "Elmar Rueckert"], "title": "Learning Human Postural Control with Hierarchical Acquisition Functions", "abstract": "Learning control policies in robotic tasks requires a large number of interactions due to small learning rates, bounds on the updates or unknown constraints. In contrast humans can infer protective and safe solutions after a single failure or unexpected observation. \nIn order to reach similar performance, we developed a hierarchical Bayesian optimization algorithm that replicates the cognitive inference and memorization process for avoiding failures in motor control tasks. A Gaussian Process implements the modeling and the sampling of the acquisition function. This enables rapid learning with large learning rates while a mental replay phase ensures that policy regions that led to failures are inhibited during the sampling process.    \nThe features of the hierarchical Bayesian optimization method are evaluated in a simulated and physiological humanoid postural balancing task. We quantitatively compare the human learning performance to our learning approach by evaluating the deviations of the center of mass during training. Our results show that we can reproduce the efficient learning of human subjects in postural control tasks which provides a testable model for future physiological motor control tasks. In these postural control tasks, our method outperforms standard Bayesian Optimization in the number of interactions to solve the task, in the computational demands and in the frequency of observed failures. ", "authorids": ["rottmann@rob.uni-luebeck.de", "tjasa.kunavar@ijs.si", "jan.babic@ijs.si", "mail@jan-peters.net", "rueckert@ai-lab.science"], "keywords": ["Human Postural Control Model", "Hierarchical Bayesian Optimization", "Acquisition Function"], "TL;DR": "This paper presents a computational model for efficient human postural control adaptation based on hierarchical acquisition functions with well-known features. ", "pdf": "/pdf/3a9f19aa365f2cdf846ca5e814bde62768052edc.pdf", "paperhash": "rottmann|learning_human_postural_control_with_hierarchical_acquisition_functions", "original_pdf": "/attachment/3a9f19aa365f2cdf846ca5e814bde62768052edc.pdf", "_bibtex": "@misc{\nrottmann2020learning,\ntitle={Learning Human Postural Control with Hierarchical Acquisition Functions},\nauthor={Nils Rottmann and Tjasa Kunavar and Jan Babic and Jan Peters and Elmar Rueckert},\nyear={2020},\nurl={https://openreview.net/forum?id=S1eYchEtwH}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "S1eYchEtwH", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper122/Authors", "ICLR.cc/2020/Conference/Paper122/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper122/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper122/Reviewers", "ICLR.cc/2020/Conference/Paper122/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper122/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper122/Authors|ICLR.cc/2020/Conference/Paper122/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504176083, "tmdate": 1576860538887, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper122/Authors", "ICLR.cc/2020/Conference/Paper122/Reviewers", "ICLR.cc/2020/Conference/Paper122/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper122/-/Official_Comment"}}}, {"id": "rJlNlmY5tH", "original": null, "number": 1, "cdate": 1571619563766, "ddate": null, "tcdate": 1571619563766, "tmdate": 1572972636001, "tddate": null, "forum": "S1eYchEtwH", "replyto": "S1eYchEtwH", "invitation": "ICLR.cc/2020/Conference/Paper122/-/Official_Review", "content": {"rating": "1: Reject", "experience_assessment": "I have published one or two papers in this area.", "review_assessment:_checking_correctness_of_derivations_and_theory": "N/A", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #1", "review_assessment:_thoroughness_in_paper_reading": "N/A", "review": "How to quickly learn control policies with minimized number of environment interactions have long been an important problem. To tackle this problem, this paper proposed a \"hierarchical Bayesian optimization (HIBO)\" algorithm to optimize the \"feature parameter \\phi\" (which I don't know what that is) and the \"policy parameter \\theta\" hierarchically. Under the formulation of maximizing reward J(\\theta), the algorithm firstly uses EI to select \\phi. Given the selected \\phi, the algorithm selects the policy parameter \\theta. The proposed algorithm is evaluated on a Humanoid Postural Balancing task, and shows achieves high rewards faster than the standard EI acquisition. However, the paper is awfully written such that I cannot understand what the \"feature parameter \\phi\" is. Given my limited understanding, I think the paper should be rejected.\n\nStrengths,\n1, The paper deals with an interesting task: Humanoid Postural Balancing. A Humanoid is expected to learn how to balance as quick as possible to reduce the interactions with the environments, which suits well with Bayesian optimization.\n\nWeakness,\n1, The paper is awfully written. The problem statement subsection is unreadable. I don't see anywhere explaining how the states x_t, commands u_t, \\theta, and feature \\phi are related? What is \\phi ? It is super wired why the feature parameter \\phi is jointly maximized with the policy parameter.  Because I don't understand the formulation, I can hardly understand anything else.\n2, From my very limited understanding on the formulation, the proposed HIBO is trivial.\n3, The experiments are limited. The paper only conducts one experiment on the Humanoid control balancing. And they paper only compares with the EI acquisition, while the state-of-art acquisition MES should be also be compared with.\n4, The proposed mental replay is not well justified, qualitatively or empirically."}, "signatures": ["ICLR.cc/2020/Conference/Paper122/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper122/AnonReviewer1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authors": ["Nils Rottmann", "Tjasa Kunavar", "Jan Babic", "Jan Peters", "Elmar Rueckert"], "title": "Learning Human Postural Control with Hierarchical Acquisition Functions", "abstract": "Learning control policies in robotic tasks requires a large number of interactions due to small learning rates, bounds on the updates or unknown constraints. In contrast humans can infer protective and safe solutions after a single failure or unexpected observation. \nIn order to reach similar performance, we developed a hierarchical Bayesian optimization algorithm that replicates the cognitive inference and memorization process for avoiding failures in motor control tasks. A Gaussian Process implements the modeling and the sampling of the acquisition function. This enables rapid learning with large learning rates while a mental replay phase ensures that policy regions that led to failures are inhibited during the sampling process.    \nThe features of the hierarchical Bayesian optimization method are evaluated in a simulated and physiological humanoid postural balancing task. We quantitatively compare the human learning performance to our learning approach by evaluating the deviations of the center of mass during training. Our results show that we can reproduce the efficient learning of human subjects in postural control tasks which provides a testable model for future physiological motor control tasks. In these postural control tasks, our method outperforms standard Bayesian Optimization in the number of interactions to solve the task, in the computational demands and in the frequency of observed failures. ", "authorids": ["rottmann@rob.uni-luebeck.de", "tjasa.kunavar@ijs.si", "jan.babic@ijs.si", "mail@jan-peters.net", "rueckert@ai-lab.science"], "keywords": ["Human Postural Control Model", "Hierarchical Bayesian Optimization", "Acquisition Function"], "TL;DR": "This paper presents a computational model for efficient human postural control adaptation based on hierarchical acquisition functions with well-known features. ", "pdf": "/pdf/3a9f19aa365f2cdf846ca5e814bde62768052edc.pdf", "paperhash": "rottmann|learning_human_postural_control_with_hierarchical_acquisition_functions", "original_pdf": "/attachment/3a9f19aa365f2cdf846ca5e814bde62768052edc.pdf", "_bibtex": "@misc{\nrottmann2020learning,\ntitle={Learning Human Postural Control with Hierarchical Acquisition Functions},\nauthor={Nils Rottmann and Tjasa Kunavar and Jan Babic and Jan Peters and Elmar Rueckert},\nyear={2020},\nurl={https://openreview.net/forum?id=S1eYchEtwH}\n}"}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "S1eYchEtwH", "replyto": "S1eYchEtwH", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper122/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper122/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1575370842993, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper122/Reviewers"], "noninvitees": [], "tcdate": 1570237756745, "tmdate": 1575370843007, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper122/-/Official_Review"}}}], "count": 7}