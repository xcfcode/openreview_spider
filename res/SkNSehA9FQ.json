{"notes": [{"id": "SkNSehA9FQ", "original": "S1eIqMn9t7", "number": 1075, "cdate": 1538087917466, "ddate": null, "tcdate": 1538087917466, "tmdate": 1545355406241, "tddate": null, "forum": "SkNSehA9FQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Open Vocabulary Learning on Source Code with a Graph-Structured Cache", "abstract": "Machine learning models that take computer program source code as input typically use Natural Language Processing (NLP) techniques. However, a major challenge is that code is written using an open, rapidly changing vocabulary due to, e.g., the coinage of new variable and method names.  Reasoning over such a vocabulary is not something for which most NLP methods are designed.  We introduce a Graph-Structured Cache to address this problem; this cache contains a node for each new word the model encounters with edges connecting each word to its occurrences in the code.  We find that combining this graph-structured cache strategy with recent Graph-Neural-Network-based models for supervised learning on code improves the models' performance on a code completion task and a variable naming task --- with over 100\\% relative improvement on the latter --- at the cost of a moderate increase in computation time.", "keywords": ["deep learning", "graph neural network", "open vocabulary", "natural language processing", "source code", "abstract syntax tree", "code completion", "variable naming"], "authorids": ["mcvitkov@caltech.edu", "sbadal@amazon.com", "anima@caltech.edu"], "authors": ["Milan Cvitkovic", "Badal Singh", "Anima Anandkumar"], "TL;DR": "We show that caching out-of-vocabulary words in a graph, with edges connecting them to their usages, and processing it with a graph neural network improves performance on supervised learning tasks on computer source code.", "pdf": "/pdf/4623d2c5c474fb8c96fa6c61208550217535d02f.pdf", "paperhash": "cvitkovic|open_vocabulary_learning_on_source_code_with_a_graphstructured_cache", "_bibtex": "@misc{\ncvitkovic2019open,\ntitle={Open Vocabulary Learning on Source Code with a Graph-Structured Cache},\nauthor={Milan Cvitkovic and Badal Singh and Anima Anandkumar},\nyear={2019},\nurl={https://openreview.net/forum?id=SkNSehA9FQ},\n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"replyCount": 17, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Blind_Submission", "rdate": null, "ddate": null, "expdate": null, "duedate": 1538085600000, "tmdate": 1538142958393, "tddate": null, "super": null, "final": null, "reply": {"signatures": {"values": ["ICLR.cc/2019/Conference"]}, "forum": null, "readers": {"values": ["everyone"]}, "replyto": null, "content": {"authorids": {"values-regex": ".*"}, "authors": {"values": ["Anonymous"]}}, "writers": {"values": ["ICLR.cc/2019/Conference"]}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["~"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": null, "taskCompletionCount": null, "transform": null, "cdate": 1538142958393}}, "tauthor": "OpenReview.net"}, {"id": "ByltV_RJeV", "original": null, "number": 1, "cdate": 1544706097500, "ddate": null, "tcdate": 1544706097500, "tmdate": 1545354507392, "tddate": null, "forum": "SkNSehA9FQ", "replyto": "SkNSehA9FQ", "invitation": "ICLR.cc/2019/Conference/-/Paper1075/Meta_Review", "content": {"metareview": "This paper introduces fairly complex methods for dealing with OOV words in graphs representing source code, and aims to show that these improve over existing methods. The chief and valid concern raised by the reviewers was that the experiments had been changed so as to not allow proper comparison to prior work, or where comparison can be made. It is essential that a new method such as this be properly evaluated against existing benchmarks, under the same experimental conditions as presented in related literature. It seems that while the method is interesting, the empirical section of this paper needs reworking in order to be suitable for publication.", "confidence": "4: The area chair is confident but not absolutely certain", "recommendation": "Reject", "title": "Results do not justify method complexity"}, "signatures": ["ICLR.cc/2019/Conference/Paper1075/Area_Chair1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference/Paper1075/Area_Chair1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Open Vocabulary Learning on Source Code with a Graph-Structured Cache", "abstract": "Machine learning models that take computer program source code as input typically use Natural Language Processing (NLP) techniques. However, a major challenge is that code is written using an open, rapidly changing vocabulary due to, e.g., the coinage of new variable and method names.  Reasoning over such a vocabulary is not something for which most NLP methods are designed.  We introduce a Graph-Structured Cache to address this problem; this cache contains a node for each new word the model encounters with edges connecting each word to its occurrences in the code.  We find that combining this graph-structured cache strategy with recent Graph-Neural-Network-based models for supervised learning on code improves the models' performance on a code completion task and a variable naming task --- with over 100\\% relative improvement on the latter --- at the cost of a moderate increase in computation time.", "keywords": ["deep learning", "graph neural network", "open vocabulary", "natural language processing", "source code", "abstract syntax tree", "code completion", "variable naming"], "authorids": ["mcvitkov@caltech.edu", "sbadal@amazon.com", "anima@caltech.edu"], "authors": ["Milan Cvitkovic", "Badal Singh", "Anima Anandkumar"], "TL;DR": "We show that caching out-of-vocabulary words in a graph, with edges connecting them to their usages, and processing it with a graph neural network improves performance on supervised learning tasks on computer source code.", "pdf": "/pdf/4623d2c5c474fb8c96fa6c61208550217535d02f.pdf", "paperhash": "cvitkovic|open_vocabulary_learning_on_source_code_with_a_graphstructured_cache", "_bibtex": "@misc{\ncvitkovic2019open,\ntitle={Open Vocabulary Learning on Source Code with a Graph-Structured Cache},\nauthor={Milan Cvitkovic and Badal Singh and Anima Anandkumar},\nyear={2019},\nurl={https://openreview.net/forum?id=SkNSehA9FQ},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper1075/Meta_Review", "rdate": null, "ddate": null, "expdate": null, "duedate": 1541548800000, "tmdate": 1545352974597, "tddate": null, "super": null, "final": null, "reply": {"forum": "SkNSehA9FQ", "replyto": "SkNSehA9FQ", "readers": {"description": "Select all user groups that should be able to read this comment. Selecting 'All Users' will allow paper authors, reviewers, area chairs, and program chairs to view this comment.", "values": ["everyone"]}, "signatures": {"description": "How your identity will be displayed with the above content.", "values-regex": "ICLR.cc/2019/Conference/Paper1075/Area_Chair[0-9]+"}, "writers": {"description": "Users that may modify this record.", "values-regex": "ICLR.cc/2019/Conference/Paper1075/Area_Chair[0-9]+"}, "content": {"title": {"order": 1, "value-regex": ".{1,500}", "description": "Brief summary of your review.", "required": true}, "metareview": {"order": 2, "value-regex": "[\\S\\s]{1,5000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "required": true}, "recommendation": {"order": 3, "value-dropdown": ["Accept (Oral)", "Accept (Poster)", "Reject"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The area chair is absolutely certain", "4: The area chair is confident but not absolutely certain", "3: The area chair is somewhat confident", "2: The area chair is not sure", "1: The area chair's evaluation is an educated guess"], "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper1075/Area_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": false, "taskCompletionCount": null, "transform": null, "cdate": 1545352974597}}}, {"id": "B1l4NLJk1E", "original": null, "number": 17, "cdate": 1543595564386, "ddate": null, "tcdate": 1543595564386, "tmdate": 1543595564386, "tddate": null, "forum": "SkNSehA9FQ", "replyto": "SkNSehA9FQ", "invitation": "ICLR.cc/2019/Conference/-/Paper1075/Official_Comment", "content": {"title": "A good example", "comment": "Thank you to the reviewers of this paper for engaging in discussion not just with the authors, but with one another, and providing substantial and detailed reviews. You are an excellent example for the community, and demonstrate the high standard according to which papers should be evaluated in ML conferences. Your efforts are deeply appreciated.\n\nAC"}, "signatures": ["ICLR.cc/2019/Conference/Paper1075/Area_Chair1"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper1075/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper1075/Area_Chair1", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Open Vocabulary Learning on Source Code with a Graph-Structured Cache", "abstract": "Machine learning models that take computer program source code as input typically use Natural Language Processing (NLP) techniques. However, a major challenge is that code is written using an open, rapidly changing vocabulary due to, e.g., the coinage of new variable and method names.  Reasoning over such a vocabulary is not something for which most NLP methods are designed.  We introduce a Graph-Structured Cache to address this problem; this cache contains a node for each new word the model encounters with edges connecting each word to its occurrences in the code.  We find that combining this graph-structured cache strategy with recent Graph-Neural-Network-based models for supervised learning on code improves the models' performance on a code completion task and a variable naming task --- with over 100\\% relative improvement on the latter --- at the cost of a moderate increase in computation time.", "keywords": ["deep learning", "graph neural network", "open vocabulary", "natural language processing", "source code", "abstract syntax tree", "code completion", "variable naming"], "authorids": ["mcvitkov@caltech.edu", "sbadal@amazon.com", "anima@caltech.edu"], "authors": ["Milan Cvitkovic", "Badal Singh", "Anima Anandkumar"], "TL;DR": "We show that caching out-of-vocabulary words in a graph, with edges connecting them to their usages, and processing it with a graph neural network improves performance on supervised learning tasks on computer source code.", "pdf": "/pdf/4623d2c5c474fb8c96fa6c61208550217535d02f.pdf", "paperhash": "cvitkovic|open_vocabulary_learning_on_source_code_with_a_graphstructured_cache", "_bibtex": "@misc{\ncvitkovic2019open,\ntitle={Open Vocabulary Learning on Source Code with a Graph-Structured Cache},\nauthor={Milan Cvitkovic and Badal Singh and Anima Anandkumar},\nyear={2019},\nurl={https://openreview.net/forum?id=SkNSehA9FQ},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper1075/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621621303, "tddate": null, "super": null, "final": null, "reply": {"forum": "SkNSehA9FQ", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper1075/Authors", "ICLR.cc/2019/Conference/Paper1075/Reviewers", "ICLR.cc/2019/Conference/Paper1075/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper1075/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper1075/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper1075/Authors|ICLR.cc/2019/Conference/Paper1075/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper1075/Reviewers", "ICLR.cc/2019/Conference/Paper1075/Authors", "ICLR.cc/2019/Conference/Paper1075/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621621303}}}, {"id": "rklbFlAO2X", "original": null, "number": 3, "cdate": 1541099641305, "ddate": null, "tcdate": 1541099641305, "tmdate": 1543267190704, "tddate": null, "forum": "SkNSehA9FQ", "replyto": "SkNSehA9FQ", "invitation": "ICLR.cc/2019/Conference/-/Paper1075/Official_Review", "content": {"title": "Overly complicated techniques for previously well-addressed tasks in literature", "review": "(updated with some summaries from discussion over the initial review)\n\nThe paper discusses the topics of predicting out-of-vocabulary tokens in programs abstract syntax trees. This could have application in code completion and more concretely two tasks are evaluated:\n - predicting a missing reference to a variable (called FillInTheBlank)\n - predicting a name of a variable (NameMe)\n\nUnfortunately, the paper proposes overly complex and strange formulations of these tasks, heavy implementation with unnecessary (non-motivated) neural architectures and as a result, does not demonstrate state-of-the-art performance or precision on comparable tasks. Figure 1 shows the complexity of the approach, with multiple steps of building a graph, introducing the vocabulary cache to then produce a vector at every node of the input tree of the program (instead of creating architecture for a given task), yet simple analysis over which variables can be chosen is missing.\n\nThe FillInTheBlank task is badly defined already on the running example. The goal is to select a variable to fill in a blank and already in the example on Figure 2, one of the candidate variables is out of scope at the location to fill. The motivation for the proposed formulation with building a graph and then computing attention over nodes in that graph is unclear and experiments do not help it. For example, [1] (also cited in the paper) solves the same problem more cleanly by considering only the variables in the scope*. There is no good experimental comparison to that work, but it is unlikely it will perform worse. Also [1] does not suffer from vocabulary problems for that task.\n\nSummary discussion below: the experiments here are incomparable on many levels with prior works: different architecture details, different even smaller dataset than from [1]. There is a third-party claim that on a full system, the general idea improves performance, but I take it with a grain of salt as no clean experiment was yet done. The reviewer notes that the authors disagree the baselines are not meaningful.\n\nThe NameMe tasks also shows the weakness of the proposed architectures. This work proposes to compute vectors at every node where a variable occurs and then to average them and decode the variable name to predict. In comparison, several prior works introduce one node per variable (not per occurrence), essentially removing the long distance relationships between occurrences of the same variable variables and removing the need to average vectors and enforcing the same name representation at every occurrence of the variable [name]. The setup here is incomparable to specialized naming prior works, one feature (a node per variable) is replaced with another (a node per subtoken), but for baselines authors choose to only to be similar to [1]. Also, while not on the same dataset, [2,3] consistently get higher accuracy on a related and more complicated task of predicting multiple names at the same time over multiple programming languages and with much simpler linear models. This is not surprising, because they propose simpler architectures better suited for the NameMe task.\n\n[1] Miltiadis Allamanis, Marc Brockschmidt, and Mahmoud Khademi. Learning to represent programs\nwith graphs. ICLR 2017\n[2] Veselin Raychev, Martin Vechev, and Andreas Krause. Predicting program properties from Big\nCode\n[3] Uri Alon, Meital Zilberstein, Omer Levy, Eran Yahav. A General Path-Based Representation for Predicting Program\n\n* corrected text\n", "rating": "4: Ok but not good enough - rejection", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["ICLR.cc/2019/Conference/Paper1075/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": true, "forumContent": {"title": "Open Vocabulary Learning on Source Code with a Graph-Structured Cache", "abstract": "Machine learning models that take computer program source code as input typically use Natural Language Processing (NLP) techniques. However, a major challenge is that code is written using an open, rapidly changing vocabulary due to, e.g., the coinage of new variable and method names.  Reasoning over such a vocabulary is not something for which most NLP methods are designed.  We introduce a Graph-Structured Cache to address this problem; this cache contains a node for each new word the model encounters with edges connecting each word to its occurrences in the code.  We find that combining this graph-structured cache strategy with recent Graph-Neural-Network-based models for supervised learning on code improves the models' performance on a code completion task and a variable naming task --- with over 100\\% relative improvement on the latter --- at the cost of a moderate increase in computation time.", "keywords": ["deep learning", "graph neural network", "open vocabulary", "natural language processing", "source code", "abstract syntax tree", "code completion", "variable naming"], "authorids": ["mcvitkov@caltech.edu", "sbadal@amazon.com", "anima@caltech.edu"], "authors": ["Milan Cvitkovic", "Badal Singh", "Anima Anandkumar"], "TL;DR": "We show that caching out-of-vocabulary words in a graph, with edges connecting them to their usages, and processing it with a graph neural network improves performance on supervised learning tasks on computer source code.", "pdf": "/pdf/4623d2c5c474fb8c96fa6c61208550217535d02f.pdf", "paperhash": "cvitkovic|open_vocabulary_learning_on_source_code_with_a_graphstructured_cache", "_bibtex": "@misc{\ncvitkovic2019open,\ntitle={Open Vocabulary Learning on Source Code with a Graph-Structured Cache},\nauthor={Milan Cvitkovic and Badal Singh and Anima Anandkumar},\nyear={2019},\nurl={https://openreview.net/forum?id=SkNSehA9FQ},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper1075/Official_Review", "cdate": 1542234311753, "expdate": 1552335264000, "duedate": 1541196000000, "reply": {"forum": "SkNSehA9FQ", "replyto": "SkNSehA9FQ", "readers": {"description": "The users who will be allowed to read the reply content.", "values": ["everyone"]}, "nonreaders": {"values": []}, "signatures": {"description": "How your identity will be displayed with the above content.", "values-regex": "ICLR.cc/2019/Conference/Paper1075/AnonReviewer[0-9]+"}, "writers": {"description": "Users that may modify this record.", "values": ["ICLR.cc/2019/Conference"]}, "content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "required": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}}, "multiReply": false, "tcdate": 1552335867319, "tmdate": 1552335867319, "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "invitees": ["ICLR.cc/2019/Conference/Paper1075/Reviewers"], "noninvitees": [], "signatures": ["ICLR.cc/2019/Conference"]}}}, {"id": "HkepXwWspm", "original": null, "number": 14, "cdate": 1542293285488, "ddate": null, "tcdate": 1542293285488, "tmdate": 1542293490150, "tddate": null, "forum": "SkNSehA9FQ", "replyto": "SJgyeZli6Q", "invitation": "ICLR.cc/2019/Conference/-/Paper1075/Official_Comment", "content": {"title": "Response to AnonReviewer3", "comment": "Thanks again for all your attention to our paper, AnonReviewer3.  I'm sorry that our rebuttal came off as aggressive - that certainly wasn't our intention.  We're very grateful for all your feedback!\n\nJust to hopefully resolve the remaining open points:\n\n1) \"...without 10x more data.\"\nWe should have been clearer here: we were referring only to other work on Java.  It's been our experience (and demonstrated in e.g. [2]) that performance between programming languages are pretty incomparable.  [1] doesn't study Java, and we also show that their model performs less well than our method (on our Java dataset and tasks) in our paper.  But instead of \"better performance\" we should have written \"better performance on our same tasks on Java\", which would have avoided our claim sounding incorrect.\n\n2) \"...improve performance over a reasonable baseline...\"\nI suppose we'll have to agree to disagree here.\n\n3) \"The Closed Vocab + AugAST entry in Table 2 is the same model as in [1]\"\nIt is as far as we can tell, but maybe we've missed something?\n\n4) \"...why is the attention not to supernodes...\"\nThis is a great idea for an architecture, and an interesting question!  It's just not one we studied.  But it's not obvious to me that it is so much simpler and better than our method that our contribution is pointless in light of it.\n\n5) \"...no state-of-the-art results or even comparable results...\"\nAgain, I suppose we'll have to agree to disagree.  Our naming task is identical to that of [1] and other prior work, and we feel our Fill-In-The-Blank task is comparable to [1] and other prior work as well (I'll defer to Miltos's comment here).  But if you don't feel our comparisons to the model in [1] and our ablation studies show state-of-the-art results and justify \"why this idea and not a similar one\", then I'm not sure what more we can offer to convince you."}, "signatures": ["ICLR.cc/2019/Conference/Paper1075/Authors"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper1075/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper1075/Authors", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Open Vocabulary Learning on Source Code with a Graph-Structured Cache", "abstract": "Machine learning models that take computer program source code as input typically use Natural Language Processing (NLP) techniques. However, a major challenge is that code is written using an open, rapidly changing vocabulary due to, e.g., the coinage of new variable and method names.  Reasoning over such a vocabulary is not something for which most NLP methods are designed.  We introduce a Graph-Structured Cache to address this problem; this cache contains a node for each new word the model encounters with edges connecting each word to its occurrences in the code.  We find that combining this graph-structured cache strategy with recent Graph-Neural-Network-based models for supervised learning on code improves the models' performance on a code completion task and a variable naming task --- with over 100\\% relative improvement on the latter --- at the cost of a moderate increase in computation time.", "keywords": ["deep learning", "graph neural network", "open vocabulary", "natural language processing", "source code", "abstract syntax tree", "code completion", "variable naming"], "authorids": ["mcvitkov@caltech.edu", "sbadal@amazon.com", "anima@caltech.edu"], "authors": ["Milan Cvitkovic", "Badal Singh", "Anima Anandkumar"], "TL;DR": "We show that caching out-of-vocabulary words in a graph, with edges connecting them to their usages, and processing it with a graph neural network improves performance on supervised learning tasks on computer source code.", "pdf": "/pdf/4623d2c5c474fb8c96fa6c61208550217535d02f.pdf", "paperhash": "cvitkovic|open_vocabulary_learning_on_source_code_with_a_graphstructured_cache", "_bibtex": "@misc{\ncvitkovic2019open,\ntitle={Open Vocabulary Learning on Source Code with a Graph-Structured Cache},\nauthor={Milan Cvitkovic and Badal Singh and Anima Anandkumar},\nyear={2019},\nurl={https://openreview.net/forum?id=SkNSehA9FQ},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper1075/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621621303, "tddate": null, "super": null, "final": null, "reply": {"forum": "SkNSehA9FQ", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper1075/Authors", "ICLR.cc/2019/Conference/Paper1075/Reviewers", "ICLR.cc/2019/Conference/Paper1075/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper1075/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper1075/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper1075/Authors|ICLR.cc/2019/Conference/Paper1075/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper1075/Reviewers", "ICLR.cc/2019/Conference/Paper1075/Authors", "ICLR.cc/2019/Conference/Paper1075/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621621303}}}, {"id": "BJlH3PWsaQ", "original": null, "number": 15, "cdate": 1542293421179, "ddate": null, "tcdate": 1542293421179, "tmdate": 1542293421179, "tddate": null, "forum": "SkNSehA9FQ", "replyto": "HyxkBEZo6m", "invitation": "ICLR.cc/2019/Conference/-/Paper1075/Official_Comment", "content": {"title": "claims", "comment": "of you agree with (b), then no baseline is [1]. The difference is not merely in the readout.\n\nI take the results of Miltos as a positive sign, but I cannot realistically give a good recommendation to the authors to implement what he has done. Specifically for (a), this is central for all of the prior works that do such models.\n\nWhat I can recommend to the authors to improve the paper is to change the architecture to be not so unusual in comparison to prior works that deal with program variables (e.g. to include scope analysis) and to implement more fair comparison."}, "signatures": ["ICLR.cc/2019/Conference/Paper1075/AnonReviewer3"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper1075/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper1075/AnonReviewer3", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Open Vocabulary Learning on Source Code with a Graph-Structured Cache", "abstract": "Machine learning models that take computer program source code as input typically use Natural Language Processing (NLP) techniques. However, a major challenge is that code is written using an open, rapidly changing vocabulary due to, e.g., the coinage of new variable and method names.  Reasoning over such a vocabulary is not something for which most NLP methods are designed.  We introduce a Graph-Structured Cache to address this problem; this cache contains a node for each new word the model encounters with edges connecting each word to its occurrences in the code.  We find that combining this graph-structured cache strategy with recent Graph-Neural-Network-based models for supervised learning on code improves the models' performance on a code completion task and a variable naming task --- with over 100\\% relative improvement on the latter --- at the cost of a moderate increase in computation time.", "keywords": ["deep learning", "graph neural network", "open vocabulary", "natural language processing", "source code", "abstract syntax tree", "code completion", "variable naming"], "authorids": ["mcvitkov@caltech.edu", "sbadal@amazon.com", "anima@caltech.edu"], "authors": ["Milan Cvitkovic", "Badal Singh", "Anima Anandkumar"], "TL;DR": "We show that caching out-of-vocabulary words in a graph, with edges connecting them to their usages, and processing it with a graph neural network improves performance on supervised learning tasks on computer source code.", "pdf": "/pdf/4623d2c5c474fb8c96fa6c61208550217535d02f.pdf", "paperhash": "cvitkovic|open_vocabulary_learning_on_source_code_with_a_graphstructured_cache", "_bibtex": "@misc{\ncvitkovic2019open,\ntitle={Open Vocabulary Learning on Source Code with a Graph-Structured Cache},\nauthor={Milan Cvitkovic and Badal Singh and Anima Anandkumar},\nyear={2019},\nurl={https://openreview.net/forum?id=SkNSehA9FQ},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper1075/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621621303, "tddate": null, "super": null, "final": null, "reply": {"forum": "SkNSehA9FQ", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper1075/Authors", "ICLR.cc/2019/Conference/Paper1075/Reviewers", "ICLR.cc/2019/Conference/Paper1075/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper1075/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper1075/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper1075/Authors|ICLR.cc/2019/Conference/Paper1075/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper1075/Reviewers", "ICLR.cc/2019/Conference/Paper1075/Authors", "ICLR.cc/2019/Conference/Paper1075/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621621303}}}, {"id": "ByewoRiy67", "original": null, "number": 1, "cdate": 1541549727150, "ddate": null, "tcdate": 1541549727150, "tmdate": 1542291132394, "tddate": null, "forum": "SkNSehA9FQ", "replyto": "rklbFlAO2X", "invitation": "ICLR.cc/2019/Conference/-/Paper1075/Official_Comment", "content": {"title": "Response to AnonReviewer3", "comment": "\nThanks very much for your time and comments, AnonReviewer3.  \n\nFor readability, let me list my responses and questions with references to your review:\n\n1) \"...strange formulations of these tasks, which are overly complex...\"\nDid you mean the tasks themselves were overly complex, or our formulations of them were overly complex?  If the former, we should point out that we test on nearly identical tasks to [Allamanis et al. 2018].\n\n2) \"...does not demonstrate state-of-the-art performance...\"\nWe are not aware of any work that achieves better performance than ours without using >10x more data.  But even so, while models tailored to each task have certainly performed better, as far as we know we are the only model that uses the same pipeline (in fact, even the same hyperparameters) to achieve comparable to state-of-the-art performance on both these tasks on Java code.  Did you have a reference in mind that does similar?  If so, we want to make sure we cite it!\n\n3) \"Figure 1 shows the complexity of the approach,...\"\nWe were aiming for thoroughness with this figure, hence showing all the steps.  But compared to prior works, we only add one new step - we just depict the entire procedure in our figure.\n\n4) \"...introducing the vocabulary cache to then produce a vector at every node of the input tree of the program, which is unnecessary.\"\nWere you saying the cache was unnecessary, or vectorizing every node was unnecessary?\nIf the former, we feel the experiments refute that, showing that the cache improved performance quite a bit.\nIf the latter, it is certainly *possible* that there exists an architecture for which this is unnecessary, but this is what every Graph-Neural-Network-based approach does.  Doing so is not particularly computationally expensive.\n\n5) \"The FillInTheBlank task is badly defined already on the running example. ...one of the candidate variables is out of scope at the location to fill.\"\nThis was intentional: we wanted our models to learn to consider lexical scope via the AST representation.  Indeed, as you say, we could likely improve performance by restricting the model's attention in a scope-aware way - but our objective was to compare architectures, not to maximize performance on this task.\nThanks for pointing out the confusion: we will make this clearer in the paper.\n\n6) \"Also [1] does not suffer from vocabulary problems for that task.\"\nThe Closed Vocab + AugAST entry in Table 2 is the same model as in [1].  So while it may not have suffered from vocabulary problems in [1]'s C# dataset, it indeed suffered from fairly significant vocabulary problems on our Java dataset.\n\n7) \"The NameMe tasks also shows the weakness of the proposed architectures. This work proposes to compute vectors at every node... In comparison, several prior works introduce one node per variable...\"\nWere you suggesting here that the only weakness of our architecture was that we average several vectors on this task as opposed to using one vector?  Or were you giving one example of a more general critique?  If the latter, could you say more about what the general critique is?\n\n8) \"While not on the same dataset, [2,3] consistently get higher accuracy on a related and more complicated task...\"\nPerhaps I'm misunderstanding, but I don't see how these papers' results are comparable to our results.\n[3] considers a JavaScript dataset, not a Java dataset.  These are very different languages, and the results of [2] suggest that variable naming in Javascript is significantly easier.\n[2] uses, as you say, a different dataset.  They use more than 16x as much data as we do and achieve around 5% better accuracy on this dataset (and only if you don't count method naming, which our model does).  But beyond their use of much more data, their model is designed specifically for the task of variable naming - ours is meant to be a general representation learning strategy for source code.  This is why we test it on two tasks and on entirely unseen repositories.\nDoes this bear upon your concerns, or have I misunderstood your comment?\n\nThanks again!"}, "signatures": ["ICLR.cc/2019/Conference/Paper1075/Authors"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper1075/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper1075/Authors", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Open Vocabulary Learning on Source Code with a Graph-Structured Cache", "abstract": "Machine learning models that take computer program source code as input typically use Natural Language Processing (NLP) techniques. However, a major challenge is that code is written using an open, rapidly changing vocabulary due to, e.g., the coinage of new variable and method names.  Reasoning over such a vocabulary is not something for which most NLP methods are designed.  We introduce a Graph-Structured Cache to address this problem; this cache contains a node for each new word the model encounters with edges connecting each word to its occurrences in the code.  We find that combining this graph-structured cache strategy with recent Graph-Neural-Network-based models for supervised learning on code improves the models' performance on a code completion task and a variable naming task --- with over 100\\% relative improvement on the latter --- at the cost of a moderate increase in computation time.", "keywords": ["deep learning", "graph neural network", "open vocabulary", "natural language processing", "source code", "abstract syntax tree", "code completion", "variable naming"], "authorids": ["mcvitkov@caltech.edu", "sbadal@amazon.com", "anima@caltech.edu"], "authors": ["Milan Cvitkovic", "Badal Singh", "Anima Anandkumar"], "TL;DR": "We show that caching out-of-vocabulary words in a graph, with edges connecting them to their usages, and processing it with a graph neural network improves performance on supervised learning tasks on computer source code.", "pdf": "/pdf/4623d2c5c474fb8c96fa6c61208550217535d02f.pdf", "paperhash": "cvitkovic|open_vocabulary_learning_on_source_code_with_a_graphstructured_cache", "_bibtex": "@misc{\ncvitkovic2019open,\ntitle={Open Vocabulary Learning on Source Code with a Graph-Structured Cache},\nauthor={Milan Cvitkovic and Badal Singh and Anima Anandkumar},\nyear={2019},\nurl={https://openreview.net/forum?id=SkNSehA9FQ},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper1075/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621621303, "tddate": null, "super": null, "final": null, "reply": {"forum": "SkNSehA9FQ", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper1075/Authors", "ICLR.cc/2019/Conference/Paper1075/Reviewers", "ICLR.cc/2019/Conference/Paper1075/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper1075/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper1075/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper1075/Authors|ICLR.cc/2019/Conference/Paper1075/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper1075/Reviewers", "ICLR.cc/2019/Conference/Paper1075/Authors", "ICLR.cc/2019/Conference/Paper1075/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621621303}}}, {"id": "ryxAy3xsTX", "original": null, "number": 12, "cdate": 1542290406371, "ddate": null, "tcdate": 1542290406371, "tmdate": 1542290437895, "tddate": null, "forum": "SkNSehA9FQ", "replyto": "rkxChreiTQ", "invitation": "ICLR.cc/2019/Conference/-/Paper1075/Official_Comment", "content": {"title": "?", "comment": "I apologize for discussing the incorrect claims. I don't see how further discussion about them being in gray or white area leads to any positive outcome.\n\nCorrect me if I am wrong on these:\na) Conceptually, the paper removes supernodes of prior works [1,2,3] (one node per variable) and introduces one node per subtoken. \nb) None of the baselines include the one node per variable.\n\n"}, "signatures": ["ICLR.cc/2019/Conference/Paper1075/AnonReviewer3"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper1075/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper1075/AnonReviewer3", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Open Vocabulary Learning on Source Code with a Graph-Structured Cache", "abstract": "Machine learning models that take computer program source code as input typically use Natural Language Processing (NLP) techniques. However, a major challenge is that code is written using an open, rapidly changing vocabulary due to, e.g., the coinage of new variable and method names.  Reasoning over such a vocabulary is not something for which most NLP methods are designed.  We introduce a Graph-Structured Cache to address this problem; this cache contains a node for each new word the model encounters with edges connecting each word to its occurrences in the code.  We find that combining this graph-structured cache strategy with recent Graph-Neural-Network-based models for supervised learning on code improves the models' performance on a code completion task and a variable naming task --- with over 100\\% relative improvement on the latter --- at the cost of a moderate increase in computation time.", "keywords": ["deep learning", "graph neural network", "open vocabulary", "natural language processing", "source code", "abstract syntax tree", "code completion", "variable naming"], "authorids": ["mcvitkov@caltech.edu", "sbadal@amazon.com", "anima@caltech.edu"], "authors": ["Milan Cvitkovic", "Badal Singh", "Anima Anandkumar"], "TL;DR": "We show that caching out-of-vocabulary words in a graph, with edges connecting them to their usages, and processing it with a graph neural network improves performance on supervised learning tasks on computer source code.", "pdf": "/pdf/4623d2c5c474fb8c96fa6c61208550217535d02f.pdf", "paperhash": "cvitkovic|open_vocabulary_learning_on_source_code_with_a_graphstructured_cache", "_bibtex": "@misc{\ncvitkovic2019open,\ntitle={Open Vocabulary Learning on Source Code with a Graph-Structured Cache},\nauthor={Milan Cvitkovic and Badal Singh and Anima Anandkumar},\nyear={2019},\nurl={https://openreview.net/forum?id=SkNSehA9FQ},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper1075/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621621303, "tddate": null, "super": null, "final": null, "reply": {"forum": "SkNSehA9FQ", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper1075/Authors", "ICLR.cc/2019/Conference/Paper1075/Reviewers", "ICLR.cc/2019/Conference/Paper1075/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper1075/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper1075/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper1075/Authors|ICLR.cc/2019/Conference/Paper1075/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper1075/Reviewers", "ICLR.cc/2019/Conference/Paper1075/Authors", "ICLR.cc/2019/Conference/Paper1075/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621621303}}}, {"id": "SJgyeZli6Q", "original": null, "number": 10, "cdate": 1542287591096, "ddate": null, "tcdate": 1542287591096, "tmdate": 1542287591096, "tddate": null, "forum": "SkNSehA9FQ", "replyto": "rygfOL0qTm", "invitation": "ICLR.cc/2019/Conference/-/Paper1075/Official_Comment", "content": {"title": "Incorrect claims:", "comment": "\"We are not aware of any work that achieves better performance than ours without using >10x more data\". Already shown that related work [1] has similar amount of data and gets better precision.\n\n\"If the former, we feel the experiments refute that, showing that the cache improved performance quite a bit.\". The cache is not shown to improve over a reasonable baseline.\n\n\"The Closed Vocab + AugAST entry in Table 2 is the same model as in [1]\"\n\nremark that prior works don't count method naming, which our model does\n\n---\n\nOverall, I disagree with the premise that to fix the paper, one needs to only fix the presentation. The incorrect claims come from the aggressiveness to rebute the review. The problem with the work is that it does not demonstrate the need for what it introduces and why is it a good idea. Miltos's comment also points at least at two differences with [1] - i) attention and ii) the vocabulary and is not clear how their improvements relate to this work except at high level.\n\nIn terms of optimality of the architecture, the biggest problem comes from the fact that both tasks need to predict facts about a variable. If attention to existing variables is used, why is the attention not to supernodes summarizing all occurrences of a variable? If a variable is to be named, the same question applies - why isn't it one supernode for all occurrences of the predicted variable? Would these natural changes eliminate much of the need for the contribution of the paper?\n\nAt the moment I see the work as presenting an idea, but without depth of what tasks is this good at (no state-of-the-art results or even comparable results to other work) and why this idea and not a similar one."}, "signatures": ["ICLR.cc/2019/Conference/Paper1075/AnonReviewer3"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper1075/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper1075/AnonReviewer3", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Open Vocabulary Learning on Source Code with a Graph-Structured Cache", "abstract": "Machine learning models that take computer program source code as input typically use Natural Language Processing (NLP) techniques. However, a major challenge is that code is written using an open, rapidly changing vocabulary due to, e.g., the coinage of new variable and method names.  Reasoning over such a vocabulary is not something for which most NLP methods are designed.  We introduce a Graph-Structured Cache to address this problem; this cache contains a node for each new word the model encounters with edges connecting each word to its occurrences in the code.  We find that combining this graph-structured cache strategy with recent Graph-Neural-Network-based models for supervised learning on code improves the models' performance on a code completion task and a variable naming task --- with over 100\\% relative improvement on the latter --- at the cost of a moderate increase in computation time.", "keywords": ["deep learning", "graph neural network", "open vocabulary", "natural language processing", "source code", "abstract syntax tree", "code completion", "variable naming"], "authorids": ["mcvitkov@caltech.edu", "sbadal@amazon.com", "anima@caltech.edu"], "authors": ["Milan Cvitkovic", "Badal Singh", "Anima Anandkumar"], "TL;DR": "We show that caching out-of-vocabulary words in a graph, with edges connecting them to their usages, and processing it with a graph neural network improves performance on supervised learning tasks on computer source code.", "pdf": "/pdf/4623d2c5c474fb8c96fa6c61208550217535d02f.pdf", "paperhash": "cvitkovic|open_vocabulary_learning_on_source_code_with_a_graphstructured_cache", "_bibtex": "@misc{\ncvitkovic2019open,\ntitle={Open Vocabulary Learning on Source Code with a Graph-Structured Cache},\nauthor={Milan Cvitkovic and Badal Singh and Anima Anandkumar},\nyear={2019},\nurl={https://openreview.net/forum?id=SkNSehA9FQ},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper1075/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621621303, "tddate": null, "super": null, "final": null, "reply": {"forum": "SkNSehA9FQ", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper1075/Authors", "ICLR.cc/2019/Conference/Paper1075/Reviewers", "ICLR.cc/2019/Conference/Paper1075/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper1075/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper1075/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper1075/Authors|ICLR.cc/2019/Conference/Paper1075/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper1075/Reviewers", "ICLR.cc/2019/Conference/Paper1075/Authors", "ICLR.cc/2019/Conference/Paper1075/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621621303}}}, {"id": "BkxrXrewT7", "original": null, "number": 1, "cdate": 1542026525512, "ddate": null, "tcdate": 1542026525512, "tmdate": 1542026525512, "tddate": null, "forum": "SkNSehA9FQ", "replyto": "S1eEG1gLam", "invitation": "ICLR.cc/2019/Conference/-/Paper1075/Public_Comment", "content": {"comment": "Hi,\nI've followed the discussion here and as one of the authors of [1] I would like to mention two points with respect to the \"FillInTheBlank\" task:\n\n* I don't feel that the formulation used by the authors is unnecessarily complex. In particular, I find the fact that they avoid the painful speculative analysis for each candidate variable, which we needed to do, very appealing.\n\n* Although it's true that VarMisuse doesn't suffer from a vocabulary problem, per se, the idea of connecting all nodes with the same subtokens to a single \"supernode\" is interesting. Based on a workshop presentation by the authors earlier this year, we did implement this trick within our existing VarMisuse code, which gave a +5% absolute performance increase, placing the VarMisuse accuracy to around 90%. In that sense, I find this a valuable idea.\n\n(full disclosure: I am aware of the identity of the authors but I have no conflict of interest with them)\n\n-Miltos", "title": "Thoughts on the FillInTheBlank task"}, "signatures": ["~Miltiadis_Allamanis1"], "readers": ["everyone"], "nonreaders": [], "writers": ["~Miltiadis_Allamanis1", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Open Vocabulary Learning on Source Code with a Graph-Structured Cache", "abstract": "Machine learning models that take computer program source code as input typically use Natural Language Processing (NLP) techniques. However, a major challenge is that code is written using an open, rapidly changing vocabulary due to, e.g., the coinage of new variable and method names.  Reasoning over such a vocabulary is not something for which most NLP methods are designed.  We introduce a Graph-Structured Cache to address this problem; this cache contains a node for each new word the model encounters with edges connecting each word to its occurrences in the code.  We find that combining this graph-structured cache strategy with recent Graph-Neural-Network-based models for supervised learning on code improves the models' performance on a code completion task and a variable naming task --- with over 100\\% relative improvement on the latter --- at the cost of a moderate increase in computation time.", "keywords": ["deep learning", "graph neural network", "open vocabulary", "natural language processing", "source code", "abstract syntax tree", "code completion", "variable naming"], "authorids": ["mcvitkov@caltech.edu", "sbadal@amazon.com", "anima@caltech.edu"], "authors": ["Milan Cvitkovic", "Badal Singh", "Anima Anandkumar"], "TL;DR": "We show that caching out-of-vocabulary words in a graph, with edges connecting them to their usages, and processing it with a graph neural network improves performance on supervised learning tasks on computer source code.", "pdf": "/pdf/4623d2c5c474fb8c96fa6c61208550217535d02f.pdf", "paperhash": "cvitkovic|open_vocabulary_learning_on_source_code_with_a_graphstructured_cache", "_bibtex": "@misc{\ncvitkovic2019open,\ntitle={Open Vocabulary Learning on Source Code with a Graph-Structured Cache},\nauthor={Milan Cvitkovic and Badal Singh and Anima Anandkumar},\nyear={2019},\nurl={https://openreview.net/forum?id=SkNSehA9FQ},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper1075/Public_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1542311684790, "tddate": null, "super": null, "final": null, "reply": {"signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed."}, "nonreaders": {"values": []}, "forum": "SkNSehA9FQ", "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper1075/Authors", "ICLR.cc/2019/Conference/Paper1075/Reviewers", "ICLR.cc/2019/Conference/Paper1075/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "replyto": null, "content": {"comment": {"value-regex": "[\\S\\s]{1,5000}", "required": true, "order": 1, "description": "Your comment or reply (max 5000 characters)."}, "title": {"value-regex": ".{1,500}", "required": true, "order": 0, "description": "Brief summary of your comment."}}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["~"], "noninvitees": ["ICLR.cc/2019/Conference/Paper1075/Authors", "ICLR.cc/2019/Conference/Paper1075/Reviewers", "ICLR.cc/2019/Conference/Paper1075/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1542311684790}}}, {"id": "B1xbctmITX", "original": null, "number": 7, "cdate": 1541974409221, "ddate": null, "tcdate": 1541974409221, "tmdate": 1541974502097, "tddate": null, "forum": "SkNSehA9FQ", "replyto": "S1eEG1gLam", "invitation": "ICLR.cc/2019/Conference/-/Paper1075/Official_Comment", "content": {"title": "Response to AnonReviewer3 ", "comment": "Thanks again for the comments and clarifications, AnonReviewer3.\n\nWe agree with all your descriptions of the prior works you mention.  We had read them all before publishing our paper.  But I'm afraid I don't see what \"incorrect claims\" we made - could you be more specific?\n\nWe also certainly agree with your overarching point that our architecture, optimized as it is for performing multiple tasks, is unlikely to be state-of-the-art for any one of them.  If you don't feel that developing an architecture for learning representations of source code that are useful for multiple tasks is a worthwhile goal, then I doubt there's anything we can say to convince you our paper is meritorious."}, "signatures": ["ICLR.cc/2019/Conference/Paper1075/Authors"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper1075/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper1075/Authors", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Open Vocabulary Learning on Source Code with a Graph-Structured Cache", "abstract": "Machine learning models that take computer program source code as input typically use Natural Language Processing (NLP) techniques. However, a major challenge is that code is written using an open, rapidly changing vocabulary due to, e.g., the coinage of new variable and method names.  Reasoning over such a vocabulary is not something for which most NLP methods are designed.  We introduce a Graph-Structured Cache to address this problem; this cache contains a node for each new word the model encounters with edges connecting each word to its occurrences in the code.  We find that combining this graph-structured cache strategy with recent Graph-Neural-Network-based models for supervised learning on code improves the models' performance on a code completion task and a variable naming task --- with over 100\\% relative improvement on the latter --- at the cost of a moderate increase in computation time.", "keywords": ["deep learning", "graph neural network", "open vocabulary", "natural language processing", "source code", "abstract syntax tree", "code completion", "variable naming"], "authorids": ["mcvitkov@caltech.edu", "sbadal@amazon.com", "anima@caltech.edu"], "authors": ["Milan Cvitkovic", "Badal Singh", "Anima Anandkumar"], "TL;DR": "We show that caching out-of-vocabulary words in a graph, with edges connecting them to their usages, and processing it with a graph neural network improves performance on supervised learning tasks on computer source code.", "pdf": "/pdf/4623d2c5c474fb8c96fa6c61208550217535d02f.pdf", "paperhash": "cvitkovic|open_vocabulary_learning_on_source_code_with_a_graphstructured_cache", "_bibtex": "@misc{\ncvitkovic2019open,\ntitle={Open Vocabulary Learning on Source Code with a Graph-Structured Cache},\nauthor={Milan Cvitkovic and Badal Singh and Anima Anandkumar},\nyear={2019},\nurl={https://openreview.net/forum?id=SkNSehA9FQ},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper1075/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621621303, "tddate": null, "super": null, "final": null, "reply": {"forum": "SkNSehA9FQ", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper1075/Authors", "ICLR.cc/2019/Conference/Paper1075/Reviewers", "ICLR.cc/2019/Conference/Paper1075/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper1075/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper1075/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper1075/Authors|ICLR.cc/2019/Conference/Paper1075/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper1075/Reviewers", "ICLR.cc/2019/Conference/Paper1075/Authors", "ICLR.cc/2019/Conference/Paper1075/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621621303}}}, {"id": "S1eEG1gLam", "original": null, "number": 6, "cdate": 1541959435685, "ddate": null, "tcdate": 1541959435685, "tmdate": 1541959435685, "tddate": null, "forum": "SkNSehA9FQ", "replyto": "ByewoRiy67", "invitation": "ICLR.cc/2019/Conference/-/Paper1075/Official_Comment", "content": {"title": "Incorrect claims in rebuttal about prior works, please read the references.", "comment": "First, there are comparisons for two tasks: FillInTheBlank vs NameMe.\n\nFillInTheBlank is addressed in\n[1] Miltiadis Allamanis, Marc Brockschmidt, and Mahmoud Khademi. Learning to represent programs\nwith graphs. ICLR 2017\n\n1). The formulation is unnecessarily complex. The final task is nearly identical to [1], but the means to solve it introduce problems that do not exist for this task.\n4) See 6. [1] solves VarMisuse without the need for any cache.\n6) VarMisuse from [1] does not suffer from vocabulary problems, because they pick from variables in scope and do softmax from their computed vectors. See also row \"Node Labels: Tokens instead of subtokens\" in their ablation study that there is no loss in accuracy from vocabulary. Vocabulary does not play a role here if the task is defined properly.\nAlso [1] does not have C++ dataset, only C# dataset.\n\nNameMe is task that is previously solved with other methods and architectures.\n[2] Veselin Raychev, Martin Vechev, and Andreas Krause. Predicting program properties from Big\nCode\n[3] Uri Alon, Meital Zilberstein, Omer Levy, Eran Yahav. A General Path-Based Representation for Predicting Program\n[2,3] are solving much more complex problem with higher precision. Have a look also at: https://arxiv.org/pdf/1809.05193.pdf , which uses neural networks.\n\n1) See how the task is formulated in [2,3]. What is proposed in Figure 1 is strictly more complicated and NameMe solves only a subset of the task from [2,3]. Experimentally, there is code from these prior works to compare to if results are meant to become comparable\n2) This is a weakness of the paper, not a strength. Evaluation does not help conveying a message.\n8) Method names are also counted in [2,3]. Again, aiming to make the results incomparable to prior works certainly does not make the submission stronger.\n\nIdeally, the a selling point of this paper may be that one architecture is \"good\" in both of these tasks. However, it is  unlikely to be state-of-the-art for any of them and one architecture for the two tasks needs stronger application motivation."}, "signatures": ["ICLR.cc/2019/Conference/Paper1075/AnonReviewer3"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper1075/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper1075/AnonReviewer3", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Open Vocabulary Learning on Source Code with a Graph-Structured Cache", "abstract": "Machine learning models that take computer program source code as input typically use Natural Language Processing (NLP) techniques. However, a major challenge is that code is written using an open, rapidly changing vocabulary due to, e.g., the coinage of new variable and method names.  Reasoning over such a vocabulary is not something for which most NLP methods are designed.  We introduce a Graph-Structured Cache to address this problem; this cache contains a node for each new word the model encounters with edges connecting each word to its occurrences in the code.  We find that combining this graph-structured cache strategy with recent Graph-Neural-Network-based models for supervised learning on code improves the models' performance on a code completion task and a variable naming task --- with over 100\\% relative improvement on the latter --- at the cost of a moderate increase in computation time.", "keywords": ["deep learning", "graph neural network", "open vocabulary", "natural language processing", "source code", "abstract syntax tree", "code completion", "variable naming"], "authorids": ["mcvitkov@caltech.edu", "sbadal@amazon.com", "anima@caltech.edu"], "authors": ["Milan Cvitkovic", "Badal Singh", "Anima Anandkumar"], "TL;DR": "We show that caching out-of-vocabulary words in a graph, with edges connecting them to their usages, and processing it with a graph neural network improves performance on supervised learning tasks on computer source code.", "pdf": "/pdf/4623d2c5c474fb8c96fa6c61208550217535d02f.pdf", "paperhash": "cvitkovic|open_vocabulary_learning_on_source_code_with_a_graphstructured_cache", "_bibtex": "@misc{\ncvitkovic2019open,\ntitle={Open Vocabulary Learning on Source Code with a Graph-Structured Cache},\nauthor={Milan Cvitkovic and Badal Singh and Anima Anandkumar},\nyear={2019},\nurl={https://openreview.net/forum?id=SkNSehA9FQ},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper1075/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621621303, "tddate": null, "super": null, "final": null, "reply": {"forum": "SkNSehA9FQ", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper1075/Authors", "ICLR.cc/2019/Conference/Paper1075/Reviewers", "ICLR.cc/2019/Conference/Paper1075/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper1075/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper1075/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper1075/Authors|ICLR.cc/2019/Conference/Paper1075/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper1075/Reviewers", "ICLR.cc/2019/Conference/Paper1075/Authors", "ICLR.cc/2019/Conference/Paper1075/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621621303}}}, {"id": "HJehnx0bam", "original": null, "number": 5, "cdate": 1541689523575, "ddate": null, "tcdate": 1541689523575, "tmdate": 1541690949952, "tddate": null, "forum": "SkNSehA9FQ", "replyto": "HJexTpnWaQ", "invitation": "ICLR.cc/2019/Conference/-/Paper1075/Official_Comment", "content": {"title": "Response to AnonReviewer2", "comment": "Thank you so much for the detailed comments!  These are really helpful.\n\nRegarding 1: You're exactly right about the model structure, and I'm completely with you that \"graph\" is a term so flexible as to be often unhelpful.  We just had to pick a name for the model feature we were introducing, and we hoped \"graph-structured cache\" was clear and correct: it's a collection of words represented as nodes in a graph.\nBut I entirely see how the name \"graph-structured cache\" might cause a reader expect to see a complicated adjacency structure within the cache nodes.  There is \"depth\" due to the message passing in the GNN, but I'll ask my coauthors and other readers if we can find a clearer name.\n\nRegarding 2: This is entirely our fault for not being clearer.\nIn the Fixed Vocab baseline model, vector(name) = f(vector(word_1), ..., vector(word_n)).  (No CharCNN involved.  <unk> token used if word_k isn't in the vocabulary.)\nIn the CharCNN baseline model, vector(name) = CharCNN(name).  (No splitting name into words.)\nBut in our GSC model there is no single vector(name) exactly: a variable's name is \"embedded\" as CharCNN(name) along with edges connecting the variable to word nodes in graph-structured cache.  E.g. initializing a node containing a variable named \"getGuavaDictionary\" involves producing a vector CharCNN(\"getGuavaDictionary\") and also adding \"WORD_USE\"/\"reverse_WORD_USE\" edges pointing to/from the \"get\", \"guava\" and \"dictionary\" nodes in the GSC, each of which contains CharCNN(word).\nSo the baseline models are indeed standard NLP approaches, but ours (as far as we know) is new.  I'll edit the document to make this entirely clear.\n\nThanks very much again for helping us improve our presentation!"}, "signatures": ["ICLR.cc/2019/Conference/Paper1075/Authors"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper1075/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper1075/Authors", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Open Vocabulary Learning on Source Code with a Graph-Structured Cache", "abstract": "Machine learning models that take computer program source code as input typically use Natural Language Processing (NLP) techniques. However, a major challenge is that code is written using an open, rapidly changing vocabulary due to, e.g., the coinage of new variable and method names.  Reasoning over such a vocabulary is not something for which most NLP methods are designed.  We introduce a Graph-Structured Cache to address this problem; this cache contains a node for each new word the model encounters with edges connecting each word to its occurrences in the code.  We find that combining this graph-structured cache strategy with recent Graph-Neural-Network-based models for supervised learning on code improves the models' performance on a code completion task and a variable naming task --- with over 100\\% relative improvement on the latter --- at the cost of a moderate increase in computation time.", "keywords": ["deep learning", "graph neural network", "open vocabulary", "natural language processing", "source code", "abstract syntax tree", "code completion", "variable naming"], "authorids": ["mcvitkov@caltech.edu", "sbadal@amazon.com", "anima@caltech.edu"], "authors": ["Milan Cvitkovic", "Badal Singh", "Anima Anandkumar"], "TL;DR": "We show that caching out-of-vocabulary words in a graph, with edges connecting them to their usages, and processing it with a graph neural network improves performance on supervised learning tasks on computer source code.", "pdf": "/pdf/4623d2c5c474fb8c96fa6c61208550217535d02f.pdf", "paperhash": "cvitkovic|open_vocabulary_learning_on_source_code_with_a_graphstructured_cache", "_bibtex": "@misc{\ncvitkovic2019open,\ntitle={Open Vocabulary Learning on Source Code with a Graph-Structured Cache},\nauthor={Milan Cvitkovic and Badal Singh and Anima Anandkumar},\nyear={2019},\nurl={https://openreview.net/forum?id=SkNSehA9FQ},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper1075/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621621303, "tddate": null, "super": null, "final": null, "reply": {"forum": "SkNSehA9FQ", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper1075/Authors", "ICLR.cc/2019/Conference/Paper1075/Reviewers", "ICLR.cc/2019/Conference/Paper1075/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper1075/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper1075/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper1075/Authors|ICLR.cc/2019/Conference/Paper1075/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper1075/Reviewers", "ICLR.cc/2019/Conference/Paper1075/Authors", "ICLR.cc/2019/Conference/Paper1075/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621621303}}}, {"id": "HJexTpnWaQ", "original": null, "number": 4, "cdate": 1541684664192, "ddate": null, "tcdate": 1541684664192, "tmdate": 1541684664192, "tddate": null, "forum": "SkNSehA9FQ", "replyto": "rylubM3k6Q", "invitation": "ICLR.cc/2019/Conference/-/Paper1075/Official_Comment", "content": {"title": "response", "comment": "Thanks for the response. I would like to clarify my points centering around your main contribution: \n\n\"3. Further augment the Augmented AST by adding a Graph\u2013Structured Cache. That is, add a\nnode to the Augmented AST for each vocabulary word encountered in the input instance. Then\nconnect each such \u201ccache node\u201d with an edge (of edge type WORD USE) to all variables whose\nnames contain its word.\"\n\nFirstly, I think that the title is misleading because it's too much to claim that your vocabulary model uses \"Graph\u2013Structured Cache\". Of course, most (or every) math objects can be represented by graphs. But here, the graph is too shallow. You have a layer of words and connect it to phrases (or variable/function names, which can be considered as phrases). \n\nSecondly, your model does remind me of subword approaches in NLP. For instance, I believe that you split variable/function names into tokens (such as \"getGuavaDictionary\" into \"get\", \"Guava\", \"Dictionary\"). Then\nvector(name) = f(vector(tok_1),...,vector(tok_n)). If tok_k isn't in your voca, you use a charNN to combute vector(tok_k). If I understand it correctly, this method is widely used in NLP. \n\nIf you think I misunderstood your model, I'm willing to change my review and I hope you will write your model in a clearer way."}, "signatures": ["ICLR.cc/2019/Conference/Paper1075/AnonReviewer2"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper1075/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper1075/AnonReviewer2", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Open Vocabulary Learning on Source Code with a Graph-Structured Cache", "abstract": "Machine learning models that take computer program source code as input typically use Natural Language Processing (NLP) techniques. However, a major challenge is that code is written using an open, rapidly changing vocabulary due to, e.g., the coinage of new variable and method names.  Reasoning over such a vocabulary is not something for which most NLP methods are designed.  We introduce a Graph-Structured Cache to address this problem; this cache contains a node for each new word the model encounters with edges connecting each word to its occurrences in the code.  We find that combining this graph-structured cache strategy with recent Graph-Neural-Network-based models for supervised learning on code improves the models' performance on a code completion task and a variable naming task --- with over 100\\% relative improvement on the latter --- at the cost of a moderate increase in computation time.", "keywords": ["deep learning", "graph neural network", "open vocabulary", "natural language processing", "source code", "abstract syntax tree", "code completion", "variable naming"], "authorids": ["mcvitkov@caltech.edu", "sbadal@amazon.com", "anima@caltech.edu"], "authors": ["Milan Cvitkovic", "Badal Singh", "Anima Anandkumar"], "TL;DR": "We show that caching out-of-vocabulary words in a graph, with edges connecting them to their usages, and processing it with a graph neural network improves performance on supervised learning tasks on computer source code.", "pdf": "/pdf/4623d2c5c474fb8c96fa6c61208550217535d02f.pdf", "paperhash": "cvitkovic|open_vocabulary_learning_on_source_code_with_a_graphstructured_cache", "_bibtex": "@misc{\ncvitkovic2019open,\ntitle={Open Vocabulary Learning on Source Code with a Graph-Structured Cache},\nauthor={Milan Cvitkovic and Badal Singh and Anima Anandkumar},\nyear={2019},\nurl={https://openreview.net/forum?id=SkNSehA9FQ},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper1075/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621621303, "tddate": null, "super": null, "final": null, "reply": {"forum": "SkNSehA9FQ", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper1075/Authors", "ICLR.cc/2019/Conference/Paper1075/Reviewers", "ICLR.cc/2019/Conference/Paper1075/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper1075/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper1075/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper1075/Authors|ICLR.cc/2019/Conference/Paper1075/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper1075/Reviewers", "ICLR.cc/2019/Conference/Paper1075/Authors", "ICLR.cc/2019/Conference/Paper1075/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621621303}}}, {"id": "rylubM3k6Q", "original": null, "number": 2, "cdate": 1541550591883, "ddate": null, "tcdate": 1541550591883, "tmdate": 1541598647022, "tddate": null, "forum": "SkNSehA9FQ", "replyto": "HkgDMtLd37", "invitation": "ICLR.cc/2019/Conference/-/Paper1075/Official_Comment", "content": {"title": "Response to AnonReviewer2", "comment": "\nThanks very much for your time and comments, AnonReviewer2.  \n\nTo respond to your title, first con, and question, I'm worried that a big misunderstanding has been caused somehow.  We don't use a \"subword vocabulary\" per se, and our embedding strategy is very ancillary to the main contribution of our work.  We use a CharCNN embedding in some of the models - is what you are referring to?  If so, it's very minor part to our main contribution, which is the usage of the graph structured cache.  (Hence our title.)  Were you referring to this cache as the shallow subword embedding?  Or have I misunderstood your comment?\n\nTo respond to your second con, we are certainly continuing in the same direction as the excellent work in [Allamanis et al. 2018].  But our contributions extend quite a bit farther than that paper: we introduce an entirely new way of handling an open vocabulary, show that it improves performance on two well-studied tasks, present experiments with more Graph Neural Network architectures, and do all this on Java - a much more widely used language.  Would you consider this a fair characterization, or are we overstating the case?\n\nThanks again!"}, "signatures": ["ICLR.cc/2019/Conference/Paper1075/Authors"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper1075/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper1075/Authors", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Open Vocabulary Learning on Source Code with a Graph-Structured Cache", "abstract": "Machine learning models that take computer program source code as input typically use Natural Language Processing (NLP) techniques. However, a major challenge is that code is written using an open, rapidly changing vocabulary due to, e.g., the coinage of new variable and method names.  Reasoning over such a vocabulary is not something for which most NLP methods are designed.  We introduce a Graph-Structured Cache to address this problem; this cache contains a node for each new word the model encounters with edges connecting each word to its occurrences in the code.  We find that combining this graph-structured cache strategy with recent Graph-Neural-Network-based models for supervised learning on code improves the models' performance on a code completion task and a variable naming task --- with over 100\\% relative improvement on the latter --- at the cost of a moderate increase in computation time.", "keywords": ["deep learning", "graph neural network", "open vocabulary", "natural language processing", "source code", "abstract syntax tree", "code completion", "variable naming"], "authorids": ["mcvitkov@caltech.edu", "sbadal@amazon.com", "anima@caltech.edu"], "authors": ["Milan Cvitkovic", "Badal Singh", "Anima Anandkumar"], "TL;DR": "We show that caching out-of-vocabulary words in a graph, with edges connecting them to their usages, and processing it with a graph neural network improves performance on supervised learning tasks on computer source code.", "pdf": "/pdf/4623d2c5c474fb8c96fa6c61208550217535d02f.pdf", "paperhash": "cvitkovic|open_vocabulary_learning_on_source_code_with_a_graphstructured_cache", "_bibtex": "@misc{\ncvitkovic2019open,\ntitle={Open Vocabulary Learning on Source Code with a Graph-Structured Cache},\nauthor={Milan Cvitkovic and Badal Singh and Anima Anandkumar},\nyear={2019},\nurl={https://openreview.net/forum?id=SkNSehA9FQ},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper1075/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621621303, "tddate": null, "super": null, "final": null, "reply": {"forum": "SkNSehA9FQ", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper1075/Authors", "ICLR.cc/2019/Conference/Paper1075/Reviewers", "ICLR.cc/2019/Conference/Paper1075/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper1075/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper1075/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper1075/Authors|ICLR.cc/2019/Conference/Paper1075/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper1075/Reviewers", "ICLR.cc/2019/Conference/Paper1075/Authors", "ICLR.cc/2019/Conference/Paper1075/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621621303}}}, {"id": "S1xu_TT1T7", "original": null, "number": 3, "cdate": 1541557615977, "ddate": null, "tcdate": 1541557615977, "tmdate": 1541557615977, "tddate": null, "forum": "SkNSehA9FQ", "replyto": "rJxfsg4Dh7", "invitation": "ICLR.cc/2019/Conference/-/Paper1075/Official_Comment", "content": {"title": "Response to AnonReviewer1", "comment": "\nThanks very much for your time and comments, AnonReviewer1.\n\nRegarding your overall comment, we agree, though our hope is that the graph-structured cache strategy we propose will be of general use in open set/open vocabulary learning problems.  We simply focused on a particularly acute open vocabulary learning problem in this paper to explore its utility.  We will add this motivation more clearly to the paper to make it more relevant to a wider audience.\n\nRegarding the minor comments, thank you for your careful reading!  We will upload a version ASAP that addresses all of these, but to answer your questions:\n- Sect 4.: We actually do introduce them for field names and method names depending on the task - we will make that clearer.\n- Sec5 5.: We checked for duplicate code with CPD (https://pmd.github.io/latest/pmd_userdocs_cpd.html) and didn't find a worrying amount.  Out of the 500k nonempty, noncomment lines of code in our dataset, about 92k lines were duplicates of some other line in the dataset, with the majority of contiguous, duplicated lines of code containing fewer than 150 tokens and only being duplicated once.  We didn't find any duplicated files in our code.\n- Table 1: The Pointer Sentinel model can incorporate words from the vocabulary cache in its output by pointing to them with attention.  The Closed Vocab model can only produce names using words from its closed vocabulary.  So as you say, the only difference between the Pointer Sentinel model and our full model is the absence of the edges indicating word usage, but both are fairly different from the Closed Vocab model.\n- Table 1: Yes, Pointer Sentinel/GSC use a CharCNN to embed node labels for all non-internal nodes in the AST, including variables like \"foo\".\n- Page 6: About 53% are larger.\n- Page 7: We do.  If the model picks a non-variable, it is counted as a mistake.  But this (essentially) never happens: non-variable nodes are identified by their node type, so the model learns within a few batches not to attend to any non-variable nodes."}, "signatures": ["ICLR.cc/2019/Conference/Paper1075/Authors"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper1075/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper1075/Authors", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Open Vocabulary Learning on Source Code with a Graph-Structured Cache", "abstract": "Machine learning models that take computer program source code as input typically use Natural Language Processing (NLP) techniques. However, a major challenge is that code is written using an open, rapidly changing vocabulary due to, e.g., the coinage of new variable and method names.  Reasoning over such a vocabulary is not something for which most NLP methods are designed.  We introduce a Graph-Structured Cache to address this problem; this cache contains a node for each new word the model encounters with edges connecting each word to its occurrences in the code.  We find that combining this graph-structured cache strategy with recent Graph-Neural-Network-based models for supervised learning on code improves the models' performance on a code completion task and a variable naming task --- with over 100\\% relative improvement on the latter --- at the cost of a moderate increase in computation time.", "keywords": ["deep learning", "graph neural network", "open vocabulary", "natural language processing", "source code", "abstract syntax tree", "code completion", "variable naming"], "authorids": ["mcvitkov@caltech.edu", "sbadal@amazon.com", "anima@caltech.edu"], "authors": ["Milan Cvitkovic", "Badal Singh", "Anima Anandkumar"], "TL;DR": "We show that caching out-of-vocabulary words in a graph, with edges connecting them to their usages, and processing it with a graph neural network improves performance on supervised learning tasks on computer source code.", "pdf": "/pdf/4623d2c5c474fb8c96fa6c61208550217535d02f.pdf", "paperhash": "cvitkovic|open_vocabulary_learning_on_source_code_with_a_graphstructured_cache", "_bibtex": "@misc{\ncvitkovic2019open,\ntitle={Open Vocabulary Learning on Source Code with a Graph-Structured Cache},\nauthor={Milan Cvitkovic and Badal Singh and Anima Anandkumar},\nyear={2019},\nurl={https://openreview.net/forum?id=SkNSehA9FQ},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper1075/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621621303, "tddate": null, "super": null, "final": null, "reply": {"forum": "SkNSehA9FQ", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper1075/Authors", "ICLR.cc/2019/Conference/Paper1075/Reviewers", "ICLR.cc/2019/Conference/Paper1075/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper1075/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper1075/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper1075/Authors|ICLR.cc/2019/Conference/Paper1075/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper1075/Reviewers", "ICLR.cc/2019/Conference/Paper1075/Authors", "ICLR.cc/2019/Conference/Paper1075/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621621303}}}, {"id": "HkgDMtLd37", "original": null, "number": 2, "cdate": 1541069071307, "ddate": null, "tcdate": 1541069071307, "tmdate": 1541533444172, "tddate": null, "forum": "SkNSehA9FQ", "replyto": "SkNSehA9FQ", "invitation": "ICLR.cc/2019/Conference/-/Paper1075/Official_Review", "content": {"title": "A subword embedding model for codes. What's new?", "review": "The paper introduces a new way to use a subword embedding model 2 tasks related to codes: fill-in-blank and variable naming. \n\n* pros: \n- the paper is very well written. \n- the model is easily to reimplement. \n- the experiments are solid and the results are convincing. \n\n* cons: \n- the title is very misleading. In fact, what the paper does is to use a very shallow subword embedding method for names. This approach is widely used in NLP, especially in machine translation. \n- the work is progressing, meaning that most of it is based on another work (i.e. Allamanis et al 2018). \n\n* questions: \n- how to build the (subword) vocabulary? \n", "rating": "4: Ok but not good enough - rejection", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["ICLR.cc/2019/Conference/Paper1075/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Open Vocabulary Learning on Source Code with a Graph-Structured Cache", "abstract": "Machine learning models that take computer program source code as input typically use Natural Language Processing (NLP) techniques. However, a major challenge is that code is written using an open, rapidly changing vocabulary due to, e.g., the coinage of new variable and method names.  Reasoning over such a vocabulary is not something for which most NLP methods are designed.  We introduce a Graph-Structured Cache to address this problem; this cache contains a node for each new word the model encounters with edges connecting each word to its occurrences in the code.  We find that combining this graph-structured cache strategy with recent Graph-Neural-Network-based models for supervised learning on code improves the models' performance on a code completion task and a variable naming task --- with over 100\\% relative improvement on the latter --- at the cost of a moderate increase in computation time.", "keywords": ["deep learning", "graph neural network", "open vocabulary", "natural language processing", "source code", "abstract syntax tree", "code completion", "variable naming"], "authorids": ["mcvitkov@caltech.edu", "sbadal@amazon.com", "anima@caltech.edu"], "authors": ["Milan Cvitkovic", "Badal Singh", "Anima Anandkumar"], "TL;DR": "We show that caching out-of-vocabulary words in a graph, with edges connecting them to their usages, and processing it with a graph neural network improves performance on supervised learning tasks on computer source code.", "pdf": "/pdf/4623d2c5c474fb8c96fa6c61208550217535d02f.pdf", "paperhash": "cvitkovic|open_vocabulary_learning_on_source_code_with_a_graphstructured_cache", "_bibtex": "@misc{\ncvitkovic2019open,\ntitle={Open Vocabulary Learning on Source Code with a Graph-Structured Cache},\nauthor={Milan Cvitkovic and Badal Singh and Anima Anandkumar},\nyear={2019},\nurl={https://openreview.net/forum?id=SkNSehA9FQ},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper1075/Official_Review", "cdate": 1542234311753, "expdate": 1552335264000, "duedate": 1541196000000, "reply": {"forum": "SkNSehA9FQ", "replyto": "SkNSehA9FQ", "readers": {"description": "The users who will be allowed to read the reply content.", "values": ["everyone"]}, "nonreaders": {"values": []}, "signatures": {"description": "How your identity will be displayed with the above content.", "values-regex": "ICLR.cc/2019/Conference/Paper1075/AnonReviewer[0-9]+"}, "writers": {"description": "Users that may modify this record.", "values": ["ICLR.cc/2019/Conference"]}, "content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "required": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}}, "multiReply": false, "tcdate": 1552335867319, "tmdate": 1552335867319, "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "invitees": ["ICLR.cc/2019/Conference/Paper1075/Reviewers"], "noninvitees": [], "signatures": ["ICLR.cc/2019/Conference"]}}}, {"id": "rJxfsg4Dh7", "original": null, "number": 1, "cdate": 1540993178220, "ddate": null, "tcdate": 1540993178220, "tmdate": 1541533443961, "tddate": null, "forum": "SkNSehA9FQ", "replyto": "SkNSehA9FQ", "invitation": "ICLR.cc/2019/Conference/-/Paper1075/Official_Review", "content": {"title": "Improved graph representation for learning from programs", "review": "The submission presents an extension to the Allamanis et al ICLR'18 paper on learning from programs as graphs. The core contribution is the idea of introducing extra nodes and edges into the graph that correspond to (potentially rare) subwords used in the analyzed program code. Experiments show that this extended graph leads to better performance on two tasks, compared to a wide range of baseline methods.\n\nOverall, this is a nice paper with a small, incremental idea and substantial experiments that show its practical value. I only have minor comments / questions on the actual core content. However, the contribution is very incremental and of interest to a specialized subsegment of the ICLR audience, so it may be appropriate to reject the paper and redirect the authors to a more specialized venue.\n\nMinor comments:\n- There's a bunch of places where \\citep/\\citet are mixed up (e.g., second to last paragraph of page 2). It would make sense to go through the paper one more time to clean this up.\n- Sect. 4: I understand the need to introduce context, but it feels that more space should be spent on the actual contribution here (step 3). For example, it remains unclear why this extra nodes / edges are only introduced for subwords appearing in variables - why not also for field names / method names?\n- Sect. 5: It would be helpful if the authors would explicitly handle the code duplication problem (Lopes et al., OOPSLA'17), or discuss how they avoided these problems. Duplicated data files occurring in several folds are a significant risk to the validity of their experimental findings, and very common in code corpora.\n- Table 1: It is unclear to me what the \"Pointer Sentinel\" model can achieve. Without edges connecting the additional words to where they occur, it seems that this should not be performing different than \"Closed Vocab\", apart from noise introduced by additional nodes.\n- Table 1: Do Pointer Sentinel/GSC use a CharCNN to embed node labels of nodes that are not part of the \"cache\", or a closed vocabulary? [i.e., what's the embedding of a variable \"foo\"?] If not, what is the performance of the GSC model with CharCNN-embeddings everywhere? That would be architecturally simpler than the split variant, and so may be of interest.\n- Page 6: When truncating to 500 nodes per graph: How many graphs in your dataset are larger than that?\n- Page 7: Do you really use attention over all nodes, instead of only nodes corresponding to variables? How do you deal with results where the model picks a non-variable (e.g., a corresponding cache node)? Does this happen?\n", "rating": "6: Marginally above acceptance threshold", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}, "signatures": ["ICLR.cc/2019/Conference/Paper1075/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Open Vocabulary Learning on Source Code with a Graph-Structured Cache", "abstract": "Machine learning models that take computer program source code as input typically use Natural Language Processing (NLP) techniques. However, a major challenge is that code is written using an open, rapidly changing vocabulary due to, e.g., the coinage of new variable and method names.  Reasoning over such a vocabulary is not something for which most NLP methods are designed.  We introduce a Graph-Structured Cache to address this problem; this cache contains a node for each new word the model encounters with edges connecting each word to its occurrences in the code.  We find that combining this graph-structured cache strategy with recent Graph-Neural-Network-based models for supervised learning on code improves the models' performance on a code completion task and a variable naming task --- with over 100\\% relative improvement on the latter --- at the cost of a moderate increase in computation time.", "keywords": ["deep learning", "graph neural network", "open vocabulary", "natural language processing", "source code", "abstract syntax tree", "code completion", "variable naming"], "authorids": ["mcvitkov@caltech.edu", "sbadal@amazon.com", "anima@caltech.edu"], "authors": ["Milan Cvitkovic", "Badal Singh", "Anima Anandkumar"], "TL;DR": "We show that caching out-of-vocabulary words in a graph, with edges connecting them to their usages, and processing it with a graph neural network improves performance on supervised learning tasks on computer source code.", "pdf": "/pdf/4623d2c5c474fb8c96fa6c61208550217535d02f.pdf", "paperhash": "cvitkovic|open_vocabulary_learning_on_source_code_with_a_graphstructured_cache", "_bibtex": "@misc{\ncvitkovic2019open,\ntitle={Open Vocabulary Learning on Source Code with a Graph-Structured Cache},\nauthor={Milan Cvitkovic and Badal Singh and Anima Anandkumar},\nyear={2019},\nurl={https://openreview.net/forum?id=SkNSehA9FQ},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper1075/Official_Review", "cdate": 1542234311753, "expdate": 1552335264000, "duedate": 1541196000000, "reply": {"forum": "SkNSehA9FQ", "replyto": "SkNSehA9FQ", "readers": {"description": "The users who will be allowed to read the reply content.", "values": ["everyone"]}, "nonreaders": {"values": []}, "signatures": {"description": "How your identity will be displayed with the above content.", "values-regex": "ICLR.cc/2019/Conference/Paper1075/AnonReviewer[0-9]+"}, "writers": {"description": "Users that may modify this record.", "values": ["ICLR.cc/2019/Conference"]}, "content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "required": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}}, "multiReply": false, "tcdate": 1552335867319, "tmdate": 1552335867319, "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "invitees": ["ICLR.cc/2019/Conference/Paper1075/Reviewers"], "noninvitees": [], "signatures": ["ICLR.cc/2019/Conference"]}}}], "count": 18}