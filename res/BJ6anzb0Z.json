{"notes": [{"tddate": null, "ddate": null, "tmdate": 1518730159851, "tcdate": 1509137609410, "number": 978, "cdate": 1518730159841, "id": "BJ6anzb0Z", "invitation": "ICLR.cc/2018/Conference/-/Blind_Submission", "forum": "BJ6anzb0Z", "original": "ry5FnGZRW", "signatures": ["ICLR.cc/2018/Conference"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Conference"], "content": {"title": "Multimodal Sentiment Analysis To Explore the Structure of Emotions", "abstract": "We propose a novel approach to multimodal sentiment analysis using deep neural\nnetworks combining visual recognition and natural language processing. Our\ngoal is different than the standard sentiment analysis goal of predicting whether\na sentence expresses positive or negative sentiment; instead, we aim to infer the\nlatent emotional state of the user. Thus, we focus on predicting the emotion word\ntags attached by users to their Tumblr posts, treating these as \u201cself-reported emotions.\u201d\nWe demonstrate that our multimodal model combining both text and image\nfeatures outperforms separate models based solely on either images or text. Our\nmodel\u2019s results are interpretable, automatically yielding sensible word lists associated\nwith emotions. We explore the structure of emotions implied by our model\nand compare it to what has been posited in the psychology literature, and validate\nour model on a set of images that have been used in psychology studies. Finally,\nour work also provides a useful tool for the growing academic study of images\u2014\nboth photographs and memes\u2014on social networks.", "pdf": "/pdf/c67ea97ba6ec82c7f5cdc05854baf5de21205158.pdf", "paperhash": "hu|multimodal_sentiment_analysis_to_explore_the_structure_of_emotions", "_bibtex": "@misc{\nhu2018multimodal,\ntitle={Multimodal Sentiment Analysis To Explore the Structure of Emotions},\nauthor={Anthony Hu and Seth Flaxman},\nyear={2018},\nurl={https://openreview.net/forum?id=BJ6anzb0Z},\n}", "keywords": [], "authors": ["Anthony Hu", "Seth Flaxman"], "authorids": ["anthony.hu@stats.ox.ac.uk", "s.flaxman@imperial.ac.uk"]}, "nonreaders": [], "details": {"replyCount": 8, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "tmdate": 1506717071958, "id": "ICLR.cc/2018/Conference/-/Blind_Submission", "writers": ["ICLR.cc/2018/Conference"], "signatures": ["ICLR.cc/2018/Conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2018/Conference"], "reply": {"forum": null, "replyto": null, "writers": {"values": ["ICLR.cc/2018/Conference"]}, "signatures": {"description": "How your identity will be displayed with the above content.", "values": ["ICLR.cc/2018/Conference"]}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"authors": {"required": false, "order": 1, "values-regex": ".*", "description": "Comma separated list of author names, as they appear in the paper."}, "authorids": {"required": false, "order": 2, "values-regex": ".*", "description": "Comma separated list of author email addresses, in the same order as above."}}}, "nonreaders": [], "noninvitees": [], "cdate": 1506717071958}}, "tauthor": "ICLR.cc/2018/Conference"}, {"tddate": null, "ddate": null, "original": null, "tmdate": 1517260082950, "tcdate": 1517249973948, "number": 661, "cdate": 1517249973908, "id": "By02HJ6Sf", "invitation": "ICLR.cc/2018/Conference/-/Acceptance_Decision", "forum": "BJ6anzb0Z", "replyto": "BJ6anzb0Z", "signatures": ["ICLR.cc/2018/Conference/Program_Chairs"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Conference/Program_Chairs"], "content": {"decision": "Reject", "title": "ICLR 2018 Conference Acceptance Decision", "comment": "This work combines words and images from Tumblr to provide more fine-grained sentiment analysis than just positive-negative. The contribution is too slight, as a straightforward combination of existing architectures applied on an emotion classification task with conclusions that aren't well motivated and are not providing any comparison to existing related work on finer emotion classification."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Multimodal Sentiment Analysis To Explore the Structure of Emotions", "abstract": "We propose a novel approach to multimodal sentiment analysis using deep neural\nnetworks combining visual recognition and natural language processing. Our\ngoal is different than the standard sentiment analysis goal of predicting whether\na sentence expresses positive or negative sentiment; instead, we aim to infer the\nlatent emotional state of the user. Thus, we focus on predicting the emotion word\ntags attached by users to their Tumblr posts, treating these as \u201cself-reported emotions.\u201d\nWe demonstrate that our multimodal model combining both text and image\nfeatures outperforms separate models based solely on either images or text. Our\nmodel\u2019s results are interpretable, automatically yielding sensible word lists associated\nwith emotions. We explore the structure of emotions implied by our model\nand compare it to what has been posited in the psychology literature, and validate\nour model on a set of images that have been used in psychology studies. Finally,\nour work also provides a useful tool for the growing academic study of images\u2014\nboth photographs and memes\u2014on social networks.", "pdf": "/pdf/c67ea97ba6ec82c7f5cdc05854baf5de21205158.pdf", "paperhash": "hu|multimodal_sentiment_analysis_to_explore_the_structure_of_emotions", "_bibtex": "@misc{\nhu2018multimodal,\ntitle={Multimodal Sentiment Analysis To Explore the Structure of Emotions},\nauthor={Anthony Hu and Seth Flaxman},\nyear={2018},\nurl={https://openreview.net/forum?id=BJ6anzb0Z},\n}", "keywords": [], "authors": ["Anthony Hu", "Seth Flaxman"], "authorids": ["anthony.hu@stats.ox.ac.uk", "s.flaxman@imperial.ac.uk"]}, "tags": [], "invitation": {"id": "ICLR.cc/2018/Conference/-/Acceptance_Decision", "rdate": null, "ddate": null, "expdate": 1541175629000, "duedate": null, "tmdate": 1541177635767, "tddate": null, "super": null, "final": null, "reply": {"forum": null, "replyto": null, "invitation": "ICLR.cc/2018/Conference/-/Blind_Submission", "writers": {"values": ["ICLR.cc/2018/Conference/Program_Chairs"]}, "signatures": {"description": "How your identity will be displayed with the above content.", "values": ["ICLR.cc/2018/Conference/Program_Chairs"]}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["ICLR.cc/2018/Conference/Program_Chairs", "everyone"]}, "content": {"title": {"required": true, "order": 1, "value": "ICLR 2018 Conference Acceptance Decision"}, "comment": {"required": false, "order": 3, "description": "(optional) Comment on this decision.", "value-regex": "[\\S\\s]{0,5000}"}, "decision": {"required": true, "order": 2, "value-dropdown": ["Accept (Oral)", "Accept (Poster)", "Reject", "Invite to Workshop Track"]}}}, "signatures": ["ICLR.cc/2018/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": [], "noninvitees": [], "writers": ["ICLR.cc/2018/Conference"], "multiReply": null, "taskCompletionCount": null, "transform": null, "cdate": 1541177635767}}}, {"tddate": null, "ddate": null, "original": null, "tmdate": 1515642537332, "tcdate": 1511557814275, "number": 1, "cdate": 1511557814275, "id": "rJA29bLxf", "invitation": "ICLR.cc/2018/Conference/-/Paper978/Official_Review", "forum": "BJ6anzb0Z", "replyto": "BJ6anzb0Z", "signatures": ["ICLR.cc/2018/Conference/Paper978/AnonReviewer2"], "readers": ["everyone"], "content": {"title": "The authors present a study that aims at inferring the \"emotional\" tags provided by Thumblr users starting from images and texts in the captions. ", "rating": "6: Marginally above acceptance threshold", "review": "\nThe authors present a study that aims at inferring the \"emotional\" tags provided by Thumblr users starting from images and texts in the captions. For text processing the authors use a standard LSTM taking as input GLOVE vectors of words in a sentence. For visual information, authors use a pretrained CNN (with fine tuning). A fully connected layer is used to fuse the multimodal information. Experimental results are reported in a self generated data set. \n\nThe contribution from the RL perspective is limited, in the sense that the authors simply applied standard models to predict a bunch of labels (in this case, emotion labels). It is interesting the \"psychological\" analysis that the authors present in Section 6. Still, I think the contribution in that part is a: sentiment-psychologically inspired analysis of the Thumbrl data set. \n\nI think the author's statement on that this study leads to a more plausible psychological model of emotion is not well founded (they also mention to learn to recognize the latent emotional state). Whereas it is true that psychological studies rely on self - filled questionnaires, comparing a questionnaire (produced by expert psychologist) to the tags provided by users in a social network is to ambitious. (in some parts the authors make explicit this is an approximation, this should be stressed in every part of the paper)\n", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}, "writers": [], "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Multimodal Sentiment Analysis To Explore the Structure of Emotions", "abstract": "We propose a novel approach to multimodal sentiment analysis using deep neural\nnetworks combining visual recognition and natural language processing. Our\ngoal is different than the standard sentiment analysis goal of predicting whether\na sentence expresses positive or negative sentiment; instead, we aim to infer the\nlatent emotional state of the user. Thus, we focus on predicting the emotion word\ntags attached by users to their Tumblr posts, treating these as \u201cself-reported emotions.\u201d\nWe demonstrate that our multimodal model combining both text and image\nfeatures outperforms separate models based solely on either images or text. Our\nmodel\u2019s results are interpretable, automatically yielding sensible word lists associated\nwith emotions. We explore the structure of emotions implied by our model\nand compare it to what has been posited in the psychology literature, and validate\nour model on a set of images that have been used in psychology studies. Finally,\nour work also provides a useful tool for the growing academic study of images\u2014\nboth photographs and memes\u2014on social networks.", "pdf": "/pdf/c67ea97ba6ec82c7f5cdc05854baf5de21205158.pdf", "paperhash": "hu|multimodal_sentiment_analysis_to_explore_the_structure_of_emotions", "_bibtex": "@misc{\nhu2018multimodal,\ntitle={Multimodal Sentiment Analysis To Explore the Structure of Emotions},\nauthor={Anthony Hu and Seth Flaxman},\nyear={2018},\nurl={https://openreview.net/forum?id=BJ6anzb0Z},\n}", "keywords": [], "authors": ["Anthony Hu", "Seth Flaxman"], "authorids": ["anthony.hu@stats.ox.ac.uk", "s.flaxman@imperial.ac.uk"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1511845199000, "tmdate": 1515642537233, "id": "ICLR.cc/2018/Conference/-/Paper978/Official_Review", "writers": ["ICLR.cc/2018/Conference"], "signatures": ["ICLR.cc/2018/Conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2018/Conference/Paper978/Reviewers"], "noninvitees": ["ICLR.cc/2018/Conference/Paper978/AnonReviewer2", "ICLR.cc/2018/Conference/Paper978/AnonReviewer3", "ICLR.cc/2018/Conference/Paper978/AnonReviewer1"], "reply": {"forum": "BJ6anzb0Z", "replyto": "BJ6anzb0Z", "writers": {"values": []}, "signatures": {"values-regex": "ICLR.cc/2018/Conference/Paper978/AnonReviewer[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"required": true, "order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"required": true, "order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "value-regex": "[\\S\\s]{1,200000}"}, "rating": {"required": true, "order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"required": true, "order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1519621199000, "cdate": 1515642537233}}}, {"tddate": null, "ddate": null, "original": null, "tmdate": 1515642537288, "tcdate": 1511801572341, "number": 2, "cdate": 1511801572341, "id": "BJ2J7pFgf", "invitation": "ICLR.cc/2018/Conference/-/Paper978/Official_Review", "forum": "BJ6anzb0Z", "replyto": "BJ6anzb0Z", "signatures": ["ICLR.cc/2018/Conference/Paper978/AnonReviewer3"], "readers": ["everyone"], "content": {"title": "Hashtag classification of Tumblr Posts ", "rating": "4: Ok but not good enough - rejection", "review": "This paper presents a method for classifying Tumblr posts with associated images according to associated single emotion word hashtags.  The method relies on sentiment pre-processing from GloVe and image pre-processing from Inception.  \n \nMy strongest criticism for this paper is against the claim that Tumblr post represent self-reported emotions and that this method sheds new insight on emotion representation and my secondary criticism is a lack of novelty in the method, which seems to be simply a combination of previously published sentiment analysis module and previously published image analysis module, fused in an output layer. \n\nThe authors claim that the hashtags represent self-reported emotions, but this is not true in the way that psychologists query participants regarding emotion words in psychology studies.  Instead these are emotion words that a person chooses to broadcast along with an associated announcement.  As the authors point out, hashtags and words may be used sarcastically or in different ways from what is understood in emotion theory.  It is quite common for everyday people to use emotion words this way e.g. using #love to express strong approval rather than an actual feeling of love.   \n\nIn their analysis the authors claim:\n\u201cThe 15 emotions retained were those with high relative frequencies on Tumblr among the PANAS-X scale (Watson & Clark, 1999)\u201d.\nHowever five of the words the authors retain: bored, annoyed, love, optimistic, and pensive are not in fact found in the PANAS-X scale:\n\nReference: The PANAS-X Scale: https://wiki.aalto.fi/download/attachments/50102838/PANAS-X-scale_spec.pdf Also the longer version that the authors cited: \nhttps://www2.psychology.uiowa.edu/faculty/clark/panas-x.pdf\n\nIt should also be noted that the PANAS (Positive and Negative Affect Scale) scale and the PANAS-X (the \u201cX\u201d is for eXtended) scale are questionnaires used to elicit from participants feelings of positive and negative affect, they are not collections of \"core\" emotion words, but rather words that are colloquially attached to either positive or negative sentiment.  For example PANAS-X includes words like:\u201cstrong\u201d ,\u201cactive\u201d, \u201chealthy\u201d, \u201csleepy\u201d which are not considered emotion words by psychology.  \n\nIf the authors stated goal is \"different than the standard sentiment analysis goal of predicting whether a sentence expresses positive or negative sentiment\" they should be aware that this is exactly what PANAS is designed to do - not to infer the latent emotional state of a person, except to the extent that their affect is positive or negative.\n\n\nThe work of representing emotions had been an field in psychology for over a hundred years and it is still continuing.  https://en.wikipedia.org/wiki/Contrasting_and_categorization_of_emotions.\n\nOne of the most popular theories of emotion is the theory that there exist \u201cbasic\u201d emotions: Anger, Disgust, Fear, Happiness (enjoyment), Sadness and Surprise (Paul Ekman, cited by the authors).  These are short duration sates lasting only seconds.  They are also fairly specific, for example \u201csurprise\u201d is sudden reaction to something unexpected, which is it exactly the same as seeing a flower on your car and expressing \u201cwhat a nice surprise.\u201d  The surprise would be the initial reaction of \u201cwhat\u2019s that on my car?  Is it dangerous?\u201d but after identifying the object as non-threatening, the emotion of \u201csurprise\u201d would likely pass and be replaced with appreciation.  \n\nThe Circumplex Model of Emotions (Posner et al 2005) the authors refer to actually stands in opposition to the theories of Ekman.  From the cited paper by Posner et al : \n\"The circumplex model of affect proposes that all affective states arise from cognitive interpretations of core neural sensations that are the product of two independent neurophysiological systems. This model stands in contrast to theories of basic emotions, which posit that a discrete and independent neural system subserves every emotion.\"\nFrom my reading of this paper, it is clear to me that the authors do not have a clear understanding of the current state of psychology\u2019s view of emotion representation and this work would not likely contribute to a new understanding of the latent structure of peoples\u2019 emotions.\n\nIn the PCA result, it is not \"clear\" that the first axis represents valence, as \"sad\" has a slight positive on this scale and \"sad\" is one of the emotions most clearly associated with negative valence.\n\nWith respect to the rest of the paper, the level of novelty and impact is \"ok, but not good enough.\"  This analysis does not seem very different from Twitter analysis, because although Tumblr posts are allowed to be longer than Twitter posts, the authors truncate the posts to 50 characters.  Additionally, the images do not seem to add very much to the classification.  The authors algorithm also seems to be essentially a combination of two other, previously published algorithms.\n\nFor me the novelty of this paper was in its application to the realm of emotion theory, but I do not feel there is a contribution here.  This paper is more about classifying Tumblr posts according to emotion word hashtags than a paper that generates a new insights into emotion representation or that can infer latent emotional state. \n\n\n\n\n\n\n\n\n\n\n\n", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}, "writers": [], "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Multimodal Sentiment Analysis To Explore the Structure of Emotions", "abstract": "We propose a novel approach to multimodal sentiment analysis using deep neural\nnetworks combining visual recognition and natural language processing. Our\ngoal is different than the standard sentiment analysis goal of predicting whether\na sentence expresses positive or negative sentiment; instead, we aim to infer the\nlatent emotional state of the user. Thus, we focus on predicting the emotion word\ntags attached by users to their Tumblr posts, treating these as \u201cself-reported emotions.\u201d\nWe demonstrate that our multimodal model combining both text and image\nfeatures outperforms separate models based solely on either images or text. Our\nmodel\u2019s results are interpretable, automatically yielding sensible word lists associated\nwith emotions. We explore the structure of emotions implied by our model\nand compare it to what has been posited in the psychology literature, and validate\nour model on a set of images that have been used in psychology studies. Finally,\nour work also provides a useful tool for the growing academic study of images\u2014\nboth photographs and memes\u2014on social networks.", "pdf": "/pdf/c67ea97ba6ec82c7f5cdc05854baf5de21205158.pdf", "paperhash": "hu|multimodal_sentiment_analysis_to_explore_the_structure_of_emotions", "_bibtex": "@misc{\nhu2018multimodal,\ntitle={Multimodal Sentiment Analysis To Explore the Structure of Emotions},\nauthor={Anthony Hu and Seth Flaxman},\nyear={2018},\nurl={https://openreview.net/forum?id=BJ6anzb0Z},\n}", "keywords": [], "authors": ["Anthony Hu", "Seth Flaxman"], "authorids": ["anthony.hu@stats.ox.ac.uk", "s.flaxman@imperial.ac.uk"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1511845199000, "tmdate": 1515642537233, "id": "ICLR.cc/2018/Conference/-/Paper978/Official_Review", "writers": ["ICLR.cc/2018/Conference"], "signatures": ["ICLR.cc/2018/Conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2018/Conference/Paper978/Reviewers"], "noninvitees": ["ICLR.cc/2018/Conference/Paper978/AnonReviewer2", "ICLR.cc/2018/Conference/Paper978/AnonReviewer3", "ICLR.cc/2018/Conference/Paper978/AnonReviewer1"], "reply": {"forum": "BJ6anzb0Z", "replyto": "BJ6anzb0Z", "writers": {"values": []}, "signatures": {"values-regex": "ICLR.cc/2018/Conference/Paper978/AnonReviewer[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"required": true, "order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"required": true, "order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "value-regex": "[\\S\\s]{1,200000}"}, "rating": {"required": true, "order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"required": true, "order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1519621199000, "cdate": 1515642537233}}}, {"tddate": null, "ddate": null, "original": null, "tmdate": 1515642537248, "tcdate": 1511812706471, "number": 3, "cdate": 1511812706471, "id": "HJcw0y5eM", "invitation": "ICLR.cc/2018/Conference/-/Paper978/Official_Review", "forum": "BJ6anzb0Z", "replyto": "BJ6anzb0Z", "signatures": ["ICLR.cc/2018/Conference/Paper978/AnonReviewer1"], "readers": ["everyone"], "content": {"title": "Interesting paper on sentiment analysis combining image and text ", "rating": "5: Marginally below acceptance threshold", "review": "The paper presents a multi-modal CNN model for sentiment analysis that combines images and text.  The model is trained on a new dataset collected from Tumblr.\n\nPositive aspects:\n+ Emphasis in model interpretability and its connection to psychological findings in emotions\n+ The idea of using Tumblr data seems interesting, allowing to work with a large set of emotion categories, instead of considering just the binary task positive vs. negative. \n\nWeaknesses:\n- A deeper analysis of previous work on the combination of image and text for sentiment analysis (both datasets and methods) and its relation with the presented work is necessary. \n- The proposed method is not compared with other methods that combine text and image for sentiment analysis.\n-  The study is limited to just one dataset.\n\nThe paper presents interesting ideas and findings in an important challenging area. The main novelties of the paper are: (1) the use of Tumblr data, (2) the proposed CNN architecture, combining images and text (using word embedding. \n\nI missed a \"related work section\", where authors clearly mention previous works on similar datasets. Some related works are mentioned in the paper, but those are spread in different sections. It's hard to get a clear overview of the previous research: datasets, methods and contextualization of the proposed approach in relation with previous work. I think authors should cite Sentibanks. Also, at some point authors should compare their proposal with previous work. \n\nMore comments:\n\n- Some figures could be more complete: to see more examples in Fig 1, 2, 3 would help to understand better the dataset and the challenges. \n- In table 4, for example, it would be nice to see the performance on the different emotion categories.\n- It would be interesting to see qualitative visual results on recognitions.\n\nI like this work, but I think authors should improve the aspects I mention for its publication.\n", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}, "writers": [], "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Multimodal Sentiment Analysis To Explore the Structure of Emotions", "abstract": "We propose a novel approach to multimodal sentiment analysis using deep neural\nnetworks combining visual recognition and natural language processing. Our\ngoal is different than the standard sentiment analysis goal of predicting whether\na sentence expresses positive or negative sentiment; instead, we aim to infer the\nlatent emotional state of the user. Thus, we focus on predicting the emotion word\ntags attached by users to their Tumblr posts, treating these as \u201cself-reported emotions.\u201d\nWe demonstrate that our multimodal model combining both text and image\nfeatures outperforms separate models based solely on either images or text. Our\nmodel\u2019s results are interpretable, automatically yielding sensible word lists associated\nwith emotions. We explore the structure of emotions implied by our model\nand compare it to what has been posited in the psychology literature, and validate\nour model on a set of images that have been used in psychology studies. Finally,\nour work also provides a useful tool for the growing academic study of images\u2014\nboth photographs and memes\u2014on social networks.", "pdf": "/pdf/c67ea97ba6ec82c7f5cdc05854baf5de21205158.pdf", "paperhash": "hu|multimodal_sentiment_analysis_to_explore_the_structure_of_emotions", "_bibtex": "@misc{\nhu2018multimodal,\ntitle={Multimodal Sentiment Analysis To Explore the Structure of Emotions},\nauthor={Anthony Hu and Seth Flaxman},\nyear={2018},\nurl={https://openreview.net/forum?id=BJ6anzb0Z},\n}", "keywords": [], "authors": ["Anthony Hu", "Seth Flaxman"], "authorids": ["anthony.hu@stats.ox.ac.uk", "s.flaxman@imperial.ac.uk"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1511845199000, "tmdate": 1515642537233, "id": "ICLR.cc/2018/Conference/-/Paper978/Official_Review", "writers": ["ICLR.cc/2018/Conference"], "signatures": ["ICLR.cc/2018/Conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2018/Conference/Paper978/Reviewers"], "noninvitees": ["ICLR.cc/2018/Conference/Paper978/AnonReviewer2", "ICLR.cc/2018/Conference/Paper978/AnonReviewer3", "ICLR.cc/2018/Conference/Paper978/AnonReviewer1"], "reply": {"forum": "BJ6anzb0Z", "replyto": "BJ6anzb0Z", "writers": {"values": []}, "signatures": {"values-regex": "ICLR.cc/2018/Conference/Paper978/AnonReviewer[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"required": true, "order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"required": true, "order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "value-regex": "[\\S\\s]{1,200000}"}, "rating": {"required": true, "order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"required": true, "order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1519621199000, "cdate": 1515642537233}}}, {"tddate": null, "ddate": null, "tmdate": 1515186934369, "tcdate": 1515186934369, "number": 4, "cdate": 1515186934369, "id": "B1AeovaXM", "invitation": "ICLR.cc/2018/Conference/-/Paper978/Official_Comment", "forum": "BJ6anzb0Z", "replyto": "BJ2J7pFgf", "signatures": ["ICLR.cc/2018/Conference/Paper978/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Conference/Paper978/Authors"], "content": {"title": "Reply (part 2)", "comment": "4) \u201cThe work of representing emotions had been an field in psychology for over a hundred years and it is still continuing.  https://en.wikipedia.org/wiki/Contrasting_and_categorization_of_emotions.\n\nOne of the most popular theories of emotion is the theory that there exist \u201cbasic\u201d emotions: Anger, Disgust, Fear, Happiness (enjoyment), Sadness and Surprise (Paul Ekman, cited by the authors).  These are short duration sates lasting only seconds.  They are also fairly specific, for example \u201csurprise\u201d is sudden reaction to something unexpected, which is it exactly the same as seeing a flower on your car and expressing \u201cwhat a nice surprise.\u201d  The surprise would be the initial reaction of \u201cwhat\u2019s that on my car?  Is it dangerous?\u201d but after identifying the object as non-threatening, the emotion of \u201csurprise\u201d would likely pass and be replaced with appreciation.  \n\nThe Circumplex Model of Emotions (Posner et al 2005) the authors refer to actually stands in opposition to the theories of Ekman.  From the cited paper by Posner et al : \n\"The circumplex model of affect proposes that all affective states arise from cognitive interpretations of core neural sensations that are the product of two independent neurophysiological systems. This model stands in contrast to theories of basic emotions, which posit that a discrete and independent neural system subserves every emotion.\"\nFrom my reading of this paper, it is clear to me that the authors do not have a clear understanding of the current state of psychology\u2019s view of emotion representation and this work would not likely contribute to a new understanding of the latent structure of peoples\u2019 emotions.\u201d\n\nWe agree with your characterization of two of the theories in the literature, but as you say this work continues. As we believe this is by no means a settled field, we see our contribution as that of providing a new measurement tool, more robust than standard sentiment analysis, for the automatic measurement of emotion. We reference both Ekman and the Circumplex model because we see our work as attempting to find evidence, positive or negative, for these theories. But indeed, a longer a more detailed study is needed--we have just scratched the surface in terms of creating a relevant dataset and showing that simple neural network models can achieve good accuracy on this dataset.\n\n5) \u201cIn the PCA result, it is not \"clear\" that the first axis represents valence, as \"sad\" has a slight positive on this scale and \"sad\" is one of the emotions most clearly associated with negative valence.\u201d\n\nWe agree and will update our text with caveats accordingly.\n\n6) \u201cWith respect to the rest of the paper, the level of novelty and impact is \"ok, but not good enough.\"  This analysis does not seem very different from Twitter analysis, because although Tumblr posts are allowed to be longer than Twitter posts, the authors truncate the posts to 50 characters.\u201d\n\nWe truncate to 50 words, not 50 characters, and therefore if we consider that on average an English word contains 4.5 characters (http://www.cs.trincoll.edu/~crypto/resources/LetFreq.html), the Tumblr text is 60% longer than the maximum Twitter post, and probably more than twice longer than the average Twitter post.\n\n7) \u201cAdditionally, the images do not seem to add very much to the classification.  The authors algorithm also seems to be essentially a combination of two other, previously published algorithms.\n\nFor me the novelty of this paper was in its application to the realm of emotion theory, but I do not feel there is a contribution here.  This paper is more about classifying Tumblr posts according to emotion word hashtags than a paper that generates a new insights into emotion representation or that can infer latent emotional state.\u201d\n\nThank you for your careful reading of our paper.\n"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Multimodal Sentiment Analysis To Explore the Structure of Emotions", "abstract": "We propose a novel approach to multimodal sentiment analysis using deep neural\nnetworks combining visual recognition and natural language processing. Our\ngoal is different than the standard sentiment analysis goal of predicting whether\na sentence expresses positive or negative sentiment; instead, we aim to infer the\nlatent emotional state of the user. Thus, we focus on predicting the emotion word\ntags attached by users to their Tumblr posts, treating these as \u201cself-reported emotions.\u201d\nWe demonstrate that our multimodal model combining both text and image\nfeatures outperforms separate models based solely on either images or text. Our\nmodel\u2019s results are interpretable, automatically yielding sensible word lists associated\nwith emotions. We explore the structure of emotions implied by our model\nand compare it to what has been posited in the psychology literature, and validate\nour model on a set of images that have been used in psychology studies. Finally,\nour work also provides a useful tool for the growing academic study of images\u2014\nboth photographs and memes\u2014on social networks.", "pdf": "/pdf/c67ea97ba6ec82c7f5cdc05854baf5de21205158.pdf", "paperhash": "hu|multimodal_sentiment_analysis_to_explore_the_structure_of_emotions", "_bibtex": "@misc{\nhu2018multimodal,\ntitle={Multimodal Sentiment Analysis To Explore the Structure of Emotions},\nauthor={Anthony Hu and Seth Flaxman},\nyear={2018},\nurl={https://openreview.net/forum?id=BJ6anzb0Z},\n}", "keywords": [], "authors": ["Anthony Hu", "Seth Flaxman"], "authorids": ["anthony.hu@stats.ox.ac.uk", "s.flaxman@imperial.ac.uk"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "tmdate": 1516825725103, "id": "ICLR.cc/2018/Conference/-/Paper978/Official_Comment", "writers": ["ICLR.cc/2018/Conference"], "signatures": ["ICLR.cc/2018/Conference"], "readers": ["everyone"], "reply": {"replyto": null, "forum": "BJ6anzb0Z", "writers": {"values-regex": "ICLR.cc/2018/Conference/Paper978/AnonReviewer[0-9]+|ICLR.cc/2018/Conference/Paper978/Authors|ICLR.cc/2018/Conference/Paper978/Area_Chair|ICLR.cc/2018/Conference/Program_Chairs"}, "signatures": {"values-regex": "ICLR.cc/2018/Conference/Paper978/AnonReviewer[0-9]+|ICLR.cc/2018/Conference/Paper978/Authors|ICLR.cc/2018/Conference/Paper978/Area_Chair|ICLR.cc/2018/Conference/Program_Chairs", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2018/Conference/Paper978/Authors_and_Higher", "ICLR.cc/2018/Conference/Paper978/Reviewers_and_Higher", "ICLR.cc/2018/Conference/Paper978/Area_Chairs_and_Higher", "ICLR.cc/2018/Conference/Program_Chairs"]}, "content": {"title": {"required": true, "order": 0, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"required": true, "order": 1, "description": "Your comment or reply (max 5000 characters).", "value-regex": "[\\S\\s]{1,5000}"}}}, "nonreaders": [], "noninvitees": [], "invitees": ["ICLR.cc/2018/Conference/Paper978/Reviewers", "ICLR.cc/2018/Conference/Paper978/Authors", "ICLR.cc/2018/Conference/Paper978/Area_Chair", "ICLR.cc/2018/Conference/Program_Chairs"], "cdate": 1516825725103}}}, {"tddate": null, "ddate": null, "tmdate": 1515186904474, "tcdate": 1515186904474, "number": 3, "cdate": 1515186904474, "id": "Ske1iPpQG", "invitation": "ICLR.cc/2018/Conference/-/Paper978/Official_Comment", "forum": "BJ6anzb0Z", "replyto": "BJ2J7pFgf", "signatures": ["ICLR.cc/2018/Conference/Paper978/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Conference/Paper978/Authors"], "content": {"title": "Reply (part 1)", "comment": "1) \u201cThe authors claim that the hashtags represent self-reported emotions, but this is not true in the way that psychologists query participants regarding emotion words in psychology studies.  Instead these are emotion words that a person chooses to broadcast along with an associated announcement.  As the authors point out, hashtags and words may be used sarcastically or in different ways from what is understood in emotion theory.  It is quite common for everyday people to use emotion words this way e.g. using #love to express strong approval rather than an actual feeling of love.\u201d\n\nAs we describe in the paper, there is no agreed upon gold-standard for measuring emotion in psychology. Self-report is considered the best, but there can be demand effects (Orne 1962) through which subjects try to tailor their responses in some way due to the fact that they are participating in a study. By contrast, behavioral measures (Webb et al, 1966) can be more reliable as they are less subject to demand effects. We see all of the performance by users on Tumblr as behavioral, with the emotion tags are as a behavioral report of emotion. We agree that there is noise inherent in this measure, due to, e.g. sarcasm, but did not see reason to worry that this was a significant source of bias.\n\n2) \u201cIn their analysis the authors claim:\n\u201cThe 15 emotions retained were those with high relative frequencies on Tumblr among the PANAS-X scale (Watson & Clark, 1999)\u201d.\nHowever five of the words the authors retain: bored, annoyed, love, optimistic, and pensive are not in fact found in the PANAS-X scale:\n\nReference: The PANAS-X Scale: https://wiki.aalto.fi/download/attachments/50102838/PANAS-X-scale_spec.pdf Also the longer version that the authors cited: \nhttps://www2.psychology.uiowa.edu/faculty/clark/panas-x.pdf\n\nIt should also be noted that the PANAS (Positive and Negative Affect Scale) scale and the PANAS-X (the \u201cX\u201d is for eXtended) scale are questionnaires used to elicit from participants feelings of positive and negative affect, they are not collections of \"core\" emotion words, but rather words that are colloquially attached to either positive or negative sentiment.  For example PANAS-X includes words like:\u201cstrong\u201d ,\u201cactive\u201d, \u201chealthy\u201d, \u201csleepy\u201d which are not considered emotion words by psychology. \u201d\n\nGood point, the five emotions not appearing in the PANAS-X scale were found in the Plutchik's Wheel of Emotions. We extracted as many posts as possible for various emotions and kept the 15 emotions with the highest relative frequencies. We clarified that point in the paper, page 2.\n\n3) \u201cIf the authors stated goal is \"different than the standard sentiment analysis goal of predicting whether a sentence expresses positive or negative sentiment\" they should be aware that this is exactly what PANAS is designed to do - not to infer the latent emotional state of a person, except to the extent that their affect is positive or negative.\u201d\n\nBy standard sentiment analysis, we simply mean methods designed to categorize a sentence like \"I loved the new Star Wars movie!\" as positive. Very simple methods (e.g. LIWC) can do a decent job at this task. But do these methods capture latent emotional state? (Whether this emotional state is conceived of as positive/negative affect, core emotions, or a circumplex model is a separate issue we discuss below). We argue that there is strong evidence that standard sentiment analysis methods do NOT correspond to the latent emotional of the user and have added a citation (Flaxman and Kassam, 2016) backing up this claim. This is what motivates our attempts to find a new sentiment analysis method."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Multimodal Sentiment Analysis To Explore the Structure of Emotions", "abstract": "We propose a novel approach to multimodal sentiment analysis using deep neural\nnetworks combining visual recognition and natural language processing. Our\ngoal is different than the standard sentiment analysis goal of predicting whether\na sentence expresses positive or negative sentiment; instead, we aim to infer the\nlatent emotional state of the user. Thus, we focus on predicting the emotion word\ntags attached by users to their Tumblr posts, treating these as \u201cself-reported emotions.\u201d\nWe demonstrate that our multimodal model combining both text and image\nfeatures outperforms separate models based solely on either images or text. Our\nmodel\u2019s results are interpretable, automatically yielding sensible word lists associated\nwith emotions. We explore the structure of emotions implied by our model\nand compare it to what has been posited in the psychology literature, and validate\nour model on a set of images that have been used in psychology studies. Finally,\nour work also provides a useful tool for the growing academic study of images\u2014\nboth photographs and memes\u2014on social networks.", "pdf": "/pdf/c67ea97ba6ec82c7f5cdc05854baf5de21205158.pdf", "paperhash": "hu|multimodal_sentiment_analysis_to_explore_the_structure_of_emotions", "_bibtex": "@misc{\nhu2018multimodal,\ntitle={Multimodal Sentiment Analysis To Explore the Structure of Emotions},\nauthor={Anthony Hu and Seth Flaxman},\nyear={2018},\nurl={https://openreview.net/forum?id=BJ6anzb0Z},\n}", "keywords": [], "authors": ["Anthony Hu", "Seth Flaxman"], "authorids": ["anthony.hu@stats.ox.ac.uk", "s.flaxman@imperial.ac.uk"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "tmdate": 1516825725103, "id": "ICLR.cc/2018/Conference/-/Paper978/Official_Comment", "writers": ["ICLR.cc/2018/Conference"], "signatures": ["ICLR.cc/2018/Conference"], "readers": ["everyone"], "reply": {"replyto": null, "forum": "BJ6anzb0Z", "writers": {"values-regex": "ICLR.cc/2018/Conference/Paper978/AnonReviewer[0-9]+|ICLR.cc/2018/Conference/Paper978/Authors|ICLR.cc/2018/Conference/Paper978/Area_Chair|ICLR.cc/2018/Conference/Program_Chairs"}, "signatures": {"values-regex": "ICLR.cc/2018/Conference/Paper978/AnonReviewer[0-9]+|ICLR.cc/2018/Conference/Paper978/Authors|ICLR.cc/2018/Conference/Paper978/Area_Chair|ICLR.cc/2018/Conference/Program_Chairs", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2018/Conference/Paper978/Authors_and_Higher", "ICLR.cc/2018/Conference/Paper978/Reviewers_and_Higher", "ICLR.cc/2018/Conference/Paper978/Area_Chairs_and_Higher", "ICLR.cc/2018/Conference/Program_Chairs"]}, "content": {"title": {"required": true, "order": 0, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"required": true, "order": 1, "description": "Your comment or reply (max 5000 characters).", "value-regex": "[\\S\\s]{1,5000}"}}}, "nonreaders": [], "noninvitees": [], "invitees": ["ICLR.cc/2018/Conference/Paper978/Reviewers", "ICLR.cc/2018/Conference/Paper978/Authors", "ICLR.cc/2018/Conference/Paper978/Area_Chair", "ICLR.cc/2018/Conference/Program_Chairs"], "cdate": 1516825725103}}}, {"tddate": null, "ddate": null, "tmdate": 1515186537199, "tcdate": 1515186537199, "number": 2, "cdate": 1515186537199, "id": "HkZ_Yw6mM", "invitation": "ICLR.cc/2018/Conference/-/Paper978/Official_Comment", "forum": "BJ6anzb0Z", "replyto": "rJA29bLxf", "signatures": ["ICLR.cc/2018/Conference/Paper978/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Conference/Paper978/Authors"], "content": {"title": "Reply", "comment": "Thank you for the review.\n\n\u201cThe contribution from the RL perspective is limited, in the sense that the authors simply applied standard models to predict a bunch of labels (in this case, emotion labels)\u201d\nWe wouldn\u2019t qualify our model to just be predicting a \u201cbunch of labels\u201d given the complexity of inferring emotional states (due to the high intra class variability). The main contribution of the paper is that we investigate the study of emotion with a novel and large dataset including images (which is not as readily available on other social media such as Twitter), and further use the model to examine psychological components of the structure of emotion.\n"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Multimodal Sentiment Analysis To Explore the Structure of Emotions", "abstract": "We propose a novel approach to multimodal sentiment analysis using deep neural\nnetworks combining visual recognition and natural language processing. Our\ngoal is different than the standard sentiment analysis goal of predicting whether\na sentence expresses positive or negative sentiment; instead, we aim to infer the\nlatent emotional state of the user. Thus, we focus on predicting the emotion word\ntags attached by users to their Tumblr posts, treating these as \u201cself-reported emotions.\u201d\nWe demonstrate that our multimodal model combining both text and image\nfeatures outperforms separate models based solely on either images or text. Our\nmodel\u2019s results are interpretable, automatically yielding sensible word lists associated\nwith emotions. We explore the structure of emotions implied by our model\nand compare it to what has been posited in the psychology literature, and validate\nour model on a set of images that have been used in psychology studies. Finally,\nour work also provides a useful tool for the growing academic study of images\u2014\nboth photographs and memes\u2014on social networks.", "pdf": "/pdf/c67ea97ba6ec82c7f5cdc05854baf5de21205158.pdf", "paperhash": "hu|multimodal_sentiment_analysis_to_explore_the_structure_of_emotions", "_bibtex": "@misc{\nhu2018multimodal,\ntitle={Multimodal Sentiment Analysis To Explore the Structure of Emotions},\nauthor={Anthony Hu and Seth Flaxman},\nyear={2018},\nurl={https://openreview.net/forum?id=BJ6anzb0Z},\n}", "keywords": [], "authors": ["Anthony Hu", "Seth Flaxman"], "authorids": ["anthony.hu@stats.ox.ac.uk", "s.flaxman@imperial.ac.uk"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "tmdate": 1516825725103, "id": "ICLR.cc/2018/Conference/-/Paper978/Official_Comment", "writers": ["ICLR.cc/2018/Conference"], "signatures": ["ICLR.cc/2018/Conference"], "readers": ["everyone"], "reply": {"replyto": null, "forum": "BJ6anzb0Z", "writers": {"values-regex": "ICLR.cc/2018/Conference/Paper978/AnonReviewer[0-9]+|ICLR.cc/2018/Conference/Paper978/Authors|ICLR.cc/2018/Conference/Paper978/Area_Chair|ICLR.cc/2018/Conference/Program_Chairs"}, "signatures": {"values-regex": "ICLR.cc/2018/Conference/Paper978/AnonReviewer[0-9]+|ICLR.cc/2018/Conference/Paper978/Authors|ICLR.cc/2018/Conference/Paper978/Area_Chair|ICLR.cc/2018/Conference/Program_Chairs", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2018/Conference/Paper978/Authors_and_Higher", "ICLR.cc/2018/Conference/Paper978/Reviewers_and_Higher", "ICLR.cc/2018/Conference/Paper978/Area_Chairs_and_Higher", "ICLR.cc/2018/Conference/Program_Chairs"]}, "content": {"title": {"required": true, "order": 0, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"required": true, "order": 1, "description": "Your comment or reply (max 5000 characters).", "value-regex": "[\\S\\s]{1,5000}"}}}, "nonreaders": [], "noninvitees": [], "invitees": ["ICLR.cc/2018/Conference/Paper978/Reviewers", "ICLR.cc/2018/Conference/Paper978/Authors", "ICLR.cc/2018/Conference/Paper978/Area_Chair", "ICLR.cc/2018/Conference/Program_Chairs"], "cdate": 1516825725103}}}, {"tddate": null, "ddate": null, "tmdate": 1515186477968, "tcdate": 1515186477968, "number": 1, "cdate": 1515186477968, "id": "S1U4Kv67f", "invitation": "ICLR.cc/2018/Conference/-/Paper978/Official_Comment", "forum": "BJ6anzb0Z", "replyto": "HJcw0y5eM", "signatures": ["ICLR.cc/2018/Conference/Paper978/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Conference/Paper978/Authors"], "content": {"title": "Reply", "comment": "Thank you very much for your comments which helped us restructure the paper that is hopefully more intelligible now.\n\n\u201cA deeper analysis of previous work on the combination of image and text for sentiment analysis (both datasets and methods) and its relation with the presented work is necessary.\u201d\nWe added a \u201cRelated work\u201d section (page 2) to better contextualise our proposed model with what has been previously done in visual and textual sentiment analysis.\n\n\u201cSome figures could be more complete: to see more examples in Fig 1, 2, 3 would help to understand better the dataset and the challenges.\u201d\nMore examples of Tumblr posts are now in the Appendix, page 13.\n"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Multimodal Sentiment Analysis To Explore the Structure of Emotions", "abstract": "We propose a novel approach to multimodal sentiment analysis using deep neural\nnetworks combining visual recognition and natural language processing. Our\ngoal is different than the standard sentiment analysis goal of predicting whether\na sentence expresses positive or negative sentiment; instead, we aim to infer the\nlatent emotional state of the user. Thus, we focus on predicting the emotion word\ntags attached by users to their Tumblr posts, treating these as \u201cself-reported emotions.\u201d\nWe demonstrate that our multimodal model combining both text and image\nfeatures outperforms separate models based solely on either images or text. Our\nmodel\u2019s results are interpretable, automatically yielding sensible word lists associated\nwith emotions. We explore the structure of emotions implied by our model\nand compare it to what has been posited in the psychology literature, and validate\nour model on a set of images that have been used in psychology studies. Finally,\nour work also provides a useful tool for the growing academic study of images\u2014\nboth photographs and memes\u2014on social networks.", "pdf": "/pdf/c67ea97ba6ec82c7f5cdc05854baf5de21205158.pdf", "paperhash": "hu|multimodal_sentiment_analysis_to_explore_the_structure_of_emotions", "_bibtex": "@misc{\nhu2018multimodal,\ntitle={Multimodal Sentiment Analysis To Explore the Structure of Emotions},\nauthor={Anthony Hu and Seth Flaxman},\nyear={2018},\nurl={https://openreview.net/forum?id=BJ6anzb0Z},\n}", "keywords": [], "authors": ["Anthony Hu", "Seth Flaxman"], "authorids": ["anthony.hu@stats.ox.ac.uk", "s.flaxman@imperial.ac.uk"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "tmdate": 1516825725103, "id": "ICLR.cc/2018/Conference/-/Paper978/Official_Comment", "writers": ["ICLR.cc/2018/Conference"], "signatures": ["ICLR.cc/2018/Conference"], "readers": ["everyone"], "reply": {"replyto": null, "forum": "BJ6anzb0Z", "writers": {"values-regex": "ICLR.cc/2018/Conference/Paper978/AnonReviewer[0-9]+|ICLR.cc/2018/Conference/Paper978/Authors|ICLR.cc/2018/Conference/Paper978/Area_Chair|ICLR.cc/2018/Conference/Program_Chairs"}, "signatures": {"values-regex": "ICLR.cc/2018/Conference/Paper978/AnonReviewer[0-9]+|ICLR.cc/2018/Conference/Paper978/Authors|ICLR.cc/2018/Conference/Paper978/Area_Chair|ICLR.cc/2018/Conference/Program_Chairs", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2018/Conference/Paper978/Authors_and_Higher", "ICLR.cc/2018/Conference/Paper978/Reviewers_and_Higher", "ICLR.cc/2018/Conference/Paper978/Area_Chairs_and_Higher", "ICLR.cc/2018/Conference/Program_Chairs"]}, "content": {"title": {"required": true, "order": 0, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"required": true, "order": 1, "description": "Your comment or reply (max 5000 characters).", "value-regex": "[\\S\\s]{1,5000}"}}}, "nonreaders": [], "noninvitees": [], "invitees": ["ICLR.cc/2018/Conference/Paper978/Reviewers", "ICLR.cc/2018/Conference/Paper978/Authors", "ICLR.cc/2018/Conference/Paper978/Area_Chair", "ICLR.cc/2018/Conference/Program_Chairs"], "cdate": 1516825725103}}}], "count": 9}