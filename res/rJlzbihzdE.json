{"notes": [{"id": "rJlzbihzdE", "original": "HJl5E3ebOE", "number": 34, "cdate": 1553283834463, "ddate": null, "tcdate": 1553283834463, "tmdate": 1562082118011, "tddate": null, "forum": "rJlzbihzdE", "replyto": null, "invitation": "ICLR.cc/2019/Workshop/LLD/-/Blind_Submission", "content": {"title": "Enhancing Generalization of First-Order Meta-Learning", "authors": ["Mirantha Jayathilaka"], "authorids": ["mirantha.jayathilaka@manchester.ac.uk"], "keywords": ["meta-learning", "generalization", "few-shot learning"], "TL;DR": "The study introduces two approaches to enhance generalization of first-order meta-learning and presents empirical evaluation on few-shot image classification.", "abstract": "In this study we focus on first-order meta-learning algorithms that aim to learn a parameter initialization of a network which can quickly adapt to new concepts, given a few examples. We investigate two approaches to enhance generalization and speed of learning of such algorithms, particularly expanding on the Reptile (Nichol et al., 2018) algorithm. We introduce a novel regularization technique called meta-step gradient pruning and also investigate the effects of increasing the depth of network architectures in first-order meta-learning. We present an empirical evaluation of both approaches, where we match benchmark few-shot image classification results with 10 times fewer iterations using Mini-ImageNet dataset and with the use of deeper networks, we attain accuracies that surpass the current benchmarks of few-shot image classification using Omniglot dataset.", "pdf": "/pdf/4375b11693ba8d020e04136041419f1714153837.pdf", "paperhash": "jayathilaka|enhancing_generalization_of_firstorder_metalearning"}, "signatures": ["ICLR.cc/2019/Workshop/LLD"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Workshop/LLD"], "details": {"replyCount": 3, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"id": "ICLR.cc/2019/Workshop/LLD/-/Blind_Submission", "cdate": 1548689671889, "reply": {"forum": null, "replyto": null, "readers": {"values-regex": ".*"}, "writers": {"values": ["ICLR.cc/2019/Workshop/LLD"]}, "signatures": {"values": ["ICLR.cc/2019/Workshop/LLD"]}, "content": {"authors": {"values-regex": ".*"}, "authorids": {"values-regex": ".*"}}}, "tcdate": 1548689671889, "tmdate": 1557933709646, "readers": ["everyone"], "writers": ["ICLR.cc/2019/Workshop/LLD"], "invitees": ["~"], "signatures": ["ICLR.cc/2019/Workshop/LLD"], "details": {"writable": true}}}, "tauthor": "OpenReview.net"}, {"id": "SJlECS-_FE", "original": null, "number": 1, "cdate": 1554679244272, "ddate": null, "tcdate": 1554679244272, "tmdate": 1555511887742, "tddate": null, "forum": "rJlzbihzdE", "replyto": "rJlzbihzdE", "invitation": "ICLR.cc/2019/Workshop/LLD/-/Paper34/Official_Review", "content": {"title": "A first step towards gaining a better understanding of first-order meta-learning", "review": "This work presents an empirical study of the first-order meta-learning Reptile algorithm, in particular investigating a proposed regularization technique and deeper networks. Their regularization method is to train as usual for the first \\psi steps and subsequently only apply the training update to the learned initialization if the difference between that initialization before and after the task-specific update on the current task is greater than another hyperparameter \\gamma.\n\nThey show experimentally that when training Reptile using the above procedure it overfits less: the gap between the training and testing accuracy is smaller (though not by a significant amount). What is perhaps more impressive is that they can obtain similar to state-of-the-art results on Omniglot and mini-ImageNet by applying 10x less updates than the corresponding state-of-the-art methods. Finally, they show that using deeper networks yields a benefit on Omniglot. This is an interesting observation, contradicting the intuition that when learning from little data larger networks would be more prone to overfitting.\n\nSome concerns / suggestions:\n-    I\u2019m curious if a similar behaviour to the proposed regularization can be obtained simply by using a learning rate schedule, and / or using ADAM in the outer loop as well.\n-    The results in Table 2 are slightly lower than MAML and Reptile\u2019s and it\u2019s not clear how many additional iterations would be required to match those results. It may be that to squeeze out that last bit of performance a lot more updates are required even with the proposed method. It therefore seems more informative to keep running the proposed method until that performance is reached and then compare the number of iterations required. Alternatively, showing the curve of the performance on held-out data throughout training would address this point as well.\n-    Regarding the experiments with the deeper networks: the authors describe this as using deeper networks in the inner loop specifically. It found this confusing. Are the additional weights only \u201cfast weights\u201d (e.g. part of a task-specific classifier) that are not meta-learned (by the outer loop)? It would be useful to be more specific about this.\n-    It would be interesting to present deeper network experiments on mini-ImageNet instead of (or in addition to) Omniglot, since it\u2019s a more realistic and challenging benchmark with larger resolution images.\n-    From what I understand, the proposed modifications are not applicable exclusively to first-order meta-learning. I would therefore be curious about whether applying these to second-order methods (e.g. full MAML) would yield similar conclusions.\n\nOverall, I feel that meta-training is still poorly understood so I think empirical investigations like the one in this work are useful for gaining stronger intuitions for best practices in this setup. I therefore recommend acceptance of this work.\n", "rating": "3: Marginally above acceptance threshold", "confidence": "3: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}, "signatures": ["ICLR.cc/2019/Workshop/LLD/Paper34/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Workshop/LLD/Paper34/AnonReviewer1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Enhancing Generalization of First-Order Meta-Learning", "authors": ["Mirantha Jayathilaka"], "authorids": ["mirantha.jayathilaka@manchester.ac.uk"], "keywords": ["meta-learning", "generalization", "few-shot learning"], "TL;DR": "The study introduces two approaches to enhance generalization of first-order meta-learning and presents empirical evaluation on few-shot image classification.", "abstract": "In this study we focus on first-order meta-learning algorithms that aim to learn a parameter initialization of a network which can quickly adapt to new concepts, given a few examples. We investigate two approaches to enhance generalization and speed of learning of such algorithms, particularly expanding on the Reptile (Nichol et al., 2018) algorithm. We introduce a novel regularization technique called meta-step gradient pruning and also investigate the effects of increasing the depth of network architectures in first-order meta-learning. We present an empirical evaluation of both approaches, where we match benchmark few-shot image classification results with 10 times fewer iterations using Mini-ImageNet dataset and with the use of deeper networks, we attain accuracies that surpass the current benchmarks of few-shot image classification using Omniglot dataset.", "pdf": "/pdf/4375b11693ba8d020e04136041419f1714153837.pdf", "paperhash": "jayathilaka|enhancing_generalization_of_firstorder_metalearning"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Workshop/LLD/-/Paper34/Official_Review", "cdate": 1553713416328, "expdate": 1555718400000, "duedate": 1554681600000, "reply": {"forum": "rJlzbihzdE", "replyto": "rJlzbihzdE", "writers": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2019/Workshop/LLD/Paper34/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2019/Workshop/LLD/Paper34/AnonReviewer[0-9]+"}, "readers": {"values": ["everyone"], "description": "The users who will be allowed to read the above content."}, "content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "required": true}, "rating": {"order": 3, "value-dropdown": ["5: Top 15% of accepted papers, strong accept", "4: Top 50% of accepted papers, clear accept", "3: Marginally above acceptance threshold", "2: Marginally below acceptance threshold", "1: Strong rejection"], "required": true}, "confidence": {"order": 4, "value-radio": ["3: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "2: The reviewer is fairly confident that the evaluation is correct", "1: The reviewer's evaluation is an educated guess"], "required": true}}}, "tcdate": 1553713416328, "tmdate": 1555511826549, "readers": ["everyone"], "writers": ["ICLR.cc/2019/Workshop/LLD"], "invitees": ["ICLR.cc/2019/Workshop/LLD/Paper34/Reviewers"], "signatures": ["ICLR.cc/2019/Workshop/LLD"]}}}, {"id": "ryeQgHNaYV", "original": null, "number": 2, "cdate": 1555018986680, "ddate": null, "tcdate": 1555018986680, "tmdate": 1555511877373, "tddate": null, "forum": "rJlzbihzdE", "replyto": "rJlzbihzdE", "invitation": "ICLR.cc/2019/Workshop/LLD/-/Paper34/Official_Review", "content": {"title": "This in an interesting simple extension, results seem promising, but very preliminary", "review": "The paper introduces a simple extension of first-order MAML/Reptile algorithm. It proposes to stop the inner loop if the magnitude of the update does not exceed a certain threshold. Exprerimentation looks promising, although confusing. It is not clear why Table 1 accuracies are different from Table 2. For Table 2 it makes sense to demonstrate learning curves to emphasize the convergence speed. Metalearning algorithms are known to have high variance, so it makes sense to report error bars across multiple seeds.\n\nAll in all, the idea to improve the convergence is worth exploring and interesting to discuss, but the paper is a bit raw.", "rating": "3: Marginally above acceptance threshold", "confidence": "2: The reviewer is fairly confident that the evaluation is correct"}, "signatures": ["ICLR.cc/2019/Workshop/LLD/Paper34/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Workshop/LLD/Paper34/AnonReviewer2"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Enhancing Generalization of First-Order Meta-Learning", "authors": ["Mirantha Jayathilaka"], "authorids": ["mirantha.jayathilaka@manchester.ac.uk"], "keywords": ["meta-learning", "generalization", "few-shot learning"], "TL;DR": "The study introduces two approaches to enhance generalization of first-order meta-learning and presents empirical evaluation on few-shot image classification.", "abstract": "In this study we focus on first-order meta-learning algorithms that aim to learn a parameter initialization of a network which can quickly adapt to new concepts, given a few examples. We investigate two approaches to enhance generalization and speed of learning of such algorithms, particularly expanding on the Reptile (Nichol et al., 2018) algorithm. We introduce a novel regularization technique called meta-step gradient pruning and also investigate the effects of increasing the depth of network architectures in first-order meta-learning. We present an empirical evaluation of both approaches, where we match benchmark few-shot image classification results with 10 times fewer iterations using Mini-ImageNet dataset and with the use of deeper networks, we attain accuracies that surpass the current benchmarks of few-shot image classification using Omniglot dataset.", "pdf": "/pdf/4375b11693ba8d020e04136041419f1714153837.pdf", "paperhash": "jayathilaka|enhancing_generalization_of_firstorder_metalearning"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Workshop/LLD/-/Paper34/Official_Review", "cdate": 1553713416328, "expdate": 1555718400000, "duedate": 1554681600000, "reply": {"forum": "rJlzbihzdE", "replyto": "rJlzbihzdE", "writers": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2019/Workshop/LLD/Paper34/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2019/Workshop/LLD/Paper34/AnonReviewer[0-9]+"}, "readers": {"values": ["everyone"], "description": "The users who will be allowed to read the above content."}, "content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "required": true}, "rating": {"order": 3, "value-dropdown": ["5: Top 15% of accepted papers, strong accept", "4: Top 50% of accepted papers, clear accept", "3: Marginally above acceptance threshold", "2: Marginally below acceptance threshold", "1: Strong rejection"], "required": true}, "confidence": {"order": 4, "value-radio": ["3: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "2: The reviewer is fairly confident that the evaluation is correct", "1: The reviewer's evaluation is an educated guess"], "required": true}}}, "tcdate": 1553713416328, "tmdate": 1555511826549, "readers": ["everyone"], "writers": ["ICLR.cc/2019/Workshop/LLD"], "invitees": ["ICLR.cc/2019/Workshop/LLD/Paper34/Reviewers"], "signatures": ["ICLR.cc/2019/Workshop/LLD"]}}}, {"id": "HJeu2gaf9N", "original": null, "number": 1, "cdate": 1555382448271, "ddate": null, "tcdate": 1555382448271, "tmdate": 1555510973814, "tddate": null, "forum": "rJlzbihzdE", "replyto": "rJlzbihzdE", "invitation": "ICLR.cc/2019/Workshop/LLD/-/Paper34/Decision", "content": {"title": "Acceptance Decision", "decision": "Accept"}, "signatures": ["ICLR.cc/2019/Workshop/LLD/Program_Chairs"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Workshop/LLD/Program_Chairs"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Enhancing Generalization of First-Order Meta-Learning", "authors": ["Mirantha Jayathilaka"], "authorids": ["mirantha.jayathilaka@manchester.ac.uk"], "keywords": ["meta-learning", "generalization", "few-shot learning"], "TL;DR": "The study introduces two approaches to enhance generalization of first-order meta-learning and presents empirical evaluation on few-shot image classification.", "abstract": "In this study we focus on first-order meta-learning algorithms that aim to learn a parameter initialization of a network which can quickly adapt to new concepts, given a few examples. We investigate two approaches to enhance generalization and speed of learning of such algorithms, particularly expanding on the Reptile (Nichol et al., 2018) algorithm. We introduce a novel regularization technique called meta-step gradient pruning and also investigate the effects of increasing the depth of network architectures in first-order meta-learning. We present an empirical evaluation of both approaches, where we match benchmark few-shot image classification results with 10 times fewer iterations using Mini-ImageNet dataset and with the use of deeper networks, we attain accuracies that surpass the current benchmarks of few-shot image classification using Omniglot dataset.", "pdf": "/pdf/4375b11693ba8d020e04136041419f1714153837.pdf", "paperhash": "jayathilaka|enhancing_generalization_of_firstorder_metalearning"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Workshop/LLD/-/Paper34/Decision", "cdate": 1554736077776, "reply": {"forum": "rJlzbihzdE", "replyto": "rJlzbihzdE", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-regex": ["ICLR.cc/2019/Workshop/LLD/Program_Chairs"], "description": "How your identity will be displayed."}, "signatures": {"values": ["ICLR.cc/2019/Workshop/LLD/Program_Chairs"], "description": "How your identity will be displayed."}, "content": {"title": {"order": 1, "required": true, "value": "Acceptance Decision"}, "decision": {"order": 2, "required": true, "value-radio": ["Accept", "Reject"], "description": "Acceptance decision"}, "comment": {"order": 3, "required": false, "value-regex": "[\\S\\s]{0,5000}", "description": ""}}}, "tcdate": 1554736077776, "tmdate": 1555510961065, "readers": ["everyone"], "writers": ["ICLR.cc/2019/Workshop/LLD"], "invitees": ["ICLR.cc/2019/Workshop/LLD/Program_Chairs"], "signatures": ["ICLR.cc/2019/Workshop/LLD"]}}}], "count": 4}