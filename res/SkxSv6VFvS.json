{"notes": [{"id": "SkxYphBsir", "original": null, "number": 7, "cdate": 1573768384583, "ddate": null, "tcdate": 1573768384583, "tmdate": 1586062496696, "tddate": null, "forum": "SkxSv6VFvS", "replyto": "SkxSv6VFvS", "invitation": "ICLR.cc/2020/Conference/Paper594/-/Official_Comment", "content": {"title": "Paper updated with more details in the Appendix", "comment": "We have updated our paper during the rebuttal session to include more details regarding to \n    + implementation of the operators (Appendix A), \n    + model specifics we used for experiments (Appendix B),\n    + and more visualization of ERFs under different forms of object deformation (Appendix C).\n\nWe will make our code publicly available. Thank all for suggestions."}, "signatures": ["ICLR.cc/2020/Conference/Paper594/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper594/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Deformable Kernels: Adapting Effective Receptive Fields for Object Deformation", "authors": ["Hang Gao", "Xizhou Zhu", "Stephen Lin", "Jifeng Dai"], "authorids": ["hangg@berkeley.edu", "ezra0408@mail.ustc.edu.cn", "stevelin@microsoft.com", "jifdai@microsoft.com"], "keywords": ["Effective Receptive Fields", "Deformation Modeling", "Dynamic Inference"], "TL;DR": "Don't deform your convolutions -- deform your kernels.", "abstract": "Convolutional networks are not aware of an object's geometric variations, which leads to inefficient utilization of model and data capacity. To overcome this issue, recent works on deformation modeling seek to spatially reconfigure the data towards a common arrangement such that semantic recognition suffers less from deformation. This is typically done by augmenting static operators with learned free-form sampling grids in the image space, dynamically tuned to the data and task for adapting the receptive field. Yet adapting the receptive field does not quite reach the actual goal -- what really matters to the network is the *effective* receptive field (ERF), which reflects how much each pixel contributes. It is thus natural to design other approaches to adapt the ERF directly during runtime. In this work, we instantiate one possible solution as Deformable Kernels (DKs), a family of novel and generic convolutional operators for handling object deformations by directly adapting the ERF while leaving the receptive field untouched. At the heart of our method is the ability to resample the original kernel space towards recovering the deformation of objects. This approach is justified with theoretical insights that the ERF is strictly determined by data sampling locations and kernel values. We implement DKs as generic drop-in replacements of rigid kernels and conduct a series of empirical studies whose results conform with our theories. Over several tasks and standard base models, our approach compares favorably against prior works that adapt during runtime. In addition, further experiments suggest a working mechanism orthogonal and complementary to previous works.", "pdf": "/pdf/40aff08bc4a8149bdd5dd4b58a2fac68b78c7c8f.pdf", "paperhash": "gao|deformable_kernels_adapting_effective_receptive_fields_for_object_deformation", "code": "https://github.com/hangg7/deformable-kernels/", "_bibtex": "@inproceedings{\nGao2020Deformable,\ntitle={Deformable Kernels: Adapting Effective Receptive Fields for Object Deformation},\nauthor={Hang Gao and Xizhou Zhu and Stephen Lin and Jifeng Dai},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=SkxSv6VFvS}\n}", "full_presentation_video": "", "original_pdf": "/attachment/df2a72d34c76d6b88b15e776e4954c317bdfca47.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "SkxSv6VFvS", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper594/Authors", "ICLR.cc/2020/Conference/Paper594/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper594/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper594/Reviewers", "ICLR.cc/2020/Conference/Paper594/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper594/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper594/Authors|ICLR.cc/2020/Conference/Paper594/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504169119, "tmdate": 1576860532152, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper594/Authors", "ICLR.cc/2020/Conference/Paper594/Reviewers", "ICLR.cc/2020/Conference/Paper594/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper594/-/Official_Comment"}}}, {"id": "SkxSv6VFvS", "original": "ByeoW09PvH", "number": 594, "cdate": 1569439068735, "ddate": null, "tcdate": 1569439068735, "tmdate": 1583912043237, "tddate": null, "forum": "SkxSv6VFvS", "replyto": null, "invitation": "ICLR.cc/2020/Conference/-/Blind_Submission", "content": {"title": "Deformable Kernels: Adapting Effective Receptive Fields for Object Deformation", "authors": ["Hang Gao", "Xizhou Zhu", "Stephen Lin", "Jifeng Dai"], "authorids": ["hangg@berkeley.edu", "ezra0408@mail.ustc.edu.cn", "stevelin@microsoft.com", "jifdai@microsoft.com"], "keywords": ["Effective Receptive Fields", "Deformation Modeling", "Dynamic Inference"], "TL;DR": "Don't deform your convolutions -- deform your kernels.", "abstract": "Convolutional networks are not aware of an object's geometric variations, which leads to inefficient utilization of model and data capacity. To overcome this issue, recent works on deformation modeling seek to spatially reconfigure the data towards a common arrangement such that semantic recognition suffers less from deformation. This is typically done by augmenting static operators with learned free-form sampling grids in the image space, dynamically tuned to the data and task for adapting the receptive field. Yet adapting the receptive field does not quite reach the actual goal -- what really matters to the network is the *effective* receptive field (ERF), which reflects how much each pixel contributes. It is thus natural to design other approaches to adapt the ERF directly during runtime. In this work, we instantiate one possible solution as Deformable Kernels (DKs), a family of novel and generic convolutional operators for handling object deformations by directly adapting the ERF while leaving the receptive field untouched. At the heart of our method is the ability to resample the original kernel space towards recovering the deformation of objects. This approach is justified with theoretical insights that the ERF is strictly determined by data sampling locations and kernel values. We implement DKs as generic drop-in replacements of rigid kernels and conduct a series of empirical studies whose results conform with our theories. Over several tasks and standard base models, our approach compares favorably against prior works that adapt during runtime. In addition, further experiments suggest a working mechanism orthogonal and complementary to previous works.", "pdf": "/pdf/40aff08bc4a8149bdd5dd4b58a2fac68b78c7c8f.pdf", "paperhash": "gao|deformable_kernels_adapting_effective_receptive_fields_for_object_deformation", "code": "https://github.com/hangg7/deformable-kernels/", "_bibtex": "@inproceedings{\nGao2020Deformable,\ntitle={Deformable Kernels: Adapting Effective Receptive Fields for Object Deformation},\nauthor={Hang Gao and Xizhou Zhu and Stephen Lin and Jifeng Dai},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=SkxSv6VFvS}\n}", "full_presentation_video": "", "original_pdf": "/attachment/df2a72d34c76d6b88b15e776e4954c317bdfca47.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "signatures": ["ICLR.cc/2020/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference"], "details": {"replyCount": 8, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"reply": {"readers": {"values-regex": ".*"}, "writers": {"values": ["ICLR.cc/2020/Conference"]}, "signatures": {"values": ["ICLR.cc/2020/Conference"]}, "content": {"spotlight_video": {"value-regex": ".*"}, "full_presentation_video": {"value-regex": ".*"}, "original_pdf": {"required": false, "description": "Upload a PDF file that ends with .pdf", "value-regex": ".*"}, "appendix": {"value-regex": ".*"}, "authorids": {"values-regex": ".*"}, "poster": {"value-regex": ".*"}, "authors": {"values": ["Anonymous"]}, "slides": {"value-regex": ".*"}}}, "final": [], "signatures": ["ICLR.cc/2020/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference"], "noninvitees": [], "tcdate": 1569271260237, "tmdate": 1593459412141, "id": "ICLR.cc/2020/Conference/-/Blind_Submission"}}, "tauthor": "ICLR.cc/2020/Conference"}, {"id": "d0rnS5fOgH", "original": null, "number": 1, "cdate": 1576798700762, "ddate": null, "tcdate": 1576798700762, "tmdate": 1576800935190, "tddate": null, "forum": "SkxSv6VFvS", "replyto": "SkxSv6VFvS", "invitation": "ICLR.cc/2020/Conference/Paper594/-/Decision", "content": {"decision": "Accept (Poster)", "comment": "In my opinion, this paper is borderline (but my expertise is not in this area) and the reviewers are too uncertain to be of help in making an informed decision.", "title": "Paper Decision"}, "signatures": ["ICLR.cc/2020/Conference/Program_Chairs"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Program_Chairs"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Deformable Kernels: Adapting Effective Receptive Fields for Object Deformation", "authors": ["Hang Gao", "Xizhou Zhu", "Stephen Lin", "Jifeng Dai"], "authorids": ["hangg@berkeley.edu", "ezra0408@mail.ustc.edu.cn", "stevelin@microsoft.com", "jifdai@microsoft.com"], "keywords": ["Effective Receptive Fields", "Deformation Modeling", "Dynamic Inference"], "TL;DR": "Don't deform your convolutions -- deform your kernels.", "abstract": "Convolutional networks are not aware of an object's geometric variations, which leads to inefficient utilization of model and data capacity. To overcome this issue, recent works on deformation modeling seek to spatially reconfigure the data towards a common arrangement such that semantic recognition suffers less from deformation. This is typically done by augmenting static operators with learned free-form sampling grids in the image space, dynamically tuned to the data and task for adapting the receptive field. Yet adapting the receptive field does not quite reach the actual goal -- what really matters to the network is the *effective* receptive field (ERF), which reflects how much each pixel contributes. It is thus natural to design other approaches to adapt the ERF directly during runtime. In this work, we instantiate one possible solution as Deformable Kernels (DKs), a family of novel and generic convolutional operators for handling object deformations by directly adapting the ERF while leaving the receptive field untouched. At the heart of our method is the ability to resample the original kernel space towards recovering the deformation of objects. This approach is justified with theoretical insights that the ERF is strictly determined by data sampling locations and kernel values. We implement DKs as generic drop-in replacements of rigid kernels and conduct a series of empirical studies whose results conform with our theories. Over several tasks and standard base models, our approach compares favorably against prior works that adapt during runtime. In addition, further experiments suggest a working mechanism orthogonal and complementary to previous works.", "pdf": "/pdf/40aff08bc4a8149bdd5dd4b58a2fac68b78c7c8f.pdf", "paperhash": "gao|deformable_kernels_adapting_effective_receptive_fields_for_object_deformation", "code": "https://github.com/hangg7/deformable-kernels/", "_bibtex": "@inproceedings{\nGao2020Deformable,\ntitle={Deformable Kernels: Adapting Effective Receptive Fields for Object Deformation},\nauthor={Hang Gao and Xizhou Zhu and Stephen Lin and Jifeng Dai},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=SkxSv6VFvS}\n}", "full_presentation_video": "", "original_pdf": "/attachment/df2a72d34c76d6b88b15e776e4954c317bdfca47.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "tags": [], "invitation": {"reply": {"writers": {"description": "How your identity will be displayed.", "values-regex": ["ICLR.cc/2020/Conference/Program_Chairs"]}, "signatures": {"values": ["ICLR.cc/2020/Conference/Program_Chairs"], "description": "How your identity will be displayed."}, "content": {"decision": {"value-radio": ["Accept (Spotlight)", "Accept (Talk)", "Accept (Poster)", "Reject"], "description": "Decision", "required": true, "order": 2}, "title": {"value": "Paper Decision", "required": true, "order": 1}, "comment": {"value-regex": "[\\S\\s]{0,5000}", "description": "", "required": false, "order": 3}}, "forum": "SkxSv6VFvS", "replyto": "SkxSv6VFvS", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}}, "expdate": 1576854540000, "duedate": 1576853940000, "multiReply": false, "readers": ["everyone"], "invitees": ["ICLR.cc/2020/Conference/Program_Chairs"], "tcdate": 1576795713826, "tmdate": 1576800263524, "super": "ICLR.cc/2020/Conference/-/Decision", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper594/-/Decision"}}}, {"id": "SkxDm5xCYH", "original": null, "number": 1, "cdate": 1571846687353, "ddate": null, "tcdate": 1571846687353, "tmdate": 1575645094204, "tddate": null, "forum": "SkxSv6VFvS", "replyto": "SkxSv6VFvS", "invitation": "ICLR.cc/2020/Conference/Paper594/-/Official_Review", "content": {"experience_assessment": "I do not know much about this area.", "rating": "6: Weak Accept", "review_assessment:_checking_correctness_of_experiments": "N/A", "review_assessment:_thoroughness_in_paper_reading": "N/A", "title": "Official Blind Review #3", "review": "Updates:\nThanks for the updates and I appreciate the authors' effort in running new experiments, whose results are very interesting and inspiring to me.  \n\nMy score remains unchanged. The main reason is that I am not an expert in this subject.  \n \n\n--------------------------------------------\nTraditional convolution neural networks are not aware of object\u2019s geometric variations (i.e. rotation), while human being are very good at abstracting out such variation. \nIn this paper, the authors propose an approach known as DKs (deformation kernels) to overcome such issues. The high level picture is make the convolutional filter data dependable. For convnets, the filter is independent of the data. To make it data dependent (potentially able to detect the objects geometric information), DKs first initialize a larger filter (say 9 * 9) that is universal to all inputs and then `subsampling` a smaller filter (say 3 *3), the `subsampling` strategy is input dependent and also learnable (similar to attention mechanism.) \n\nI do not have much background in this field, but I found the ideas of DKs very interesting and novel (assuming this is the first work to make the filter data dependent and learnable.)  I lean to a weakly accept. \n\nMinor Comments: \n1. Below equation (1). Z  -> Z^2; above (1) : j \\in R^2  -> Z^2   \n2. above (5) as a composition --> as a sum ?? \n3. can you elaborate on 'In practice, we use the bilinear sampling operator to interpolate within the discrete kernel grid.' In particular, how the `smalle`r kernel is learned/subsampled from the larger kernel? (i.e. how \\Delta k is learned?) \n\nMore interesting experiments? \n1. Compare performance of the two methods below:   \n a. standard architectures using data deformation (translation, rotation, dilation)\n b. DKs without applying data deformation. \n2. Figure 4.  Could you produce plots similar to the setting of figure 1., i.e. rotate / dilate the images. Showing that DKs could effectively capture such deformation.  \n\n", "review_assessment:_checking_correctness_of_derivations_and_theory": "N/A"}, "signatures": ["ICLR.cc/2020/Conference/Paper594/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper594/AnonReviewer3"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Deformable Kernels: Adapting Effective Receptive Fields for Object Deformation", "authors": ["Hang Gao", "Xizhou Zhu", "Stephen Lin", "Jifeng Dai"], "authorids": ["hangg@berkeley.edu", "ezra0408@mail.ustc.edu.cn", "stevelin@microsoft.com", "jifdai@microsoft.com"], "keywords": ["Effective Receptive Fields", "Deformation Modeling", "Dynamic Inference"], "TL;DR": "Don't deform your convolutions -- deform your kernels.", "abstract": "Convolutional networks are not aware of an object's geometric variations, which leads to inefficient utilization of model and data capacity. To overcome this issue, recent works on deformation modeling seek to spatially reconfigure the data towards a common arrangement such that semantic recognition suffers less from deformation. This is typically done by augmenting static operators with learned free-form sampling grids in the image space, dynamically tuned to the data and task for adapting the receptive field. Yet adapting the receptive field does not quite reach the actual goal -- what really matters to the network is the *effective* receptive field (ERF), which reflects how much each pixel contributes. It is thus natural to design other approaches to adapt the ERF directly during runtime. In this work, we instantiate one possible solution as Deformable Kernels (DKs), a family of novel and generic convolutional operators for handling object deformations by directly adapting the ERF while leaving the receptive field untouched. At the heart of our method is the ability to resample the original kernel space towards recovering the deformation of objects. This approach is justified with theoretical insights that the ERF is strictly determined by data sampling locations and kernel values. We implement DKs as generic drop-in replacements of rigid kernels and conduct a series of empirical studies whose results conform with our theories. Over several tasks and standard base models, our approach compares favorably against prior works that adapt during runtime. In addition, further experiments suggest a working mechanism orthogonal and complementary to previous works.", "pdf": "/pdf/40aff08bc4a8149bdd5dd4b58a2fac68b78c7c8f.pdf", "paperhash": "gao|deformable_kernels_adapting_effective_receptive_fields_for_object_deformation", "code": "https://github.com/hangg7/deformable-kernels/", "_bibtex": "@inproceedings{\nGao2020Deformable,\ntitle={Deformable Kernels: Adapting Effective Receptive Fields for Object Deformation},\nauthor={Hang Gao and Xizhou Zhu and Stephen Lin and Jifeng Dai},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=SkxSv6VFvS}\n}", "full_presentation_video": "", "original_pdf": "/attachment/df2a72d34c76d6b88b15e776e4954c317bdfca47.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "SkxSv6VFvS", "replyto": "SkxSv6VFvS", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper594/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper594/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1576072419309, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper594/Reviewers"], "noninvitees": [], "tcdate": 1570237749883, "tmdate": 1576072419322, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper594/-/Official_Review"}}}, {"id": "SkgzaqHjir", "original": null, "number": 6, "cdate": 1573767866251, "ddate": null, "tcdate": 1573767866251, "tmdate": 1573843752493, "tddate": null, "forum": "SkxSv6VFvS", "replyto": "SkxDm5xCYH", "invitation": "ICLR.cc/2020/Conference/Paper594/-/Official_Comment", "content": {"title": "Response to Reviewer 3", "comment": "Thanks for your review and suggestion to improve our work. Before we step forward to answer your questions, we want to first clarify on your comment \u201cassuming this is the first work to make the filter data-dependent and learnable\u201c. This is unfortunately not true. As we mentioned in Section 2 (or more specifically, the \u201cDynamic Inference\u201c subsection), there are works that \u201cadapt convolutional kernels at runtime\u201c and \u201ccan learn and infer customized kernel spaces with respect to the data\u201c. Our DKs differ from these works with the emphasis on directly adapting ERFs by spatial subsampling. We also compared with one method from such line of works, i.e., Conditional Convolutions [Yang et al., 2019], which is referred to as SCC in our experiments. Figure 3 shows that the dynamics of SCC are closer to semantics, while our DKs learn dynamics that are significantly related to scales. We will underscore the difference between our DKs and previous works from Dynamic Inference in our next revision.\n \n----------\nQ1. \u201cAbove (5) as a composition --> as a sum?? \u201d\nA1. The term \u201ccomposition\u201c may be ambiguous here and lead to confusion. In fact, a KxK kernel can be deemed as a sum of $K^2$ shifted 1x1 kernels according to its kernel position. We will make this point clearer and rewrite this specific sentence in our next version.\n\n----------\nQ2. \u201cHow is the 'smaller' kernel learned/subsampled from the larger kernel? (i.e., how is $\\Delta k$ learned?)\u201d\nA2. In a nutshell, we follow a very similar computational flow as in Deformable Convolutions [Dai et al., 2017; Zhu et al., 2019]. We have added a new section in Appendix A to resolve your concern -- hopefully, it could help make things clearer. Meanwhile, R2 has similar concerns regarding our implementation of DK. Please refer to our response to R2-A2 for more details as well.\n \n----------\nQ3. \u201cMore interesting experiments?\u201d\n\nQ3(1). \u201cStandard architectures using data deformation (translation, rotation, dilation)\u201d\nA3(1). Thanks for your suggestion. And actually, our baselines on ImageNet (also as in the standard ImageNet training protocol) already use certain kinds of data deformation, such as random cropped resizing that simulate scaling and shifting deformation.\n\nQ3(2). \u201cDKs without applying data deformation.\u201d\nA3(2). Thanks for your suggestion. Yet we want to argue that the experiments without applying data augmentation actually cannot provide much insight. Since training on ImageNet with scaling data augmentation is crucial for high accuracy, the result of DKs without such augmentation is predictable to be much worse. Yet this does not necessarily mean that our DKs cannot learn deformation modalities. On the other hand, also because of the optimization problem we mentioned in R2-A3, our DKs still need a lot of data capacity to learn good adaptation of object deformations. We deem our DKs as a probe to enable convolutions to explicitly model deformation. However, to make them work nicely in practice, practitioners need good training strategies, and applying data deformation is one of them.\n\nQ3(3). \u201cCould you produce plots similar to the setting of Figure 1.\u201d\nA3(3). We add a new plot in Figure 6 (Appendix C) to compare rigid kernels and our DKs under rotation and scaling conditions, respectively. Our DKs can learn persistent feature encoding of images that is not sensitive to data deformation.\n"}, "signatures": ["ICLR.cc/2020/Conference/Paper594/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper594/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Deformable Kernels: Adapting Effective Receptive Fields for Object Deformation", "authors": ["Hang Gao", "Xizhou Zhu", "Stephen Lin", "Jifeng Dai"], "authorids": ["hangg@berkeley.edu", "ezra0408@mail.ustc.edu.cn", "stevelin@microsoft.com", "jifdai@microsoft.com"], "keywords": ["Effective Receptive Fields", "Deformation Modeling", "Dynamic Inference"], "TL;DR": "Don't deform your convolutions -- deform your kernels.", "abstract": "Convolutional networks are not aware of an object's geometric variations, which leads to inefficient utilization of model and data capacity. To overcome this issue, recent works on deformation modeling seek to spatially reconfigure the data towards a common arrangement such that semantic recognition suffers less from deformation. This is typically done by augmenting static operators with learned free-form sampling grids in the image space, dynamically tuned to the data and task for adapting the receptive field. Yet adapting the receptive field does not quite reach the actual goal -- what really matters to the network is the *effective* receptive field (ERF), which reflects how much each pixel contributes. It is thus natural to design other approaches to adapt the ERF directly during runtime. In this work, we instantiate one possible solution as Deformable Kernels (DKs), a family of novel and generic convolutional operators for handling object deformations by directly adapting the ERF while leaving the receptive field untouched. At the heart of our method is the ability to resample the original kernel space towards recovering the deformation of objects. This approach is justified with theoretical insights that the ERF is strictly determined by data sampling locations and kernel values. We implement DKs as generic drop-in replacements of rigid kernels and conduct a series of empirical studies whose results conform with our theories. Over several tasks and standard base models, our approach compares favorably against prior works that adapt during runtime. In addition, further experiments suggest a working mechanism orthogonal and complementary to previous works.", "pdf": "/pdf/40aff08bc4a8149bdd5dd4b58a2fac68b78c7c8f.pdf", "paperhash": "gao|deformable_kernels_adapting_effective_receptive_fields_for_object_deformation", "code": "https://github.com/hangg7/deformable-kernels/", "_bibtex": "@inproceedings{\nGao2020Deformable,\ntitle={Deformable Kernels: Adapting Effective Receptive Fields for Object Deformation},\nauthor={Hang Gao and Xizhou Zhu and Stephen Lin and Jifeng Dai},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=SkxSv6VFvS}\n}", "full_presentation_video": "", "original_pdf": "/attachment/df2a72d34c76d6b88b15e776e4954c317bdfca47.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "SkxSv6VFvS", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper594/Authors", "ICLR.cc/2020/Conference/Paper594/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper594/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper594/Reviewers", "ICLR.cc/2020/Conference/Paper594/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper594/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper594/Authors|ICLR.cc/2020/Conference/Paper594/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504169119, "tmdate": 1576860532152, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper594/Authors", "ICLR.cc/2020/Conference/Paper594/Reviewers", "ICLR.cc/2020/Conference/Paper594/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper594/-/Official_Comment"}}}, {"id": "SJgy9-BisB", "original": null, "number": 4, "cdate": 1573765511110, "ddate": null, "tcdate": 1573765511110, "tmdate": 1573843637183, "tddate": null, "forum": "SkxSv6VFvS", "replyto": "H1eXSFlSqr", "invitation": "ICLR.cc/2020/Conference/Paper594/-/Official_Comment", "content": {"title": "Response to Reviewer 1", "comment": " Thanks for your review and comments. We here clarify to each of your inquiries accordingly:\n\n----------\nQ1. \u201cNovelty compared to previous methods.\u201d\nA1. Our novelty is mainly threefold: \n    + the observation that, while most current deformation modeling approaches [Dai et al. 2017; Zhu et al., 2019], as well as some dynamic inference approaches [Li et al., 2019; Shelhamer et al., 2019], adapt the convolutional Receptive Field (RF) during runtime, the ultimate goal should actually be to manipulate the Effective Receptive Field (ERF) instead. This discrepancy motivates us to look closer at what factors control ERF.\n    + the insight and analysis of factors that *directly* control ERF \u2014 i.e., data sampling locations & kernel values \u2014 on top of and beyond the original proposal by Luo et al., 2016, which emphasizes expectation cases that cannot be leveraged to manipulate ERF arbitrarily (say 2x bigger). To the best of our knowledge, our paper is the first work that systematically discusses how we can actively manipulate ERF during runtime.\n    + a new family of convolutional operators, namely Deformable Kernel (DK), that leverages our theory to manipulate ERFs. In the range of possible designs that our theory suggests, we choose one for which it is possible to adapt the ERF without touching the RF in general -- strickly different from what Deformable Convolution (DC) [Dai et al. 2017; Zhu et al., 2019] does. We also prove with thorough experiments and qualitative insights that our DK can indeed help to model object deformations.\n\nTo be more specific, we deem DC as our \u201cnearest neighbor\u201c with respect to both general purpose and computational form. The main difference between DC and our DK is that, for each convolution, DC learns to sample the data space (see Equation 9, so as to change RF as well), while our DK learns to sample the kernel space (see Equation 7, so as to not change RF at all). Empirically we show that such a simple difference leads to different characteristics in practice. For example, visualization of ERFs learned by both operators (Figure 4b & 4c) shows that DCs encourage ERFs to spread out and have sparse responses while DKs tend to make them concentrated and densely activated within an object region.\n\n---------- \nQ2. \u201cWhat does DK learn and why is it different from what DC learns?\u201d\nA2. In Figure 3b, we show t-SNE results of learned dynamics (or kernel sampling offsets) from our local DK operators, and they are significantly related to scale -- one of the most common forms of object deformation in 2D space. \n\nIn Figure 6 (Appendix C), we provide new experimental results to show that ERFs learned by DKs are nearly equivariant to rotation (-90\u00b0) and scaling (1.5x). Note that similar properties are also observed in DCs [Zhu et al., 2019] (see their Figure 5). So to answer your second question: what DK learns is very similar to what DC learns, even though computationally, they have different behaviors. And in fact, this is also our initial design intention, since being able to persistently fire to an object\u2019s semantics rather than its possible geometric configuration is one of the most straightforward ways of dealing with deformation.\n"}, "signatures": ["ICLR.cc/2020/Conference/Paper594/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper594/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Deformable Kernels: Adapting Effective Receptive Fields for Object Deformation", "authors": ["Hang Gao", "Xizhou Zhu", "Stephen Lin", "Jifeng Dai"], "authorids": ["hangg@berkeley.edu", "ezra0408@mail.ustc.edu.cn", "stevelin@microsoft.com", "jifdai@microsoft.com"], "keywords": ["Effective Receptive Fields", "Deformation Modeling", "Dynamic Inference"], "TL;DR": "Don't deform your convolutions -- deform your kernels.", "abstract": "Convolutional networks are not aware of an object's geometric variations, which leads to inefficient utilization of model and data capacity. To overcome this issue, recent works on deformation modeling seek to spatially reconfigure the data towards a common arrangement such that semantic recognition suffers less from deformation. This is typically done by augmenting static operators with learned free-form sampling grids in the image space, dynamically tuned to the data and task for adapting the receptive field. Yet adapting the receptive field does not quite reach the actual goal -- what really matters to the network is the *effective* receptive field (ERF), which reflects how much each pixel contributes. It is thus natural to design other approaches to adapt the ERF directly during runtime. In this work, we instantiate one possible solution as Deformable Kernels (DKs), a family of novel and generic convolutional operators for handling object deformations by directly adapting the ERF while leaving the receptive field untouched. At the heart of our method is the ability to resample the original kernel space towards recovering the deformation of objects. This approach is justified with theoretical insights that the ERF is strictly determined by data sampling locations and kernel values. We implement DKs as generic drop-in replacements of rigid kernels and conduct a series of empirical studies whose results conform with our theories. Over several tasks and standard base models, our approach compares favorably against prior works that adapt during runtime. In addition, further experiments suggest a working mechanism orthogonal and complementary to previous works.", "pdf": "/pdf/40aff08bc4a8149bdd5dd4b58a2fac68b78c7c8f.pdf", "paperhash": "gao|deformable_kernels_adapting_effective_receptive_fields_for_object_deformation", "code": "https://github.com/hangg7/deformable-kernels/", "_bibtex": "@inproceedings{\nGao2020Deformable,\ntitle={Deformable Kernels: Adapting Effective Receptive Fields for Object Deformation},\nauthor={Hang Gao and Xizhou Zhu and Stephen Lin and Jifeng Dai},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=SkxSv6VFvS}\n}", "full_presentation_video": "", "original_pdf": "/attachment/df2a72d34c76d6b88b15e776e4954c317bdfca47.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "SkxSv6VFvS", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper594/Authors", "ICLR.cc/2020/Conference/Paper594/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper594/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper594/Reviewers", "ICLR.cc/2020/Conference/Paper594/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper594/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper594/Authors|ICLR.cc/2020/Conference/Paper594/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504169119, "tmdate": 1576860532152, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper594/Authors", "ICLR.cc/2020/Conference/Paper594/Reviewers", "ICLR.cc/2020/Conference/Paper594/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper594/-/Official_Comment"}}}, {"id": "Bkgp-8SsiH", "original": null, "number": 5, "cdate": 1573766660695, "ddate": null, "tcdate": 1573766660695, "tmdate": 1573766660695, "tddate": null, "forum": "SkxSv6VFvS", "replyto": "H1guw8eW9S", "invitation": "ICLR.cc/2020/Conference/Paper594/-/Official_Comment", "content": {"title": "Response to Reviewer 2", "comment": "We would like to thank you for your constructive comments, and please see below our response to each of your concerns.\n\n----------\nQ1. \u201cUnfortunately the authors get hand-wavy when in Sec 3.2, they claim that the idea of subsampling kernels 'roughly generalizes' to non-linear networks. I don't see how they can generalize what they present beyond piece-wise linear networks.\u201d\nA1. To our understanding, ReLU networks are the piece-wise linear networks that you may be referring to. If so, that is indeed the case -- our current analysis can only generalize to ReLU networks, but not to other non-linear networks. However, it should be noted that since most of the currently prevalent models are actual ReLU networks, our analysis is broadly applicable. On the other hand, for other non-linear networks, the $C^{(n)}$ term in the equation at the end of Page 4 would become a cumulative product of corresponding non-linear activation derivatives, which is not simply a binary switch and thus hard to analysis. We will revise this part as well as make our point clearer in the next version. Thanks for your suggestion.\n\n---------- \nQ2. \u201cIt is not entirely clear how the offset predictors are trained, how exactly the sampling is used, details of architecture, etc.\u201d\nA2. We follow Deformable Convolution (DC) [Dai et al., 2017; Zhu et al., 2019] on computing kernel offsets. For each input feature map of Deformable Kernel (DK), we use a 3x3 convolution with 18 dimensional output (3x3 points with x and y coordinate offsets) to generate the kernel offsets. Since our offsets are not integers, we use a differentiable bilinear sampling to sample kernels from non-integer coordinates (see Appendix A for detailed illustration on the forward and backward passes). On the other hand, our base network architectures are just modified ResNet (what we call ResNet-50-DW) and MobileNet-V2, respectively. To make this point clearer, we add more details in Table 5 of Appendix B. For all the experiments, we replace convolutions in each Residual Block with DKs, as discussed in Section 4.\n \n----------\nQ3. \u201cThe finding that kernel sizes beyond 4x4 don't seem to offer any benefit makes the idea practically questionable.\u201d\nA3. Indeed, intuitively, with a higher resolution of kernel space (what we called \u201cscope size\u201c), our bilinear sampler for generating kernel values should yield a better approximation of latent kernel values at given coordinates. Yet in practice, we observe the performance saturate at 4x4 scope size. We speculate that this issue may stem from the side of optimization: consider sampling a 3x3 kernel from a 9x9 kernel space; to learn a good 9x9 kernel space, it is reasonable to assume each specific kernel value shall consume a certain amount of data. Since our gradient is either sparse -- not all kernel values in the 9x9 space will get the gradient as opposed to rigid kernels, DKs will roughly require 9 = (9 x 9) / (3 x 3) times more data. In practice, this indicates that some of the kernels cannot be trained sufficiently, which can partly explain the phenomenon we have observed."}, "signatures": ["ICLR.cc/2020/Conference/Paper594/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper594/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Deformable Kernels: Adapting Effective Receptive Fields for Object Deformation", "authors": ["Hang Gao", "Xizhou Zhu", "Stephen Lin", "Jifeng Dai"], "authorids": ["hangg@berkeley.edu", "ezra0408@mail.ustc.edu.cn", "stevelin@microsoft.com", "jifdai@microsoft.com"], "keywords": ["Effective Receptive Fields", "Deformation Modeling", "Dynamic Inference"], "TL;DR": "Don't deform your convolutions -- deform your kernels.", "abstract": "Convolutional networks are not aware of an object's geometric variations, which leads to inefficient utilization of model and data capacity. To overcome this issue, recent works on deformation modeling seek to spatially reconfigure the data towards a common arrangement such that semantic recognition suffers less from deformation. This is typically done by augmenting static operators with learned free-form sampling grids in the image space, dynamically tuned to the data and task for adapting the receptive field. Yet adapting the receptive field does not quite reach the actual goal -- what really matters to the network is the *effective* receptive field (ERF), which reflects how much each pixel contributes. It is thus natural to design other approaches to adapt the ERF directly during runtime. In this work, we instantiate one possible solution as Deformable Kernels (DKs), a family of novel and generic convolutional operators for handling object deformations by directly adapting the ERF while leaving the receptive field untouched. At the heart of our method is the ability to resample the original kernel space towards recovering the deformation of objects. This approach is justified with theoretical insights that the ERF is strictly determined by data sampling locations and kernel values. We implement DKs as generic drop-in replacements of rigid kernels and conduct a series of empirical studies whose results conform with our theories. Over several tasks and standard base models, our approach compares favorably against prior works that adapt during runtime. In addition, further experiments suggest a working mechanism orthogonal and complementary to previous works.", "pdf": "/pdf/40aff08bc4a8149bdd5dd4b58a2fac68b78c7c8f.pdf", "paperhash": "gao|deformable_kernels_adapting_effective_receptive_fields_for_object_deformation", "code": "https://github.com/hangg7/deformable-kernels/", "_bibtex": "@inproceedings{\nGao2020Deformable,\ntitle={Deformable Kernels: Adapting Effective Receptive Fields for Object Deformation},\nauthor={Hang Gao and Xizhou Zhu and Stephen Lin and Jifeng Dai},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=SkxSv6VFvS}\n}", "full_presentation_video": "", "original_pdf": "/attachment/df2a72d34c76d6b88b15e776e4954c317bdfca47.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "SkxSv6VFvS", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper594/Authors", "ICLR.cc/2020/Conference/Paper594/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper594/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper594/Reviewers", "ICLR.cc/2020/Conference/Paper594/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper594/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper594/Authors|ICLR.cc/2020/Conference/Paper594/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504169119, "tmdate": 1576860532152, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper594/Authors", "ICLR.cc/2020/Conference/Paper594/Reviewers", "ICLR.cc/2020/Conference/Paper594/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper594/-/Official_Comment"}}}, {"id": "H1guw8eW9S", "original": null, "number": 2, "cdate": 1572042336324, "ddate": null, "tcdate": 1572042336324, "tmdate": 1572972575921, "tddate": null, "forum": "SkxSv6VFvS", "replyto": "SkxSv6VFvS", "invitation": "ICLR.cc/2020/Conference/Paper594/-/Official_Review", "content": {"experience_assessment": "I do not know much about this area.", "rating": "6: Weak Accept", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #2", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "This work presents the idea of deformable kernels (DKs). As opposed to rigid kernels in standard convolutional networks, DKs allow each of their grid locations to be moved around in a larger kernel field. The offset by which a DK grid cell is moved is computed conditioned on the input to the network. To motivate the idea of DKs, the authors give some background on convolution, receptive and effective receptive fields (ERFs). The authors argue that since ERFs are spatially porous and irregularly distributed, one way to model them is to convolve square grids of input with DKs, which are composed of samples drawn from larger kernels. The authors define the concept of global and local DKs. They further contrast DKs with spatial sampling (deformable convolutions) and argue that although conceptually similar, both approaches are complementary to each other and can be used in combination in practice. Numerical experiments show competitive performance of DKs on image classification and object detection tasks. In the end empirical analysis is performed to analyze the characteristics of DKs.\n\nI am unfamiliar with prior work in this direction, but the idea of DKs seems to be conceptually appealing and as the authors point-out, their approach can be seen as an alternative to spatial sampling for modeling deformations. Unfortunately the authors get hand-wavy when in Sec 3.2, they claim that the idea of subsampling kernels \"roughly generalizes\" to non-linear networks. I don't see how they can generalize what they present beyond piece-wise linear networks. I appreciate the effort to give a background on ERFs and describe (local and global) DKs, but in my opinion, technical sections of the paper partly very obscure. For instance it is not entirely clear how the offset predictors are trained, how exactly the sampling is used, details of architecture etc. \n\nEmpirically the method does not seem to offer a significant performance boost. Also, while the authors sell the idea of subsampling kernels, but the finding that kernel sizes beyond 4x4 don't seem to offer any benefit make the idea practically questionable. \n\nThe idea of DKs seems relevant, but both conceptually and empirically it seems very close to deformable convolutions. The authors need to clearly present their work, including its shortcomings (i.e., generalization or not beyond linear networks)."}, "signatures": ["ICLR.cc/2020/Conference/Paper594/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper594/AnonReviewer2"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Deformable Kernels: Adapting Effective Receptive Fields for Object Deformation", "authors": ["Hang Gao", "Xizhou Zhu", "Stephen Lin", "Jifeng Dai"], "authorids": ["hangg@berkeley.edu", "ezra0408@mail.ustc.edu.cn", "stevelin@microsoft.com", "jifdai@microsoft.com"], "keywords": ["Effective Receptive Fields", "Deformation Modeling", "Dynamic Inference"], "TL;DR": "Don't deform your convolutions -- deform your kernels.", "abstract": "Convolutional networks are not aware of an object's geometric variations, which leads to inefficient utilization of model and data capacity. To overcome this issue, recent works on deformation modeling seek to spatially reconfigure the data towards a common arrangement such that semantic recognition suffers less from deformation. This is typically done by augmenting static operators with learned free-form sampling grids in the image space, dynamically tuned to the data and task for adapting the receptive field. Yet adapting the receptive field does not quite reach the actual goal -- what really matters to the network is the *effective* receptive field (ERF), which reflects how much each pixel contributes. It is thus natural to design other approaches to adapt the ERF directly during runtime. In this work, we instantiate one possible solution as Deformable Kernels (DKs), a family of novel and generic convolutional operators for handling object deformations by directly adapting the ERF while leaving the receptive field untouched. At the heart of our method is the ability to resample the original kernel space towards recovering the deformation of objects. This approach is justified with theoretical insights that the ERF is strictly determined by data sampling locations and kernel values. We implement DKs as generic drop-in replacements of rigid kernels and conduct a series of empirical studies whose results conform with our theories. Over several tasks and standard base models, our approach compares favorably against prior works that adapt during runtime. In addition, further experiments suggest a working mechanism orthogonal and complementary to previous works.", "pdf": "/pdf/40aff08bc4a8149bdd5dd4b58a2fac68b78c7c8f.pdf", "paperhash": "gao|deformable_kernels_adapting_effective_receptive_fields_for_object_deformation", "code": "https://github.com/hangg7/deformable-kernels/", "_bibtex": "@inproceedings{\nGao2020Deformable,\ntitle={Deformable Kernels: Adapting Effective Receptive Fields for Object Deformation},\nauthor={Hang Gao and Xizhou Zhu and Stephen Lin and Jifeng Dai},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=SkxSv6VFvS}\n}", "full_presentation_video": "", "original_pdf": "/attachment/df2a72d34c76d6b88b15e776e4954c317bdfca47.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "SkxSv6VFvS", "replyto": "SkxSv6VFvS", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper594/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper594/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1576072419309, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper594/Reviewers"], "noninvitees": [], "tcdate": 1570237749883, "tmdate": 1576072419322, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper594/-/Official_Review"}}}, {"id": "H1eXSFlSqr", "original": null, "number": 3, "cdate": 1572305211422, "ddate": null, "tcdate": 1572305211422, "tmdate": 1572972575879, "tddate": null, "forum": "SkxSv6VFvS", "replyto": "SkxSv6VFvS", "invitation": "ICLR.cc/2020/Conference/Paper594/-/Official_Review", "content": {"experience_assessment": "I do not know much about this area.", "rating": "6: Weak Accept", "review_assessment:_thoroughness_in_paper_reading": "N/A", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #1", "review_assessment:_checking_correctness_of_derivations_and_theory": "N/A", "review": "This paper introduce a simple algorithm called deformable kernels. It learns to generate a collection of coordinate offset \u0394k for each of the convolutional kernel element. Then during convolution, the kernel is treated as a 2D regular grid and sampled (interpolated) according to the generated coordinate offset before applying to the inputs. An auxiliary shallow network is learned to generate those coordinate offsets based in inputs. This method is very similar to the existing \"deformable convolution\" algorithm, though this operate on the kernels instead. Numerical experiments on image classification and object detection tasks show that the method performs better or comparably to strong baselines. It boost the performance even more when combined with existing methods.\n\nThis paper is relatively easy to follow and the ideas are simple and effective.\n\nMy main concern about this paper is the novelty given its similarity to the previous methods. Maybe it could improve if more and in-depth studies are shown that analyze what deformable kernel learns and why that is different from what deformable convolution learn. "}, "signatures": ["ICLR.cc/2020/Conference/Paper594/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper594/AnonReviewer1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Deformable Kernels: Adapting Effective Receptive Fields for Object Deformation", "authors": ["Hang Gao", "Xizhou Zhu", "Stephen Lin", "Jifeng Dai"], "authorids": ["hangg@berkeley.edu", "ezra0408@mail.ustc.edu.cn", "stevelin@microsoft.com", "jifdai@microsoft.com"], "keywords": ["Effective Receptive Fields", "Deformation Modeling", "Dynamic Inference"], "TL;DR": "Don't deform your convolutions -- deform your kernels.", "abstract": "Convolutional networks are not aware of an object's geometric variations, which leads to inefficient utilization of model and data capacity. To overcome this issue, recent works on deformation modeling seek to spatially reconfigure the data towards a common arrangement such that semantic recognition suffers less from deformation. This is typically done by augmenting static operators with learned free-form sampling grids in the image space, dynamically tuned to the data and task for adapting the receptive field. Yet adapting the receptive field does not quite reach the actual goal -- what really matters to the network is the *effective* receptive field (ERF), which reflects how much each pixel contributes. It is thus natural to design other approaches to adapt the ERF directly during runtime. In this work, we instantiate one possible solution as Deformable Kernels (DKs), a family of novel and generic convolutional operators for handling object deformations by directly adapting the ERF while leaving the receptive field untouched. At the heart of our method is the ability to resample the original kernel space towards recovering the deformation of objects. This approach is justified with theoretical insights that the ERF is strictly determined by data sampling locations and kernel values. We implement DKs as generic drop-in replacements of rigid kernels and conduct a series of empirical studies whose results conform with our theories. Over several tasks and standard base models, our approach compares favorably against prior works that adapt during runtime. In addition, further experiments suggest a working mechanism orthogonal and complementary to previous works.", "pdf": "/pdf/40aff08bc4a8149bdd5dd4b58a2fac68b78c7c8f.pdf", "paperhash": "gao|deformable_kernels_adapting_effective_receptive_fields_for_object_deformation", "code": "https://github.com/hangg7/deformable-kernels/", "_bibtex": "@inproceedings{\nGao2020Deformable,\ntitle={Deformable Kernels: Adapting Effective Receptive Fields for Object Deformation},\nauthor={Hang Gao and Xizhou Zhu and Stephen Lin and Jifeng Dai},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=SkxSv6VFvS}\n}", "full_presentation_video": "", "original_pdf": "/attachment/df2a72d34c76d6b88b15e776e4954c317bdfca47.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "SkxSv6VFvS", "replyto": "SkxSv6VFvS", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper594/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper594/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1576072419309, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper594/Reviewers"], "noninvitees": [], "tcdate": 1570237749883, "tmdate": 1576072419322, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper594/-/Official_Review"}}}], "count": 9}