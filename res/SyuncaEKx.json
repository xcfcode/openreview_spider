{"notes": [{"tddate": null, "ddate": null, "cdate": null, "original": null, "tmdate": 1490028606884, "tcdate": 1490028606884, "number": 1, "id": "BkPHOKaix", "invitation": "ICLR.cc/2017/workshop/-/paper112/acceptance", "forum": "SyuncaEKx", "replyto": "SyuncaEKx", "signatures": ["ICLR.cc/2017/pcs"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/pcs"], "content": {"decision": "Reject", "title": "ICLR committee final decision"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"TL;DR": "", "title": "Adversarial Autoencoders for Novelty Detection", "abstract": "In this paper, we address the problem of novelty detection, \\textit{i.e} recognizing at test time if a data item comes from the training data distribution or not. We focus on Adversarial autoencoders (AAE) that have the advantage to explicitly control the distribution of the known data in the feature space. We show that when they are trained in a (semi-)supervised way, they provide consistent novelty detection improvements compared to a classical autoencoder. We further improve their performance by introducing an explicit rejection class in the prior distribution coupled with random input images to the autoencoder.  ", "pdf": "/pdf/7f993aa7c2f2ff1a40300e169178410c85511c73.pdf", "paperhash": "leveau|adversarial_autoencoders_for_novelty_detection", "conflicts": ["inria.fr"], "keywords": ["Deep learning", "Unsupervised Learning", "Semi-Supervised Learning"], "authors": ["Valentin Leveau", "Alexis Joly"], "authorids": ["vleveau@inria.fr", "ajoly@inria.fr"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "tmdate": 1490028607452, "id": "ICLR.cc/2017/workshop/-/paper112/acceptance", "writers": ["ICLR.cc/2017/workshop"], "signatures": ["ICLR.cc/2017/workshop"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/pcs"], "noninvitees": ["ICLR.cc/2017/pcs"], "reply": {"forum": "SyuncaEKx", "replyto": "SyuncaEKx", "writers": {"values-regex": "ICLR.cc/2017/pcs"}, "signatures": {"values-regex": "ICLR.cc/2017/pcs", "description": "Your displayed identity associated with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your decision.", "value": "ICLR committee final decision"}, "decision": {"required": true, "order": 3, "value-radio": ["Accept", "Reject"]}}}, "nonreaders": [], "cdate": 1490028607452}}}, {"tddate": null, "nonreaders": null, "tmdate": 1489892191362, "tcdate": 1489179459036, "number": 1, "id": "Hkor7qlil", "invitation": "ICLR.cc/2017/workshop/-/paper112/official/review", "forum": "SyuncaEKx", "replyto": "SyuncaEKx", "signatures": ["ICLR.cc/2017/workshop/paper112/AnonReviewer1"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/workshop/paper112/AnonReviewer1"], "content": {"title": "", "rating": "4: Ok but not good enough - rejection", "review": "The paper proposes to use Adversarial Auto Encoders in the context of anomaly/novelty detection. They explore the use of different priors, semi-supervised learning and using an anomaly class. \n\nAlthough this is the first occurrence of adversarial auto-encoder used for novelty detection, using auto-encoder based approaches for this application is not novel. \nThe description of the experiments and the model seems clear, except some part like defining the novelty rate when using explicit rejection class. Claims like \"This might be related to the fact that, whatever the used prior distribution, randomly generated images are distributed according to a normal distribution at the center of the feature space (because of the central limit theorem)\" needs to be explained if accurate or relevant. \nThe experimental procedure does not compare to simple baseline like mixture of Gaussians. Moreover, apart from visualization purpose, restricting the models to a 2D latent space is not well justified for the purpose of novelty detection. Using confusion matrices and precision-recall curves might help understand more what is going on. \n\nAlthough the use of adversarial auto-encoder for anomaly detection might be worth exploring, the experimental procedure needs to be more rigorous in order to draw any conclusion.", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"TL;DR": "", "title": "Adversarial Autoencoders for Novelty Detection", "abstract": "In this paper, we address the problem of novelty detection, \\textit{i.e} recognizing at test time if a data item comes from the training data distribution or not. We focus on Adversarial autoencoders (AAE) that have the advantage to explicitly control the distribution of the known data in the feature space. We show that when they are trained in a (semi-)supervised way, they provide consistent novelty detection improvements compared to a classical autoencoder. We further improve their performance by introducing an explicit rejection class in the prior distribution coupled with random input images to the autoencoder.  ", "pdf": "/pdf/7f993aa7c2f2ff1a40300e169178410c85511c73.pdf", "paperhash": "leveau|adversarial_autoencoders_for_novelty_detection", "conflicts": ["inria.fr"], "keywords": ["Deep learning", "Unsupervised Learning", "Semi-Supervised Learning"], "authors": ["Valentin Leveau", "Alexis Joly"], "authorids": ["vleveau@inria.fr", "ajoly@inria.fr"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1489183200000, "tmdate": 1489203267314, "id": "ICLR.cc/2017/workshop/-/paper112/official/review", "writers": ["ICLR.cc/2017/workshop"], "signatures": ["ICLR.cc/2017/workshop"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/workshop/paper112/reviewers"], "noninvitees": ["ICLR.cc/2017/workshop/paper112/AnonReviewer1", "ICLR.cc/2017/workshop/paper112/AnonReviewer2"], "reply": {"forum": "SyuncaEKx", "replyto": "SyuncaEKx", "writers": {"values-regex": "ICLR.cc/2017/workshop/paper112/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/workshop/paper112/AnonReviewer[0-9]+"}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "value-regex": "[\\S\\s]{1,5000}"}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1496959200000, "cdate": 1489203267314}}}, {"tddate": null, "tmdate": 1489758707402, "tcdate": 1489758707402, "number": 2, "id": "Skolqvtig", "invitation": "ICLR.cc/2017/workshop/-/paper112/public/comment", "forum": "SyuncaEKx", "replyto": "Hkor7qlil", "signatures": ["~Valentin_Leveau2"], "readers": ["everyone"], "writers": ["~Valentin_Leveau2"], "content": {"title": "Answers to Reviewer 2", "comment": "Thank you very much for your feedback and recommendations. Here are a few comments and answers to them:\n\n\u201cAlthough this is the first occurrence of adversarial auto-encoder used for novelty detection, using auto-encoder based approaches for this application is not novel.\u201d\n\u2192 You are absolutely right. This is precisely the purpose of the paper: showing how the adversarial training can improve the baseline auto-encoder by enforcing a known prior distribution in the latent space. And we did show in this preliminary study that it can potentially improve a lot. \n\n\n\u201cThe description of the experiments and the model seems clear, except some part like defining the novelty rate when using explicit rejection class.\u201d\n\u2192 You are right. We forgot to give that precision in the paper. The novelty rate is defined according to the proportion of noise images added in the training set. In our experiments, we used as much noisy images as the initial number of images in the training set (60K images). So that, in Equation 3, we used p(y=0)=0.5 \n\n\u201cClaims like \"This might be related to the fact that, whatever the used prior distribution, randomly generated images are distributed according to a normal distribution at the center of the feature space (because of the central limit theorem)\" needs to be explained if accurate or relevant.\u201d \n\u2192 Let x be the random input image(s) and f_w(x) the activation function of a neuron in the latent space of the auto-encoder. Since the last layer of the encoder is a linear layer, f_w(x) can be re-written as a sum of random variables (the activation values of the previous layer multiplied by a weight). As these random variables are obtained through a deterministic function of the i.i.d. random images x given as input of the network, they are themselves i.i.d. Consequently the central limit theorem applies and the f_w(x)\u2019s are independently and approximately normally distributed. Now, we agree that the notion of \u201ccenter of the feature space\u201d is more discutable. A way to see it is to consider that the set of the real images of the training set is a specific sampling of the random images distribution. In that case, the mean of the f_w(x)\u2019s for the real images of the training set can be considered as an estimator of the mean of the normal distribution. Consequently, the mean of the normal distribution is approximately equal to the mean of the prior distribution (what we call the center of the feature space). Note that, empirically, if you plot the features of the random images in the 2D latent space, you observe that phenomenon. \nSince, we don\u2019t have enough place to discuss that point in the paper, we suggest simply removing the sentence and keep this for a further work. \n\n\u201cThe experimental procedure does not compare to simple baseline like mixture of Gaussians.\u201d\n\u2192 Our goal was to show how the adversarial training can improve the baseline auto-encoder by enforcing a known prior distribution in the latent space. For a full paper submission (and not a 3 page workshop paper), we would surely have explored other baselines (e.g. GMM but also GAN, VAE, DAE, CAE, etc.). Our opinion is that a workshop track is well adapted to host preliminary studies contrary to conference tracks for which one can be more exigent in terms of experimental load. \n\n\u201cMoreover, apart from visualization purpose, restricting the models to a 2D latent space is not well justified for the purpose of novelty detection.\u201d\n\u2192 Sure. Our goal was to gain knowledge on the contribution of adversarial learning over a baseline autoencoder, not to win the performance race.\n\n\u201cUsing accuracy as performance is not fully informative and the choice of thresholding remains arbitrary. Using confusion matrices and precision-recall curves might help understand more what is going on\u201d\n\u2192 Actually, we did not use accuracy but Mean Average Precision (as explained in section \u201cProtocol and settings\u201d). The term \u201caccuracy\u201d does even not appear in the paper. Mean Average Precision does not involve any thresholding and is among the most fully informative metric summarizing the precision-recall curve. Investigating other metrics or plots would not be possible in a 3 pages paper. "}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"TL;DR": "", "title": "Adversarial Autoencoders for Novelty Detection", "abstract": "In this paper, we address the problem of novelty detection, \\textit{i.e} recognizing at test time if a data item comes from the training data distribution or not. We focus on Adversarial autoencoders (AAE) that have the advantage to explicitly control the distribution of the known data in the feature space. We show that when they are trained in a (semi-)supervised way, they provide consistent novelty detection improvements compared to a classical autoencoder. We further improve their performance by introducing an explicit rejection class in the prior distribution coupled with random input images to the autoencoder.  ", "pdf": "/pdf/7f993aa7c2f2ff1a40300e169178410c85511c73.pdf", "paperhash": "leveau|adversarial_autoencoders_for_novelty_detection", "conflicts": ["inria.fr"], "keywords": ["Deep learning", "Unsupervised Learning", "Semi-Supervised Learning"], "authors": ["Valentin Leveau", "Alexis Joly"], "authorids": ["vleveau@inria.fr", "ajoly@inria.fr"]}, "tags": [], "invitation": {"tddate": null, "tmdate": 1487358640116, "tcdate": 1487358640116, "id": "ICLR.cc/2017/workshop/-/paper112/public/comment", "writers": ["ICLR.cc/2017/workshop"], "signatures": ["ICLR.cc/2017/workshop"], "readers": ["everyone"], "invitees": ["~"], "noninvitees": ["ICLR.cc/2017/workshop/paper112/reviewers"], "reply": {"forum": "SyuncaEKx", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/workshop/reviewers", "ICLR.cc/2017/pcs"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,5000}"}}}, "nonreaders": [], "cdate": 1487358640116}}}, {"tddate": null, "tmdate": 1489758672887, "tcdate": 1489758672887, "number": 1, "id": "H1KCtvFjg", "invitation": "ICLR.cc/2017/workshop/-/paper112/public/comment", "forum": "SyuncaEKx", "replyto": "B19SegZje", "signatures": ["~Valentin_Leveau2"], "readers": ["everyone"], "writers": ["~Valentin_Leveau2"], "content": {"title": "Answers to Reviewer 1", "comment": "Thank you very much for your feedback and recommendations. Here are a few comments and answers to them:\n\n\"The idea is interesting, but there are no baselines comparing to other methods in the literature, so it's unclear exactly how good the proposed approach is.\"\n\u2192 Actually, there is a baseline: the reconstruction error of the (non-adversarial) auto-encoder. The objective of the paper was precisely to show how the adversarial training can improve this baseline by enforcing a known prior distribution in the latent space. \n\n\"What about simply training a generative model like a VAE and evaluating the approximate log-likelihood with some threshold?\"\n\u2192 We focused on adversarial auto-encoders because it has been shown in the paper of  Makhzani et al. that they outperform VAE in the context of semi-supervised learning. We agree that it would be relevant to also make that comparison in the specific case of novelty detection. We will do that in the next few weeks.\n\n\u201cOr perhaps using the discriminator in a GAN to determine if a test point is real or fake data?\u201d\n\u2192 Actually, this was the first thing we tested before switching to variational auto-encoders (because it was not working well). After convergence, the discriminator of a GAN is not able to determine if a test point is real or fake data because the distribution of the fake data converges to the one of the real data. Thus, the discriminator strongly overfits and is near random on novelty detection. Using intermediate versions of the discriminator could be an option that we also experimented but that was theoretically and experimentally not convincing.    \n\n\u201cI'm sure there are other good baselines in the literature, some of which are cited in the introduction.\u201d \n\u2192 For a full paper submission and not a 3 page workshop paper, we would surely have explored such other baselines."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"TL;DR": "", "title": "Adversarial Autoencoders for Novelty Detection", "abstract": "In this paper, we address the problem of novelty detection, \\textit{i.e} recognizing at test time if a data item comes from the training data distribution or not. We focus on Adversarial autoencoders (AAE) that have the advantage to explicitly control the distribution of the known data in the feature space. We show that when they are trained in a (semi-)supervised way, they provide consistent novelty detection improvements compared to a classical autoencoder. We further improve their performance by introducing an explicit rejection class in the prior distribution coupled with random input images to the autoencoder.  ", "pdf": "/pdf/7f993aa7c2f2ff1a40300e169178410c85511c73.pdf", "paperhash": "leveau|adversarial_autoencoders_for_novelty_detection", "conflicts": ["inria.fr"], "keywords": ["Deep learning", "Unsupervised Learning", "Semi-Supervised Learning"], "authors": ["Valentin Leveau", "Alexis Joly"], "authorids": ["vleveau@inria.fr", "ajoly@inria.fr"]}, "tags": [], "invitation": {"tddate": null, "tmdate": 1487358640116, "tcdate": 1487358640116, "id": "ICLR.cc/2017/workshop/-/paper112/public/comment", "writers": ["ICLR.cc/2017/workshop"], "signatures": ["ICLR.cc/2017/workshop"], "readers": ["everyone"], "invitees": ["~"], "noninvitees": ["ICLR.cc/2017/workshop/paper112/reviewers"], "reply": {"forum": "SyuncaEKx", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/workshop/reviewers", "ICLR.cc/2017/pcs"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,5000}"}}}, "nonreaders": [], "cdate": 1487358640116}}}, {"tddate": null, "tmdate": 1489203266544, "tcdate": 1489203266544, "number": 2, "id": "B19SegZje", "invitation": "ICLR.cc/2017/workshop/-/paper112/official/review", "forum": "SyuncaEKx", "replyto": "SyuncaEKx", "signatures": ["ICLR.cc/2017/workshop/paper112/AnonReviewer2"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/workshop/paper112/AnonReviewer2"], "content": {"title": "", "rating": "5: Marginally below acceptance threshold", "review": "This paper uses adversarial auto-encoders for the purposes of novelty detection - detecting outliers that do not belong to the training data distribution. Three criteria are developed for determining novelty: reconstruction error, 1 - probability under the latent prior, and probability of belonging to an explicit rejection class. The idea is interesting, but there are no baselines comparing to other methods in the literature, so it's unclear exactly how good the proposed approach is. What about simply training a generative model like a VAE and evaluating the approximate log-likelihood with some threshold? Or perhaps using the discriminator in a GAN to determine if a test point is real or fake data? I'm sure there are other good baselines in the literature, some of which are cited in the introduction.\n\nI would also recommend applying this to other datasets than MNIST, or even a synthetic dataset.\n\nThere is a typo in the paragraph at the end of section 2: P(f(x) | y(x = 0)) => P(f(x) | y(x) = 0).\n\nIn the Gaussian mixture, does C_i refer to component i? I think this doesn't refer to class i in the sense of supervision, but it's not entirely clear.", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"TL;DR": "", "title": "Adversarial Autoencoders for Novelty Detection", "abstract": "In this paper, we address the problem of novelty detection, \\textit{i.e} recognizing at test time if a data item comes from the training data distribution or not. We focus on Adversarial autoencoders (AAE) that have the advantage to explicitly control the distribution of the known data in the feature space. We show that when they are trained in a (semi-)supervised way, they provide consistent novelty detection improvements compared to a classical autoencoder. We further improve their performance by introducing an explicit rejection class in the prior distribution coupled with random input images to the autoencoder.  ", "pdf": "/pdf/7f993aa7c2f2ff1a40300e169178410c85511c73.pdf", "paperhash": "leveau|adversarial_autoencoders_for_novelty_detection", "conflicts": ["inria.fr"], "keywords": ["Deep learning", "Unsupervised Learning", "Semi-Supervised Learning"], "authors": ["Valentin Leveau", "Alexis Joly"], "authorids": ["vleveau@inria.fr", "ajoly@inria.fr"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1489183200000, "tmdate": 1489203267314, "id": "ICLR.cc/2017/workshop/-/paper112/official/review", "writers": ["ICLR.cc/2017/workshop"], "signatures": ["ICLR.cc/2017/workshop"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/workshop/paper112/reviewers"], "noninvitees": ["ICLR.cc/2017/workshop/paper112/AnonReviewer1", "ICLR.cc/2017/workshop/paper112/AnonReviewer2"], "reply": {"forum": "SyuncaEKx", "replyto": "SyuncaEKx", "writers": {"values-regex": "ICLR.cc/2017/workshop/paper112/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/workshop/paper112/AnonReviewer[0-9]+"}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "value-regex": "[\\S\\s]{1,5000}"}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1496959200000, "cdate": 1489203267314}}}, {"tddate": null, "replyto": null, "nonreaders": null, "ddate": null, "tmdate": 1487667160040, "tcdate": 1487358639580, "number": 112, "id": "SyuncaEKx", "invitation": "ICLR.cc/2017/workshop/-/submission", "forum": "SyuncaEKx", "signatures": ["~Valentin_Leveau2"], "readers": ["everyone"], "content": {"TL;DR": "", "title": "Adversarial Autoencoders for Novelty Detection", "abstract": "In this paper, we address the problem of novelty detection, \\textit{i.e} recognizing at test time if a data item comes from the training data distribution or not. We focus on Adversarial autoencoders (AAE) that have the advantage to explicitly control the distribution of the known data in the feature space. We show that when they are trained in a (semi-)supervised way, they provide consistent novelty detection improvements compared to a classical autoencoder. We further improve their performance by introducing an explicit rejection class in the prior distribution coupled with random input images to the autoencoder.  ", "pdf": "/pdf/7f993aa7c2f2ff1a40300e169178410c85511c73.pdf", "paperhash": "leveau|adversarial_autoencoders_for_novelty_detection", "conflicts": ["inria.fr"], "keywords": ["Deep learning", "Unsupervised Learning", "Semi-Supervised Learning"], "authors": ["Valentin Leveau", "Alexis Joly"], "authorids": ["vleveau@inria.fr", "ajoly@inria.fr"]}, "writers": [], "details": {"replyCount": 5, "writable": false, "overwriting": [], "revisions": false, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1487690420000, "tmdate": 1484242559574, "id": "ICLR.cc/2017/workshop/-/submission", "writers": ["ICLR.cc/2017/workshop"], "signatures": ["ICLR.cc/2017/pcs"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": null, "replyto": null, "writers": {"values-regex": "~.*"}, "signatures": {"values-regex": "~.*", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"pdf": {"required": true, "order": 5, "description": "Either upload a PDF file or provide a direct link to your PDF on ArXiv (link must begin with http(s) and end with .pdf)", "value-regex": "upload|(http|https):\\/\\/.+\\.pdf"}, "title": {"required": true, "order": 1, "description": "Title of paper.", "value-regex": ".{1,250}"}, "abstract": {"required": true, "order": 4, "description": "Abstract of paper.", "value-regex": "[\\S\\s]{1,5000}"}, "authors": {"required": true, "order": 2, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of author names, as they appear in the paper."}, "conflicts": {"required": true, "order": 100, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of email domains of people who would have a conflict of interest in reviewing this paper, (e.g., cs.umass.edu;google.com, etc.)."}, "keywords": {"order": 6, "description": "Comma separated list of keywords.", "values-dropdown": ["Theory", "Computer vision", "Speech", "Natural language processing", "Deep learning", "Unsupervised Learning", "Supervised Learning", "Semi-Supervised Learning", "Reinforcement Learning", "Transfer Learning", "Multi-modal learning", "Applications", "Optimization", "Structured prediction", "Games"]}, "TL;DR": {"required": false, "order": 3, "description": "\"Too Long; Didn't Read\": a short sentence describing your paper", "value-regex": "[^\\n]{0,250}"}, "authorids": {"required": true, "order": 3, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of author email addresses, in the same order as above."}}}, "nonreaders": [], "noninvitees": [], "expdate": 1495466420000, "cdate": 1484242559574}}}], "count": 6}