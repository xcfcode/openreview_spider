{"notes": [{"id": "HJlP_pEFPH", "original": "BygIfZnvwr", "number": 635, "cdate": 1569439086894, "ddate": null, "tcdate": 1569439086894, "tmdate": 1577168268653, "tddate": null, "forum": "HJlP_pEFPH", "replyto": null, "invitation": "ICLR.cc/2020/Conference/-/Blind_Submission", "content": {"title": "SRDGAN: learning the noise prior for Super Resolution with Dual Generative Adversarial Networks", "authors": ["Jingwei GUAN", "Cheng PAN", "Songnan LI and Dahai YU"], "authorids": ["jwguan37@gmail.com", "pancheng@tcl.com", "lisn@tcl.com", "dahai.yu@tcl.com"], "keywords": ["Super Resolution GAN Denoise"], "abstract": "Single Image Super Resolution (SISR) is the task of producing a high resolution (HR) image from a given low-resolution (LR) image. It is a well researched prob- lem with extensive commercial applications like digital camera, video compres- sion, medical imaging, etc. Most recent super resolution works focus on the fea- ture learning architecture, like Chao Dong (2016); Dong et al. (2016); Wang et al. (2018b); Ledig et al. (2017). However, these works suffer from the following chal- lenges: (1) The low-resolution (LR) training images are artificially synthesized us- ing HR images with bicubic downsampling, which have much more information than real demosaic-upscaled images. The mismatch between training and realistic mobile data heavily blocks the effect on practical SR problem. (2) These methods cannot effectively handle the blind distortions during super resolution in practical applications. In this work, an end-to-end novel framework, including high-to-low network and low-to-high network, is proposed to solve the above problems with dual Generative Adversarial Networks (GAN). First, the above mismatch prob- lems are well explored with the high-to-low network, where clear high-resolution image and the corresponding realistic low-resolution image pairs can be gener- ated. With high-to-low network, a large-scale General Mobile Super Resolution Dataset, GMSR, is proposed, which can be utilized for training or as a bench- mark for super resolution methods. Second, an effective low-to-high network (super resolution network) is proposed in the framework. Benefiting from the GMSR dataset and novel training strategies, the proposed super resolution model can effectively handle detail recovery and denoising at the same time.", "pdf": "/pdf/c169f54333a1eee74982c59e447ddecad70ec0a5.pdf", "paperhash": "guan|srdgan_learning_the_noise_prior_for_super_resolution_with_dual_generative_adversarial_networks", "original_pdf": "/attachment/c169f54333a1eee74982c59e447ddecad70ec0a5.pdf", "_bibtex": "@misc{\nguan2020srdgan,\ntitle={{\\{}SRDGAN{\\}}: learning the noise prior for Super Resolution with Dual Generative Adversarial Networks},\nauthor={Jingwei GUAN and Cheng PAN and Songnan LI and Dahai YU},\nyear={2020},\nurl={https://openreview.net/forum?id=HJlP_pEFPH}\n}"}, "signatures": ["ICLR.cc/2020/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference"], "details": {"replyCount": 4, "writable": false, "overwriting": [], "revisions": false, "tags": [], "invitation": {"reply": {"readers": {"values-regex": ".*"}, "writers": {"values": ["ICLR.cc/2020/Conference"]}, "signatures": {"values": ["ICLR.cc/2020/Conference"]}, "content": {"spotlight_video": {"value-regex": ".*"}, "full_presentation_video": {"value-regex": ".*"}, "original_pdf": {"required": false, "description": "Upload a PDF file that ends with .pdf", "value-regex": ".*"}, "appendix": {"value-regex": ".*"}, "authorids": {"values-regex": ".*"}, "poster": {"value-regex": ".*"}, "authors": {"values": ["Anonymous"]}, "slides": {"value-regex": ".*"}}}, "final": [], "signatures": ["ICLR.cc/2020/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference"], "noninvitees": [], "tcdate": 1569271260237, "tmdate": 1593459412141, "id": "ICLR.cc/2020/Conference/-/Blind_Submission"}}, "tauthor": "OpenReview.net"}, {"id": "3OPk5qQLcN", "original": null, "number": 1, "cdate": 1576798701951, "ddate": null, "tcdate": 1576798701951, "tmdate": 1576800934045, "tddate": null, "forum": "HJlP_pEFPH", "replyto": "HJlP_pEFPH", "invitation": "ICLR.cc/2020/Conference/Paper635/-/Decision", "content": {"decision": "Reject", "comment": "All reviewers agree that the authors have done a great job identifying weaknesses with the current SOTA in super-resolution.   However, there is also agreement that the proposed approach may be too simple to accurately capture a range of real camera distortions, and more comparisons to the SOTA are needed.   While this paper certainly has merits and opens the door for strong work in the future, there is not enough support to accept the paper in its current form.", "title": "Paper Decision"}, "signatures": ["ICLR.cc/2020/Conference/Program_Chairs"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Program_Chairs"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "SRDGAN: learning the noise prior for Super Resolution with Dual Generative Adversarial Networks", "authors": ["Jingwei GUAN", "Cheng PAN", "Songnan LI and Dahai YU"], "authorids": ["jwguan37@gmail.com", "pancheng@tcl.com", "lisn@tcl.com", "dahai.yu@tcl.com"], "keywords": ["Super Resolution GAN Denoise"], "abstract": "Single Image Super Resolution (SISR) is the task of producing a high resolution (HR) image from a given low-resolution (LR) image. It is a well researched prob- lem with extensive commercial applications like digital camera, video compres- sion, medical imaging, etc. Most recent super resolution works focus on the fea- ture learning architecture, like Chao Dong (2016); Dong et al. (2016); Wang et al. (2018b); Ledig et al. (2017). However, these works suffer from the following chal- lenges: (1) The low-resolution (LR) training images are artificially synthesized us- ing HR images with bicubic downsampling, which have much more information than real demosaic-upscaled images. The mismatch between training and realistic mobile data heavily blocks the effect on practical SR problem. (2) These methods cannot effectively handle the blind distortions during super resolution in practical applications. In this work, an end-to-end novel framework, including high-to-low network and low-to-high network, is proposed to solve the above problems with dual Generative Adversarial Networks (GAN). First, the above mismatch prob- lems are well explored with the high-to-low network, where clear high-resolution image and the corresponding realistic low-resolution image pairs can be gener- ated. With high-to-low network, a large-scale General Mobile Super Resolution Dataset, GMSR, is proposed, which can be utilized for training or as a bench- mark for super resolution methods. Second, an effective low-to-high network (super resolution network) is proposed in the framework. Benefiting from the GMSR dataset and novel training strategies, the proposed super resolution model can effectively handle detail recovery and denoising at the same time.", "pdf": "/pdf/c169f54333a1eee74982c59e447ddecad70ec0a5.pdf", "paperhash": "guan|srdgan_learning_the_noise_prior_for_super_resolution_with_dual_generative_adversarial_networks", "original_pdf": "/attachment/c169f54333a1eee74982c59e447ddecad70ec0a5.pdf", "_bibtex": "@misc{\nguan2020srdgan,\ntitle={{\\{}SRDGAN{\\}}: learning the noise prior for Super Resolution with Dual Generative Adversarial Networks},\nauthor={Jingwei GUAN and Cheng PAN and Songnan LI and Dahai YU},\nyear={2020},\nurl={https://openreview.net/forum?id=HJlP_pEFPH}\n}"}, "tags": [], "invitation": {"reply": {"writers": {"description": "How your identity will be displayed.", "values-regex": ["ICLR.cc/2020/Conference/Program_Chairs"]}, "signatures": {"values": ["ICLR.cc/2020/Conference/Program_Chairs"], "description": "How your identity will be displayed."}, "content": {"decision": {"value-radio": ["Accept (Spotlight)", "Accept (Talk)", "Accept (Poster)", "Reject"], "description": "Decision", "required": true, "order": 2}, "title": {"value": "Paper Decision", "required": true, "order": 1}, "comment": {"value-regex": "[\\S\\s]{0,5000}", "description": "", "required": false, "order": 3}}, "forum": "HJlP_pEFPH", "replyto": "HJlP_pEFPH", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}}, "expdate": 1576854540000, "duedate": 1576853940000, "multiReply": false, "readers": ["everyone"], "invitees": ["ICLR.cc/2020/Conference/Program_Chairs"], "tcdate": 1576795729037, "tmdate": 1576800281563, "super": "ICLR.cc/2020/Conference/-/Decision", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper635/-/Decision"}}}, {"id": "BygtgrvnKS", "original": null, "number": 1, "cdate": 1571742961282, "ddate": null, "tcdate": 1571742961282, "tmdate": 1572972570982, "tddate": null, "forum": "HJlP_pEFPH", "replyto": "HJlP_pEFPH", "invitation": "ICLR.cc/2020/Conference/Paper635/-/Official_Review", "content": {"rating": "3: Weak Reject", "experience_assessment": "I have published one or two papers in this area.", "review_assessment:_checking_correctness_of_derivations_and_theory": "N/A", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #1", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review": "In the paper, the authors proposed an end-to-end single image super-resolution framework, which is composed of two parts. First, a high-to-low network is trained to generate realistic HR/LR image pairs for training super-resolution models. Using this network, the authors designed a large-scale General Mobile Super Resolution Dataset, GMSR, which can be utilized for training or as a benchmark for super-resolution methods. Second, a low-to-high network is trained to produce a super-resolution image. Bene\ufb01ting from the GMSR dataset and novel training strategies, the proposed low-to-high network could thus deal with the real distortions and restore \ufb01ne details.\n\nThe paper is easy to follow. The proposed framework is logical and the experiments proved to be effective. However, there are some problems as follows:\n\n1. In the high-to-low network of framework, Gaussian random noise is added to clean high-resolution images to simulate the randomness of the distortions in LR. Why can do this in this way? The rationality of this setting should be given. Are there other kinds of noises be applied? As far as I knew, the in-camera processing pipeline will involve  Poisson-Gaussian noise rather than Gaussian only and other factors such as demosaicing, Gamma correction, and JPEG compression. It is hard to only consider Gaussian noise to stimulate the whole in-camera process. \n\n2. The experimental part is remarkable insufficient to an ICLR paper. There only have a quantitative evaluation of the proposed framework with other super-resolution algorithms, while lacking the qualitative evaluation of the framework itself. \n\n3. There are some formatting issues in the paper,\n   1. Page 8, figure 5, here some errors in the label color of the figure.\n   2. Page 1, introduction, line 14, \"However, In most practical...\" -> \"However, in most practical...\";\n   3. Page 2, line 10, \"...many problems, such as..., which is hard to avoid\" -> \"...many problems, such as..., which are hard to avoid\";\n   4. The last paragraph of the introduction, line 6, \"...parameters.Third,...\" -> \"...parameters. Third,...\"\n      ..."}, "signatures": ["ICLR.cc/2020/Conference/Paper635/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper635/AnonReviewer1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "SRDGAN: learning the noise prior for Super Resolution with Dual Generative Adversarial Networks", "authors": ["Jingwei GUAN", "Cheng PAN", "Songnan LI and Dahai YU"], "authorids": ["jwguan37@gmail.com", "pancheng@tcl.com", "lisn@tcl.com", "dahai.yu@tcl.com"], "keywords": ["Super Resolution GAN Denoise"], "abstract": "Single Image Super Resolution (SISR) is the task of producing a high resolution (HR) image from a given low-resolution (LR) image. It is a well researched prob- lem with extensive commercial applications like digital camera, video compres- sion, medical imaging, etc. Most recent super resolution works focus on the fea- ture learning architecture, like Chao Dong (2016); Dong et al. (2016); Wang et al. (2018b); Ledig et al. (2017). However, these works suffer from the following chal- lenges: (1) The low-resolution (LR) training images are artificially synthesized us- ing HR images with bicubic downsampling, which have much more information than real demosaic-upscaled images. The mismatch between training and realistic mobile data heavily blocks the effect on practical SR problem. (2) These methods cannot effectively handle the blind distortions during super resolution in practical applications. In this work, an end-to-end novel framework, including high-to-low network and low-to-high network, is proposed to solve the above problems with dual Generative Adversarial Networks (GAN). First, the above mismatch prob- lems are well explored with the high-to-low network, where clear high-resolution image and the corresponding realistic low-resolution image pairs can be gener- ated. With high-to-low network, a large-scale General Mobile Super Resolution Dataset, GMSR, is proposed, which can be utilized for training or as a bench- mark for super resolution methods. Second, an effective low-to-high network (super resolution network) is proposed in the framework. Benefiting from the GMSR dataset and novel training strategies, the proposed super resolution model can effectively handle detail recovery and denoising at the same time.", "pdf": "/pdf/c169f54333a1eee74982c59e447ddecad70ec0a5.pdf", "paperhash": "guan|srdgan_learning_the_noise_prior_for_super_resolution_with_dual_generative_adversarial_networks", "original_pdf": "/attachment/c169f54333a1eee74982c59e447ddecad70ec0a5.pdf", "_bibtex": "@misc{\nguan2020srdgan,\ntitle={{\\{}SRDGAN{\\}}: learning the noise prior for Super Resolution with Dual Generative Adversarial Networks},\nauthor={Jingwei GUAN and Cheng PAN and Songnan LI and Dahai YU},\nyear={2020},\nurl={https://openreview.net/forum?id=HJlP_pEFPH}\n}"}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "HJlP_pEFPH", "replyto": "HJlP_pEFPH", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper635/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper635/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1574978534943, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper635/Reviewers"], "noninvitees": [], "tcdate": 1570237749286, "tmdate": 1574978534956, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper635/-/Official_Review"}}}, {"id": "SkgLCEuTKB", "original": null, "number": 2, "cdate": 1571812558203, "ddate": null, "tcdate": 1571812558203, "tmdate": 1572972570948, "tddate": null, "forum": "HJlP_pEFPH", "replyto": "HJlP_pEFPH", "invitation": "ICLR.cc/2020/Conference/Paper635/-/Official_Review", "content": {"experience_assessment": "I have published in this field for several years.", "rating": "3: Weak Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #2", "review_assessment:_checking_correctness_of_derivations_and_theory": "N/A", "review": "This work proposes a framework for real world super resolution, which includes two networks: high-to-low and low-to-high. With high-to-low network, a general mobile super resolution dataset is proposed. According to the proposed framework and dataset, promising results are achieved for realistic image super-resolution.\n\n[Strengths]\n- This paper is well-written and easy to follow.\n- A new dataset is proposed for real world image super-resolution task.\n\n[Weaknesses]\n- The novelty of this work is relatively limited. The idea to use a high-to-low network to model distribution of real-world low resolution images has already been investigated in several works, like Bulat et al. (2018) and Zhao et al. (2018). However, no comparisons are conducted with these two works. Besides, the network structures are very similar to SRGAN and ESRGAN, which again shows little novelty.\n\n- The authors claimed the recent SOTA optical based method from Zhang et al. (2019) suffers from many problems. However, no direct comparisons are conducted to verify their viewpoints, and it's difficult to distinguish which one is better.\n\n- Is there any visualization for the distributions of real work noisy images and the learned low resolution images? Besieds, since only one mobile device is used to capture the images, why does the proposed method generalize well on other mobile phones? Any distribution illustrations?"}, "signatures": ["ICLR.cc/2020/Conference/Paper635/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper635/AnonReviewer2"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "SRDGAN: learning the noise prior for Super Resolution with Dual Generative Adversarial Networks", "authors": ["Jingwei GUAN", "Cheng PAN", "Songnan LI and Dahai YU"], "authorids": ["jwguan37@gmail.com", "pancheng@tcl.com", "lisn@tcl.com", "dahai.yu@tcl.com"], "keywords": ["Super Resolution GAN Denoise"], "abstract": "Single Image Super Resolution (SISR) is the task of producing a high resolution (HR) image from a given low-resolution (LR) image. It is a well researched prob- lem with extensive commercial applications like digital camera, video compres- sion, medical imaging, etc. Most recent super resolution works focus on the fea- ture learning architecture, like Chao Dong (2016); Dong et al. (2016); Wang et al. (2018b); Ledig et al. (2017). However, these works suffer from the following chal- lenges: (1) The low-resolution (LR) training images are artificially synthesized us- ing HR images with bicubic downsampling, which have much more information than real demosaic-upscaled images. The mismatch between training and realistic mobile data heavily blocks the effect on practical SR problem. (2) These methods cannot effectively handle the blind distortions during super resolution in practical applications. In this work, an end-to-end novel framework, including high-to-low network and low-to-high network, is proposed to solve the above problems with dual Generative Adversarial Networks (GAN). First, the above mismatch prob- lems are well explored with the high-to-low network, where clear high-resolution image and the corresponding realistic low-resolution image pairs can be gener- ated. With high-to-low network, a large-scale General Mobile Super Resolution Dataset, GMSR, is proposed, which can be utilized for training or as a bench- mark for super resolution methods. Second, an effective low-to-high network (super resolution network) is proposed in the framework. Benefiting from the GMSR dataset and novel training strategies, the proposed super resolution model can effectively handle detail recovery and denoising at the same time.", "pdf": "/pdf/c169f54333a1eee74982c59e447ddecad70ec0a5.pdf", "paperhash": "guan|srdgan_learning_the_noise_prior_for_super_resolution_with_dual_generative_adversarial_networks", "original_pdf": "/attachment/c169f54333a1eee74982c59e447ddecad70ec0a5.pdf", "_bibtex": "@misc{\nguan2020srdgan,\ntitle={{\\{}SRDGAN{\\}}: learning the noise prior for Super Resolution with Dual Generative Adversarial Networks},\nauthor={Jingwei GUAN and Cheng PAN and Songnan LI and Dahai YU},\nyear={2020},\nurl={https://openreview.net/forum?id=HJlP_pEFPH}\n}"}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "HJlP_pEFPH", "replyto": "HJlP_pEFPH", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper635/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper635/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1574978534943, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper635/Reviewers"], "noninvitees": [], "tcdate": 1570237749286, "tmdate": 1574978534956, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper635/-/Official_Review"}}}, {"id": "HkevFaACKB", "original": null, "number": 3, "cdate": 1571904895103, "ddate": null, "tcdate": 1571904895103, "tmdate": 1572972570904, "tddate": null, "forum": "HJlP_pEFPH", "replyto": "HJlP_pEFPH", "invitation": "ICLR.cc/2020/Conference/Paper635/-/Official_Review", "content": {"experience_assessment": "I have published in this field for several years.", "rating": "1: Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #3", "review_assessment:_checking_correctness_of_derivations_and_theory": "I carefully checked the derivations and theory.", "review": "This paper presents a single image super-resolution method. The motivation is real and practical.  In almost all existing methods the low-resolution training images are artificially synthesized using the available high-resolution images with bicubic downsampling, which allows LR images to carry more information than real demosaic-upscaled LR images. This mismatch between training and realistic\ndata hinders the practicability of such solutions (not limited to mobile scenarios). \n\nYet, the proposed remedy in the paper is not an answer either. It simply adds a noise image to the HR image, passes it through a convolutional network to construct an LR version, which is then fed into a deconvolutional network. Both these networks are build by residual blocks. Even worse, the paper simply uses zero-mean Gaussian random noise with a standard deviation of 0.05 to simulate the distortions. This is myopic and questionable. \n\nThe introduced dataset is very small, it contains only 447 pairs of images, with an additional 206 images as reference images. These pairs consist of a normal image (considered to be noisy) and a computed image by aggregating 20 images (considered to be clean) using a Blackberry Key2. In other words, the dataset only models a single device and a single camera lens. For practical purposes, this is not much different than using a bicubic sampling and adding noise drawn from a fixed distribution.  \n\nThe paper fails to provide comparisons with the top methods in the NTIRE 2019 single image super-resolution challenge leaderboard. "}, "signatures": ["ICLR.cc/2020/Conference/Paper635/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper635/AnonReviewer3"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "SRDGAN: learning the noise prior for Super Resolution with Dual Generative Adversarial Networks", "authors": ["Jingwei GUAN", "Cheng PAN", "Songnan LI and Dahai YU"], "authorids": ["jwguan37@gmail.com", "pancheng@tcl.com", "lisn@tcl.com", "dahai.yu@tcl.com"], "keywords": ["Super Resolution GAN Denoise"], "abstract": "Single Image Super Resolution (SISR) is the task of producing a high resolution (HR) image from a given low-resolution (LR) image. It is a well researched prob- lem with extensive commercial applications like digital camera, video compres- sion, medical imaging, etc. Most recent super resolution works focus on the fea- ture learning architecture, like Chao Dong (2016); Dong et al. (2016); Wang et al. (2018b); Ledig et al. (2017). However, these works suffer from the following chal- lenges: (1) The low-resolution (LR) training images are artificially synthesized us- ing HR images with bicubic downsampling, which have much more information than real demosaic-upscaled images. The mismatch between training and realistic mobile data heavily blocks the effect on practical SR problem. (2) These methods cannot effectively handle the blind distortions during super resolution in practical applications. In this work, an end-to-end novel framework, including high-to-low network and low-to-high network, is proposed to solve the above problems with dual Generative Adversarial Networks (GAN). First, the above mismatch prob- lems are well explored with the high-to-low network, where clear high-resolution image and the corresponding realistic low-resolution image pairs can be gener- ated. With high-to-low network, a large-scale General Mobile Super Resolution Dataset, GMSR, is proposed, which can be utilized for training or as a bench- mark for super resolution methods. Second, an effective low-to-high network (super resolution network) is proposed in the framework. Benefiting from the GMSR dataset and novel training strategies, the proposed super resolution model can effectively handle detail recovery and denoising at the same time.", "pdf": "/pdf/c169f54333a1eee74982c59e447ddecad70ec0a5.pdf", "paperhash": "guan|srdgan_learning_the_noise_prior_for_super_resolution_with_dual_generative_adversarial_networks", "original_pdf": "/attachment/c169f54333a1eee74982c59e447ddecad70ec0a5.pdf", "_bibtex": "@misc{\nguan2020srdgan,\ntitle={{\\{}SRDGAN{\\}}: learning the noise prior for Super Resolution with Dual Generative Adversarial Networks},\nauthor={Jingwei GUAN and Cheng PAN and Songnan LI and Dahai YU},\nyear={2020},\nurl={https://openreview.net/forum?id=HJlP_pEFPH}\n}"}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "HJlP_pEFPH", "replyto": "HJlP_pEFPH", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper635/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper635/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1574978534943, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper635/Reviewers"], "noninvitees": [], "tcdate": 1570237749286, "tmdate": 1574978534956, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper635/-/Official_Review"}}}], "count": 5}