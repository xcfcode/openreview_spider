{"notes": [{"id": "B1lFa3EFwB", "original": "HJxqN8oXDH", "number": 234, "cdate": 1569438912751, "ddate": null, "tcdate": 1569438912751, "tmdate": 1577168245648, "tddate": null, "forum": "B1lFa3EFwB", "replyto": null, "invitation": "ICLR.cc/2020/Conference/-/Blind_Submission", "content": {"authorids": ["iwasawa@weblab.t.u-tokyo.ac.jp", "akuzawa-kei@weblab.t.u-tokyo.ac.jp", "matsuo@weblab.t.u-tokyo.ac.jp"], "title": "Stablizing Adversarial Invariance Induction by Discriminator Matching", "authors": ["Yusuke Iwasawa", "Kei Akuzawa", "Yutaka Matsuo"], "pdf": "/pdf/1d18f8fa9539eb5c076a21b4e781164ea090e944.pdf", "abstract": "Incorporating the desired invariance into representation learning is a key challenge in many situations, e.g., for domain generalization and privacy/fairness constraints. An adversarial invariance induction (AII) shows its power on this purpose, which maximizes the proxy of the conditional entropy between representations and attributes by adversarial training between an attribute discriminator and feature extractor. However, the practical behavior of AII is still unclear as the previous analysis assumes the optimality of the attribute classifier, which is rarely held in practice. This paper first analyzes the practical behavior of AII both theoretically and empirically, indicating that AII has theoretical difficulty as it maximizes variational {\\em upper} bound of the actual conditional entropy, and AII catastrophically fails to induce invariance even in simple cases as suggested by the above theoretical findings. We then argue that a simple modification to AII can significantly stabilize the adversarial induction framework and achieve better invariant representations. Our modification is based on the property of conditional entropy; it is maximized if and only if the divergence between all pairs of marginal distributions over $z$ between different attributes is minimized. The proposed method, {\\em invariance induction by discriminator matching}, modify AII objective to explicitly consider the divergence minimization requirements by defining a proxy of the divergence by using the attribute discriminator. Empirical validations on both the toy dataset and four real-world datasets (related to applications of user anonymization and domain generalization) reveal that the proposed method provides superior performance when inducing invariance for nuisance factors. ", "keywords": ["invariance induction", "adversarial training", "domain generalization"], "paperhash": "iwasawa|stablizing_adversarial_invariance_induction_by_discriminator_matching", "original_pdf": "/attachment/8fb217aa06f3176dbbd2f067ff9435e4e4859158.pdf", "_bibtex": "@misc{\niwasawa2020stablizing,\ntitle={Stablizing Adversarial Invariance Induction by Discriminator Matching},\nauthor={Yusuke Iwasawa and Kei Akuzawa and Yutaka Matsuo},\nyear={2020},\nurl={https://openreview.net/forum?id=B1lFa3EFwB}\n}"}, "signatures": ["ICLR.cc/2020/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference"], "details": {"replyCount": 8, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"reply": {"readers": {"values-regex": ".*"}, "writers": {"values": ["ICLR.cc/2020/Conference"]}, "signatures": {"values": ["ICLR.cc/2020/Conference"]}, "content": {"spotlight_video": {"value-regex": ".*"}, "full_presentation_video": {"value-regex": ".*"}, "original_pdf": {"required": false, "description": "Upload a PDF file that ends with .pdf", "value-regex": ".*"}, "appendix": {"value-regex": ".*"}, "authorids": {"values-regex": ".*"}, "poster": {"value-regex": ".*"}, "authors": {"values": ["Anonymous"]}, "slides": {"value-regex": ".*"}}}, "final": [], "signatures": ["ICLR.cc/2020/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference"], "noninvitees": [], "tcdate": 1569271260237, "tmdate": 1593459412141, "id": "ICLR.cc/2020/Conference/-/Blind_Submission"}}, "tauthor": "OpenReview.net"}, {"id": "hv0TZQNchU", "original": null, "number": 1, "cdate": 1576798691004, "ddate": null, "tcdate": 1576798691004, "tmdate": 1576800944226, "tddate": null, "forum": "B1lFa3EFwB", "replyto": "B1lFa3EFwB", "invitation": "ICLR.cc/2020/Conference/Paper234/-/Decision", "content": {"decision": "Reject", "comment": "The paper proposes a modification to improve adversarial invariance induction for learning representations under invariance constraints. The authors provide both a formal analysis and experimental evaluation of the method. The reviewers generally agree that the experimental evaluation is rigorous and above average, but the paper lacks clarity making it difficult to judge the significance of it. Therefore, I recommend rejection, but encourage the authors to improve the presentation and resubmit.", "title": "Paper Decision"}, "signatures": ["ICLR.cc/2020/Conference/Program_Chairs"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Program_Chairs"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["iwasawa@weblab.t.u-tokyo.ac.jp", "akuzawa-kei@weblab.t.u-tokyo.ac.jp", "matsuo@weblab.t.u-tokyo.ac.jp"], "title": "Stablizing Adversarial Invariance Induction by Discriminator Matching", "authors": ["Yusuke Iwasawa", "Kei Akuzawa", "Yutaka Matsuo"], "pdf": "/pdf/1d18f8fa9539eb5c076a21b4e781164ea090e944.pdf", "abstract": "Incorporating the desired invariance into representation learning is a key challenge in many situations, e.g., for domain generalization and privacy/fairness constraints. An adversarial invariance induction (AII) shows its power on this purpose, which maximizes the proxy of the conditional entropy between representations and attributes by adversarial training between an attribute discriminator and feature extractor. However, the practical behavior of AII is still unclear as the previous analysis assumes the optimality of the attribute classifier, which is rarely held in practice. This paper first analyzes the practical behavior of AII both theoretically and empirically, indicating that AII has theoretical difficulty as it maximizes variational {\\em upper} bound of the actual conditional entropy, and AII catastrophically fails to induce invariance even in simple cases as suggested by the above theoretical findings. We then argue that a simple modification to AII can significantly stabilize the adversarial induction framework and achieve better invariant representations. Our modification is based on the property of conditional entropy; it is maximized if and only if the divergence between all pairs of marginal distributions over $z$ between different attributes is minimized. The proposed method, {\\em invariance induction by discriminator matching}, modify AII objective to explicitly consider the divergence minimization requirements by defining a proxy of the divergence by using the attribute discriminator. Empirical validations on both the toy dataset and four real-world datasets (related to applications of user anonymization and domain generalization) reveal that the proposed method provides superior performance when inducing invariance for nuisance factors. ", "keywords": ["invariance induction", "adversarial training", "domain generalization"], "paperhash": "iwasawa|stablizing_adversarial_invariance_induction_by_discriminator_matching", "original_pdf": "/attachment/8fb217aa06f3176dbbd2f067ff9435e4e4859158.pdf", "_bibtex": "@misc{\niwasawa2020stablizing,\ntitle={Stablizing Adversarial Invariance Induction by Discriminator Matching},\nauthor={Yusuke Iwasawa and Kei Akuzawa and Yutaka Matsuo},\nyear={2020},\nurl={https://openreview.net/forum?id=B1lFa3EFwB}\n}"}, "tags": [], "invitation": {"reply": {"writers": {"description": "How your identity will be displayed.", "values-regex": ["ICLR.cc/2020/Conference/Program_Chairs"]}, "signatures": {"values": ["ICLR.cc/2020/Conference/Program_Chairs"], "description": "How your identity will be displayed."}, "content": {"decision": {"value-radio": ["Accept (Spotlight)", "Accept (Talk)", "Accept (Poster)", "Reject"], "description": "Decision", "required": true, "order": 2}, "title": {"value": "Paper Decision", "required": true, "order": 1}, "comment": {"value-regex": "[\\S\\s]{0,5000}", "description": "", "required": false, "order": 3}}, "forum": "B1lFa3EFwB", "replyto": "B1lFa3EFwB", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}}, "expdate": 1576854540000, "duedate": 1576853940000, "multiReply": false, "readers": ["everyone"], "invitees": ["ICLR.cc/2020/Conference/Program_Chairs"], "tcdate": 1576795720411, "tmdate": 1576800271235, "super": "ICLR.cc/2020/Conference/-/Decision", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper234/-/Decision"}}}, {"id": "H1eWRiz_jr", "original": null, "number": 4, "cdate": 1573559241495, "ddate": null, "tcdate": 1573559241495, "tmdate": 1573606518892, "tddate": null, "forum": "B1lFa3EFwB", "replyto": "rkg8J4Vg9r", "invitation": "ICLR.cc/2020/Conference/Paper234/-/Official_Comment", "content": {"title": "Response to review #3", "comment": "We thank the reviewer for the detailed and encouraging comments. We have been updated the manuscript following the reviewers' comments. Please refer to the thread of \"Summary of general updates.\". \n\nBelow are several clarifications. \n\n--- Response ---\n> In eq. 1, it is not explained what the expectation is wrt. It should be x drawn from p(x). But it would be better to make it explicit.\n\nThe expectation is with respect to $p(x, a)$. We make it explicit in the new version. \n\n> The setting defined in sect.2 should be more rigorous: it is not clear what y is and what are the attributes we would like to be invariant for. \n\nWe add several examples after the description of the problem settings. Please check the section 2 of the new version. \n\n> While the intuition behind using the divergence is sound, as it is mentioned, it seems to suffer from the same issue as the original AII: minimizing a lower bound does not guarantee that we are minimizing the actual objective. Having the support of 0, does not seem to make it much more sensible.\n\nWe refine the explanation about the problem of AII (in section 3.2) and how it is alleviated in the proposed method (in section 4.1, the paragraph starting \u201cIntuitively speaking\u201d).  Please check the new version and the update 4 in the thread of \"Summary of general updates\". \n\n> As the description of the algorithm advances in Sect.4.2, it is clear that many additional choices need to be made in order to have a full workable algorithm (e.g., how to estimate q_\\phi^i). In the paper, the actual algorithm is never reported in detail and this makes the experiments very hard to reproduce in my opinion.\n\nWe refine the explanation about the proposed method. Please refer to the update of 1 in the thread of \"Summary of general updates\". \n\n> At the best of my understanding, the algorithm may become more and more intractable as the number of attribute values grows. In fact, you need to check the divergence for each pair of values and estimated distributions.\n\nWe are afraid this is partially true but partially not true. More specifically, the exact computation of eq 5 (in the new version) becomes intractable as the number of attribute values grows. The naive implementation requires $O(K^2)$ computation, where $K$ is the number of attribute values. However, we introduce the moving centroids approximation to alleviate this intractable computation. Its order is $O(K)$ and can be trained with standard mini-batch training. We clarify this point in section 4.2 of the new version. \n\n---- \n\n\nWe look forward to hearing from you regarding our submission. We would be glad to respond to any further questions and comments that you may have.\n"}, "signatures": ["ICLR.cc/2020/Conference/Paper234/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper234/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["iwasawa@weblab.t.u-tokyo.ac.jp", "akuzawa-kei@weblab.t.u-tokyo.ac.jp", "matsuo@weblab.t.u-tokyo.ac.jp"], "title": "Stablizing Adversarial Invariance Induction by Discriminator Matching", "authors": ["Yusuke Iwasawa", "Kei Akuzawa", "Yutaka Matsuo"], "pdf": "/pdf/1d18f8fa9539eb5c076a21b4e781164ea090e944.pdf", "abstract": "Incorporating the desired invariance into representation learning is a key challenge in many situations, e.g., for domain generalization and privacy/fairness constraints. An adversarial invariance induction (AII) shows its power on this purpose, which maximizes the proxy of the conditional entropy between representations and attributes by adversarial training between an attribute discriminator and feature extractor. However, the practical behavior of AII is still unclear as the previous analysis assumes the optimality of the attribute classifier, which is rarely held in practice. This paper first analyzes the practical behavior of AII both theoretically and empirically, indicating that AII has theoretical difficulty as it maximizes variational {\\em upper} bound of the actual conditional entropy, and AII catastrophically fails to induce invariance even in simple cases as suggested by the above theoretical findings. We then argue that a simple modification to AII can significantly stabilize the adversarial induction framework and achieve better invariant representations. Our modification is based on the property of conditional entropy; it is maximized if and only if the divergence between all pairs of marginal distributions over $z$ between different attributes is minimized. The proposed method, {\\em invariance induction by discriminator matching}, modify AII objective to explicitly consider the divergence minimization requirements by defining a proxy of the divergence by using the attribute discriminator. Empirical validations on both the toy dataset and four real-world datasets (related to applications of user anonymization and domain generalization) reveal that the proposed method provides superior performance when inducing invariance for nuisance factors. ", "keywords": ["invariance induction", "adversarial training", "domain generalization"], "paperhash": "iwasawa|stablizing_adversarial_invariance_induction_by_discriminator_matching", "original_pdf": "/attachment/8fb217aa06f3176dbbd2f067ff9435e4e4859158.pdf", "_bibtex": "@misc{\niwasawa2020stablizing,\ntitle={Stablizing Adversarial Invariance Induction by Discriminator Matching},\nauthor={Yusuke Iwasawa and Kei Akuzawa and Yutaka Matsuo},\nyear={2020},\nurl={https://openreview.net/forum?id=B1lFa3EFwB}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "B1lFa3EFwB", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper234/Authors", "ICLR.cc/2020/Conference/Paper234/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper234/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper234/Reviewers", "ICLR.cc/2020/Conference/Paper234/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper234/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper234/Authors|ICLR.cc/2020/Conference/Paper234/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504174401, "tmdate": 1576860548911, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper234/Authors", "ICLR.cc/2020/Conference/Paper234/Reviewers", "ICLR.cc/2020/Conference/Paper234/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper234/-/Official_Comment"}}}, {"id": "BJgDJ_GOjr", "original": null, "number": 3, "cdate": 1573558238681, "ddate": null, "tcdate": 1573558238681, "tmdate": 1573606487849, "tddate": null, "forum": "B1lFa3EFwB", "replyto": "HJg0D4d0YH", "invitation": "ICLR.cc/2020/Conference/Paper234/-/Official_Comment", "content": {"title": "Response to review #1", "comment": "We thank the reviewer for the detailed comments. We have been updated the manuscript following the reviewers' comments. Please refer to the thread of \"Summary of general updates.\". \n\nBelow are several clarifications. \n\n--- Response ---\n> The paper says that it analyzes AII theoretically and empirically. But it only shows the practical drawback of AII intuitively without any theoretical proof.\n\nSection 3 of the new version focus on the theoretical analysis. If the reviewer feels it is too exaggerated to use the term \"theoretical.\", we could omit the word. We believe minor wording does not harm the overall contributions of this paper.  \n\n > In Section 3, the paper says : 'In general, maximizing the upper bound of the function of interest $f$ does not guarantee the minimizing the $f$'\n > Also in the section 3, the paper says : 'Figure 2-(b) visualizes how distribution move during the optimization of AII on synthesized data'. And I want to ask why the caption of Figure 2-(b) is IIDM ?\n\nWe are sorry that these are typographical mistakes. We fix the typo in the new version. \n\n> The proposition 1 on which the modification proposed in the paper is based \n\nThe uniform $p(a)$ is an assumption of the analysis, as mentioned in the original manuscripts. We clarify this assumption more in the new version. Moreover, the analysis was indeed based on that assumption, but we believe it does not need to hold in practice. Our method works properly in the PACS dataset, where the attributes are imbalanced and still gives better performance than AII. We will add that to the discussion in the final manuscript if the reviewer thinks it is needed. \n\n> In the proof of equation 4 which is the main theorem of the total work.\n\nWe admit our mistakes regarding equation 4. We fix the mistake in the new version. We believe that the revision does not harm the main contributions. Please refer to the update 5 in the thread of \"Summary of general updates\". \n\n----\n\nWe look forward to hearing from you regarding our submission. We would be glad to respond to any further questions and comments that you may have.\n"}, "signatures": ["ICLR.cc/2020/Conference/Paper234/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper234/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["iwasawa@weblab.t.u-tokyo.ac.jp", "akuzawa-kei@weblab.t.u-tokyo.ac.jp", "matsuo@weblab.t.u-tokyo.ac.jp"], "title": "Stablizing Adversarial Invariance Induction by Discriminator Matching", "authors": ["Yusuke Iwasawa", "Kei Akuzawa", "Yutaka Matsuo"], "pdf": "/pdf/1d18f8fa9539eb5c076a21b4e781164ea090e944.pdf", "abstract": "Incorporating the desired invariance into representation learning is a key challenge in many situations, e.g., for domain generalization and privacy/fairness constraints. An adversarial invariance induction (AII) shows its power on this purpose, which maximizes the proxy of the conditional entropy between representations and attributes by adversarial training between an attribute discriminator and feature extractor. However, the practical behavior of AII is still unclear as the previous analysis assumes the optimality of the attribute classifier, which is rarely held in practice. This paper first analyzes the practical behavior of AII both theoretically and empirically, indicating that AII has theoretical difficulty as it maximizes variational {\\em upper} bound of the actual conditional entropy, and AII catastrophically fails to induce invariance even in simple cases as suggested by the above theoretical findings. We then argue that a simple modification to AII can significantly stabilize the adversarial induction framework and achieve better invariant representations. Our modification is based on the property of conditional entropy; it is maximized if and only if the divergence between all pairs of marginal distributions over $z$ between different attributes is minimized. The proposed method, {\\em invariance induction by discriminator matching}, modify AII objective to explicitly consider the divergence minimization requirements by defining a proxy of the divergence by using the attribute discriminator. Empirical validations on both the toy dataset and four real-world datasets (related to applications of user anonymization and domain generalization) reveal that the proposed method provides superior performance when inducing invariance for nuisance factors. ", "keywords": ["invariance induction", "adversarial training", "domain generalization"], "paperhash": "iwasawa|stablizing_adversarial_invariance_induction_by_discriminator_matching", "original_pdf": "/attachment/8fb217aa06f3176dbbd2f067ff9435e4e4859158.pdf", "_bibtex": "@misc{\niwasawa2020stablizing,\ntitle={Stablizing Adversarial Invariance Induction by Discriminator Matching},\nauthor={Yusuke Iwasawa and Kei Akuzawa and Yutaka Matsuo},\nyear={2020},\nurl={https://openreview.net/forum?id=B1lFa3EFwB}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "B1lFa3EFwB", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper234/Authors", "ICLR.cc/2020/Conference/Paper234/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper234/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper234/Reviewers", "ICLR.cc/2020/Conference/Paper234/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper234/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper234/Authors|ICLR.cc/2020/Conference/Paper234/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504174401, "tmdate": 1576860548911, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper234/Authors", "ICLR.cc/2020/Conference/Paper234/Reviewers", "ICLR.cc/2020/Conference/Paper234/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper234/-/Official_Comment"}}}, {"id": "r1lLPXGusr", "original": null, "number": 2, "cdate": 1573557085551, "ddate": null, "tcdate": 1573557085551, "tmdate": 1573606416029, "tddate": null, "forum": "B1lFa3EFwB", "replyto": "BJxoDJtnKS", "invitation": "ICLR.cc/2020/Conference/Paper234/-/Official_Comment", "content": {"title": "Response to review #2", "comment": "We thank the reviewer for detailed and encouraging comments. We have been updated the manuscript following the reviewers' comments. Please refer to the thread of \"Summary of general updates.\". \n\nBelow are several clarifications. As the reviewer suggested, we mainly focus on improving the clarity in this rebuttal period. \n\n---- Responses ----\n> The paper is hard to get, if the reader is not familiar with related literature\n\nWe updated the manuscript to improve clarity. Please refer to the update 1, 2, 3 for more detail. \n\n> It is not fully clear from the paper which parts are original and which are inherited from prior work.\n\nWe made several restructuring. Specifically, \n(1) We concentrate the explanation about AII in section 2 to make the paper (and the originality of this work) easy to understand. (2) Section 3 focuses on analyzing the practical issue of AII, which is the first contribution of this paper. (3) Section 4 derives a stable variant of AII, which is the second contribution of this paper. \n\nWe also add a flow-diagrams and pseudo-code for a better explanation. \n\n> 3. Although already convincing, the experimental part can be improved: 3.a. Instead of a version of rotated-MNIST, authors can test on the \u201cdigits-five\u201d setting (MNIST, MNIST-M, SVHN, UPS, SYN) as done in several works like http://openaccess.thecvf.com/content_cvpr_2018/papers/Xu_Deep_Cocktail_Network_CVPR_2018_paper.pdf. 3.b. In addition to multi-domain generalization, authors could also have tried more classical unsupervised domain adaptation settings or, even, single-source domain generalization as in https://papers.nips.cc/paper/7779-generalizing-to-unseen-domains-via-adversarial-data-augmentation.\n\nAs suggested by the reviewer, we agree it would be interesting to see its performance on the other benchmarks. Unfortunately, we do not have much time and computational resources during this rebuttal period. Of course, we are happy to share the source code for additional tests after the acceptance of the paper.  \n----\n\nWe look forward to hearing from you regarding our submission. We would be glad to respond to any further questions and comments that you may have."}, "signatures": ["ICLR.cc/2020/Conference/Paper234/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper234/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["iwasawa@weblab.t.u-tokyo.ac.jp", "akuzawa-kei@weblab.t.u-tokyo.ac.jp", "matsuo@weblab.t.u-tokyo.ac.jp"], "title": "Stablizing Adversarial Invariance Induction by Discriminator Matching", "authors": ["Yusuke Iwasawa", "Kei Akuzawa", "Yutaka Matsuo"], "pdf": "/pdf/1d18f8fa9539eb5c076a21b4e781164ea090e944.pdf", "abstract": "Incorporating the desired invariance into representation learning is a key challenge in many situations, e.g., for domain generalization and privacy/fairness constraints. An adversarial invariance induction (AII) shows its power on this purpose, which maximizes the proxy of the conditional entropy between representations and attributes by adversarial training between an attribute discriminator and feature extractor. However, the practical behavior of AII is still unclear as the previous analysis assumes the optimality of the attribute classifier, which is rarely held in practice. This paper first analyzes the practical behavior of AII both theoretically and empirically, indicating that AII has theoretical difficulty as it maximizes variational {\\em upper} bound of the actual conditional entropy, and AII catastrophically fails to induce invariance even in simple cases as suggested by the above theoretical findings. We then argue that a simple modification to AII can significantly stabilize the adversarial induction framework and achieve better invariant representations. Our modification is based on the property of conditional entropy; it is maximized if and only if the divergence between all pairs of marginal distributions over $z$ between different attributes is minimized. The proposed method, {\\em invariance induction by discriminator matching}, modify AII objective to explicitly consider the divergence minimization requirements by defining a proxy of the divergence by using the attribute discriminator. Empirical validations on both the toy dataset and four real-world datasets (related to applications of user anonymization and domain generalization) reveal that the proposed method provides superior performance when inducing invariance for nuisance factors. ", "keywords": ["invariance induction", "adversarial training", "domain generalization"], "paperhash": "iwasawa|stablizing_adversarial_invariance_induction_by_discriminator_matching", "original_pdf": "/attachment/8fb217aa06f3176dbbd2f067ff9435e4e4859158.pdf", "_bibtex": "@misc{\niwasawa2020stablizing,\ntitle={Stablizing Adversarial Invariance Induction by Discriminator Matching},\nauthor={Yusuke Iwasawa and Kei Akuzawa and Yutaka Matsuo},\nyear={2020},\nurl={https://openreview.net/forum?id=B1lFa3EFwB}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "B1lFa3EFwB", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper234/Authors", "ICLR.cc/2020/Conference/Paper234/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper234/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper234/Reviewers", "ICLR.cc/2020/Conference/Paper234/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper234/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper234/Authors|ICLR.cc/2020/Conference/Paper234/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504174401, "tmdate": 1576860548911, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper234/Authors", "ICLR.cc/2020/Conference/Paper234/Reviewers", "ICLR.cc/2020/Conference/Paper234/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper234/-/Official_Comment"}}}, {"id": "HkggTqZusH", "original": null, "number": 1, "cdate": 1573554871544, "ddate": null, "tcdate": 1573554871544, "tmdate": 1573554871544, "tddate": null, "forum": "B1lFa3EFwB", "replyto": "B1lFa3EFwB", "invitation": "ICLR.cc/2020/Conference/Paper234/-/Official_Comment", "content": {"title": "Summary of general updates", "comment": "We thank all reviewers for their comments. They are insightful and help us to make our paper better. To address their comments, we substantially updated our paper to improve clarity. We admit several mistakes (including typos and a wrong inequality) and fixed the explanation accordingly. The revision does not harm the overall contributions of this paper.  \n \nBelow is a summary of the major changes. We will clarify several points in the detailed response for each review.\n \n[Update 1] Clarification of the proposed method (review #2 and #3):\nWe clarify our algorithm in multiple-level of granularity. In section 1 (Figure 1), we add flow-diagrams for helping the readers to get the concept of the proposed method rapidly. We also explicit a workable algorithm in the text and provide the pseud-code (in section 4.2).\n \n[Update 2] Explanation about the previous method (review #2):\nWe concentrate the explanation about AII in section 2 to make the paper (and the originality of this work) easy to understand.\n \n[Update 3] Organization of section 3 and section 4 (review #2):\nWe refine the explanation in section 3 and section 4 thoroughly. We move section 4.1 of the first version (explanation about the divergence minimization requirements) to section 3.2 in the new version. We also move simulation results about AII (the later parts of section 3 in the first version) to section 4.3 in the new version. We refine the text accordingly.\n \n[Update 4] Explanation about the merit of the proposed method (review #3):\nWe refine the explanation about the problem of AII (in section 3.2) and how it is alleviated in the proposed method (in section 4.1, the paragraph starting \u201cIntuitively speaking\u201d).  Briefly, AII has an incentive to move the distribution far away even when the conditional entropy is successfully maximized (or equivalently, the marginal distributions of different attributes are aligned). Our proposed method stabilizes the behavior around this optimal point by restricting the update of the encoder to consider the location of the marginal distributions of a different attribute.\n \n [Update 5] Fix the inequality in section 4 (review #1):\nWe admit our mistake regarding the (part of) inequality regarding our discriminator matching loss and the divergence between the marginal distributions $p(z)$ of different attributes. We refine the explanation about the analysis of the relationships between the proposed method and the divergence minimization requirements (in section 4.1 and appendix B). Note that the revision *does not change* the conclusions. Specifically, discriminator matching loss is related to the required divergence minimization. The empirical validations support the merits of the proposal.\n \n[Update 6] Typos (review #1 and #3):\nWe fix the typographical mistakes.\n \n \nThanks."}, "signatures": ["ICLR.cc/2020/Conference/Paper234/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper234/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["iwasawa@weblab.t.u-tokyo.ac.jp", "akuzawa-kei@weblab.t.u-tokyo.ac.jp", "matsuo@weblab.t.u-tokyo.ac.jp"], "title": "Stablizing Adversarial Invariance Induction by Discriminator Matching", "authors": ["Yusuke Iwasawa", "Kei Akuzawa", "Yutaka Matsuo"], "pdf": "/pdf/1d18f8fa9539eb5c076a21b4e781164ea090e944.pdf", "abstract": "Incorporating the desired invariance into representation learning is a key challenge in many situations, e.g., for domain generalization and privacy/fairness constraints. An adversarial invariance induction (AII) shows its power on this purpose, which maximizes the proxy of the conditional entropy between representations and attributes by adversarial training between an attribute discriminator and feature extractor. However, the practical behavior of AII is still unclear as the previous analysis assumes the optimality of the attribute classifier, which is rarely held in practice. This paper first analyzes the practical behavior of AII both theoretically and empirically, indicating that AII has theoretical difficulty as it maximizes variational {\\em upper} bound of the actual conditional entropy, and AII catastrophically fails to induce invariance even in simple cases as suggested by the above theoretical findings. We then argue that a simple modification to AII can significantly stabilize the adversarial induction framework and achieve better invariant representations. Our modification is based on the property of conditional entropy; it is maximized if and only if the divergence between all pairs of marginal distributions over $z$ between different attributes is minimized. The proposed method, {\\em invariance induction by discriminator matching}, modify AII objective to explicitly consider the divergence minimization requirements by defining a proxy of the divergence by using the attribute discriminator. Empirical validations on both the toy dataset and four real-world datasets (related to applications of user anonymization and domain generalization) reveal that the proposed method provides superior performance when inducing invariance for nuisance factors. ", "keywords": ["invariance induction", "adversarial training", "domain generalization"], "paperhash": "iwasawa|stablizing_adversarial_invariance_induction_by_discriminator_matching", "original_pdf": "/attachment/8fb217aa06f3176dbbd2f067ff9435e4e4859158.pdf", "_bibtex": "@misc{\niwasawa2020stablizing,\ntitle={Stablizing Adversarial Invariance Induction by Discriminator Matching},\nauthor={Yusuke Iwasawa and Kei Akuzawa and Yutaka Matsuo},\nyear={2020},\nurl={https://openreview.net/forum?id=B1lFa3EFwB}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "B1lFa3EFwB", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper234/Authors", "ICLR.cc/2020/Conference/Paper234/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper234/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper234/Reviewers", "ICLR.cc/2020/Conference/Paper234/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper234/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper234/Authors|ICLR.cc/2020/Conference/Paper234/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504174401, "tmdate": 1576860548911, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper234/Authors", "ICLR.cc/2020/Conference/Paper234/Reviewers", "ICLR.cc/2020/Conference/Paper234/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper234/-/Official_Comment"}}}, {"id": "BJxoDJtnKS", "original": null, "number": 1, "cdate": 1571749730733, "ddate": null, "tcdate": 1571749730733, "tmdate": 1572972621590, "tddate": null, "forum": "B1lFa3EFwB", "replyto": "B1lFa3EFwB", "invitation": "ICLR.cc/2020/Conference/Paper234/-/Official_Review", "content": {"experience_assessment": "I have read many papers in this area.", "rating": "3: Weak Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #2", "review_assessment:_checking_correctness_of_derivations_and_theory": "I did not assess the derivations or theory.", "review": "*Summary*\n\nThe paper proposes a new method to learn data-driven representations, being invariant to some specific nuisance factors which are detrimental for the selected (supervised) classification task.\nAuthors build upon the existing probabilistic framework termed Adversarial Invariant Induction (AII) from (Xie et al., 2017). \n\nThey claim to explore it under a both theoretical and practical point of view, demonstrating the limitations of maximizing a variational upper bound on conditional entropy as a proxy to achieve invariance. \n\nLeveraging these observation, authors propose a novel method, called \u201cinvariance induction by discriminator matching\u201d (IIDM) that is based on a regularized classification loss, penalized by a Kullbach-Leibler divergence between conditional distributions of the nuisance factor.\n\nExtremely convincing experiments are carried out on a synthetic and a real benchmark in multi-source domain generalization (PACS).\n\n\n\n*Pros*\n1. The genesis of the proposed IIDM is extremely paced since smoothly derived from the AII framework.\n2. Experimental results on a synthetic benchmark (a version of rotated MNIST) and on a popular benchmark for domain generalization (PACS) proved the effectiveness of IIDM\n\n\n\n *Cons*\n1. The paper is hard to get, if the reader is not familiar with related literature\n2. It is not fully clear from the paper which parts are original and which are inherited from prior work.\n3. The structure of the paper needs to be improved (check my comments in the section beneath)\nSome of the proposed methodologies are not clear (IIDM+)\n\n\n\n\n*Detailed Comments*\n\nThe problem considered by authors is surely interesting and addressing a popular topic in computer vision and deep learning. \n\n1. Unfortunately, the paper, as it is is hard to get for scholars which are not expert of the AII formalism, which, in my opinion is not enough detailed. Therefore, in my opinion clarity is something that authors should try to work hard on: for instance, during the rebuttal time, authors can write from scratch an entire new Section in which they explain in plain terms the main outcomes of their paper, without entering too much into technical details.\n\n\n2. Additionally, the structure of the paper needs, in my opinion a major re-styling, still for the sake of better readability:\n2.a. A visualization of the proposed method (for instance, using flow-diagrams) in comparison with the existing AII should help in rapidly getting the factors of novelty of the proposed IIDM method. I would also encourage authors to add a pseudo-code\n2.b. Since authors claim two major contributions (understanding AII + IIDM), I would like to see those two contributions thoroughly presented and dissected in two separated sections of the paper. I am not fully convinced with the actual writing style in which the two contributions seem to be intertwined together.\n\n\n3. Although already convincing, the experimental part can be improved:\n3.a. Instead of a version of rotated-MNIST, authors can test on the \u201cdigits-five\u201d setting (MNIST, MNIST-M, SVHN, UPS, SYN) as done in several works like http://openaccess.thecvf.com/content_cvpr_2018/papers/Xu_Deep_Cocktail_Network_CVPR_2018_paper.pdf.\n3.b. In addition to multi-domain generalization, authors could also have tried more classical unsupervised domain adaptation settings or, even, single-source domain generalization as in https://papers.nips.cc/paper/7779-generalizing-to-unseen-domains-via-adversarial-data-augmentation.\n\n\n\n*Final Evaluation*\n\nI think that the main aspect that authors should face during the rebuttal is to make the paper more easy to read and better separate the two contributions (understanding AII and IIDM). What I am not convinced at all about the writing style of the authors since when reading the paper I am not always capable of understanding what is novel (since proposed by authors) and what is inherited from prior work. But, maybe, the reason for this is that I am not an expert of the specific related field - but, even so, I think that the paper needs to be understood from the broadest audience possible.\n\nInstead, I am familiar with multi-source/single-source domain generalization (and adaptation) and, after my careful analysis of the experiments, I see a lot of potential in the approach. I would me more than interested in checking the performance of the proposed method over some of the novel benchmarks that I have recommended. It would be nice if authors add more experiments, but I know that this is always a complicated request during a rebuttal period.\nGlobally, if I were asked to only rate the experimental part, I would have promoted for full acceptance. Unfortunately, the theoretical part of the paper is not fully clear to me and, therefore, I am not confident in calling for a full acceptance only based on the experiments. \n\nIn brief, I would go for a weak reject, looking forward to the authors\u2019 rebuttal and the opinion of the other Fellow Reviewers."}, "signatures": ["ICLR.cc/2020/Conference/Paper234/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper234/AnonReviewer2"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["iwasawa@weblab.t.u-tokyo.ac.jp", "akuzawa-kei@weblab.t.u-tokyo.ac.jp", "matsuo@weblab.t.u-tokyo.ac.jp"], "title": "Stablizing Adversarial Invariance Induction by Discriminator Matching", "authors": ["Yusuke Iwasawa", "Kei Akuzawa", "Yutaka Matsuo"], "pdf": "/pdf/1d18f8fa9539eb5c076a21b4e781164ea090e944.pdf", "abstract": "Incorporating the desired invariance into representation learning is a key challenge in many situations, e.g., for domain generalization and privacy/fairness constraints. An adversarial invariance induction (AII) shows its power on this purpose, which maximizes the proxy of the conditional entropy between representations and attributes by adversarial training between an attribute discriminator and feature extractor. However, the practical behavior of AII is still unclear as the previous analysis assumes the optimality of the attribute classifier, which is rarely held in practice. This paper first analyzes the practical behavior of AII both theoretically and empirically, indicating that AII has theoretical difficulty as it maximizes variational {\\em upper} bound of the actual conditional entropy, and AII catastrophically fails to induce invariance even in simple cases as suggested by the above theoretical findings. We then argue that a simple modification to AII can significantly stabilize the adversarial induction framework and achieve better invariant representations. Our modification is based on the property of conditional entropy; it is maximized if and only if the divergence between all pairs of marginal distributions over $z$ between different attributes is minimized. The proposed method, {\\em invariance induction by discriminator matching}, modify AII objective to explicitly consider the divergence minimization requirements by defining a proxy of the divergence by using the attribute discriminator. Empirical validations on both the toy dataset and four real-world datasets (related to applications of user anonymization and domain generalization) reveal that the proposed method provides superior performance when inducing invariance for nuisance factors. ", "keywords": ["invariance induction", "adversarial training", "domain generalization"], "paperhash": "iwasawa|stablizing_adversarial_invariance_induction_by_discriminator_matching", "original_pdf": "/attachment/8fb217aa06f3176dbbd2f067ff9435e4e4859158.pdf", "_bibtex": "@misc{\niwasawa2020stablizing,\ntitle={Stablizing Adversarial Invariance Induction by Discriminator Matching},\nauthor={Yusuke Iwasawa and Kei Akuzawa and Yutaka Matsuo},\nyear={2020},\nurl={https://openreview.net/forum?id=B1lFa3EFwB}\n}"}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "B1lFa3EFwB", "replyto": "B1lFa3EFwB", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper234/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper234/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1575550007547, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper234/Reviewers"], "noninvitees": [], "tcdate": 1570237755084, "tmdate": 1575550007566, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper234/-/Official_Review"}}}, {"id": "HJg0D4d0YH", "original": null, "number": 2, "cdate": 1571877989793, "ddate": null, "tcdate": 1571877989793, "tmdate": 1572972621547, "tddate": null, "forum": "B1lFa3EFwB", "replyto": "B1lFa3EFwB", "invitation": "ICLR.cc/2020/Conference/Paper234/-/Official_Review", "content": {"experience_assessment": "I have published one or two papers in this area.", "rating": "1: Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #1", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "The paper points out that the practical behavior of AII assumes the optimality of the attribute classifier, which is rarely held in practice. And claims that the paper analyzes the practical behavior of AII both theoretically and empirically, indicating that AII has theoretical difficulty as it maximizes variational upper bound of the actual conditional entropy. Then it argues an ugly modification based on a wrong property of conditional entropy. \n\n- The paper says that it analyzes AII theoretically and empirically. But it only shows the practical drawback of AII intuitively without any theoretical proof.\n- In Section 3, the paper says : 'In general, maximizing the upper bound of the function of interest $f$ does not guarantee the minimizing the $f$ '. \n- Also in the section 3, the paper says : 'Figure 2-(b) visualizes how distribution move during the optimization of AII on synthesized data'. And I want to ask why the caption of Figure 2-(b) is IIDM ?\n- The proposition 1 on which the modification proposed in the paper is based will be not true when the distribution of attributes is not uniform by Bayses' s law which is used in the so called proof of the proposition 1. Which means that $p(z|a_i)=p(z|a_j) \\Leftarrow p(a_i|z)=p(a_j|z)$ if and only if $p(a_i)=p(a_j)$.\n- In the proof of equation 4 which is the main theorem of the total work. We can find $-\\sum q_{\\phi}^i(a)\\log\\mathbb{E}_{p_{\\theta}^j(z)}[q_{\\phi}(a|z)]\\ge -\\sum q_{\\phi}^i(a)\\mathbb{E}_{p_{\\theta}^j(z)}[\\log q_{\\phi}(a|z)]$.  The inequality direction is reversed. \n"}, "signatures": ["ICLR.cc/2020/Conference/Paper234/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper234/AnonReviewer1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["iwasawa@weblab.t.u-tokyo.ac.jp", "akuzawa-kei@weblab.t.u-tokyo.ac.jp", "matsuo@weblab.t.u-tokyo.ac.jp"], "title": "Stablizing Adversarial Invariance Induction by Discriminator Matching", "authors": ["Yusuke Iwasawa", "Kei Akuzawa", "Yutaka Matsuo"], "pdf": "/pdf/1d18f8fa9539eb5c076a21b4e781164ea090e944.pdf", "abstract": "Incorporating the desired invariance into representation learning is a key challenge in many situations, e.g., for domain generalization and privacy/fairness constraints. An adversarial invariance induction (AII) shows its power on this purpose, which maximizes the proxy of the conditional entropy between representations and attributes by adversarial training between an attribute discriminator and feature extractor. However, the practical behavior of AII is still unclear as the previous analysis assumes the optimality of the attribute classifier, which is rarely held in practice. This paper first analyzes the practical behavior of AII both theoretically and empirically, indicating that AII has theoretical difficulty as it maximizes variational {\\em upper} bound of the actual conditional entropy, and AII catastrophically fails to induce invariance even in simple cases as suggested by the above theoretical findings. We then argue that a simple modification to AII can significantly stabilize the adversarial induction framework and achieve better invariant representations. Our modification is based on the property of conditional entropy; it is maximized if and only if the divergence between all pairs of marginal distributions over $z$ between different attributes is minimized. The proposed method, {\\em invariance induction by discriminator matching}, modify AII objective to explicitly consider the divergence minimization requirements by defining a proxy of the divergence by using the attribute discriminator. Empirical validations on both the toy dataset and four real-world datasets (related to applications of user anonymization and domain generalization) reveal that the proposed method provides superior performance when inducing invariance for nuisance factors. ", "keywords": ["invariance induction", "adversarial training", "domain generalization"], "paperhash": "iwasawa|stablizing_adversarial_invariance_induction_by_discriminator_matching", "original_pdf": "/attachment/8fb217aa06f3176dbbd2f067ff9435e4e4859158.pdf", "_bibtex": "@misc{\niwasawa2020stablizing,\ntitle={Stablizing Adversarial Invariance Induction by Discriminator Matching},\nauthor={Yusuke Iwasawa and Kei Akuzawa and Yutaka Matsuo},\nyear={2020},\nurl={https://openreview.net/forum?id=B1lFa3EFwB}\n}"}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "B1lFa3EFwB", "replyto": "B1lFa3EFwB", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper234/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper234/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1575550007547, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper234/Reviewers"], "noninvitees": [], "tcdate": 1570237755084, "tmdate": 1575550007566, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper234/-/Official_Review"}}}, {"id": "rkg8J4Vg9r", "original": null, "number": 3, "cdate": 1571992542258, "ddate": null, "tcdate": 1571992542258, "tmdate": 1572972621503, "tddate": null, "forum": "B1lFa3EFwB", "replyto": "B1lFa3EFwB", "invitation": "ICLR.cc/2020/Conference/Paper234/-/Official_Review", "content": {"experience_assessment": "I do not know much about this area.", "rating": "3: Weak Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #3", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "** Summary\nThe paper studies the problem of representation learning under invariance constraints (i.e., the representation should be invariant wrt some attributes). The authors first review the adversarial invariance induction (AII) approach and they point out its limitations and then they propose a novel variant, which introduces an explicit regularization to minimize pairwise divergence (i.e., different attributes should lead to the same conditional distribution over the learned representation). The authors support the modified objective function both from a formal point of view and with an extensive empirical validation\n\n** Evaluation\nThe paper lies a bit outside my area of expertise. Although the paper tries to capture intrinsic limitations of the AII approach and build a more stable algorithm, my impression is that too many elements in the discussion and derivation remain too vague at the current stage and they would require better and clearer explanation.\n\nDetailed comments:\n1- In many parts of the paper the notation is not very rigorous and sometimes it may create confusion. In general, the writing needs to be improved in many parts:\n- In eq. 1, it is not explained what the expectation is wrt. It should be x drawn from p(x). But it would be better to make it explicit.\n- The setting defined in sect.2 should be more rigorous: it is not clear what y is and what are the attributes we would like to be invariant for. This notation is not fully consistent with eq.1.\n- In the first paragraph of Sect.3, it would be very helpful to have a more complete sketch of the algorithm. In general, you mention in the Sect. 2 that you focus on the supervised case, but then it is not clear whether this is the case across the paper.\n2- While the intuition behind using the divergence is sound, as it is mentioned, it seems to suffer from the same issue as the original AII: minimizing a lower bound does not guarantee that we are minimizing the actual objective. Having the support of 0, does not seem to make it much more sensible.\n3- As the description of the algorithm advances in Sect.4.2, it is clear that many additional choices need to be made in order to have a full workable algorithm (e.g., how to estimate q_\\phi^i). In the paper, the actual algorithm is never reported in detail and this makes the experiments very hard to reproduce in my opinion.\n4- At the best of my understanding, the algorithm may become more and more intractable as the number of attribute values grows. In fact, you need to check the divergence for each pair of values and estimated distributions.\n5- The empirical analysis seems well executed and a good level of detail is reported on how the datasets are managed and the experiments are set up.\n\nMinor comments:\n- The caption of Fig.1 is not very clear. Many elements at this stage of the paper are not defined yet (e.g., \"our proposal minimize the proxy of divergence ...\").\n- p2: \"as the assumption of ... is rarely holds\", remove \"is\"\n- p3: \"(encoder) that parameterized\", remove \"that\"\n- last paragraph of Sect.2 is very confusing.\n- p4: \"updation\" is not a word\n- p4: \"In general, minimizing the upper bound...\" does not seem correct.\n- p4: \"even such a simple case\" -> \"even in such a simple case\"\n- Sect 4.1 \"the above theoretical\", I would not really say there is much theory behind the analysis in the previous section.\n- p5 \"an ttribute\" -> \"an attribute\"\n- p6 \"the average discriminator's perception\" what is the perception?"}, "signatures": ["ICLR.cc/2020/Conference/Paper234/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper234/AnonReviewer3"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["iwasawa@weblab.t.u-tokyo.ac.jp", "akuzawa-kei@weblab.t.u-tokyo.ac.jp", "matsuo@weblab.t.u-tokyo.ac.jp"], "title": "Stablizing Adversarial Invariance Induction by Discriminator Matching", "authors": ["Yusuke Iwasawa", "Kei Akuzawa", "Yutaka Matsuo"], "pdf": "/pdf/1d18f8fa9539eb5c076a21b4e781164ea090e944.pdf", "abstract": "Incorporating the desired invariance into representation learning is a key challenge in many situations, e.g., for domain generalization and privacy/fairness constraints. An adversarial invariance induction (AII) shows its power on this purpose, which maximizes the proxy of the conditional entropy between representations and attributes by adversarial training between an attribute discriminator and feature extractor. However, the practical behavior of AII is still unclear as the previous analysis assumes the optimality of the attribute classifier, which is rarely held in practice. This paper first analyzes the practical behavior of AII both theoretically and empirically, indicating that AII has theoretical difficulty as it maximizes variational {\\em upper} bound of the actual conditional entropy, and AII catastrophically fails to induce invariance even in simple cases as suggested by the above theoretical findings. We then argue that a simple modification to AII can significantly stabilize the adversarial induction framework and achieve better invariant representations. Our modification is based on the property of conditional entropy; it is maximized if and only if the divergence between all pairs of marginal distributions over $z$ between different attributes is minimized. The proposed method, {\\em invariance induction by discriminator matching}, modify AII objective to explicitly consider the divergence minimization requirements by defining a proxy of the divergence by using the attribute discriminator. Empirical validations on both the toy dataset and four real-world datasets (related to applications of user anonymization and domain generalization) reveal that the proposed method provides superior performance when inducing invariance for nuisance factors. ", "keywords": ["invariance induction", "adversarial training", "domain generalization"], "paperhash": "iwasawa|stablizing_adversarial_invariance_induction_by_discriminator_matching", "original_pdf": "/attachment/8fb217aa06f3176dbbd2f067ff9435e4e4859158.pdf", "_bibtex": "@misc{\niwasawa2020stablizing,\ntitle={Stablizing Adversarial Invariance Induction by Discriminator Matching},\nauthor={Yusuke Iwasawa and Kei Akuzawa and Yutaka Matsuo},\nyear={2020},\nurl={https://openreview.net/forum?id=B1lFa3EFwB}\n}"}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "B1lFa3EFwB", "replyto": "B1lFa3EFwB", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper234/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper234/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1575550007547, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper234/Reviewers"], "noninvitees": [], "tcdate": 1570237755084, "tmdate": 1575550007566, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper234/-/Official_Review"}}}], "count": 9}