{"notes": [{"id": "rJxWxxSYvB", "original": "rkl2Qn1YPr", "number": 2088, "cdate": 1569439720983, "ddate": null, "tcdate": 1569439720983, "tmdate": 1583912044163, "tddate": null, "forum": "rJxWxxSYvB", "replyto": null, "invitation": "ICLR.cc/2020/Conference/-/Blind_Submission", "content": {"title": "Spike-based causal inference for weight alignment", "authors": ["Jordan Guerguiev", "Konrad Kording", "Blake Richards"], "authorids": ["jordan.guerguiev@utoronto.ca", "koerding@gmail.com", "blake.richards@mcgill.ca"], "keywords": ["causal", "inference", "weight", "transport", "rdd", "regression", "discontinuity", "design", "cifar10", "biologically", "plausible"], "TL;DR": "We present a learning rule for feedback weights in a spiking neural network that addresses the weight transport problem.", "abstract": "In artificial neural networks trained with gradient descent, the weights used for processing stimuli are also used during backward passes to calculate gradients. For the real brain to approximate gradients, gradient information would have to be propagated separately, such that one set of synaptic weights is used for processing and another set is used for backward passes. This produces the so-called \"weight transport problem\" for biological models of learning, where the backward weights used to calculate gradients need to mirror the forward weights used to process stimuli. This weight transport problem has been considered so hard that popular proposals for biological learning assume that the backward weights are simply random, as in the feedback alignment algorithm. However, such random weights do not appear to work well for large networks. Here we show how the discontinuity introduced in a spiking system can lead to a solution to this problem. The resulting algorithm is a special case of an estimator used for causal inference in econometrics, regression discontinuity design. We show empirically that this algorithm rapidly makes the backward weights approximate the forward weights. As the backward weights become correct, this improves learning performance over feedback alignment on tasks such as Fashion-MNIST and CIFAR-10. Our results demonstrate that a simple learning rule in a spiking network can allow neurons to produce the right backward connections and thus solve the weight transport problem.", "pdf": "/pdf/857516daf7cda3fae833c10b2e12ed6cf6094d49.pdf", "code": "https://anonfile.com/51V8Ge66n3/Code_zip", "paperhash": "guerguiev|spikebased_causal_inference_for_weight_alignment", "_bibtex": "@inproceedings{\nGuerguiev2020Spike-based,\ntitle={Spike-based causal inference for weight alignment},\nauthor={Jordan Guerguiev and Konrad Kording and Blake Richards},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=rJxWxxSYvB}\n}", "full_presentation_video": "", "original_pdf": "/attachment/b7c0b84df96b2baf079ef31d47fb9e47b6d84e7a.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "signatures": ["ICLR.cc/2020/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference"], "details": {"replyCount": 8, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"reply": {"readers": {"values-regex": ".*"}, "writers": {"values": ["ICLR.cc/2020/Conference"]}, "signatures": {"values": ["ICLR.cc/2020/Conference"]}, "content": {"spotlight_video": {"value-regex": ".*"}, "full_presentation_video": {"value-regex": ".*"}, "original_pdf": {"required": false, "description": "Upload a PDF file that ends with .pdf", "value-regex": ".*"}, "appendix": {"value-regex": ".*"}, "authorids": {"values-regex": ".*"}, "poster": {"value-regex": ".*"}, "authors": {"values": ["Anonymous"]}, "slides": {"value-regex": ".*"}}}, "final": [], "signatures": ["ICLR.cc/2020/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference"], "noninvitees": [], "tcdate": 1569271260237, "tmdate": 1593459412141, "id": "ICLR.cc/2020/Conference/-/Blind_Submission"}}, "tauthor": "ICLR.cc/2020/Conference"}, {"id": "P7wcJAFekV", "original": null, "number": 1, "cdate": 1576798740171, "ddate": null, "tcdate": 1576798740171, "tmdate": 1576800896084, "tddate": null, "forum": "rJxWxxSYvB", "replyto": "rJxWxxSYvB", "invitation": "ICLR.cc/2020/Conference/Paper2088/-/Decision", "content": {"decision": "Accept (Poster)", "comment": "All authors agree the paper is well written, and there is a good consensus on acceptance.  The last reviewer was concerned about a lack of diversity in datasets, but this was addressed in the rebuttal.", "title": "Paper Decision"}, "signatures": ["ICLR.cc/2020/Conference/Program_Chairs"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Program_Chairs"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Spike-based causal inference for weight alignment", "authors": ["Jordan Guerguiev", "Konrad Kording", "Blake Richards"], "authorids": ["jordan.guerguiev@utoronto.ca", "koerding@gmail.com", "blake.richards@mcgill.ca"], "keywords": ["causal", "inference", "weight", "transport", "rdd", "regression", "discontinuity", "design", "cifar10", "biologically", "plausible"], "TL;DR": "We present a learning rule for feedback weights in a spiking neural network that addresses the weight transport problem.", "abstract": "In artificial neural networks trained with gradient descent, the weights used for processing stimuli are also used during backward passes to calculate gradients. For the real brain to approximate gradients, gradient information would have to be propagated separately, such that one set of synaptic weights is used for processing and another set is used for backward passes. This produces the so-called \"weight transport problem\" for biological models of learning, where the backward weights used to calculate gradients need to mirror the forward weights used to process stimuli. This weight transport problem has been considered so hard that popular proposals for biological learning assume that the backward weights are simply random, as in the feedback alignment algorithm. However, such random weights do not appear to work well for large networks. Here we show how the discontinuity introduced in a spiking system can lead to a solution to this problem. The resulting algorithm is a special case of an estimator used for causal inference in econometrics, regression discontinuity design. We show empirically that this algorithm rapidly makes the backward weights approximate the forward weights. As the backward weights become correct, this improves learning performance over feedback alignment on tasks such as Fashion-MNIST and CIFAR-10. Our results demonstrate that a simple learning rule in a spiking network can allow neurons to produce the right backward connections and thus solve the weight transport problem.", "pdf": "/pdf/857516daf7cda3fae833c10b2e12ed6cf6094d49.pdf", "code": "https://anonfile.com/51V8Ge66n3/Code_zip", "paperhash": "guerguiev|spikebased_causal_inference_for_weight_alignment", "_bibtex": "@inproceedings{\nGuerguiev2020Spike-based,\ntitle={Spike-based causal inference for weight alignment},\nauthor={Jordan Guerguiev and Konrad Kording and Blake Richards},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=rJxWxxSYvB}\n}", "full_presentation_video": "", "original_pdf": "/attachment/b7c0b84df96b2baf079ef31d47fb9e47b6d84e7a.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "tags": [], "invitation": {"reply": {"writers": {"description": "How your identity will be displayed.", "values-regex": ["ICLR.cc/2020/Conference/Program_Chairs"]}, "signatures": {"values": ["ICLR.cc/2020/Conference/Program_Chairs"], "description": "How your identity will be displayed."}, "content": {"decision": {"value-radio": ["Accept (Spotlight)", "Accept (Talk)", "Accept (Poster)", "Reject"], "description": "Decision", "required": true, "order": 2}, "title": {"value": "Paper Decision", "required": true, "order": 1}, "comment": {"value-regex": "[\\S\\s]{0,5000}", "description": "", "required": false, "order": 3}}, "forum": "rJxWxxSYvB", "replyto": "rJxWxxSYvB", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}}, "expdate": 1576854540000, "duedate": 1576853940000, "multiReply": false, "readers": ["everyone"], "invitees": ["ICLR.cc/2020/Conference/Program_Chairs"], "tcdate": 1576795714535, "tmdate": 1576800264262, "super": "ICLR.cc/2020/Conference/-/Decision", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper2088/-/Decision"}}}, {"id": "S1eQziLmFB", "original": null, "number": 1, "cdate": 1571150602918, "ddate": null, "tcdate": 1571150602918, "tmdate": 1573826869938, "tddate": null, "forum": "rJxWxxSYvB", "replyto": "rJxWxxSYvB", "invitation": "ICLR.cc/2020/Conference/Paper2088/-/Official_Review", "content": {"experience_assessment": "I have read many papers in this area.", "rating": "6: Weak Accept", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "review_assessment:_thoroughness_in_paper_reading": "I made a quick assessment of this paper.", "title": "Official Blind Review #2", "review": "The paper introduces a training mechanism for spiking neural nets that employs a causal inference technique, called RDD, for adjustment of backward spiking weights. This technique induces the backward influence strengths to be reciprocal to the forward ones, bringing desirable symmetry properties.\n\nPros:\n * The relationship between causal inference and biologically plausible learning is very interesting. This relationship is also important and impactful for the machine learning community, as we are on the quest of new deep learning technologies.\n\n * Application of the RDD method to spiking neural net training is novel. The reciprocal relationship of the causal effect to the synaptic strength is a very intuitive and elegant solution to the weight transport problem.\n\nCons:\n * From the reported results, it is not possible to decide whether RDD really outperforms Feedback Alignment (FA). The comparison is performed on only two data sets and each algorithm is better on one. Could the authors report results on at least two more data sets (however small or simple) during the rebuttal?\n\n * Fig and Table 1 report the same outcome. One of the two need to be removed.\n\nFurther Questions:\n * The Conv Net illustrated in Fig 2 panel A shares its weights with the biologically plausible net on panel B. Further, these two nets communicate for pre-training. How does the paper then isolate the contribution of the biologically plausible net to the prediction accuracy from the vanilla ConvNet? What would happen if we trained only the LIF net without a contact with the conv net?\n\n * Eq. 1 proposes induction of symmetry to solve the weight transform. At the extreme, this regularizer would make W and Y identical, boiling down to  a vanilla artificial neural net, which the ML community already knows wella nd performs with excellence. Would not having the biologically  implausible artificial neural model as the extreme solution contradict with the goal of biologically plausible learning? This would in the end make one conclude that the biological brain only performs a broken gradient descent.\n\nOverall, this is a decent piece of work with some potential. My initial vote is a weak reject, as I  am at present missing sufficient evidence that the improved symmetry properties introduced by the causal inference scheme also brings an accuracy improvement over the vanilla feedback alignment method. I am open to improve to an accept if this evidence is provided and my aforementioned concerns primarily on the role of ConvNet are properly addressed during rebuttal.\n\n\n--\nPost-rebuttal: My only major concern was the lack of sufficient empirical evidence to support the idea. The updated version of the manuscript has properly addressed this issue by reporting results on additional data sets. The authors have also given enlightening clarifications to some of the open points I have raised earlier. Hence, I'm happy to increase my score.", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory."}, "signatures": ["ICLR.cc/2020/Conference/Paper2088/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper2088/AnonReviewer2"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Spike-based causal inference for weight alignment", "authors": ["Jordan Guerguiev", "Konrad Kording", "Blake Richards"], "authorids": ["jordan.guerguiev@utoronto.ca", "koerding@gmail.com", "blake.richards@mcgill.ca"], "keywords": ["causal", "inference", "weight", "transport", "rdd", "regression", "discontinuity", "design", "cifar10", "biologically", "plausible"], "TL;DR": "We present a learning rule for feedback weights in a spiking neural network that addresses the weight transport problem.", "abstract": "In artificial neural networks trained with gradient descent, the weights used for processing stimuli are also used during backward passes to calculate gradients. For the real brain to approximate gradients, gradient information would have to be propagated separately, such that one set of synaptic weights is used for processing and another set is used for backward passes. This produces the so-called \"weight transport problem\" for biological models of learning, where the backward weights used to calculate gradients need to mirror the forward weights used to process stimuli. This weight transport problem has been considered so hard that popular proposals for biological learning assume that the backward weights are simply random, as in the feedback alignment algorithm. However, such random weights do not appear to work well for large networks. Here we show how the discontinuity introduced in a spiking system can lead to a solution to this problem. The resulting algorithm is a special case of an estimator used for causal inference in econometrics, regression discontinuity design. We show empirically that this algorithm rapidly makes the backward weights approximate the forward weights. As the backward weights become correct, this improves learning performance over feedback alignment on tasks such as Fashion-MNIST and CIFAR-10. Our results demonstrate that a simple learning rule in a spiking network can allow neurons to produce the right backward connections and thus solve the weight transport problem.", "pdf": "/pdf/857516daf7cda3fae833c10b2e12ed6cf6094d49.pdf", "code": "https://anonfile.com/51V8Ge66n3/Code_zip", "paperhash": "guerguiev|spikebased_causal_inference_for_weight_alignment", "_bibtex": "@inproceedings{\nGuerguiev2020Spike-based,\ntitle={Spike-based causal inference for weight alignment},\nauthor={Jordan Guerguiev and Konrad Kording and Blake Richards},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=rJxWxxSYvB}\n}", "full_presentation_video": "", "original_pdf": "/attachment/b7c0b84df96b2baf079ef31d47fb9e47b6d84e7a.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "rJxWxxSYvB", "replyto": "rJxWxxSYvB", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper2088/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper2088/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1574990807171, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper2088/Reviewers"], "noninvitees": [], "tcdate": 1570237727872, "tmdate": 1574990807187, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper2088/-/Official_Review"}}}, {"id": "H1xV5ffosr", "original": null, "number": 4, "cdate": 1573753483602, "ddate": null, "tcdate": 1573753483602, "tmdate": 1573753483602, "tddate": null, "forum": "rJxWxxSYvB", "replyto": "rJxWxxSYvB", "invitation": "ICLR.cc/2020/Conference/Paper2088/-/Official_Comment", "content": {"title": "Response to Reviewers", "comment": "We would like to thank all of the reviewers for their encouraging comments and helpful critiques. We have updated the manuscript and believe that we have addressed the concerns that were raised. We provide responses to specific points below."}, "signatures": ["ICLR.cc/2020/Conference/Paper2088/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper2088/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Spike-based causal inference for weight alignment", "authors": ["Jordan Guerguiev", "Konrad Kording", "Blake Richards"], "authorids": ["jordan.guerguiev@utoronto.ca", "koerding@gmail.com", "blake.richards@mcgill.ca"], "keywords": ["causal", "inference", "weight", "transport", "rdd", "regression", "discontinuity", "design", "cifar10", "biologically", "plausible"], "TL;DR": "We present a learning rule for feedback weights in a spiking neural network that addresses the weight transport problem.", "abstract": "In artificial neural networks trained with gradient descent, the weights used for processing stimuli are also used during backward passes to calculate gradients. For the real brain to approximate gradients, gradient information would have to be propagated separately, such that one set of synaptic weights is used for processing and another set is used for backward passes. This produces the so-called \"weight transport problem\" for biological models of learning, where the backward weights used to calculate gradients need to mirror the forward weights used to process stimuli. This weight transport problem has been considered so hard that popular proposals for biological learning assume that the backward weights are simply random, as in the feedback alignment algorithm. However, such random weights do not appear to work well for large networks. Here we show how the discontinuity introduced in a spiking system can lead to a solution to this problem. The resulting algorithm is a special case of an estimator used for causal inference in econometrics, regression discontinuity design. We show empirically that this algorithm rapidly makes the backward weights approximate the forward weights. As the backward weights become correct, this improves learning performance over feedback alignment on tasks such as Fashion-MNIST and CIFAR-10. Our results demonstrate that a simple learning rule in a spiking network can allow neurons to produce the right backward connections and thus solve the weight transport problem.", "pdf": "/pdf/857516daf7cda3fae833c10b2e12ed6cf6094d49.pdf", "code": "https://anonfile.com/51V8Ge66n3/Code_zip", "paperhash": "guerguiev|spikebased_causal_inference_for_weight_alignment", "_bibtex": "@inproceedings{\nGuerguiev2020Spike-based,\ntitle={Spike-based causal inference for weight alignment},\nauthor={Jordan Guerguiev and Konrad Kording and Blake Richards},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=rJxWxxSYvB}\n}", "full_presentation_video": "", "original_pdf": "/attachment/b7c0b84df96b2baf079ef31d47fb9e47b6d84e7a.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "rJxWxxSYvB", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper2088/Authors", "ICLR.cc/2020/Conference/Paper2088/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper2088/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper2088/Reviewers", "ICLR.cc/2020/Conference/Paper2088/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper2088/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper2088/Authors|ICLR.cc/2020/Conference/Paper2088/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504146510, "tmdate": 1576860531680, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper2088/Authors", "ICLR.cc/2020/Conference/Paper2088/Reviewers", "ICLR.cc/2020/Conference/Paper2088/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper2088/-/Official_Comment"}}}, {"id": "HyxVOMzior", "original": null, "number": 3, "cdate": 1573753451623, "ddate": null, "tcdate": 1573753451623, "tmdate": 1573753451623, "tddate": null, "forum": "rJxWxxSYvB", "replyto": "S1eQziLmFB", "invitation": "ICLR.cc/2020/Conference/Paper2088/-/Official_Comment", "content": {"title": "Response to Reviewer #2", "comment": "\"From the reported results, it is not possible to decide whether RDD really outperforms Feedback Alignment (FA). The comparison is performed on only two data sets and each algorithm is better on one.\"  \n\nWe are afraid that we must have been unclear in the original submission, so thank you for raising this. To clarify, RDD performs better than FA on all of the datasets we have investigated to date. \n\n\"Could the authors report results on at least two more data sets (however small or simple) during the rebuttal?\"\n\nThis is a very valid request, and we are happy to oblige. We have no also tested on the SVHN and VOC datasets. RDD outperforms FA on both datasets (see updated Figure 5).\n\n\"Fig and Table 1 report the same outcome. One of the two need to be removed.\"\n\nFair point, we have removed Table 1, and provide both training and testing results in Figure 5 now.\n\n\"The Conv Net illustrated in Fig 2 panel A shares its weights with the biologically plausible net on panel B. Further, these two nets communicate for pre-training. How does the paper then isolate the contribution of the biologically plausible net to the prediction accuracy from the vanilla ConvNet? What would happen if we trained only the LIF net without a contact with the conv net?\"\n\nWe now see that we were insufficiently clear in the original submission, so again, thank you for raising this. The interaction between the ConvNet and the LIF net is as follows: the two networks share weights, but the ConvNet is used for training the feedforward weights and measuring accuracy, while the LIF net is only for training the feedback weights. More specifically, on each epoch, we train the feedforward weights with the ConvNet, using the current setting of the feedback weights. This means that the transpose of the feedforward weights in the usual gradient update term is replaced with the current feedback weights. Then, we transfer the new feedforward weights from the ConvNet to the LIF net, and we train only the feedback weights. This continues: the feedback weights of the ConvNet are set to the new values from the LIF net, and so on. Thus, the LIF net is not learning to categorize the images, it is only learning the feedback weights, which get used by the ConvNet for the feedforward training. We have clarified this in the text and Figure 2A. We do this because our goal in this paper is simply to test the RDD algorithm's ability to learn good feedback weights, not to test the ability of an LIF net to perform categorization.\n\n\"Eq. 1 proposes induction of symmetry to solve the weight transform. At the extreme, this regularizer would make W and Y identical, boiling down to  a vanilla artificial neural net, which the ML community already knows well and performs with excellence. Would not having the biologically  implausible artificial neural model as the extreme solution contradict with the goal of biologically plausible learning? This would in the end make one conclude that the biological brain only performs a broken gradient descent.\"\n\nThe reviewer is correct that the symmetric alignment cost function would only be zero when perfect symmetry in weights is achieved. The reviewer is also correct that this would indicate that biological networks were approximating gradient descent. However, that is part of the point of this exercise. To date, no one has demonstrated how one can achieve efficient credit assignment in large networks without at least a good correlation with the true gradient. To be clear, we hypothesize that the brain may in fact have a means of estimating gradients, and that this would be achieved, in part, by ensuring symmetry between feedforward and feedback pathways. That may not be a \"broken\" gradient descent, in so far as there can be regularizing advantages to not always perfectly following the gradient. If the reviewer is interested in this perspective, they can read more in our recent review on the topic: Richards, et al. Nature Neuroscience 22, no. 11 (2019): 1761-1770."}, "signatures": ["ICLR.cc/2020/Conference/Paper2088/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper2088/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Spike-based causal inference for weight alignment", "authors": ["Jordan Guerguiev", "Konrad Kording", "Blake Richards"], "authorids": ["jordan.guerguiev@utoronto.ca", "koerding@gmail.com", "blake.richards@mcgill.ca"], "keywords": ["causal", "inference", "weight", "transport", "rdd", "regression", "discontinuity", "design", "cifar10", "biologically", "plausible"], "TL;DR": "We present a learning rule for feedback weights in a spiking neural network that addresses the weight transport problem.", "abstract": "In artificial neural networks trained with gradient descent, the weights used for processing stimuli are also used during backward passes to calculate gradients. For the real brain to approximate gradients, gradient information would have to be propagated separately, such that one set of synaptic weights is used for processing and another set is used for backward passes. This produces the so-called \"weight transport problem\" for biological models of learning, where the backward weights used to calculate gradients need to mirror the forward weights used to process stimuli. This weight transport problem has been considered so hard that popular proposals for biological learning assume that the backward weights are simply random, as in the feedback alignment algorithm. However, such random weights do not appear to work well for large networks. Here we show how the discontinuity introduced in a spiking system can lead to a solution to this problem. The resulting algorithm is a special case of an estimator used for causal inference in econometrics, regression discontinuity design. We show empirically that this algorithm rapidly makes the backward weights approximate the forward weights. As the backward weights become correct, this improves learning performance over feedback alignment on tasks such as Fashion-MNIST and CIFAR-10. Our results demonstrate that a simple learning rule in a spiking network can allow neurons to produce the right backward connections and thus solve the weight transport problem.", "pdf": "/pdf/857516daf7cda3fae833c10b2e12ed6cf6094d49.pdf", "code": "https://anonfile.com/51V8Ge66n3/Code_zip", "paperhash": "guerguiev|spikebased_causal_inference_for_weight_alignment", "_bibtex": "@inproceedings{\nGuerguiev2020Spike-based,\ntitle={Spike-based causal inference for weight alignment},\nauthor={Jordan Guerguiev and Konrad Kording and Blake Richards},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=rJxWxxSYvB}\n}", "full_presentation_video": "", "original_pdf": "/attachment/b7c0b84df96b2baf079ef31d47fb9e47b6d84e7a.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "rJxWxxSYvB", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper2088/Authors", "ICLR.cc/2020/Conference/Paper2088/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper2088/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper2088/Reviewers", "ICLR.cc/2020/Conference/Paper2088/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper2088/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper2088/Authors|ICLR.cc/2020/Conference/Paper2088/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504146510, "tmdate": 1576860531680, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper2088/Authors", "ICLR.cc/2020/Conference/Paper2088/Reviewers", "ICLR.cc/2020/Conference/Paper2088/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper2088/-/Official_Comment"}}}, {"id": "Hyxe0-GoiS", "original": null, "number": 2, "cdate": 1573753287915, "ddate": null, "tcdate": 1573753287915, "tmdate": 1573753287915, "tddate": null, "forum": "rJxWxxSYvB", "replyto": "H1lpyw_atB", "invitation": "ICLR.cc/2020/Conference/Paper2088/-/Official_Comment", "content": {"title": "Response to Reviewer #1", "comment": "\"I had one minor comment on the arrangement of the writing of the paper. Section 4 starts off with \"Results\" but the earlier sub-sections are not really about the results. I would split section 4 as methodology/algorithm and include the everything until section 4.4. From sub section 4.5 onwards are the actual results.\"\n\nYes, we see your point. We have split the materials into methods/results as requested."}, "signatures": ["ICLR.cc/2020/Conference/Paper2088/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper2088/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Spike-based causal inference for weight alignment", "authors": ["Jordan Guerguiev", "Konrad Kording", "Blake Richards"], "authorids": ["jordan.guerguiev@utoronto.ca", "koerding@gmail.com", "blake.richards@mcgill.ca"], "keywords": ["causal", "inference", "weight", "transport", "rdd", "regression", "discontinuity", "design", "cifar10", "biologically", "plausible"], "TL;DR": "We present a learning rule for feedback weights in a spiking neural network that addresses the weight transport problem.", "abstract": "In artificial neural networks trained with gradient descent, the weights used for processing stimuli are also used during backward passes to calculate gradients. For the real brain to approximate gradients, gradient information would have to be propagated separately, such that one set of synaptic weights is used for processing and another set is used for backward passes. This produces the so-called \"weight transport problem\" for biological models of learning, where the backward weights used to calculate gradients need to mirror the forward weights used to process stimuli. This weight transport problem has been considered so hard that popular proposals for biological learning assume that the backward weights are simply random, as in the feedback alignment algorithm. However, such random weights do not appear to work well for large networks. Here we show how the discontinuity introduced in a spiking system can lead to a solution to this problem. The resulting algorithm is a special case of an estimator used for causal inference in econometrics, regression discontinuity design. We show empirically that this algorithm rapidly makes the backward weights approximate the forward weights. As the backward weights become correct, this improves learning performance over feedback alignment on tasks such as Fashion-MNIST and CIFAR-10. Our results demonstrate that a simple learning rule in a spiking network can allow neurons to produce the right backward connections and thus solve the weight transport problem.", "pdf": "/pdf/857516daf7cda3fae833c10b2e12ed6cf6094d49.pdf", "code": "https://anonfile.com/51V8Ge66n3/Code_zip", "paperhash": "guerguiev|spikebased_causal_inference_for_weight_alignment", "_bibtex": "@inproceedings{\nGuerguiev2020Spike-based,\ntitle={Spike-based causal inference for weight alignment},\nauthor={Jordan Guerguiev and Konrad Kording and Blake Richards},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=rJxWxxSYvB}\n}", "full_presentation_video": "", "original_pdf": "/attachment/b7c0b84df96b2baf079ef31d47fb9e47b6d84e7a.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "rJxWxxSYvB", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper2088/Authors", "ICLR.cc/2020/Conference/Paper2088/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper2088/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper2088/Reviewers", "ICLR.cc/2020/Conference/Paper2088/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper2088/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper2088/Authors|ICLR.cc/2020/Conference/Paper2088/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504146510, "tmdate": 1576860531680, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper2088/Authors", "ICLR.cc/2020/Conference/Paper2088/Reviewers", "ICLR.cc/2020/Conference/Paper2088/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper2088/-/Official_Comment"}}}, {"id": "BJx5tbGjjB", "original": null, "number": 1, "cdate": 1573753217989, "ddate": null, "tcdate": 1573753217989, "tmdate": 1573753217989, "tddate": null, "forum": "rJxWxxSYvB", "replyto": "H1lQdqkRKB", "invitation": "ICLR.cc/2020/Conference/Paper2088/-/Official_Comment", "content": {"title": "Response to Reviewer #3", "comment": "Thank you for your comments!"}, "signatures": ["ICLR.cc/2020/Conference/Paper2088/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper2088/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Spike-based causal inference for weight alignment", "authors": ["Jordan Guerguiev", "Konrad Kording", "Blake Richards"], "authorids": ["jordan.guerguiev@utoronto.ca", "koerding@gmail.com", "blake.richards@mcgill.ca"], "keywords": ["causal", "inference", "weight", "transport", "rdd", "regression", "discontinuity", "design", "cifar10", "biologically", "plausible"], "TL;DR": "We present a learning rule for feedback weights in a spiking neural network that addresses the weight transport problem.", "abstract": "In artificial neural networks trained with gradient descent, the weights used for processing stimuli are also used during backward passes to calculate gradients. For the real brain to approximate gradients, gradient information would have to be propagated separately, such that one set of synaptic weights is used for processing and another set is used for backward passes. This produces the so-called \"weight transport problem\" for biological models of learning, where the backward weights used to calculate gradients need to mirror the forward weights used to process stimuli. This weight transport problem has been considered so hard that popular proposals for biological learning assume that the backward weights are simply random, as in the feedback alignment algorithm. However, such random weights do not appear to work well for large networks. Here we show how the discontinuity introduced in a spiking system can lead to a solution to this problem. The resulting algorithm is a special case of an estimator used for causal inference in econometrics, regression discontinuity design. We show empirically that this algorithm rapidly makes the backward weights approximate the forward weights. As the backward weights become correct, this improves learning performance over feedback alignment on tasks such as Fashion-MNIST and CIFAR-10. Our results demonstrate that a simple learning rule in a spiking network can allow neurons to produce the right backward connections and thus solve the weight transport problem.", "pdf": "/pdf/857516daf7cda3fae833c10b2e12ed6cf6094d49.pdf", "code": "https://anonfile.com/51V8Ge66n3/Code_zip", "paperhash": "guerguiev|spikebased_causal_inference_for_weight_alignment", "_bibtex": "@inproceedings{\nGuerguiev2020Spike-based,\ntitle={Spike-based causal inference for weight alignment},\nauthor={Jordan Guerguiev and Konrad Kording and Blake Richards},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=rJxWxxSYvB}\n}", "full_presentation_video": "", "original_pdf": "/attachment/b7c0b84df96b2baf079ef31d47fb9e47b6d84e7a.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "rJxWxxSYvB", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper2088/Authors", "ICLR.cc/2020/Conference/Paper2088/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper2088/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper2088/Reviewers", "ICLR.cc/2020/Conference/Paper2088/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper2088/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper2088/Authors|ICLR.cc/2020/Conference/Paper2088/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504146510, "tmdate": 1576860531680, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper2088/Authors", "ICLR.cc/2020/Conference/Paper2088/Reviewers", "ICLR.cc/2020/Conference/Paper2088/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper2088/-/Official_Comment"}}}, {"id": "H1lpyw_atB", "original": null, "number": 2, "cdate": 1571813093192, "ddate": null, "tcdate": 1571813093192, "tmdate": 1572972384563, "tddate": null, "forum": "rJxWxxSYvB", "replyto": "rJxWxxSYvB", "invitation": "ICLR.cc/2020/Conference/Paper2088/-/Official_Review", "content": {"experience_assessment": "I do not know much about this area.", "rating": "6: Weak Accept", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #1", "review_assessment:_checking_correctness_of_derivations_and_theory": "I carefully checked the derivations and theory.", "review": "summary\n\nThis paper considers the \"weight transport problem\" which is the problem of ensuring that the feedforward weights $W_{ij}$ is the same as the feedback weights $W_{ji}$ in the spiking NN model of computation. This paper proposes a novel learning method for the feedback weights which depends on accurately estimating the causal effect of any spiking neuron on the other neurons deeper in the network. Additionally, they show that this method also minimizes a natural cost function. They run many experiments on FashionMNIST and CIFAR-10 to validate this and also show that for deeper networks this approaches the accuracy levels of GD-based algorithms. \n\n\n\ncomments\n\nOverall I find this paper to be well-written and _accessible_ to someone who is not familiar with the biologically plausible learning algorithms. To overcome the massive computational burden, they employ a novel experimental setup. In particular, they use a separate non-spiking neural network to train the feedforward weights and use the spiking neurons only for alignment of weights. They have experimental evidence to show that this method is a legitimate workaround. I find their experimental setup and the results convincing to the best of my knowledge. The experimental results indeed show the claim that the proposed algorithm has the properties stated earlier (i.e., learns the feedback weights correctly and that using this to train deep neural nets provide better performance than weight alignment procedure). I must warn that I am not an expert in this area and thus, might miss some subtleties. Given this, it is also unclear to me why this problem is important and thus, would leave the judgement of this to other reviewers. Here I will score only based on the technical merit of the method used to solve the problem.\n\nI had one minor comment on the arrangement of the writing of the paper. Section 4 starts off with \"Results\" but the earlier sub-sections are not really about the results. I would split section 4 as methodology/algorithm and include the everything until section 4.4. From sub section 4.5 onwards are the actual results.\n\n\noverall decision\n\nWithout commenting on the importance of this problem, I think this paper merits an acceptance based on the technical content. The paper provides convincing experiments to test the properties the author claim the new algorithm has."}, "signatures": ["ICLR.cc/2020/Conference/Paper2088/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper2088/AnonReviewer1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Spike-based causal inference for weight alignment", "authors": ["Jordan Guerguiev", "Konrad Kording", "Blake Richards"], "authorids": ["jordan.guerguiev@utoronto.ca", "koerding@gmail.com", "blake.richards@mcgill.ca"], "keywords": ["causal", "inference", "weight", "transport", "rdd", "regression", "discontinuity", "design", "cifar10", "biologically", "plausible"], "TL;DR": "We present a learning rule for feedback weights in a spiking neural network that addresses the weight transport problem.", "abstract": "In artificial neural networks trained with gradient descent, the weights used for processing stimuli are also used during backward passes to calculate gradients. For the real brain to approximate gradients, gradient information would have to be propagated separately, such that one set of synaptic weights is used for processing and another set is used for backward passes. This produces the so-called \"weight transport problem\" for biological models of learning, where the backward weights used to calculate gradients need to mirror the forward weights used to process stimuli. This weight transport problem has been considered so hard that popular proposals for biological learning assume that the backward weights are simply random, as in the feedback alignment algorithm. However, such random weights do not appear to work well for large networks. Here we show how the discontinuity introduced in a spiking system can lead to a solution to this problem. The resulting algorithm is a special case of an estimator used for causal inference in econometrics, regression discontinuity design. We show empirically that this algorithm rapidly makes the backward weights approximate the forward weights. As the backward weights become correct, this improves learning performance over feedback alignment on tasks such as Fashion-MNIST and CIFAR-10. Our results demonstrate that a simple learning rule in a spiking network can allow neurons to produce the right backward connections and thus solve the weight transport problem.", "pdf": "/pdf/857516daf7cda3fae833c10b2e12ed6cf6094d49.pdf", "code": "https://anonfile.com/51V8Ge66n3/Code_zip", "paperhash": "guerguiev|spikebased_causal_inference_for_weight_alignment", "_bibtex": "@inproceedings{\nGuerguiev2020Spike-based,\ntitle={Spike-based causal inference for weight alignment},\nauthor={Jordan Guerguiev and Konrad Kording and Blake Richards},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=rJxWxxSYvB}\n}", "full_presentation_video": "", "original_pdf": "/attachment/b7c0b84df96b2baf079ef31d47fb9e47b6d84e7a.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "rJxWxxSYvB", "replyto": "rJxWxxSYvB", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper2088/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper2088/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1574990807171, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper2088/Reviewers"], "noninvitees": [], "tcdate": 1570237727872, "tmdate": 1574990807187, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper2088/-/Official_Review"}}}, {"id": "H1lQdqkRKB", "original": null, "number": 3, "cdate": 1571842667317, "ddate": null, "tcdate": 1571842667317, "tmdate": 1572972384518, "tddate": null, "forum": "rJxWxxSYvB", "replyto": "rJxWxxSYvB", "invitation": "ICLR.cc/2020/Conference/Paper2088/-/Official_Review", "content": {"experience_assessment": "I do not know much about this area.", "rating": "8: Accept", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #3", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "Strong paper in the direction of a more biologically plausible solution for the weight transport problem, where the forward and the backward weights need to be aligned. Earlier work for feedback alignment has included methods such as hard-coding sign symmetry. In this method, the authors show that a piece-wise linear model of the feedback as a function of the input given to a neuron can estimate the causal effect of a spike on downstream neurons. The authors propose a learning rule based on regression discontinuity design (RDD) and show that this leads to stronger alignment of weights (especially in earlier layers) compared to previous methods. The causal effect is measured directly from the discontinuity introduced while spiking - the difference between the outputs of the estimated piece-wise linear model at the point of discontinuity is used as the feedback.\n\nCompared to feedback alignment, RDD-based pre-training demonstrates stronger alignment between forward and backward weights and better performance on CIFAR-10 and Fashion-MNIST datasets. Overall, the paper is very well written and addresses an important problem. The theoretical foundation, to my knowledge, is well studied."}, "signatures": ["ICLR.cc/2020/Conference/Paper2088/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper2088/AnonReviewer3"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Spike-based causal inference for weight alignment", "authors": ["Jordan Guerguiev", "Konrad Kording", "Blake Richards"], "authorids": ["jordan.guerguiev@utoronto.ca", "koerding@gmail.com", "blake.richards@mcgill.ca"], "keywords": ["causal", "inference", "weight", "transport", "rdd", "regression", "discontinuity", "design", "cifar10", "biologically", "plausible"], "TL;DR": "We present a learning rule for feedback weights in a spiking neural network that addresses the weight transport problem.", "abstract": "In artificial neural networks trained with gradient descent, the weights used for processing stimuli are also used during backward passes to calculate gradients. For the real brain to approximate gradients, gradient information would have to be propagated separately, such that one set of synaptic weights is used for processing and another set is used for backward passes. This produces the so-called \"weight transport problem\" for biological models of learning, where the backward weights used to calculate gradients need to mirror the forward weights used to process stimuli. This weight transport problem has been considered so hard that popular proposals for biological learning assume that the backward weights are simply random, as in the feedback alignment algorithm. However, such random weights do not appear to work well for large networks. Here we show how the discontinuity introduced in a spiking system can lead to a solution to this problem. The resulting algorithm is a special case of an estimator used for causal inference in econometrics, regression discontinuity design. We show empirically that this algorithm rapidly makes the backward weights approximate the forward weights. As the backward weights become correct, this improves learning performance over feedback alignment on tasks such as Fashion-MNIST and CIFAR-10. Our results demonstrate that a simple learning rule in a spiking network can allow neurons to produce the right backward connections and thus solve the weight transport problem.", "pdf": "/pdf/857516daf7cda3fae833c10b2e12ed6cf6094d49.pdf", "code": "https://anonfile.com/51V8Ge66n3/Code_zip", "paperhash": "guerguiev|spikebased_causal_inference_for_weight_alignment", "_bibtex": "@inproceedings{\nGuerguiev2020Spike-based,\ntitle={Spike-based causal inference for weight alignment},\nauthor={Jordan Guerguiev and Konrad Kording and Blake Richards},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=rJxWxxSYvB}\n}", "full_presentation_video": "", "original_pdf": "/attachment/b7c0b84df96b2baf079ef31d47fb9e47b6d84e7a.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "rJxWxxSYvB", "replyto": "rJxWxxSYvB", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper2088/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper2088/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1574990807171, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper2088/Reviewers"], "noninvitees": [], "tcdate": 1570237727872, "tmdate": 1574990807187, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper2088/-/Official_Review"}}}], "count": 9}