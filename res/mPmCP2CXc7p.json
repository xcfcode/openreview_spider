{"notes": [{"id": "mPmCP2CXc7p", "original": "b5FCnvp6SY4", "number": 2895, "cdate": 1601308321078, "ddate": null, "tcdate": 1601308321078, "tmdate": 1614985724450, "tddate": null, "forum": "mPmCP2CXc7p", "replyto": null, "invitation": "ICLR.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Dynamic Feature Selection for Efficient and Interpretable Human Activity Recognition", "authorids": ["~Randy_Ardywibowo1", "~Shahin_Boluki1", "~Zhangyang_Wang1", "~Bobak_J_Mortazavi1", "~Shuai_Huang1", "~Xiaoning_Qian2"], "authors": ["Randy Ardywibowo", "Shahin Boluki", "Zhangyang Wang", "Bobak J Mortazavi", "Shuai Huang", "Xiaoning Qian"], "keywords": ["dynamic feature selection", "human activity recognition", "sparse monitoring"], "abstract": "In many machine learning tasks, input features with varying degrees of predictive capability are usually acquired at some cost. For example, in human activity recognition (HAR) and mobile health (mHealth) applications, monitoring performance should be achieved with a low cost to gather different sensory features, as maintaining sensors incur monetary, computation, and energy cost. We propose an adaptive feature selection method that dynamically selects features for prediction at any given time point. We formulate this problem as an $\\ell_0$ minimization problem across time, and cast the combinatorial optimization problem into a stochastic optimization formulation. We then utilize a differentiable relaxation to make the problem amenable to gradient-based optimization. Our evaluations on four activity recognition datasets show that our method achieves a favorable trade-off between performance and the number of features used. Moreover, the dynamically selected features of our approach are shown to be interpretable and associated with the actual activity types.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "ardywibowo|dynamic_feature_selection_for_efficient_and_interpretable_human_activity_recognition", "one-sentence_summary": "We propose a task-driven dynamic feature selection method to perform human activity recognition efficiently.", "supplementary_material": "/attachment/0442d36e6c7fe5a2ad24564f6cc62cfd16c1fe28.zip", "pdf": "/pdf/90ae614f77bddbf5e9f886151a7fe2c54ddf1cdb.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=Z6AE_bSR8R", "_bibtex": "@misc{\nardywibowo2021dynamic,\ntitle={Dynamic Feature Selection for Efficient and Interpretable Human Activity Recognition},\nauthor={Randy Ardywibowo and Shahin Boluki and Zhangyang Wang and Bobak J Mortazavi and Shuai Huang and Xiaoning Qian},\nyear={2021},\nurl={https://openreview.net/forum?id=mPmCP2CXc7p}\n}"}, "signatures": ["ICLR.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference"], "details": {"replyCount": 17, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"reply": {"readers": {"values-regex": ".*"}, "writers": {"values": ["ICLR.cc/2021/Conference"]}, "signatures": {"values": ["ICLR.cc/2021/Conference"]}, "content": {"authors": {"values": ["Anonymous"]}, "authorids": {"values-regex": ".*"}, "reviewed_version_(pdf)": {"required": false, "description": "Upload a PDF file that ends with .pdf", "value-regex": ".*"}}}, "signatures": ["ICLR.cc/2021/Conference"], "readers": ["everyone"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["~", "OpenReview.net/Support"], "tcdate": 1601308008205, "tmdate": 1614984599368, "id": "ICLR.cc/2021/Conference/-/Blind_Submission"}}, "tauthor": "OpenReview.net"}, {"id": "J8RGfMTmBfo", "original": null, "number": 1, "cdate": 1610040416071, "ddate": null, "tcdate": 1610040416071, "tmdate": 1610474014192, "tddate": null, "forum": "mPmCP2CXc7p", "replyto": "mPmCP2CXc7p", "invitation": "ICLR.cc/2021/Conference/Paper2895/-/Decision", "content": {"title": "Final Decision", "decision": "Reject", "comment": "The authors propose a methodoloy for dynamic feature selection. They use differentiable gates with \nan RNN architecture to select different subsets of features at each time point thus resulting in dynamic selection. \nThe reviewers agree that the idea is interesting and the method could be useful and I share their opinion.\n\nThe majority vote is towards rejection. The overarching mwssage of the reviews is that the manuscript raises confusion in a number of points. I see this work as one with good potential for impact but its current presentation is confusing. The vivid discussion that it raised is also an indication of it. The authors have done a good job replying to the concerns and the questions raised. However, the reviewers were still unsatisfied with the authors response to their concerns.  I recommend rejection at this time, while encouraging the authors to take seriously the reviewers' requests for a clearer presentation of their approach's contribution in order to strengthen their paper for future submission.\n\n"}, "signatures": ["ICLR.cc/2021/Conference/Program_Chairs"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference/Program_Chairs"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Dynamic Feature Selection for Efficient and Interpretable Human Activity Recognition", "authorids": ["~Randy_Ardywibowo1", "~Shahin_Boluki1", "~Zhangyang_Wang1", "~Bobak_J_Mortazavi1", "~Shuai_Huang1", "~Xiaoning_Qian2"], "authors": ["Randy Ardywibowo", "Shahin Boluki", "Zhangyang Wang", "Bobak J Mortazavi", "Shuai Huang", "Xiaoning Qian"], "keywords": ["dynamic feature selection", "human activity recognition", "sparse monitoring"], "abstract": "In many machine learning tasks, input features with varying degrees of predictive capability are usually acquired at some cost. For example, in human activity recognition (HAR) and mobile health (mHealth) applications, monitoring performance should be achieved with a low cost to gather different sensory features, as maintaining sensors incur monetary, computation, and energy cost. We propose an adaptive feature selection method that dynamically selects features for prediction at any given time point. We formulate this problem as an $\\ell_0$ minimization problem across time, and cast the combinatorial optimization problem into a stochastic optimization formulation. We then utilize a differentiable relaxation to make the problem amenable to gradient-based optimization. Our evaluations on four activity recognition datasets show that our method achieves a favorable trade-off between performance and the number of features used. Moreover, the dynamically selected features of our approach are shown to be interpretable and associated with the actual activity types.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "ardywibowo|dynamic_feature_selection_for_efficient_and_interpretable_human_activity_recognition", "one-sentence_summary": "We propose a task-driven dynamic feature selection method to perform human activity recognition efficiently.", "supplementary_material": "/attachment/0442d36e6c7fe5a2ad24564f6cc62cfd16c1fe28.zip", "pdf": "/pdf/90ae614f77bddbf5e9f886151a7fe2c54ddf1cdb.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=Z6AE_bSR8R", "_bibtex": "@misc{\nardywibowo2021dynamic,\ntitle={Dynamic Feature Selection for Efficient and Interpretable Human Activity Recognition},\nauthor={Randy Ardywibowo and Shahin Boluki and Zhangyang Wang and Bobak J Mortazavi and Shuai Huang and Xiaoning Qian},\nyear={2021},\nurl={https://openreview.net/forum?id=mPmCP2CXc7p}\n}"}, "tags": [], "invitation": {"reply": {"forum": "mPmCP2CXc7p", "replyto": "mPmCP2CXc7p", "readers": {"values": ["everyone"]}, "writers": {"values": ["ICLR.cc/2021/Conference/Program_Chairs"]}, "signatures": {"values": ["ICLR.cc/2021/Conference/Program_Chairs"]}, "content": {"title": {"value": "Final Decision"}, "decision": {"value-radio": ["Accept (Oral)", "Accept (Spotlight)", "Accept (Poster)", "Reject"]}, "comment": {"value-regex": "[\\S\\s]{0,50000}", "markdown": true}}}, "multiReply": false, "signatures": ["ICLR.cc/2021/Conference"], "readers": ["everyone"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Program_Chairs"], "tcdate": 1610040416057, "tmdate": 1610474014176, "id": "ICLR.cc/2021/Conference/Paper2895/-/Decision"}}}, {"id": "JB558U0yuIo", "original": null, "number": 13, "cdate": 1606198926349, "ddate": null, "tcdate": 1606198926349, "tmdate": 1606198926349, "tddate": null, "forum": "mPmCP2CXc7p", "replyto": "_ih8FZgwtX0", "invitation": "ICLR.cc/2021/Conference/Paper2895/-/Official_Comment", "content": {"title": "Reply to Reviewer 2", "comment": "We thank the reviewer for spending significant time on reading our submission and responses multiple times. We also apologize if we have offended the reviewer somehow either in our original submission or our first response. We are glad to come to a mutual understanding.\n\nWe would, however, now draw the reviewer\u2019s attention to our latest draft. Frankly, we suspect our submission was not assessed on its merits due to the previous concerns raised by the reviewer. In particular, we draw attention back to three points: \n\n1) The reviewer originally did not seem to get what we tried to claim that our dynamic/adaptive feature selection formulation is new and different from the existing work. We got this impression as the reviewer compared our method to the reference [1] in regards to model compression/inference speed up in his/her original review. We tried to explain the possible confusion in our first response because of this impression.  \n\n2) Regarding the $l_0$ relaxation accusation, we again clearly stated that we \u201cextend\u201d the existing non-adaptive/static solutions to help solve our adaptive formulation in Section 2.3 of the original submission. We would like to again note that it is critical to present Eq. 6 in methodology to derive adaptive and locally parametrized feature selection, which is essential for our paper. We presented the non-adaptive static formulations there for better readability to make sure that the readers can get the differences between Eq. 4 and Eq. 6. As we have shown in our ongoing revision, we took the reviewer\u2019s original review seriously and have tried to address this concern by adding more detailed discussion as well as references in Section 2.3. We did not post the revision with our first response as we were waiting for all the additional experimental results to address all the reviewers\u2019 comments. We welcome more suggestions if the reviewer felt that our current revision still has issues or statements that somehow annoy the reviewer. \n\n3) The reviewer misunderstood our purpose of dynamic feature selection in the original review stating \u201cthere is no way to infer if this feature selection method can result in any compression of the model or could lead to training or inference speed up.\u201d We tried to explain this in our first response that we have never tried to compress or simplify the activity recognition model in the first place. Our purpose is to reduce the sensor and thereafter power usage, which was presented in our original submission. \n\nAgain, we are open to any constructive suggestions on how we shall further improve our presentation and truly appreciate any concrete and constructive requested changes, including reorganizing the specific content, that we may need to revise further. Meanwhile, from the current discussion, it has been very clear that:\n\n- Our current paper has no major technical flaw, and several misunderstandings were already clarified.\n- We have not over-claimed our contribution. The relationship between our submission and related work has been addressed, from the first submission draft, to the current discussion thread. \n- We\u2019re open to more paper structure discussions and appreciate your inputs, but those only re-organized what we already have had in paper. \n\nWe politely request the reviewer to:\n\n- Take back his/her ungrounded accusation on \u201cviolating code of ethics\u201d. That is too serious for us to accept.\nConsider providing another fair re-assessment of this work based on the above clarification discussions.\n\n- Let\u2019s all lower the temperature and focus back on the science - we very respectfully thank the reviewer\u2019s time and would sincerely appreciate a more positive consideration. \n"}, "signatures": ["ICLR.cc/2021/Conference/Paper2895/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2895/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Dynamic Feature Selection for Efficient and Interpretable Human Activity Recognition", "authorids": ["~Randy_Ardywibowo1", "~Shahin_Boluki1", "~Zhangyang_Wang1", "~Bobak_J_Mortazavi1", "~Shuai_Huang1", "~Xiaoning_Qian2"], "authors": ["Randy Ardywibowo", "Shahin Boluki", "Zhangyang Wang", "Bobak J Mortazavi", "Shuai Huang", "Xiaoning Qian"], "keywords": ["dynamic feature selection", "human activity recognition", "sparse monitoring"], "abstract": "In many machine learning tasks, input features with varying degrees of predictive capability are usually acquired at some cost. For example, in human activity recognition (HAR) and mobile health (mHealth) applications, monitoring performance should be achieved with a low cost to gather different sensory features, as maintaining sensors incur monetary, computation, and energy cost. We propose an adaptive feature selection method that dynamically selects features for prediction at any given time point. We formulate this problem as an $\\ell_0$ minimization problem across time, and cast the combinatorial optimization problem into a stochastic optimization formulation. We then utilize a differentiable relaxation to make the problem amenable to gradient-based optimization. Our evaluations on four activity recognition datasets show that our method achieves a favorable trade-off between performance and the number of features used. Moreover, the dynamically selected features of our approach are shown to be interpretable and associated with the actual activity types.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "ardywibowo|dynamic_feature_selection_for_efficient_and_interpretable_human_activity_recognition", "one-sentence_summary": "We propose a task-driven dynamic feature selection method to perform human activity recognition efficiently.", "supplementary_material": "/attachment/0442d36e6c7fe5a2ad24564f6cc62cfd16c1fe28.zip", "pdf": "/pdf/90ae614f77bddbf5e9f886151a7fe2c54ddf1cdb.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=Z6AE_bSR8R", "_bibtex": "@misc{\nardywibowo2021dynamic,\ntitle={Dynamic Feature Selection for Efficient and Interpretable Human Activity Recognition},\nauthor={Randy Ardywibowo and Shahin Boluki and Zhangyang Wang and Bobak J Mortazavi and Shuai Huang and Xiaoning Qian},\nyear={2021},\nurl={https://openreview.net/forum?id=mPmCP2CXc7p}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "mPmCP2CXc7p", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper2895/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper2895/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper2895/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper2895/Authors|ICLR.cc/2021/Conference/Paper2895/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2895/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923843367, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper2895/-/Official_Comment"}}}, {"id": "_ih8FZgwtX0", "original": null, "number": 12, "cdate": 1606160424460, "ddate": null, "tcdate": 1606160424460, "tmdate": 1606160424460, "tddate": null, "forum": "mPmCP2CXc7p", "replyto": "ayaFJyVKKFQ", "invitation": "ICLR.cc/2021/Conference/Paper2895/-/Official_Comment", "content": {"title": "Reply to authors", "comment": "I have carefully read the paper, numerous times. I am extremely familiar with the field and with the existing results. I have reviewed numerous papers in this field, and have never seen authors mention work developed by others under a section titled \"Methodology\", without explicitly mentioning that what they are presenting is existing work (which should be under background).  \n\n\n\n\"We felt that the reviewer misread and tried to mis-present our paper based on his/her own reading, which is not only careless but also unethical itself to impose this baseless accusation.\"\nIn my initial review, I kindly requested the authors to address this concern, however, this was not fully addressed in their response. \n\nIn the original version these are the locations the authors gave credit for existing results presented under the methodology section (citing the authors):\n\"Note that we have attributed the static l0 formulation to Louizos et al. (2017) (or [18]) in the Results table (Table 2) and in the following location in the original submission file: \u201cTo show the effect of considering dynamic feature selection, we compare a nonadaptive l0 formulation that statically selects features by solving (4) [18]\u201d. Although [18]\u2019s goal is not feature selection, due to the similarity of the optimization strategy, we have attributed the static feature selection by relaxation of l0 and the solution to Eq. (4) to that work. \"\n-Credit is only given in the results section, so if a reader only reads the Methodology section, the relaxation is attributed to the authors. And Credit was not given to Yamada et al. which use the relaxation for feature selection.\n\nI thank the authors for addressing my concern in the current version they due give credit at the appropriate location.\n\n\n\"Since we feel that the reviewer now brought the discussion to quite an emotional state and put ungrounded yet overly harsh criticism to our work (we\u2019re not sure why, though), we politely urge the area chair to take this factor into account and step in this discussion, if possible.\"\nI apologize if this has offended the authors, I do not claim that this was intentional, however, the presentation of the methodology was misleading, especially for readers that are not familiar with this line of works. \n\nThanks for pointing out the union of features, I think this is substantial and should be emphasized in your revised versions. "}, "signatures": ["ICLR.cc/2021/Conference/Paper2895/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2895/AnonReviewer2"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Dynamic Feature Selection for Efficient and Interpretable Human Activity Recognition", "authorids": ["~Randy_Ardywibowo1", "~Shahin_Boluki1", "~Zhangyang_Wang1", "~Bobak_J_Mortazavi1", "~Shuai_Huang1", "~Xiaoning_Qian2"], "authors": ["Randy Ardywibowo", "Shahin Boluki", "Zhangyang Wang", "Bobak J Mortazavi", "Shuai Huang", "Xiaoning Qian"], "keywords": ["dynamic feature selection", "human activity recognition", "sparse monitoring"], "abstract": "In many machine learning tasks, input features with varying degrees of predictive capability are usually acquired at some cost. For example, in human activity recognition (HAR) and mobile health (mHealth) applications, monitoring performance should be achieved with a low cost to gather different sensory features, as maintaining sensors incur monetary, computation, and energy cost. We propose an adaptive feature selection method that dynamically selects features for prediction at any given time point. We formulate this problem as an $\\ell_0$ minimization problem across time, and cast the combinatorial optimization problem into a stochastic optimization formulation. We then utilize a differentiable relaxation to make the problem amenable to gradient-based optimization. Our evaluations on four activity recognition datasets show that our method achieves a favorable trade-off between performance and the number of features used. Moreover, the dynamically selected features of our approach are shown to be interpretable and associated with the actual activity types.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "ardywibowo|dynamic_feature_selection_for_efficient_and_interpretable_human_activity_recognition", "one-sentence_summary": "We propose a task-driven dynamic feature selection method to perform human activity recognition efficiently.", "supplementary_material": "/attachment/0442d36e6c7fe5a2ad24564f6cc62cfd16c1fe28.zip", "pdf": "/pdf/90ae614f77bddbf5e9f886151a7fe2c54ddf1cdb.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=Z6AE_bSR8R", "_bibtex": "@misc{\nardywibowo2021dynamic,\ntitle={Dynamic Feature Selection for Efficient and Interpretable Human Activity Recognition},\nauthor={Randy Ardywibowo and Shahin Boluki and Zhangyang Wang and Bobak J Mortazavi and Shuai Huang and Xiaoning Qian},\nyear={2021},\nurl={https://openreview.net/forum?id=mPmCP2CXc7p}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "mPmCP2CXc7p", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper2895/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper2895/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper2895/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper2895/Authors|ICLR.cc/2021/Conference/Paper2895/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2895/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923843367, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper2895/-/Official_Comment"}}}, {"id": "Sqk8BHX8QRC", "original": null, "number": 11, "cdate": 1606150387438, "ddate": null, "tcdate": 1606150387438, "tmdate": 1606150387438, "tddate": null, "forum": "mPmCP2CXc7p", "replyto": "-B96ryrnoCT", "invitation": "ICLR.cc/2021/Conference/Paper2895/-/Official_Comment", "content": {"title": "Response to Reviewer 4 continued", "comment": "\u201cAlso, selecting the training/validation/testing set by randomly shuffling 70%/10%/20% does not make sense\u201d. As we have stated, our random shuffles split data both chronologically and by different subjects. The human activity recognition (HAR) problem is a multi-class problem. To make sure that we evaluate HAR performance for all the activity types, we compared the performance with baselines in the current setup. To obtain the evaluation as suggested and cover all the activity types, it requires to check all the testing data and often depending on the datasets, it can be difficult to get such a comprehensive testing set. We also note that the UCI HAR dataset is divided into full trajectories of separate subjects in our experiments. The performance of our model on this dataset shows that indeed our model is stable for long-term predictions. To further illustrate this, we show the average accuracy over 1000 seconds of running the model on the testing subjects in this dataset. The results are shown below:\n\nTime: 0-999, 1000-1999, 2000-2999, 3000-3999\n\nErrors (%): 3.49, 2.93, 6.46, 4.06\n\nStd. Dev.: 1.89, 1.23, 1.05, 1.67\n\nBased on the results, there is no clear temporal degradation in the testing performance for this dataset. Instead, the change of prediction errors is mostly dependent on the underlying activity types. \n\nWe thank the reviewer again for the reply, but we would like to firmly state our standing again that we believe our proposed work is a fundamental starting point and the first adaptive feature selection method for HAR to the best of our knowledge. Our method learns a feature selection policy offline, is practically applicable and achieves a comparable or better human activity recognition performance compared to existing baselines using a fraction of the sensor features on average.  We hope the above explanations have clarified the confusions and hope the reviewer could more positively evaluate our work accordingly.\n\n[1] Ross, St\u00e9phane, Geoffrey Gordon, and Drew Bagnell. \"A reduction of imitation learning and structured prediction to no-regret online learning.\" Proceedings of the fourteenth international conference on artificial intelligence and statistics. 2011."}, "signatures": ["ICLR.cc/2021/Conference/Paper2895/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2895/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Dynamic Feature Selection for Efficient and Interpretable Human Activity Recognition", "authorids": ["~Randy_Ardywibowo1", "~Shahin_Boluki1", "~Zhangyang_Wang1", "~Bobak_J_Mortazavi1", "~Shuai_Huang1", "~Xiaoning_Qian2"], "authors": ["Randy Ardywibowo", "Shahin Boluki", "Zhangyang Wang", "Bobak J Mortazavi", "Shuai Huang", "Xiaoning Qian"], "keywords": ["dynamic feature selection", "human activity recognition", "sparse monitoring"], "abstract": "In many machine learning tasks, input features with varying degrees of predictive capability are usually acquired at some cost. For example, in human activity recognition (HAR) and mobile health (mHealth) applications, monitoring performance should be achieved with a low cost to gather different sensory features, as maintaining sensors incur monetary, computation, and energy cost. We propose an adaptive feature selection method that dynamically selects features for prediction at any given time point. We formulate this problem as an $\\ell_0$ minimization problem across time, and cast the combinatorial optimization problem into a stochastic optimization formulation. We then utilize a differentiable relaxation to make the problem amenable to gradient-based optimization. Our evaluations on four activity recognition datasets show that our method achieves a favorable trade-off between performance and the number of features used. Moreover, the dynamically selected features of our approach are shown to be interpretable and associated with the actual activity types.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "ardywibowo|dynamic_feature_selection_for_efficient_and_interpretable_human_activity_recognition", "one-sentence_summary": "We propose a task-driven dynamic feature selection method to perform human activity recognition efficiently.", "supplementary_material": "/attachment/0442d36e6c7fe5a2ad24564f6cc62cfd16c1fe28.zip", "pdf": "/pdf/90ae614f77bddbf5e9f886151a7fe2c54ddf1cdb.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=Z6AE_bSR8R", "_bibtex": "@misc{\nardywibowo2021dynamic,\ntitle={Dynamic Feature Selection for Efficient and Interpretable Human Activity Recognition},\nauthor={Randy Ardywibowo and Shahin Boluki and Zhangyang Wang and Bobak J Mortazavi and Shuai Huang and Xiaoning Qian},\nyear={2021},\nurl={https://openreview.net/forum?id=mPmCP2CXc7p}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "mPmCP2CXc7p", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper2895/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper2895/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper2895/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper2895/Authors|ICLR.cc/2021/Conference/Paper2895/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2895/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923843367, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper2895/-/Official_Comment"}}}, {"id": "-B96ryrnoCT", "original": null, "number": 10, "cdate": 1606150361832, "ddate": null, "tcdate": 1606150361832, "tmdate": 1606150361832, "tddate": null, "forum": "mPmCP2CXc7p", "replyto": "hQzFUXMiCs5", "invitation": "ICLR.cc/2021/Conference/Paper2895/-/Official_Comment", "content": {"title": "Response to Reviewer 4", "comment": "We truly appreciate the reviewer\u2019s timely reply to our responses. \n\nWe first would like to clarify that the setting we consider in our paper is not an online learning/training setting where the model parameters are constantly updated. We instead learn the selection policy and prediction model offline and test it without parameter updates (neither the policy nor the prediction model). Nowhere in our paper did we state that we are considering the online learning setting. We would think our current setup is a fundamental and critical starting point, especially considering that there is no similar model or method exactly doing what we try to accomplish to the best of our knowledge, as well as after checking the suggested references based on all the reviewers\u2019 comments. Further, we note that consideration of an online learning setting would not be very practical for human activity recognition systems, with or without considering dynamic feature selection. Even considering the case where we are able to observe all the features, it is unrealistic to assume that an end user would be able to label the activities in each instance reliably to help refine the model with better prediction performance. These would be interesting research directions that would need to consider non-stationarity of the signals, domain adaptation if any pre-trained model exists, as well as the extreme lack of labeled data. \n\nThat being said, assuming that these complications are addressed, our model can be readily applied to the online setting, although this is beyond the scope of our paper due to the aforementioned complexity. To see this, we can think of our model as a reinforcement learning agent that is tasked to both give a prediction and select the next feature set to observe given the current belief state summarizing the previous observations. With this, we can see that optimizing (eq. 6) is equivalent to the reinforcement learning objective of minimizing the expected loss following a parameterized policy. While this is typically optimized through techniques such as policy gradient, we are instead estimating the gradients of the objective using the Gumbel-softmax relaxation. In general, we would recommend setting the temperature of the Gumbel-softmax to be lower than the one in the offline setting to enable feature sparsity even when not directly sampling discrete variables. Our model can then be trained by aggregating the data collected online, similar to [1]. We will consider investigating this possibility of online learning but we do believe that our presented work in the current submission is meaningful, practically applicable, and novel both in the problem we are considering and in the model formulation. \n\nBelow, we clarify the additional misconceptions that the reviewer brought up:\n\n\u201cHow can you let the model decide to turn it on again? There is no data for specific sensors\u201d. As we have stated, the model maintains a latent representation that enables previously turned-off features to be turned on again given the context. Our experiments clearly show that to be the case at test time, where some features are not selected to have the corresponding sensors turned on in the earlier time points but get selected to have the sensors turned on as the context changes. Note that the selection mechanism Eq. 7 only depends on the previously selected feature sets, and not all the features.  In the online learning setting, the model would start with a random feature selection policy. The randomness of our selection policy ensures that our model would explore using a variety of feature sets for a given context. This enables the model to gradually explore the state-action space before arriving at an optimal selection policy. Moreover, the randomness of our selection policy ensures that a well-optimized model would still occasionally explore using features it has previously deemed uninformative.\n\n\u201cAlthough the model (Eq. 3 and Eq. 6) can be trained by previous observations, can you guarantee that it will work in the long-term?\u201d. We appreciate the concern. As we explained, our current setup is assuming that the underlying dynamics are stationary and the training and testing data are from the same distribution, a common assumption in classical machine learning. Performance degradation can happen if there are internal or environmental changes. These are challenges that all machine learning models in a wide range of applications face when being deployed. As we stated at the beginning, these will be all interesting research problems involving transfer/self-supervised learning that we can explore within our presented framework. We refer the reviewer to [1] (Theorem 3.1) for guarantees in applying our algorithm to the online learning setting."}, "signatures": ["ICLR.cc/2021/Conference/Paper2895/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2895/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Dynamic Feature Selection for Efficient and Interpretable Human Activity Recognition", "authorids": ["~Randy_Ardywibowo1", "~Shahin_Boluki1", "~Zhangyang_Wang1", "~Bobak_J_Mortazavi1", "~Shuai_Huang1", "~Xiaoning_Qian2"], "authors": ["Randy Ardywibowo", "Shahin Boluki", "Zhangyang Wang", "Bobak J Mortazavi", "Shuai Huang", "Xiaoning Qian"], "keywords": ["dynamic feature selection", "human activity recognition", "sparse monitoring"], "abstract": "In many machine learning tasks, input features with varying degrees of predictive capability are usually acquired at some cost. For example, in human activity recognition (HAR) and mobile health (mHealth) applications, monitoring performance should be achieved with a low cost to gather different sensory features, as maintaining sensors incur monetary, computation, and energy cost. We propose an adaptive feature selection method that dynamically selects features for prediction at any given time point. We formulate this problem as an $\\ell_0$ minimization problem across time, and cast the combinatorial optimization problem into a stochastic optimization formulation. We then utilize a differentiable relaxation to make the problem amenable to gradient-based optimization. Our evaluations on four activity recognition datasets show that our method achieves a favorable trade-off between performance and the number of features used. Moreover, the dynamically selected features of our approach are shown to be interpretable and associated with the actual activity types.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "ardywibowo|dynamic_feature_selection_for_efficient_and_interpretable_human_activity_recognition", "one-sentence_summary": "We propose a task-driven dynamic feature selection method to perform human activity recognition efficiently.", "supplementary_material": "/attachment/0442d36e6c7fe5a2ad24564f6cc62cfd16c1fe28.zip", "pdf": "/pdf/90ae614f77bddbf5e9f886151a7fe2c54ddf1cdb.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=Z6AE_bSR8R", "_bibtex": "@misc{\nardywibowo2021dynamic,\ntitle={Dynamic Feature Selection for Efficient and Interpretable Human Activity Recognition},\nauthor={Randy Ardywibowo and Shahin Boluki and Zhangyang Wang and Bobak J Mortazavi and Shuai Huang and Xiaoning Qian},\nyear={2021},\nurl={https://openreview.net/forum?id=mPmCP2CXc7p}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "mPmCP2CXc7p", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper2895/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper2895/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper2895/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper2895/Authors|ICLR.cc/2021/Conference/Paper2895/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2895/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923843367, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper2895/-/Official_Comment"}}}, {"id": "ayaFJyVKKFQ", "original": null, "number": 9, "cdate": 1606150281077, "ddate": null, "tcdate": 1606150281077, "tmdate": 1606150281077, "tddate": null, "forum": "mPmCP2CXc7p", "replyto": "sWn6eSaVmhC", "invitation": "ICLR.cc/2021/Conference/Paper2895/-/Official_Comment", "content": {"title": "Disagree with your serious accusation of \u201cviolation of a code of ethic\u201d (Please avoid emotional and ungrounded criticism)", "comment": "While we respect the discussion on problem formulation we are disappointed and, frankly, shocked at such an accusation. To reiterate from our prior response (paragraph 3), we claim that our problem and formulation are new regarding dynamically selecting features based on the underlying states/contexts, and we tried different ways to explain this in our responses in addition to our efforts in our original submission. \n\nWe never claimed that the $l_0$ relaxation solution is our own and we have cited all the papers that deal with stochastic optimization when involving discrete decision variables to our knowledge, including the original straight-through idea, and the relaxation methods including Gumbel-softmax, as well as more recent methods including ARM. \n\nNote that we have attributed the static l0 formulation to Louizos et al. (2017) (or [18]) in the Results table (Table 2) and in the following location in the original submission file: \u201cTo show the effect of considering dynamic feature selection, we compare a nonadaptive l0 formulation that statically selects features by solving (4) [18]\u201d.  Although [18]\u2019s goal is not feature selection, due to the similarity of the optimization strategy, we have attributed the static feature selection by relaxation of l0 and the solution to Eq. (4) to that work. Clearly, we are not trying to get credit for the l0 relaxation under static setup with global parameters. \n\nFurther, in Section 2.4 of our original submission, we clearly referred to the Gumbel-Softmax (Concrete) papers. In Sections 3 and 4, we have extensively discussed the different methods for optimization involving discrete variables in neural networks and cited relevant papers. We would like to note that we are currently revising our paper based on all four reviewers\u2019 comments. If there are sentences in our submission that made the reviewers or other readers feel that we invented these relaxation techniques, please kindly point out these places so that we are aware of these. We feel insulted by getting such an accusation.\n\nIn the original submission file, in Section 2.3, the sentence starting with \u201cTo extend ...\u201d is our contribution regarding relaxation of the adaptive feature selection formulation. In the revised manuscript that we upload now (but still trying to revise to make sure that we address all the concerns from all four reviewers), we have added the following sentences below Eq (5) to prevent any potential confusion for readers unfamiliar with the literature that the reviewer is concerned about:\n\n\u201cRelaxation of binary random variables has been adopted in Louizos et al. (2017) for network architecture\nsparsification, and in Yamada et al. (2019); Bal\u0131n et al. (2019) for static feature selection. Here, we\nextend the above relaxation for time series data, where unlike previous works, the binary random\nvariables are parameterized locally and are context-dependent, and features are selected adaptively\nacross time.\u201d\n \nWe are sorry if it is not intuitive that the number of features will be positively correlated with the number of required sensors, and therefore directly reflect the power usage. Reporting the average number of features used has been done by other previous works in similar setups (see [d, e] or [2, 42] in the paper). We did check the union of the selected features for three datasets as mentioned in our reply above, which still show our method to be superior to the non-adaptive method. Please do refer to our first reply \u201cResponse to Reviewer 2\u201d. We also post the statistics here for easier reference: \n\nUCI HAR: 3.56%.\n \nOPPORTUNITY: 19.83%.\n \nExtraSensory: 26.66%.\n \nAn example of including what the reviewer had asked, i.e. providing the union of all features, in our direct response to the comments, and the reviewer again asking for the same result, leads us to the conclusion that the reviewer has not carefully or completely read our paper and responses. We felt that the reviewer misread and tried to mis-present our paper based on his/her own reading, which is not only careless but also unethical itself to impose this baseless accusation.\n\nWe are indeed trying to revise our submission based on all four reviewers\u2019 comments at this moment. We surely welcome all your suggestions on how we shall present our method and results but would appreciate your constructive suggestions instead of accusing us without giving the actual examples where we violated the code of ethics.  Since we feel that the reviewer now brought the discussion to quite an emotional state and put ungrounded yet overly harsh criticism to our work (we\u2019re not sure why, though), we politely urge the area chair to take this factor into account and step in this discussion, if possible.\n\n[d] Yang, Xiaodong, et al. \"Instance-Wise Dynamic Sensor Selection for Human Activity Recognition.\" (2020).\n\n[e] Strubell, Emma, et al. \"Learning dynamic feature selection for fast sequential prediction.\" (2015)."}, "signatures": ["ICLR.cc/2021/Conference/Paper2895/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2895/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Dynamic Feature Selection for Efficient and Interpretable Human Activity Recognition", "authorids": ["~Randy_Ardywibowo1", "~Shahin_Boluki1", "~Zhangyang_Wang1", "~Bobak_J_Mortazavi1", "~Shuai_Huang1", "~Xiaoning_Qian2"], "authors": ["Randy Ardywibowo", "Shahin Boluki", "Zhangyang Wang", "Bobak J Mortazavi", "Shuai Huang", "Xiaoning Qian"], "keywords": ["dynamic feature selection", "human activity recognition", "sparse monitoring"], "abstract": "In many machine learning tasks, input features with varying degrees of predictive capability are usually acquired at some cost. For example, in human activity recognition (HAR) and mobile health (mHealth) applications, monitoring performance should be achieved with a low cost to gather different sensory features, as maintaining sensors incur monetary, computation, and energy cost. We propose an adaptive feature selection method that dynamically selects features for prediction at any given time point. We formulate this problem as an $\\ell_0$ minimization problem across time, and cast the combinatorial optimization problem into a stochastic optimization formulation. We then utilize a differentiable relaxation to make the problem amenable to gradient-based optimization. Our evaluations on four activity recognition datasets show that our method achieves a favorable trade-off between performance and the number of features used. Moreover, the dynamically selected features of our approach are shown to be interpretable and associated with the actual activity types.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "ardywibowo|dynamic_feature_selection_for_efficient_and_interpretable_human_activity_recognition", "one-sentence_summary": "We propose a task-driven dynamic feature selection method to perform human activity recognition efficiently.", "supplementary_material": "/attachment/0442d36e6c7fe5a2ad24564f6cc62cfd16c1fe28.zip", "pdf": "/pdf/90ae614f77bddbf5e9f886151a7fe2c54ddf1cdb.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=Z6AE_bSR8R", "_bibtex": "@misc{\nardywibowo2021dynamic,\ntitle={Dynamic Feature Selection for Efficient and Interpretable Human Activity Recognition},\nauthor={Randy Ardywibowo and Shahin Boluki and Zhangyang Wang and Bobak J Mortazavi and Shuai Huang and Xiaoning Qian},\nyear={2021},\nurl={https://openreview.net/forum?id=mPmCP2CXc7p}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "mPmCP2CXc7p", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper2895/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper2895/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper2895/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper2895/Authors|ICLR.cc/2021/Conference/Paper2895/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2895/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923843367, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper2895/-/Official_Comment"}}}, {"id": "Tt_lnX1n0s", "original": null, "number": 8, "cdate": 1606150208633, "ddate": null, "tcdate": 1606150208633, "tmdate": 1606150208633, "tddate": null, "forum": "mPmCP2CXc7p", "replyto": "aEyOoDp3IsO", "invitation": "ICLR.cc/2021/Conference/Paper2895/-/Official_Comment", "content": {"title": "Response to Reviewer 1", "comment": "We thank the reviewer for the constructive comments and criticisms. \n\nWe agree that in the current formulation, \u201cone can only argue that the required features can be estimated from the older measurement. So, the current set of active sensors is not the full set of required measurement values and can not be exclusively used to explain the logic of the system.\u201d Indeed, some features can potentially be reliably estimated from older measurements, and our method can decide to turn off these sensors depending on the underlying states or contexts and save energy. Using the previously observed features, our model is able to select the next feature set to query without observing the entire feature set. We tried to explain this by showing that the selected features indeed reflect the actual activities. As the reviewer pointed out, our dynamic/adaptive feature selection is learned using all the training data. Showing the activity class specific features can be considered as a retrospective interpretation of what our method can do. For testing, dynamic feature selection is determined by the derived latent representations based on all the past observations. We will revise to better explain this point.\n"}, "signatures": ["ICLR.cc/2021/Conference/Paper2895/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2895/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Dynamic Feature Selection for Efficient and Interpretable Human Activity Recognition", "authorids": ["~Randy_Ardywibowo1", "~Shahin_Boluki1", "~Zhangyang_Wang1", "~Bobak_J_Mortazavi1", "~Shuai_Huang1", "~Xiaoning_Qian2"], "authors": ["Randy Ardywibowo", "Shahin Boluki", "Zhangyang Wang", "Bobak J Mortazavi", "Shuai Huang", "Xiaoning Qian"], "keywords": ["dynamic feature selection", "human activity recognition", "sparse monitoring"], "abstract": "In many machine learning tasks, input features with varying degrees of predictive capability are usually acquired at some cost. For example, in human activity recognition (HAR) and mobile health (mHealth) applications, monitoring performance should be achieved with a low cost to gather different sensory features, as maintaining sensors incur monetary, computation, and energy cost. We propose an adaptive feature selection method that dynamically selects features for prediction at any given time point. We formulate this problem as an $\\ell_0$ minimization problem across time, and cast the combinatorial optimization problem into a stochastic optimization formulation. We then utilize a differentiable relaxation to make the problem amenable to gradient-based optimization. Our evaluations on four activity recognition datasets show that our method achieves a favorable trade-off between performance and the number of features used. Moreover, the dynamically selected features of our approach are shown to be interpretable and associated with the actual activity types.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "ardywibowo|dynamic_feature_selection_for_efficient_and_interpretable_human_activity_recognition", "one-sentence_summary": "We propose a task-driven dynamic feature selection method to perform human activity recognition efficiently.", "supplementary_material": "/attachment/0442d36e6c7fe5a2ad24564f6cc62cfd16c1fe28.zip", "pdf": "/pdf/90ae614f77bddbf5e9f886151a7fe2c54ddf1cdb.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=Z6AE_bSR8R", "_bibtex": "@misc{\nardywibowo2021dynamic,\ntitle={Dynamic Feature Selection for Efficient and Interpretable Human Activity Recognition},\nauthor={Randy Ardywibowo and Shahin Boluki and Zhangyang Wang and Bobak J Mortazavi and Shuai Huang and Xiaoning Qian},\nyear={2021},\nurl={https://openreview.net/forum?id=mPmCP2CXc7p}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "mPmCP2CXc7p", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper2895/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper2895/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper2895/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper2895/Authors|ICLR.cc/2021/Conference/Paper2895/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2895/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923843367, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper2895/-/Official_Comment"}}}, {"id": "sWn6eSaVmhC", "original": null, "number": 7, "cdate": 1606062251674, "ddate": null, "tcdate": 1606062251674, "tmdate": 1606062251674, "tddate": null, "forum": "mPmCP2CXc7p", "replyto": "pWmxCwPcsRK", "invitation": "ICLR.cc/2021/Conference/Paper2895/-/Official_Comment", "content": {"title": "Severity of the \"confusion\" by author", "comment": "I want to start by stressing the severity of what you term \"confusion\".\nIn your manuscript, you have presented existing results as if they are your own, you have not given proper credit to the creators of these results. This is in violation of a code of ethic by ICLR:\n\"Researchers should therefore credit the creators of ideas, inventions, work, and artefacts, and respect copyrights, patents, trade secrets, license agreements, and other methods of protecting authors' works.\"\nI wasn't sure if I wanted to bring this up, but from your response, it seems that you are completely ignoring my main criticism. I believe that the way you falsely presented the $l_0$ relaxation as if it was your own could have biased the score given by reviewer 1.\nAddressing the rest of your response:\nIf you claim that your method provides a computational advantage or power reduction why didn't you demonstrate such a result? The fact is that you've focused on providing performance plots vs. the number of selected features, these plots are MISLEADING. If your model is not using all features, you should indicate how many features it is using (by counting the union).\nTo summarize, given the fact that the authors did not address my main concerns about the false way they have presented the results of other authors, I can not raise my score.\nI think the idea presented in the paper is worth a publication, but the authors need to drastically revise the way the method and results are presented.\n\n"}, "signatures": ["ICLR.cc/2021/Conference/Paper2895/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2895/AnonReviewer2"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Dynamic Feature Selection for Efficient and Interpretable Human Activity Recognition", "authorids": ["~Randy_Ardywibowo1", "~Shahin_Boluki1", "~Zhangyang_Wang1", "~Bobak_J_Mortazavi1", "~Shuai_Huang1", "~Xiaoning_Qian2"], "authors": ["Randy Ardywibowo", "Shahin Boluki", "Zhangyang Wang", "Bobak J Mortazavi", "Shuai Huang", "Xiaoning Qian"], "keywords": ["dynamic feature selection", "human activity recognition", "sparse monitoring"], "abstract": "In many machine learning tasks, input features with varying degrees of predictive capability are usually acquired at some cost. For example, in human activity recognition (HAR) and mobile health (mHealth) applications, monitoring performance should be achieved with a low cost to gather different sensory features, as maintaining sensors incur monetary, computation, and energy cost. We propose an adaptive feature selection method that dynamically selects features for prediction at any given time point. We formulate this problem as an $\\ell_0$ minimization problem across time, and cast the combinatorial optimization problem into a stochastic optimization formulation. We then utilize a differentiable relaxation to make the problem amenable to gradient-based optimization. Our evaluations on four activity recognition datasets show that our method achieves a favorable trade-off between performance and the number of features used. Moreover, the dynamically selected features of our approach are shown to be interpretable and associated with the actual activity types.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "ardywibowo|dynamic_feature_selection_for_efficient_and_interpretable_human_activity_recognition", "one-sentence_summary": "We propose a task-driven dynamic feature selection method to perform human activity recognition efficiently.", "supplementary_material": "/attachment/0442d36e6c7fe5a2ad24564f6cc62cfd16c1fe28.zip", "pdf": "/pdf/90ae614f77bddbf5e9f886151a7fe2c54ddf1cdb.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=Z6AE_bSR8R", "_bibtex": "@misc{\nardywibowo2021dynamic,\ntitle={Dynamic Feature Selection for Efficient and Interpretable Human Activity Recognition},\nauthor={Randy Ardywibowo and Shahin Boluki and Zhangyang Wang and Bobak J Mortazavi and Shuai Huang and Xiaoning Qian},\nyear={2021},\nurl={https://openreview.net/forum?id=mPmCP2CXc7p}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "mPmCP2CXc7p", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper2895/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper2895/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper2895/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper2895/Authors|ICLR.cc/2021/Conference/Paper2895/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2895/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923843367, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper2895/-/Official_Comment"}}}, {"id": "hQzFUXMiCs5", "original": null, "number": 6, "cdate": 1605584618547, "ddate": null, "tcdate": 1605584618547, "tmdate": 1605584618547, "tddate": null, "forum": "mPmCP2CXc7p", "replyto": "lidPvR6nuMN", "invitation": "ICLR.cc/2021/Conference/Paper2895/-/Official_Comment", "content": {"title": "Thanks for your answer, here is my follow-up thought.", "comment": "Hello authors, thank you for clarifying my understanding. I have carefully read other reviews and your replies. While reading the manuscript, my main concern was the practical applicability of the solution you proposed. It is like the one that Reviewer 2 asked:\n\n\"Given that this is what you measure since you still need all the features to use your model, what are the advantages of the method? Only interpretability?\"\n\n-> First of all, I was reviewing the paper by considering applying this algorithm in an online setting (predefined model & online update). I understand the answers and your point that the features that are not selected are set to zero in this framework. As you responded, it will lead the device to turn off the sensors that relate to the features in practice. But once the sensors are turned off, there will be no more observations. Then, the training dataset for that feature will not be collected. This will lead you to this question: How can you let the model decide to turn it on again? There is no data for specific sensors.\n\nYou were able to train a model since, in an offline environment that was considered, there was a dump training set that every feature values are recorded. Although the model (Eq. 3 and Eq. 6) can be trained by previous observations, can you guarantee that it will work in the long-term? Also, selecting training/validation/testing set by randomly shuffling 70%/10%/20% does not make sense. To build something that's robust, you may want to split data chronologically and check parameter stability over time.\n\nTo conclude, I would like to thank the authors for clarifying some misunderstandings that I have, but I feel there is some gap between offline experiment settings and online settings. To guarantee that the proposed model is working in a real environment that requires HAR, it may require additional check-ups and justifications. Evaluating the algorithm with three datasets is a great starting point. However, I believe there is room to enhance the quality of the paper. The authors can consider advancing the current algorithm in 1) technically novel, or 2) practically applicable. For the former direction, I suggest you address comments from other reviewers. For the latter path, the applied science track of data mining conferences would also be suitable. They may want to see some results from user studies or A/B test results after deploying this solution to your products.\n\n"}, "signatures": ["ICLR.cc/2021/Conference/Paper2895/AnonReviewer4"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2895/AnonReviewer4"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Dynamic Feature Selection for Efficient and Interpretable Human Activity Recognition", "authorids": ["~Randy_Ardywibowo1", "~Shahin_Boluki1", "~Zhangyang_Wang1", "~Bobak_J_Mortazavi1", "~Shuai_Huang1", "~Xiaoning_Qian2"], "authors": ["Randy Ardywibowo", "Shahin Boluki", "Zhangyang Wang", "Bobak J Mortazavi", "Shuai Huang", "Xiaoning Qian"], "keywords": ["dynamic feature selection", "human activity recognition", "sparse monitoring"], "abstract": "In many machine learning tasks, input features with varying degrees of predictive capability are usually acquired at some cost. For example, in human activity recognition (HAR) and mobile health (mHealth) applications, monitoring performance should be achieved with a low cost to gather different sensory features, as maintaining sensors incur monetary, computation, and energy cost. We propose an adaptive feature selection method that dynamically selects features for prediction at any given time point. We formulate this problem as an $\\ell_0$ minimization problem across time, and cast the combinatorial optimization problem into a stochastic optimization formulation. We then utilize a differentiable relaxation to make the problem amenable to gradient-based optimization. Our evaluations on four activity recognition datasets show that our method achieves a favorable trade-off between performance and the number of features used. Moreover, the dynamically selected features of our approach are shown to be interpretable and associated with the actual activity types.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "ardywibowo|dynamic_feature_selection_for_efficient_and_interpretable_human_activity_recognition", "one-sentence_summary": "We propose a task-driven dynamic feature selection method to perform human activity recognition efficiently.", "supplementary_material": "/attachment/0442d36e6c7fe5a2ad24564f6cc62cfd16c1fe28.zip", "pdf": "/pdf/90ae614f77bddbf5e9f886151a7fe2c54ddf1cdb.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=Z6AE_bSR8R", "_bibtex": "@misc{\nardywibowo2021dynamic,\ntitle={Dynamic Feature Selection for Efficient and Interpretable Human Activity Recognition},\nauthor={Randy Ardywibowo and Shahin Boluki and Zhangyang Wang and Bobak J Mortazavi and Shuai Huang and Xiaoning Qian},\nyear={2021},\nurl={https://openreview.net/forum?id=mPmCP2CXc7p}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "mPmCP2CXc7p", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper2895/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper2895/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper2895/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper2895/Authors|ICLR.cc/2021/Conference/Paper2895/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2895/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923843367, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper2895/-/Official_Comment"}}}, {"id": "9JSBD42c20Y", "original": null, "number": 4, "cdate": 1605372759040, "ddate": null, "tcdate": 1605372759040, "tmdate": 1605373061522, "tddate": null, "forum": "mPmCP2CXc7p", "replyto": "pWmxCwPcsRK", "invitation": "ICLR.cc/2021/Conference/Paper2895/-/Official_Comment", "content": {"title": "References", "comment": "[a] Wu, Bichen, et al. \"Fbnet: Hardware-aware efficient convnet design via differentiable neural architecture search.\" Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. 2019.\n\n[b] V Campos, et al. Skip RNN: Learning to Skip State Updates in Recurrent Neural Networks. ICLR 2018.\n\n[c] van Baalen, Mart, et al. \"Bayesian Bits: Unifying Quantization and Pruning.\" 2020.\n"}, "signatures": ["ICLR.cc/2021/Conference/Paper2895/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2895/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Dynamic Feature Selection for Efficient and Interpretable Human Activity Recognition", "authorids": ["~Randy_Ardywibowo1", "~Shahin_Boluki1", "~Zhangyang_Wang1", "~Bobak_J_Mortazavi1", "~Shuai_Huang1", "~Xiaoning_Qian2"], "authors": ["Randy Ardywibowo", "Shahin Boluki", "Zhangyang Wang", "Bobak J Mortazavi", "Shuai Huang", "Xiaoning Qian"], "keywords": ["dynamic feature selection", "human activity recognition", "sparse monitoring"], "abstract": "In many machine learning tasks, input features with varying degrees of predictive capability are usually acquired at some cost. For example, in human activity recognition (HAR) and mobile health (mHealth) applications, monitoring performance should be achieved with a low cost to gather different sensory features, as maintaining sensors incur monetary, computation, and energy cost. We propose an adaptive feature selection method that dynamically selects features for prediction at any given time point. We formulate this problem as an $\\ell_0$ minimization problem across time, and cast the combinatorial optimization problem into a stochastic optimization formulation. We then utilize a differentiable relaxation to make the problem amenable to gradient-based optimization. Our evaluations on four activity recognition datasets show that our method achieves a favorable trade-off between performance and the number of features used. Moreover, the dynamically selected features of our approach are shown to be interpretable and associated with the actual activity types.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "ardywibowo|dynamic_feature_selection_for_efficient_and_interpretable_human_activity_recognition", "one-sentence_summary": "We propose a task-driven dynamic feature selection method to perform human activity recognition efficiently.", "supplementary_material": "/attachment/0442d36e6c7fe5a2ad24564f6cc62cfd16c1fe28.zip", "pdf": "/pdf/90ae614f77bddbf5e9f886151a7fe2c54ddf1cdb.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=Z6AE_bSR8R", "_bibtex": "@misc{\nardywibowo2021dynamic,\ntitle={Dynamic Feature Selection for Efficient and Interpretable Human Activity Recognition},\nauthor={Randy Ardywibowo and Shahin Boluki and Zhangyang Wang and Bobak J Mortazavi and Shuai Huang and Xiaoning Qian},\nyear={2021},\nurl={https://openreview.net/forum?id=mPmCP2CXc7p}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "mPmCP2CXc7p", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper2895/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper2895/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper2895/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper2895/Authors|ICLR.cc/2021/Conference/Paper2895/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2895/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923843367, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper2895/-/Official_Comment"}}}, {"id": "pWmxCwPcsRK", "original": null, "number": 3, "cdate": 1605372702657, "ddate": null, "tcdate": 1605372702657, "tmdate": 1605373041053, "tddate": null, "forum": "mPmCP2CXc7p", "replyto": "caIqTnXIjD", "invitation": "ICLR.cc/2021/Conference/Paper2895/-/Official_Comment", "content": {"title": "Response to Reviewer 2", "comment": "We thank the reviewer for the constructive comments and criticisms. \n \nWe will clarify confusions and improve the presentation of our manuscript. Here, we would like to **strongly point out the possible misunderstanding by the reviewer**. Most importantly, our aim is **NOT** to have a compressed/simplified neural network model for activity recognition. Instead, we would like our dynamic feature selection framework to not only have good activity recognition performance, but also (more importantly) to inform which sensors should be turned on or off to achieve desired performance-cost tradeoff. \n\nHere the cost is incurred for sensor feature collection but not the inference for activity recognition based on given features. In mobile sensing tasks, devices are typically equipped with a redundant set of sensors, and turning on/off those sensors accounts for a major portion of on-device energy budgets. As Reviewer 1 has insightfully pointed out: \u201cThis has implications in energy consumptions of wearable sensors. but could even generalize to measurement timings in clinical care to make the work of nurses more efficient, and reduce the stress caused by some medical procedures.\u201d\n\nWe consider dynamic feature selection as  sequential context-dependent feature subset selection and cast it into a stochastic optimization formulation, enabling gradient-based solutions. The method we derived in our manuscript is a temporal feature selection method, which is different from the one presented in [1], where the goal is neural network architecture sparsification. Unlike in [1] where the weight masking is done independent of the current input data, our feature selection method is context dependent and adapts to the input data currently being handled. This introduces non-trivial complications when solving the optimization problem, especially when using the ARM optimization strategies. Also different from [1], our method selects features across time, while [1] is concerned with model compression. We note that many other methods in the literature can be derived as a relaxation similar to the one presented in [1] (see [a], [b], [c]). The fact that our method uses a similar relaxation as [1] should not discredit its novelty. It was never our intention to misrepresent our work and we will modify our write-up to more clearly show its relation to existing work.\n\nThe other works [2] and [3] that the reviewer cited are also unlike the method in our manuscript. Crucially, both deal with static feature selection as opposed to the dynamic feature selection method we are proposing.\n\nWe beg to differ from the reviewer\u2019s statement that we should compare the union of the selected features to the constant number of features selected by the non-adaptive method. As we have stated numerous times in our manuscript, the problem we are concerned with is regarding DYNAMIC feature selection for continuous human activity recognition. Here, we are tasked to give a prediction for each time point while achieving sensor power efficiency by dynamically selecting the sensor set used for each time point. Because we are able to select fewer sensors on average, we are able to keep more sensors turned off on average thus achieving greater power efficiency. Comparing the union of the selected sensors would not be representative of the sensor power consumed by our method, as not all sensors in the union would be turned on at all times when using our method. Nevertheless, we have computed the union of features selected. All of them still show our method to be superior to the non adaptive method. We list these numbers below:\n\nUCI HAR: 3.56%.\n\nOPPORTUNITY: 19.83%.\n\nExtraSensory: 26.66%.\n\nWe emphasize that our model DOES NOT need all the features observed and to be entered as input. Using the previously observed features, our model is able to select the next feature set to query without observing the entire feature set. As stated in our methodology section (equations (2), (3), (4), and (6)), the features that are not selected are set to zero and thus need not be observed.\n\nIn the testing phase, the randomness is not removed, we stated this in section 2.4. We would place additional details regarding training/testing in the main manuscript if the page limit permits. However, we believe that the training details would detract from our main message of achieving efficiency and interpretability using our model. We are currently revising both the main text and supplement to try our best to make these points clearer. \n\nWe would truly appreciate the reviewer to reply to our post and ask more questions, if our points are still not clear enough, to ensure there are no misunderstandings regarding our method and motivations to develop dynamic/adaptive feature selection. At this point, we are very confident that our above clarifications have thoroughly addressed the potential confusions and misunderstandings in the current review."}, "signatures": ["ICLR.cc/2021/Conference/Paper2895/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2895/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Dynamic Feature Selection for Efficient and Interpretable Human Activity Recognition", "authorids": ["~Randy_Ardywibowo1", "~Shahin_Boluki1", "~Zhangyang_Wang1", "~Bobak_J_Mortazavi1", "~Shuai_Huang1", "~Xiaoning_Qian2"], "authors": ["Randy Ardywibowo", "Shahin Boluki", "Zhangyang Wang", "Bobak J Mortazavi", "Shuai Huang", "Xiaoning Qian"], "keywords": ["dynamic feature selection", "human activity recognition", "sparse monitoring"], "abstract": "In many machine learning tasks, input features with varying degrees of predictive capability are usually acquired at some cost. For example, in human activity recognition (HAR) and mobile health (mHealth) applications, monitoring performance should be achieved with a low cost to gather different sensory features, as maintaining sensors incur monetary, computation, and energy cost. We propose an adaptive feature selection method that dynamically selects features for prediction at any given time point. We formulate this problem as an $\\ell_0$ minimization problem across time, and cast the combinatorial optimization problem into a stochastic optimization formulation. We then utilize a differentiable relaxation to make the problem amenable to gradient-based optimization. Our evaluations on four activity recognition datasets show that our method achieves a favorable trade-off between performance and the number of features used. Moreover, the dynamically selected features of our approach are shown to be interpretable and associated with the actual activity types.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "ardywibowo|dynamic_feature_selection_for_efficient_and_interpretable_human_activity_recognition", "one-sentence_summary": "We propose a task-driven dynamic feature selection method to perform human activity recognition efficiently.", "supplementary_material": "/attachment/0442d36e6c7fe5a2ad24564f6cc62cfd16c1fe28.zip", "pdf": "/pdf/90ae614f77bddbf5e9f886151a7fe2c54ddf1cdb.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=Z6AE_bSR8R", "_bibtex": "@misc{\nardywibowo2021dynamic,\ntitle={Dynamic Feature Selection for Efficient and Interpretable Human Activity Recognition},\nauthor={Randy Ardywibowo and Shahin Boluki and Zhangyang Wang and Bobak J Mortazavi and Shuai Huang and Xiaoning Qian},\nyear={2021},\nurl={https://openreview.net/forum?id=mPmCP2CXc7p}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "mPmCP2CXc7p", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper2895/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper2895/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper2895/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper2895/Authors|ICLR.cc/2021/Conference/Paper2895/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2895/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923843367, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper2895/-/Official_Comment"}}}, {"id": "lidPvR6nuMN", "original": null, "number": 5, "cdate": 1605372887679, "ddate": null, "tcdate": 1605372887679, "tmdate": 1605372887679, "tddate": null, "forum": "mPmCP2CXc7p", "replyto": "Jrf1dulzrls", "invitation": "ICLR.cc/2021/Conference/Paper2895/-/Official_Comment", "content": {"title": "Response to Reviewer 4", "comment": "We thank the reviewer for the constructive comments and criticisms.\n\nCrucially, we clarify that our algorithm DOES NOT need all features to be entered as input. Using the previously observed feature sets, our model is able to select the next feature set to query without observing the entire feature set. As stated in our methodology section (equations (2), (3), (4), and (6)), the features that are not selected are set to zero and thus need not be observed. In practice, the next feature set to use can be determined without ever observing all of the features. We have shown through extensive experiments that our method drastically reduces the number of features that are not necessary for prediction for certain contexts.\n\nWe also would like to point out the possible misunderstanding. Mostly importantly, our aim is not to have a compressed/simplified neural network model for activity recognition. Instead, we would like our dynamic feature selection framework to not only have good activity recognition performance, but also (more importantly) to inform which sensors should be turned on or off to achieve desired performance-cost tradeoff. Note that here the cost is incurred for sensor feature collection but not the inference for activity recognition based on given features. \n\nAs we have stated in our manuscript, our claim on efficiency is not regarding computational efficiency, but rather efficiency in maintaining the sensors needed for prediction. Since not all sensors will be used at all times, we can use our gating method to safely TURN OFF sensors to achieve power efficiency.\n\n\nWe answer the questions the reviewer listed below:\n\n- The running time of our model compared to a standard GRU is quite comparable. On the UCI HAR dataset, our model takes 11.15ms to predict each time point while a standard GRU takes 7.68ms. This is still within acceptable latencies for continuous activity monitoring.\n\n- The model learns a feature selection policy offline and uses the learned policy to select features during testing time. The parameters of the model and selection policy are fixed during testing and no online update of the parameters are done in this setting. The dynamic feature selection is achieved because the selection policy is conditioned on the previous observations to determine the next feature set to use. From this perspective, the technique can indeed be thought of as maintaining a dashboard indicating which features are important given the context summarized by the previous observations.\n\n- We note that we are still achieving competitive performance on the NTU-RGB-D dataset, with only about a 2.5% accuracy drop compared to the baseline model which uses the entire sensor set. We attribute this to the fact that the dataset only contains 25 sensors in total. We believe that such a small sensor set is already curated to be the most informative and therefore, any additional sensor selection would slightly degrade the performance of a predictive model.\n\n- We note that our model isn\u2019t simply \u201can RNN with an additional sigmoid layer\u201d. In fact, adding a simple sigmoid layer would not produce any feature sparsity by itself as shown by our comparisons with an attention-based model. Instead, in our model, the next feature set is sampled using a learned discrete probability distribution conditioned on the previous observations. Such a model isn\u2019t trivial to optimize, as backpropagation isn\u2019t trivially done through the discrete probability distribution parameters. Moreover, we also introduce a regularization that is easily evaluated using a stochastic relaxation. The resulting module is then highly applicable to more complex architectures and modeling scenarios. \n\n- In Figure 2a, the orange and blue lines both overlap exactly, causing the blue line to be unseen. We will fix this in our revision of our manuscript.\n\nWe truly appreciate the reviewer to reply to our post and ask more questions to ensure there are no more misunderstandings that would have affected your assessment of our method. At this point, we are very confident that our above clarifications have thoroughly addressed the potential confusions and misunderstandings in the current review."}, "signatures": ["ICLR.cc/2021/Conference/Paper2895/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2895/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Dynamic Feature Selection for Efficient and Interpretable Human Activity Recognition", "authorids": ["~Randy_Ardywibowo1", "~Shahin_Boluki1", "~Zhangyang_Wang1", "~Bobak_J_Mortazavi1", "~Shuai_Huang1", "~Xiaoning_Qian2"], "authors": ["Randy Ardywibowo", "Shahin Boluki", "Zhangyang Wang", "Bobak J Mortazavi", "Shuai Huang", "Xiaoning Qian"], "keywords": ["dynamic feature selection", "human activity recognition", "sparse monitoring"], "abstract": "In many machine learning tasks, input features with varying degrees of predictive capability are usually acquired at some cost. For example, in human activity recognition (HAR) and mobile health (mHealth) applications, monitoring performance should be achieved with a low cost to gather different sensory features, as maintaining sensors incur monetary, computation, and energy cost. We propose an adaptive feature selection method that dynamically selects features for prediction at any given time point. We formulate this problem as an $\\ell_0$ minimization problem across time, and cast the combinatorial optimization problem into a stochastic optimization formulation. We then utilize a differentiable relaxation to make the problem amenable to gradient-based optimization. Our evaluations on four activity recognition datasets show that our method achieves a favorable trade-off between performance and the number of features used. Moreover, the dynamically selected features of our approach are shown to be interpretable and associated with the actual activity types.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "ardywibowo|dynamic_feature_selection_for_efficient_and_interpretable_human_activity_recognition", "one-sentence_summary": "We propose a task-driven dynamic feature selection method to perform human activity recognition efficiently.", "supplementary_material": "/attachment/0442d36e6c7fe5a2ad24564f6cc62cfd16c1fe28.zip", "pdf": "/pdf/90ae614f77bddbf5e9f886151a7fe2c54ddf1cdb.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=Z6AE_bSR8R", "_bibtex": "@misc{\nardywibowo2021dynamic,\ntitle={Dynamic Feature Selection for Efficient and Interpretable Human Activity Recognition},\nauthor={Randy Ardywibowo and Shahin Boluki and Zhangyang Wang and Bobak J Mortazavi and Shuai Huang and Xiaoning Qian},\nyear={2021},\nurl={https://openreview.net/forum?id=mPmCP2CXc7p}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "mPmCP2CXc7p", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper2895/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper2895/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper2895/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper2895/Authors|ICLR.cc/2021/Conference/Paper2895/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2895/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923843367, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper2895/-/Official_Comment"}}}, {"id": "Z0SPy3Cbv90", "original": null, "number": 2, "cdate": 1605372243598, "ddate": null, "tcdate": 1605372243598, "tmdate": 1605372777878, "tddate": null, "forum": "mPmCP2CXc7p", "replyto": "CIGP18JiNz", "invitation": "ICLR.cc/2021/Conference/Paper2895/-/Official_Comment", "content": {"title": "Response  to Reviewer 3", "comment": "We thank the reviewer for the constructive comments and criticisms. \n\nWe emphasize that our method is a dynamic sensor selection method that infers which **small subset of sensor features** to use **adaptively**, at any given context or state indicated by the latent representation, **at any given time point**. In this way, its aim is to optimize the tradeoff between prediction accuracy and power and/or other incurring cost to maintain the sensor features,  It is unlike any of the methods the reviewer has cited. \n\n[a] selects wavelet scales used for prediction, instead of which features to use at any given context. This is motivated by a need to capture multi-scale patterns to achieve a more expressive model, instead of for energy efficiency or interpretability.\n\n[b] selects which time steps to skip for updating the recurrent state, and applies this to sequence modeling tasks. This may not be appropriate for continuous monitoring tasks, where we are tasked to give a prediction at every time step. Moreover, it doesn\u2019t enable interpretability of the model\u2019s decisions. Indeed, with our model, we can maintain a small adaptive set of sensors for easily discriminable contexts, and we can observe these sensors for interpretation of the model\u2019s behavior.\n\n[c] introduces a gating mechanism across time which controls the frequency with which the memory cell is updated. Such a selection is not context based, as the parameters of the gating mechanism, such as the period and the phase shift, are independent of the current state of information given in order to optimize both prediction accuracy and sensor usage. On the other hand, our dynamic selection mechanism is context dependent, it uses the previous observations to infer the next feature set to use in order to optimize both the prediction accuracy and sensor usage.\n\nWe further note that all the references applied selection or skipping along the temporal direction, which is only loosely related to our work, to say the least. Our proposed dynamic feature selection focuses on which sensor features across time points should be selected to achieve the desired performance-cost tradeoff and the feature selection is adaptive with respect to the underlying states or contexts of the corresponding activities and environment. Our dynamic/adaptive feature selection is orthogonal to temporal selection/skipping and we do believe these are two different research questions. But we will be happy to cite those papers as our broader context, and we can explore the potential of integrating these two directions as our future research.  \n\nGumbel-softmax is one strategy to solve our proposed optimization formulation (the true originality and merit): we neither claimed it as our originality, nor consider it the only way to go; in face, we also state that the Gumbel-softmax along with many other categorical selection mechanisms have been used for many purposes such as attention, model compression, mixture of experts, Neural Turing Machines, etc. Usage of such a selection mechanism alone should not be grounds to say that a method is not novel. We would consider these are potential solution strategies to achieve our proposed dynamic/adaptive feature selection. Indeed, we benchmarked multiple methods to optimize our dynamic feature selection formulation and found that the Gumbel-softmax performed most favorably for our applications.\n\nWe have tested different hyperparameters \\tau ranging from 0.001 to 5 and did not notice any significant differences in performance. We will shortly update our manuscript to include our comparisons on \\tau in the appendix.\n\nWe hope the above can clarify several confusions and make our novelty & merit much more clear to the reviewer.\n"}, "signatures": ["ICLR.cc/2021/Conference/Paper2895/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2895/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Dynamic Feature Selection for Efficient and Interpretable Human Activity Recognition", "authorids": ["~Randy_Ardywibowo1", "~Shahin_Boluki1", "~Zhangyang_Wang1", "~Bobak_J_Mortazavi1", "~Shuai_Huang1", "~Xiaoning_Qian2"], "authors": ["Randy Ardywibowo", "Shahin Boluki", "Zhangyang Wang", "Bobak J Mortazavi", "Shuai Huang", "Xiaoning Qian"], "keywords": ["dynamic feature selection", "human activity recognition", "sparse monitoring"], "abstract": "In many machine learning tasks, input features with varying degrees of predictive capability are usually acquired at some cost. For example, in human activity recognition (HAR) and mobile health (mHealth) applications, monitoring performance should be achieved with a low cost to gather different sensory features, as maintaining sensors incur monetary, computation, and energy cost. We propose an adaptive feature selection method that dynamically selects features for prediction at any given time point. We formulate this problem as an $\\ell_0$ minimization problem across time, and cast the combinatorial optimization problem into a stochastic optimization formulation. We then utilize a differentiable relaxation to make the problem amenable to gradient-based optimization. Our evaluations on four activity recognition datasets show that our method achieves a favorable trade-off between performance and the number of features used. Moreover, the dynamically selected features of our approach are shown to be interpretable and associated with the actual activity types.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "ardywibowo|dynamic_feature_selection_for_efficient_and_interpretable_human_activity_recognition", "one-sentence_summary": "We propose a task-driven dynamic feature selection method to perform human activity recognition efficiently.", "supplementary_material": "/attachment/0442d36e6c7fe5a2ad24564f6cc62cfd16c1fe28.zip", "pdf": "/pdf/90ae614f77bddbf5e9f886151a7fe2c54ddf1cdb.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=Z6AE_bSR8R", "_bibtex": "@misc{\nardywibowo2021dynamic,\ntitle={Dynamic Feature Selection for Efficient and Interpretable Human Activity Recognition},\nauthor={Randy Ardywibowo and Shahin Boluki and Zhangyang Wang and Bobak J Mortazavi and Shuai Huang and Xiaoning Qian},\nyear={2021},\nurl={https://openreview.net/forum?id=mPmCP2CXc7p}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "mPmCP2CXc7p", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper2895/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper2895/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper2895/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper2895/Authors|ICLR.cc/2021/Conference/Paper2895/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2895/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923843367, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper2895/-/Official_Comment"}}}, {"id": "Jrf1dulzrls", "original": null, "number": 1, "cdate": 1603696830902, "ddate": null, "tcdate": 1603696830902, "tmdate": 1605024108860, "tddate": null, "forum": "mPmCP2CXc7p", "replyto": "mPmCP2CXc7p", "invitation": "ICLR.cc/2021/Conference/Paper2895/-/Official_Review", "content": {"title": "I wonder if it can be applied directly to the online setting, which gradually decreases the number of features.", "review": "This paper proposes an RNN model for adaptive dynamic feature selection, for efficient and interpretable human activity recognition (HAR). From the intuition that human activity can be predictable by using a small number of sensors, the paper introduces an l0-norm minimization problem with parameter regularization, and provide a logic on formulating a dynamic feature selection model with relaxations. The difficulty of the discrete optimization problem is solved by differentiable relaxation, which is known as Gumbel-Softmax reparameterization techniques. The formulation is naturally led to an RNN model that uses histories as input with an additional sigmoid unit for adaptive feature selection. \n\nEmpirical studies are performed to show the superiority of the adaptive feature selection network. Results are shown on the task of 1) UCI-HAR smartphone dataset with 561 features, 2) UCI Opportunity sensor dataset with 242 features, 3) ExtraSensory dataset with 225 features for multilabel binary classification. In particular, by using the adaptive feature selection technique, the average number of features necessary for HAR prediction can be very small (0.3%, 15.9%, 11.3% among all features) at any given time. Overall, the paper is well written. In particular, analysis results on three datasets are clear and detailed, so that the reader would be available to understand what sensors were necessary for HAR prediction.\n \nThe key concern about the paper is that the algorithm lacks practicality. To show the adaptive selection algorithm is efficient, it should be shown that the algorithm drastically reduces features that are not necessary for prediction over time, while maintaining the performance even in the lighter feature space. Although the average number of features selected by the adaptive selection algorithm for each snapshot is small, all features are entered as input, which may not help to speed up the algorithm. To claim that the algorithm is efficient, it is required to show that the computation cost can be saved. Also, based on the current experimental results, it is difficult to say that features that were not used in earlier timestamp will not be used in later timestamp with a different context. \n \nMinor comments and questions:\n- Can you report the running time of each model? \n- Is this model working in an online setting without tuning? If yes, would you like to clarify? If no, may I think this technique is for maintaining a dashboard that informs important features every time to users by calculating feature importance over time?\n- The performance of the adaptive method on the NTU-RGB-D dataset is quite poor. What part of the dataset do you think caused the difficulty in feature selection? Do all features important?\n- The technical novelty seems to be low if the proposed model is an RNN with an additional sigmoid layer.\n- Figure 2a does not have a ground truth blue line.\n", "rating": "4: Ok but not good enough - rejection", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "signatures": ["ICLR.cc/2021/Conference/Paper2895/AnonReviewer4"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2895/AnonReviewer4"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Dynamic Feature Selection for Efficient and Interpretable Human Activity Recognition", "authorids": ["~Randy_Ardywibowo1", "~Shahin_Boluki1", "~Zhangyang_Wang1", "~Bobak_J_Mortazavi1", "~Shuai_Huang1", "~Xiaoning_Qian2"], "authors": ["Randy Ardywibowo", "Shahin Boluki", "Zhangyang Wang", "Bobak J Mortazavi", "Shuai Huang", "Xiaoning Qian"], "keywords": ["dynamic feature selection", "human activity recognition", "sparse monitoring"], "abstract": "In many machine learning tasks, input features with varying degrees of predictive capability are usually acquired at some cost. For example, in human activity recognition (HAR) and mobile health (mHealth) applications, monitoring performance should be achieved with a low cost to gather different sensory features, as maintaining sensors incur monetary, computation, and energy cost. We propose an adaptive feature selection method that dynamically selects features for prediction at any given time point. We formulate this problem as an $\\ell_0$ minimization problem across time, and cast the combinatorial optimization problem into a stochastic optimization formulation. We then utilize a differentiable relaxation to make the problem amenable to gradient-based optimization. Our evaluations on four activity recognition datasets show that our method achieves a favorable trade-off between performance and the number of features used. Moreover, the dynamically selected features of our approach are shown to be interpretable and associated with the actual activity types.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "ardywibowo|dynamic_feature_selection_for_efficient_and_interpretable_human_activity_recognition", "one-sentence_summary": "We propose a task-driven dynamic feature selection method to perform human activity recognition efficiently.", "supplementary_material": "/attachment/0442d36e6c7fe5a2ad24564f6cc62cfd16c1fe28.zip", "pdf": "/pdf/90ae614f77bddbf5e9f886151a7fe2c54ddf1cdb.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=Z6AE_bSR8R", "_bibtex": "@misc{\nardywibowo2021dynamic,\ntitle={Dynamic Feature Selection for Efficient and Interpretable Human Activity Recognition},\nauthor={Randy Ardywibowo and Shahin Boluki and Zhangyang Wang and Bobak J Mortazavi and Shuai Huang and Xiaoning Qian},\nyear={2021},\nurl={https://openreview.net/forum?id=mPmCP2CXc7p}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq . ***Please remember to file the Code-of-Ethics report. Once you submitted the review, a link to the report will be visible in the bottom right corner of your review.***", "required": true, "markdown": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}, "forum": "mPmCP2CXc7p", "replyto": "mPmCP2CXc7p", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"], "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper2895/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1607428800000, "duedate": 1606752000000, "multiReply": false, "readers": ["everyone"], "tcdate": 1602538086468, "tmdate": 1606915777106, "super": "ICLR.cc/2021/Conference/-/Official_Review", "signatures": ["OpenReview.net"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Paper2895/Reviewers", "OpenReview.net/Support"], "id": "ICLR.cc/2021/Conference/Paper2895/-/Official_Review"}}}, {"id": "caIqTnXIjD", "original": null, "number": 2, "cdate": 1603810587535, "ddate": null, "tcdate": 1603810587535, "tmdate": 1605024108800, "tddate": null, "forum": "mPmCP2CXc7p", "replyto": "mPmCP2CXc7p", "invitation": "ICLR.cc/2021/Conference/Paper2895/-/Official_Review", "content": {"title": "Review Dynamic Feature Selection", "review": "The authors tackle the important problem of feature selection. They propose to use differentiable gates with an RNN architecture to select different subsets of features for each time point. I think the idea and method are interesting, and the method could be useful. However, I have crucial problems with the way the paper is presented. Most importantly, the authors describe the l_0 relaxation of Bernoulli random variables as if it is their own contribution. They describe existing known results under a section titles \u201cMethodology\u201d as if they are the first to present Bernoulli random variables to feature selection or that they are the first to relax them using the Gumbel Softmax trick. They also use the word: \u201cwe derive\u201d (p.3). This is wrong! And misleading! The same relaxation appears in [1] and used for model sparsification, the descriptions are almost identical to what appears in [1] with almost zero credit to the authors in [1] (a citation appears in related work in a different context). Bernoulli relaxation was already used for feature selection, in [2], and [3], these papers were not even mentioned. The reader can think the authors are the first to introduce such relaxation into the problem of feature selection, while this is again, clearly wrong.\nThe authors are well aware of that this relaxation was presented in [1], and in the experiment section they describe the baseline which solves (4) by citing [1] (citation [18] in their paper), this is again in contradiction to the way they describe the relaxation as if it is their own contribution. \n\nPutting these CRITICAL comments aside, I think the results are misleading. Specifically, comparing the average number of selected features to the (constant) number of selected features of the non-adaptive method is misleading. You need to compare the union of selected features by your method to the constant number, otherwise, there is no way to infer if this feature selection method can result in any compression of the model or could lead to training or inference speed up.  Given that this is what you measure since you still need all the features to use your model, what are the advantages of the method? Only interpretability?\n\nThe authors do not explain how the method is used in the testing phase, is the randomness removed? How exactly?\nThe authors do not explain how training/ testing is performed, this appears in the appendix but should be moved to the main texts.\nThe authors should compare the method to the distribution suggested in [1], which seems more suitable for feature selection than the Concrete distribution (used by the authors).\nCitations are not in the correct ICLR format.\n\nSome pros: I like the examples used in the paper as well as the comparison to ARM, ST, ST-ARM.\nTo conclude, I am voting to reject the paper, based on all the reasons mentioned above.\n\n[1] Louizos, Christos, Max Welling, and Diederik P. Kingma. \"Learning Sparse Neural Networks through $ L_0 $ Regularization.\" ICLR, 2018.\n\n[2] Yamada, Y., Lindenbaum, O., Negahban, S., & Kluger, Y.  Feature selection using stochastic gates. ICML, 2020.\n\n[3] Bal\u0131n, Muhammed Fatih, Abubakar Abid, and James Zou. \"Concrete autoencoders: Differentiable feature selection and reconstruction.\" ICML. 2019.\n\n", "rating": "3: Clear rejection", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}, "signatures": ["ICLR.cc/2021/Conference/Paper2895/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2895/AnonReviewer2"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Dynamic Feature Selection for Efficient and Interpretable Human Activity Recognition", "authorids": ["~Randy_Ardywibowo1", "~Shahin_Boluki1", "~Zhangyang_Wang1", "~Bobak_J_Mortazavi1", "~Shuai_Huang1", "~Xiaoning_Qian2"], "authors": ["Randy Ardywibowo", "Shahin Boluki", "Zhangyang Wang", "Bobak J Mortazavi", "Shuai Huang", "Xiaoning Qian"], "keywords": ["dynamic feature selection", "human activity recognition", "sparse monitoring"], "abstract": "In many machine learning tasks, input features with varying degrees of predictive capability are usually acquired at some cost. For example, in human activity recognition (HAR) and mobile health (mHealth) applications, monitoring performance should be achieved with a low cost to gather different sensory features, as maintaining sensors incur monetary, computation, and energy cost. We propose an adaptive feature selection method that dynamically selects features for prediction at any given time point. We formulate this problem as an $\\ell_0$ minimization problem across time, and cast the combinatorial optimization problem into a stochastic optimization formulation. We then utilize a differentiable relaxation to make the problem amenable to gradient-based optimization. Our evaluations on four activity recognition datasets show that our method achieves a favorable trade-off between performance and the number of features used. Moreover, the dynamically selected features of our approach are shown to be interpretable and associated with the actual activity types.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "ardywibowo|dynamic_feature_selection_for_efficient_and_interpretable_human_activity_recognition", "one-sentence_summary": "We propose a task-driven dynamic feature selection method to perform human activity recognition efficiently.", "supplementary_material": "/attachment/0442d36e6c7fe5a2ad24564f6cc62cfd16c1fe28.zip", "pdf": "/pdf/90ae614f77bddbf5e9f886151a7fe2c54ddf1cdb.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=Z6AE_bSR8R", "_bibtex": "@misc{\nardywibowo2021dynamic,\ntitle={Dynamic Feature Selection for Efficient and Interpretable Human Activity Recognition},\nauthor={Randy Ardywibowo and Shahin Boluki and Zhangyang Wang and Bobak J Mortazavi and Shuai Huang and Xiaoning Qian},\nyear={2021},\nurl={https://openreview.net/forum?id=mPmCP2CXc7p}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq . ***Please remember to file the Code-of-Ethics report. Once you submitted the review, a link to the report will be visible in the bottom right corner of your review.***", "required": true, "markdown": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}, "forum": "mPmCP2CXc7p", "replyto": "mPmCP2CXc7p", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"], "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper2895/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1607428800000, "duedate": 1606752000000, "multiReply": false, "readers": ["everyone"], "tcdate": 1602538086468, "tmdate": 1606915777106, "super": "ICLR.cc/2021/Conference/-/Official_Review", "signatures": ["OpenReview.net"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Paper2895/Reviewers", "OpenReview.net/Support"], "id": "ICLR.cc/2021/Conference/Paper2895/-/Official_Review"}}}, {"id": "CIGP18JiNz", "original": null, "number": 3, "cdate": 1603932589050, "ddate": null, "tcdate": 1603932589050, "tmdate": 1605024108738, "tddate": null, "forum": "mPmCP2CXc7p", "replyto": "mPmCP2CXc7p", "invitation": "ICLR.cc/2021/Conference/Paper2895/-/Official_Review", "content": {"title": "Although this paper is well written and reported results are positive, the novelty of this paper is quite limited. Besides, several highly-related previous works are missing, and important hyper parameter studies are not reported. These problems prevent me from rating the paper as acceptable.", "review": "This paper presents a learning-based binary sampling mechanism for feature selection. It filters salient feature dimensions by sampling from a Gumbel-softmax distribution, which is differentiable and can be trained with other network parameters. The proposed method is evaluated on several Human Activity Recognition (HAR) datasets.\n\nThe positive and negative points of this paper can be summarized as following:\n\npros:\n+ This paper is well written and is easy to follow.\n+ The experimental evaluations give positive results. \n\ncons: \n- Important previous works are missing. Learning to generate categorical samples for RNNs is not a fresh idea. Actually, [a] has already employs Gumbel-softmax to sample scales in order to dynamically control the temporal pattern learning; More generally, the topic of this paper is connected to a amount of previous works aiming to adaptively decide how/when to memorize/update the inputs/states, such as [b] and [c]. These works should also been cited by this paper.\n\n- With these missing works taking into account, the novelty of this paper becomes incremental and contribution is trivial. Integrating Gumbel-softmax sampling with RNN cells is very straightforward, and the motivation of applying Gumbel-softmax is very similar to [a]. While [a] is proposed for general sequence tasks, the proposed method seems to work only for HAR with multi-dimensional inputs. \n\n- Since \\tau is the only hyper parameter of Gumbel-softmax, evaluations on how the value of \\tau could impact the performance can be important. Yet no such results are reported in the paper. From the original Gumbel-softmax paper we can see a sample can approximate to a one-hot vector when \\tau is small and be closed to a uniform distribution when \\tau goes large. So it is very likely that the performance will become unstable as \\tau changes. Showing such experimental results could be definitely improve the paper quality. I would suggest to report the means and stds of accuracies with different sampling seeds.\n\nSummary:\nConsidering the concerns listed above, I believe there are problems that outweighs the strengths of this paper. They should be fixed before acceptance.\n\n[a] H Hu, et al. Learning to Adaptively Scale Recurrent Neural Networks. AAAI 2019\n[b] V Campos, et al. Skip RNN: Learning to Skip State Updates in Recurrent Neural Networks. ICLR 2018\n[c] D Neil, et al. Phased LSTM: Accelerating Recurrent Network Training for Long or Event-based Sequences. NIPS 2016\n", "rating": "4: Ok but not good enough - rejection", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["ICLR.cc/2021/Conference/Paper2895/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2895/AnonReviewer3"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Dynamic Feature Selection for Efficient and Interpretable Human Activity Recognition", "authorids": ["~Randy_Ardywibowo1", "~Shahin_Boluki1", "~Zhangyang_Wang1", "~Bobak_J_Mortazavi1", "~Shuai_Huang1", "~Xiaoning_Qian2"], "authors": ["Randy Ardywibowo", "Shahin Boluki", "Zhangyang Wang", "Bobak J Mortazavi", "Shuai Huang", "Xiaoning Qian"], "keywords": ["dynamic feature selection", "human activity recognition", "sparse monitoring"], "abstract": "In many machine learning tasks, input features with varying degrees of predictive capability are usually acquired at some cost. For example, in human activity recognition (HAR) and mobile health (mHealth) applications, monitoring performance should be achieved with a low cost to gather different sensory features, as maintaining sensors incur monetary, computation, and energy cost. We propose an adaptive feature selection method that dynamically selects features for prediction at any given time point. We formulate this problem as an $\\ell_0$ minimization problem across time, and cast the combinatorial optimization problem into a stochastic optimization formulation. We then utilize a differentiable relaxation to make the problem amenable to gradient-based optimization. Our evaluations on four activity recognition datasets show that our method achieves a favorable trade-off between performance and the number of features used. Moreover, the dynamically selected features of our approach are shown to be interpretable and associated with the actual activity types.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "ardywibowo|dynamic_feature_selection_for_efficient_and_interpretable_human_activity_recognition", "one-sentence_summary": "We propose a task-driven dynamic feature selection method to perform human activity recognition efficiently.", "supplementary_material": "/attachment/0442d36e6c7fe5a2ad24564f6cc62cfd16c1fe28.zip", "pdf": "/pdf/90ae614f77bddbf5e9f886151a7fe2c54ddf1cdb.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=Z6AE_bSR8R", "_bibtex": "@misc{\nardywibowo2021dynamic,\ntitle={Dynamic Feature Selection for Efficient and Interpretable Human Activity Recognition},\nauthor={Randy Ardywibowo and Shahin Boluki and Zhangyang Wang and Bobak J Mortazavi and Shuai Huang and Xiaoning Qian},\nyear={2021},\nurl={https://openreview.net/forum?id=mPmCP2CXc7p}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq . ***Please remember to file the Code-of-Ethics report. Once you submitted the review, a link to the report will be visible in the bottom right corner of your review.***", "required": true, "markdown": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}, "forum": "mPmCP2CXc7p", "replyto": "mPmCP2CXc7p", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"], "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper2895/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1607428800000, "duedate": 1606752000000, "multiReply": false, "readers": ["everyone"], "tcdate": 1602538086468, "tmdate": 1606915777106, "super": "ICLR.cc/2021/Conference/-/Official_Review", "signatures": ["OpenReview.net"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Paper2895/Reviewers", "OpenReview.net/Support"], "id": "ICLR.cc/2021/Conference/Paper2895/-/Official_Review"}}}, {"id": "aEyOoDp3IsO", "original": null, "number": 4, "cdate": 1604408224452, "ddate": null, "tcdate": 1604408224452, "tmdate": 1605024108679, "tddate": null, "forum": "mPmCP2CXc7p", "replyto": "mPmCP2CXc7p", "invitation": "ICLR.cc/2021/Conference/Paper2895/-/Official_Review", "content": {"title": "Very good paper, but some tuning required in its claims.", "review": "The authors provide a novel combination of known architectures to an important use case of reducing the density of required  measurements in sensor-fusion based temporal multi-class inference tasks. This has implications in energy consumptions of wearable sensors.  but could even generalise to measurement timings in clinical care to make the work of nurses more efficient, and reduce the stress caused by some medical procedures..\n\nThe authors represent a way to train consistent policy that predicts the best combination of sensors to estimate the state of the subjects.  They have found that a smaller set of features.  is more explainable than the full set of features.  However, I think that this somewhat of an overpromise.  The trained model gives the optimal density of the measurements and can discern also if old values and features measured are till OK for the inference.  This does not mean that those measurements are not needed at all in the features.  One can only argue that the required features can be estimated from the older measurement. So, the current set of active sensors is not the full set of required measurement values and can not be exclusively used to explain the logic of the system. Even more, the logic of the policy deciding the new  measurement is not discussed in an explainability context. The authors provide no data on this. It may be just an  estimate the derivative of the signal and ignore a new measurement, if it's time  derivative is small enough. \n\nAs a summary , I support publication of the manuscript, provided  the authors modify the message on the interpretable features.", "rating": "9: Top 15% of accepted papers, strong accept", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}, "signatures": ["ICLR.cc/2021/Conference/Paper2895/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2895/AnonReviewer1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Dynamic Feature Selection for Efficient and Interpretable Human Activity Recognition", "authorids": ["~Randy_Ardywibowo1", "~Shahin_Boluki1", "~Zhangyang_Wang1", "~Bobak_J_Mortazavi1", "~Shuai_Huang1", "~Xiaoning_Qian2"], "authors": ["Randy Ardywibowo", "Shahin Boluki", "Zhangyang Wang", "Bobak J Mortazavi", "Shuai Huang", "Xiaoning Qian"], "keywords": ["dynamic feature selection", "human activity recognition", "sparse monitoring"], "abstract": "In many machine learning tasks, input features with varying degrees of predictive capability are usually acquired at some cost. For example, in human activity recognition (HAR) and mobile health (mHealth) applications, monitoring performance should be achieved with a low cost to gather different sensory features, as maintaining sensors incur monetary, computation, and energy cost. We propose an adaptive feature selection method that dynamically selects features for prediction at any given time point. We formulate this problem as an $\\ell_0$ minimization problem across time, and cast the combinatorial optimization problem into a stochastic optimization formulation. We then utilize a differentiable relaxation to make the problem amenable to gradient-based optimization. Our evaluations on four activity recognition datasets show that our method achieves a favorable trade-off between performance and the number of features used. Moreover, the dynamically selected features of our approach are shown to be interpretable and associated with the actual activity types.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "ardywibowo|dynamic_feature_selection_for_efficient_and_interpretable_human_activity_recognition", "one-sentence_summary": "We propose a task-driven dynamic feature selection method to perform human activity recognition efficiently.", "supplementary_material": "/attachment/0442d36e6c7fe5a2ad24564f6cc62cfd16c1fe28.zip", "pdf": "/pdf/90ae614f77bddbf5e9f886151a7fe2c54ddf1cdb.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=Z6AE_bSR8R", "_bibtex": "@misc{\nardywibowo2021dynamic,\ntitle={Dynamic Feature Selection for Efficient and Interpretable Human Activity Recognition},\nauthor={Randy Ardywibowo and Shahin Boluki and Zhangyang Wang and Bobak J Mortazavi and Shuai Huang and Xiaoning Qian},\nyear={2021},\nurl={https://openreview.net/forum?id=mPmCP2CXc7p}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq . ***Please remember to file the Code-of-Ethics report. Once you submitted the review, a link to the report will be visible in the bottom right corner of your review.***", "required": true, "markdown": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}, "forum": "mPmCP2CXc7p", "replyto": "mPmCP2CXc7p", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"], "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper2895/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1607428800000, "duedate": 1606752000000, "multiReply": false, "readers": ["everyone"], "tcdate": 1602538086468, "tmdate": 1606915777106, "super": "ICLR.cc/2021/Conference/-/Official_Review", "signatures": ["OpenReview.net"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Paper2895/Reviewers", "OpenReview.net/Support"], "id": "ICLR.cc/2021/Conference/Paper2895/-/Official_Review"}}}], "count": 18}