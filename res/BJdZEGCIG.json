{"notes": [{"tddate": null, "ddate": null, "tmdate": 1521805487466, "tcdate": 1521805487466, "number": 1, "cdate": 1521805487466, "id": "HkPhuvf5G", "invitation": "ICLR.cc/2018/Workshop/-/Paper71/Official_Comment", "forum": "BJdZEGCIG", "replyto": "S19gtdrFf", "signatures": ["ICLR.cc/2018/Workshop/Paper71/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Workshop/Paper71/Authors"], "content": {"title": "Answer to the reviewer points", "comment": "The input of the reviewer is appreciated. Yet, we strongly disagree with the points mentioned in it. In particular, regarding the comparison to previous works and availability of the data. We now turn to address all the points: \n\n\n- The idea is not new (hundreds of CNN papers end-to-end trained for image processing are available).\n\nA: To the best of our knowledge, there is no prior work for learning end-to-end image processing, we would appreciate an example of such paper. \n\n-------------------------------------------------------------------------\n\n- Nothing new is said about why use this particular model/architecture (no comparison with other architectures for complete learning, no analysis of the model trained). - There is no new information about the training procedure (tips, training time...). - There are no new ideas about the loss function to use (maybe different perceptual metrics could be used).\n\nA: We do compare (and outperform) SOTA solutions for the measurable task of joint denoising and demosaicing. While we generally agree more ablation studies regarding architecture, loss function and training procedure can be performed, we believe these don't fit the limited extended abstract format. \n\n-------------------------------------------------------------------------\n\n- The set of data collected is not well described, is poor (only images with a particular smartphone and fixed settings) and is not really publicly available (you have to register in a system to get it). \n\nA: The dataset is available on kaggle.com, which hosts many open datasets. Many researchers have already downloaded and are using it. Here is the link for anyone interested https://www.kaggle.com/knn165897/s7-isp-dataset \nWe wonder if the reviewer also thinks that the Imagenet dataset is not really public as it also requires registration. \n\n-------------------------------------------------------------------------\n\n- The tool is trained and tested with data with only one configuration (smartphone and settings). Can it be used in other devices?\n\nA: In the extended version of this short abstract we demonstrate that the tool works also for other lighting conditions. The fact that we treat the phone as a black box, make it easily transferable to any other device. \n\n-------------------------------------------------------------------------\n\n- No information is given on the amount of memory rewired, computational load or time processing.\n\nA: Since it is a fully convolutional model estimating memory and computational costs is trivial. \n\n-------------------------------------------------------------------------\n\n- No comparison is made with other (maybe simpler) options. \n\nA: As mentioned above we do compare to SOTA results for joint denoising and demosaicing. For the full ISP, there is no prior work to compare against and thus we compare against the camera manufacture ISP (which is known to be one of the best on the market).\n"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "DeepISP: Learning End-to-End Image Processing Pipeline", "abstract": "We present DeepISP, a full end-to-end deep neural model of the camera image signal processing (ISP) pipeline. Our model learns a mapping from the raw low-light mosaiced image to the final visually compelling image and encompasses low-level tasks such as demosaicing and denoising as well as higher-level tasks such as color correction and image adjustment. The training and evaluation of the pipeline were performed on a dedicated dataset, the S7-ISP dataset, containing pairs of low-light and well-lit images captured by a Samsung S7 smartphone camera in both raw and processed JPEG formats. The proposed solution achieves state-of-the-art performance in objective evaluation of PSNR on the subtask of joint denoising and demosaicing. For the full end-to-end pipeline, it achieves better visual quality compared to the manufacturer ISP, in both a subjective human assessment and when rated by a deep model trained for assessing image quality. ", "pdf": "/pdf/deb7356673b87bee3d169425bdc6a48ec6816f81.pdf", "TL;DR": "First to show learning of the full image processing pipeline end-to-end. SOTA results for joint denoising and demosaicing.", "paperhash": "schwartz|deepisp_learning_endtoend_image_processing_pipeline", "keywords": ["deep learning", "ISP", "image processing", "denoising", "demosaicing", "s7-isp", "deepisp"], "authors": ["Eli Schwartz", "Raja Giryes", "Alex M. Bronstein"], "authorids": ["eliyahus@mail.tau.ac.il", "raja@tauex.tau.ac.il", "bron@cs.technion.ac.il"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "tmdate": 1519222449739, "id": "ICLR.cc/2018/Workshop/-/Paper71/Official_Comment", "writers": ["ICLR.cc/2018/Workshop"], "signatures": ["ICLR.cc/2018/Workshop"], "readers": ["everyone"], "reply": {"replyto": null, "forum": "BJdZEGCIG", "writers": {"values-regex": "ICLR.cc/2018/Workshop/Paper71/AnonReviewer[0-9]+|ICLR.cc/2018/Workshop/Paper71/Authors|ICLR.cc/2018/Workshop/Program_Chairs"}, "signatures": {"values-regex": "ICLR.cc/2018/Workshop/Paper71/AnonReviewer[0-9]+|ICLR.cc/2018/Workshop/Paper71/Authors|ICLR.cc/2018/Workshop/Program_Chairs", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2018/Workshop/Program_Chairs"]}, "content": {"title": {"required": true, "order": 0, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"required": true, "order": 1, "description": "Your comment or reply (max 5000 characters).", "value-regex": "[\\S\\s]{1,5000}"}}}, "nonreaders": [], "noninvitees": [], "invitees": ["ICLR.cc/2018/Workshop/Paper71/Reviewers", "ICLR.cc/2018/Workshop/Paper71/Authors", "ICLR.cc/2018/Workshop/Program_Chairs"], "cdate": 1519222449739}}, "tauthor": "eliyahus@mail.tau.ac.il"}, {"tddate": null, "ddate": null, "original": null, "tmdate": 1521582753672, "tcdate": 1520650876156, "number": 1, "cdate": 1520650876156, "id": "SkEFqpxFM", "invitation": "ICLR.cc/2018/Workshop/-/Paper71/Official_Review", "forum": "BJdZEGCIG", "replyto": "BJdZEGCIG", "signatures": ["ICLR.cc/2018/Workshop/Paper71/AnonReviewer1"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Workshop/Paper71/AnonReviewer1"], "content": {"title": "A Deep Neural Net for End to End Image Signal Processing ", "rating": "7: Good paper, accept", "review": "The paper presents a deep neural net for doing Image Signal Processing (ISP), as done by a digital camera. The network learns the transformations of denoising and demosaicing as a subtask for converting raw low lit mosaiced image into visually pleasing images.  The network has two stages : the first stage sequentially applies convolutional blocks that learn a feature representation and a residual image, the second stage uses the features from the first stage to learn a transform that is finally applied to the image estimate from the first stage. The latter does low local level transformations (denosiing and demosaicing), while the former does a higher level global correction. The first stage network outperforms existing state of the art methods for the problem of joint denoising and demosaicing, evaluated using PSNR. For evaluation of the full model, a new dataset is created by taking images captured by Samsung S7 camera. The full model is successfully able to outdo the industry grade ISP on the Samsung smartphone in a perceptual study (MOS) on AMT and a learnt classifier.\n\nPaper is well written. The work is novel. Neural networks have been applied for the problems of denoising and demosaicing, but this is the first paper that replicates the entire image processing pipeline in a digital camera using a deep neural net. This approach can jointly performs image processing tasks like de-noising, de-mosaicing, color correction, sharpening.", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "DeepISP: Learning End-to-End Image Processing Pipeline", "abstract": "We present DeepISP, a full end-to-end deep neural model of the camera image signal processing (ISP) pipeline. Our model learns a mapping from the raw low-light mosaiced image to the final visually compelling image and encompasses low-level tasks such as demosaicing and denoising as well as higher-level tasks such as color correction and image adjustment. The training and evaluation of the pipeline were performed on a dedicated dataset, the S7-ISP dataset, containing pairs of low-light and well-lit images captured by a Samsung S7 smartphone camera in both raw and processed JPEG formats. The proposed solution achieves state-of-the-art performance in objective evaluation of PSNR on the subtask of joint denoising and demosaicing. For the full end-to-end pipeline, it achieves better visual quality compared to the manufacturer ISP, in both a subjective human assessment and when rated by a deep model trained for assessing image quality. ", "pdf": "/pdf/deb7356673b87bee3d169425bdc6a48ec6816f81.pdf", "TL;DR": "First to show learning of the full image processing pipeline end-to-end. SOTA results for joint denoising and demosaicing.", "paperhash": "schwartz|deepisp_learning_endtoend_image_processing_pipeline", "keywords": ["deep learning", "ISP", "image processing", "denoising", "demosaicing", "s7-isp", "deepisp"], "authors": ["Eli Schwartz", "Raja Giryes", "Alex M. Bronstein"], "authorids": ["eliyahus@mail.tau.ac.il", "raja@tauex.tau.ac.il", "bron@cs.technion.ac.il"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1520657999000, "tmdate": 1521582753454, "id": "ICLR.cc/2018/Workshop/-/Paper71/Official_Review", "writers": ["ICLR.cc/2018/Workshop"], "signatures": ["ICLR.cc/2018/Workshop"], "readers": ["everyone"], "invitees": ["ICLR.cc/2018/Workshop/Paper71/Reviewers"], "noninvitees": ["ICLR.cc/2018/Workshop/Paper71/AnonReviewer1", "ICLR.cc/2018/Workshop/Paper71/AnonReviewer3"], "reply": {"forum": "BJdZEGCIG", "replyto": "BJdZEGCIG", "writers": {"values-regex": "ICLR.cc/2018/Workshop/Paper71/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2018/Workshop/Paper71/AnonReviewer[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"required": true, "order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"required": true, "order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "value-regex": "[\\S\\s]{1,200000}"}, "rating": {"required": true, "order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"required": true, "order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1528433999000, "cdate": 1521582753454}}}, {"tddate": null, "ddate": null, "original": null, "tmdate": 1521582602935, "tcdate": 1520957682044, "number": 2, "cdate": 1520957682044, "id": "S19gtdrFf", "invitation": "ICLR.cc/2018/Workshop/-/Paper71/Official_Review", "forum": "BJdZEGCIG", "replyto": "BJdZEGCIG", "signatures": ["ICLR.cc/2018/Workshop/Paper71/AnonReviewer3"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Workshop/Paper71/AnonReviewer3"], "content": {"title": "Not deep analysis", "rating": "3: Clear rejection", "review": "The work applies a CNN to predict a well lit image given a poorly illuminated image. Authors collect a set of data from poorly-well illuminated image pairs and train CNN to minimize MS-SSIM, and compare their results with the smartphone's built-in processing software. Results are better in MOS terms. \n\nI would not recommend this article for publication. Application and model are well defined and well evaluated (authors even conduct psychophysical experiments). However in my opinion, the most interesting part (Full ISP) does not bring anything new. From a scientific point of view:\n- The idea is not new (hundreds of CNN papers end-to-end trained for image processing are available).\n- Nothing new is said about why use this particular model/architecture (no comparison with other architectures for complete learning, no analysis of the model trained).\n- There is no new information about the training procedure (tips, training time...).\n- There are no new ideas about the loss function to use (maybe different perceptual metrics could be used).\n- The set of data collected is not well described, is poor (only images with a particular smartphone and fixed settings) and is not really publicly available (you have to register in a system to get it).\n\nFrom the technical point of view, perhaps a company is interested in the application but:\n- The tool is trained and tested with data with only one configuration (smartphone and settings). Can it be used in other devices?\n- No information is given on the amount of memory rewired, computational load or time processing.\n- No comparison is made with other (maybe simpler) options.", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "DeepISP: Learning End-to-End Image Processing Pipeline", "abstract": "We present DeepISP, a full end-to-end deep neural model of the camera image signal processing (ISP) pipeline. Our model learns a mapping from the raw low-light mosaiced image to the final visually compelling image and encompasses low-level tasks such as demosaicing and denoising as well as higher-level tasks such as color correction and image adjustment. The training and evaluation of the pipeline were performed on a dedicated dataset, the S7-ISP dataset, containing pairs of low-light and well-lit images captured by a Samsung S7 smartphone camera in both raw and processed JPEG formats. The proposed solution achieves state-of-the-art performance in objective evaluation of PSNR on the subtask of joint denoising and demosaicing. For the full end-to-end pipeline, it achieves better visual quality compared to the manufacturer ISP, in both a subjective human assessment and when rated by a deep model trained for assessing image quality. ", "pdf": "/pdf/deb7356673b87bee3d169425bdc6a48ec6816f81.pdf", "TL;DR": "First to show learning of the full image processing pipeline end-to-end. SOTA results for joint denoising and demosaicing.", "paperhash": "schwartz|deepisp_learning_endtoend_image_processing_pipeline", "keywords": ["deep learning", "ISP", "image processing", "denoising", "demosaicing", "s7-isp", "deepisp"], "authors": ["Eli Schwartz", "Raja Giryes", "Alex M. Bronstein"], "authorids": ["eliyahus@mail.tau.ac.il", "raja@tauex.tau.ac.il", "bron@cs.technion.ac.il"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1520657999000, "tmdate": 1521582753454, "id": "ICLR.cc/2018/Workshop/-/Paper71/Official_Review", "writers": ["ICLR.cc/2018/Workshop"], "signatures": ["ICLR.cc/2018/Workshop"], "readers": ["everyone"], "invitees": ["ICLR.cc/2018/Workshop/Paper71/Reviewers"], "noninvitees": ["ICLR.cc/2018/Workshop/Paper71/AnonReviewer1", "ICLR.cc/2018/Workshop/Paper71/AnonReviewer3"], "reply": {"forum": "BJdZEGCIG", "replyto": "BJdZEGCIG", "writers": {"values-regex": "ICLR.cc/2018/Workshop/Paper71/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2018/Workshop/Paper71/AnonReviewer[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"required": true, "order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"required": true, "order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "value-regex": "[\\S\\s]{1,200000}"}, "rating": {"required": true, "order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"required": true, "order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1528433999000, "cdate": 1521582753454}}}, {"tddate": null, "ddate": null, "original": null, "tmdate": 1521573583560, "tcdate": 1521573583560, "number": 173, "cdate": 1521573583218, "id": "r1_0R00Fz", "invitation": "ICLR.cc/2018/Workshop/-/Acceptance_Decision", "forum": "BJdZEGCIG", "replyto": "BJdZEGCIG", "signatures": ["ICLR.cc/2018/Workshop/Program_Chairs"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Workshop/Program_Chairs"], "content": {"decision": "Reject", "title": "ICLR 2018 Workshop Acceptance Decision", "comment": "Based on the reviews, this paper has not been accepted for presentation at the ICLR workshop. However, the conversation and updates can continue to appear here on OpenReview."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "DeepISP: Learning End-to-End Image Processing Pipeline", "abstract": "We present DeepISP, a full end-to-end deep neural model of the camera image signal processing (ISP) pipeline. Our model learns a mapping from the raw low-light mosaiced image to the final visually compelling image and encompasses low-level tasks such as demosaicing and denoising as well as higher-level tasks such as color correction and image adjustment. The training and evaluation of the pipeline were performed on a dedicated dataset, the S7-ISP dataset, containing pairs of low-light and well-lit images captured by a Samsung S7 smartphone camera in both raw and processed JPEG formats. The proposed solution achieves state-of-the-art performance in objective evaluation of PSNR on the subtask of joint denoising and demosaicing. For the full end-to-end pipeline, it achieves better visual quality compared to the manufacturer ISP, in both a subjective human assessment and when rated by a deep model trained for assessing image quality. ", "pdf": "/pdf/deb7356673b87bee3d169425bdc6a48ec6816f81.pdf", "TL;DR": "First to show learning of the full image processing pipeline end-to-end. SOTA results for joint denoising and demosaicing.", "paperhash": "schwartz|deepisp_learning_endtoend_image_processing_pipeline", "keywords": ["deep learning", "ISP", "image processing", "denoising", "demosaicing", "s7-isp", "deepisp"], "authors": ["Eli Schwartz", "Raja Giryes", "Alex M. Bronstein"], "authorids": ["eliyahus@mail.tau.ac.il", "raja@tauex.tau.ac.il", "bron@cs.technion.ac.il"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "tmdate": 1518629844880, "id": "ICLR.cc/2018/Workshop/-/Acceptance_Decision", "writers": ["ICLR.cc/2018/Workshop"], "signatures": ["ICLR.cc/2018/Workshop"], "readers": ["everyone"], "invitees": ["ICLR.cc/2018/Workshop/Program_Chairs"], "reply": {"forum": null, "replyto": null, "invitation": "ICLR.cc/2018/Workshop/-/Submission", "writers": {"values": ["ICLR.cc/2018/Workshop/Program_Chairs"]}, "signatures": {"description": "How your identity will be displayed with the above content.", "values": ["ICLR.cc/2018/Workshop/Program_Chairs"]}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["ICLR.cc/2018/Workshop/Program_Chairs", "everyone"]}, "content": {"title": {"required": true, "order": 1, "value": "ICLR 2018 Workshop Acceptance Decision"}, "comment": {"required": false, "order": 3, "description": "(optional) Comment on this decision.", "value-regex": "[\\S\\s]{0,5000}"}, "decision": {"required": true, "order": 2, "value-dropdown": ["Accept", "Reject"]}}}, "nonreaders": [], "noninvitees": [], "cdate": 1518629844880}}}, {"tddate": null, "replyto": null, "ddate": null, "tmdate": 1518375936532, "tcdate": 1518375936532, "number": 71, "cdate": 1518375936532, "id": "BJdZEGCIG", "invitation": "ICLR.cc/2018/Workshop/-/Submission", "forum": "BJdZEGCIG", "signatures": ["~Eli_Schwartz1"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Workshop"], "content": {"title": "DeepISP: Learning End-to-End Image Processing Pipeline", "abstract": "We present DeepISP, a full end-to-end deep neural model of the camera image signal processing (ISP) pipeline. Our model learns a mapping from the raw low-light mosaiced image to the final visually compelling image and encompasses low-level tasks such as demosaicing and denoising as well as higher-level tasks such as color correction and image adjustment. The training and evaluation of the pipeline were performed on a dedicated dataset, the S7-ISP dataset, containing pairs of low-light and well-lit images captured by a Samsung S7 smartphone camera in both raw and processed JPEG formats. The proposed solution achieves state-of-the-art performance in objective evaluation of PSNR on the subtask of joint denoising and demosaicing. For the full end-to-end pipeline, it achieves better visual quality compared to the manufacturer ISP, in both a subjective human assessment and when rated by a deep model trained for assessing image quality. ", "pdf": "/pdf/deb7356673b87bee3d169425bdc6a48ec6816f81.pdf", "TL;DR": "First to show learning of the full image processing pipeline end-to-end. SOTA results for joint denoising and demosaicing.", "paperhash": "schwartz|deepisp_learning_endtoend_image_processing_pipeline", "keywords": ["deep learning", "ISP", "image processing", "denoising", "demosaicing", "s7-isp", "deepisp"], "authors": ["Eli Schwartz", "Raja Giryes", "Alex M. Bronstein"], "authorids": ["eliyahus@mail.tau.ac.il", "raja@tauex.tau.ac.il", "bron@cs.technion.ac.il"]}, "nonreaders": [], "details": {"replyCount": 4, "writable": false, "overwriting": [], "revisions": false, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1518472800000, "tmdate": 1518474081690, "id": "ICLR.cc/2018/Workshop/-/Submission", "writers": ["ICLR.cc/2018/Workshop"], "signatures": ["ICLR.cc/2018/Workshop"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": null, "replyto": null, "writers": {"values": ["ICLR.cc/2018/Workshop"]}, "signatures": {"values-regex": "~.*|ICLR.cc/2018/Workshop", "description": "Your authorized identity to be associated with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"pdf": {"required": true, "order": 9, "value-regex": "upload", "description": "Upload a PDF file that ends with .pdf"}, "title": {"required": true, "order": 1, "description": "Title of paper.", "value-regex": ".{1,250}"}, "abstract": {"required": true, "order": 8, "description": "Abstract of paper.", "value-regex": "[\\S\\s]{1,5000}"}, "authors": {"required": true, "order": 2, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of author names. Please provide real names; identities will be anonymized."}, "keywords": {"order": 6, "values-regex": "(^$)|[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of keywords."}, "TL;DR": {"required": false, "order": 7, "description": "\"Too Long; Didn't Read\": a short sentence describing your paper", "value-regex": "[^\\n]{0,500}"}, "authorids": {"required": true, "order": 3, "values-regex": "([a-z0-9_\\-\\.]{2,}@[a-z0-9_\\-\\.]{2,}\\.[a-z]{2,},){0,}([a-z0-9_\\-\\.]{2,}@[a-z0-9_\\-\\.]{2,}\\.[a-z]{2,})", "description": "Comma separated list of author email addresses, lowercased, in the same order as above. For authors with existing OpenReview accounts, please make sure that the provided email address(es) match those listed in the author's profile. Please provide real emails; identities will be anonymized."}}}, "nonreaders": [], "noninvitees": [], "expdate": 1526248800000, "cdate": 1518474081690}}}], "count": 5}