{"notes": [{"id": "lJuOUWlAC8i", "original": "XZLTZ5iwpX_", "number": 2935, "cdate": 1601308325655, "ddate": null, "tcdate": 1601308325655, "tmdate": 1614985776286, "tddate": null, "forum": "lJuOUWlAC8i", "replyto": null, "invitation": "ICLR.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Learning Contextualized Knowledge Graph Structures for Commonsense Reasoning", "authorids": ["~Jun_Yan5", "mt1170736@iitd.ac.in", "zhang-ty17@mails.tsinghua.edu.cn", "~Ryan_Rossi1", "~Handong_Zhao3", "sukim@adobe.com", "lipka@adobe.com", "~Xiang_Ren1"], "authors": ["Jun Yan", "Mrigank Raman", "Tianyu Zhang", "Ryan Rossi", "Handong Zhao", "Sungchul Kim", "Nedim Lipka", "Xiang Ren"], "keywords": [], "abstract": "Recently, neural-symbolic architectures have achieved success on commonsense reasoning through effectively encoding relational structures retrieved from external knowledge graphs (KGs) and obtained state-of-the-art results in tasks such as (commonsense) question answering and natural language inference. However, current neural-symbolic reasoning methods rely on quality and contextualized knowledge structures (i.e., fact triples) that can be retrieved at the pre-processing stage and overlook challenges such as dealing with incompleteness of a KG (low coverage), limited expressiveness of its relations, and irrelevant retrieved facts in the reasoning context. \nIn this paper, we present a novel neural-symbolic approach, named Hybrid Graph Network (HGN), which jointly generates feature representations for new triples (as complement to the existing edges in the KG), determines relevance of the triples to the reasoning context, and learns graph model parameters for encoding the relational information. Our method learns a compact graph structure (comprising both retrieved and generated edges) through filtering edges that are unhelpful to the reasoning process. We show marked improvements on three commonsense reasoning benchmarks and demonstrate the superiority of the learned graph structures with user studies.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "yan|learning_contextualized_knowledge_graph_structures_for_commonsense_reasoning", "supplementary_material": "/attachment/1e47d3b68eab190164d91f4948ebb222edd215c0.zip", "pdf": "/pdf/3f662940cb9772aec838615078bbb78e81459b18.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=3-26L3usav", "_bibtex": "@misc{\nyan2021learning,\ntitle={Learning Contextualized Knowledge Graph Structures for Commonsense Reasoning},\nauthor={Jun Yan and Mrigank Raman and Tianyu Zhang and Ryan Rossi and Handong Zhao and Sungchul Kim and Nedim Lipka and Xiang Ren},\nyear={2021},\nurl={https://openreview.net/forum?id=lJuOUWlAC8i}\n}"}, "signatures": ["ICLR.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference"], "details": {"replyCount": 19, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"reply": {"readers": {"values-regex": ".*"}, "writers": {"values": ["ICLR.cc/2021/Conference"]}, "signatures": {"values": ["ICLR.cc/2021/Conference"]}, "content": {"authors": {"values": ["Anonymous"]}, "authorids": {"values-regex": ".*"}, "reviewed_version_(pdf)": {"required": false, "description": "Upload a PDF file that ends with .pdf", "value-regex": ".*"}}}, "signatures": ["ICLR.cc/2021/Conference"], "readers": ["everyone"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["~", "OpenReview.net/Support"], "tcdate": 1601308008205, "tmdate": 1614984599368, "id": "ICLR.cc/2021/Conference/-/Blind_Submission"}}, "tauthor": "OpenReview.net"}, {"id": "LSc44Fj0O70", "original": null, "number": 1, "cdate": 1610040354802, "ddate": null, "tcdate": 1610040354802, "tmdate": 1610473944229, "tddate": null, "forum": "lJuOUWlAC8i", "replyto": "lJuOUWlAC8i", "invitation": "ICLR.cc/2021/Conference/Paper2935/-/Decision", "content": {"title": "Final Decision", "decision": "Reject", "comment": "The paper proposes an interesting step in the direction of neuro-symbolic reasoning. While there is no consensus among reviewers about the key novelty of the method, all acknowledge the interest of the direction. All of them also recognize that the submission improved greatly during the discussion phase: clarification of motivations, of experimental settings and results, of discussion with previous work.\n\nHowever, despite those improvements, the submission is not yet ready for publication at ICLR. We encourage the authors to use the very detailed reviews and comments to improve the work. In particular, we encourage them to pay attention at three aspects:\n\n1/ Comparison with large language models: the discussion wrt T5 is important. A key motivation for the proposed model is that it is bringing information and elements for QA (or other reasoning tasks) that purely scaling up language models can not bring. Or maybe they can bring the same kind of improvement but at a much lower computational cost. In any case, this is a very important point to justify the interest of such approach, and neuro-symbolic reasoning overall, empirically.\n\n2/ Using GPT2 (or equivalent): the discussion on using GPT-2 for generating new facts is key too. It is essential to bring this description from appendix to the core of the paper. But more discussion are expected.  For instance, what if GPT-2 generates facts that are false and lead to answering and justifying a wrong answer? In other words, how does it impact the integrity of the contextualized KG? This is an essential point that needs to be worked on more thoroughly. \n\n3/ Overall there have been a lot of discussion to improve the motivations and the contributions. But they are not reflected in the paper necessarily. Following R2, we encourage the authors to \"refocus the existing version (e.g., from vague discussion about neural-symbolic models towards establishing solid comparison to the most related previous work in various sections of the submission)\"\n\n\n\n"}, "signatures": ["ICLR.cc/2021/Conference/Program_Chairs"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference/Program_Chairs"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Learning Contextualized Knowledge Graph Structures for Commonsense Reasoning", "authorids": ["~Jun_Yan5", "mt1170736@iitd.ac.in", "zhang-ty17@mails.tsinghua.edu.cn", "~Ryan_Rossi1", "~Handong_Zhao3", "sukim@adobe.com", "lipka@adobe.com", "~Xiang_Ren1"], "authors": ["Jun Yan", "Mrigank Raman", "Tianyu Zhang", "Ryan Rossi", "Handong Zhao", "Sungchul Kim", "Nedim Lipka", "Xiang Ren"], "keywords": [], "abstract": "Recently, neural-symbolic architectures have achieved success on commonsense reasoning through effectively encoding relational structures retrieved from external knowledge graphs (KGs) and obtained state-of-the-art results in tasks such as (commonsense) question answering and natural language inference. However, current neural-symbolic reasoning methods rely on quality and contextualized knowledge structures (i.e., fact triples) that can be retrieved at the pre-processing stage and overlook challenges such as dealing with incompleteness of a KG (low coverage), limited expressiveness of its relations, and irrelevant retrieved facts in the reasoning context. \nIn this paper, we present a novel neural-symbolic approach, named Hybrid Graph Network (HGN), which jointly generates feature representations for new triples (as complement to the existing edges in the KG), determines relevance of the triples to the reasoning context, and learns graph model parameters for encoding the relational information. Our method learns a compact graph structure (comprising both retrieved and generated edges) through filtering edges that are unhelpful to the reasoning process. We show marked improvements on three commonsense reasoning benchmarks and demonstrate the superiority of the learned graph structures with user studies.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "yan|learning_contextualized_knowledge_graph_structures_for_commonsense_reasoning", "supplementary_material": "/attachment/1e47d3b68eab190164d91f4948ebb222edd215c0.zip", "pdf": "/pdf/3f662940cb9772aec838615078bbb78e81459b18.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=3-26L3usav", "_bibtex": "@misc{\nyan2021learning,\ntitle={Learning Contextualized Knowledge Graph Structures for Commonsense Reasoning},\nauthor={Jun Yan and Mrigank Raman and Tianyu Zhang and Ryan Rossi and Handong Zhao and Sungchul Kim and Nedim Lipka and Xiang Ren},\nyear={2021},\nurl={https://openreview.net/forum?id=lJuOUWlAC8i}\n}"}, "tags": [], "invitation": {"reply": {"forum": "lJuOUWlAC8i", "replyto": "lJuOUWlAC8i", "readers": {"values": ["everyone"]}, "writers": {"values": ["ICLR.cc/2021/Conference/Program_Chairs"]}, "signatures": {"values": ["ICLR.cc/2021/Conference/Program_Chairs"]}, "content": {"title": {"value": "Final Decision"}, "decision": {"value-radio": ["Accept (Oral)", "Accept (Spotlight)", "Accept (Poster)", "Reject"]}, "comment": {"value-regex": "[\\S\\s]{0,50000}", "markdown": true}}}, "multiReply": false, "signatures": ["ICLR.cc/2021/Conference"], "readers": ["everyone"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Program_Chairs"], "tcdate": 1610040354785, "tmdate": 1610473944211, "id": "ICLR.cc/2021/Conference/Paper2935/-/Decision"}}}, {"id": "55ZmquMImnm", "original": null, "number": 1, "cdate": 1603919085671, "ddate": null, "tcdate": 1603919085671, "tmdate": 1606503804363, "tddate": null, "forum": "lJuOUWlAC8i", "replyto": "lJuOUWlAC8i", "invitation": "ICLR.cc/2021/Conference/Paper2935/-/Official_Review", "content": {"title": "Well evaluated and effective KG-based commonsense QA framework", "review": "=== Summary ===\n\nIn this paper, the authors propose a new approach towards incorporating knowledge graphs (KG) into commonsense QA frameworks. KGs are helpful for adding structured \"world\" information, which neural-symbolic architectures can leverage to do commonsense reasoning, e.g., \"what is the expensive resource in printing on paper?\" (paper). In such architectures, however, the authors argue that KG quality is a large impediment (e.g., missing or incorrect edges, distracting nodes, etc). Therefore, they propose a \"hybrid\" KG-based model (accordingly named \"Hybrid Graph Network\") that jointly learns to refine/augment the graph structure while also optimizing it for inference performance.\n\nExperiments are conducted on a number of commonsense reasoning tasks with multiple KG sources, and compared to relevant baselines. They also perform a user study to examine the \"helpfulness\" of the refined KGs produced by the HGN.\n\n=== Justification for Score ===\n\nThis paper is well-written and well-evaluated. The proposed method is also relatively simple and intuitively motivated. The experiments, however, only show modest (yet still positive) empirical gains. Perhaps not a game-changer for commonsense QA, but still a reasonable contribution that I would recommend for acceptance.\n\n=== Strengths ===\n\n+ The paper is clear and well-written. \n+ The experimental section is strong. The model is compared to strong baselines, and I appreciated the extra user-study on learned graph structure.\n+ The method is well-motivated, and provides (modest) empirical gains compared to some baselines.\n+ The method shows good performance with respect to increasing data efficiency (Fig. 4).\n\n=== Concerns ===\n\n- The main concern is on the empirical effectiveness of the model. The results appear to give only modest gains at best (against comparable baselines to the best of my knowledge). For a number of the results the variance is large compared to the relative difference---it would helpful to also include tests of significance for these improvements.\n\n- On OpenbookQA the model significantly underperforms T5-based models. Though I appreciate T5 is unwieldy due to its large size, it makes me question if this method indeed presents a complimentary gain, or is climbing the wrong architectural hill.\n\n=== Update After Rebuttal ===\n\nI commend the authors on a through rebuttal and active rewrites/experimentation. I still think the work is good, and can warrant acceptance. However, I still find the empirical results to be only moderate at best (though I appreciated the authors' rebuttal and significance testing). I am keeping my score the same.", "rating": "7: Good paper, accept", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "signatures": ["ICLR.cc/2021/Conference/Paper2935/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2935/AnonReviewer1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Learning Contextualized Knowledge Graph Structures for Commonsense Reasoning", "authorids": ["~Jun_Yan5", "mt1170736@iitd.ac.in", "zhang-ty17@mails.tsinghua.edu.cn", "~Ryan_Rossi1", "~Handong_Zhao3", "sukim@adobe.com", "lipka@adobe.com", "~Xiang_Ren1"], "authors": ["Jun Yan", "Mrigank Raman", "Tianyu Zhang", "Ryan Rossi", "Handong Zhao", "Sungchul Kim", "Nedim Lipka", "Xiang Ren"], "keywords": [], "abstract": "Recently, neural-symbolic architectures have achieved success on commonsense reasoning through effectively encoding relational structures retrieved from external knowledge graphs (KGs) and obtained state-of-the-art results in tasks such as (commonsense) question answering and natural language inference. However, current neural-symbolic reasoning methods rely on quality and contextualized knowledge structures (i.e., fact triples) that can be retrieved at the pre-processing stage and overlook challenges such as dealing with incompleteness of a KG (low coverage), limited expressiveness of its relations, and irrelevant retrieved facts in the reasoning context. \nIn this paper, we present a novel neural-symbolic approach, named Hybrid Graph Network (HGN), which jointly generates feature representations for new triples (as complement to the existing edges in the KG), determines relevance of the triples to the reasoning context, and learns graph model parameters for encoding the relational information. Our method learns a compact graph structure (comprising both retrieved and generated edges) through filtering edges that are unhelpful to the reasoning process. We show marked improvements on three commonsense reasoning benchmarks and demonstrate the superiority of the learned graph structures with user studies.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "yan|learning_contextualized_knowledge_graph_structures_for_commonsense_reasoning", "supplementary_material": "/attachment/1e47d3b68eab190164d91f4948ebb222edd215c0.zip", "pdf": "/pdf/3f662940cb9772aec838615078bbb78e81459b18.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=3-26L3usav", "_bibtex": "@misc{\nyan2021learning,\ntitle={Learning Contextualized Knowledge Graph Structures for Commonsense Reasoning},\nauthor={Jun Yan and Mrigank Raman and Tianyu Zhang and Ryan Rossi and Handong Zhao and Sungchul Kim and Nedim Lipka and Xiang Ren},\nyear={2021},\nurl={https://openreview.net/forum?id=lJuOUWlAC8i}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq . ***Please remember to file the Code-of-Ethics report. Once you submitted the review, a link to the report will be visible in the bottom right corner of your review.***", "required": true, "markdown": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}, "forum": "lJuOUWlAC8i", "replyto": "lJuOUWlAC8i", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"], "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper2935/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1607428800000, "duedate": 1606752000000, "multiReply": false, "readers": ["everyone"], "tcdate": 1602538085711, "tmdate": 1606915759756, "super": "ICLR.cc/2021/Conference/-/Official_Review", "signatures": ["OpenReview.net"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Paper2935/Reviewers", "OpenReview.net/Support"], "id": "ICLR.cc/2021/Conference/Paper2935/-/Official_Review"}}}, {"id": "q9h9xwYPmS1", "original": null, "number": 3, "cdate": 1605869242777, "ddate": null, "tcdate": 1605869242777, "tmdate": 1606304965815, "tddate": null, "forum": "lJuOUWlAC8i", "replyto": "lJuOUWlAC8i", "invitation": "ICLR.cc/2021/Conference/Paper2935/-/Official_Comment", "content": {"title": "General Response", "comment": "We would like to thank all reviewers very much for your valuable feedback and constructive comments. In our updated draft, we have included additional experiments to address reviewers' questions and improve the writing based on the suggestions.\n\n### Summary of Updates\n\nBelow we briefly summarize our major updates:\n\n- We replace the edge features in our model with ones generated by a contemporaneous work, PathGenerator (Wang et al., 2020). We compare this variant with baseline models and conduct statistical significance tests. [New_Table 1 in General Response]\n- As a fair comparison to PathGenerator-Full (PG-Full), we augment our model with the graph vector generated by RN and compare it with PG-Full. [New_Table 2 in Response to Reviewer 2]\n- We compare our method with Graph Attention Network (GAT) to study the design of edge attention. [New_Table 3 in Response to Reviewer 3]\n- We compare our method with a variant that encodes retrieved facts as edge features. [New_Table 4 in Response to Reviewer 3]\n- We update the draft for fixing typos and grammatical errors and incorporating suggestions for better presentation (especially on motivations and details for the GPT-2 based edge feature generator and edge weights, discussions on PathGenerator and missing reference). \n\n### Performance Gains over Strong Baselines\n\nThere are concerns about the performance gains of our method, especially compared to a contemporaneous work, PathGenerator (Wang et al., 2020). The PathGenerator paper proposes a multi-hop path generator (a fine-tuned GPT-2 model) to generate the path between a pair of concepts. We admit that their generator is stronger than the one we use as it captures *multi-hop* relations between concepts. However, we want to highlight that our proposed method can cope with different designs of the edge feature generator (please see footnote 2 in the paper) and can incorporate stronger edge features like the ones proposed by PathGenerator. Our main contribution is on jointly generating edge features, learning the graph structure, and performing reasoning over the pruned graph structure --- we leave the development of more sophisticated edge feature generation as future work.\n\nWe want to note that PathGenerator (Wang et al., 2020) is a contemporaneous work that was accepted to EMNLP 2020 on Sep 14 and released code on Oct 3. As suggested by the conference organizers (https://iclr.cc/Conferences/2021/ReviewerGuide), \"If a paper was published on or after Aug 2, 2020, authors are not required to compare their own work to that paper. Authors are encouraged to cite and discuss all relevant papers, but they may be excused for not knowing about papers not published in peer-reviewed conference proceedings or journals.\" We didn't reproduce and adopt their generator given the limited time before the ICLR deadline.\n\nAs Wang et al. (2020) have recently released their code, we build our HGN on top of their proposed PathGenerator with the strongest text encoders on two datasets (RoBERTa for CommonsenseQA, and AristoRoBERTa for OpenbookQA).  We summarize the comparison results below, where we observe consistent improvements over all baselines. \n\n|CommonsenseQA|RoBERTa| |OpenbookQA|AristoRoBERTa|\n|:---------------------|:------------:| |:---------------------|:-------------:|\n| **RN**| 70.08(\u00b10.21)| |**RN**| 75.35(\u00b11.39)|\n| **MHGRN**| 71.11(\u00b10.81)| |**MHGRN** | 77.75(\u00b10.38)|\n| **PathGenerator**| 71.55(\u00b10.99)| | **PathGenerator**| 80.05(\u00b10.68)|\n| **HGN**| 72.88(\u00b10.83)| | **HGN**| 79.00(\u00b11.43) |\n| **HGN (w PathGenerator)**| **73.53(\u00b10.67)**| |**HGN (w PathGenerator)**|**80.10(\u00b11.03)**|\n\n**New_Table 1. Performance comparison between our model using PathGenerator as the edge feature generator with strong baseline models on CommonsenseQA and OpenbookQA datasets.**\n\n### Significant Tests on Results of HGN (w PathGenerator) vs Strong Baselines\n\nTo address the concerns on the statistical significance of the performance differences (Reviewers 1, 3), we perform unpaired two-tailed t-Tests (with p-value < 0.05). On CommonsenseQA, HGN (with PathGenerator) is significantly better than all baselines. On OpenbookQA, HGN (with PathGenerator) is significantly better than all baselines except PathGenerator.\n\nIn addition to outperforming baseline methods, we also want to highlight that our model demonstrates its strong performance under *low-resource settings* (where we observe relatively more performance gains, as shown in Figure 6 in the paper). Besides, our way of explicitly generating, denoising, and reasoning with supporting evidence provides good *interpretability* towards building more trustworthy reasoning systems. Our work also points out a direction towards improving KG-augmented QA framework with a focus on the *coverage and quality of knowledge facts*.\n\n-----------------------------------\nReference:\n- Wang et al., EMNLP 2020: Connecting the Dots: A Knowledgeable Path Generator for Commonsense Question Answering"}, "signatures": ["ICLR.cc/2021/Conference/Paper2935/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2935/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Learning Contextualized Knowledge Graph Structures for Commonsense Reasoning", "authorids": ["~Jun_Yan5", "mt1170736@iitd.ac.in", "zhang-ty17@mails.tsinghua.edu.cn", "~Ryan_Rossi1", "~Handong_Zhao3", "sukim@adobe.com", "lipka@adobe.com", "~Xiang_Ren1"], "authors": ["Jun Yan", "Mrigank Raman", "Tianyu Zhang", "Ryan Rossi", "Handong Zhao", "Sungchul Kim", "Nedim Lipka", "Xiang Ren"], "keywords": [], "abstract": "Recently, neural-symbolic architectures have achieved success on commonsense reasoning through effectively encoding relational structures retrieved from external knowledge graphs (KGs) and obtained state-of-the-art results in tasks such as (commonsense) question answering and natural language inference. However, current neural-symbolic reasoning methods rely on quality and contextualized knowledge structures (i.e., fact triples) that can be retrieved at the pre-processing stage and overlook challenges such as dealing with incompleteness of a KG (low coverage), limited expressiveness of its relations, and irrelevant retrieved facts in the reasoning context. \nIn this paper, we present a novel neural-symbolic approach, named Hybrid Graph Network (HGN), which jointly generates feature representations for new triples (as complement to the existing edges in the KG), determines relevance of the triples to the reasoning context, and learns graph model parameters for encoding the relational information. Our method learns a compact graph structure (comprising both retrieved and generated edges) through filtering edges that are unhelpful to the reasoning process. We show marked improvements on three commonsense reasoning benchmarks and demonstrate the superiority of the learned graph structures with user studies.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "yan|learning_contextualized_knowledge_graph_structures_for_commonsense_reasoning", "supplementary_material": "/attachment/1e47d3b68eab190164d91f4948ebb222edd215c0.zip", "pdf": "/pdf/3f662940cb9772aec838615078bbb78e81459b18.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=3-26L3usav", "_bibtex": "@misc{\nyan2021learning,\ntitle={Learning Contextualized Knowledge Graph Structures for Commonsense Reasoning},\nauthor={Jun Yan and Mrigank Raman and Tianyu Zhang and Ryan Rossi and Handong Zhao and Sungchul Kim and Nedim Lipka and Xiang Ren},\nyear={2021},\nurl={https://openreview.net/forum?id=lJuOUWlAC8i}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "lJuOUWlAC8i", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper2935/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper2935/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper2935/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper2935/Authors|ICLR.cc/2021/Conference/Paper2935/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2935/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923842938, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper2935/-/Official_Comment"}}}, {"id": "26h38yh3hAK", "original": null, "number": 7, "cdate": 1605871557805, "ddate": null, "tcdate": 1605871557805, "tmdate": 1606304747659, "tddate": null, "forum": "lJuOUWlAC8i", "replyto": "UdpljQPZXK", "invitation": "ICLR.cc/2021/Conference/Paper2935/-/Official_Comment", "content": {"title": "Response to Reviewer 3 (1/3) ", "comment": "Thank you for your thoughtful review and constructive feedback! We have incorporated your comments to update our paper.\n\n### Weaknesses & Questions 1\n\n>My biggest complaint of the paper in its current form is that several modeling choices were not motivated at all. For example, generating edges between nodes using GPT-2 language model is fairly non-standard. However, the paper lacks any motivation on why this is the right approach to generate facts which are not captured in a KG. What is the guarantee that GPT-2 will not hallucinate and generate a false fact and thereby adding unnecessary noise in the reasoning process.\n\nGenerating facts given a pair of concepts is essentially a KG completion task. Unlike conventional KGs, commonsense KGs are much sparser, which poses challenges for adopting standard embedding-based approaches. As analyzed in Malaviya et al. (2019), an encyclopedic KG like FB15K-237 has 100x the density of a commonsense KG like ConceptNet. Recent works (Malaviya et al., 2019; Bosselut et al., 2019) show that pretrained language models can effectively tackle the sparsity challenge through well-learned semantics of concepts captured during large-scale pretraining. Also, pretrained language models themselves have proven to possess certain commonsense knowledge (Davison et al., 2019). These features make pretrained language models a reasonable choice for commonsense KG completion tasks and motivate our design for the edge feature generator. \n\nAs two examples on applying language models for KG completion, COMET (Bosselut et al., 2019) and PathGenerator (Wang et al., 2020) fine-tune GPT and GPT-2 on KG fact triples (or its template-based sentences) to generate novel facts and achieve impressive results. That motivates us to implement the edge feature generator with GPT-2. The major difference between our generator and Wang et al. (2020) is that we use the generator to predict a relation while they use it to predict a path. We admit that noisy facts could be generated by GPT-2. We therefore propose to jointly learn the graph structure to minimize the impact brought by noisy edges generated by the model. In the second example of case study (Appendix \u00a7C), the generated facts that are kept after pruning include (office worker, AtLocation, water cooler), (worker, AtLocation, water cooler), (gossip, AtLocation, water cooler). All of them make sense in the context provided by the question-answer pair (\"Where would you find an office worker gossiping with their colleagues?\", \"water cooler\").\n\n### Weaknesses & Questions 2\n\n>Following up on the previous point, there could have been several other modeling choices. For example, instead of generating text via a language model, one could gather text (sentences) from Wikipedia or other text corpora containing the entities (which would mean the text would probably not be a false fact). These modeling choices were not explored and were not discussed.\n\nThe characteristics of retrieved textual knowledge are touched in the second paragraph of the Introduction section. A sentence usually contains many concepts and the highly unstructured nature makes it difficult and error-prone to induce the relation between two mentioned concepts. What's more, as commonsense knowledge is usually assumed by humans, most of the commonsense facts are not explicitly written down, especially in Wikipedia which collects encyclopedic knowledge. These issues make retrieved sentences less ideal to be used as features for edges, which are supposed to capture the atomic relational knowledge between concepts. An alternative retrieving source may be OPIEC (Gashteovski et al., 2019), which is a corpus that stores \"semi-structured\" knowledge in Wikipedia extracted by OpenIE techniques. Given a pair of concepts, we plan to retrieve sentences from OPIEC and encode them as the edge feature. We will report back with results and analysis. Please also feel free to suggest any other experiment settings that you think are more reasonable.\n\n### Weaknesses & Questions 3\n> The GPT-2 modeling choice was also moved to the appendix and I think it should definitely be moved to the main section of the paper as it is one of the core  technical contributions of the paper.\n\nThanks for pointing it out! Besides the reason for the space limit, we moved it to appendix because we thought our main model is agnostic to the implementation of the edge feature generator. We agree with your points that it definitely should be put into the main section as it's an important component of the framework and also part of the technical contribution. We have accordingly updated the draft."}, "signatures": ["ICLR.cc/2021/Conference/Paper2935/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2935/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Learning Contextualized Knowledge Graph Structures for Commonsense Reasoning", "authorids": ["~Jun_Yan5", "mt1170736@iitd.ac.in", "zhang-ty17@mails.tsinghua.edu.cn", "~Ryan_Rossi1", "~Handong_Zhao3", "sukim@adobe.com", "lipka@adobe.com", "~Xiang_Ren1"], "authors": ["Jun Yan", "Mrigank Raman", "Tianyu Zhang", "Ryan Rossi", "Handong Zhao", "Sungchul Kim", "Nedim Lipka", "Xiang Ren"], "keywords": [], "abstract": "Recently, neural-symbolic architectures have achieved success on commonsense reasoning through effectively encoding relational structures retrieved from external knowledge graphs (KGs) and obtained state-of-the-art results in tasks such as (commonsense) question answering and natural language inference. However, current neural-symbolic reasoning methods rely on quality and contextualized knowledge structures (i.e., fact triples) that can be retrieved at the pre-processing stage and overlook challenges such as dealing with incompleteness of a KG (low coverage), limited expressiveness of its relations, and irrelevant retrieved facts in the reasoning context. \nIn this paper, we present a novel neural-symbolic approach, named Hybrid Graph Network (HGN), which jointly generates feature representations for new triples (as complement to the existing edges in the KG), determines relevance of the triples to the reasoning context, and learns graph model parameters for encoding the relational information. Our method learns a compact graph structure (comprising both retrieved and generated edges) through filtering edges that are unhelpful to the reasoning process. We show marked improvements on three commonsense reasoning benchmarks and demonstrate the superiority of the learned graph structures with user studies.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "yan|learning_contextualized_knowledge_graph_structures_for_commonsense_reasoning", "supplementary_material": "/attachment/1e47d3b68eab190164d91f4948ebb222edd215c0.zip", "pdf": "/pdf/3f662940cb9772aec838615078bbb78e81459b18.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=3-26L3usav", "_bibtex": "@misc{\nyan2021learning,\ntitle={Learning Contextualized Knowledge Graph Structures for Commonsense Reasoning},\nauthor={Jun Yan and Mrigank Raman and Tianyu Zhang and Ryan Rossi and Handong Zhao and Sungchul Kim and Nedim Lipka and Xiang Ren},\nyear={2021},\nurl={https://openreview.net/forum?id=lJuOUWlAC8i}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "lJuOUWlAC8i", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper2935/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper2935/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper2935/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper2935/Authors|ICLR.cc/2021/Conference/Paper2935/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2935/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923842938, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper2935/-/Official_Comment"}}}, {"id": "HCRGfkeNLf", "original": null, "number": 8, "cdate": 1605871680152, "ddate": null, "tcdate": 1605871680152, "tmdate": 1606304654118, "tddate": null, "forum": "lJuOUWlAC8i", "replyto": "26h38yh3hAK", "invitation": "ICLR.cc/2021/Conference/Paper2935/-/Official_Comment", "content": {"title": "Response to Reviewer 3 (2/3)", "comment": "### Weaknesses & Questions 4\n> Another modeling decision that was not motivated was the graph reasoning part. It is unclear to me why the edge weight is modeled as a part of the message passing process. Another (simpler) alternative could be modeling it as an edge attention, which is computed wrt the text and the current node embeddings. I would be curious to know how this simple model worked and if it didn't why was the case.\n\nWe understand the \u201cedge attention\u201d you suggested as an attention mechanism that assigns different scores to different nodes based on node embeddings and the statement vector, and then normalizes the scores in a local neighborhood. It can be implemented as an extension of the graph attention network (GAT) that considers node embeddings and a statement vector. For simplicity, we denote it as \"GAT\".\n\nIn contrast, our edge weights design can be understood as a global attention mechanism. The model determines the score for each edge and performs normalization over all edges in the contextualized KG. Besides different designs on how to calculate the unnormalized edge scores, we choose global normalization instead of local normalization because local normalization assumes at least one edge should be helpful in a node's incoming neighborhood, which is not true in our situation. For example, for the distracting or wrongly-grounded concepts (e.g. concept \u201cair\u201d in the example from response to \u201cWeaknesses & Questions 7\u201d), none of their connected edges could be helpful to reasoning and all edges in the neighborhood should be pruned. Those noisy nodes should be softly excluded from message passing (results of global normalization) rather than still receive message from a weighted combination of their neighbors (results of local normalization).\n\nWe also do experiments to better understand the difference between these two designs. Results suggest that our edge weight design is superior to the local edge attention.\n\n| **CommonsenseQA**\t| RoBERTa     | | OpenbookQA\t| RoBERTa       |\n|-------------------|-------------| |-------------|---------------| \n| **GAT**\t\t\t| 71.20(\u00b10.72)| |    \t**GAT**\t\t| 65.10(\u00b10.77)  |\n| **HGN**\t\t\t| **72.88(\u00b10.83)**|\t| \t**HGN**\t\t| **69.00(\u00b10.95)**  |\n\n**New_Table 3. Comparison between our model with a variant using GAT-like local edge attention.**\n\n### Weaknesses & Questions 5\n>Even though there are improvements across datasets, the improvements are relatively minor (<1% in few datasets). I think it would be useful to have statistical significance tests.\n\nThanks for your suggestion! You can refer to the general response for the discussion on improvements and significant tests. We will also include that in our future version.\n\n### Weaknesses & Questions 6\n>Regarding the human study, if I understand correctly, was only the node and adjacent matrix shown to the annotators?. Was the relation type (KB relations and generated sentences) included too?\n\nRelation types are included in the human study. We presented facts to the annotators for evaluation of validness and helpfulness and a fact takes the form of a triple which describes the relation between two concepts.\n\n### Weaknesses & Questions 7\n>Can you elaborate on the average helpfulness score of edges in table 5? How many (what proportions) were scored 0, 1 or 2 for both the graphs? I think it would also be helpful to report how many facts all/majority of the annotators found to be helpful for both the graphs.\n\nWe introduce the criteria for helpfulness score in \u00a74.5 and here we'd like to present the example which we gave to the annotators to make it clearer. For a question-answer pair, (\"A man wants air conditioning while we watches the game on Saturday, where will it likely be installed?\", \"house\"), all facts in our learned graph structure include (air conditioning, AtLocation, house), (man, RelatedTo, house), (game, RelatedTo, house), and (air, AtLocation, house). Among them, (air conditioning, AtLocation, house) gets score 2 as this fact corresponds to exactly what the question is asking for -- it \"directly leads to the answer\". (man, RelatedTo, house) and (game, RelatedTo, house) get score 1 because although they are relevant to the discussed topic, they are not conclusive evidence that justifies the answer. (air, AtLocation, house) gets score 0 as it's irrelevant to the discussed topic, which is caused by redundant recognized concepts.\n\nThere are 30 graphs in the user study, each graph contains multiple facts, and each fact is rated by 5 annotators. We average all scores (5 annotators * # of facts in 30 graphs) to get the average helpfulness score.\n\nFor extracted graph structures, on average 26% facts get score 2 (very helpful) and 41% facts get score 1 (moderate helpful). For our learned graph structures, on average 42% facts get score 2 and 36% facts get score 1. This suggests that our model can learn a graph structure with a larger portion of helpful facts."}, "signatures": ["ICLR.cc/2021/Conference/Paper2935/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2935/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Learning Contextualized Knowledge Graph Structures for Commonsense Reasoning", "authorids": ["~Jun_Yan5", "mt1170736@iitd.ac.in", "zhang-ty17@mails.tsinghua.edu.cn", "~Ryan_Rossi1", "~Handong_Zhao3", "sukim@adobe.com", "lipka@adobe.com", "~Xiang_Ren1"], "authors": ["Jun Yan", "Mrigank Raman", "Tianyu Zhang", "Ryan Rossi", "Handong Zhao", "Sungchul Kim", "Nedim Lipka", "Xiang Ren"], "keywords": [], "abstract": "Recently, neural-symbolic architectures have achieved success on commonsense reasoning through effectively encoding relational structures retrieved from external knowledge graphs (KGs) and obtained state-of-the-art results in tasks such as (commonsense) question answering and natural language inference. However, current neural-symbolic reasoning methods rely on quality and contextualized knowledge structures (i.e., fact triples) that can be retrieved at the pre-processing stage and overlook challenges such as dealing with incompleteness of a KG (low coverage), limited expressiveness of its relations, and irrelevant retrieved facts in the reasoning context. \nIn this paper, we present a novel neural-symbolic approach, named Hybrid Graph Network (HGN), which jointly generates feature representations for new triples (as complement to the existing edges in the KG), determines relevance of the triples to the reasoning context, and learns graph model parameters for encoding the relational information. Our method learns a compact graph structure (comprising both retrieved and generated edges) through filtering edges that are unhelpful to the reasoning process. We show marked improvements on three commonsense reasoning benchmarks and demonstrate the superiority of the learned graph structures with user studies.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "yan|learning_contextualized_knowledge_graph_structures_for_commonsense_reasoning", "supplementary_material": "/attachment/1e47d3b68eab190164d91f4948ebb222edd215c0.zip", "pdf": "/pdf/3f662940cb9772aec838615078bbb78e81459b18.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=3-26L3usav", "_bibtex": "@misc{\nyan2021learning,\ntitle={Learning Contextualized Knowledge Graph Structures for Commonsense Reasoning},\nauthor={Jun Yan and Mrigank Raman and Tianyu Zhang and Ryan Rossi and Handong Zhao and Sungchul Kim and Nedim Lipka and Xiang Ren},\nyear={2021},\nurl={https://openreview.net/forum?id=lJuOUWlAC8i}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "lJuOUWlAC8i", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper2935/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper2935/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper2935/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper2935/Authors|ICLR.cc/2021/Conference/Paper2935/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2935/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923842938, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper2935/-/Official_Comment"}}}, {"id": "DaksNRwDid", "original": null, "number": 17, "cdate": 1606229783038, "ddate": null, "tcdate": 1606229783038, "tmdate": 1606304596160, "tddate": null, "forum": "lJuOUWlAC8i", "replyto": "HfH-ZxDS723", "invitation": "ICLR.cc/2021/Conference/Paper2935/-/Official_Comment", "content": {"title": "Response to Q4, Q5", "comment": ">Q4: It is nice that the current method outperforms GAT, however, in the draft of the paper, the modeling decision was not motivated as global reasoning. I think the paper would need more motivation about why a global model is required and why is this the best choice for a global model.\n\nThanks for your suggestions! We have added detailed discussion about motivations for global edge weight and local edge attention in \u00a73.2 \u201cReasoning with Weighted Graph\u201d as well as experiment results in \u00a74.3 \u201cStudy on More Model Variants\u201d in the updated draft. We also updated our response to \u201cWeaknesses & Questions 4\u201d to make it clearer.\n\n>Q5: Thanks for doing the significance test. If I understand correctly, these tests are done over the results of the latest model (i.e. with PathGenerator)?. Were the results of the original HGN model not significant?\n\nThe significance test in the general response is done on HGN (w PathGenerator).\n\nFor our original HGN:\n- on 60% CommonsenseQA + BERT-Base: significant over all baselines\n- on 100% CommonsenseQA + BERT-Base: significant over all baselines\n- on 60% CommonsenseQA + BERT-Large: significant over all baselines except MHGRN\n- on 100% CommonsenseQA + BERT-Large: significant over all baselines except MHGRN\n- on 60% CommonsenseQA + RoBERTa: significant over all baselines except MHGRN\n- on 100% CommonsenseQA + RoBERTa: significant over all baselines except PathGenerator\n- on OpenbookQA + RoBERTa: significant over all baselines except PathGenerator\n- on OpenbookQA + AristoRoBERTa: significant over RN, RGCN, GconAttn\n- on CODAH: significant over RGCN on RoBERTa\n\nNote that MHGRN and PathGen are both to be published in EMNLP 2020. For CODAH, we analyze in \u00a74.3 \u201cPerformance Comparisons\u201d that: \u201cAs Chen et al. (2019) suggest, questions in CODAH mainly target commonsense reasoning about quantitative, negation and object reference. In this case, relational knowledge provided by ConceptNet may only offer limited help.\u201d\n\nWe do observe more significant improvement when equipping our model with PathGenerator (without hyperparameter tuning) as presented in the general response. Other advantages and values of our model beyond performance gain are also discussed there. We\u2019ll do more exploration and tuning on our HGN (w PathGenrator) model to include stronger results.\n\n> Some of the initial concerns remain. I think the paper still lacks motivation wrt the GPT2 model generating missing edges. \n\nThanks for bringing this up! We have included more details and motivations for GPT-2 based edge feature generator in \u00a73.1 \u201cEdge Feature Generator\u201d based on our discussion. We hope our updated draft could address your concern. If there\u2019s still something unclear, we appreciate it if you could provide more feedback."}, "signatures": ["ICLR.cc/2021/Conference/Paper2935/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2935/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Learning Contextualized Knowledge Graph Structures for Commonsense Reasoning", "authorids": ["~Jun_Yan5", "mt1170736@iitd.ac.in", "zhang-ty17@mails.tsinghua.edu.cn", "~Ryan_Rossi1", "~Handong_Zhao3", "sukim@adobe.com", "lipka@adobe.com", "~Xiang_Ren1"], "authors": ["Jun Yan", "Mrigank Raman", "Tianyu Zhang", "Ryan Rossi", "Handong Zhao", "Sungchul Kim", "Nedim Lipka", "Xiang Ren"], "keywords": [], "abstract": "Recently, neural-symbolic architectures have achieved success on commonsense reasoning through effectively encoding relational structures retrieved from external knowledge graphs (KGs) and obtained state-of-the-art results in tasks such as (commonsense) question answering and natural language inference. However, current neural-symbolic reasoning methods rely on quality and contextualized knowledge structures (i.e., fact triples) that can be retrieved at the pre-processing stage and overlook challenges such as dealing with incompleteness of a KG (low coverage), limited expressiveness of its relations, and irrelevant retrieved facts in the reasoning context. \nIn this paper, we present a novel neural-symbolic approach, named Hybrid Graph Network (HGN), which jointly generates feature representations for new triples (as complement to the existing edges in the KG), determines relevance of the triples to the reasoning context, and learns graph model parameters for encoding the relational information. Our method learns a compact graph structure (comprising both retrieved and generated edges) through filtering edges that are unhelpful to the reasoning process. We show marked improvements on three commonsense reasoning benchmarks and demonstrate the superiority of the learned graph structures with user studies.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "yan|learning_contextualized_knowledge_graph_structures_for_commonsense_reasoning", "supplementary_material": "/attachment/1e47d3b68eab190164d91f4948ebb222edd215c0.zip", "pdf": "/pdf/3f662940cb9772aec838615078bbb78e81459b18.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=3-26L3usav", "_bibtex": "@misc{\nyan2021learning,\ntitle={Learning Contextualized Knowledge Graph Structures for Commonsense Reasoning},\nauthor={Jun Yan and Mrigank Raman and Tianyu Zhang and Ryan Rossi and Handong Zhao and Sungchul Kim and Nedim Lipka and Xiang Ren},\nyear={2021},\nurl={https://openreview.net/forum?id=lJuOUWlAC8i}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "lJuOUWlAC8i", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper2935/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper2935/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper2935/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper2935/Authors|ICLR.cc/2021/Conference/Paper2935/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2935/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923842938, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper2935/-/Official_Comment"}}}, {"id": "bxYn5ektF5E", "original": null, "number": 9, "cdate": 1605871723055, "ddate": null, "tcdate": 1605871723055, "tmdate": 1606304490538, "tddate": null, "forum": "lJuOUWlAC8i", "replyto": "HCRGfkeNLf", "invitation": "ICLR.cc/2021/Conference/Paper2935/-/Official_Comment", "content": {"title": "Response to Reviewer 3 (3/3)", "comment": "### Missing Reference\n\nThanks for suggesting these papers. In our updated draft, we discuss them when we introduce our methodology (\u00a73.1) and related work (\u00a75). Sun et al. (2019) propose PullNet, which iteratively constructs a question-specific subgraph which contains information relevant to the question. They work on open-domain question answering where retrieved factual knowledge plays a decisive role in inferring the answer entity. However in our task of multiple-choice commonsense question answering, the collected commonsense knowledge is for offering helpful background facts of mentioned concepts to enhance context understanding. Neelakantan et al. (2015) and  Das et al. (2017) leverage the path connecting two entities to infer the relation between them for KG completion. They can be used as an edge feature generator but still face the challenges brought by characteristics of commonsense KGs (as discussed in the response to Weaknesses & Questions 1).\n\n-----------------------------------\nReference:\n- Malaviya et al., AAAI 2020: Exploiting Structural and Semantic Context for Commonsense Knowledge Base Completion\n- Davison et al., EMNLP 2019: Commonsense Knowledge Mining from Pretrained Models\n- Wang et al., EMNLP 2020: Connecting the Dots: A Knowledgeable Path Generator for Commonsense Question Answering\n- Bosselut et al., ACL 2019: COMET: Commonsense Transformers for Automatic Knowledge Graph Construction\n- Gashteovski et al., AKBC 2019: OPIEC: An Open Information Extraction Corpus\n- Sun et al., EMNLP 2019: PullNet: Open Domain Question Answering with Iterative Retrieval on Knowledge Bases and Text\n- Neelakantan et al., ACL 2015: Compositional Vector Space Models for Knowledge Base Completion\n- Das et al., EACL 2017: Chains of Reasoning over Entities, Relations, and Text using Recurrent Neural Networks"}, "signatures": ["ICLR.cc/2021/Conference/Paper2935/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2935/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Learning Contextualized Knowledge Graph Structures for Commonsense Reasoning", "authorids": ["~Jun_Yan5", "mt1170736@iitd.ac.in", "zhang-ty17@mails.tsinghua.edu.cn", "~Ryan_Rossi1", "~Handong_Zhao3", "sukim@adobe.com", "lipka@adobe.com", "~Xiang_Ren1"], "authors": ["Jun Yan", "Mrigank Raman", "Tianyu Zhang", "Ryan Rossi", "Handong Zhao", "Sungchul Kim", "Nedim Lipka", "Xiang Ren"], "keywords": [], "abstract": "Recently, neural-symbolic architectures have achieved success on commonsense reasoning through effectively encoding relational structures retrieved from external knowledge graphs (KGs) and obtained state-of-the-art results in tasks such as (commonsense) question answering and natural language inference. However, current neural-symbolic reasoning methods rely on quality and contextualized knowledge structures (i.e., fact triples) that can be retrieved at the pre-processing stage and overlook challenges such as dealing with incompleteness of a KG (low coverage), limited expressiveness of its relations, and irrelevant retrieved facts in the reasoning context. \nIn this paper, we present a novel neural-symbolic approach, named Hybrid Graph Network (HGN), which jointly generates feature representations for new triples (as complement to the existing edges in the KG), determines relevance of the triples to the reasoning context, and learns graph model parameters for encoding the relational information. Our method learns a compact graph structure (comprising both retrieved and generated edges) through filtering edges that are unhelpful to the reasoning process. We show marked improvements on three commonsense reasoning benchmarks and demonstrate the superiority of the learned graph structures with user studies.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "yan|learning_contextualized_knowledge_graph_structures_for_commonsense_reasoning", "supplementary_material": "/attachment/1e47d3b68eab190164d91f4948ebb222edd215c0.zip", "pdf": "/pdf/3f662940cb9772aec838615078bbb78e81459b18.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=3-26L3usav", "_bibtex": "@misc{\nyan2021learning,\ntitle={Learning Contextualized Knowledge Graph Structures for Commonsense Reasoning},\nauthor={Jun Yan and Mrigank Raman and Tianyu Zhang and Ryan Rossi and Handong Zhao and Sungchul Kim and Nedim Lipka and Xiang Ren},\nyear={2021},\nurl={https://openreview.net/forum?id=lJuOUWlAC8i}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "lJuOUWlAC8i", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper2935/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper2935/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper2935/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper2935/Authors|ICLR.cc/2021/Conference/Paper2935/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2935/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923842938, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper2935/-/Official_Comment"}}}, {"id": "RDL_XNdchnc", "original": null, "number": 10, "cdate": 1605871852598, "ddate": null, "tcdate": 1605871852598, "tmdate": 1606302540227, "tddate": null, "forum": "lJuOUWlAC8i", "replyto": "55ZmquMImnm", "invitation": "ICLR.cc/2021/Conference/Paper2935/-/Official_Comment", "content": {"title": "Response to Reviewer 1", "comment": "Thanks for your valuable feedback!\n\n### Concerns 1\n>The main concern is on the empirical effectiveness of the model. The results appear to give only modest gains at best (against comparable baselines to the best of my knowledge). For a number of the results the variance is large compared to the relative difference---it would helpful to also include tests of significance for these improvements.\n\nThanks for pointing this out. You can refer to our general response for the discussion on the empirically performance gains, significance of improvements, and other merits of our proposed model. We equip our HGN with a stronger edge feature generator. Without hyperparameter tuning, it significantly outperforms all baselines on CommonsenseQA and all baselines except PathGenerator on OpenbookQA with p-value < 0.05.\n\nFor our original HGN:\n- on 60% CommonsenseQA + BERT-Base: significant over all baselines\n- on 100% CommonsenseQA + BERT-Base: significant over all baselines\n- on 60% CommonsenseQA + BERT-Large: significant over all baselines except MHGRN\n- on 100% CommonsenseQA + BERT-Large: significant over all baselines except MHGRN\n- on 60% CommonsenseQA + RoBERTa: significant over all baselines except MHGRN\n- on 100% CommonsenseQA + RoBERTa: significant over all baselines except PathGenerator\n- on OpenbookQA + RoBERTa: significant over all baselines except PathGenerator\n- on OpenbookQA + AristoRoBERTa: significant over RN, RGCN, GconAttn\n- on CODAH: significant over RGCN on RoBERTa\n\nNote that MHGRN and PathGenerator are both to be published in EMNLP 2020. For CODAH, we analyze in \u00a74.3 \u201cPerformance Comparisons\u201d that: \u201cAs Chen et al. (2019) suggest, questions in CODAH mainly target commonsense reasoning about quantitative, negation and object reference. In this case, relational knowledge provided by ConceptNet may only offer limited help.\u201d\n\nWe\u2019ll do more exploration and tuning on our new model to include stronger results.\n\n### Concerns 2\n>On OpenbookQA the model significantly underperforms T5-based models. Though I appreciate T5 is unwieldy due to its large size, it makes me question if this method indeed presents a complimentary gain, or is climbing the wrong architectural hill.\n\nT5 is a stronger pretrained model compared to BERT, RoBERTa, etc. and established new SOTA results on a series of benchmarks. However, full T5 has 11B parameters, which is 30 times larger than RoBERTa-large (355M parameters). The huge size makes it impractical to be widely studied and deployed due to lack of computing infrastructure.\n\nWe believe in the potential of our model even with T5 as decoder based on two observations:\n1. On ComonsenseQA and OpenbookQA, with BERT-Base, BERT-Large and RoBERTa being the text encoders, our model consistently outperforms knowledge-augmented baselines, which are generally better than the knowledge-agnostic baseline (LM Finetuning). It suggests that, if a knowledge-agnostic model can be improved with existing knowledge-augmented reasoning methods, then it can get further enhancement with our proposed HGN which resolves the coverage and quality issues of the supporting knowledge facts that are of vital importance in knowledge-augmented reasoning.\n2. Although T5 hasn't been widely tested on many benchmarks, results on OpenbookQA's leaderboard suggest that T5 can also benefit from KG knowledge (T5 got 83.2 test acc while T5+KB got 85.4 test acc, as shown in Table 3 in the paper).\n\nTherefore, we believe incorporating external (KG) knowledge is still an important direction towards advanced commonsense reasoning abilities. The key challenge is how to effectively collect and reason over high-quality knowledge facts, which our model is targeting at."}, "signatures": ["ICLR.cc/2021/Conference/Paper2935/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2935/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Learning Contextualized Knowledge Graph Structures for Commonsense Reasoning", "authorids": ["~Jun_Yan5", "mt1170736@iitd.ac.in", "zhang-ty17@mails.tsinghua.edu.cn", "~Ryan_Rossi1", "~Handong_Zhao3", "sukim@adobe.com", "lipka@adobe.com", "~Xiang_Ren1"], "authors": ["Jun Yan", "Mrigank Raman", "Tianyu Zhang", "Ryan Rossi", "Handong Zhao", "Sungchul Kim", "Nedim Lipka", "Xiang Ren"], "keywords": [], "abstract": "Recently, neural-symbolic architectures have achieved success on commonsense reasoning through effectively encoding relational structures retrieved from external knowledge graphs (KGs) and obtained state-of-the-art results in tasks such as (commonsense) question answering and natural language inference. However, current neural-symbolic reasoning methods rely on quality and contextualized knowledge structures (i.e., fact triples) that can be retrieved at the pre-processing stage and overlook challenges such as dealing with incompleteness of a KG (low coverage), limited expressiveness of its relations, and irrelevant retrieved facts in the reasoning context. \nIn this paper, we present a novel neural-symbolic approach, named Hybrid Graph Network (HGN), which jointly generates feature representations for new triples (as complement to the existing edges in the KG), determines relevance of the triples to the reasoning context, and learns graph model parameters for encoding the relational information. Our method learns a compact graph structure (comprising both retrieved and generated edges) through filtering edges that are unhelpful to the reasoning process. We show marked improvements on three commonsense reasoning benchmarks and demonstrate the superiority of the learned graph structures with user studies.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "yan|learning_contextualized_knowledge_graph_structures_for_commonsense_reasoning", "supplementary_material": "/attachment/1e47d3b68eab190164d91f4948ebb222edd215c0.zip", "pdf": "/pdf/3f662940cb9772aec838615078bbb78e81459b18.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=3-26L3usav", "_bibtex": "@misc{\nyan2021learning,\ntitle={Learning Contextualized Knowledge Graph Structures for Commonsense Reasoning},\nauthor={Jun Yan and Mrigank Raman and Tianyu Zhang and Ryan Rossi and Handong Zhao and Sungchul Kim and Nedim Lipka and Xiang Ren},\nyear={2021},\nurl={https://openreview.net/forum?id=lJuOUWlAC8i}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "lJuOUWlAC8i", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper2935/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper2935/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper2935/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper2935/Authors|ICLR.cc/2021/Conference/Paper2935/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2935/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923842938, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper2935/-/Official_Comment"}}}, {"id": "DrFIkRqacfn", "original": null, "number": 6, "cdate": 1605870826064, "ddate": null, "tcdate": 1605870826064, "tmdate": 1606300561510, "tddate": null, "forum": "lJuOUWlAC8i", "replyto": "Z8UFagFl1dW", "invitation": "ICLR.cc/2021/Conference/Paper2935/-/Official_Comment", "content": {"title": "Response to Reviewer 2 (3/3)", "comment": "### Comments 1\n\n>The paper uses much space to discuss neural symbolic approaches. Given the vague benefit of doing so, it may be better to use the limited space to focus more on establishing the contributions w.r.t. existing models; e.g., more details about (Wang et al., 2020) can be provided and compared to in both methodological and experimental analyses.\n\nThanks for the suggestion! In the updated draft, we have compressed the discussion and made \u00a72 a more compact background section that presents the problem formulation, notations, and high-level architecture. We discuss the design difference when we introduce our methodology (the last paragraph of \u00a72; \u00a73.1 \"Edge Feature Generator\"). We highlight Wang et al. (2020) by putting it into a category named \"Models Using Generated Facts\" and providing more details when we introduce the compared methods (\u00a74.2). We also make it clear in \u00a75 that the core difference between our work and Wang et al. (2020) is that they still assume a static graph structure for reasoning. We will formally add more empirical discussion in the future version where we also adopt the path generator (Wang et al., 2020) as an implementation of our relational feature generator f_{gen}.\n\n### Comments 2\n\n>The human evaluation was performed on the questions with correct questions. More analyses on the edges and weights generated for questions that were not correctly answered may help better understand the proposed model.\n\nSorry for the confusion. We don't distinguish correctly-answered questions from wrongly-answered questions in the user study --- we looked at both of them. Specifically, in CommonsenseQA, each question has five answer candidates and these five (question, answer candidate) pairs will give five graphs. Among these five graphs, we want to select the one that corresponds to the question with the correct answer candidate. This is because the contextualized KG provides evidence facts in a supportive way --- plausible answer candidates get more supportive facts while implausible answer candidates get fewer. Therefore, analyzing how a correct answer candidate can be better supported by our hybrid facts compared to extracted facts could be a more intuitive way to understand the effectiveness of our graph structure learning strategies. On the contrary, wrong answer candidates are usually less relevant to the question concepts. The contextualized KG is much sparser with less room to be improved with supportive facts.\n\nTo better address your concern, we also investigate the questions that are wrongly answered by our model. We identify two patterns from these wrongly answered questions:\n\n\\* edge format: (subject, relation, object, edge weight)\n1. The wrong answer is associated with many more facts than the correct answer.\n\n\t*Example:* \n\t- Question: What would encourage someone to continue playing tennis?\n\t- Wrong answer (model's prediction): exercise\n\t\t- Edges (weight \u2265 0.01): (play tennis, Causes, exercise, 0.47), (playing tennis, Causes, exercise, 0.47), (tennis, IsA, exercise, 0.04), (play, RelatedTo, exercise, 0.01), (playing, UsedFor, exercise, 0.01)\n\t- Correct answer: victory \n\t\t- Edges (weight \u2265 0.01): (playing tennis, Causes, victory, 0.99)\n\t- Analysis: Answers with more supporting facts are more likely to be the correct one in the training set. That may make the model biased towards choosing the answer associated with many more facts regardless of their relevance to the question. Some kind of normalization could be helpful to alleviate this issue.\n\n2. The crucial fact leading to the correct answer is not identified and upweighted.\n\n\t*Example:*\n\t- Question: A revolving door is convenient for two direction travel, but it also serves as a security measure at a what?\n\t- Wrong answer (model's prediction): mall\n\t\t- Edges (weight \u2265 0.01): (revolving door, AtLocation, mall, 0.98)\n\t- Correct answer: bank\n\t\t- Edges (weight \u2265 0.01): (revolving door, AtLocation, bank, 0.94), (security, RelatedTo, bank, 0.03), (two, RelatedTo, bank, 0.03)\n\t- Analysis: Both the correct answer and the wrong answer has a revolving door, making (security, RelatedTo, bank) the most discriminative fact. However, the model fails to identify this crucial fact and upweight it. This is a weakness brought by separately modeling the question with different answers, which makes it difficult for the model to identify the discriminative facts by comparing different answer choices. A future direction could be modeling all choices within one contextualized KG to make them aware of each other and identify discriminative facts.\n\n-----------------------------------\nReference:\n- Wang et al., EMNLP 2020: Connecting the Dots: A Knowledgeable Path Generator for Commonsense Question Answering"}, "signatures": ["ICLR.cc/2021/Conference/Paper2935/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2935/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Learning Contextualized Knowledge Graph Structures for Commonsense Reasoning", "authorids": ["~Jun_Yan5", "mt1170736@iitd.ac.in", "zhang-ty17@mails.tsinghua.edu.cn", "~Ryan_Rossi1", "~Handong_Zhao3", "sukim@adobe.com", "lipka@adobe.com", "~Xiang_Ren1"], "authors": ["Jun Yan", "Mrigank Raman", "Tianyu Zhang", "Ryan Rossi", "Handong Zhao", "Sungchul Kim", "Nedim Lipka", "Xiang Ren"], "keywords": [], "abstract": "Recently, neural-symbolic architectures have achieved success on commonsense reasoning through effectively encoding relational structures retrieved from external knowledge graphs (KGs) and obtained state-of-the-art results in tasks such as (commonsense) question answering and natural language inference. However, current neural-symbolic reasoning methods rely on quality and contextualized knowledge structures (i.e., fact triples) that can be retrieved at the pre-processing stage and overlook challenges such as dealing with incompleteness of a KG (low coverage), limited expressiveness of its relations, and irrelevant retrieved facts in the reasoning context. \nIn this paper, we present a novel neural-symbolic approach, named Hybrid Graph Network (HGN), which jointly generates feature representations for new triples (as complement to the existing edges in the KG), determines relevance of the triples to the reasoning context, and learns graph model parameters for encoding the relational information. Our method learns a compact graph structure (comprising both retrieved and generated edges) through filtering edges that are unhelpful to the reasoning process. We show marked improvements on three commonsense reasoning benchmarks and demonstrate the superiority of the learned graph structures with user studies.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "yan|learning_contextualized_knowledge_graph_structures_for_commonsense_reasoning", "supplementary_material": "/attachment/1e47d3b68eab190164d91f4948ebb222edd215c0.zip", "pdf": "/pdf/3f662940cb9772aec838615078bbb78e81459b18.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=3-26L3usav", "_bibtex": "@misc{\nyan2021learning,\ntitle={Learning Contextualized Knowledge Graph Structures for Commonsense Reasoning},\nauthor={Jun Yan and Mrigank Raman and Tianyu Zhang and Ryan Rossi and Handong Zhao and Sungchul Kim and Nedim Lipka and Xiang Ren},\nyear={2021},\nurl={https://openreview.net/forum?id=lJuOUWlAC8i}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "lJuOUWlAC8i", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper2935/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper2935/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper2935/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper2935/Authors|ICLR.cc/2021/Conference/Paper2935/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2935/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923842938, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper2935/-/Official_Comment"}}}, {"id": "Z8UFagFl1dW", "original": null, "number": 5, "cdate": 1605870649659, "ddate": null, "tcdate": 1605870649659, "tmdate": 1606299918735, "tddate": null, "forum": "lJuOUWlAC8i", "replyto": "PCGBH7odeI-", "invitation": "ICLR.cc/2021/Conference/Paper2935/-/Official_Comment", "content": {"title": "Response to Reviewer 2 (2/3)", "comment": "### Cons 2\n\n>The empirical comparison to previous work (e.g., Wang et al. 2020) needs to be clearer to help understand the empirical advantages of the proposed models. The paper mentioned some reason of excluding PG-Full from comparison, but since PG-Global does not include static knowledge embedding and PG-full does, is the latter a more reasonable baseline to be compared with? The model does not achieve better performance than existing models on some tasks, which casts doubts on its effectiveness; e.g., whether its advantage is orthogonal to that brought by stronger models such as those performing much better on the OpenbookQA task.\n\nThanks for your question! The PG-Full model is described as:\n>(3) PathGeneratorFull (or PG-Full): We equip our reasoning module with both the global path generator and the RN baseline described above. In specific, we extend Eq. 8 by feeding the concatenation of the context embedding, the path embedding and the static knowledge embedding to the classifier.\" (https://arxiv.org/abs/2005.00691v1)\n\nThe authors concatenate the knowledge embedding generated by PG-Global model (\"the path embedding\") and the knowledge embedding generated by RN model (\"the static knowledge embedding\") as the final knowledge embedding used for making predictions. Since it directly combines the features generated by PG-Global and RN, we consider it as an ensemble model of these two models, instead of a unified graph reasoning model that operates on both generated and extracted facts. We think it's unfair to compare our single HGN model with their ensemble PG-Full model.\n\nTo better support our argument, we build a variant of our model named \"HGN+RN\" by combining the features generated by our model and RN, with the statement vector (\"context embedding\"). New_Table 2 shows that we can also get improvement by integrating RN. HGN+RN significantly outperforms PG-Full with p-value < 0.05. That makes us think that it's more meaningful to do comparison among \"single\" models by excluding the \"ensemble\" one.\n\n| CommonsenseQA\t\t| RoBERTa| | CommonsenseQA\t\t| RoBERTa|\n|:--------------------------|:---------------:|--|:--------------------------|:---------------:|\n| **PathGenerator (PG-Global)** | 71.55(\u00b10.99)| | **PG-Full (PG-Global+RN)**    | 72.68(\u00b10.42)|\n| **HGN**                       | **72.88(\u00b10.83)**| | **HGN+RN**                    | **73.43(\u00b10.26)**|  \n\n**New_Table 2. Effect of adding features generated by RN to our model.**\n\nRegarding the effectiveness of our proposed model on OpenbookQA, we observe consistent improvement over all baselines (with the contemporaneous work Wang et al., (2020) as the only exception) when we shift our text encoder from RoBERTa to AristoRoBERTa, which implies our advantage is orthogonal to that brought by stronger base models. As shown in the general response, our HGN outperforms PathGenerator with the AristoRoBERTa encoder when equipped with a stronger edge feature generator. On OpenbookQA's leaderboard, our original HGN achieves the highest test accuracy (81.4) among all models using AristoRoBERTa as the text encoder, which is higher than PathGenerator (80.4). Submissions using different text encoders are not comparable. We choose AristoRoBERTa instead of AristoAlbert as the text encoder because: \n1. AristoRoBERTa is a well-established model and used by many other competitors so we can have fair comparisons with more models;\n2. the training of AristoAlbert is about 8 times slower than AristoRoBERTa, making it less practical to be adopted.\n\nMore discussion on the empirical effectiveness of our model is presented in the general response, where we adopt a stronger edge feature generator and achieve significant performance gains."}, "signatures": ["ICLR.cc/2021/Conference/Paper2935/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2935/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Learning Contextualized Knowledge Graph Structures for Commonsense Reasoning", "authorids": ["~Jun_Yan5", "mt1170736@iitd.ac.in", "zhang-ty17@mails.tsinghua.edu.cn", "~Ryan_Rossi1", "~Handong_Zhao3", "sukim@adobe.com", "lipka@adobe.com", "~Xiang_Ren1"], "authors": ["Jun Yan", "Mrigank Raman", "Tianyu Zhang", "Ryan Rossi", "Handong Zhao", "Sungchul Kim", "Nedim Lipka", "Xiang Ren"], "keywords": [], "abstract": "Recently, neural-symbolic architectures have achieved success on commonsense reasoning through effectively encoding relational structures retrieved from external knowledge graphs (KGs) and obtained state-of-the-art results in tasks such as (commonsense) question answering and natural language inference. However, current neural-symbolic reasoning methods rely on quality and contextualized knowledge structures (i.e., fact triples) that can be retrieved at the pre-processing stage and overlook challenges such as dealing with incompleteness of a KG (low coverage), limited expressiveness of its relations, and irrelevant retrieved facts in the reasoning context. \nIn this paper, we present a novel neural-symbolic approach, named Hybrid Graph Network (HGN), which jointly generates feature representations for new triples (as complement to the existing edges in the KG), determines relevance of the triples to the reasoning context, and learns graph model parameters for encoding the relational information. Our method learns a compact graph structure (comprising both retrieved and generated edges) through filtering edges that are unhelpful to the reasoning process. We show marked improvements on three commonsense reasoning benchmarks and demonstrate the superiority of the learned graph structures with user studies.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "yan|learning_contextualized_knowledge_graph_structures_for_commonsense_reasoning", "supplementary_material": "/attachment/1e47d3b68eab190164d91f4948ebb222edd215c0.zip", "pdf": "/pdf/3f662940cb9772aec838615078bbb78e81459b18.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=3-26L3usav", "_bibtex": "@misc{\nyan2021learning,\ntitle={Learning Contextualized Knowledge Graph Structures for Commonsense Reasoning},\nauthor={Jun Yan and Mrigank Raman and Tianyu Zhang and Ryan Rossi and Handong Zhao and Sungchul Kim and Nedim Lipka and Xiang Ren},\nyear={2021},\nurl={https://openreview.net/forum?id=lJuOUWlAC8i}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "lJuOUWlAC8i", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper2935/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper2935/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper2935/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper2935/Authors|ICLR.cc/2021/Conference/Paper2935/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2935/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923842938, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper2935/-/Official_Comment"}}}, {"id": "PCGBH7odeI-", "original": null, "number": 4, "cdate": 1605870556352, "ddate": null, "tcdate": 1605870556352, "tmdate": 1606298723412, "tddate": null, "forum": "lJuOUWlAC8i", "replyto": "JzSfOkUXAkc", "invitation": "ICLR.cc/2021/Conference/Paper2935/-/Official_Comment", "content": {"title": "Response to Reviewer 2 (1/3)", "comment": "Thank you for your thoughtful comments!\n\n### Cons 1\n\n> My major concern about this paper is the novelty and contributions in terms of methodology. Compared to existing methods (e.g., those PG models proposed (Wang et al. 2020)), the novelty of the current submission is rather limited --- the proposed model of jointly generating new triples and learning (pruning) the graph structure with the network parameters is an interesting, but a pretty incremental idea.\n\nThank you for the question regarding the novelty of our work. We have included more discussions about the novelty in the updated draft (mainly in \u00a71) and also recap our contributions here.\n\nThe quality of the collected evidence facts plays a vital role in KG-augmented commonsense reasoning but has been overlooked by previous works. Enriching KG facts with generated facts and pruning unreliable and unrelated facts is an important problem for maintaining strong reasoning performance. However, how to jointly manipulate (prune) the graph structure while performing message passing-based reasoning in a graph network (along with edge features) is a non-trivial problem --- there\u2019s no direct supervision guiding us to either keep or remove certain facts and existing works simply assume a *static graph* is used throughout the learning process. We therefore propose to jointly learn the graph structure using the downstream task as the signal. To our knowledge, our work is one of the first to jointly conduct graph structure pruning and parameter learning on graph networks (along with updating edge features) for KG-augmented commonsense reasoning. Our comparisons to baseline models show that our joint learning approach helps obtain stronger performance.\n\nCompared with path-based methods including PathGenerator, we also want to clarify our novelty claim is not on the \u201ctriple generation\u201d module alone, but more on jointly learning the graph structure with the parameters for reasoning (contributions summarized in the last paragraph of \u00a71). While previous works study how to reason over an extracted graph and Wang et al. (2020) focus on how to generate new paths as evidence, they all reason over a static graph, which is assumed to have a \u201cclean\u201d structure. Our work is the first to drop this problematic assumption, and integrate both extracted and generated facts into a unified graph reasoning model with the denoising ability.\n\nTo summarize, our work resolves three intrinsic issues with KG-augmented commonsense reasoning models:\n\n1.  low coverage of KG facts: we generate facts to complete the contextualized KG.\n\n2. limited expressiveness of KG relations: we generate continuous relational features instead of embedding the generated relations with a lookup table for better expressiveness.\n\n3. wrong facts or uncontextualized facts (facts that contain mentioned concepts but are not helpful for reasoning): we jointly prune the graph structure by edge reweighting with entropy regularization during reasoning.\n\nWe consider 3 as our major novelty and uniqueness from previous and contemporaneous works --- we no longer assume the perfect graph structure of a contextualized KG, which is too good to be true and hinders the model from benefiting from high-quality supporting facts."}, "signatures": ["ICLR.cc/2021/Conference/Paper2935/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2935/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Learning Contextualized Knowledge Graph Structures for Commonsense Reasoning", "authorids": ["~Jun_Yan5", "mt1170736@iitd.ac.in", "zhang-ty17@mails.tsinghua.edu.cn", "~Ryan_Rossi1", "~Handong_Zhao3", "sukim@adobe.com", "lipka@adobe.com", "~Xiang_Ren1"], "authors": ["Jun Yan", "Mrigank Raman", "Tianyu Zhang", "Ryan Rossi", "Handong Zhao", "Sungchul Kim", "Nedim Lipka", "Xiang Ren"], "keywords": [], "abstract": "Recently, neural-symbolic architectures have achieved success on commonsense reasoning through effectively encoding relational structures retrieved from external knowledge graphs (KGs) and obtained state-of-the-art results in tasks such as (commonsense) question answering and natural language inference. However, current neural-symbolic reasoning methods rely on quality and contextualized knowledge structures (i.e., fact triples) that can be retrieved at the pre-processing stage and overlook challenges such as dealing with incompleteness of a KG (low coverage), limited expressiveness of its relations, and irrelevant retrieved facts in the reasoning context. \nIn this paper, we present a novel neural-symbolic approach, named Hybrid Graph Network (HGN), which jointly generates feature representations for new triples (as complement to the existing edges in the KG), determines relevance of the triples to the reasoning context, and learns graph model parameters for encoding the relational information. Our method learns a compact graph structure (comprising both retrieved and generated edges) through filtering edges that are unhelpful to the reasoning process. We show marked improvements on three commonsense reasoning benchmarks and demonstrate the superiority of the learned graph structures with user studies.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "yan|learning_contextualized_knowledge_graph_structures_for_commonsense_reasoning", "supplementary_material": "/attachment/1e47d3b68eab190164d91f4948ebb222edd215c0.zip", "pdf": "/pdf/3f662940cb9772aec838615078bbb78e81459b18.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=3-26L3usav", "_bibtex": "@misc{\nyan2021learning,\ntitle={Learning Contextualized Knowledge Graph Structures for Commonsense Reasoning},\nauthor={Jun Yan and Mrigank Raman and Tianyu Zhang and Ryan Rossi and Handong Zhao and Sungchul Kim and Nedim Lipka and Xiang Ren},\nyear={2021},\nurl={https://openreview.net/forum?id=lJuOUWlAC8i}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "lJuOUWlAC8i", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper2935/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper2935/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper2935/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper2935/Authors|ICLR.cc/2021/Conference/Paper2935/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2935/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923842938, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper2935/-/Official_Comment"}}}, {"id": "UdpljQPZXK", "original": null, "number": 2, "cdate": 1603928613867, "ddate": null, "tcdate": 1603928613867, "tmdate": 1606242791575, "tddate": null, "forum": "lJuOUWlAC8i", "replyto": "lJuOUWlAC8i", "invitation": "ICLR.cc/2021/Conference/Paper2935/-/Official_Review", "content": {"title": "Review", "review": "The paper proposes a question answering model that is augmented with a common-sense knowledge graph (KG). The paper builds on the following two observations \u2014 (a) KGs are incomplete often lacking facts that would be needed for reasoning to answer a question. (b) Current methods over-retrieves facts (edges) from the KG leading to a lot of unrelated facts that potentially makes reasoning noisier and harder.\n\nThe paper first retrieves all possible facts from the KG connecting entities in the question and answer. However, due to the incompleteness of the KG, the retrieved subgraph might be missing important edges between entities. To deal with this, they connect all nodes between question and answer entities and initialize the embedding of the newly added edge with hidden layers of a sentence generated from a fine-tuned GPT2 language model (this important detail was mentioned in the appendix). However, currently the graph is over complete and very noisy. The proposed model then sparsifies the graph by learning edge weights via a two-step message passing process. The edge weight is learned as a function of the current edge representation and the textual representation. Lastly, an entropy term is added to the objective function to encourage more peakiness (and sparsity). \n\nThe model is tested on three common-sense QA benchmarks and on three of them they beat the baselines albeit only around 1-2%. Statistical significance of the result was not reported. Ablation study show that the efficacy of including the generated edges and pruning the graph. There was a small human-study also done where the annotators were shown a binarized graph and were asked to rate each edge. Annotators had moderate agreement between themselves in finding that the pruned graph was better than the original retrieved graph.\n\n\nStrengths:\n* Developing models that can use symbolic external knowledge present in common-sense KGs and also overcome the sparsity in KG is important and this model is a step in that direction\n* The paper achieves a little improvement in performance in all three datasets and ablation experiments are helpful in understanding the results\n* The paper is clearly written and it was easy to follow for the most part\n\nWeaknesses & clarifying questions for the authors:\n* My biggest complain of the paper in its current form is that several modeling choices were not motivated at all. For example, generating edges between nodes using GPT-2 language model is fairly non-standard. However, the paper lacks any motivation on why this is the right approach to generate facts which are not captured in a KG. What is the guarantee that GPT-2 will not hallucinate and generate a false fact and thereby adding unnecessary noise in the reasoning process.\n* Following up on the previous point, there could have been several other modeling choices. For example, instead of generating text via a language model, one could gather text (sentences) from Wikipedia or other text corpora containing the entities (which would mean the text would probably not be a false fact). These modeling choices were not explored and were not discussed. \n* The GPT-2 modeling choice was also moved to the appendix and I think it should definitely be moved to the main section of the paper as it is one of the core technical contribution of the paper.\n* Another modeling decision that was not motivated was the graph reasoning part. It is unclear to me why the edge weight is modeled as a part of the message passing process. Another (simpler) alternative could be modeling it as an edge attention, which is computed wrt the text and the current node embeddings. I would be curious to know how this simple model worked and if it didn\u2019t why was the case.\n* Even though there are improvements across dataset, the improvements are relatively minor (<1% in few datasets). I think it would be useful to have statistical significance test.\n* Regarding the human study, if I understand correctly, was only the node and adjacent matrix shown to the annotators?. Was the relation type (KB relations and generated sentences) included too? If they were not included I think they should be because knowing the relations is also very improvement.\n* Can you elaborate on the average helpfulness score of edges in table 5? How many (what proportions) were scored 0, 1 or 2 for both the graphs? I think it would also be helpful to report how many facts all/majority of the annotators found to be helpful for both the graphs. \n\nMissing Reference: It would be nice to cite Sun et al EMNLP 2019 -- PullNet: Open Domain Question Answering with\nIterative Retrieval on Knowledge Bases and Text since one of the core contributions of that paper was to retrieve and keep only relevant facts from the KG. Relation paths in KG were explored by several works before Wang et al 2020 such as Neelakantan et al ACL 2015 - Compositional Vector Space Models for Knowledge Base Completion, Das et al EACL 2017 -- Chains of reasoning over entities, relations and text etc. It would be nice to cite those work as well.\n\nRecommendation:  In light of the current weaknesses of the paper, I am giving it a score of 5 and I look forward to the discussion.\n\n=======11/22======\n\nI am deciding to keep the same scores as before. Some of the initial concerns remain. I think the paper still lacks motivation wrt the GPT2 model generating missing edges. Thank you for getting the latest results, the paper is stronger than before and with some more work, I am confident it will be a good contribution to the research community.\n\n=====11/24======\n\nAfter having read through the explanation behind using GPT2 as edge features (and sufficient backing by 2 closely related work), I am increasing my score to 6. I think the discussion helped in somewhat convincing me that this approach would work for ConceptNet because of its limited schema.\n", "rating": "6: Marginally above acceptance threshold", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["ICLR.cc/2021/Conference/Paper2935/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2935/AnonReviewer3"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Learning Contextualized Knowledge Graph Structures for Commonsense Reasoning", "authorids": ["~Jun_Yan5", "mt1170736@iitd.ac.in", "zhang-ty17@mails.tsinghua.edu.cn", "~Ryan_Rossi1", "~Handong_Zhao3", "sukim@adobe.com", "lipka@adobe.com", "~Xiang_Ren1"], "authors": ["Jun Yan", "Mrigank Raman", "Tianyu Zhang", "Ryan Rossi", "Handong Zhao", "Sungchul Kim", "Nedim Lipka", "Xiang Ren"], "keywords": [], "abstract": "Recently, neural-symbolic architectures have achieved success on commonsense reasoning through effectively encoding relational structures retrieved from external knowledge graphs (KGs) and obtained state-of-the-art results in tasks such as (commonsense) question answering and natural language inference. However, current neural-symbolic reasoning methods rely on quality and contextualized knowledge structures (i.e., fact triples) that can be retrieved at the pre-processing stage and overlook challenges such as dealing with incompleteness of a KG (low coverage), limited expressiveness of its relations, and irrelevant retrieved facts in the reasoning context. \nIn this paper, we present a novel neural-symbolic approach, named Hybrid Graph Network (HGN), which jointly generates feature representations for new triples (as complement to the existing edges in the KG), determines relevance of the triples to the reasoning context, and learns graph model parameters for encoding the relational information. Our method learns a compact graph structure (comprising both retrieved and generated edges) through filtering edges that are unhelpful to the reasoning process. We show marked improvements on three commonsense reasoning benchmarks and demonstrate the superiority of the learned graph structures with user studies.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "yan|learning_contextualized_knowledge_graph_structures_for_commonsense_reasoning", "supplementary_material": "/attachment/1e47d3b68eab190164d91f4948ebb222edd215c0.zip", "pdf": "/pdf/3f662940cb9772aec838615078bbb78e81459b18.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=3-26L3usav", "_bibtex": "@misc{\nyan2021learning,\ntitle={Learning Contextualized Knowledge Graph Structures for Commonsense Reasoning},\nauthor={Jun Yan and Mrigank Raman and Tianyu Zhang and Ryan Rossi and Handong Zhao and Sungchul Kim and Nedim Lipka and Xiang Ren},\nyear={2021},\nurl={https://openreview.net/forum?id=lJuOUWlAC8i}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq . ***Please remember to file the Code-of-Ethics report. Once you submitted the review, a link to the report will be visible in the bottom right corner of your review.***", "required": true, "markdown": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}, "forum": "lJuOUWlAC8i", "replyto": "lJuOUWlAC8i", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"], "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper2935/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1607428800000, "duedate": 1606752000000, "multiReply": false, "readers": ["everyone"], "tcdate": 1602538085711, "tmdate": 1606915759756, "super": "ICLR.cc/2021/Conference/-/Official_Review", "signatures": ["OpenReview.net"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Paper2935/Reviewers", "OpenReview.net/Support"], "id": "ICLR.cc/2021/Conference/Paper2935/-/Official_Review"}}}, {"id": "HfH-ZxDS723", "original": null, "number": 14, "cdate": 1606099169892, "ddate": null, "tcdate": 1606099169892, "tmdate": 1606242738211, "tddate": null, "forum": "lJuOUWlAC8i", "replyto": "HCRGfkeNLf", "invitation": "ICLR.cc/2021/Conference/Paper2935/-/Official_Comment", "content": {"title": "Response", "comment": "Q4: It is nice that the current method outperforms GAT, however, in the draft of the paper, the modeling decision was not motivated as global reasoning. I think the paper would need more motivation about why a global model is required and why is this the best choice for a global model. \n\nQ5: Thanks for doing the significance test. If I understand correctly, these tests are done over the results of the latest model (i.e. with PathGenerator)?. Were the results of the original HGN model not significant?\n\nQ6 and 7: Thanks for the clarification.\n\n=======11/22======\n\nI am deciding to keep the same scores as before. Some of the initial concerns remain. I think the paper still lacks motivation wrt the GPT2 model generating missing edges. Thank you for getting the latest results, the paper is stronger than before and with some more work, I am confident it will be a good contribution to the research community.\n\n=====11/24======\n\nAfter having read through the explanation behind using GPT2 as edge features (and sufficient backing by 2 closely related work), I am increasing my score to 6. I think the discussion helped in somewhat convincing me that this approach would work for ConceptNet because of its limited schema."}, "signatures": ["ICLR.cc/2021/Conference/Paper2935/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2935/AnonReviewer3"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Learning Contextualized Knowledge Graph Structures for Commonsense Reasoning", "authorids": ["~Jun_Yan5", "mt1170736@iitd.ac.in", "zhang-ty17@mails.tsinghua.edu.cn", "~Ryan_Rossi1", "~Handong_Zhao3", "sukim@adobe.com", "lipka@adobe.com", "~Xiang_Ren1"], "authors": ["Jun Yan", "Mrigank Raman", "Tianyu Zhang", "Ryan Rossi", "Handong Zhao", "Sungchul Kim", "Nedim Lipka", "Xiang Ren"], "keywords": [], "abstract": "Recently, neural-symbolic architectures have achieved success on commonsense reasoning through effectively encoding relational structures retrieved from external knowledge graphs (KGs) and obtained state-of-the-art results in tasks such as (commonsense) question answering and natural language inference. However, current neural-symbolic reasoning methods rely on quality and contextualized knowledge structures (i.e., fact triples) that can be retrieved at the pre-processing stage and overlook challenges such as dealing with incompleteness of a KG (low coverage), limited expressiveness of its relations, and irrelevant retrieved facts in the reasoning context. \nIn this paper, we present a novel neural-symbolic approach, named Hybrid Graph Network (HGN), which jointly generates feature representations for new triples (as complement to the existing edges in the KG), determines relevance of the triples to the reasoning context, and learns graph model parameters for encoding the relational information. Our method learns a compact graph structure (comprising both retrieved and generated edges) through filtering edges that are unhelpful to the reasoning process. We show marked improvements on three commonsense reasoning benchmarks and demonstrate the superiority of the learned graph structures with user studies.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "yan|learning_contextualized_knowledge_graph_structures_for_commonsense_reasoning", "supplementary_material": "/attachment/1e47d3b68eab190164d91f4948ebb222edd215c0.zip", "pdf": "/pdf/3f662940cb9772aec838615078bbb78e81459b18.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=3-26L3usav", "_bibtex": "@misc{\nyan2021learning,\ntitle={Learning Contextualized Knowledge Graph Structures for Commonsense Reasoning},\nauthor={Jun Yan and Mrigank Raman and Tianyu Zhang and Ryan Rossi and Handong Zhao and Sungchul Kim and Nedim Lipka and Xiang Ren},\nyear={2021},\nurl={https://openreview.net/forum?id=lJuOUWlAC8i}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "lJuOUWlAC8i", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper2935/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper2935/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper2935/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper2935/Authors|ICLR.cc/2021/Conference/Paper2935/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2935/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923842938, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper2935/-/Official_Comment"}}}, {"id": "bDcEr4opJ5g", "original": null, "number": 19, "cdate": 1606232113119, "ddate": null, "tcdate": 1606232113119, "tmdate": 1606232113119, "tddate": null, "forum": "lJuOUWlAC8i", "replyto": "55ZmquMImnm", "invitation": "ICLR.cc/2021/Conference/Paper2935/-/Official_Comment", "content": {"title": "Look Forward to Hearing from You", "comment": "Dear Reviewer 1,\n\nWe really appreciate your positive feedback and thoughtful comments! We have responded to your concerns with more discussion on empirical effectiveness and other advantages of our model, as well as the value of our proposed method over huge pretrained models like T5. We're wondering if our response addresses your concern? We really appreciate it if you could let us know any further comments before the end of the rebuttal period.\n\nThanks again for your time!"}, "signatures": ["ICLR.cc/2021/Conference/Paper2935/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2935/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Learning Contextualized Knowledge Graph Structures for Commonsense Reasoning", "authorids": ["~Jun_Yan5", "mt1170736@iitd.ac.in", "zhang-ty17@mails.tsinghua.edu.cn", "~Ryan_Rossi1", "~Handong_Zhao3", "sukim@adobe.com", "lipka@adobe.com", "~Xiang_Ren1"], "authors": ["Jun Yan", "Mrigank Raman", "Tianyu Zhang", "Ryan Rossi", "Handong Zhao", "Sungchul Kim", "Nedim Lipka", "Xiang Ren"], "keywords": [], "abstract": "Recently, neural-symbolic architectures have achieved success on commonsense reasoning through effectively encoding relational structures retrieved from external knowledge graphs (KGs) and obtained state-of-the-art results in tasks such as (commonsense) question answering and natural language inference. However, current neural-symbolic reasoning methods rely on quality and contextualized knowledge structures (i.e., fact triples) that can be retrieved at the pre-processing stage and overlook challenges such as dealing with incompleteness of a KG (low coverage), limited expressiveness of its relations, and irrelevant retrieved facts in the reasoning context. \nIn this paper, we present a novel neural-symbolic approach, named Hybrid Graph Network (HGN), which jointly generates feature representations for new triples (as complement to the existing edges in the KG), determines relevance of the triples to the reasoning context, and learns graph model parameters for encoding the relational information. Our method learns a compact graph structure (comprising both retrieved and generated edges) through filtering edges that are unhelpful to the reasoning process. We show marked improvements on three commonsense reasoning benchmarks and demonstrate the superiority of the learned graph structures with user studies.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "yan|learning_contextualized_knowledge_graph_structures_for_commonsense_reasoning", "supplementary_material": "/attachment/1e47d3b68eab190164d91f4948ebb222edd215c0.zip", "pdf": "/pdf/3f662940cb9772aec838615078bbb78e81459b18.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=3-26L3usav", "_bibtex": "@misc{\nyan2021learning,\ntitle={Learning Contextualized Knowledge Graph Structures for Commonsense Reasoning},\nauthor={Jun Yan and Mrigank Raman and Tianyu Zhang and Ryan Rossi and Handong Zhao and Sungchul Kim and Nedim Lipka and Xiang Ren},\nyear={2021},\nurl={https://openreview.net/forum?id=lJuOUWlAC8i}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "lJuOUWlAC8i", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper2935/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper2935/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper2935/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper2935/Authors|ICLR.cc/2021/Conference/Paper2935/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2935/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923842938, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper2935/-/Official_Comment"}}}, {"id": "DHwaMj0U8BT", "original": null, "number": 18, "cdate": 1606231257056, "ddate": null, "tcdate": 1606231257056, "tmdate": 1606231257056, "tddate": null, "forum": "lJuOUWlAC8i", "replyto": "JzSfOkUXAkc", "invitation": "ICLR.cc/2021/Conference/Paper2935/-/Official_Comment", "content": {"title": "Look Forward to Hearing from You", "comment": "Dear Reviewer 2,\n\nThank you very much for your feedback! In our response, we have included more discussion and new experiments to address your concern. We have also updated our draft based on your suggestion. We're wondering if you have further questions or comments regarding this work? We really appreciate it if you could let us know before the end of the rebuttal period.\n\nThanks again for your time!"}, "signatures": ["ICLR.cc/2021/Conference/Paper2935/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2935/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Learning Contextualized Knowledge Graph Structures for Commonsense Reasoning", "authorids": ["~Jun_Yan5", "mt1170736@iitd.ac.in", "zhang-ty17@mails.tsinghua.edu.cn", "~Ryan_Rossi1", "~Handong_Zhao3", "sukim@adobe.com", "lipka@adobe.com", "~Xiang_Ren1"], "authors": ["Jun Yan", "Mrigank Raman", "Tianyu Zhang", "Ryan Rossi", "Handong Zhao", "Sungchul Kim", "Nedim Lipka", "Xiang Ren"], "keywords": [], "abstract": "Recently, neural-symbolic architectures have achieved success on commonsense reasoning through effectively encoding relational structures retrieved from external knowledge graphs (KGs) and obtained state-of-the-art results in tasks such as (commonsense) question answering and natural language inference. However, current neural-symbolic reasoning methods rely on quality and contextualized knowledge structures (i.e., fact triples) that can be retrieved at the pre-processing stage and overlook challenges such as dealing with incompleteness of a KG (low coverage), limited expressiveness of its relations, and irrelevant retrieved facts in the reasoning context. \nIn this paper, we present a novel neural-symbolic approach, named Hybrid Graph Network (HGN), which jointly generates feature representations for new triples (as complement to the existing edges in the KG), determines relevance of the triples to the reasoning context, and learns graph model parameters for encoding the relational information. Our method learns a compact graph structure (comprising both retrieved and generated edges) through filtering edges that are unhelpful to the reasoning process. We show marked improvements on three commonsense reasoning benchmarks and demonstrate the superiority of the learned graph structures with user studies.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "yan|learning_contextualized_knowledge_graph_structures_for_commonsense_reasoning", "supplementary_material": "/attachment/1e47d3b68eab190164d91f4948ebb222edd215c0.zip", "pdf": "/pdf/3f662940cb9772aec838615078bbb78e81459b18.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=3-26L3usav", "_bibtex": "@misc{\nyan2021learning,\ntitle={Learning Contextualized Knowledge Graph Structures for Commonsense Reasoning},\nauthor={Jun Yan and Mrigank Raman and Tianyu Zhang and Ryan Rossi and Handong Zhao and Sungchul Kim and Nedim Lipka and Xiang Ren},\nyear={2021},\nurl={https://openreview.net/forum?id=lJuOUWlAC8i}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "lJuOUWlAC8i", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper2935/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper2935/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper2935/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper2935/Authors|ICLR.cc/2021/Conference/Paper2935/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2935/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923842938, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper2935/-/Official_Comment"}}}, {"id": "VPqWeqgASAp", "original": null, "number": 16, "cdate": 1606181653627, "ddate": null, "tcdate": 1606181653627, "tmdate": 1606181653627, "tddate": null, "forum": "lJuOUWlAC8i", "replyto": "kJxGp7rAsTW", "invitation": "ICLR.cc/2021/Conference/Paper2935/-/Official_Comment", "content": {"title": "Response to Q2", "comment": ">Q2: I agree with you regarding the reporting bias wrt common-sense concepts in text. However, the LMs that you are using to generate facts have only been trained on a lot of text, so I am not sure, how generating text from pre-trained LMs helps you overcome that. The experiment you suggested makes sense. I would also try to retrieve text containing entities conditioned on the context and generate text features (using LMs) rather than generating text from LMs and featurizing them.\n\nSorry for the confusion. The GPT2 model is pretrained on large corpora and then **finetuned on ConceptNet facts in the prompt-generation format** (described in \u00a7C in the original version). The finetuning process makes it no longer a general-purpose language model. The finetuned GPT2 can generalize ConceptNet facts to more novel commonsense facts because it can leverage the rich semantic and relational knowledge learned during pretraining and fineuning. As an intuitive example, a pretrained language model will assign a higher probability to \u201cbook is located in house\u201d (corresponding to the correct fact (book, AtLocation, house)) than \u201cbook is a house\u201d (corresponding to the wrong fact (book, IsA, house)). The knowledge it captures during finetuning is very helpful for the commonsense KG completion task.\n\nFor the experiments on retrieving facts from OPIEC instead of generating facts using GPT2, we name it as \u201cHGN (w OPIEC)\u201d. Given a pair of concepts that are non-adjacent in ConceptNet, we want to retrieve all triples describing their relations from OPIEC based on string matching. If there's no such triple, then these two concepts won't be connected in the contextualized knowledge graph. If there's at least one matching triple, then we convert each triple into a natural language sentence and adopt a BERT-base model (which has the same hidden dimension as GPT2 that enables a fair comparison) to encode the concatenation of all the sentences, which will be used as the edge feature. The results are shown in New_Table 4, suggesting that generated facts are more helpful than retrieved facts. Generated facts are more likely to fill the knowledge gap for reasoning than retrieved facts because they don\u2019t have the coverage issue as the retrieved facts.\n\n| **CommonsenseQA**\t| RoBERTa     | | OpenbookQA| RoBERTa       |\n|:-------------------|:-------------:|-|:-------------|:---------------:| \n| **HGN (w OPIEC)**\t| 71.35(\u00b10.21)| |    \t**HGN (w OPIEC)**\t| 67.95(\u00b11.23) | \n| **HGN**\t\t| **72.88(\u00b10.83)**|| \t**HGN**\t| **69.00(\u00b10.95)**  |\n\n**New_Table 4. Comparison between our model with a variant using retrieved facts from OPIEC.**\n\nThank you for suggesting the context-aware retrieval approach. We agree that it\u2019s a great direction to explore. While this approach is trying to get more contextualized facts at the graph initialization stage, our work is more focused on how to jointly denoise the collected facts at the graph reasoning stage. As it\u2019s non-trivial to retrieve contextualized **atomic relational knowledge** given two concepts and their context, we will leave it as future work."}, "signatures": ["ICLR.cc/2021/Conference/Paper2935/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2935/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Learning Contextualized Knowledge Graph Structures for Commonsense Reasoning", "authorids": ["~Jun_Yan5", "mt1170736@iitd.ac.in", "zhang-ty17@mails.tsinghua.edu.cn", "~Ryan_Rossi1", "~Handong_Zhao3", "sukim@adobe.com", "lipka@adobe.com", "~Xiang_Ren1"], "authors": ["Jun Yan", "Mrigank Raman", "Tianyu Zhang", "Ryan Rossi", "Handong Zhao", "Sungchul Kim", "Nedim Lipka", "Xiang Ren"], "keywords": [], "abstract": "Recently, neural-symbolic architectures have achieved success on commonsense reasoning through effectively encoding relational structures retrieved from external knowledge graphs (KGs) and obtained state-of-the-art results in tasks such as (commonsense) question answering and natural language inference. However, current neural-symbolic reasoning methods rely on quality and contextualized knowledge structures (i.e., fact triples) that can be retrieved at the pre-processing stage and overlook challenges such as dealing with incompleteness of a KG (low coverage), limited expressiveness of its relations, and irrelevant retrieved facts in the reasoning context. \nIn this paper, we present a novel neural-symbolic approach, named Hybrid Graph Network (HGN), which jointly generates feature representations for new triples (as complement to the existing edges in the KG), determines relevance of the triples to the reasoning context, and learns graph model parameters for encoding the relational information. Our method learns a compact graph structure (comprising both retrieved and generated edges) through filtering edges that are unhelpful to the reasoning process. We show marked improvements on three commonsense reasoning benchmarks and demonstrate the superiority of the learned graph structures with user studies.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "yan|learning_contextualized_knowledge_graph_structures_for_commonsense_reasoning", "supplementary_material": "/attachment/1e47d3b68eab190164d91f4948ebb222edd215c0.zip", "pdf": "/pdf/3f662940cb9772aec838615078bbb78e81459b18.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=3-26L3usav", "_bibtex": "@misc{\nyan2021learning,\ntitle={Learning Contextualized Knowledge Graph Structures for Commonsense Reasoning},\nauthor={Jun Yan and Mrigank Raman and Tianyu Zhang and Ryan Rossi and Handong Zhao and Sungchul Kim and Nedim Lipka and Xiang Ren},\nyear={2021},\nurl={https://openreview.net/forum?id=lJuOUWlAC8i}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "lJuOUWlAC8i", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper2935/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper2935/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper2935/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper2935/Authors|ICLR.cc/2021/Conference/Paper2935/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2935/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923842938, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper2935/-/Official_Comment"}}}, {"id": "1p6wG2vjvv", "original": null, "number": 15, "cdate": 1606181016932, "ddate": null, "tcdate": 1606181016932, "tmdate": 1606181016932, "tddate": null, "forum": "lJuOUWlAC8i", "replyto": "kJxGp7rAsTW", "invitation": "ICLR.cc/2021/Conference/Paper2935/-/Official_Comment", "content": {"title": "Response to Q1", "comment": ">Q1: An entity pair can have multiple relations between them. For example, two entities can be spouse, and friends, and co-workers. It is unclear to me, just giving [h and t] as a prompt to GPT2, would generate all possible relations between them. I think, ideally, you would need to give more context than the name of the entities. I am also still not clear how learning graph structure jointly will help mitigate cases when GPT2 would generate wrong facts.\n\nThanks for your question. We want to highlight that the characteristics of ConceptNet are very different from conventional KGs like DBPedia. For nodes, while DBPedia focuses on named entities, ConceptNet \u201cputs more emphasis on collecting information about common words than about named entities\u201d (Speer and Havasi, 2013). For edges, while DBPedia contains thousands of relations, ConceptNet only defines 34 **basic** relations which are listed in https://github.com/commonsense/conceptnet5/wiki/Relations. These predefined basic relations are mostly exclusive. In ConceptNet, 95.3% of all concept pairs only have one relation between them, which means we can approximately define the relation prediction (KG completion) task as a single-label classification task. Therefore, even if there could be multiple relations between an entity pair, most of them will not be captured in ConceptNet. Relations like \u201cspouse\u201d, \u201cfriend\u201d, \u201cco-worker\u201d are too specific. They are captured by DBPedia but not by ConceptNet. We choose ConceptNet as our knowledge source because we want to incorporate commonsense knowledge about concepts (e.g. (book, AtLocation, house)) rather than world knowledge about named entities (e.g. (Apple, /business/company/founders, Steve Jobs)).\n\nThe role of the edge feature generator is to do the KG completion task where we want to predict **one relation out of 34 predefined ConceptNet relations** given a pair of concepts. In other words, given [h, t] as a prompt, the GPT2 model is only asked to generate one sentence in the form of [h, r, t] that describes the possible ConceptNet relation between them. This is like doing on-the-fly KG completion to incorporate missing edges when we construct the contextualized KG. Note that although r is predicted in a generative way, it will still be one of 34 ConceptNet relations, because **GPT2 is finetuned on ConceptNet facts** and can be easily fitted to only predict ConceptNet relations. This module is not designed to be context-aware for two reasons:\n\n- Commonsense knowledge itself is independent of any context. For example, (book, AtLocation, house) is a commonsense fact just because it holds true in most cases in people\u2019s lives. Though being uncontextualized, it \u201clays a critical foundation without which more nuanced interpretation cannot exist\u201d (Liu and Singh, 2004). What should be contextualized is the incorporation of certain commonsense facts --- that\u2019s why we do pruning after collecting the facts by determining whether they are helpful for reasoning. \n\n- It\u2019s hard to get training data that has both the commonsense fact and the context that needs this fact.\n\nGPT2 is a plug-in module. We don\u2019t change it after it has been finetuned on ConceptNet facts. We just use it to generate facts between concept pairs of interests. The generated facts correspond to edges in the contextualized KG. They can be clean or noisy, helpful or unhelpful. We jointly learn the edge weights (graph structure) with the reasoning parameters, so that the edges will be reweighted according to their helpfulness for reasoning. Figure 6 in the paper gives an example. We should have a contextualized KG with fully-connected edges between question and answer concepts after graph initialization (\u00a73.1). By using our joint learning approach, wrong facts and unhelpful facts (41 out of all 48 extracted and generated facts) are softly removed.\n\n---\nReference:\n- Speer and Havasi, 2013: ConceptNet 5: A Large Semantic Network for Relational Knowledge\n- Liu and Singh, 2004: ConceptNet\u2014a practical commonsense reasoning tool-kit"}, "signatures": ["ICLR.cc/2021/Conference/Paper2935/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2935/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Learning Contextualized Knowledge Graph Structures for Commonsense Reasoning", "authorids": ["~Jun_Yan5", "mt1170736@iitd.ac.in", "zhang-ty17@mails.tsinghua.edu.cn", "~Ryan_Rossi1", "~Handong_Zhao3", "sukim@adobe.com", "lipka@adobe.com", "~Xiang_Ren1"], "authors": ["Jun Yan", "Mrigank Raman", "Tianyu Zhang", "Ryan Rossi", "Handong Zhao", "Sungchul Kim", "Nedim Lipka", "Xiang Ren"], "keywords": [], "abstract": "Recently, neural-symbolic architectures have achieved success on commonsense reasoning through effectively encoding relational structures retrieved from external knowledge graphs (KGs) and obtained state-of-the-art results in tasks such as (commonsense) question answering and natural language inference. However, current neural-symbolic reasoning methods rely on quality and contextualized knowledge structures (i.e., fact triples) that can be retrieved at the pre-processing stage and overlook challenges such as dealing with incompleteness of a KG (low coverage), limited expressiveness of its relations, and irrelevant retrieved facts in the reasoning context. \nIn this paper, we present a novel neural-symbolic approach, named Hybrid Graph Network (HGN), which jointly generates feature representations for new triples (as complement to the existing edges in the KG), determines relevance of the triples to the reasoning context, and learns graph model parameters for encoding the relational information. Our method learns a compact graph structure (comprising both retrieved and generated edges) through filtering edges that are unhelpful to the reasoning process. We show marked improvements on three commonsense reasoning benchmarks and demonstrate the superiority of the learned graph structures with user studies.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "yan|learning_contextualized_knowledge_graph_structures_for_commonsense_reasoning", "supplementary_material": "/attachment/1e47d3b68eab190164d91f4948ebb222edd215c0.zip", "pdf": "/pdf/3f662940cb9772aec838615078bbb78e81459b18.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=3-26L3usav", "_bibtex": "@misc{\nyan2021learning,\ntitle={Learning Contextualized Knowledge Graph Structures for Commonsense Reasoning},\nauthor={Jun Yan and Mrigank Raman and Tianyu Zhang and Ryan Rossi and Handong Zhao and Sungchul Kim and Nedim Lipka and Xiang Ren},\nyear={2021},\nurl={https://openreview.net/forum?id=lJuOUWlAC8i}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "lJuOUWlAC8i", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper2935/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper2935/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper2935/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper2935/Authors|ICLR.cc/2021/Conference/Paper2935/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2935/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923842938, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper2935/-/Official_Comment"}}}, {"id": "kJxGp7rAsTW", "original": null, "number": 13, "cdate": 1606098332184, "ddate": null, "tcdate": 1606098332184, "tmdate": 1606098332184, "tddate": null, "forum": "lJuOUWlAC8i", "replyto": "26h38yh3hAK", "invitation": "ICLR.cc/2021/Conference/Paper2935/-/Official_Comment", "content": {"title": "Response", "comment": "Thank you for the detailed response to my review.\n\nQ1: An entity pair can have multiple relations between them. For example, two entities can be spouse, and friends, and co-workers. It is unclear to me, just giving [h and t] as a prompt to GPT2, would generate all possible relations between them. I think, ideally, you would need to give more context than the name of the entities. I am also still not clear how learning graph structure jointly will help mitigate cases when GPT2 would generate wrong facts. \n\nQ2: I agree with you regarding the reporting bias wrt common-sense concepts in text. However, the LMs that you are using to generate facts have only been trained on a lot of text, so I am not sure, how generating text from pre-trained LMs helps you overcome that. The experiment you suggested makes sense. I would also try to retrieve text containing entities conditioned on the context and generate text features (using LMs) rather than generating text from LMs and featurizing them. \n"}, "signatures": ["ICLR.cc/2021/Conference/Paper2935/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2935/AnonReviewer3"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Learning Contextualized Knowledge Graph Structures for Commonsense Reasoning", "authorids": ["~Jun_Yan5", "mt1170736@iitd.ac.in", "zhang-ty17@mails.tsinghua.edu.cn", "~Ryan_Rossi1", "~Handong_Zhao3", "sukim@adobe.com", "lipka@adobe.com", "~Xiang_Ren1"], "authors": ["Jun Yan", "Mrigank Raman", "Tianyu Zhang", "Ryan Rossi", "Handong Zhao", "Sungchul Kim", "Nedim Lipka", "Xiang Ren"], "keywords": [], "abstract": "Recently, neural-symbolic architectures have achieved success on commonsense reasoning through effectively encoding relational structures retrieved from external knowledge graphs (KGs) and obtained state-of-the-art results in tasks such as (commonsense) question answering and natural language inference. However, current neural-symbolic reasoning methods rely on quality and contextualized knowledge structures (i.e., fact triples) that can be retrieved at the pre-processing stage and overlook challenges such as dealing with incompleteness of a KG (low coverage), limited expressiveness of its relations, and irrelevant retrieved facts in the reasoning context. \nIn this paper, we present a novel neural-symbolic approach, named Hybrid Graph Network (HGN), which jointly generates feature representations for new triples (as complement to the existing edges in the KG), determines relevance of the triples to the reasoning context, and learns graph model parameters for encoding the relational information. Our method learns a compact graph structure (comprising both retrieved and generated edges) through filtering edges that are unhelpful to the reasoning process. We show marked improvements on three commonsense reasoning benchmarks and demonstrate the superiority of the learned graph structures with user studies.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "yan|learning_contextualized_knowledge_graph_structures_for_commonsense_reasoning", "supplementary_material": "/attachment/1e47d3b68eab190164d91f4948ebb222edd215c0.zip", "pdf": "/pdf/3f662940cb9772aec838615078bbb78e81459b18.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=3-26L3usav", "_bibtex": "@misc{\nyan2021learning,\ntitle={Learning Contextualized Knowledge Graph Structures for Commonsense Reasoning},\nauthor={Jun Yan and Mrigank Raman and Tianyu Zhang and Ryan Rossi and Handong Zhao and Sungchul Kim and Nedim Lipka and Xiang Ren},\nyear={2021},\nurl={https://openreview.net/forum?id=lJuOUWlAC8i}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "lJuOUWlAC8i", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper2935/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper2935/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper2935/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper2935/Authors|ICLR.cc/2021/Conference/Paper2935/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2935/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923842938, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper2935/-/Official_Comment"}}}, {"id": "JzSfOkUXAkc", "original": null, "number": 3, "cdate": 1604023805175, "ddate": null, "tcdate": 1604023805175, "tmdate": 1605024101383, "tddate": null, "forum": "lJuOUWlAC8i", "replyto": "lJuOUWlAC8i", "invitation": "ICLR.cc/2021/Conference/Paper2935/-/Official_Review", "content": {"title": "Novelty of the proposed model is limited", "review": "The paper proposes a graph network (called HGN), aiming to better leverage commonsense knowledge graphs (KGs) to solve commonsense question answering and reasoning tasks, by jointly generating representations for new triples from KGs, determining relevance of the triples, and learning graph model parameters. The proposed model is tested on several tasks: CommonsenseQA, OpenbookQA, and CODAH.\n\nPros:\n-  Overall, the paper is easy to follow, although there are a number of typos or grammatical errors that need to be fixed.  The overall idea is clear.\n-  Jointly learning (pruning) the graph structure with the network parameters is interesting.\n-  The proposed model outperforms the baselines in comparison.\n-  Human evaluation is provided.\n\nCons:\n-  My major concern about this paper is the novelty and contributions in terms of methodology. Compared to existing methods (e.g., those PG models proposed (Wang et al. 2020)), the novelty of the current submission is rather limited---the proposed model of jointly generating new triples and learning (pruning) the graph structure with the network parameters is an interesting, but a pretty incremental idea. \n\n-  The empirical comparison to previous work (e.g., Wang et al. 2020) needs to be clearer to help understand the empirical advantages of the proposed models. The paper mentioned some reason of excluding PG-Full from comparison, but since PG-Global does not include static knowledge embedding and PG-full does, is the latter a more reasonable baseline to be compared with? The model does not achieve better performance than existing models on some tasks, which casts doubts on its effectiveness; e.g., whether its advantage is orthogonal to that brought by stronger models such as those performing much better on the OpenbookQA task.\n\nMore comments:\n-  The paper uses much space to discuss neural symbolic approaches. Given the vague benefit of doing so, it may be better to use the limited space to focus more on establishing the contributions w.r.t. existing models; e.g., more details about (Wang et al., 2020) can be provided and compared to in both methodological and experimental analyses.\n- The human evaluation was performed on the questions with correct questions. More analyses on the edges and weights generated for questions that were not correctly answers may help better understand the proposed model. \n", "rating": "5: Marginally below acceptance threshold", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "signatures": ["ICLR.cc/2021/Conference/Paper2935/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2935/AnonReviewer2"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Learning Contextualized Knowledge Graph Structures for Commonsense Reasoning", "authorids": ["~Jun_Yan5", "mt1170736@iitd.ac.in", "zhang-ty17@mails.tsinghua.edu.cn", "~Ryan_Rossi1", "~Handong_Zhao3", "sukim@adobe.com", "lipka@adobe.com", "~Xiang_Ren1"], "authors": ["Jun Yan", "Mrigank Raman", "Tianyu Zhang", "Ryan Rossi", "Handong Zhao", "Sungchul Kim", "Nedim Lipka", "Xiang Ren"], "keywords": [], "abstract": "Recently, neural-symbolic architectures have achieved success on commonsense reasoning through effectively encoding relational structures retrieved from external knowledge graphs (KGs) and obtained state-of-the-art results in tasks such as (commonsense) question answering and natural language inference. However, current neural-symbolic reasoning methods rely on quality and contextualized knowledge structures (i.e., fact triples) that can be retrieved at the pre-processing stage and overlook challenges such as dealing with incompleteness of a KG (low coverage), limited expressiveness of its relations, and irrelevant retrieved facts in the reasoning context. \nIn this paper, we present a novel neural-symbolic approach, named Hybrid Graph Network (HGN), which jointly generates feature representations for new triples (as complement to the existing edges in the KG), determines relevance of the triples to the reasoning context, and learns graph model parameters for encoding the relational information. Our method learns a compact graph structure (comprising both retrieved and generated edges) through filtering edges that are unhelpful to the reasoning process. We show marked improvements on three commonsense reasoning benchmarks and demonstrate the superiority of the learned graph structures with user studies.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "yan|learning_contextualized_knowledge_graph_structures_for_commonsense_reasoning", "supplementary_material": "/attachment/1e47d3b68eab190164d91f4948ebb222edd215c0.zip", "pdf": "/pdf/3f662940cb9772aec838615078bbb78e81459b18.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=3-26L3usav", "_bibtex": "@misc{\nyan2021learning,\ntitle={Learning Contextualized Knowledge Graph Structures for Commonsense Reasoning},\nauthor={Jun Yan and Mrigank Raman and Tianyu Zhang and Ryan Rossi and Handong Zhao and Sungchul Kim and Nedim Lipka and Xiang Ren},\nyear={2021},\nurl={https://openreview.net/forum?id=lJuOUWlAC8i}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq . ***Please remember to file the Code-of-Ethics report. Once you submitted the review, a link to the report will be visible in the bottom right corner of your review.***", "required": true, "markdown": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}, "forum": "lJuOUWlAC8i", "replyto": "lJuOUWlAC8i", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"], "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper2935/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1607428800000, "duedate": 1606752000000, "multiReply": false, "readers": ["everyone"], "tcdate": 1602538085711, "tmdate": 1606915759756, "super": "ICLR.cc/2021/Conference/-/Official_Review", "signatures": ["OpenReview.net"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Paper2935/Reviewers", "OpenReview.net/Support"], "id": "ICLR.cc/2021/Conference/Paper2935/-/Official_Review"}}}], "count": 20}