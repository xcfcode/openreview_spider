{"notes": [{"tddate": null, "ddate": null, "cdate": null, "tmdate": 1486396371618, "tcdate": 1486396371618, "number": 1, "id": "SknRsfUue", "invitation": "ICLR.cc/2017/conference/-/paper125/acceptance", "forum": "S1xh5sYgx", "replyto": "S1xh5sYgx", "signatures": ["ICLR.cc/2017/pcs"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/pcs"], "content": {"decision": "Reject", "title": "ICLR committee final decision", "comment": "The paper proposes a ConvNet architecture (\"SqueezeNet\") and a building block (\"Fire module\") aimed at reducing the model size while maintaining the AlexNet level of accuracy. The novelty of the submission is very limited as very similar design choices have already been used for model complexity reduction in Inception and ResNet. Because of this, we recommend rejection and invite the authors to further develop their method."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "SqueezeNet: AlexNet-level accuracy with 50x fewer parameters and <0.5MB model size", "abstract": "Recent research on deep neural networks has focused primarily on improving accuracy. For a given accuracy level, it is typically possible to identify multiple DNN architectures that achieve that accuracy level. With equivalent accuracy, smaller DNN architectures offer at least three advantages: (1) Smaller DNNs require less communication across servers during distributed training. (2) Smaller DNNs require less bandwidth to export a new model from the cloud to an autonomous car. (3) Smaller DNNs are more feasible to deploy on FPGAs and other hardware with limited memory. To provide all of these advantages, we propose a small DNN architecture called SqueezeNet. SqueezeNet achieves AlexNet-level accuracy on ImageNet with 50x fewer parameters. Additionally, with model compression techniques we are able to compress SqueezeNet to less than 0.5MB (510x smaller than AlexNet).", "pdf": "/pdf/6b649f83c76024a3120850a3f9e78d1560ad6fcd.pdf", "TL;DR": "Small CNN models", "paperhash": "iandola|squeezenet_alexnetlevel_accuracy_with_50x_fewer_parameters_and_05mb_model_size", "conflicts": ["stanford.edu", "berkeley.edu", "deepscale.ai"], "keywords": ["Computer vision", "Deep learning"], "authors": ["Forrest N. Iandola", "Song Han", "Matthew W. Moskewicz", "Khalid Ashraf", "William J. Dally", "Kurt Keutzer"], "authorids": ["forresti@eecs.berkeley.edu", "songhan@stanford.edu", "moskewcz@eecs.berkeley.edu", "kashraf@eecs.berkeley.edu", "dally@stanford.edu", "keutzer@eecs.berkeley.edu"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1486396372165, "id": "ICLR.cc/2017/conference/-/paper125/acceptance", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/pcs"], "noninvitees": ["ICLR.cc/2017/pcs"], "reply": {"forum": "S1xh5sYgx", "replyto": "S1xh5sYgx", "writers": {"values-regex": "ICLR.cc/2017/pcs"}, "signatures": {"values-regex": "ICLR.cc/2017/pcs", "description": "Your displayed identity associated with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your decision.", "value": "ICLR committee final decision"}, "comment": {"required": true, "order": 2, "description": "Decision comments.", "value-regex": "[\\S\\s]{1,5000}"}, "decision": {"required": true, "order": 3, "value-radio": ["Accept (Oral)", "Accept (Poster)", "Reject", "Invite to Workshop Track"]}}}, "nonreaders": [], "cdate": 1486396372165}}}, {"tddate": null, "tmdate": 1484876815176, "tcdate": 1481767079160, "number": 2, "id": "Byk2d_y4x", "invitation": "ICLR.cc/2017/conference/-/paper125/official/review", "forum": "S1xh5sYgx", "replyto": "S1xh5sYgx", "signatures": ["ICLR.cc/2017/conference/paper125/AnonReviewer1"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/conference/paper125/AnonReviewer1"], "content": {"title": "Are fire modules an application of concepts from GoogLeNet and ResNet?", "rating": "7: Good paper, accept", "review": "Summary: The paper presents a smaller CNN architecture called SqueezeNet for embedded deployment. The paper explores CNN macroarchitecture and microarchitecture to develop SqueezeNet, which is composed of fire modules.\n\nPros: \nAchieves x50 less memory usage than AlexNet while keeping similar accuracy.\n\nCons & Questions:\nComplex by-pass has less accuracy than simple by-pass. And simple by-pass is like ResNet bottlenecks and complex by-pass is like inception modules in GoogLeNet. Can we say that these two valiants of SqueezeNet are adaptation of concepts seen in GoogLeNet and ResNet? If so, then shouldn\u2019t be there a SqueezeNet like model that achieves similar accuracy compared with GoogLeNet and ResNet?\n", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "SqueezeNet: AlexNet-level accuracy with 50x fewer parameters and <0.5MB model size", "abstract": "Recent research on deep neural networks has focused primarily on improving accuracy. For a given accuracy level, it is typically possible to identify multiple DNN architectures that achieve that accuracy level. With equivalent accuracy, smaller DNN architectures offer at least three advantages: (1) Smaller DNNs require less communication across servers during distributed training. (2) Smaller DNNs require less bandwidth to export a new model from the cloud to an autonomous car. (3) Smaller DNNs are more feasible to deploy on FPGAs and other hardware with limited memory. To provide all of these advantages, we propose a small DNN architecture called SqueezeNet. SqueezeNet achieves AlexNet-level accuracy on ImageNet with 50x fewer parameters. Additionally, with model compression techniques we are able to compress SqueezeNet to less than 0.5MB (510x smaller than AlexNet).", "pdf": "/pdf/6b649f83c76024a3120850a3f9e78d1560ad6fcd.pdf", "TL;DR": "Small CNN models", "paperhash": "iandola|squeezenet_alexnetlevel_accuracy_with_50x_fewer_parameters_and_05mb_model_size", "conflicts": ["stanford.edu", "berkeley.edu", "deepscale.ai"], "keywords": ["Computer vision", "Deep learning"], "authors": ["Forrest N. Iandola", "Song Han", "Matthew W. Moskewicz", "Khalid Ashraf", "William J. Dally", "Kurt Keutzer"], "authorids": ["forresti@eecs.berkeley.edu", "songhan@stanford.edu", "moskewcz@eecs.berkeley.edu", "kashraf@eecs.berkeley.edu", "dally@stanford.edu", "keutzer@eecs.berkeley.edu"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1481932799000, "tmdate": 1482537865067, "id": "ICLR.cc/2017/conference/-/paper125/official/review", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/conference/paper125/reviewers"], "noninvitees": ["ICLR.cc/2017/conference/paper125/AnonReviewer2", "ICLR.cc/2017/conference/paper125/AnonReviewer1", "ICLR.cc/2017/conference/paper125/AnonReviewer3"], "reply": {"forum": "S1xh5sYgx", "replyto": "S1xh5sYgx", "writers": {"values-regex": "ICLR.cc/2017/conference/paper125/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/conference/paper125/AnonReviewer[0-9]+"}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "value-regex": "[\\S\\s]{1,20000}"}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1489708799000, "cdate": 1482537865067}}}, {"tddate": null, "tmdate": 1482962727736, "tcdate": 1482961579749, "number": 6, "id": "HyVnMnZSl", "invitation": "ICLR.cc/2017/conference/-/paper125/public/comment", "forum": "S1xh5sYgx", "replyto": "ryx9sViEg", "signatures": ["~Forrest_Iandola1"], "readers": ["everyone"], "writers": ["~Forrest_Iandola1"], "content": {"title": "SqueezeNet on other tasks", "comment": "Thank you for your feedback and encouragement. Let me take a moment to discuss the weaknesses/questions that you mentioned.\n\n1. SqueezeNet on other tasks.\nWe recently added a detection layer at the end of SqueezeNet and fine-tuned it on KITTI object detection. We identified a variant of SqueezeNet that is simultaneously the fastest, smallest, and most accurate (in terms of mean-average precision) model on the KITTI detection task, compared to previous reported results. We will be posting this to the KITTI leaderboard soon, but meanwhile we have released some details in this paper:\nhttps://arxiv.org/abs/1612.01051\n\n2. Theoretical analysis.\nWe certainly appreciate the theoretical aspects of deep neural network research. If you ask a more specific question, we will do our best to answer it.\n\n3. Placing SqueezeNet in the context of GoogLeNet and ResNet.\nTake a look at our response to the earlier comment thread, \"SqueezeNet versus other models than AlexNet.\"\n\n\n"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "SqueezeNet: AlexNet-level accuracy with 50x fewer parameters and <0.5MB model size", "abstract": "Recent research on deep neural networks has focused primarily on improving accuracy. For a given accuracy level, it is typically possible to identify multiple DNN architectures that achieve that accuracy level. With equivalent accuracy, smaller DNN architectures offer at least three advantages: (1) Smaller DNNs require less communication across servers during distributed training. (2) Smaller DNNs require less bandwidth to export a new model from the cloud to an autonomous car. (3) Smaller DNNs are more feasible to deploy on FPGAs and other hardware with limited memory. To provide all of these advantages, we propose a small DNN architecture called SqueezeNet. SqueezeNet achieves AlexNet-level accuracy on ImageNet with 50x fewer parameters. Additionally, with model compression techniques we are able to compress SqueezeNet to less than 0.5MB (510x smaller than AlexNet).", "pdf": "/pdf/6b649f83c76024a3120850a3f9e78d1560ad6fcd.pdf", "TL;DR": "Small CNN models", "paperhash": "iandola|squeezenet_alexnetlevel_accuracy_with_50x_fewer_parameters_and_05mb_model_size", "conflicts": ["stanford.edu", "berkeley.edu", "deepscale.ai"], "keywords": ["Computer vision", "Deep learning"], "authors": ["Forrest N. Iandola", "Song Han", "Matthew W. Moskewicz", "Khalid Ashraf", "William J. Dally", "Kurt Keutzer"], "authorids": ["forresti@eecs.berkeley.edu", "songhan@stanford.edu", "moskewcz@eecs.berkeley.edu", "kashraf@eecs.berkeley.edu", "dally@stanford.edu", "keutzer@eecs.berkeley.edu"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287717339, "id": "ICLR.cc/2017/conference/-/paper125/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "S1xh5sYgx", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper125/reviewers", "ICLR.cc/2017/conference/paper125/areachairs"], "cdate": 1485287717339}}}, {"tddate": null, "tmdate": 1482537864432, "tcdate": 1482537864432, "number": 3, "id": "ryx9sViEg", "invitation": "ICLR.cc/2017/conference/-/paper125/official/review", "forum": "S1xh5sYgx", "replyto": "S1xh5sYgx", "signatures": ["ICLR.cc/2017/conference/paper125/AnonReviewer3"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/conference/paper125/AnonReviewer3"], "content": {"title": "excellent empirical work with potential impact, but the impact would be greater if insights and analysis can be provided by reading back earlier work aimed to analyse the \u201cby-pass\u201d architecture by mixing linear and nonlinear predictions similar to the proposed architecture ", "rating": "5: Marginally below acceptance threshold", "review": "Strengths\n\uf06e-- An interesting proposal for a smaller CNN architecture designed for embedded CNN applications. \n\uf06e-- Balanced exploration of CNN macroarchitecture and microarchitecture with fire modules.\n\uf06e-- x50 less memory usage than AlexNet, keeping similar accuracy \n\uf06e-- strong experimental results\n\nWeaknesses\n\uf06e--Would be nice to test Sqeezenet on multiple tasks\n\n\uf06e--lack of insights and rigorous analysis into what factors are responsible for the success of SqueezeNet. For example, how are ResNet and GoogleNet connected to the current architecture? Another old paper (Analysis of correlation structure for a neural predictive model with application to speech recognition, Neural Networks, 1994) also showed that the \u201cby-pass\u201d architecture by mixing linear and nonlinear prediction terms improves long term dependency in NN based on rigorous perturbation analysis. Can the current work be placed more rigorously on theoretical analysis?\n", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "SqueezeNet: AlexNet-level accuracy with 50x fewer parameters and <0.5MB model size", "abstract": "Recent research on deep neural networks has focused primarily on improving accuracy. For a given accuracy level, it is typically possible to identify multiple DNN architectures that achieve that accuracy level. With equivalent accuracy, smaller DNN architectures offer at least three advantages: (1) Smaller DNNs require less communication across servers during distributed training. (2) Smaller DNNs require less bandwidth to export a new model from the cloud to an autonomous car. (3) Smaller DNNs are more feasible to deploy on FPGAs and other hardware with limited memory. To provide all of these advantages, we propose a small DNN architecture called SqueezeNet. SqueezeNet achieves AlexNet-level accuracy on ImageNet with 50x fewer parameters. Additionally, with model compression techniques we are able to compress SqueezeNet to less than 0.5MB (510x smaller than AlexNet).", "pdf": "/pdf/6b649f83c76024a3120850a3f9e78d1560ad6fcd.pdf", "TL;DR": "Small CNN models", "paperhash": "iandola|squeezenet_alexnetlevel_accuracy_with_50x_fewer_parameters_and_05mb_model_size", "conflicts": ["stanford.edu", "berkeley.edu", "deepscale.ai"], "keywords": ["Computer vision", "Deep learning"], "authors": ["Forrest N. Iandola", "Song Han", "Matthew W. Moskewicz", "Khalid Ashraf", "William J. Dally", "Kurt Keutzer"], "authorids": ["forresti@eecs.berkeley.edu", "songhan@stanford.edu", "moskewcz@eecs.berkeley.edu", "kashraf@eecs.berkeley.edu", "dally@stanford.edu", "keutzer@eecs.berkeley.edu"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1481932799000, "tmdate": 1482537865067, "id": "ICLR.cc/2017/conference/-/paper125/official/review", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/conference/paper125/reviewers"], "noninvitees": ["ICLR.cc/2017/conference/paper125/AnonReviewer2", "ICLR.cc/2017/conference/paper125/AnonReviewer1", "ICLR.cc/2017/conference/paper125/AnonReviewer3"], "reply": {"forum": "S1xh5sYgx", "replyto": "S1xh5sYgx", "writers": {"values-regex": "ICLR.cc/2017/conference/paper125/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/conference/paper125/AnonReviewer[0-9]+"}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "value-regex": "[\\S\\s]{1,20000}"}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1489708799000, "cdate": 1482537865067}}}, {"tddate": null, "tmdate": 1482114059094, "tcdate": 1482114059094, "number": 5, "id": "r1mz4TVVg", "invitation": "ICLR.cc/2017/conference/-/paper125/public/comment", "forum": "S1xh5sYgx", "replyto": "H1BSKEJEg", "signatures": ["~Forrest_Iandola1"], "readers": ["everyone"], "writers": ["~Forrest_Iandola1"], "content": {"title": "Thanks!", "comment": "Thanks for the encouraging and positive feedback. "}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "SqueezeNet: AlexNet-level accuracy with 50x fewer parameters and <0.5MB model size", "abstract": "Recent research on deep neural networks has focused primarily on improving accuracy. For a given accuracy level, it is typically possible to identify multiple DNN architectures that achieve that accuracy level. With equivalent accuracy, smaller DNN architectures offer at least three advantages: (1) Smaller DNNs require less communication across servers during distributed training. (2) Smaller DNNs require less bandwidth to export a new model from the cloud to an autonomous car. (3) Smaller DNNs are more feasible to deploy on FPGAs and other hardware with limited memory. To provide all of these advantages, we propose a small DNN architecture called SqueezeNet. SqueezeNet achieves AlexNet-level accuracy on ImageNet with 50x fewer parameters. Additionally, with model compression techniques we are able to compress SqueezeNet to less than 0.5MB (510x smaller than AlexNet).", "pdf": "/pdf/6b649f83c76024a3120850a3f9e78d1560ad6fcd.pdf", "TL;DR": "Small CNN models", "paperhash": "iandola|squeezenet_alexnetlevel_accuracy_with_50x_fewer_parameters_and_05mb_model_size", "conflicts": ["stanford.edu", "berkeley.edu", "deepscale.ai"], "keywords": ["Computer vision", "Deep learning"], "authors": ["Forrest N. Iandola", "Song Han", "Matthew W. Moskewicz", "Khalid Ashraf", "William J. Dally", "Kurt Keutzer"], "authorids": ["forresti@eecs.berkeley.edu", "songhan@stanford.edu", "moskewcz@eecs.berkeley.edu", "kashraf@eecs.berkeley.edu", "dally@stanford.edu", "keutzer@eecs.berkeley.edu"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287717339, "id": "ICLR.cc/2017/conference/-/paper125/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "S1xh5sYgx", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper125/reviewers", "ICLR.cc/2017/conference/paper125/areachairs"], "cdate": 1485287717339}}}, {"tddate": null, "tmdate": 1481876779091, "tcdate": 1481876779091, "number": 4, "id": "BJ74HQWNg", "invitation": "ICLR.cc/2017/conference/-/paper125/public/comment", "forum": "S1xh5sYgx", "replyto": "Byk2d_y4x", "signatures": ["~Forrest_Iandola1"], "readers": ["everyone"], "writers": ["~Forrest_Iandola1"], "content": {"title": "See previous comments", "comment": "Good questions. I think we address most of your questions in an earlier comment thread. Search this page for \"SqueezeNet versus other models than AlexNet.\""}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "SqueezeNet: AlexNet-level accuracy with 50x fewer parameters and <0.5MB model size", "abstract": "Recent research on deep neural networks has focused primarily on improving accuracy. For a given accuracy level, it is typically possible to identify multiple DNN architectures that achieve that accuracy level. With equivalent accuracy, smaller DNN architectures offer at least three advantages: (1) Smaller DNNs require less communication across servers during distributed training. (2) Smaller DNNs require less bandwidth to export a new model from the cloud to an autonomous car. (3) Smaller DNNs are more feasible to deploy on FPGAs and other hardware with limited memory. To provide all of these advantages, we propose a small DNN architecture called SqueezeNet. SqueezeNet achieves AlexNet-level accuracy on ImageNet with 50x fewer parameters. Additionally, with model compression techniques we are able to compress SqueezeNet to less than 0.5MB (510x smaller than AlexNet).", "pdf": "/pdf/6b649f83c76024a3120850a3f9e78d1560ad6fcd.pdf", "TL;DR": "Small CNN models", "paperhash": "iandola|squeezenet_alexnetlevel_accuracy_with_50x_fewer_parameters_and_05mb_model_size", "conflicts": ["stanford.edu", "berkeley.edu", "deepscale.ai"], "keywords": ["Computer vision", "Deep learning"], "authors": ["Forrest N. Iandola", "Song Han", "Matthew W. Moskewicz", "Khalid Ashraf", "William J. Dally", "Kurt Keutzer"], "authorids": ["forresti@eecs.berkeley.edu", "songhan@stanford.edu", "moskewcz@eecs.berkeley.edu", "kashraf@eecs.berkeley.edu", "dally@stanford.edu", "keutzer@eecs.berkeley.edu"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287717339, "id": "ICLR.cc/2017/conference/-/paper125/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "S1xh5sYgx", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper125/reviewers", "ICLR.cc/2017/conference/paper125/areachairs"], "cdate": 1485287717339}}}, {"tddate": null, "tmdate": 1481750844582, "tcdate": 1481750844575, "number": 1, "id": "H1BSKEJEg", "invitation": "ICLR.cc/2017/conference/-/paper125/official/review", "forum": "S1xh5sYgx", "replyto": "S1xh5sYgx", "signatures": ["ICLR.cc/2017/conference/paper125/AnonReviewer2"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/conference/paper125/AnonReviewer2"], "content": {"title": "Reasonable convnet engineering paper", "rating": "7: Good paper, accept", "review": "The Squeezenet paper came out in Feb 2016, and I read it with interest. It has a series of completely reasonable engineering suggestions for how to save parameter memory for CNNs for object recognition (imagenet). The suggestions make a lot of sense, and provide an excellent compression of about 50x versus AlexNet. (Looks like ~500x if combined with Han, 2015). So, very nice results, definitely worth publishing.\n\nSince the arxiv paper came out, people have noticed and worked to extend the paper. This is already evidence that this paper will have impact --- and deserves to have a permanent published home.\n\nOn the negative side, the architecture was only tested on ImageNet -- unclear whether the ideas transfer to other tasks (e.g., audio or text recognition). And, as with many other architecture-tweaking papers, there is no real mathematical or theoretical support for the ideas: they are just sensible and empirically work.\n\nOh the whole, I think the paper deserves to appear at ICLR, being in the mainline of work on deep learning architectures.", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "SqueezeNet: AlexNet-level accuracy with 50x fewer parameters and <0.5MB model size", "abstract": "Recent research on deep neural networks has focused primarily on improving accuracy. For a given accuracy level, it is typically possible to identify multiple DNN architectures that achieve that accuracy level. With equivalent accuracy, smaller DNN architectures offer at least three advantages: (1) Smaller DNNs require less communication across servers during distributed training. (2) Smaller DNNs require less bandwidth to export a new model from the cloud to an autonomous car. (3) Smaller DNNs are more feasible to deploy on FPGAs and other hardware with limited memory. To provide all of these advantages, we propose a small DNN architecture called SqueezeNet. SqueezeNet achieves AlexNet-level accuracy on ImageNet with 50x fewer parameters. Additionally, with model compression techniques we are able to compress SqueezeNet to less than 0.5MB (510x smaller than AlexNet).", "pdf": "/pdf/6b649f83c76024a3120850a3f9e78d1560ad6fcd.pdf", "TL;DR": "Small CNN models", "paperhash": "iandola|squeezenet_alexnetlevel_accuracy_with_50x_fewer_parameters_and_05mb_model_size", "conflicts": ["stanford.edu", "berkeley.edu", "deepscale.ai"], "keywords": ["Computer vision", "Deep learning"], "authors": ["Forrest N. Iandola", "Song Han", "Matthew W. Moskewicz", "Khalid Ashraf", "William J. Dally", "Kurt Keutzer"], "authorids": ["forresti@eecs.berkeley.edu", "songhan@stanford.edu", "moskewcz@eecs.berkeley.edu", "kashraf@eecs.berkeley.edu", "dally@stanford.edu", "keutzer@eecs.berkeley.edu"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1481932799000, "tmdate": 1482537865067, "id": "ICLR.cc/2017/conference/-/paper125/official/review", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/conference/paper125/reviewers"], "noninvitees": ["ICLR.cc/2017/conference/paper125/AnonReviewer2", "ICLR.cc/2017/conference/paper125/AnonReviewer1", "ICLR.cc/2017/conference/paper125/AnonReviewer3"], "reply": {"forum": "S1xh5sYgx", "replyto": "S1xh5sYgx", "writers": {"values-regex": "ICLR.cc/2017/conference/paper125/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/conference/paper125/AnonReviewer[0-9]+"}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "value-regex": "[\\S\\s]{1,20000}"}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1489708799000, "cdate": 1482537865067}}}, {"tddate": null, "tmdate": 1480886733751, "tcdate": 1480886733746, "number": 3, "id": "rJUAKWzXe", "invitation": "ICLR.cc/2017/conference/-/paper125/public/comment", "forum": "S1xh5sYgx", "replyto": "Bkt52_jGx", "signatures": ["~Forrest_Iandola1"], "readers": ["everyone"], "writers": ["~Forrest_Iandola1"], "content": {"title": "ZynqNet and memory space for activations", "comment": "First, we are quite enthusiastic about Gschwend's work. In his \"ZynqNet\" technical report, Gschwend says, \"[We used] SqueezeNet as the basis for our own CNN topology, due to its good fit for an FPGA-based implementation. The tiny parameter set could even be fit into the on-chip SRAM of a medium-sized FPGA, and optimizations are relatively easy to try thanks to the fast training cycles and the clear network structure.\" We are glad that Gschwend found value in using SqueezeNet as a starting point for some of his work.\n\nWhen executing a CNN, it is correct that some activations need to be stored. Specifically, it's necessary to allocate enough memory to store the activations of the two contiguous layers with the largest total quantity of activations. In the case of SqueezeNet, the largest activation storage requirement is in {conv1 (3.27MB) + fire2/conv1x1_1 (0.19MB)}, which means we need to allocate 3.46MB of storage for activations. So, for uncompressed SqueezeNet, the activation storage (3.46MB) is a bit smaller than the parameter storage (4.80MB).\n\nA side note -- in total, SqueezeNet produces 11.05MB of activations over all layers combined. Here is a table that includes the quantity of activations in each SqueezeNet layer:\nhttps://docs.google.com/document/d/1X9ENqsU6sMkjj2DVjEJfI16Nu3JPXRVFcu7tqMoVl3o\n\n"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "SqueezeNet: AlexNet-level accuracy with 50x fewer parameters and <0.5MB model size", "abstract": "Recent research on deep neural networks has focused primarily on improving accuracy. For a given accuracy level, it is typically possible to identify multiple DNN architectures that achieve that accuracy level. With equivalent accuracy, smaller DNN architectures offer at least three advantages: (1) Smaller DNNs require less communication across servers during distributed training. (2) Smaller DNNs require less bandwidth to export a new model from the cloud to an autonomous car. (3) Smaller DNNs are more feasible to deploy on FPGAs and other hardware with limited memory. To provide all of these advantages, we propose a small DNN architecture called SqueezeNet. SqueezeNet achieves AlexNet-level accuracy on ImageNet with 50x fewer parameters. Additionally, with model compression techniques we are able to compress SqueezeNet to less than 0.5MB (510x smaller than AlexNet).", "pdf": "/pdf/6b649f83c76024a3120850a3f9e78d1560ad6fcd.pdf", "TL;DR": "Small CNN models", "paperhash": "iandola|squeezenet_alexnetlevel_accuracy_with_50x_fewer_parameters_and_05mb_model_size", "conflicts": ["stanford.edu", "berkeley.edu", "deepscale.ai"], "keywords": ["Computer vision", "Deep learning"], "authors": ["Forrest N. Iandola", "Song Han", "Matthew W. Moskewicz", "Khalid Ashraf", "William J. Dally", "Kurt Keutzer"], "authorids": ["forresti@eecs.berkeley.edu", "songhan@stanford.edu", "moskewcz@eecs.berkeley.edu", "kashraf@eecs.berkeley.edu", "dally@stanford.edu", "keutzer@eecs.berkeley.edu"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287717339, "id": "ICLR.cc/2017/conference/-/paper125/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "S1xh5sYgx", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper125/reviewers", "ICLR.cc/2017/conference/paper125/areachairs"], "cdate": 1485287717339}}}, {"tddate": null, "tmdate": 1480885933994, "tcdate": 1480885933987, "number": 2, "id": "SyU3L-GXx", "invitation": "ICLR.cc/2017/conference/-/paper125/public/comment", "forum": "S1xh5sYgx", "replyto": "HytpAbsMg", "signatures": ["~Forrest_Iandola1"], "readers": ["everyone"], "writers": ["~Forrest_Iandola1"], "content": {"title": "Broader architectural context on SqueezeNet and its variants", "comment": "Let us break this into three questions:\n1. Architecturally, what do SqueezeNet's Fire modules have in common with Inception modules?\nAs in Inception modules, Fire modules have multiple sizes of filters at the same level of depth in the NN. For example, Inception-v1 modules have multiple instances with 1x1, 3x3, and 5x5 filters alongside each other. \nOne of our biggest questions when looking at the Inception paper was \"how does a CNN architect decide how many of each size of filter to have in each module?\" Some versions of the inception modules have 10 or more filter banks (layers?) per module. Doing careful A/B comparisons of \"how many of each type of filter\" would lead to a combinatorial explosion. But, in the Fire modules, we have just 3 filter banks (1x1_1, 1x1_2, and 3x3_2). With this setup, we were able to ask:\n\n- What are the tradeoffs in \"many 1x1_2 and few 3x3_2\" vs \"few 1x1_2 and many 3x3_2\" in terms of metrics such as model size and accuracy? In Section 5.3, we learn that 50% 1x1_2 and 50% 3x3_2 filters generates the same accuracy level as 99% 3x3_2. However, there's a significant difference in the model size and computational footprint of these these models. The lesson is: look for the point where adding more spatial resolution to the filters stops improving accuracy, and stop there; otherwise computation and model parameters are being wasted.\n\n- In GoogLeNet-v1, some of the Inception-v1 modules are set up such that the early filter banks have 75% the number of filters as the late filter banks. In our terminology, this is like they have a \"squeeze ratio\" (SR) of 0.75. We wanted to understand what the tradeoffs that emerge if we more aggressively cut down the number of filters at the beginning of each module. We were able to do this experiment in Section 5.2, and we found (again) that there's a saturation point where going from SR=0.75 to SR=1.0 increases the computational footprint and model size, but it does not improve accuracy. \n\n- Thus, the Fire modules have served as a good vehicle for understanding the tradeoffs that emerge when selecting the number of filters inside of CNN modules.\n\n2. Architecturally, what does SqueezeNet have in common ResNet?\nWe spend most of the paper presenting and evaluating SqueezeNet with no residual connections (Figure 2, left side). As a bonus, we experiment with adding residual connections to SqueezeNet, and we find that this does improve the accuracy. In some ways, the paper might deliver a stronger message if we had just focused on the standard SqueezeNet model. But, we thought the residual results were interesting, and we felt compelled to share them with the community.\n\n3. How does SqueezeNet's accuracy compare with other modern CNN architectures' accuracy?\nGoogLeNet (BVLC_googlenet) achieves single-crop top-5 ImageNet accuracy of 87.3% and is a 53MB model. In Section 5.2 and Figure 3a, we describe a 13MB (uncompressed) version of the SqueezeNet model that achieves 85.3% top-5 accuracy while being 4x smaller than GoogLeNet."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "SqueezeNet: AlexNet-level accuracy with 50x fewer parameters and <0.5MB model size", "abstract": "Recent research on deep neural networks has focused primarily on improving accuracy. For a given accuracy level, it is typically possible to identify multiple DNN architectures that achieve that accuracy level. With equivalent accuracy, smaller DNN architectures offer at least three advantages: (1) Smaller DNNs require less communication across servers during distributed training. (2) Smaller DNNs require less bandwidth to export a new model from the cloud to an autonomous car. (3) Smaller DNNs are more feasible to deploy on FPGAs and other hardware with limited memory. To provide all of these advantages, we propose a small DNN architecture called SqueezeNet. SqueezeNet achieves AlexNet-level accuracy on ImageNet with 50x fewer parameters. Additionally, with model compression techniques we are able to compress SqueezeNet to less than 0.5MB (510x smaller than AlexNet).", "pdf": "/pdf/6b649f83c76024a3120850a3f9e78d1560ad6fcd.pdf", "TL;DR": "Small CNN models", "paperhash": "iandola|squeezenet_alexnetlevel_accuracy_with_50x_fewer_parameters_and_05mb_model_size", "conflicts": ["stanford.edu", "berkeley.edu", "deepscale.ai"], "keywords": ["Computer vision", "Deep learning"], "authors": ["Forrest N. Iandola", "Song Han", "Matthew W. Moskewicz", "Khalid Ashraf", "William J. Dally", "Kurt Keutzer"], "authorids": ["forresti@eecs.berkeley.edu", "songhan@stanford.edu", "moskewcz@eecs.berkeley.edu", "kashraf@eecs.berkeley.edu", "dally@stanford.edu", "keutzer@eecs.berkeley.edu"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287717339, "id": "ICLR.cc/2017/conference/-/paper125/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "S1xh5sYgx", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper125/reviewers", "ICLR.cc/2017/conference/paper125/areachairs"], "cdate": 1485287717339}}}, {"tddate": null, "tmdate": 1480885647523, "tcdate": 1480885647519, "number": 1, "id": "B1P9rWMmx", "invitation": "ICLR.cc/2017/conference/-/paper125/public/comment", "forum": "S1xh5sYgx", "replyto": "SJHRKU1Xe", "signatures": ["~Forrest_Iandola1"], "readers": ["everyone"], "writers": ["~Forrest_Iandola1"], "content": {"title": "Knowledge Distillation is a complementary approach", "comment": "In all of our experiments, we are optimizing classification accuracy using a softmax at the end of our CNN. In Knowledge Distillation, the approach is to optimize a small CNN to replicate the output of a large CNN. \n\nSo, while we don't use Knowledge Distillation here, it is a complementary approach that may enable the SqueezeNet family of models to further improve in accuracy.\n"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "SqueezeNet: AlexNet-level accuracy with 50x fewer parameters and <0.5MB model size", "abstract": "Recent research on deep neural networks has focused primarily on improving accuracy. For a given accuracy level, it is typically possible to identify multiple DNN architectures that achieve that accuracy level. With equivalent accuracy, smaller DNN architectures offer at least three advantages: (1) Smaller DNNs require less communication across servers during distributed training. (2) Smaller DNNs require less bandwidth to export a new model from the cloud to an autonomous car. (3) Smaller DNNs are more feasible to deploy on FPGAs and other hardware with limited memory. To provide all of these advantages, we propose a small DNN architecture called SqueezeNet. SqueezeNet achieves AlexNet-level accuracy on ImageNet with 50x fewer parameters. Additionally, with model compression techniques we are able to compress SqueezeNet to less than 0.5MB (510x smaller than AlexNet).", "pdf": "/pdf/6b649f83c76024a3120850a3f9e78d1560ad6fcd.pdf", "TL;DR": "Small CNN models", "paperhash": "iandola|squeezenet_alexnetlevel_accuracy_with_50x_fewer_parameters_and_05mb_model_size", "conflicts": ["stanford.edu", "berkeley.edu", "deepscale.ai"], "keywords": ["Computer vision", "Deep learning"], "authors": ["Forrest N. Iandola", "Song Han", "Matthew W. Moskewicz", "Khalid Ashraf", "William J. Dally", "Kurt Keutzer"], "authorids": ["forresti@eecs.berkeley.edu", "songhan@stanford.edu", "moskewcz@eecs.berkeley.edu", "kashraf@eecs.berkeley.edu", "dally@stanford.edu", "keutzer@eecs.berkeley.edu"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287717339, "id": "ICLR.cc/2017/conference/-/paper125/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "S1xh5sYgx", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper125/reviewers", "ICLR.cc/2017/conference/paper125/areachairs"], "cdate": 1485287717339}}}, {"tddate": null, "tmdate": 1480710604894, "tcdate": 1480710604890, "number": 3, "id": "SJHRKU1Xe", "invitation": "ICLR.cc/2017/conference/-/paper125/pre-review/question", "forum": "S1xh5sYgx", "replyto": "S1xh5sYgx", "signatures": ["ICLR.cc/2017/conference/paper125/AnonReviewer3"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/conference/paper125/AnonReviewer3"], "content": {"title": "Comparisons with Knowledge Distillation", "question": "How does your method compare with Knowledge Distillation method?\n"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "SqueezeNet: AlexNet-level accuracy with 50x fewer parameters and <0.5MB model size", "abstract": "Recent research on deep neural networks has focused primarily on improving accuracy. For a given accuracy level, it is typically possible to identify multiple DNN architectures that achieve that accuracy level. With equivalent accuracy, smaller DNN architectures offer at least three advantages: (1) Smaller DNNs require less communication across servers during distributed training. (2) Smaller DNNs require less bandwidth to export a new model from the cloud to an autonomous car. (3) Smaller DNNs are more feasible to deploy on FPGAs and other hardware with limited memory. To provide all of these advantages, we propose a small DNN architecture called SqueezeNet. SqueezeNet achieves AlexNet-level accuracy on ImageNet with 50x fewer parameters. Additionally, with model compression techniques we are able to compress SqueezeNet to less than 0.5MB (510x smaller than AlexNet).", "pdf": "/pdf/6b649f83c76024a3120850a3f9e78d1560ad6fcd.pdf", "TL;DR": "Small CNN models", "paperhash": "iandola|squeezenet_alexnetlevel_accuracy_with_50x_fewer_parameters_and_05mb_model_size", "conflicts": ["stanford.edu", "berkeley.edu", "deepscale.ai"], "keywords": ["Computer vision", "Deep learning"], "authors": ["Forrest N. Iandola", "Song Han", "Matthew W. Moskewicz", "Khalid Ashraf", "William J. Dally", "Kurt Keutzer"], "authorids": ["forresti@eecs.berkeley.edu", "songhan@stanford.edu", "moskewcz@eecs.berkeley.edu", "kashraf@eecs.berkeley.edu", "dally@stanford.edu", "keutzer@eecs.berkeley.edu"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1480741199000, "tmdate": 1480959448894, "id": "ICLR.cc/2017/conference/-/paper125/pre-review/question", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/conference/paper125/reviewers"], "noninvitees": ["ICLR.cc/2017/conference/paper125/AnonReviewer1", "ICLR.cc/2017/conference/paper125/AnonReviewer2", "ICLR.cc/2017/conference/paper125/AnonReviewer3"], "reply": {"forum": "S1xh5sYgx", "replyto": "S1xh5sYgx", "writers": {"values-regex": "ICLR.cc/2017/conference/paper125/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/conference/paper125/AnonReviewer[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your question.", "value-regex": ".{1,500}"}, "question": {"order": 2, "description": "Your question", "value-regex": "[\\S\\s]{1,5000}"}}}, "nonreaders": [], "expdate": 1488517199000, "cdate": 1480959448894}}}, {"tddate": null, "tmdate": 1480457360711, "tcdate": 1480457360708, "number": 2, "id": "Bkt52_jGx", "invitation": "ICLR.cc/2017/conference/-/paper125/pre-review/question", "forum": "S1xh5sYgx", "replyto": "S1xh5sYgx", "signatures": ["ICLR.cc/2017/conference/paper125/AnonReviewer2"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/conference/paper125/AnonReviewer2"], "content": {"title": "Memory for storing activations?", "question": "The authors analyze the amount of space required for storing the parameters of SqueezeNet (which is valuable to estimate for downloading speed, etc.) But, the Gschwend thesis also analyzes the amount of space required to store the activations during run time. Gschwend's results seem to show that the activation memory is much larger than the parameter memory.\n\nComments? Is Gschwend right? If so, can you add this to the paper?"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "SqueezeNet: AlexNet-level accuracy with 50x fewer parameters and <0.5MB model size", "abstract": "Recent research on deep neural networks has focused primarily on improving accuracy. For a given accuracy level, it is typically possible to identify multiple DNN architectures that achieve that accuracy level. With equivalent accuracy, smaller DNN architectures offer at least three advantages: (1) Smaller DNNs require less communication across servers during distributed training. (2) Smaller DNNs require less bandwidth to export a new model from the cloud to an autonomous car. (3) Smaller DNNs are more feasible to deploy on FPGAs and other hardware with limited memory. To provide all of these advantages, we propose a small DNN architecture called SqueezeNet. SqueezeNet achieves AlexNet-level accuracy on ImageNet with 50x fewer parameters. Additionally, with model compression techniques we are able to compress SqueezeNet to less than 0.5MB (510x smaller than AlexNet).", "pdf": "/pdf/6b649f83c76024a3120850a3f9e78d1560ad6fcd.pdf", "TL;DR": "Small CNN models", "paperhash": "iandola|squeezenet_alexnetlevel_accuracy_with_50x_fewer_parameters_and_05mb_model_size", "conflicts": ["stanford.edu", "berkeley.edu", "deepscale.ai"], "keywords": ["Computer vision", "Deep learning"], "authors": ["Forrest N. Iandola", "Song Han", "Matthew W. Moskewicz", "Khalid Ashraf", "William J. Dally", "Kurt Keutzer"], "authorids": ["forresti@eecs.berkeley.edu", "songhan@stanford.edu", "moskewcz@eecs.berkeley.edu", "kashraf@eecs.berkeley.edu", "dally@stanford.edu", "keutzer@eecs.berkeley.edu"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1480741199000, "tmdate": 1480959448894, "id": "ICLR.cc/2017/conference/-/paper125/pre-review/question", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/conference/paper125/reviewers"], "noninvitees": ["ICLR.cc/2017/conference/paper125/AnonReviewer1", "ICLR.cc/2017/conference/paper125/AnonReviewer2", "ICLR.cc/2017/conference/paper125/AnonReviewer3"], "reply": {"forum": "S1xh5sYgx", "replyto": "S1xh5sYgx", "writers": {"values-regex": "ICLR.cc/2017/conference/paper125/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/conference/paper125/AnonReviewer[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your question.", "value-regex": ".{1,500}"}, "question": {"order": 2, "description": "Your question", "value-regex": "[\\S\\s]{1,5000}"}}}, "nonreaders": [], "expdate": 1488517199000, "cdate": 1480959448894}}}, {"tddate": null, "tmdate": 1480429249516, "tcdate": 1480429249512, "number": 1, "id": "HytpAbsMg", "invitation": "ICLR.cc/2017/conference/-/paper125/pre-review/question", "forum": "S1xh5sYgx", "replyto": "S1xh5sYgx", "signatures": ["ICLR.cc/2017/conference/paper125/AnonReviewer1"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/conference/paper125/AnonReviewer1"], "content": {"title": "SqueezeNet versus other models than AlexNet", "question": "The SqueezeNet seems to be an application of ideas from inception modules (CNN Microarchitecture) and ResNet modules (CNN Macroarchitecture). Question: how does SqueezeNet performs compared to GoogLeNet and ResNet in terms of accuracy?"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "SqueezeNet: AlexNet-level accuracy with 50x fewer parameters and <0.5MB model size", "abstract": "Recent research on deep neural networks has focused primarily on improving accuracy. For a given accuracy level, it is typically possible to identify multiple DNN architectures that achieve that accuracy level. With equivalent accuracy, smaller DNN architectures offer at least three advantages: (1) Smaller DNNs require less communication across servers during distributed training. (2) Smaller DNNs require less bandwidth to export a new model from the cloud to an autonomous car. (3) Smaller DNNs are more feasible to deploy on FPGAs and other hardware with limited memory. To provide all of these advantages, we propose a small DNN architecture called SqueezeNet. SqueezeNet achieves AlexNet-level accuracy on ImageNet with 50x fewer parameters. Additionally, with model compression techniques we are able to compress SqueezeNet to less than 0.5MB (510x smaller than AlexNet).", "pdf": "/pdf/6b649f83c76024a3120850a3f9e78d1560ad6fcd.pdf", "TL;DR": "Small CNN models", "paperhash": "iandola|squeezenet_alexnetlevel_accuracy_with_50x_fewer_parameters_and_05mb_model_size", "conflicts": ["stanford.edu", "berkeley.edu", "deepscale.ai"], "keywords": ["Computer vision", "Deep learning"], "authors": ["Forrest N. Iandola", "Song Han", "Matthew W. Moskewicz", "Khalid Ashraf", "William J. Dally", "Kurt Keutzer"], "authorids": ["forresti@eecs.berkeley.edu", "songhan@stanford.edu", "moskewcz@eecs.berkeley.edu", "kashraf@eecs.berkeley.edu", "dally@stanford.edu", "keutzer@eecs.berkeley.edu"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1480741199000, "tmdate": 1480959448894, "id": "ICLR.cc/2017/conference/-/paper125/pre-review/question", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/conference/paper125/reviewers"], "noninvitees": ["ICLR.cc/2017/conference/paper125/AnonReviewer1", "ICLR.cc/2017/conference/paper125/AnonReviewer2", "ICLR.cc/2017/conference/paper125/AnonReviewer3"], "reply": {"forum": "S1xh5sYgx", "replyto": "S1xh5sYgx", "writers": {"values-regex": "ICLR.cc/2017/conference/paper125/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/conference/paper125/AnonReviewer[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your question.", "value-regex": ".{1,500}"}, "question": {"order": 2, "description": "Your question", "value-regex": "[\\S\\s]{1,5000}"}}}, "nonreaders": [], "expdate": 1488517199000, "cdate": 1480959448894}}}, {"tddate": null, "replyto": null, "ddate": null, "tmdate": 1478242561723, "tcdate": 1478240936515, "number": 125, "id": "S1xh5sYgx", "invitation": "ICLR.cc/2017/conference/-/submission", "forum": "S1xh5sYgx", "signatures": ["~Forrest_Iandola1"], "readers": ["everyone"], "content": {"title": "SqueezeNet: AlexNet-level accuracy with 50x fewer parameters and <0.5MB model size", "abstract": "Recent research on deep neural networks has focused primarily on improving accuracy. For a given accuracy level, it is typically possible to identify multiple DNN architectures that achieve that accuracy level. With equivalent accuracy, smaller DNN architectures offer at least three advantages: (1) Smaller DNNs require less communication across servers during distributed training. (2) Smaller DNNs require less bandwidth to export a new model from the cloud to an autonomous car. (3) Smaller DNNs are more feasible to deploy on FPGAs and other hardware with limited memory. To provide all of these advantages, we propose a small DNN architecture called SqueezeNet. SqueezeNet achieves AlexNet-level accuracy on ImageNet with 50x fewer parameters. Additionally, with model compression techniques we are able to compress SqueezeNet to less than 0.5MB (510x smaller than AlexNet).", "pdf": "/pdf/6b649f83c76024a3120850a3f9e78d1560ad6fcd.pdf", "TL;DR": "Small CNN models", "paperhash": "iandola|squeezenet_alexnetlevel_accuracy_with_50x_fewer_parameters_and_05mb_model_size", "conflicts": ["stanford.edu", "berkeley.edu", "deepscale.ai"], "keywords": ["Computer vision", "Deep learning"], "authors": ["Forrest N. Iandola", "Song Han", "Matthew W. Moskewicz", "Khalid Ashraf", "William J. Dally", "Kurt Keutzer"], "authorids": ["forresti@eecs.berkeley.edu", "songhan@stanford.edu", "moskewcz@eecs.berkeley.edu", "kashraf@eecs.berkeley.edu", "dally@stanford.edu", "keutzer@eecs.berkeley.edu"]}, "writers": [], "nonreaders": [], "details": {"replyCount": 13, "writable": false, "overwriting": [], "revisions": false, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1475686800000, "tmdate": 1478287705855, "id": "ICLR.cc/2017/conference/-/submission", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/pcs"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": null, "replyto": null, "writers": {"values-regex": "~.*"}, "signatures": {"values-regex": "~.*", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"pdf": {"required": true, "order": 5, "description": "Either upload a PDF file or provide a direct link to your PDF on ArXiv (link must begin with http(s) and end with .pdf)", "value-regex": "upload|(http|https):\\/\\/.+\\.pdf"}, "title": {"required": true, "order": 1, "description": "Title of paper.", "value-regex": ".{1,250}"}, "abstract": {"required": true, "order": 4, "description": "Abstract of paper.", "value-regex": "[\\S\\s]{1,5000}"}, "authors": {"required": true, "order": 2, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of author names, as they appear in the paper."}, "conflicts": {"required": true, "order": 100, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of email domains of people who would have a conflict of interest in reviewing this paper, (e.g., cs.umass.edu;google.com, etc.)."}, "keywords": {"order": 6, "description": "Comma separated list of keywords.", "values-dropdown": ["Theory", "Computer vision", "Speech", "Natural language processing", "Deep learning", "Unsupervised Learning", "Supervised Learning", "Semi-Supervised Learning", "Reinforcement Learning", "Transfer Learning", "Multi-modal learning", "Applications", "Optimization", "Structured prediction", "Games"]}, "TL;DR": {"required": false, "order": 3, "description": "\"Too Long; Didn't Read\": a short sentence describing your paper", "value-regex": "[^\\n]{0,250}"}, "authorids": {"required": true, "order": 3, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of author email addresses, in the same order as above."}}}, "nonreaders": [], "noninvitees": [], "expdate": 1483462800000, "cdate": 1478287705855}}}], "count": 14}