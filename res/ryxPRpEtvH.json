{"notes": [{"id": "ryxPRpEtvH", "original": "SylUXc-_vB", "number": 858, "cdate": 1569439182598, "ddate": null, "tcdate": 1569439182598, "tmdate": 1577168223985, "tddate": null, "forum": "ryxPRpEtvH", "replyto": null, "invitation": "ICLR.cc/2020/Conference/-/Blind_Submission", "content": {"title": "Omnibus Dropout for Improving The Probabilistic Classification Outputs of ConvNets", "authors": ["Zhilu Zhang", "Adrian V. Dalca", "Mert R. Sabuncu"], "authorids": ["zz452@cornell.edu", "adalca@mit.edu", "msabuncu@cornell.edu"], "keywords": ["Uncertainty Estimation", "Calibration", "Deep Learning"], "TL;DR": "We propose to combine structured dropout methods at different scales for improved model diversity and performance of dropout uncertainty estimates.", "abstract": "While neural network models achieve impressive classification accuracy across different tasks, they can suffer from poor calibration of their probabilistic predictions. A Bayesian perspective has recently suggested that dropout, a regularization strategy popularly used during training, can be employed to obtain better probabilistic predictions at test time (Gal & Ghahramani, 2016a). However, empirical results so far have not been encouraging, particularly with convolutional networks. In this paper, through the lens of ensemble learning, we associate this unsatisfactory performance with the correlation between the models sampled with dropout. Motivated by this, we explore the use of various structured dropout techniques to promote model diversity and improve the quality of probabilistic predictions. We also propose an omnibus dropout strategy that combines various structured dropout methods. Using the SVHN, CIFAR-10 and CIFAR-100 datasets, we empirically demonstrate the superior performance of omnibus dropout relative to several widely used strong baselines in addition to regular dropout. Lastly, we show the merit of omnibus dropout in a Bayesian active learning application. ", "pdf": "/pdf/11d4d33cbcafdbe85c3348375475f71d62e69311.pdf", "paperhash": "zhang|omnibus_dropout_for_improving_the_probabilistic_classification_outputs_of_convnets", "original_pdf": "/attachment/11d4d33cbcafdbe85c3348375475f71d62e69311.pdf", "_bibtex": "@misc{\nzhang2020omnibus,\ntitle={Omnibus Dropout for Improving The Probabilistic Classification Outputs of ConvNets},\nauthor={Zhilu Zhang and Adrian V. Dalca and Mert R. Sabuncu},\nyear={2020},\nurl={https://openreview.net/forum?id=ryxPRpEtvH}\n}"}, "signatures": ["ICLR.cc/2020/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference"], "details": {"replyCount": 7, "writable": false, "overwriting": [], "revisions": false, "tags": [], "invitation": {"reply": {"readers": {"values-regex": ".*"}, "writers": {"values": ["ICLR.cc/2020/Conference"]}, "signatures": {"values": ["ICLR.cc/2020/Conference"]}, "content": {"spotlight_video": {"value-regex": ".*"}, "full_presentation_video": {"value-regex": ".*"}, "original_pdf": {"required": false, "description": "Upload a PDF file that ends with .pdf", "value-regex": ".*"}, "appendix": {"value-regex": ".*"}, "authorids": {"values-regex": ".*"}, "poster": {"value-regex": ".*"}, "authors": {"values": ["Anonymous"]}, "slides": {"value-regex": ".*"}}}, "final": [], "signatures": ["ICLR.cc/2020/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference"], "noninvitees": [], "tcdate": 1569271260237, "tmdate": 1593459412141, "id": "ICLR.cc/2020/Conference/-/Blind_Submission"}}, "tauthor": "OpenReview.net"}, {"id": "UZSQLxHM-z", "original": null, "number": 1, "cdate": 1576798707971, "ddate": null, "tcdate": 1576798707971, "tmdate": 1576800928382, "tddate": null, "forum": "ryxPRpEtvH", "replyto": "ryxPRpEtvH", "invitation": "ICLR.cc/2020/Conference/Paper858/-/Decision", "content": {"decision": "Reject", "comment": "The paper investigates how to improve the performance of dropout and proposes an omnibus dropout strategy to reduce the correlation between the individual models.\n\nAll the reviewers felt that the paper requires more work before it can be accepted. In particular, the reviewers raised several concerns about novelty of the method relative to existing methods, significance of performance improvements and clarity of the presentation. \n\nI encourage the authors to revise the draft based on the reviewers\u2019 feedback and resubmit to a different venue.\n", "title": "Paper Decision"}, "signatures": ["ICLR.cc/2020/Conference/Program_Chairs"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Program_Chairs"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Omnibus Dropout for Improving The Probabilistic Classification Outputs of ConvNets", "authors": ["Zhilu Zhang", "Adrian V. Dalca", "Mert R. Sabuncu"], "authorids": ["zz452@cornell.edu", "adalca@mit.edu", "msabuncu@cornell.edu"], "keywords": ["Uncertainty Estimation", "Calibration", "Deep Learning"], "TL;DR": "We propose to combine structured dropout methods at different scales for improved model diversity and performance of dropout uncertainty estimates.", "abstract": "While neural network models achieve impressive classification accuracy across different tasks, they can suffer from poor calibration of their probabilistic predictions. A Bayesian perspective has recently suggested that dropout, a regularization strategy popularly used during training, can be employed to obtain better probabilistic predictions at test time (Gal & Ghahramani, 2016a). However, empirical results so far have not been encouraging, particularly with convolutional networks. In this paper, through the lens of ensemble learning, we associate this unsatisfactory performance with the correlation between the models sampled with dropout. Motivated by this, we explore the use of various structured dropout techniques to promote model diversity and improve the quality of probabilistic predictions. We also propose an omnibus dropout strategy that combines various structured dropout methods. Using the SVHN, CIFAR-10 and CIFAR-100 datasets, we empirically demonstrate the superior performance of omnibus dropout relative to several widely used strong baselines in addition to regular dropout. Lastly, we show the merit of omnibus dropout in a Bayesian active learning application. ", "pdf": "/pdf/11d4d33cbcafdbe85c3348375475f71d62e69311.pdf", "paperhash": "zhang|omnibus_dropout_for_improving_the_probabilistic_classification_outputs_of_convnets", "original_pdf": "/attachment/11d4d33cbcafdbe85c3348375475f71d62e69311.pdf", "_bibtex": "@misc{\nzhang2020omnibus,\ntitle={Omnibus Dropout for Improving The Probabilistic Classification Outputs of ConvNets},\nauthor={Zhilu Zhang and Adrian V. Dalca and Mert R. Sabuncu},\nyear={2020},\nurl={https://openreview.net/forum?id=ryxPRpEtvH}\n}"}, "tags": [], "invitation": {"reply": {"writers": {"description": "How your identity will be displayed.", "values-regex": ["ICLR.cc/2020/Conference/Program_Chairs"]}, "signatures": {"values": ["ICLR.cc/2020/Conference/Program_Chairs"], "description": "How your identity will be displayed."}, "content": {"decision": {"value-radio": ["Accept (Spotlight)", "Accept (Talk)", "Accept (Poster)", "Reject"], "description": "Decision", "required": true, "order": 2}, "title": {"value": "Paper Decision", "required": true, "order": 1}, "comment": {"value-regex": "[\\S\\s]{0,5000}", "description": "", "required": false, "order": 3}}, "forum": "ryxPRpEtvH", "replyto": "ryxPRpEtvH", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}}, "expdate": 1576854540000, "duedate": 1576853940000, "multiReply": false, "readers": ["everyone"], "invitees": ["ICLR.cc/2020/Conference/Program_Chairs"], "tcdate": 1576795728300, "tmdate": 1576800280688, "super": "ICLR.cc/2020/Conference/-/Decision", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper858/-/Decision"}}}, {"id": "ByxUkcTRtS", "original": null, "number": 1, "cdate": 1571899870222, "ddate": null, "tcdate": 1571899870222, "tmdate": 1574317824177, "tddate": null, "forum": "ryxPRpEtvH", "replyto": "ryxPRpEtvH", "invitation": "ICLR.cc/2020/Conference/Paper858/-/Official_Review", "content": {"experience_assessment": "I have published in this field for several years.", "rating": "3: Weak Reject", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "title": "Official Blind Review #1", "review": "This paper proposed to use multiple structured dropout techniques to improve the ensemble performance of convolutional neural networks as well as the calibration of their probabilistic predictions. \n\nThe approach, which is termed omnibus dropout and combines multiple existing dropout methods, is reasonable and straightforward. \n\nThe paper presents extensive experimental results and analyses by mainly comparing with the explicit ensemble of multiple neural networks. The experiments reveal interesting properties of the learned networks and compelling results. \n\nMy main concern is about the technical novelty of the paper. It does not supply a new method in essence and instead provides careful experimental studies, from both accuracy and calibration perspectives, about a combination of existing dropout techniques. It reads like a very solid workshop paper in my opinion, but it is probably not a good fit to the main conference.\n\nQuestions:\n1. The reasoning in the first two paragraphs of the introduction is confusing or misleading. The first paragraph is mainly about the poorly calibrated probabilistic outputs of neural networks, while the second paragraph suddenly shifts to the performance of ensembled networks in terms of accuracy. \n\n2. Some of the comparisons with the \"deep ensemble\" may be unfair. There are only five networks in \"deep ensemble\", but 30 are used in test time for the proposed method. \n\n3. Where is \"deep ensemble\" in the active learning experiments? I could not find it in Figure 5. ", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory."}, "signatures": ["ICLR.cc/2020/Conference/Paper858/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper858/AnonReviewer1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Omnibus Dropout for Improving The Probabilistic Classification Outputs of ConvNets", "authors": ["Zhilu Zhang", "Adrian V. Dalca", "Mert R. Sabuncu"], "authorids": ["zz452@cornell.edu", "adalca@mit.edu", "msabuncu@cornell.edu"], "keywords": ["Uncertainty Estimation", "Calibration", "Deep Learning"], "TL;DR": "We propose to combine structured dropout methods at different scales for improved model diversity and performance of dropout uncertainty estimates.", "abstract": "While neural network models achieve impressive classification accuracy across different tasks, they can suffer from poor calibration of their probabilistic predictions. A Bayesian perspective has recently suggested that dropout, a regularization strategy popularly used during training, can be employed to obtain better probabilistic predictions at test time (Gal & Ghahramani, 2016a). However, empirical results so far have not been encouraging, particularly with convolutional networks. In this paper, through the lens of ensemble learning, we associate this unsatisfactory performance with the correlation between the models sampled with dropout. Motivated by this, we explore the use of various structured dropout techniques to promote model diversity and improve the quality of probabilistic predictions. We also propose an omnibus dropout strategy that combines various structured dropout methods. Using the SVHN, CIFAR-10 and CIFAR-100 datasets, we empirically demonstrate the superior performance of omnibus dropout relative to several widely used strong baselines in addition to regular dropout. Lastly, we show the merit of omnibus dropout in a Bayesian active learning application. ", "pdf": "/pdf/11d4d33cbcafdbe85c3348375475f71d62e69311.pdf", "paperhash": "zhang|omnibus_dropout_for_improving_the_probabilistic_classification_outputs_of_convnets", "original_pdf": "/attachment/11d4d33cbcafdbe85c3348375475f71d62e69311.pdf", "_bibtex": "@misc{\nzhang2020omnibus,\ntitle={Omnibus Dropout for Improving The Probabilistic Classification Outputs of ConvNets},\nauthor={Zhilu Zhang and Adrian V. Dalca and Mert R. Sabuncu},\nyear={2020},\nurl={https://openreview.net/forum?id=ryxPRpEtvH}\n}"}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "ryxPRpEtvH", "replyto": "ryxPRpEtvH", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper858/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper858/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1576036443552, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper858/Reviewers"], "noninvitees": [], "tcdate": 1570237745963, "tmdate": 1576036443564, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper858/-/Official_Review"}}}, {"id": "SJxKxI4soS", "original": null, "number": 8, "cdate": 1573762544825, "ddate": null, "tcdate": 1573762544825, "tmdate": 1573762544825, "tddate": null, "forum": "ryxPRpEtvH", "replyto": "Hkl9f4ilir", "invitation": "ICLR.cc/2020/Conference/Paper858/-/Official_Comment", "content": {"title": "Response to Review #4", "comment": "We would like to thank you for taking precious time to review our paper.\n\n1.\tWe will make the justification as to why the omnibus dropout strategy improves the performance more clearly stated. In essence, we empirically find that structured dropout methods promote model diversity in the sampled models compared to regular dropout. This enhanced model diversity leads to more calibrated predictions, according to equation 2. However, as illustrated in Figure 3 of the paper, the improved model diversity provided by structured dropouts like dropBlock and dropChannel can come at the expense of reduced MSE of individual sampled models, thereby reducing the overall ensemble performance. An omnibus strategy strikes the right balance between the performance of the average individual sample performance and model diversity, as illustrated by low Brier score when n=1 and much larger improvement when the number of samples increases, thereby achieving better results overall.\n\n2.\tIn terms of performance improvement, we would like to emphasize that, to the best of our knowledge, no prior work has considered any form of structured dropout for uncertainty estimation and the proposed technique can perform better than three of the most widely used strategies (MC dropout, deep ensemble, and temperature scaling) in terms of NLL, ECE and Brier score, as demonstrated in our experiments.\n\n3.\tWe address your main concern regarding the technical novelty of the paper here. While we do agree that the proposed method of omnibus dropout is simple, we believe that the paper provides several significant contributions to the field of uncertainty estimation for deep learning as listed below.\na.\tWhile it was previously discovered empirically that deep ensembles lead to better uncertainty estimates compare to MC dropout, no justification has been given to explain this surprising observation that, even a simple frequentist approach of ensembling 5 neural networks can outperform some of the Bayesian approaches like MC dropout. In this paper, we attribute the lackluster performance of MC dropout to the lack of diversity in the predictions of models sampled through dropout.\nb.\tAlthough structured dropout techniques are widely used as regularization techniques to improve the accuracy of neural networks, they are not adopted for uncertainty estimation at all. In this paper, together with the theoretical justification based on ensemble diversity, we demonstrate the merit of using structured dropout methods over the regular dropout method for uncertainty estimation as well.\nc.\tEmpirically we found that different structured dropout techniques have variable performance for different datasets and architectures, and searching for the best one can be expensive. We provide a simple solution which combines different kinds of dropout. We empirically demonstrate that this omnibus strategy yields state-of-the-art performance compared to widely used baselines for uncertainty estimates like temperature scaling, deep ensemble, and regular MC dropout.\n\n4.\tWe also considered using a constant dropout rate of 0.1 for all methods, and the proposed method still performs consistently better than most of the strategies (see Appendix C Table 2)\n"}, "signatures": ["ICLR.cc/2020/Conference/Paper858/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper858/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Omnibus Dropout for Improving The Probabilistic Classification Outputs of ConvNets", "authors": ["Zhilu Zhang", "Adrian V. Dalca", "Mert R. Sabuncu"], "authorids": ["zz452@cornell.edu", "adalca@mit.edu", "msabuncu@cornell.edu"], "keywords": ["Uncertainty Estimation", "Calibration", "Deep Learning"], "TL;DR": "We propose to combine structured dropout methods at different scales for improved model diversity and performance of dropout uncertainty estimates.", "abstract": "While neural network models achieve impressive classification accuracy across different tasks, they can suffer from poor calibration of their probabilistic predictions. A Bayesian perspective has recently suggested that dropout, a regularization strategy popularly used during training, can be employed to obtain better probabilistic predictions at test time (Gal & Ghahramani, 2016a). However, empirical results so far have not been encouraging, particularly with convolutional networks. In this paper, through the lens of ensemble learning, we associate this unsatisfactory performance with the correlation between the models sampled with dropout. Motivated by this, we explore the use of various structured dropout techniques to promote model diversity and improve the quality of probabilistic predictions. We also propose an omnibus dropout strategy that combines various structured dropout methods. Using the SVHN, CIFAR-10 and CIFAR-100 datasets, we empirically demonstrate the superior performance of omnibus dropout relative to several widely used strong baselines in addition to regular dropout. Lastly, we show the merit of omnibus dropout in a Bayesian active learning application. ", "pdf": "/pdf/11d4d33cbcafdbe85c3348375475f71d62e69311.pdf", "paperhash": "zhang|omnibus_dropout_for_improving_the_probabilistic_classification_outputs_of_convnets", "original_pdf": "/attachment/11d4d33cbcafdbe85c3348375475f71d62e69311.pdf", "_bibtex": "@misc{\nzhang2020omnibus,\ntitle={Omnibus Dropout for Improving The Probabilistic Classification Outputs of ConvNets},\nauthor={Zhilu Zhang and Adrian V. Dalca and Mert R. Sabuncu},\nyear={2020},\nurl={https://openreview.net/forum?id=ryxPRpEtvH}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "ryxPRpEtvH", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper858/Authors", "ICLR.cc/2020/Conference/Paper858/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper858/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper858/Reviewers", "ICLR.cc/2020/Conference/Paper858/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper858/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper858/Authors|ICLR.cc/2020/Conference/Paper858/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504165122, "tmdate": 1576860557627, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper858/Authors", "ICLR.cc/2020/Conference/Paper858/Reviewers", "ICLR.cc/2020/Conference/Paper858/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper858/-/Official_Comment"}}}, {"id": "ByxMPGNioB", "original": null, "number": 7, "cdate": 1573761625587, "ddate": null, "tcdate": 1573761625587, "tmdate": 1573761625587, "tddate": null, "forum": "ryxPRpEtvH", "replyto": "H1g0Jtez5S", "invitation": "ICLR.cc/2020/Conference/Paper858/-/Official_Comment", "content": {"title": "Response to reviewer #3", "comment": "We would like to thank you for taking precious time to review our paper.\n\n\u201cMotivation Unclear\u201d\n1.\tWe will fix the notational issue regarding MSE not involving y.\n2.\tWe will incorporate a detailed proof of equation (2) in the appendix.\n3.\tFrom equation (2), we can see that MSE of the overall ensemble model H can be decomposed into the difference between average MSE of individual model h_t and the model ambiguity (a notion to measure diversity among predictions, as defined in the first paragraph of section 3.2) of the individual models. Hence, the more diverse the individual predictions, the larger reduction in terms of MSE, and hence the better calibrated the predictions are (MSE can be seen as a measure of both accuracy and calibration, as described in Appendix B of our paper). This motivates us to use structured dropout methods to enhance model diversity among the sampled model, thereby producing better-calibrated predictions.\n\n\u201cUnclear / Imprecise Writing\u201d\n1.\tHigher dropout rates lead to smaller effective network capacities because high dropout rates would lead to less amount of parameters in the neural networks on average, thereby reducing the model capacity. We will make this more explicit in the updated version of the paper.\n2.\tBy \u201cdropout uncertainty can be obtained sequentially\u201d, we mean that we can iteratively get many samples by deploying dropout at test time to obtain uncertainty estimates. As a direct comparison to this, when deploying deep ensembles, multiple models have to be saved and loaded to obtain uncertainty estimates. We will make this more clear in the updated version of the paper as well.\n3.\tWe describe in the following sentence that \u201cThe implementation of omnibus dropout involves the sequential execution of the nested group of dropout methods: regular dropLayer, dropChannel, dropBlock and regular dropout.\u201d We will incorporate a figure to illustrate the architecture as well in the updated version of the paper.\n\n\u201cExperiments\u201d\n1.\tAs we analyzed in the second paragraph of Section 4.1 of our paper, we empirically demonstrated that the moderate improvement in diversity is key to why omnibus dropout is consistently one of the best approaches. In terms of performance improvement, we would like to emphasize that, to the best of our knowledge, no prior work has considered any form of structured dropout for uncertainty estimation and the proposed technique can perform better than three of the most widely used strategies (MC dropout, deep ensemble, and temperature scaling) in terms of NLL, ECE and Brier score, as demonstrated in our experiments.\n"}, "signatures": ["ICLR.cc/2020/Conference/Paper858/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper858/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Omnibus Dropout for Improving The Probabilistic Classification Outputs of ConvNets", "authors": ["Zhilu Zhang", "Adrian V. Dalca", "Mert R. Sabuncu"], "authorids": ["zz452@cornell.edu", "adalca@mit.edu", "msabuncu@cornell.edu"], "keywords": ["Uncertainty Estimation", "Calibration", "Deep Learning"], "TL;DR": "We propose to combine structured dropout methods at different scales for improved model diversity and performance of dropout uncertainty estimates.", "abstract": "While neural network models achieve impressive classification accuracy across different tasks, they can suffer from poor calibration of their probabilistic predictions. A Bayesian perspective has recently suggested that dropout, a regularization strategy popularly used during training, can be employed to obtain better probabilistic predictions at test time (Gal & Ghahramani, 2016a). However, empirical results so far have not been encouraging, particularly with convolutional networks. In this paper, through the lens of ensemble learning, we associate this unsatisfactory performance with the correlation between the models sampled with dropout. Motivated by this, we explore the use of various structured dropout techniques to promote model diversity and improve the quality of probabilistic predictions. We also propose an omnibus dropout strategy that combines various structured dropout methods. Using the SVHN, CIFAR-10 and CIFAR-100 datasets, we empirically demonstrate the superior performance of omnibus dropout relative to several widely used strong baselines in addition to regular dropout. Lastly, we show the merit of omnibus dropout in a Bayesian active learning application. ", "pdf": "/pdf/11d4d33cbcafdbe85c3348375475f71d62e69311.pdf", "paperhash": "zhang|omnibus_dropout_for_improving_the_probabilistic_classification_outputs_of_convnets", "original_pdf": "/attachment/11d4d33cbcafdbe85c3348375475f71d62e69311.pdf", "_bibtex": "@misc{\nzhang2020omnibus,\ntitle={Omnibus Dropout for Improving The Probabilistic Classification Outputs of ConvNets},\nauthor={Zhilu Zhang and Adrian V. Dalca and Mert R. Sabuncu},\nyear={2020},\nurl={https://openreview.net/forum?id=ryxPRpEtvH}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "ryxPRpEtvH", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper858/Authors", "ICLR.cc/2020/Conference/Paper858/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper858/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper858/Reviewers", "ICLR.cc/2020/Conference/Paper858/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper858/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper858/Authors|ICLR.cc/2020/Conference/Paper858/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504165122, "tmdate": 1576860557627, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper858/Authors", "ICLR.cc/2020/Conference/Paper858/Reviewers", "ICLR.cc/2020/Conference/Paper858/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper858/-/Official_Comment"}}}, {"id": "SygvvWEsiS", "original": null, "number": 6, "cdate": 1573761375492, "ddate": null, "tcdate": 1573761375492, "tmdate": 1573761495942, "tddate": null, "forum": "ryxPRpEtvH", "replyto": "ByxUkcTRtS", "invitation": "ICLR.cc/2020/Conference/Paper858/-/Official_Comment", "content": {"title": "Response to Reviewer #1", "comment": "We would like to thank you for taking precious time to review our paper.\n\nFirstly, we would like to address your main concern regarding the technical novelty of the paper. While we do agree that the proposed method of omnibus dropout is simple, we believe that the paper provides several significant contributions to the field of uncertainty estimation for deep learning as listed below.\n1. While it was previously discovered empirically that deep ensembles lead to better uncertainty estimates compared to MC dropout, no justification had been given to explain the surprising observation that, even a simple frequentist approach of ensembling 5 neural networks can outperform some of the Bayesian approaches like MC dropout. In this paper, we attribute the lackluster performance of MC dropout to the lack of diversity in the predictions of models sampled through dropout. This is a novel perspective.\n2. Although structured dropout techniques are widely used as regularization techniques to improve the accuracy of neural networks, they are not adopted for uncertainty estimation at all. In this paper, together with the theoretical justification based on ensemble diversity, we demonstrate the merit of using structured dropout methods at test time to obtain better uncertainty estimations as well.\n3. Empirically we found that different structured dropout techniques have variable performance for different datasets and architectures, and searching for the best one can be expensive. We provide a simple solution which combines different kinds of dropout. We empirically demonstrate that this omnibus strategy yields state-of-the-art performance compared to widely used baselines for uncertainty estimates like temperature scaling, deep ensemble, and regular MC dropout.\n\nResponse to specific questions:\n1. We will modify the text to make the first two paragraphs flow more naturally. To clarify, we mention \u201censembled networks\u201d in the second paragraph as it was previously demonstrated that ensembling improves calibration performance as well, which is the main focus of our paper.\n2. While we do agree that comparing an explicit ensemble of 5 models with 30 sampled models through dropout at test time may be unfair, this has been a widely adopted approach for comparison in the literature. Moreover,\u00a0despite the fact that the proposed method incurs 6 times more time complexity during test time, we would like to highlight that our proposed method (and the baseline of MC dropout) is 5 times cheaper during training\u00a0 and also 5 times cheaper in terms of memory demand as only one model needs to be saved and loaded instead of 5.\n3. We did not incorporate experiments with deep ensembles in the active learning experiments. We will include it in the updated version of the paper."}, "signatures": ["ICLR.cc/2020/Conference/Paper858/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper858/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Omnibus Dropout for Improving The Probabilistic Classification Outputs of ConvNets", "authors": ["Zhilu Zhang", "Adrian V. Dalca", "Mert R. Sabuncu"], "authorids": ["zz452@cornell.edu", "adalca@mit.edu", "msabuncu@cornell.edu"], "keywords": ["Uncertainty Estimation", "Calibration", "Deep Learning"], "TL;DR": "We propose to combine structured dropout methods at different scales for improved model diversity and performance of dropout uncertainty estimates.", "abstract": "While neural network models achieve impressive classification accuracy across different tasks, they can suffer from poor calibration of their probabilistic predictions. A Bayesian perspective has recently suggested that dropout, a regularization strategy popularly used during training, can be employed to obtain better probabilistic predictions at test time (Gal & Ghahramani, 2016a). However, empirical results so far have not been encouraging, particularly with convolutional networks. In this paper, through the lens of ensemble learning, we associate this unsatisfactory performance with the correlation between the models sampled with dropout. Motivated by this, we explore the use of various structured dropout techniques to promote model diversity and improve the quality of probabilistic predictions. We also propose an omnibus dropout strategy that combines various structured dropout methods. Using the SVHN, CIFAR-10 and CIFAR-100 datasets, we empirically demonstrate the superior performance of omnibus dropout relative to several widely used strong baselines in addition to regular dropout. Lastly, we show the merit of omnibus dropout in a Bayesian active learning application. ", "pdf": "/pdf/11d4d33cbcafdbe85c3348375475f71d62e69311.pdf", "paperhash": "zhang|omnibus_dropout_for_improving_the_probabilistic_classification_outputs_of_convnets", "original_pdf": "/attachment/11d4d33cbcafdbe85c3348375475f71d62e69311.pdf", "_bibtex": "@misc{\nzhang2020omnibus,\ntitle={Omnibus Dropout for Improving The Probabilistic Classification Outputs of ConvNets},\nauthor={Zhilu Zhang and Adrian V. Dalca and Mert R. Sabuncu},\nyear={2020},\nurl={https://openreview.net/forum?id=ryxPRpEtvH}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "ryxPRpEtvH", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper858/Authors", "ICLR.cc/2020/Conference/Paper858/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper858/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper858/Reviewers", "ICLR.cc/2020/Conference/Paper858/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper858/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper858/Authors|ICLR.cc/2020/Conference/Paper858/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504165122, "tmdate": 1576860557627, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper858/Authors", "ICLR.cc/2020/Conference/Paper858/Reviewers", "ICLR.cc/2020/Conference/Paper858/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper858/-/Official_Comment"}}}, {"id": "Hkl9f4ilir", "original": null, "number": 3, "cdate": 1573069842032, "ddate": null, "tcdate": 1573069842032, "tmdate": 1573069842032, "tddate": null, "forum": "ryxPRpEtvH", "replyto": "ryxPRpEtvH", "invitation": "ICLR.cc/2020/Conference/Paper858/-/Official_Review", "content": {"experience_assessment": "I have read many papers in this area.", "rating": "1: Reject", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "title": "Official Blind Review #4", "review": "Summary of the paper:\nThe paper tackles the probabilistic classification problem which is interesting and important in deep learning. The paper proposes an approach called omnibus dropout. Omnibus dropout is a sequential execution of existing dropout techniques such as drop layer, drop channel, drop block and regular dropout. The experimental results suggest that omnibus dropout perform reasonably well in various datasets.\n\nPros:\n1. The proposed approach is reasonable which I found no surprising it produces reasonably well results.\n\nCons:\n1. The paper could be improved in writing, especially on justification why this kind of dropout combination gives better performance. \n2. The results are mixed and the improvements are not significant. So I am not convinced the proposed approach is always a better strategy.\n3. The proposed approach is simply a combination of the existing dropout methods. The contribution of the paper is very limited.\n\nQuestions:\n1. In table 1, different dropout rate is chosen for different method. I think it is also reasonable to compare different methods with the same dropout rate (basically this corresponds to the actual model capacity).", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory."}, "signatures": ["ICLR.cc/2020/Conference/Paper858/AnonReviewer4"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper858/AnonReviewer4"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Omnibus Dropout for Improving The Probabilistic Classification Outputs of ConvNets", "authors": ["Zhilu Zhang", "Adrian V. Dalca", "Mert R. Sabuncu"], "authorids": ["zz452@cornell.edu", "adalca@mit.edu", "msabuncu@cornell.edu"], "keywords": ["Uncertainty Estimation", "Calibration", "Deep Learning"], "TL;DR": "We propose to combine structured dropout methods at different scales for improved model diversity and performance of dropout uncertainty estimates.", "abstract": "While neural network models achieve impressive classification accuracy across different tasks, they can suffer from poor calibration of their probabilistic predictions. A Bayesian perspective has recently suggested that dropout, a regularization strategy popularly used during training, can be employed to obtain better probabilistic predictions at test time (Gal & Ghahramani, 2016a). However, empirical results so far have not been encouraging, particularly with convolutional networks. In this paper, through the lens of ensemble learning, we associate this unsatisfactory performance with the correlation between the models sampled with dropout. Motivated by this, we explore the use of various structured dropout techniques to promote model diversity and improve the quality of probabilistic predictions. We also propose an omnibus dropout strategy that combines various structured dropout methods. Using the SVHN, CIFAR-10 and CIFAR-100 datasets, we empirically demonstrate the superior performance of omnibus dropout relative to several widely used strong baselines in addition to regular dropout. Lastly, we show the merit of omnibus dropout in a Bayesian active learning application. ", "pdf": "/pdf/11d4d33cbcafdbe85c3348375475f71d62e69311.pdf", "paperhash": "zhang|omnibus_dropout_for_improving_the_probabilistic_classification_outputs_of_convnets", "original_pdf": "/attachment/11d4d33cbcafdbe85c3348375475f71d62e69311.pdf", "_bibtex": "@misc{\nzhang2020omnibus,\ntitle={Omnibus Dropout for Improving The Probabilistic Classification Outputs of ConvNets},\nauthor={Zhilu Zhang and Adrian V. Dalca and Mert R. Sabuncu},\nyear={2020},\nurl={https://openreview.net/forum?id=ryxPRpEtvH}\n}"}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "ryxPRpEtvH", "replyto": "ryxPRpEtvH", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper858/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper858/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1576036443552, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper858/Reviewers"], "noninvitees": [], "tcdate": 1570237745963, "tmdate": 1576036443564, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper858/-/Official_Review"}}}, {"id": "H1g0Jtez5S", "original": null, "number": 2, "cdate": 1572108518296, "ddate": null, "tcdate": 1572108518296, "tmdate": 1572972543376, "tddate": null, "forum": "ryxPRpEtvH", "replyto": "ryxPRpEtvH", "invitation": "ICLR.cc/2020/Conference/Paper858/-/Official_Review", "content": {"experience_assessment": "I have published in this field for several years.", "rating": "1: Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #3", "review_assessment:_checking_correctness_of_derivations_and_theory": "N/A", "review": "PAPER SUMMARY: The paper argues that (ensembles of models with different types of dropout applied to each model) perform better than (ensembles in which the same type of dropout is applied to each model). They attribute this to increasing model diversity in the former case, and experimentally validate their claims.\n\nMAJOR COMMENTS: \n1. Motivation Unclear:\n- Notational issues in (2): MSE(h_t | x) involves y, but y is not specified in the definition. As a result, later E_{x}[\u2026] is evaluated disregarding the dependence on y, which is ambiguous. \n- Derivation of the second equality in (2) is not obvious, and needs a detailed proof. Notational issues exist in switching between H and h.\n- The above is used to argue that \u201cthe more diverse the models, the better performance achieved\u201d. It is unclear how this follows from (2).\n\n2. Unclear / Imprecise Writing\n- Before Sec. 3.4:  \u201cThis is because higher Dropout rates lead to smaller effective network capacities\u201d Needs reference. \n- \u201cDropout uncertainty can be obtained sequentially\u201d. Unclear what this means.\n\n3. The entire proposed method is described in one line, \u201cwe propose a novel omnibus dropout strategy, which merely combines all the aforementioned methods\u201d. It is very unclear as to what the authors mean by combination.\n\n4. Experiments\n- It seems that Omnibus dropout leads to a moderate \u201cdiversity\u201d, and improves ensemble performance only for SVHN, out of the three datasets tested in Figure 4. For SVHN, the improvement is 0.1% accuracy, which is within the standard error (0.1). Hence, it seems that the proposed method provides no performance improvement.\n- A Similar statement is true for the other metrics (NLL, Brier Score, ECE). \n\nScore [Scale of 1-10]:\n3: Reject\nThe paper needs either more convincing experiments demonstrating the claims or theoretical analysis explaining the behavior for small networks. The paper needs to be rewritten to improve presentation, and state motivation, problem statement, and contributions clearly. \n"}, "signatures": ["ICLR.cc/2020/Conference/Paper858/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper858/AnonReviewer3"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Omnibus Dropout for Improving The Probabilistic Classification Outputs of ConvNets", "authors": ["Zhilu Zhang", "Adrian V. Dalca", "Mert R. Sabuncu"], "authorids": ["zz452@cornell.edu", "adalca@mit.edu", "msabuncu@cornell.edu"], "keywords": ["Uncertainty Estimation", "Calibration", "Deep Learning"], "TL;DR": "We propose to combine structured dropout methods at different scales for improved model diversity and performance of dropout uncertainty estimates.", "abstract": "While neural network models achieve impressive classification accuracy across different tasks, they can suffer from poor calibration of their probabilistic predictions. A Bayesian perspective has recently suggested that dropout, a regularization strategy popularly used during training, can be employed to obtain better probabilistic predictions at test time (Gal & Ghahramani, 2016a). However, empirical results so far have not been encouraging, particularly with convolutional networks. In this paper, through the lens of ensemble learning, we associate this unsatisfactory performance with the correlation between the models sampled with dropout. Motivated by this, we explore the use of various structured dropout techniques to promote model diversity and improve the quality of probabilistic predictions. We also propose an omnibus dropout strategy that combines various structured dropout methods. Using the SVHN, CIFAR-10 and CIFAR-100 datasets, we empirically demonstrate the superior performance of omnibus dropout relative to several widely used strong baselines in addition to regular dropout. Lastly, we show the merit of omnibus dropout in a Bayesian active learning application. ", "pdf": "/pdf/11d4d33cbcafdbe85c3348375475f71d62e69311.pdf", "paperhash": "zhang|omnibus_dropout_for_improving_the_probabilistic_classification_outputs_of_convnets", "original_pdf": "/attachment/11d4d33cbcafdbe85c3348375475f71d62e69311.pdf", "_bibtex": "@misc{\nzhang2020omnibus,\ntitle={Omnibus Dropout for Improving The Probabilistic Classification Outputs of ConvNets},\nauthor={Zhilu Zhang and Adrian V. Dalca and Mert R. Sabuncu},\nyear={2020},\nurl={https://openreview.net/forum?id=ryxPRpEtvH}\n}"}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "ryxPRpEtvH", "replyto": "ryxPRpEtvH", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper858/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper858/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1576036443552, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper858/Reviewers"], "noninvitees": [], "tcdate": 1570237745963, "tmdate": 1576036443564, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper858/-/Official_Review"}}}], "count": 8}