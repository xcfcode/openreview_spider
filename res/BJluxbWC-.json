{"notes": [{"tddate": null, "ddate": null, "tmdate": 1518730170247, "tcdate": 1509130344189, "number": 643, "cdate": 1518730170236, "id": "BJluxbWC-", "invitation": "ICLR.cc/2018/Conference/-/Blind_Submission", "forum": "BJluxbWC-", "original": "ByQve-bCb", "signatures": ["ICLR.cc/2018/Conference"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Conference"], "content": {"title": "Unseen Class Discovery in Open-world Classification", "abstract": "This paper concerns open-world classification, where the classifier not only needs to classify test examples into seen classes that have appeared in training but also reject examples from unseen or novel classes that have not appeared in training. Specifically, this paper focuses on discovering the hidden unseen classes of the rejected examples. Clearly, without prior knowledge this is difficult. However, we do have the data from the seen training classes, which can tell us what kind of similarity/difference is expected for examples from the same class or from different classes. It is reasonable to assume that this knowledge can be transferred to the rejected examples and used to discover the hidden unseen classes in them. This paper aims to solve this problem. It first proposes a joint open classification model with a sub-model for classifying whether a pair of examples belongs to the same or different classes. This sub-model can serve as a distance function for clustering to discover the hidden classes of the rejected examples. Experimental results show that the proposed model is highly promising.\n", "pdf": "/pdf/1834d6f3c93c2efadd23527fbd64e45f7061fa02.pdf", "paperhash": "shu|unseen_class_discovery_in_openworld_classification", "_bibtex": "@misc{\nshu2018unseen,\ntitle={Unseen Class Discovery in Open-world Classification},\nauthor={Lei Shu and Hu Xu and Bing Liu},\nyear={2018},\nurl={https://openreview.net/forum?id=BJluxbWC-},\n}", "keywords": [], "authors": ["Lei Shu", "Hu Xu", "Bing Liu"], "authorids": ["lshu3@uic.edu", "hxu48@uic.edu", "liub@uic.edu"]}, "nonreaders": [], "details": {"replyCount": 4, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "tmdate": 1506717071958, "id": "ICLR.cc/2018/Conference/-/Blind_Submission", "writers": ["ICLR.cc/2018/Conference"], "signatures": ["ICLR.cc/2018/Conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2018/Conference"], "reply": {"forum": null, "replyto": null, "writers": {"values": ["ICLR.cc/2018/Conference"]}, "signatures": {"description": "How your identity will be displayed with the above content.", "values": ["ICLR.cc/2018/Conference"]}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"authors": {"required": false, "order": 1, "values-regex": ".*", "description": "Comma separated list of author names, as they appear in the paper."}, "authorids": {"required": false, "order": 2, "values-regex": ".*", "description": "Comma separated list of author email addresses, in the same order as above."}}}, "nonreaders": [], "noninvitees": [], "cdate": 1506717071958}}, "tauthor": "ICLR.cc/2018/Conference"}, {"tddate": null, "ddate": null, "original": null, "tmdate": 1517260083238, "tcdate": 1517249961129, "number": 650, "cdate": 1517249961117, "id": "SkbnHy6rf", "invitation": "ICLR.cc/2018/Conference/-/Acceptance_Decision", "forum": "BJluxbWC-", "replyto": "BJluxbWC-", "signatures": ["ICLR.cc/2018/Conference/Program_Chairs"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Conference/Program_Chairs"], "content": {"decision": "Reject", "title": "ICLR 2018 Conference Acceptance Decision", "comment": "Three reviewers recommended rejection and there was no rebuttal to overturn their recommendation."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Unseen Class Discovery in Open-world Classification", "abstract": "This paper concerns open-world classification, where the classifier not only needs to classify test examples into seen classes that have appeared in training but also reject examples from unseen or novel classes that have not appeared in training. Specifically, this paper focuses on discovering the hidden unseen classes of the rejected examples. Clearly, without prior knowledge this is difficult. However, we do have the data from the seen training classes, which can tell us what kind of similarity/difference is expected for examples from the same class or from different classes. It is reasonable to assume that this knowledge can be transferred to the rejected examples and used to discover the hidden unseen classes in them. This paper aims to solve this problem. It first proposes a joint open classification model with a sub-model for classifying whether a pair of examples belongs to the same or different classes. This sub-model can serve as a distance function for clustering to discover the hidden classes of the rejected examples. Experimental results show that the proposed model is highly promising.\n", "pdf": "/pdf/1834d6f3c93c2efadd23527fbd64e45f7061fa02.pdf", "paperhash": "shu|unseen_class_discovery_in_openworld_classification", "_bibtex": "@misc{\nshu2018unseen,\ntitle={Unseen Class Discovery in Open-world Classification},\nauthor={Lei Shu and Hu Xu and Bing Liu},\nyear={2018},\nurl={https://openreview.net/forum?id=BJluxbWC-},\n}", "keywords": [], "authors": ["Lei Shu", "Hu Xu", "Bing Liu"], "authorids": ["lshu3@uic.edu", "hxu48@uic.edu", "liub@uic.edu"]}, "tags": [], "invitation": {"id": "ICLR.cc/2018/Conference/-/Acceptance_Decision", "rdate": null, "ddate": null, "expdate": 1541175629000, "duedate": null, "tmdate": 1541177635767, "tddate": null, "super": null, "final": null, "reply": {"forum": null, "replyto": null, "invitation": "ICLR.cc/2018/Conference/-/Blind_Submission", "writers": {"values": ["ICLR.cc/2018/Conference/Program_Chairs"]}, "signatures": {"description": "How your identity will be displayed with the above content.", "values": ["ICLR.cc/2018/Conference/Program_Chairs"]}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["ICLR.cc/2018/Conference/Program_Chairs", "everyone"]}, "content": {"title": {"required": true, "order": 1, "value": "ICLR 2018 Conference Acceptance Decision"}, "comment": {"required": false, "order": 3, "description": "(optional) Comment on this decision.", "value-regex": "[\\S\\s]{0,5000}"}, "decision": {"required": true, "order": 2, "value-dropdown": ["Accept (Oral)", "Accept (Poster)", "Reject", "Invite to Workshop Track"]}}}, "signatures": ["ICLR.cc/2018/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": [], "noninvitees": [], "writers": ["ICLR.cc/2018/Conference"], "multiReply": null, "taskCompletionCount": null, "transform": null, "cdate": 1541177635767}}}, {"tddate": null, "ddate": null, "original": null, "tmdate": 1515642484625, "tcdate": 1511430393333, "number": 1, "cdate": 1511430393333, "id": "HkWZFMVxf", "invitation": "ICLR.cc/2018/Conference/-/Paper643/Official_Review", "forum": "BJluxbWC-", "replyto": "BJluxbWC-", "signatures": ["ICLR.cc/2018/Conference/Paper643/AnonReviewer1"], "readers": ["everyone"], "content": {"title": "Interesting idea, yet should be explored more extensively", "rating": "5: Marginally below acceptance threshold", "review": "The main goal of this paper is to cluster images from classes unseen during training.\nThis is an interesting extension of the open-world paradigm, where at test time, the classifier has to identify images beloning to the C seen classes during training, but also identify (reject) images which were previously unseen. These rejected images could be clustered to identify the number of unseen classes; either for revealing the underlying structure of the unseen classes, or to reduce annotation costs.\n\nIn order to do so, an extensive framework is proposed, consisting of 3 ConvNet architectures, followed by a hierarchical clustering approach. The 3 ConvNets all have a different goal:\n1. an Open Classification Network (per class sigmoid, trained 1vsRest, with thresholds for rejection)\n2. Pairwise Classification Network, (binary sigmoid, trained on pairs of images of same/different classes)\n3. Auto encoder network\n\nThese network are jointly trained, and the joint-loss is simply the addition of a cross-entropy loss (from OCN), the binary cross-entropy loss (from PCN) and a pixel wise loss (from AE). \nRemarks:\n- it is unclear if the ConvNet weights of the first layers are shared). \n- it is unclear how joint training might help, given that the objectives do not influence each other\n- Eq 1: \n  *label \"y_i\" has two different semantics (L_ocn it is the class label, while in L_pcn it is the label of an image pair being from the same class or not)\n  * s_j is undefined\n  * relation between the p(y_i = 1) (in PCN) and g(x_p,x_q) in Eq 2 could be made more explicit, PCN depends on two images, according to Eq 1, it seems just a sum over single images.\n- It is unclear why the Auto Encoder network is added, and what its function is.\n- It is unclear wether OCN requires/uses unseen class examples during training.\n- Last paragraph of 3.1 \"The 1-vs-rest ... rejected\", I don't see why you need 1vsRest classifiers for this, a multi-class (softmax) output can also be thresholded to reject an test image from the known classes and to assign it to the unknown class.\n\n\nExperimental evaluation\nThe experimental evaluation uses 2 datasets, MNIST and EMNIST, both are very specific for character recognition. It is a pity that not also more general image classification has been considered (CIFAR100, ImageNet, Places365, etc), that would provide insights to the more general behaviour of the proposed ideas.\n\nMy major concern is that the clustering task is not extensively explored. Just a single setting (with a single random sampling of seen/unseen classes) has been evaluated. This is -in part- due to the nature of the chosen datasets, in a 10 class dataset it is difficult to show the influence of the number of unseen classes. So, I'd really urge the authors to extend this evaluation. Will the method discover more classes when 100 unknown classes are used? What kind of clusters are discovered? Are the types of classes in the seen/unseen classes important, I'd expect at least multiple runs of the current experiments on (E)MNIST. \n\nFurther, I miss some baselines and ablation study. Questions which I'd like to seen answered: how good is the OCN representation when used for clustering compared to the PCN representation? What is the benefit of joint-training? How important is the AE in the loss?\n\nRemaining remarks\n- Just a very simple / non-standard ConvNet architecture is trained. Will a ResNet(32) show similar performance?\n- In Eq 4, |C_i || y_j| seems a strange notation for union.\n\nConclusion\nThis paper brings in an interesting idea, is it possible to cluster the unseen classes in an open-world classification scenario?  A solution using a pairwise convnet followed by hierarchical clustering is proposed. This is a plausible solution, yet in total I miss an exploration of the solution. \n\nBoth in terms of general visual classification (only MNIST is used, while it would be nice to see results on CIFAR and/or ImageNet as in Bendale&Boult 2016), as in exploration of different scenarios (different number of unseen classes, different samplings) and ablation of the method (independent training, using OCN for hierarchical clustering, influence of Auto Encoder). Therefore, I rate this paper as a (weak) reject: it is just not (yet) good enough for acceptance.", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "writers": [], "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Unseen Class Discovery in Open-world Classification", "abstract": "This paper concerns open-world classification, where the classifier not only needs to classify test examples into seen classes that have appeared in training but also reject examples from unseen or novel classes that have not appeared in training. Specifically, this paper focuses on discovering the hidden unseen classes of the rejected examples. Clearly, without prior knowledge this is difficult. However, we do have the data from the seen training classes, which can tell us what kind of similarity/difference is expected for examples from the same class or from different classes. It is reasonable to assume that this knowledge can be transferred to the rejected examples and used to discover the hidden unseen classes in them. This paper aims to solve this problem. It first proposes a joint open classification model with a sub-model for classifying whether a pair of examples belongs to the same or different classes. This sub-model can serve as a distance function for clustering to discover the hidden classes of the rejected examples. Experimental results show that the proposed model is highly promising.\n", "pdf": "/pdf/1834d6f3c93c2efadd23527fbd64e45f7061fa02.pdf", "paperhash": "shu|unseen_class_discovery_in_openworld_classification", "_bibtex": "@misc{\nshu2018unseen,\ntitle={Unseen Class Discovery in Open-world Classification},\nauthor={Lei Shu and Hu Xu and Bing Liu},\nyear={2018},\nurl={https://openreview.net/forum?id=BJluxbWC-},\n}", "keywords": [], "authors": ["Lei Shu", "Hu Xu", "Bing Liu"], "authorids": ["lshu3@uic.edu", "hxu48@uic.edu", "liub@uic.edu"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1511845199000, "tmdate": 1515642484528, "id": "ICLR.cc/2018/Conference/-/Paper643/Official_Review", "writers": ["ICLR.cc/2018/Conference"], "signatures": ["ICLR.cc/2018/Conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2018/Conference/Paper643/Reviewers"], "noninvitees": ["ICLR.cc/2018/Conference/Paper643/AnonReviewer1", "ICLR.cc/2018/Conference/Paper643/AnonReviewer3", "ICLR.cc/2018/Conference/Paper643/AnonReviewer2"], "reply": {"forum": "BJluxbWC-", "replyto": "BJluxbWC-", "writers": {"values": []}, "signatures": {"values-regex": "ICLR.cc/2018/Conference/Paper643/AnonReviewer[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"required": true, "order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"required": true, "order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "value-regex": "[\\S\\s]{1,200000}"}, "rating": {"required": true, "order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"required": true, "order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1519621199000, "cdate": 1515642484528}}}, {"tddate": null, "ddate": null, "original": null, "tmdate": 1515642484580, "tcdate": 1511628308301, "number": 2, "cdate": 1511628308301, "id": "ry2G0fvxM", "invitation": "ICLR.cc/2018/Conference/-/Paper643/Official_Review", "forum": "BJluxbWC-", "replyto": "BJluxbWC-", "signatures": ["ICLR.cc/2018/Conference/Paper643/AnonReviewer3"], "readers": ["everyone"], "content": {"title": "targeting a synthesized problem", "rating": "5: Marginally below acceptance threshold", "review": "This paper concerns open-world classification.  The open-world related tasks have been defined in many previous works. This paper had made a good survey. \nThe only special point of the open-word classification task defined in this paper is to employ the constraints from the similarity/difference expected for examples from the same class or from different classes.  Unfortunately, this paper is lack of novelty. \n\nFirstly, the problem context and setting is kinda synthesized. I cannot quite imagine in what kind of applications we can get \u201ca set of pairs of intra-class (same class) examples, and the negative training data consists of a set of pairs of inter-class\u201d.\n\nSecondly, this model is just a direct combination of the recent powerful algorithms such as DOC and other simple traditional models. I do not really see enough novelty here.\n\nThirdly, the experiments are only on the MNIST and EMNIST; still not quite sure any real-world problems/datasets can be used to validate this approach.\nI also cannot see the promising performance. The clustering results of rejected\nexamples are still far from the ground truth, and comparing the result with\na total unsupervised K-means is a kind of unreasonable.\n", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}, "writers": [], "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Unseen Class Discovery in Open-world Classification", "abstract": "This paper concerns open-world classification, where the classifier not only needs to classify test examples into seen classes that have appeared in training but also reject examples from unseen or novel classes that have not appeared in training. Specifically, this paper focuses on discovering the hidden unseen classes of the rejected examples. Clearly, without prior knowledge this is difficult. However, we do have the data from the seen training classes, which can tell us what kind of similarity/difference is expected for examples from the same class or from different classes. It is reasonable to assume that this knowledge can be transferred to the rejected examples and used to discover the hidden unseen classes in them. This paper aims to solve this problem. It first proposes a joint open classification model with a sub-model for classifying whether a pair of examples belongs to the same or different classes. This sub-model can serve as a distance function for clustering to discover the hidden classes of the rejected examples. Experimental results show that the proposed model is highly promising.\n", "pdf": "/pdf/1834d6f3c93c2efadd23527fbd64e45f7061fa02.pdf", "paperhash": "shu|unseen_class_discovery_in_openworld_classification", "_bibtex": "@misc{\nshu2018unseen,\ntitle={Unseen Class Discovery in Open-world Classification},\nauthor={Lei Shu and Hu Xu and Bing Liu},\nyear={2018},\nurl={https://openreview.net/forum?id=BJluxbWC-},\n}", "keywords": [], "authors": ["Lei Shu", "Hu Xu", "Bing Liu"], "authorids": ["lshu3@uic.edu", "hxu48@uic.edu", "liub@uic.edu"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1511845199000, "tmdate": 1515642484528, "id": "ICLR.cc/2018/Conference/-/Paper643/Official_Review", "writers": ["ICLR.cc/2018/Conference"], "signatures": ["ICLR.cc/2018/Conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2018/Conference/Paper643/Reviewers"], "noninvitees": ["ICLR.cc/2018/Conference/Paper643/AnonReviewer1", "ICLR.cc/2018/Conference/Paper643/AnonReviewer3", "ICLR.cc/2018/Conference/Paper643/AnonReviewer2"], "reply": {"forum": "BJluxbWC-", "replyto": "BJluxbWC-", "writers": {"values": []}, "signatures": {"values-regex": "ICLR.cc/2018/Conference/Paper643/AnonReviewer[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"required": true, "order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"required": true, "order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "value-regex": "[\\S\\s]{1,200000}"}, "rating": {"required": true, "order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"required": true, "order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1519621199000, "cdate": 1515642484528}}}, {"tddate": null, "ddate": null, "original": null, "tmdate": 1515642484543, "tcdate": 1511827105069, "number": 3, "cdate": 1511827105069, "id": "HkFsIQclG", "invitation": "ICLR.cc/2018/Conference/-/Paper643/Official_Review", "forum": "BJluxbWC-", "replyto": "BJluxbWC-", "signatures": ["ICLR.cc/2018/Conference/Paper643/AnonReviewer2"], "readers": ["everyone"], "content": {"title": "Interesting idea on transferring the similarity function learned from known classes but it basically seems like a clustering paper with limited empirical evidence of its value.", "rating": "4: Ok but not good enough - rejection", "review": "This paper focuses on the sub-problem of discovering previously unseen classes for open-world classification. \nIt employs a previously proposed system, Open Classification Network, for classifying instances into known classes or rejecting as belonging to an unseen class, and applies hierarchical clustering to the rejected instances to identify unseen classes.\nThe key novel idea is to learn a pairwise similarity function using the examples from the known classes to apply to examples of unknown classes. The argument is that we tend to use the same notion of similarity and dissimilarity to define classes (known or unknown) and one can thus expect the similarity function learned from known classes to carry over to the unknown classes.  This concept is not new. Similar idea has been explored in early 2000 by Finley and Joachims in their ICML paper titled \"Supervised Clustering with Support Vector Machines\".  But to the best of my knowledge, this is the first paper that applies this concept to the open world classification task. \n\nOnce we learn the similarity function, the rest of the approach is straightforward, without any particular technical ingenuity.  It simply applies hierarchical clustering on the learned similarities and use cross-validation to pick a stopping condition for deciding the number of clusters.  \nI find the experiments to be limited, only on two hand-written digits/letters datasets.  Such datasets are too simplistic. For example, simply applying kmeans to PCA features of the images on the MNIST data can get you pretty good performance.  \nExperiments on more complex data is desired, for example on Imagenet classes. \n\nAlso the results do not clearly demonstrate the advantage of the proposed method, in particular the benefit of using PCN. The number of clusters found by the algorithm is not particularly accurate and the NMI values obtained by the proposed approach does not show any clear advantage over baseline methods that do not use PCN. \n\nSome minor comments:\nWhen applied to the rejected examples, wouldn't the ground truth # of clusters no longer be 4 or 10 because there are some known-class examples mixed in? \nFor the base line Encoder+HC, was the encoder trained independently? Or it's trained jointly with PCN and OCN?  It is interesting to see the impact of incorporating PCN into the training of OCN and encoder. Does that have any impact on accuracy of OCN? \nIt seems that one of the claimed benefit is that the proposed method is effective at identifying the k. If so, it would be necessary to compared the proposed method to some classic methods for identifying k with kmeans, such as the elbow method, BIC, G-means etc, especially since kmeans seem to give much better NMI values.\n\n\n", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "writers": [], "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Unseen Class Discovery in Open-world Classification", "abstract": "This paper concerns open-world classification, where the classifier not only needs to classify test examples into seen classes that have appeared in training but also reject examples from unseen or novel classes that have not appeared in training. Specifically, this paper focuses on discovering the hidden unseen classes of the rejected examples. Clearly, without prior knowledge this is difficult. However, we do have the data from the seen training classes, which can tell us what kind of similarity/difference is expected for examples from the same class or from different classes. It is reasonable to assume that this knowledge can be transferred to the rejected examples and used to discover the hidden unseen classes in them. This paper aims to solve this problem. It first proposes a joint open classification model with a sub-model for classifying whether a pair of examples belongs to the same or different classes. This sub-model can serve as a distance function for clustering to discover the hidden classes of the rejected examples. Experimental results show that the proposed model is highly promising.\n", "pdf": "/pdf/1834d6f3c93c2efadd23527fbd64e45f7061fa02.pdf", "paperhash": "shu|unseen_class_discovery_in_openworld_classification", "_bibtex": "@misc{\nshu2018unseen,\ntitle={Unseen Class Discovery in Open-world Classification},\nauthor={Lei Shu and Hu Xu and Bing Liu},\nyear={2018},\nurl={https://openreview.net/forum?id=BJluxbWC-},\n}", "keywords": [], "authors": ["Lei Shu", "Hu Xu", "Bing Liu"], "authorids": ["lshu3@uic.edu", "hxu48@uic.edu", "liub@uic.edu"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1511845199000, "tmdate": 1515642484528, "id": "ICLR.cc/2018/Conference/-/Paper643/Official_Review", "writers": ["ICLR.cc/2018/Conference"], "signatures": ["ICLR.cc/2018/Conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2018/Conference/Paper643/Reviewers"], "noninvitees": ["ICLR.cc/2018/Conference/Paper643/AnonReviewer1", "ICLR.cc/2018/Conference/Paper643/AnonReviewer3", "ICLR.cc/2018/Conference/Paper643/AnonReviewer2"], "reply": {"forum": "BJluxbWC-", "replyto": "BJluxbWC-", "writers": {"values": []}, "signatures": {"values-regex": "ICLR.cc/2018/Conference/Paper643/AnonReviewer[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"required": true, "order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"required": true, "order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "value-regex": "[\\S\\s]{1,200000}"}, "rating": {"required": true, "order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"required": true, "order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1519621199000, "cdate": 1515642484528}}}], "count": 5}