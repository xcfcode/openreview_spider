{"notes": [{"id": "SJezGp4YPr", "original": "BJewe9KIvS", "number": 403, "cdate": 1569438985576, "ddate": null, "tcdate": 1569438985576, "tmdate": 1583912031457, "tddate": null, "forum": "SJezGp4YPr", "replyto": null, "invitation": "ICLR.cc/2020/Conference/-/Blind_Submission", "content": {"abstract": "While there are convergence guarantees for temporal difference (TD) learning when using linear function approximators, the situation for nonlinear models is far less understood, and divergent examples are known. Here we take a first step towards extending theoretical convergence guarantees to TD learning with nonlinear function approximation. More precisely, we consider the expected learning dynamics of the TD(0) algorithm for value estimation. As the step-size converges to zero, these dynamics are defined by a nonlinear ODE which depends on the geometry of the space of function approximators, the structure of the underlying Markov chain, and their interaction. We find a set of function approximators that includes ReLU networks and has geometry amenable to TD learning regardless of environment, so that the solution performs about as well as linear TD in the worst case. Then, we show how environments that are more reversible induce dynamics that are better for TD learning and prove global convergence to the true value function for well-conditioned function approximators. Finally, we generalize a divergent counterexample to a family of divergent problems to demonstrate how the interaction between approximator and environment can go wrong and to motivate the assumptions needed to prove convergence. ", "title": "Geometric Insights into the Convergence of Nonlinear TD Learning", "keywords": ["TD", "nonlinear", "convergence", "value estimation", "reinforcement learning"], "authors": ["David Brandfonbrener", "Joan Bruna"], "authorids": ["david.brandfonbrener@nyu.edu", "bruna@cims.nyu.edu"], "pdf": "/pdf/c07a4589f711c340b9d0263d05b00df197d9816c.pdf", "paperhash": "brandfonbrener|geometric_insights_into_the_convergence_of_nonlinear_td_learning", "_bibtex": "@inproceedings{\nBrandfonbrener2020Geometric,\ntitle={Geometric Insights into the Convergence of Nonlinear TD Learning},\nauthor={David Brandfonbrener and Joan Bruna},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=SJezGp4YPr}\n}", "full_presentation_video": "", "original_pdf": "/attachment/5e7a051b6e01ed79962a51f143047f2114d362a1.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "signatures": ["ICLR.cc/2020/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference"], "details": {"replyCount": 9, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"reply": {"readers": {"values-regex": ".*"}, "writers": {"values": ["ICLR.cc/2020/Conference"]}, "signatures": {"values": ["ICLR.cc/2020/Conference"]}, "content": {"spotlight_video": {"value-regex": ".*"}, "full_presentation_video": {"value-regex": ".*"}, "original_pdf": {"required": false, "description": "Upload a PDF file that ends with .pdf", "value-regex": ".*"}, "appendix": {"value-regex": ".*"}, "authorids": {"values-regex": ".*"}, "poster": {"value-regex": ".*"}, "authors": {"values": ["Anonymous"]}, "slides": {"value-regex": ".*"}}}, "final": [], "signatures": ["ICLR.cc/2020/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference"], "noninvitees": [], "tcdate": 1569271260237, "tmdate": 1593459412141, "id": "ICLR.cc/2020/Conference/-/Blind_Submission"}}, "tauthor": "ICLR.cc/2020/Conference"}, {"id": "rkRJ3ATVJ", "original": null, "number": 1, "cdate": 1576798695415, "ddate": null, "tcdate": 1576798695415, "tmdate": 1576800940163, "tddate": null, "forum": "SJezGp4YPr", "replyto": "SJezGp4YPr", "invitation": "ICLR.cc/2020/Conference/Paper403/-/Decision", "content": {"decision": "Accept (Poster)", "comment": "This paper takes steps towards a theory of convergence for TD(0) with non-linear function approximation.  The paper provides two theoretical results.  One result bounds the error when training the sum of linear and homogenous parameterized functions.  The second result shows global convergence when the environment dynamics are sufficiently reversible  and the differentiable function approximation is sufficiently well-conditioned.  The paper provides additional insight using a family of environments with partially reversible dynamics.\n\nThe reviewers commented on several aspects of this work.  The reviewers wrote that the presentation was clear and that the topic was relevant.  The reviewers were satisfied with the correctness of the results.  The reviewers liked the result that state value function estimation error is bounded when using homogeneous functions. They also noted that the deep networks in common use are not homogeneous so this result does not apply directly. The result showing global convergence of TD(0) with partial reversibility was also appreciated. Finally, the reviewers liked the family of examples.\n\nThis paper is acceptable for publication as the presentation was clear, the results are solid, and the research direction could lead to additional insights.", "title": "Paper Decision"}, "signatures": ["ICLR.cc/2020/Conference/Program_Chairs"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Program_Chairs"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"abstract": "While there are convergence guarantees for temporal difference (TD) learning when using linear function approximators, the situation for nonlinear models is far less understood, and divergent examples are known. Here we take a first step towards extending theoretical convergence guarantees to TD learning with nonlinear function approximation. More precisely, we consider the expected learning dynamics of the TD(0) algorithm for value estimation. As the step-size converges to zero, these dynamics are defined by a nonlinear ODE which depends on the geometry of the space of function approximators, the structure of the underlying Markov chain, and their interaction. We find a set of function approximators that includes ReLU networks and has geometry amenable to TD learning regardless of environment, so that the solution performs about as well as linear TD in the worst case. Then, we show how environments that are more reversible induce dynamics that are better for TD learning and prove global convergence to the true value function for well-conditioned function approximators. Finally, we generalize a divergent counterexample to a family of divergent problems to demonstrate how the interaction between approximator and environment can go wrong and to motivate the assumptions needed to prove convergence. ", "title": "Geometric Insights into the Convergence of Nonlinear TD Learning", "keywords": ["TD", "nonlinear", "convergence", "value estimation", "reinforcement learning"], "authors": ["David Brandfonbrener", "Joan Bruna"], "authorids": ["david.brandfonbrener@nyu.edu", "bruna@cims.nyu.edu"], "pdf": "/pdf/c07a4589f711c340b9d0263d05b00df197d9816c.pdf", "paperhash": "brandfonbrener|geometric_insights_into_the_convergence_of_nonlinear_td_learning", "_bibtex": "@inproceedings{\nBrandfonbrener2020Geometric,\ntitle={Geometric Insights into the Convergence of Nonlinear TD Learning},\nauthor={David Brandfonbrener and Joan Bruna},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=SJezGp4YPr}\n}", "full_presentation_video": "", "original_pdf": "/attachment/5e7a051b6e01ed79962a51f143047f2114d362a1.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "tags": [], "invitation": {"reply": {"writers": {"description": "How your identity will be displayed.", "values-regex": ["ICLR.cc/2020/Conference/Program_Chairs"]}, "signatures": {"values": ["ICLR.cc/2020/Conference/Program_Chairs"], "description": "How your identity will be displayed."}, "content": {"decision": {"value-radio": ["Accept (Spotlight)", "Accept (Talk)", "Accept (Poster)", "Reject"], "description": "Decision", "required": true, "order": 2}, "title": {"value": "Paper Decision", "required": true, "order": 1}, "comment": {"value-regex": "[\\S\\s]{0,5000}", "description": "", "required": false, "order": 3}}, "forum": "SJezGp4YPr", "replyto": "SJezGp4YPr", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}}, "expdate": 1576854540000, "duedate": 1576853940000, "multiReply": false, "readers": ["everyone"], "invitees": ["ICLR.cc/2020/Conference/Program_Chairs"], "tcdate": 1576795721019, "tmdate": 1576800271964, "super": "ICLR.cc/2020/Conference/-/Decision", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper403/-/Decision"}}}, {"id": "ryxJd6UDiB", "original": null, "number": 7, "cdate": 1573510502865, "ddate": null, "tcdate": 1573510502865, "tmdate": 1573510502865, "tddate": null, "forum": "SJezGp4YPr", "replyto": "rJl4tiBa9S", "invitation": "ICLR.cc/2020/Conference/Paper403/-/Official_Comment", "content": {"title": "response", "comment": "We thank the reviewer for the detailed comments and we will respond to each of the comments in order.\n\nBy neighborhood we mean a set containing the true value function. In this case the set that the approximate value function is attracted to is a ball in the mu-norm with radius B as defined in Theorem 1, which  contains the true value function.\n\nHere we were referring to how sometimes TD is motivated as an approximation to a gradient descent algorithm and in fact is gradient descent in reversible environments. This comparison to gradient descent is a main theme of the paper. We agree that the way this was explained in the sentence in question was confusing though and we will change it in the paper. And to clarify, just because the contraction mapping does not hold uniformly anymore once we add approximation, this does not necessarily imply divergence. \n\nOur point here is not that two timescale algorithms are inherently bad (this would require much stronger evidence), but rather that it is an interesting problem to analyze TD(0) directly. We can remove this clause to prevent confusion. \n\nWe did not want to put all of the definitions into the introduction, so rather put a high level description of the results to come later. We can clarify that here reversibility refers to the MRP in the usual sense of Markov chain reversibility. \n\nAs we said in the footnote, in our setting there is only one policy and thus only one value function to find so we used V^*. V is already used to represent the map from parameters to functions and we did not want to overload notation even more. We also went back and forth on this, would it be better to use V^pi instead of V^* to show that it is the value function of whatever policy induces the transitions?\n\nWe agree this is a little imprecise, we mean that the flows defined by this ODE will converge to a unique equilibrium point regardless of initial conditions. We will make the appropriate update.\n\nWe agree that tabular TD is also gradient descent. We are referring to how the algorithm is defined in Sutton and Barto, as referenced in that sentence. In that book (which is a common reference) the method is called semi-gradient to emphasize that the  and to differentiate it from the gradient TD (GTD) algorithm. \n\nWe agree that the V(theta) notation is non-standard, but our analysis relies on considering the dynamics in the space of function and so we need this mapping from parameters to functions. Tsitsiklis and Van Roy among others use a similar notation. \n\nWe agree that TD is not GD and maybe not even motivated by GD of the squared expected bellman error. Again we are referring to the introduction of the algorithm and discussion in Sutton and Barto. \n\nYes, we mean when the environment is reversible irrespective of the linearity of the function (it could be linear or nonlinear). \n\nSection 2.3 is meant to provide intuition and motivate the results to come. It is not presented as a new result (it is in the \u201cSetup\u201d section of the paper). We think it provides a useful visualization, especially for those less familiar with older papers like Tsitsiklis and Van Roy. \n\nWe agree that this is confusing. The definition is equivalent to the traditional definition of positive homogeneity. See for example: https://en.wikipedia.org/wiki/Homogeneous_function#Positive_homogeneity.  We will clarify this in the paper. Regarding the gradient at 0, reviewer 1 made a similar point, see our D2 in our response to them. \n\nWe agree that these experiments are not so surprising, but the point is just to verify some of the intuitions from the paper not to provide novel empirical results. \n\nWe agree that adding some experimental confirmation of the homogeneity results would be nice, but we are not sure exactly how to provide such evidence. Empirically, we have not seen any non-convergent behavior with homogeneous functions in any toy environments we have constructed. But simply showing some examples where the behavior is good could just mean that we were choosing easy problems. Would it be useful to show that in the same or similar environment as the other experiment we get convergence with simple homogeneous functions?\n\n\n\nWe hope that these changes provide the necessary clarification and ask the reviewer to let us know if anything remains unclear. "}, "signatures": ["ICLR.cc/2020/Conference/Paper403/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper403/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"abstract": "While there are convergence guarantees for temporal difference (TD) learning when using linear function approximators, the situation for nonlinear models is far less understood, and divergent examples are known. Here we take a first step towards extending theoretical convergence guarantees to TD learning with nonlinear function approximation. More precisely, we consider the expected learning dynamics of the TD(0) algorithm for value estimation. As the step-size converges to zero, these dynamics are defined by a nonlinear ODE which depends on the geometry of the space of function approximators, the structure of the underlying Markov chain, and their interaction. We find a set of function approximators that includes ReLU networks and has geometry amenable to TD learning regardless of environment, so that the solution performs about as well as linear TD in the worst case. Then, we show how environments that are more reversible induce dynamics that are better for TD learning and prove global convergence to the true value function for well-conditioned function approximators. Finally, we generalize a divergent counterexample to a family of divergent problems to demonstrate how the interaction between approximator and environment can go wrong and to motivate the assumptions needed to prove convergence. ", "title": "Geometric Insights into the Convergence of Nonlinear TD Learning", "keywords": ["TD", "nonlinear", "convergence", "value estimation", "reinforcement learning"], "authors": ["David Brandfonbrener", "Joan Bruna"], "authorids": ["david.brandfonbrener@nyu.edu", "bruna@cims.nyu.edu"], "pdf": "/pdf/c07a4589f711c340b9d0263d05b00df197d9816c.pdf", "paperhash": "brandfonbrener|geometric_insights_into_the_convergence_of_nonlinear_td_learning", "_bibtex": "@inproceedings{\nBrandfonbrener2020Geometric,\ntitle={Geometric Insights into the Convergence of Nonlinear TD Learning},\nauthor={David Brandfonbrener and Joan Bruna},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=SJezGp4YPr}\n}", "full_presentation_video": "", "original_pdf": "/attachment/5e7a051b6e01ed79962a51f143047f2114d362a1.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "SJezGp4YPr", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper403/Authors", "ICLR.cc/2020/Conference/Paper403/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper403/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper403/Reviewers", "ICLR.cc/2020/Conference/Paper403/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper403/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper403/Authors|ICLR.cc/2020/Conference/Paper403/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504171985, "tmdate": 1576860537393, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper403/Authors", "ICLR.cc/2020/Conference/Paper403/Reviewers", "ICLR.cc/2020/Conference/Paper403/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper403/-/Official_Comment"}}}, {"id": "HJxnrp8DoS", "original": null, "number": 6, "cdate": 1573510468055, "ddate": null, "tcdate": 1573510468055, "tmdate": 1573510468055, "tddate": null, "forum": "SJezGp4YPr", "replyto": "B1eT1g545S", "invitation": "ICLR.cc/2020/Conference/Paper403/-/Official_Comment", "content": {"title": "response", "comment": "We thank the reviewer for a very thorough review.\n\nHere are responses to the feedback provided in section D of the review:\n\nD0. We agree that connecting the results more tightly is a worthwhile goal. We began from the two known regimes (linear functions and reversible environments) and in attempting to close the gap were able to extend results from both sides, but not in such a way as to unify the two settings. Reviewer 1 raised a similar point and we will add a comment to the text to clarify this as a future direction.\n\nD1. We will add this clarification. \n\nD2. Thank you for the comment, this raises an interesting technicality. While the ReLU is not differentiable at zero, it does not change the essence of the results since at zero the non-differentiability is masked in the equation x*sigma\u2019(x) = sigma(x) (also in practice sigma\u2019(0) is usually defined to be 0). Some care needs to be taken to make sure that the dynamics are defined at the non-differentiable points, but since our analysis considers only the pointwise sign of the Lyapunov function we can use the masking observation so that all the algebraic manipulations will remain the same. Also note that a similar issue was already addressed by Chizat and Bach in https://arxiv.org/abs/1805.09545 by reparametrizing the class of ReLU functions.\n\nD3. This is an interesting question. In our mind the dream result in this direction would be an understanding of these semi-gradient algorithms in the same level of detail as gradient descent in supervised learning. For example, in that case we have a precise notion of the assumptions needed to get global convergence (i.e. convexity), guarantees of convergence and characterizations of the fixed points in hard non-convex problems (local minima), and even convergence rates under various assumptions. We can add a comment about this to the discussion to motivate further work in this area.\n\nD4. As we explained in the paper, homogeneity is nice since then the manifold of functions has the property that the function V(theta) lies in the span of the tangent space nabla V(theta) at that point. It is not as easy to say things about this manifold for non-homogeneous activations. There may be other ways to think about the benefit of homogeneity that generalize to neural nets with different activations, but we are not familiar with any. "}, "signatures": ["ICLR.cc/2020/Conference/Paper403/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper403/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"abstract": "While there are convergence guarantees for temporal difference (TD) learning when using linear function approximators, the situation for nonlinear models is far less understood, and divergent examples are known. Here we take a first step towards extending theoretical convergence guarantees to TD learning with nonlinear function approximation. More precisely, we consider the expected learning dynamics of the TD(0) algorithm for value estimation. As the step-size converges to zero, these dynamics are defined by a nonlinear ODE which depends on the geometry of the space of function approximators, the structure of the underlying Markov chain, and their interaction. We find a set of function approximators that includes ReLU networks and has geometry amenable to TD learning regardless of environment, so that the solution performs about as well as linear TD in the worst case. Then, we show how environments that are more reversible induce dynamics that are better for TD learning and prove global convergence to the true value function for well-conditioned function approximators. Finally, we generalize a divergent counterexample to a family of divergent problems to demonstrate how the interaction between approximator and environment can go wrong and to motivate the assumptions needed to prove convergence. ", "title": "Geometric Insights into the Convergence of Nonlinear TD Learning", "keywords": ["TD", "nonlinear", "convergence", "value estimation", "reinforcement learning"], "authors": ["David Brandfonbrener", "Joan Bruna"], "authorids": ["david.brandfonbrener@nyu.edu", "bruna@cims.nyu.edu"], "pdf": "/pdf/c07a4589f711c340b9d0263d05b00df197d9816c.pdf", "paperhash": "brandfonbrener|geometric_insights_into_the_convergence_of_nonlinear_td_learning", "_bibtex": "@inproceedings{\nBrandfonbrener2020Geometric,\ntitle={Geometric Insights into the Convergence of Nonlinear TD Learning},\nauthor={David Brandfonbrener and Joan Bruna},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=SJezGp4YPr}\n}", "full_presentation_video": "", "original_pdf": "/attachment/5e7a051b6e01ed79962a51f143047f2114d362a1.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "SJezGp4YPr", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper403/Authors", "ICLR.cc/2020/Conference/Paper403/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper403/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper403/Reviewers", "ICLR.cc/2020/Conference/Paper403/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper403/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper403/Authors|ICLR.cc/2020/Conference/Paper403/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504171985, "tmdate": 1576860537393, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper403/Authors", "ICLR.cc/2020/Conference/Paper403/Reviewers", "ICLR.cc/2020/Conference/Paper403/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper403/-/Official_Comment"}}}, {"id": "B1e8zT8PsB", "original": null, "number": 5, "cdate": 1573510413670, "ddate": null, "tcdate": 1573510413670, "tmdate": 1573510413670, "tddate": null, "forum": "SJezGp4YPr", "replyto": "HygHpb4qcr", "invitation": "ICLR.cc/2020/Conference/Paper403/-/Official_Comment", "content": {"title": "response", "comment": "We thank the reviewer for the positive review and are happy to provide any clarifications that could convince the reviewer to increase the score. "}, "signatures": ["ICLR.cc/2020/Conference/Paper403/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper403/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"abstract": "While there are convergence guarantees for temporal difference (TD) learning when using linear function approximators, the situation for nonlinear models is far less understood, and divergent examples are known. Here we take a first step towards extending theoretical convergence guarantees to TD learning with nonlinear function approximation. More precisely, we consider the expected learning dynamics of the TD(0) algorithm for value estimation. As the step-size converges to zero, these dynamics are defined by a nonlinear ODE which depends on the geometry of the space of function approximators, the structure of the underlying Markov chain, and their interaction. We find a set of function approximators that includes ReLU networks and has geometry amenable to TD learning regardless of environment, so that the solution performs about as well as linear TD in the worst case. Then, we show how environments that are more reversible induce dynamics that are better for TD learning and prove global convergence to the true value function for well-conditioned function approximators. Finally, we generalize a divergent counterexample to a family of divergent problems to demonstrate how the interaction between approximator and environment can go wrong and to motivate the assumptions needed to prove convergence. ", "title": "Geometric Insights into the Convergence of Nonlinear TD Learning", "keywords": ["TD", "nonlinear", "convergence", "value estimation", "reinforcement learning"], "authors": ["David Brandfonbrener", "Joan Bruna"], "authorids": ["david.brandfonbrener@nyu.edu", "bruna@cims.nyu.edu"], "pdf": "/pdf/c07a4589f711c340b9d0263d05b00df197d9816c.pdf", "paperhash": "brandfonbrener|geometric_insights_into_the_convergence_of_nonlinear_td_learning", "_bibtex": "@inproceedings{\nBrandfonbrener2020Geometric,\ntitle={Geometric Insights into the Convergence of Nonlinear TD Learning},\nauthor={David Brandfonbrener and Joan Bruna},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=SJezGp4YPr}\n}", "full_presentation_video": "", "original_pdf": "/attachment/5e7a051b6e01ed79962a51f143047f2114d362a1.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "SJezGp4YPr", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper403/Authors", "ICLR.cc/2020/Conference/Paper403/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper403/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper403/Reviewers", "ICLR.cc/2020/Conference/Paper403/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper403/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper403/Authors|ICLR.cc/2020/Conference/Paper403/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504171985, "tmdate": 1576860537393, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper403/Authors", "ICLR.cc/2020/Conference/Paper403/Reviewers", "ICLR.cc/2020/Conference/Paper403/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper403/-/Official_Comment"}}}, {"id": "HkgWl6IDiH", "original": null, "number": 4, "cdate": 1573510377469, "ddate": null, "tcdate": 1573510377469, "tmdate": 1573510377469, "tddate": null, "forum": "SJezGp4YPr", "replyto": "HkxUUm6Tcr", "invitation": "ICLR.cc/2020/Conference/Paper403/-/Official_Comment", "content": {"title": "response", "comment": "We thank the reviewer for the careful review. \n\nIn regards to Theorem 3, the reviewer makes a good point that the Theorem does not recover the results from the linear case. We think that closing this gap is an interesting direction and will add a comment about this limitation to the discussion section of the paper (the homogeneous case gives an extension of the linear setting but not in a way that closes this gap). "}, "signatures": ["ICLR.cc/2020/Conference/Paper403/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper403/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"abstract": "While there are convergence guarantees for temporal difference (TD) learning when using linear function approximators, the situation for nonlinear models is far less understood, and divergent examples are known. Here we take a first step towards extending theoretical convergence guarantees to TD learning with nonlinear function approximation. More precisely, we consider the expected learning dynamics of the TD(0) algorithm for value estimation. As the step-size converges to zero, these dynamics are defined by a nonlinear ODE which depends on the geometry of the space of function approximators, the structure of the underlying Markov chain, and their interaction. We find a set of function approximators that includes ReLU networks and has geometry amenable to TD learning regardless of environment, so that the solution performs about as well as linear TD in the worst case. Then, we show how environments that are more reversible induce dynamics that are better for TD learning and prove global convergence to the true value function for well-conditioned function approximators. Finally, we generalize a divergent counterexample to a family of divergent problems to demonstrate how the interaction between approximator and environment can go wrong and to motivate the assumptions needed to prove convergence. ", "title": "Geometric Insights into the Convergence of Nonlinear TD Learning", "keywords": ["TD", "nonlinear", "convergence", "value estimation", "reinforcement learning"], "authors": ["David Brandfonbrener", "Joan Bruna"], "authorids": ["david.brandfonbrener@nyu.edu", "bruna@cims.nyu.edu"], "pdf": "/pdf/c07a4589f711c340b9d0263d05b00df197d9816c.pdf", "paperhash": "brandfonbrener|geometric_insights_into_the_convergence_of_nonlinear_td_learning", "_bibtex": "@inproceedings{\nBrandfonbrener2020Geometric,\ntitle={Geometric Insights into the Convergence of Nonlinear TD Learning},\nauthor={David Brandfonbrener and Joan Bruna},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=SJezGp4YPr}\n}", "full_presentation_video": "", "original_pdf": "/attachment/5e7a051b6e01ed79962a51f143047f2114d362a1.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "SJezGp4YPr", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper403/Authors", "ICLR.cc/2020/Conference/Paper403/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper403/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper403/Reviewers", "ICLR.cc/2020/Conference/Paper403/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper403/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper403/Authors|ICLR.cc/2020/Conference/Paper403/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504171985, "tmdate": 1576860537393, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper403/Authors", "ICLR.cc/2020/Conference/Paper403/Reviewers", "ICLR.cc/2020/Conference/Paper403/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper403/-/Official_Comment"}}}, {"id": "B1eT1g545S", "original": null, "number": 1, "cdate": 1572278244800, "ddate": null, "tcdate": 1572278244800, "tmdate": 1572972599695, "tddate": null, "forum": "SJezGp4YPr", "replyto": "SJezGp4YPr", "invitation": "ICLR.cc/2020/Conference/Paper403/-/Official_Review", "content": {"experience_assessment": "I do not know much about this area.", "rating": "8: Accept", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #3", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "\n####\nA. Summarize what the paper claims to do/contribute. Be positive and generous.\n####\n\nThe paper characterises the convergence of Temporal Difference learning for on-policy value estimation with nonlinear function approximators. It looks at a few classes of functions which include Deep ReLU networks, with and without residual connections. It looks at how a few aspects of function approximators affect their convergence properties, and how these are intertwined with a property of the environment.\n\nThis topic is important for improving the theoretical understanding of Deep RL. The paper provides a series of mathematical results which will be interesting for the community as they are well-motivated, intuitively explained, and of clear practical relevance.  The paper works within a simplified setup that is however NOT toy. It makes reasonable simplifying assumptions to avoid confounding issues with exploration, off-policyness of data, and stochastic optimization. Within a continuous-time MRP framework they show that:\n\n1. When a particular class of function approximators known as homogenous functions (e.g. Deep ReLU networks) is used, the error on the state value function can be bounded. Tweaking the class of function approximators by making them like residual networks (residual-homogenous) obtains a bound similar to known bounds for linear function approximators.\n\n2. It is known that TD(0) converges with linear function approximators and arbitrary environments. It is also known that TD(0) converges with arbitrary function approximators when the environment is fully reversible. This paper shows that there is in fact a tradeoff between how well the function approximator is conditioned and how reversible the environment is (for particular definitions of well-conditionedness and the \"extent\" to which an environment is reversible). This nicely links up known theory and is especially relevant for practitioners who would like to apply neural net function approximators in arbitrary environments.\n\n3. They show that using n-step returns instead of TD(0) returns can have a similar effect to the environment being reversible. That's a nice insight. \n\n4. There is a classic counterexample for TD(0) with a nonlinear function approximator diverging. The paper makes this example more general which more clearly demonstrates how/why convergence fails beyond the single pathological example whose relevance to real neural nets was hard to determine. It makes it clear that a necessary condition for convergent TD learning with function approximators is dodging this more general class of divergent example.\n\n5. The theory is supported by (toy) experiments, whose empirical results suggest the theory can be made more general (e.g. to include more classes of function approximators). \n\n####\nB. Clearly state your decision (accept or reject) with one or two key reasons for this choice.\n####\n\nThis paper should be accepted because the results are interesting, relevant, novel (as far as the reviewer understands), well-explained, and as far as the reviewer can tell correct (though I have not scrutinized the proofs in the appendix).\n\nThe paper is interesting and easy to read (even for someone without background in proving the convergence of RL algorithms).\n\n####\nC. Provide supporting arguments for the reasons for the decision.\n####\n\nWhether or not (and under what conditions) TD(0) converges is an important object of study for the Deep RL community, which is well-represented at ICLR. The results shown here should be more widely known.\n\nGood intuitions given for the mathematical results in addition to proofs (e.g. why homogeneity prevents divergence).\n\nThis work contributes to the understanding of Deep RL and could eventually lead to actionable theory which lets us design more robust RL systems (with insights about the coupling between learning algorithm, function approximator, and environment).\n\n####\nD. Provide additional feedback with the aim to improve the paper. Make it clear that these points are here to help, and not necessarily part of your decision assessment.\n####\n\nD0. My main critique is that the results are somewhat disparate. How does homogeneity or residual homogeneity relate to the conditioning number of the neural tangent kernel? Can these all be connected up better?\nD1. Be more clear in Remark 1 on page 4 that the homogenous property applies to *deep* ReLU networks. Otherwise the reader may assume the proof only applies to single-layer neural networks until they read the more detailed exposition in the appendix. \nD2. Is it an issue for homogeneity if there is a point where the derivative does not exist (e.g. at x=0 for ReLU).\nD3. Can the paper make it more clear to a Deep RL audience in the intro or discussion what the holy grail of this research direction would be?\nD4. As tanh or multiplicative activations (e.g. those found in LSTM/attention networks) are not homogenous, can the authors speculate about whether or not they would have similar convergence properties to homogeneous activations? What are the obstacles to a similar proof for this class of networks?."}, "signatures": ["ICLR.cc/2020/Conference/Paper403/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper403/AnonReviewer3"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"abstract": "While there are convergence guarantees for temporal difference (TD) learning when using linear function approximators, the situation for nonlinear models is far less understood, and divergent examples are known. Here we take a first step towards extending theoretical convergence guarantees to TD learning with nonlinear function approximation. More precisely, we consider the expected learning dynamics of the TD(0) algorithm for value estimation. As the step-size converges to zero, these dynamics are defined by a nonlinear ODE which depends on the geometry of the space of function approximators, the structure of the underlying Markov chain, and their interaction. We find a set of function approximators that includes ReLU networks and has geometry amenable to TD learning regardless of environment, so that the solution performs about as well as linear TD in the worst case. Then, we show how environments that are more reversible induce dynamics that are better for TD learning and prove global convergence to the true value function for well-conditioned function approximators. Finally, we generalize a divergent counterexample to a family of divergent problems to demonstrate how the interaction between approximator and environment can go wrong and to motivate the assumptions needed to prove convergence. ", "title": "Geometric Insights into the Convergence of Nonlinear TD Learning", "keywords": ["TD", "nonlinear", "convergence", "value estimation", "reinforcement learning"], "authors": ["David Brandfonbrener", "Joan Bruna"], "authorids": ["david.brandfonbrener@nyu.edu", "bruna@cims.nyu.edu"], "pdf": "/pdf/c07a4589f711c340b9d0263d05b00df197d9816c.pdf", "paperhash": "brandfonbrener|geometric_insights_into_the_convergence_of_nonlinear_td_learning", "_bibtex": "@inproceedings{\nBrandfonbrener2020Geometric,\ntitle={Geometric Insights into the Convergence of Nonlinear TD Learning},\nauthor={David Brandfonbrener and Joan Bruna},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=SJezGp4YPr}\n}", "full_presentation_video": "", "original_pdf": "/attachment/5e7a051b6e01ed79962a51f143047f2114d362a1.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "SJezGp4YPr", "replyto": "SJezGp4YPr", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper403/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper403/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1575666042561, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper403/Reviewers"], "noninvitees": [], "tcdate": 1570237752655, "tmdate": 1575666042579, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper403/-/Official_Review"}}}, {"id": "HygHpb4qcr", "original": null, "number": 2, "cdate": 1572647357325, "ddate": null, "tcdate": 1572647357325, "tmdate": 1572972599651, "tddate": null, "forum": "SJezGp4YPr", "replyto": "SJezGp4YPr", "invitation": "ICLR.cc/2020/Conference/Paper403/-/Official_Review", "content": {"rating": "6: Weak Accept", "experience_assessment": "I do not know much about this area.", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #2", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review": "The paper analyses the convergence of TD-learning in a simplified setup (on-policy, infinitesimally small steps leading to an ODE).\n\nSeveral new results are proposed:\n- convergence of TD-learning for a new class of approximators (the h-homogenous functions)\n- convergence of TD-learning for residual-homegenous functions and a bound on the distance form optimum\n- a relaxation of the Markov chain reversibility to a reversibility coefficient and convergence proof that relates the reversibility coefficient to the conditioning number of grad_V grad_V^T.\n\nWhile the theory applies to the ideal case, t provides some practical conclusions:\n- TD learning with k-step returns  converges better because the resulting Markov chain is more reversible\n- convergence can be attained by overparmeterized function approximators, which can still generalize better than tabular value functions.\n\nThe experiments corroborate the link between reversibility factor and TD convergence on an artificial example."}, "signatures": ["ICLR.cc/2020/Conference/Paper403/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper403/AnonReviewer2"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"abstract": "While there are convergence guarantees for temporal difference (TD) learning when using linear function approximators, the situation for nonlinear models is far less understood, and divergent examples are known. Here we take a first step towards extending theoretical convergence guarantees to TD learning with nonlinear function approximation. More precisely, we consider the expected learning dynamics of the TD(0) algorithm for value estimation. As the step-size converges to zero, these dynamics are defined by a nonlinear ODE which depends on the geometry of the space of function approximators, the structure of the underlying Markov chain, and their interaction. We find a set of function approximators that includes ReLU networks and has geometry amenable to TD learning regardless of environment, so that the solution performs about as well as linear TD in the worst case. Then, we show how environments that are more reversible induce dynamics that are better for TD learning and prove global convergence to the true value function for well-conditioned function approximators. Finally, we generalize a divergent counterexample to a family of divergent problems to demonstrate how the interaction between approximator and environment can go wrong and to motivate the assumptions needed to prove convergence. ", "title": "Geometric Insights into the Convergence of Nonlinear TD Learning", "keywords": ["TD", "nonlinear", "convergence", "value estimation", "reinforcement learning"], "authors": ["David Brandfonbrener", "Joan Bruna"], "authorids": ["david.brandfonbrener@nyu.edu", "bruna@cims.nyu.edu"], "pdf": "/pdf/c07a4589f711c340b9d0263d05b00df197d9816c.pdf", "paperhash": "brandfonbrener|geometric_insights_into_the_convergence_of_nonlinear_td_learning", "_bibtex": "@inproceedings{\nBrandfonbrener2020Geometric,\ntitle={Geometric Insights into the Convergence of Nonlinear TD Learning},\nauthor={David Brandfonbrener and Joan Bruna},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=SJezGp4YPr}\n}", "full_presentation_video": "", "original_pdf": "/attachment/5e7a051b6e01ed79962a51f143047f2114d362a1.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "SJezGp4YPr", "replyto": "SJezGp4YPr", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper403/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper403/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1575666042561, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper403/Reviewers"], "noninvitees": [], "tcdate": 1570237752655, "tmdate": 1575666042579, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper403/-/Official_Review"}}}, {"id": "rJl4tiBa9S", "original": null, "number": 3, "cdate": 1572850556284, "ddate": null, "tcdate": 1572850556284, "tmdate": 1572972599607, "tddate": null, "forum": "SJezGp4YPr", "replyto": "SJezGp4YPr", "invitation": "ICLR.cc/2020/Conference/Paper403/-/Official_Review", "content": {"rating": "3: Weak Reject", "experience_assessment": "I have published in this field for several years.", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #4", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review": "This paper establishes a theoretical insight into Temporal Difference (TD) learning for policy evaluation, on the convergence issue with nonlinear function approximation. It proposes that for a so-defined class of \u201chomogeneous\u201d function approximators, the TD learning will be attracted to a \u201cneighborhood\u201d of the optimal solution. While this seems an important work, I am uncomfortable to give an accept decision because the statements of the results can be found inaccurate from place to place. I actually found it is a bit confusing to use this wording (from the paper). For example, with neural networks, there is still approximation error and local minima issue, how could you say that the update is absorbed into a neighborhood of the true solution? And this is claimed in the beginning of Section 3.\n\nTD learning follows a biased estimate of the gradient of the squared expected Bellman error, which\nis minimized by the true value function. The bias is intrinsic to the fact that one cannot obtain more\nthan one independent sample from the environment at any given time. As it turns out, this bias\ncan be seen geometrically as \u201cbending\u201d the gradient flow dynamics and potentially eliminates the\nconvergence guarantees of gradient descent when combined with nonlinear function approximation.\n\u300b\u300b I don\u2019t know what this means. TD diverges with nonlinear FA just because the contraction mapping does not hold any more. \n\nsuch as two timescale algorithms, but these algorithms are not widely used\n>>this argument is a bit weak. \n\nWe prove global convergence to the true value function when the environment is \u201cmore\nreversible\u201d than the function approximator is \u201cpoorly conditioned\u201d.\n>>not clear what this means until here. What is \u201creversible environment\u201d, what does it mean FA is \u201cpoorly conditioned\u201d? Later in Section 2, it was mentioned \u201cMRP\u201d is reversible so that some matrix is symmetric. \n\nSection 2:\n\nEquation 1 uses V^* is a bit inconsistent ( P is used). Why not use V? V^* usually means the optimal value function. I saw your footnote, but remember value function is \u201cassociated\u201d with P. \n\nConvergence to V* immediately follows. \u2013 What convergence? I thought you were talking about stability of the ODE. \n\nthe \u201csemi-gradient\u201d TD(0): do you mean tabular TD(0) is not semi-gradient? Do you think it is gradient? Even in tabular, it is not gradient descent. \n\nV(\\theta)_s: this notation is odd. \n\nit is meant to approximate gradient descent on the squared expected Bellman error:  This is arguable. Actually it is not precise. One can say it is true and others may say it\u2019s not. This is never an established result or acknowledge showing that TD is an approximation to the gradient descent on the mean squared Bellman error.  \n\n\nThe first is when V is linear and the second when the MRP is reversible so that A is symmetric.\n>>this is ambiguous. Do you mean the second case is when V is nonlinear and the MRP is reversible? I am guessing this is what you mean. And it\u2019s true. \n\nSection 2.3: doesn\u2019t carry much value. The example is from the paper cited (Tsitsiklis and Vanroy 1997). Adding the symmetric case for P doesn\u2019t give much value because that\u2019s easily seen to be true. \n\nDefinition 1: \u201chomogeneous\u201d. This is not the usual definition of homogeneous in mathematics. Square function is.  Relu: gradient at 0 exist?\n\n Section 4.2: experiments about modifying the spiral example into symmetric MRP is not very interesting, because symmetry brings obvious convergence guarantee. However, it is good to see the experiment with a variable delta that controls the level of symmetry.  \n\nI think a missing experiment is the showcase for the divergence examples the case of \u201chomogeneous\u201d function, such as the square function and the neural networks (as claimed in the paper, these are \u201chomogenous\u201d functions). How does the behavior that the TD update is absorbed into the \u201cneighborhood\u201d of the true value function? \n\n\n\n\n\n\n\n "}, "signatures": ["ICLR.cc/2020/Conference/Paper403/AnonReviewer4"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper403/AnonReviewer4"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"abstract": "While there are convergence guarantees for temporal difference (TD) learning when using linear function approximators, the situation for nonlinear models is far less understood, and divergent examples are known. Here we take a first step towards extending theoretical convergence guarantees to TD learning with nonlinear function approximation. More precisely, we consider the expected learning dynamics of the TD(0) algorithm for value estimation. As the step-size converges to zero, these dynamics are defined by a nonlinear ODE which depends on the geometry of the space of function approximators, the structure of the underlying Markov chain, and their interaction. We find a set of function approximators that includes ReLU networks and has geometry amenable to TD learning regardless of environment, so that the solution performs about as well as linear TD in the worst case. Then, we show how environments that are more reversible induce dynamics that are better for TD learning and prove global convergence to the true value function for well-conditioned function approximators. Finally, we generalize a divergent counterexample to a family of divergent problems to demonstrate how the interaction between approximator and environment can go wrong and to motivate the assumptions needed to prove convergence. ", "title": "Geometric Insights into the Convergence of Nonlinear TD Learning", "keywords": ["TD", "nonlinear", "convergence", "value estimation", "reinforcement learning"], "authors": ["David Brandfonbrener", "Joan Bruna"], "authorids": ["david.brandfonbrener@nyu.edu", "bruna@cims.nyu.edu"], "pdf": "/pdf/c07a4589f711c340b9d0263d05b00df197d9816c.pdf", "paperhash": "brandfonbrener|geometric_insights_into_the_convergence_of_nonlinear_td_learning", "_bibtex": "@inproceedings{\nBrandfonbrener2020Geometric,\ntitle={Geometric Insights into the Convergence of Nonlinear TD Learning},\nauthor={David Brandfonbrener and Joan Bruna},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=SJezGp4YPr}\n}", "full_presentation_video": "", "original_pdf": "/attachment/5e7a051b6e01ed79962a51f143047f2114d362a1.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "SJezGp4YPr", "replyto": "SJezGp4YPr", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper403/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper403/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1575666042561, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper403/Reviewers"], "noninvitees": [], "tcdate": 1570237752655, "tmdate": 1575666042579, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper403/-/Official_Review"}}}, {"id": "HkxUUm6Tcr", "original": null, "number": 4, "cdate": 1572881229642, "ddate": null, "tcdate": 1572881229642, "tmdate": 1572972599562, "tddate": null, "forum": "SJezGp4YPr", "replyto": "SJezGp4YPr", "invitation": "ICLR.cc/2020/Conference/Paper403/-/Official_Review", "content": {"rating": "8: Accept", "experience_assessment": "I have published one or two papers in this area.", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #1", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review": "What is the specific question/problem tackled by the paper?\n\nThe paper studies convergence & non-divergence of TD(0) with value function estimates from the class of ReLU deep neural nets (optionally with residual connections). \n\nIs the approach well motivated, including being well-placed in the literature?\n\nYes.\n\n\nDoes the paper support the claims? This includes determining if results, whether theoretical or empirical, are correct and if they are scientifically rigorous.\n\nThe support is adequate.\n\n\nSummarize what the paper claims to do/contribute. Be positive and generous.\n\nThe paper takes a first step in bridging the gap between existing analyses of TD(0): convergence with linear function approximators, and convergence in reversible MRPs. The first contribution is a non-divergence result for the method with ReLU deep neural networks with and without residual connection. The second result connects a notion of reversibility of an MRP and the condition number of the neural tangent kernel, saying that better conditioning can make up for the lack of reversibility.\n\n\nClearly state your decision (accept or reject) with one or two key reasons for this choice.\n\nI vote for accepting the paper.\n\n\nProvide supporting arguments for the reasons for the decision.\n\nThe paper is well written, with a clear story and accessible explanations. The paper provides novel results and an interesting line of work that allows us to tradeoff good behavior of the function space and of the MRP in order to have TD converge, in the sense that as the MDP becomes less and less reversible we can make up for it by having properly conditioned matrices.\n\nThe paper also makes an adequate choice of function space to restrict the guarantees to.\n\n\nProvide additional feedback with the aim to improve the paper. Make it clear that these points are here to help, and not necessarily part of your decision assessment.\n\nIt seems that Theorem 3 cannot recover the linear case results for properly conditioned Phi matrices and irreversible MRPs. It would be good if the result could really interpolate between the two previously studied cases (linear irreversible and nonlinear reversible). Alternatively, a comment about this limitation of the result would improve the paper."}, "signatures": ["ICLR.cc/2020/Conference/Paper403/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper403/AnonReviewer1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"abstract": "While there are convergence guarantees for temporal difference (TD) learning when using linear function approximators, the situation for nonlinear models is far less understood, and divergent examples are known. Here we take a first step towards extending theoretical convergence guarantees to TD learning with nonlinear function approximation. More precisely, we consider the expected learning dynamics of the TD(0) algorithm for value estimation. As the step-size converges to zero, these dynamics are defined by a nonlinear ODE which depends on the geometry of the space of function approximators, the structure of the underlying Markov chain, and their interaction. We find a set of function approximators that includes ReLU networks and has geometry amenable to TD learning regardless of environment, so that the solution performs about as well as linear TD in the worst case. Then, we show how environments that are more reversible induce dynamics that are better for TD learning and prove global convergence to the true value function for well-conditioned function approximators. Finally, we generalize a divergent counterexample to a family of divergent problems to demonstrate how the interaction between approximator and environment can go wrong and to motivate the assumptions needed to prove convergence. ", "title": "Geometric Insights into the Convergence of Nonlinear TD Learning", "keywords": ["TD", "nonlinear", "convergence", "value estimation", "reinforcement learning"], "authors": ["David Brandfonbrener", "Joan Bruna"], "authorids": ["david.brandfonbrener@nyu.edu", "bruna@cims.nyu.edu"], "pdf": "/pdf/c07a4589f711c340b9d0263d05b00df197d9816c.pdf", "paperhash": "brandfonbrener|geometric_insights_into_the_convergence_of_nonlinear_td_learning", "_bibtex": "@inproceedings{\nBrandfonbrener2020Geometric,\ntitle={Geometric Insights into the Convergence of Nonlinear TD Learning},\nauthor={David Brandfonbrener and Joan Bruna},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=SJezGp4YPr}\n}", "full_presentation_video": "", "original_pdf": "/attachment/5e7a051b6e01ed79962a51f143047f2114d362a1.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "SJezGp4YPr", "replyto": "SJezGp4YPr", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper403/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper403/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1575666042561, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper403/Reviewers"], "noninvitees": [], "tcdate": 1570237752655, "tmdate": 1575666042579, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper403/-/Official_Review"}}}], "count": 10}