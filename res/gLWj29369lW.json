{"notes": [{"id": "gLWj29369lW", "original": "f_mI2u7DCzR", "number": 860, "cdate": 1601308098950, "ddate": null, "tcdate": 1601308098950, "tmdate": 1615807455857, "tddate": null, "forum": "gLWj29369lW", "replyto": null, "invitation": "ICLR.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Interpreting Knowledge Graph Relation Representation from Word Embeddings", "authorids": ["~Carl_Allen1", "~Ivana_Balazevic1", "~Timothy_Hospedales1"], "authors": ["Carl Allen", "Ivana Balazevic", "Timothy Hospedales"], "keywords": ["knowledge graphs", "word embedding", "representation learning"], "abstract": "Many models learn representations of knowledge graph data by exploiting its low-rank latent structure, encoding known relations between entities and enabling unknown facts to be inferred. To predict whether a relation holds between entities, embeddings are typically compared in the latent space following a relation-specific mapping. Whilst their predictive performance has steadily improved, how such models capture the underlying latent structure of semantic information remains unexplained. Building on recent theoretical understanding of word embeddings, we categorise knowledge graph relations into three types and for each derive explicit requirements of their representations. We show that empirical properties of relation representations and the relative performance of leading knowledge graph representation methods are justified by our analysis.", "one-sentence_summary": "Interpreting the structure of knowledge graph relation representation using insight from word embeddings.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "allen|interpreting_knowledge_graph_relation_representation_from_word_embeddings", "pdf": "/pdf/1feb4e4d391a73dd7a1de57536d4621967f6cd43.pdf", "venue": "ICLR 2021 Poster", "venueid": "ICLR.cc/2021/Conference", "_bibtex": "@inproceedings{\nallen2021interpreting,\ntitle={Interpreting Knowledge Graph Relation Representation from Word Embeddings},\nauthor={Carl Allen and Ivana Balazevic and Timothy Hospedales},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=gLWj29369lW}\n}"}, "signatures": ["ICLR.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference"], "details": {"replyCount": 9, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"reply": {"readers": {"values-regex": ".*"}, "writers": {"values": ["ICLR.cc/2021/Conference"]}, "signatures": {"values": ["ICLR.cc/2021/Conference"]}, "content": {"authors": {"values": ["Anonymous"]}, "authorids": {"values-regex": ".*"}, "reviewed_version_(pdf)": {"required": false, "description": "Upload a PDF file that ends with .pdf", "value-regex": ".*"}}}, "signatures": ["ICLR.cc/2021/Conference"], "readers": ["everyone"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["~", "OpenReview.net/Support"], "tcdate": 1601308008205, "tmdate": 1614984599368, "id": "ICLR.cc/2021/Conference/-/Blind_Submission"}}, "tauthor": "OpenReview.net"}, {"id": "93lopxvJUU", "original": null, "number": 1, "cdate": 1610040493281, "ddate": null, "tcdate": 1610040493281, "tmdate": 1610474099388, "tddate": null, "forum": "gLWj29369lW", "replyto": "gLWj29369lW", "invitation": "ICLR.cc/2021/Conference/Paper860/-/Decision", "content": {"title": "Final Decision", "decision": "Accept (Poster)", "comment": "This paper extends the recent theoretical understanding on geometric properties for word embeddings to relations and entities of knowledge graph. It categorizes relations into different types and derive requirements for their representations. Empirically they experiment several graph embedding approaches and show that when the loss function is aligned with the requirement of the relation type, we can achieve better performance.  The reviewers generally find the paper to be solid, well executed and provides useful insights. The authors are encouraged to strengthen the discussion of the motivation of this work, and improve the presentation based on reviewers' comments. "}, "signatures": ["ICLR.cc/2021/Conference/Program_Chairs"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference/Program_Chairs"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Interpreting Knowledge Graph Relation Representation from Word Embeddings", "authorids": ["~Carl_Allen1", "~Ivana_Balazevic1", "~Timothy_Hospedales1"], "authors": ["Carl Allen", "Ivana Balazevic", "Timothy Hospedales"], "keywords": ["knowledge graphs", "word embedding", "representation learning"], "abstract": "Many models learn representations of knowledge graph data by exploiting its low-rank latent structure, encoding known relations between entities and enabling unknown facts to be inferred. To predict whether a relation holds between entities, embeddings are typically compared in the latent space following a relation-specific mapping. Whilst their predictive performance has steadily improved, how such models capture the underlying latent structure of semantic information remains unexplained. Building on recent theoretical understanding of word embeddings, we categorise knowledge graph relations into three types and for each derive explicit requirements of their representations. We show that empirical properties of relation representations and the relative performance of leading knowledge graph representation methods are justified by our analysis.", "one-sentence_summary": "Interpreting the structure of knowledge graph relation representation using insight from word embeddings.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "allen|interpreting_knowledge_graph_relation_representation_from_word_embeddings", "pdf": "/pdf/1feb4e4d391a73dd7a1de57536d4621967f6cd43.pdf", "venue": "ICLR 2021 Poster", "venueid": "ICLR.cc/2021/Conference", "_bibtex": "@inproceedings{\nallen2021interpreting,\ntitle={Interpreting Knowledge Graph Relation Representation from Word Embeddings},\nauthor={Carl Allen and Ivana Balazevic and Timothy Hospedales},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=gLWj29369lW}\n}"}, "tags": [], "invitation": {"reply": {"forum": "gLWj29369lW", "replyto": "gLWj29369lW", "readers": {"values": ["everyone"]}, "writers": {"values": ["ICLR.cc/2021/Conference/Program_Chairs"]}, "signatures": {"values": ["ICLR.cc/2021/Conference/Program_Chairs"]}, "content": {"title": {"value": "Final Decision"}, "decision": {"value-radio": ["Accept (Oral)", "Accept (Spotlight)", "Accept (Poster)", "Reject"]}, "comment": {"value-regex": "[\\S\\s]{0,50000}", "markdown": true}}}, "multiReply": false, "signatures": ["ICLR.cc/2021/Conference"], "readers": ["everyone"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Program_Chairs"], "tcdate": 1610040493265, "tmdate": 1610474099373, "id": "ICLR.cc/2021/Conference/Paper860/-/Decision"}}}, {"id": "eYsnoT3WX8D", "original": null, "number": 3, "cdate": 1605628651166, "ddate": null, "tcdate": 1605628651166, "tmdate": 1605708639302, "tddate": null, "forum": "gLWj29369lW", "replyto": "7pgcuislNmb", "invitation": "ICLR.cc/2021/Conference/Paper860/-/Official_Comment", "content": {"title": "Response to Reviewer 1", "comment": "Many thanks for your review.\n\n**\u201cMotivation\u201d**\\\nOur main motivation is to try to understand different KG model performance by developing a theory supported by empirical evidence. Our aim is that this contributes to a theoretical foundation for a largely empirical field, offering a principled direction for KG representation model development. \\\nOur specific approach is motivated by recent understanding for PMI-based word embeddings based on word co-occurrences. Words co-occur more than \u201cby chance\u201d (PMI>0) if they are related in some way. As such, semantic relationships induce structure in co-occurrence statistics, which manifest in geometric relationships between PMI-based embeddings of related words, e.g. analogies. We extend this semantics-to-geometry connection (shown previously for general relation types, e.g. analogy, paraphrase, similarity in [1, 2]) to the specific relations of knowledge graphs. For different relation types, we derive geometric properties of relation representations required to map between PMI-based word embeddings (which cannot be done for general \u201centity embeddings\u201d since we have little understanding of their structure). The derived geometric properties can be considered a (particular) theoretical model of how relations can be represented. We then show that the better a model fits this theoretical model, the better it performs on a relation-by-relation basis. \\\nThe \u201cmotivating premise\u201d for our approach (p.1) makes no strong claim but, since (a) PMI-based word embeddings are observed to capture semantic relationships between words and (b) KG representation models aim to capture semantic relationships between words, we proceed on the basis that an understanding from one might help the other.\n\n\n**\u201cNothing in this paper surprised me, seems like ''regular'' research\u201d, \u201cPaper not very novel\u201d**\\\nWhilst much empirical research exists in both the fields of KG representation and PMI-based word embedding, a theoretical connection between semantics and geometry of word embeddings has only been drawn recently [1, 2]; and we are unaware of a theoretical explanation for properties of KG relation representations, beyond limited specific observations (e.g. asymmetric mappings are required to represent asymmetric relations). We extend the recent theoretical understanding [1, 2] for a limited set of general relation types to develop a model for the geometric relationships between PMI-based word embeddings, corresponding to specific relations of KGs. We then show that the more the loss function of a KG model is compatible with those geometric relationships, the better it performs empirically in modelling those relations. We believe that deriving geometric properties of KG relation representations based on an understanding of how semantics can correspond to geometry is novel. We also believe that our proposed categorisation of relation types based on relation conditions is novel. \n\n\n**\u201cFig.1: Please specify the legend clearly.\u201d** \\\nThanks for the suggestion, we have updated the legend (which should be read in conjunction with Section 3 text).\n\n**\u201cTable 2: For more beginning readers, please revise the examples to human-readable.\u201d**\\\nTable 2 includes examples of relations and subject/object word pairs taken from the WN18RR data_set. We agree with the reviewer that the table could be formatted to be easier to read, but on balance believe that the current presentation gives a transparent link to the dataset (e.g. enabling these instances to be readily found), preserves all information (e.g. part-of-speech tag) and involves no subjective adjustment.\n\n**\u201cI think the categorization shall benefit the performance most when the difficulties between relation categories are balanced. Does this sound like a correct claim?\u201d**\\\nThe relation categorisation specifies the geometric relationship between word embeddings for each relation type. The geometry corresponding to each relation type is reflective of semantic properties of the relation, e.g. some relations are relatively \u201cvague/loose\u201d (e.g. \u201cmember_of_domain_region\u201d: <rome, gladiator>, <USA, multiple_voting>), which is reflected in a less tightly defined geometric relationship. We believe that such \u201clooseness\u201d increases the difficulty for a model to identify certain relations (analogously to the increasing difficulty human annotators might have in identifying increasingly vague relations).\n\n[1] Carl Allen and Timothy Hospedales. Analogies Explained: Towards Understanding Word Embeddings. ICML, 2019.\\\n[2] Carl Allen, Ivana Balazevic, and Timothy Hospedales. What the Vec? Towards Probabilistically Grounded Embeddings. NeurIPS, 2019."}, "signatures": ["ICLR.cc/2021/Conference/Paper860/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper860/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Interpreting Knowledge Graph Relation Representation from Word Embeddings", "authorids": ["~Carl_Allen1", "~Ivana_Balazevic1", "~Timothy_Hospedales1"], "authors": ["Carl Allen", "Ivana Balazevic", "Timothy Hospedales"], "keywords": ["knowledge graphs", "word embedding", "representation learning"], "abstract": "Many models learn representations of knowledge graph data by exploiting its low-rank latent structure, encoding known relations between entities and enabling unknown facts to be inferred. To predict whether a relation holds between entities, embeddings are typically compared in the latent space following a relation-specific mapping. Whilst their predictive performance has steadily improved, how such models capture the underlying latent structure of semantic information remains unexplained. Building on recent theoretical understanding of word embeddings, we categorise knowledge graph relations into three types and for each derive explicit requirements of their representations. We show that empirical properties of relation representations and the relative performance of leading knowledge graph representation methods are justified by our analysis.", "one-sentence_summary": "Interpreting the structure of knowledge graph relation representation using insight from word embeddings.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "allen|interpreting_knowledge_graph_relation_representation_from_word_embeddings", "pdf": "/pdf/1feb4e4d391a73dd7a1de57536d4621967f6cd43.pdf", "venue": "ICLR 2021 Poster", "venueid": "ICLR.cc/2021/Conference", "_bibtex": "@inproceedings{\nallen2021interpreting,\ntitle={Interpreting Knowledge Graph Relation Representation from Word Embeddings},\nauthor={Carl Allen and Ivana Balazevic and Timothy Hospedales},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=gLWj29369lW}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "gLWj29369lW", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper860/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper860/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper860/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper860/Authors|ICLR.cc/2021/Conference/Paper860/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper860/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923866420, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper860/-/Official_Comment"}}}, {"id": "dMSKxUENazf", "original": null, "number": 5, "cdate": 1605628882991, "ddate": null, "tcdate": 1605628882991, "tmdate": 1605708594410, "tddate": null, "forum": "gLWj29369lW", "replyto": "fQsJIjmExaO", "invitation": "ICLR.cc/2021/Conference/Paper860/-/Official_Comment", "content": {"title": "Response to Reviewer 3", "comment": "Many thanks for your review.\n\n**\u201cIt is not clear which particular framework is used to define the hierarchy of knowledge graph relations.\u201d**\\\nWhere a relation induces a hierarchical (tree) structure over entities, the \u201ctype\u201d of that relation is either specialisation (S) or context shift (C) (by definition, hierarchies are asymmetric so hierarchical relations cannot be type R). For example, the relation \u201cpart of\u201d induces a hierarchy, e.g. bus, wheel, tyre, where words share a common semantic theme (implying a \u201crelatedness\u201d aspect), but are not instances of each other and so the relation is a (generalised) context shift (C) type. The relation \u201cinstance of\u201d forms another hierarchy, e.g. person, officer, petty officer. Words again share a common semantic theme (implying \u201crelatedness\u201d) but are specialisations of each other, so fall under the (generalised) specialisation (S) type.\nTo try to identify hierarchical relations, we use \u201cKrackhardt score\u201d and path length in Tables 3 & 4 (following [1]). However, both of these metrics rely on a KG containing sufficient instances of a relation, since if e.g. a KG contains only \u201cone-way\u201d instances of a symmetric relation (i.e. <a,b> but not <b,a>), then the relation may have a high Krackhardt score/path length and so appear hierarchical even if it is not (e.g. see in Table 3 the relation \u201calso see\u201d capturing synonyms, e.g. <clean, tidy>, <ram, screw>).\n\n**\u201cIt is not discussed the possible benefit of the learned latent structure of knowledge graph models for the performance on downstream tasks, e.g. text classification, or natural language inference.\u201d**\\\nThe aim of this work is to develop a theoretical understanding of how entities and relations can be represented and to bridge the relatively disassociated fields of KG representation and word embedding. Although beyond the scope of our current work, we would hope/expect this to benefit the future development of representation/embedding models and to help interpret downstream processes that use these representations. \n\n**\u201cHow the main contributions relate to the experiments P1 and P2?\u201d**\\\nPrediction P1 relates to high level properties (e.g. model/relation-specific performance) based on our relation categorisation (R, S, C) and the derived geometric structure of relation representations. The first key contribution (p.2) relates to the theory behind this prediction, the second key contribution (note: we have re-ordered them) corresponds to the experiments that support it.\nPrediction P2 relates to specific properties of relation representations. The third key contribution relates to the experiments that support P2, e.g. looking at symmetry and eigenvalues of the relation matrix and the vector norm of the relation vector.\nThanks, we have added cross-references to the key contributions for greater clarity.\n\n**\u201cWhich is the relation between the used knowledge graph categorisation and the related work?\u201d**\\\nVarious ways of describing/categorising knowledge graph relations exist e.g. by symmetry/asymmetry (as identified in [2]) and hierarchy (as identified in [1]). The proposed categorisation, which is based on relation conditions, is novel and delineates relations by the required mathematical form (and complexity) of their representation. \n\n[1] Ivana Balazevic, Carl Allen and Timothy M Hospedales. Multi-relational Poincar\u00e9 Graph Embeddings. NeurIPS 2019.\\\n[2] Th\u00e9o Trouillon, Johannes Welbl, Sebastian Riedel, \u00c9ric Gaussier, and Guillaume Bouchard. Complex Embeddings for Simple Link Prediction. ICML, 2016.\n"}, "signatures": ["ICLR.cc/2021/Conference/Paper860/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper860/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Interpreting Knowledge Graph Relation Representation from Word Embeddings", "authorids": ["~Carl_Allen1", "~Ivana_Balazevic1", "~Timothy_Hospedales1"], "authors": ["Carl Allen", "Ivana Balazevic", "Timothy Hospedales"], "keywords": ["knowledge graphs", "word embedding", "representation learning"], "abstract": "Many models learn representations of knowledge graph data by exploiting its low-rank latent structure, encoding known relations between entities and enabling unknown facts to be inferred. To predict whether a relation holds between entities, embeddings are typically compared in the latent space following a relation-specific mapping. Whilst their predictive performance has steadily improved, how such models capture the underlying latent structure of semantic information remains unexplained. Building on recent theoretical understanding of word embeddings, we categorise knowledge graph relations into three types and for each derive explicit requirements of their representations. We show that empirical properties of relation representations and the relative performance of leading knowledge graph representation methods are justified by our analysis.", "one-sentence_summary": "Interpreting the structure of knowledge graph relation representation using insight from word embeddings.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "allen|interpreting_knowledge_graph_relation_representation_from_word_embeddings", "pdf": "/pdf/1feb4e4d391a73dd7a1de57536d4621967f6cd43.pdf", "venue": "ICLR 2021 Poster", "venueid": "ICLR.cc/2021/Conference", "_bibtex": "@inproceedings{\nallen2021interpreting,\ntitle={Interpreting Knowledge Graph Relation Representation from Word Embeddings},\nauthor={Carl Allen and Ivana Balazevic and Timothy Hospedales},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=gLWj29369lW}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "gLWj29369lW", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper860/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper860/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper860/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper860/Authors|ICLR.cc/2021/Conference/Paper860/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper860/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923866420, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper860/-/Official_Comment"}}}, {"id": "2RI4n3e-i88", "original": null, "number": 4, "cdate": 1605628805117, "ddate": null, "tcdate": 1605628805117, "tmdate": 1605708554041, "tddate": null, "forum": "gLWj29369lW", "replyto": "_stedc535wj", "invitation": "ICLR.cc/2021/Conference/Paper860/-/Official_Comment", "content": {"title": "Response to Reviewer 2", "comment": "Many thanks for your review.\n\n**\u201cThe relation types in the text (four bullet points, p. 4) should perhaps mirror one-to-one the types in figure 1\u201d**\\\nWe have considered this suggestion and agree it would increase clarity in a particular respect. However, we believe that the \u201cspecialisation\u201d subfigure is useful in developing an understanding of different relation types. To try to balance these, we have made the word \u201cspecialisation\u201d bold.\n\n**\u201cContext-shift relations are explained as \"subject to synonyms\", a specialisation should perhaps be explained as hypernyms and context shift e.g. as meronyms\u201d**\\\nThanks, we have added this to the paper.\n"}, "signatures": ["ICLR.cc/2021/Conference/Paper860/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper860/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Interpreting Knowledge Graph Relation Representation from Word Embeddings", "authorids": ["~Carl_Allen1", "~Ivana_Balazevic1", "~Timothy_Hospedales1"], "authors": ["Carl Allen", "Ivana Balazevic", "Timothy Hospedales"], "keywords": ["knowledge graphs", "word embedding", "representation learning"], "abstract": "Many models learn representations of knowledge graph data by exploiting its low-rank latent structure, encoding known relations between entities and enabling unknown facts to be inferred. To predict whether a relation holds between entities, embeddings are typically compared in the latent space following a relation-specific mapping. Whilst their predictive performance has steadily improved, how such models capture the underlying latent structure of semantic information remains unexplained. Building on recent theoretical understanding of word embeddings, we categorise knowledge graph relations into three types and for each derive explicit requirements of their representations. We show that empirical properties of relation representations and the relative performance of leading knowledge graph representation methods are justified by our analysis.", "one-sentence_summary": "Interpreting the structure of knowledge graph relation representation using insight from word embeddings.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "allen|interpreting_knowledge_graph_relation_representation_from_word_embeddings", "pdf": "/pdf/1feb4e4d391a73dd7a1de57536d4621967f6cd43.pdf", "venue": "ICLR 2021 Poster", "venueid": "ICLR.cc/2021/Conference", "_bibtex": "@inproceedings{\nallen2021interpreting,\ntitle={Interpreting Knowledge Graph Relation Representation from Word Embeddings},\nauthor={Carl Allen and Ivana Balazevic and Timothy Hospedales},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=gLWj29369lW}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "gLWj29369lW", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper860/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper860/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper860/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper860/Authors|ICLR.cc/2021/Conference/Paper860/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper860/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923866420, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper860/-/Official_Comment"}}}, {"id": "4tIwidb1gM", "original": null, "number": 6, "cdate": 1605629054103, "ddate": null, "tcdate": 1605629054103, "tmdate": 1605708524791, "tddate": null, "forum": "gLWj29369lW", "replyto": "Rb0isLk9cVD", "invitation": "ICLR.cc/2021/Conference/Paper860/-/Official_Comment", "content": {"title": "Response to Reviewer 4", "comment": "Many thanks for your review.\n\n**\u201cMureI seems quite close in most cases to models that involve multiplicative relatedness\u201d**\\\nWe predict that representations of S and C type relations can require both additive and multiplicative components. Based on comparison of TransE and DistMult (neither of which contain biases and so are fairly comparable), we mention that additive-only models appear in general to perform worse than multiplicative-only. However, the main point is that both additive and multiplicative components are preferable, as shown by the performance of MuRE particularly for S/C relations.\n\n**\u201cthe summary suggests that DistMult is preferable for type R, but MuRe appears to do equally well or better \u2026 it\u2019s not clear under what circumstances (what dataset dependent factor) would point to not choosing MuRe.\u201d**\\\nThat observation is correct: certainly MuRE is the best performing model overall since it is most able to represent all relation types. Our point regarding model selection is that if it were known that a dataset contained only type R relations, then DistMult may be a suitable model choice since the extra additive component of MuRE (useful for other relation types) would be superfluous. However, such redundancy of the additive component would need to be learned or else be detrimental to performance. This is supported in Table 4 for the NELL dataset, where DistMult outperforms all other models for type R relations (team_plays_against_team, clothing_to_go_with_clothing and againt_collaborates_with_agent).\n"}, "signatures": ["ICLR.cc/2021/Conference/Paper860/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper860/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Interpreting Knowledge Graph Relation Representation from Word Embeddings", "authorids": ["~Carl_Allen1", "~Ivana_Balazevic1", "~Timothy_Hospedales1"], "authors": ["Carl Allen", "Ivana Balazevic", "Timothy Hospedales"], "keywords": ["knowledge graphs", "word embedding", "representation learning"], "abstract": "Many models learn representations of knowledge graph data by exploiting its low-rank latent structure, encoding known relations between entities and enabling unknown facts to be inferred. To predict whether a relation holds between entities, embeddings are typically compared in the latent space following a relation-specific mapping. Whilst their predictive performance has steadily improved, how such models capture the underlying latent structure of semantic information remains unexplained. Building on recent theoretical understanding of word embeddings, we categorise knowledge graph relations into three types and for each derive explicit requirements of their representations. We show that empirical properties of relation representations and the relative performance of leading knowledge graph representation methods are justified by our analysis.", "one-sentence_summary": "Interpreting the structure of knowledge graph relation representation using insight from word embeddings.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "allen|interpreting_knowledge_graph_relation_representation_from_word_embeddings", "pdf": "/pdf/1feb4e4d391a73dd7a1de57536d4621967f6cd43.pdf", "venue": "ICLR 2021 Poster", "venueid": "ICLR.cc/2021/Conference", "_bibtex": "@inproceedings{\nallen2021interpreting,\ntitle={Interpreting Knowledge Graph Relation Representation from Word Embeddings},\nauthor={Carl Allen and Ivana Balazevic and Timothy Hospedales},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=gLWj29369lW}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "gLWj29369lW", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper860/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper860/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper860/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper860/Authors|ICLR.cc/2021/Conference/Paper860/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper860/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923866420, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper860/-/Official_Comment"}}}, {"id": "fQsJIjmExaO", "original": null, "number": 2, "cdate": 1603864952875, "ddate": null, "tcdate": 1603864952875, "tmdate": 1605024589066, "tddate": null, "forum": "gLWj29369lW", "replyto": "gLWj29369lW", "invitation": "ICLR.cc/2021/Conference/Paper860/-/Official_Review", "content": {"title": "Interpreting Knowledge Graph Relation Representation From Word Embeddings", "review": "Summary and Contributions\n\nThe authors study the latent semantic properties of word representation models by categorising relations between entities.  The goal is to show that word embeddings and knowledge graph representations learn a common latent structure even if both types of models have different learning objectives.  The main contributions are the mapping of relations between subjects to object word embeddings, categorisation of such relations, and evaluation of the state-of-the-art knowledge graph representations. The study shows that knowledge representation models follow the defined relation conditions.\n\nStrengths\n\n- Clear description of background knowledge needed to understand the proposed study.  \n- The authors perform a comprehensive comparison across different knowledge graph representations.\n- The findings show that there is a connection in the lower dimensional space between word and graph representations.\n\nWeaknesses\n\n- It is not clear which particular framework is used to define the hierarchy of knowledge graph relations.\n- It is not discussed the possible benefit of the learned latent structure of knowledge graph models for the performance on downstream tasks, e.g.  text classification, or natural language inference. \n\nQuestions to the Authors\n\n- How the main contributions relate to the experiments P1 and P2?\n- Could you elaborate on how you define the hierarchy knowledge graph relations.\n- Which is the relation between the used knowledge graph categorisation and the related work?\n", "rating": "7: Good paper, accept", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "signatures": ["ICLR.cc/2021/Conference/Paper860/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper860/AnonReviewer3"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Interpreting Knowledge Graph Relation Representation from Word Embeddings", "authorids": ["~Carl_Allen1", "~Ivana_Balazevic1", "~Timothy_Hospedales1"], "authors": ["Carl Allen", "Ivana Balazevic", "Timothy Hospedales"], "keywords": ["knowledge graphs", "word embedding", "representation learning"], "abstract": "Many models learn representations of knowledge graph data by exploiting its low-rank latent structure, encoding known relations between entities and enabling unknown facts to be inferred. To predict whether a relation holds between entities, embeddings are typically compared in the latent space following a relation-specific mapping. Whilst their predictive performance has steadily improved, how such models capture the underlying latent structure of semantic information remains unexplained. Building on recent theoretical understanding of word embeddings, we categorise knowledge graph relations into three types and for each derive explicit requirements of their representations. We show that empirical properties of relation representations and the relative performance of leading knowledge graph representation methods are justified by our analysis.", "one-sentence_summary": "Interpreting the structure of knowledge graph relation representation using insight from word embeddings.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "allen|interpreting_knowledge_graph_relation_representation_from_word_embeddings", "pdf": "/pdf/1feb4e4d391a73dd7a1de57536d4621967f6cd43.pdf", "venue": "ICLR 2021 Poster", "venueid": "ICLR.cc/2021/Conference", "_bibtex": "@inproceedings{\nallen2021interpreting,\ntitle={Interpreting Knowledge Graph Relation Representation from Word Embeddings},\nauthor={Carl Allen and Ivana Balazevic and Timothy Hospedales},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=gLWj29369lW}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq . ***Please remember to file the Code-of-Ethics report. Once you submitted the review, a link to the report will be visible in the bottom right corner of your review.***", "required": true, "markdown": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}, "forum": "gLWj29369lW", "replyto": "gLWj29369lW", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"], "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper860/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1607428800000, "duedate": 1606752000000, "multiReply": false, "readers": ["everyone"], "tcdate": 1602538133296, "tmdate": 1606915798330, "super": "ICLR.cc/2021/Conference/-/Official_Review", "signatures": ["OpenReview.net"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Paper860/Reviewers", "OpenReview.net/Support"], "id": "ICLR.cc/2021/Conference/Paper860/-/Official_Review"}}}, {"id": "_stedc535wj", "original": null, "number": 3, "cdate": 1603886191377, "ddate": null, "tcdate": 1603886191377, "tmdate": 1605024588999, "tddate": null, "forum": "gLWj29369lW", "replyto": "gLWj29369lW", "invitation": "ICLR.cc/2021/Conference/Paper860/-/Official_Review", "content": {"title": "This paper contributes to understanding the latent structure of low-rank knowledge graph representations. The authors draw a parallel between the embeddings of knowledge graphs and words, in the sense that they capture the same structure of relations.", "review": "Recent works toward the understanding of word embeddings can explain how semantic word relationships, such as similarity, analogy and paraphrasing are encoded as low-rank projections of high dimensional vectors of co-occurrence statistics (Allen et al., 2019). Thus, the semantic relationships correspond to linear relationships of word embeddings. This paper builds on this understanding of (PMI-based) word embeddings aiming at the task of understanding the latent structure of low-rank knowledge graph representations. The authors draw a parallel between the embeddings of knowledge graphs and words under the premise that fundamentally the same structure of relations is captured in different ways. Strong evidence to this premise is provided by starting at encoded semantic relations of word embeddings generalizing them to three types (R,S,C) of knowledge graph relations. The authors analyse the performance of different state-of-the-art knowledge graph models and identify the best performing model per relation type. While a multiplicative model performs best for R-relations (highly related), an additive-multiplicative model should be used for S- (specialisation) or C-type (context-shift) relations. These results correspond to the predictions made beforehand and the theoretically derived loss functions based on the respective conditions of each relation type.\n\nPros:\n\u2022\tThe paper is technically sound, well written and organized and free of typographical errors\n\u2022\tIt focusses on the timely and interesting problem of understanding the latent structure of knowledge graph representations\n\u2022\tThe key strength of the paper is the idea to categorize relations between entities based on the geometric properties of relation representations of word embeddings\n\u2022\tThe theoretically derived loss functions are a strong evidence to why different kind of knowledge graph models perform unequally on the defined relation types\n\nMinor comments:\n\u2022\tThe relation types in the text (four bullet points, p. 4) should perhaps mirror one-to-one the types in figure 1\n\u2022\tContext-shift relations are explained as \"subject to synonyms\", a specialisation should perhaps be explained as hypernyms and context shift e.g. as meronyms\n", "rating": "7: Good paper, accept", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "signatures": ["ICLR.cc/2021/Conference/Paper860/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper860/AnonReviewer2"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Interpreting Knowledge Graph Relation Representation from Word Embeddings", "authorids": ["~Carl_Allen1", "~Ivana_Balazevic1", "~Timothy_Hospedales1"], "authors": ["Carl Allen", "Ivana Balazevic", "Timothy Hospedales"], "keywords": ["knowledge graphs", "word embedding", "representation learning"], "abstract": "Many models learn representations of knowledge graph data by exploiting its low-rank latent structure, encoding known relations between entities and enabling unknown facts to be inferred. To predict whether a relation holds between entities, embeddings are typically compared in the latent space following a relation-specific mapping. Whilst their predictive performance has steadily improved, how such models capture the underlying latent structure of semantic information remains unexplained. Building on recent theoretical understanding of word embeddings, we categorise knowledge graph relations into three types and for each derive explicit requirements of their representations. We show that empirical properties of relation representations and the relative performance of leading knowledge graph representation methods are justified by our analysis.", "one-sentence_summary": "Interpreting the structure of knowledge graph relation representation using insight from word embeddings.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "allen|interpreting_knowledge_graph_relation_representation_from_word_embeddings", "pdf": "/pdf/1feb4e4d391a73dd7a1de57536d4621967f6cd43.pdf", "venue": "ICLR 2021 Poster", "venueid": "ICLR.cc/2021/Conference", "_bibtex": "@inproceedings{\nallen2021interpreting,\ntitle={Interpreting Knowledge Graph Relation Representation from Word Embeddings},\nauthor={Carl Allen and Ivana Balazevic and Timothy Hospedales},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=gLWj29369lW}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq . ***Please remember to file the Code-of-Ethics report. Once you submitted the review, a link to the report will be visible in the bottom right corner of your review.***", "required": true, "markdown": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}, "forum": "gLWj29369lW", "replyto": "gLWj29369lW", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"], "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper860/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1607428800000, "duedate": 1606752000000, "multiReply": false, "readers": ["everyone"], "tcdate": 1602538133296, "tmdate": 1606915798330, "super": "ICLR.cc/2021/Conference/-/Official_Review", "signatures": ["OpenReview.net"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Paper860/Reviewers", "OpenReview.net/Support"], "id": "ICLR.cc/2021/Conference/Paper860/-/Official_Review"}}}, {"id": "Rb0isLk9cVD", "original": null, "number": 4, "cdate": 1603940252022, "ddate": null, "tcdate": 1603940252022, "tmdate": 1605024588937, "tddate": null, "forum": "gLWj29369lW", "replyto": "gLWj29369lW", "invitation": "ICLR.cc/2021/Conference/Paper860/-/Official_Review", "content": {"title": "Clear exposition and hypothesis but underwhelming empirical validation", "review": "This paper aims to establish a theoretical basis for geometric properties of knowledge graph relations and embedded entities by comparing knowledge graph embeddings with word embeddings. Using the insight that the semantic properties of PMI-based word embeddings manifest as linear geometric relationships, they view and compare the relationship embeddings derived from different knowledge graph embedding schemes in this way. \nThe analysis claims to show that when the KG architecture conforms to the presented relation types and conditions (divided into similarity, relatedness, and context shift types), it has better performance of link prediction for that embedding scheme. \n\nThe empirical evaluation focuses on comparison of 4 embedding schemes that have linear transformation score functions (additive, multiplicative, both) on WN18RR and NELL-995 relations for link prediction on several examples of the relation types.\n\nOverall, the paper is well-motivated, cites relevant literature in the theory behind word embeddings, and is generally clearly written. It has a useful proposal for the types and conditions of the three relation types and clear hypothesis for the performance of knowledge graph relation transformations that have certain properties.\n\nHowever, the empirical evaluation does not seem to completely support the claims. TransE is obviously lower performing across relations, but MureI seems quite close in most cases to models that involve multiplacative relatedness, so it\u2019s not obvious to me that MureI performs worse. Further, the summery suggests that DistMult is preferable for type R, but MuRe appears to do equally well or better on most cases, thus it\u2019s not clear under what circumstances (what dataset dependent factor) would point to not choosing MuRe. \nI would expect to see a starker contrast between the performance of the different models per claim type to support the dataset dependent statement. Perhaps another experimental setting, like comparison on non-linear transformation, or other examples, would help support that claim. ", "rating": "6: Marginally above acceptance threshold", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "signatures": ["ICLR.cc/2021/Conference/Paper860/AnonReviewer4"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper860/AnonReviewer4"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Interpreting Knowledge Graph Relation Representation from Word Embeddings", "authorids": ["~Carl_Allen1", "~Ivana_Balazevic1", "~Timothy_Hospedales1"], "authors": ["Carl Allen", "Ivana Balazevic", "Timothy Hospedales"], "keywords": ["knowledge graphs", "word embedding", "representation learning"], "abstract": "Many models learn representations of knowledge graph data by exploiting its low-rank latent structure, encoding known relations between entities and enabling unknown facts to be inferred. To predict whether a relation holds between entities, embeddings are typically compared in the latent space following a relation-specific mapping. Whilst their predictive performance has steadily improved, how such models capture the underlying latent structure of semantic information remains unexplained. Building on recent theoretical understanding of word embeddings, we categorise knowledge graph relations into three types and for each derive explicit requirements of their representations. We show that empirical properties of relation representations and the relative performance of leading knowledge graph representation methods are justified by our analysis.", "one-sentence_summary": "Interpreting the structure of knowledge graph relation representation using insight from word embeddings.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "allen|interpreting_knowledge_graph_relation_representation_from_word_embeddings", "pdf": "/pdf/1feb4e4d391a73dd7a1de57536d4621967f6cd43.pdf", "venue": "ICLR 2021 Poster", "venueid": "ICLR.cc/2021/Conference", "_bibtex": "@inproceedings{\nallen2021interpreting,\ntitle={Interpreting Knowledge Graph Relation Representation from Word Embeddings},\nauthor={Carl Allen and Ivana Balazevic and Timothy Hospedales},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=gLWj29369lW}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq . ***Please remember to file the Code-of-Ethics report. Once you submitted the review, a link to the report will be visible in the bottom right corner of your review.***", "required": true, "markdown": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}, "forum": "gLWj29369lW", "replyto": "gLWj29369lW", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"], "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper860/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1607428800000, "duedate": 1606752000000, "multiReply": false, "readers": ["everyone"], "tcdate": 1602538133296, "tmdate": 1606915798330, "super": "ICLR.cc/2021/Conference/-/Official_Review", "signatures": ["OpenReview.net"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Paper860/Reviewers", "OpenReview.net/Support"], "id": "ICLR.cc/2021/Conference/Paper860/-/Official_Review"}}}, {"id": "7pgcuislNmb", "original": null, "number": 1, "cdate": 1603843082833, "ddate": null, "tcdate": 1603843082833, "tmdate": 1605024588872, "tddate": null, "forum": "gLWj29369lW", "replyto": "gLWj29369lW", "invitation": "ICLR.cc/2021/Conference/Paper860/-/Official_Review", "content": {"title": "Nothing surprised me.", "review": "Based on PMI word embedding, the authors categorize the knowledge graph relations into three types, which serve as the foundation of knowledge analysis. This paper is not well-motived but presents the methodology, well. However, nothing in this paper surprised me, because this seems like a ````''regular'' research in this field.\n\nMajor Concerns:\n1. The motivation is not crystally clear. I suggest the authors explain the motivation in detail, e.g., why different embedding are fundamentally the same (strong claim but no evidence).  I suppose the author would like to align the structure of linguistic semantics and knowledge semantics. However, there is no sufficient evidence for me to accept this alignment. Can you give me some examples or strong evidence to claim the joint learning is not incremental. \n\n2. This paper is indeed fine, except for motivation. Good presentation, the clear methodology, and promising results. However, there are plenty of researches to join the textual info and knowledge info together, which makes this paper not very novel. Besides, based on PMI embedding and relation categorization are still very regular in the field. Thus, I doubt the novelty of this paper. However, compared to these papers published in this field, I think this paper can be accepted. This is the reason why I rate 7 but I still got unsatisfactory about the novelty.\n\nMinor Concerns:\n1. Fig.1: Please specify the legend clearly. \n2. Table 2: For more beginning readers, please revise the examples to human-readable.\n\nDiscussion:\n\nI think the categorization shall benefit the performance most when the difficulties between relation categories are balanced. Does this sound like a correct claim? because in your experiment, I found R is the easiest while S is hardest, and the difficulty different for the two types is large. I don't judge this question. I just want to provide a new idea for your paper to improve.\n", "rating": "7: Good paper, accept", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["ICLR.cc/2021/Conference/Paper860/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper860/AnonReviewer1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Interpreting Knowledge Graph Relation Representation from Word Embeddings", "authorids": ["~Carl_Allen1", "~Ivana_Balazevic1", "~Timothy_Hospedales1"], "authors": ["Carl Allen", "Ivana Balazevic", "Timothy Hospedales"], "keywords": ["knowledge graphs", "word embedding", "representation learning"], "abstract": "Many models learn representations of knowledge graph data by exploiting its low-rank latent structure, encoding known relations between entities and enabling unknown facts to be inferred. To predict whether a relation holds between entities, embeddings are typically compared in the latent space following a relation-specific mapping. Whilst their predictive performance has steadily improved, how such models capture the underlying latent structure of semantic information remains unexplained. Building on recent theoretical understanding of word embeddings, we categorise knowledge graph relations into three types and for each derive explicit requirements of their representations. We show that empirical properties of relation representations and the relative performance of leading knowledge graph representation methods are justified by our analysis.", "one-sentence_summary": "Interpreting the structure of knowledge graph relation representation using insight from word embeddings.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "allen|interpreting_knowledge_graph_relation_representation_from_word_embeddings", "pdf": "/pdf/1feb4e4d391a73dd7a1de57536d4621967f6cd43.pdf", "venue": "ICLR 2021 Poster", "venueid": "ICLR.cc/2021/Conference", "_bibtex": "@inproceedings{\nallen2021interpreting,\ntitle={Interpreting Knowledge Graph Relation Representation from Word Embeddings},\nauthor={Carl Allen and Ivana Balazevic and Timothy Hospedales},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=gLWj29369lW}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq . ***Please remember to file the Code-of-Ethics report. Once you submitted the review, a link to the report will be visible in the bottom right corner of your review.***", "required": true, "markdown": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}, "forum": "gLWj29369lW", "replyto": "gLWj29369lW", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"], "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper860/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1607428800000, "duedate": 1606752000000, "multiReply": false, "readers": ["everyone"], "tcdate": 1602538133296, "tmdate": 1606915798330, "super": "ICLR.cc/2021/Conference/-/Official_Review", "signatures": ["OpenReview.net"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Paper860/Reviewers", "OpenReview.net/Support"], "id": "ICLR.cc/2021/Conference/Paper860/-/Official_Review"}}}], "count": 10}