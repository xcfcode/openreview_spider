{"notes": [{"id": "wXBt-7VM2JE", "original": "fmgqHzH7sS", "number": 2605, "cdate": 1601308288485, "ddate": null, "tcdate": 1601308288485, "tmdate": 1614985670002, "tddate": null, "forum": "wXBt-7VM2JE", "replyto": null, "invitation": "ICLR.cc/2021/Conference/-/Blind_Submission", "content": {"title": "On Single-environment Extrapolations in Graph Classification and Regression Tasks", "authorids": ["~Beatrice_Bevilacqua1", "~Yangze_Zhou1", "~Ryan_L_Murphy1", "~Bruno_Ribeiro1"], "authors": ["Beatrice Bevilacqua", "Yangze Zhou", "Ryan L Murphy", "Bruno Ribeiro"], "keywords": ["Extrapolation", "Graphs", "GNNs", "SCM", "Causality", "Counterfactual Inference"], "abstract": "Extrapolation in graph classification/regression remains an underexplored area of an otherwise rapidly developing field. Our work contributes to a growing literature by providing the first systematic counterfactual modeling framework for extrapolations in graph classification/regression tasks. To show that extrapolation from a single training environment is possible, we develop a connection between certain extrapolation tasks on graph sizes and Lovasz's characterization of graph limits. For these extrapolations, standard graph neural networks (GNNs) will fail, while classifiers using induced homomorphism densities succeed, but mostly on unattributed graphs. Generalizing these density features through a GNN subgraph decomposition allows them to also succeed in more complex attributed graph extrapolation tasks. Finally, our experiments validate our theoretical results and showcase some shortcomings of common (interpolation) methods in the literature.", "one-sentence_summary": "To the best of our knowledge, this is the first work to formalize extrapolation in graph classification tasks using counterfactual inference, showing that extrapolation in graph tasks is possible even if given a single environment in training.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "bevilacqua|on_singleenvironment_extrapolations_in_graph_classification_and_regression_tasks", "pdf": "/pdf/2ff7e3b7be9531ec6770a9c5ba4eaac1a14f4f52.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=QXz4LpWzSg", "_bibtex": "@misc{\nbevilacqua2021on,\ntitle={On Single-environment Extrapolations in Graph Classification and Regression Tasks},\nauthor={Beatrice Bevilacqua and Yangze Zhou and Ryan L Murphy and Bruno Ribeiro},\nyear={2021},\nurl={https://openreview.net/forum?id=wXBt-7VM2JE}\n}"}, "signatures": ["ICLR.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference"], "details": {"replyCount": 18, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"reply": {"readers": {"values-regex": ".*"}, "writers": {"values": ["ICLR.cc/2021/Conference"]}, "signatures": {"values": ["ICLR.cc/2021/Conference"]}, "content": {"authors": {"values": ["Anonymous"]}, "authorids": {"values-regex": ".*"}, "reviewed_version_(pdf)": {"required": false, "description": "Upload a PDF file that ends with .pdf", "value-regex": ".*"}}}, "signatures": ["ICLR.cc/2021/Conference"], "readers": ["everyone"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["~", "OpenReview.net/Support"], "tcdate": 1601308008205, "tmdate": 1614984599368, "id": "ICLR.cc/2021/Conference/-/Blind_Submission"}}, "tauthor": "OpenReview.net"}, {"id": "jsIdyHn0fo", "original": null, "number": 1, "cdate": 1610154259976, "ddate": null, "tcdate": 1610154259976, "tmdate": 1610474093047, "tddate": null, "forum": "wXBt-7VM2JE", "replyto": "wXBt-7VM2JE", "invitation": "ICLR.cc/2021/Conference/Paper2605/-/Decision", "content": {"title": "Final Decision", "decision": "Reject", "comment": "The paper introduces a new extrapolation problem for graph representation learning (they refer to it as ' counterfactual modeling').\nWhile the problem set-up is intriguing and the work likely has merit,  two reviewers (R2 and R4),  found the writing highly problematic and we share their opinion.  Even though some of the concerns they raised, as followed from the rebuttal, were not correct, this confusion, in our view, is largely due to the exposition.  Both these reviewers are experts in geometric deep learning. Their lack of understanding even of relatively central points of the paper, despite clearly investing a large amount of time in reading the paper, indicates that extra work is needed.  The only positive reviewer marked his confidence as very low, provided a rather short review, and did not choose to champion the paper.\n\nWhile the authors tried to address the reviewers' concerns both in rebuttal and by revising the manuscript, we still feel that much more work is needed before it can be presented at a conference. We understand that this is a challenge to present this work in a conference format; it builds on the diverse background (e.g., in graph representation learning and in causal modeling) and considers a novel setting. However, we still feel that it could have been done much more successfully. In principle, this work may benefit from being presented in a journal paper (e.g., jmlr)."}, "signatures": ["ICLR.cc/2021/Conference/Program_Chairs"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference/Program_Chairs"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "On Single-environment Extrapolations in Graph Classification and Regression Tasks", "authorids": ["~Beatrice_Bevilacqua1", "~Yangze_Zhou1", "~Ryan_L_Murphy1", "~Bruno_Ribeiro1"], "authors": ["Beatrice Bevilacqua", "Yangze Zhou", "Ryan L Murphy", "Bruno Ribeiro"], "keywords": ["Extrapolation", "Graphs", "GNNs", "SCM", "Causality", "Counterfactual Inference"], "abstract": "Extrapolation in graph classification/regression remains an underexplored area of an otherwise rapidly developing field. Our work contributes to a growing literature by providing the first systematic counterfactual modeling framework for extrapolations in graph classification/regression tasks. To show that extrapolation from a single training environment is possible, we develop a connection between certain extrapolation tasks on graph sizes and Lovasz's characterization of graph limits. For these extrapolations, standard graph neural networks (GNNs) will fail, while classifiers using induced homomorphism densities succeed, but mostly on unattributed graphs. Generalizing these density features through a GNN subgraph decomposition allows them to also succeed in more complex attributed graph extrapolation tasks. Finally, our experiments validate our theoretical results and showcase some shortcomings of common (interpolation) methods in the literature.", "one-sentence_summary": "To the best of our knowledge, this is the first work to formalize extrapolation in graph classification tasks using counterfactual inference, showing that extrapolation in graph tasks is possible even if given a single environment in training.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "bevilacqua|on_singleenvironment_extrapolations_in_graph_classification_and_regression_tasks", "pdf": "/pdf/2ff7e3b7be9531ec6770a9c5ba4eaac1a14f4f52.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=QXz4LpWzSg", "_bibtex": "@misc{\nbevilacqua2021on,\ntitle={On Single-environment Extrapolations in Graph Classification and Regression Tasks},\nauthor={Beatrice Bevilacqua and Yangze Zhou and Ryan L Murphy and Bruno Ribeiro},\nyear={2021},\nurl={https://openreview.net/forum?id=wXBt-7VM2JE}\n}"}, "tags": [], "invitation": {"reply": {"forum": "wXBt-7VM2JE", "replyto": "wXBt-7VM2JE", "readers": {"values": ["everyone"]}, "writers": {"values": ["ICLR.cc/2021/Conference/Program_Chairs"]}, "signatures": {"values": ["ICLR.cc/2021/Conference/Program_Chairs"]}, "content": {"title": {"value": "Final Decision"}, "decision": {"value-radio": ["Accept (Oral)", "Accept (Spotlight)", "Accept (Poster)", "Reject"]}, "comment": {"value-regex": "[\\S\\s]{0,50000}", "markdown": true}}}, "multiReply": false, "signatures": ["ICLR.cc/2021/Conference"], "readers": ["everyone"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Program_Chairs"], "tcdate": 1610040487516, "tmdate": 1610474093032, "id": "ICLR.cc/2021/Conference/Paper2605/-/Decision"}}}, {"id": "W0ELKsWrcXJ", "original": null, "number": 18, "cdate": 1606282234351, "ddate": null, "tcdate": 1606282234351, "tmdate": 1606282234351, "tddate": null, "forum": "wXBt-7VM2JE", "replyto": "kYv-z7ZEUQ", "invitation": "ICLR.cc/2021/Conference/Paper2605/-/Official_Comment", "content": {"title": "Authors have violated code of ethics", "comment": "The authors have violated the following ICLR code of ethics:\n\nBe Honest, Trustworthy and Transparent\nBe Fair and Take Action not to Discriminate\nRespect the Work Required to Produce New Ideas and Artefacts\n\nIn the author response, the authors threaten the reviewer with offensive phrases such as \"we were just warning you\". \n\nGiven that authors violate of ICLR rules, I will stop responding to their rebuttal, and report the violation to the ethics committee. On the other hand, I still try to be fair and will not decrease the rating of the paper given the authors inappropriate behavior, so I will keep the fair evaluation of this paper -- 3. Further actions will be handled by the ethics committee."}, "signatures": ["ICLR.cc/2021/Conference/Paper2605/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2605/AnonReviewer1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "On Single-environment Extrapolations in Graph Classification and Regression Tasks", "authorids": ["~Beatrice_Bevilacqua1", "~Yangze_Zhou1", "~Ryan_L_Murphy1", "~Bruno_Ribeiro1"], "authors": ["Beatrice Bevilacqua", "Yangze Zhou", "Ryan L Murphy", "Bruno Ribeiro"], "keywords": ["Extrapolation", "Graphs", "GNNs", "SCM", "Causality", "Counterfactual Inference"], "abstract": "Extrapolation in graph classification/regression remains an underexplored area of an otherwise rapidly developing field. Our work contributes to a growing literature by providing the first systematic counterfactual modeling framework for extrapolations in graph classification/regression tasks. To show that extrapolation from a single training environment is possible, we develop a connection between certain extrapolation tasks on graph sizes and Lovasz's characterization of graph limits. For these extrapolations, standard graph neural networks (GNNs) will fail, while classifiers using induced homomorphism densities succeed, but mostly on unattributed graphs. Generalizing these density features through a GNN subgraph decomposition allows them to also succeed in more complex attributed graph extrapolation tasks. Finally, our experiments validate our theoretical results and showcase some shortcomings of common (interpolation) methods in the literature.", "one-sentence_summary": "To the best of our knowledge, this is the first work to formalize extrapolation in graph classification tasks using counterfactual inference, showing that extrapolation in graph tasks is possible even if given a single environment in training.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "bevilacqua|on_singleenvironment_extrapolations_in_graph_classification_and_regression_tasks", "pdf": "/pdf/2ff7e3b7be9531ec6770a9c5ba4eaac1a14f4f52.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=QXz4LpWzSg", "_bibtex": "@misc{\nbevilacqua2021on,\ntitle={On Single-environment Extrapolations in Graph Classification and Regression Tasks},\nauthor={Beatrice Bevilacqua and Yangze Zhou and Ryan L Murphy and Bruno Ribeiro},\nyear={2021},\nurl={https://openreview.net/forum?id=wXBt-7VM2JE}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "wXBt-7VM2JE", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper2605/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper2605/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper2605/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper2605/Authors|ICLR.cc/2021/Conference/Paper2605/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2605/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923846419, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper2605/-/Official_Comment"}}}, {"id": "0plgZx1ZPS", "original": null, "number": 16, "cdate": 1606275510179, "ddate": null, "tcdate": 1606275510179, "tmdate": 1606275613719, "tddate": null, "forum": "wXBt-7VM2JE", "replyto": "MToNomnVt3-", "invitation": "ICLR.cc/2021/Conference/Paper2605/-/Official_Comment", "content": {"title": "Regarding comments", "comment": "Dear Reviewer.\n\nWe do appreciate the time and effort, thank you. It was not our intent to offend you, we were just warning you that we thought much of the criticism was unwarranted. We can tone down the reply if you think it is necessary. Most reviewers these days do not take the time. \n\nWe hope that the reviewer also understands that when one sees, for instance, \u201cNo clear algorithm process or code is given\u201d when the paper actually gave a link to code, the authors will feel that the criticism unfair. Don't you think?\n\nWe have made significant efforts to improve the presentation in our revised version. It is fair to ask for clarifications, or criticize the presentation, or make comments on the merits of the contributions. We believe we can have a healthy discussion and defend our contribution on these merits.\n\nWe feel our work makes a good effort in the right direction. An important future direction in graph representation learning.\n"}, "signatures": ["ICLR.cc/2021/Conference/Paper2605/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2605/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "On Single-environment Extrapolations in Graph Classification and Regression Tasks", "authorids": ["~Beatrice_Bevilacqua1", "~Yangze_Zhou1", "~Ryan_L_Murphy1", "~Bruno_Ribeiro1"], "authors": ["Beatrice Bevilacqua", "Yangze Zhou", "Ryan L Murphy", "Bruno Ribeiro"], "keywords": ["Extrapolation", "Graphs", "GNNs", "SCM", "Causality", "Counterfactual Inference"], "abstract": "Extrapolation in graph classification/regression remains an underexplored area of an otherwise rapidly developing field. Our work contributes to a growing literature by providing the first systematic counterfactual modeling framework for extrapolations in graph classification/regression tasks. To show that extrapolation from a single training environment is possible, we develop a connection between certain extrapolation tasks on graph sizes and Lovasz's characterization of graph limits. For these extrapolations, standard graph neural networks (GNNs) will fail, while classifiers using induced homomorphism densities succeed, but mostly on unattributed graphs. Generalizing these density features through a GNN subgraph decomposition allows them to also succeed in more complex attributed graph extrapolation tasks. Finally, our experiments validate our theoretical results and showcase some shortcomings of common (interpolation) methods in the literature.", "one-sentence_summary": "To the best of our knowledge, this is the first work to formalize extrapolation in graph classification tasks using counterfactual inference, showing that extrapolation in graph tasks is possible even if given a single environment in training.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "bevilacqua|on_singleenvironment_extrapolations_in_graph_classification_and_regression_tasks", "pdf": "/pdf/2ff7e3b7be9531ec6770a9c5ba4eaac1a14f4f52.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=QXz4LpWzSg", "_bibtex": "@misc{\nbevilacqua2021on,\ntitle={On Single-environment Extrapolations in Graph Classification and Regression Tasks},\nauthor={Beatrice Bevilacqua and Yangze Zhou and Ryan L Murphy and Bruno Ribeiro},\nyear={2021},\nurl={https://openreview.net/forum?id=wXBt-7VM2JE}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "wXBt-7VM2JE", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper2605/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper2605/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper2605/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper2605/Authors|ICLR.cc/2021/Conference/Paper2605/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2605/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923846419, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper2605/-/Official_Comment"}}}, {"id": "MToNomnVt3-", "original": null, "number": 15, "cdate": 1606268287789, "ddate": null, "tcdate": 1606268287789, "tmdate": 1606273916681, "tddate": null, "forum": "wXBt-7VM2JE", "replyto": "kYv-z7ZEUQ", "invitation": "ICLR.cc/2021/Conference/Paper2605/-/Official_Comment", "content": {"title": "Concerns not addressed", "comment": "Unfortunately, the concerns are not addressed by the author response.\n\nThe authors claim the review is \"unfair\" without evidence. To see whether the review is fair, I consulted several experts on both GNN and causality on their opinions on this paper. Their opinions reach a consensus: \n\n\"It is unclear what contribution this paper has. The idea of the paper might have been quite simple, yet the presentation is so poor that ICLR readers will not understand or appreciate the paper's contribution.\"\n\nMy initial review agrees with the opinions of several experts, so I raise my confidence to 5 and keep my initial rating.\n\nI encourage authors, however, to stick to ICLR rules. The author response is quite rude and potentially violates the ICLR code of ethics. Authors show no respect towards reviewer's time and effort."}, "signatures": ["ICLR.cc/2021/Conference/Paper2605/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2605/AnonReviewer1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "On Single-environment Extrapolations in Graph Classification and Regression Tasks", "authorids": ["~Beatrice_Bevilacqua1", "~Yangze_Zhou1", "~Ryan_L_Murphy1", "~Bruno_Ribeiro1"], "authors": ["Beatrice Bevilacqua", "Yangze Zhou", "Ryan L Murphy", "Bruno Ribeiro"], "keywords": ["Extrapolation", "Graphs", "GNNs", "SCM", "Causality", "Counterfactual Inference"], "abstract": "Extrapolation in graph classification/regression remains an underexplored area of an otherwise rapidly developing field. Our work contributes to a growing literature by providing the first systematic counterfactual modeling framework for extrapolations in graph classification/regression tasks. To show that extrapolation from a single training environment is possible, we develop a connection between certain extrapolation tasks on graph sizes and Lovasz's characterization of graph limits. For these extrapolations, standard graph neural networks (GNNs) will fail, while classifiers using induced homomorphism densities succeed, but mostly on unattributed graphs. Generalizing these density features through a GNN subgraph decomposition allows them to also succeed in more complex attributed graph extrapolation tasks. Finally, our experiments validate our theoretical results and showcase some shortcomings of common (interpolation) methods in the literature.", "one-sentence_summary": "To the best of our knowledge, this is the first work to formalize extrapolation in graph classification tasks using counterfactual inference, showing that extrapolation in graph tasks is possible even if given a single environment in training.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "bevilacqua|on_singleenvironment_extrapolations_in_graph_classification_and_regression_tasks", "pdf": "/pdf/2ff7e3b7be9531ec6770a9c5ba4eaac1a14f4f52.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=QXz4LpWzSg", "_bibtex": "@misc{\nbevilacqua2021on,\ntitle={On Single-environment Extrapolations in Graph Classification and Regression Tasks},\nauthor={Beatrice Bevilacqua and Yangze Zhou and Ryan L Murphy and Bruno Ribeiro},\nyear={2021},\nurl={https://openreview.net/forum?id=wXBt-7VM2JE}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "wXBt-7VM2JE", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper2605/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper2605/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper2605/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper2605/Authors|ICLR.cc/2021/Conference/Paper2605/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2605/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923846419, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper2605/-/Official_Comment"}}}, {"id": "kYv-z7ZEUQ", "original": null, "number": 3, "cdate": 1603859300473, "ddate": null, "tcdate": 1603859300473, "tmdate": 1606267772638, "tddate": null, "forum": "wXBt-7VM2JE", "replyto": "wXBt-7VM2JE", "invitation": "ICLR.cc/2021/Conference/Paper2605/-/Official_Review", "content": {"title": "Official Review", "review": "Below constitutes the Official Review for Paper2605.\n\nSummary of the paper:\n\nThis paper explores the problem of constructing invariant representations to certain new environments. Specifically, they constrain the problem to a so-called single-environment graph classification or regression task. Authors define a notion of counterfactual coupling, and consider a notion of invariance different from (though not well-justified) the standard literature. Based on the authors' own definition, they consider a few example tasks on random graphs. Under strong assumptions, authors show a couple generalization error bounds. Their bounds appear to be algorithm agnostic and do not take into account the neural network or optimizer properties. On the modeling side, authors propose a model: the model is to simply replace a one-hot vector with a GNN. Small-scale experiments are conducted on two toy datasets to show the proposed model slightly improves four vanilla baselines, on these two toy datasets.\n\nEvaluation:\n\nWhile it is clear that papers like Paper2605 have much to offer, the official recommendation is rejection. \n\nOverall, it is unclear what contribution this paper has. The problem setting is contrived, over-complicated, and not well-defined. It is hard for one to find the theorems meaningful: they assume strong assumptions and contrived settings, and are not applicable to real problems. What conclusion one can draw from the theorems are also quite unclear. The technical proofs are unimpressive either as they appear to be maneuvering the already contrived definitions with basic inequalities. \n\nThe proposed model is unclear, unmotivated, and has logical gaps.  No clear algorithm process or code is given. Reproducibility is impossible. No motivation or theoretical guarantee is given, neither were we given evidence how it may compare to other invariant/causal models such as IRM or domain adaptation techniques.\n\nBecause the theoretical and modeling contributions were unclear, one would expect to see strong experimental results. Yet, the experiments are particularly unconvincing, in that the proposed one had only been evaluated on two toy datasets,  and compared to four baselines. State-of-the-art models such as IRM, REx, domain invariant models are are missing from the comparison. Putting aside the unconvincing execution,  the experiments do not seem to corroborate the theorems (which are ambiguous and unclear anyways) either, making the theoretical/modeling contribution even weaker and more unclear. \n\nAdditionally, one must complain about the poor writing. This paper suffers from the lack of logic and mathematical rigor; it is full of jargons that are unexplained and undefined. For example, after reading the entire paper, one still can't find a definition of GNN or GNN+, which constitute the main part of the proposed model. It is impossible to imagine the ICLR community will appreciate this paper. Based on the evaluation, a rejection is recommended. \n\n$\\textbf{Unclear contribution and contrived/trivial theorems}$ \n\nOne cannot draw any clear conclusion from the theorems. Problem setting and theorems are contrived, over-complicated and not rigorously defined. The technical proofs are unimpressive either as they appear to be maneuvering the already contrived definitions with basic inequalities. \n\n''Definition 1 (Counterfactual coupling (CFC)).'' This definition is simply confusing and contrived. How can you even evaluate over all permutations? This is NP-hard?  The independence assumption is also strong? How is this different from standard definitions? Never explained?\n\n''Proposition 1. Let P(Y |G(obs) N(obs) = G (obs) n(obs)) and P(Y |G(cf) N(cf) = G (cf) n(cf)) be the conditional target distributions ''  Proposition 1 seems to be only stating definitions (generalization error etc), how is this even a proposition? \n\n''Proposition 1. a link function \u03c1(\u00b7, \u00b7) such that'' link function p is never defined. \n\n''assume Y \u2208 Y is discrete'' What about regression?\n\n\n'E \u2208 Z+ that describes the graph-processing environment''.  Graph-processing environment is never defined. What is that?\n\n''supervised task over a graph input Gn(n \u2265 2) and its corresponding output Y''. Problem is undefined. What is graph classification or regression?  Is the response variable over graph, edge, vertex? Is input one graph or many graphs?\n\n'' Consider a permutation-invariant graph representation \u0393 : \u222a\u221e n=1\u2126 n\u00d7n \u2192 R d''  How is this even possible?  Permutation-invariant graph representation is such a strong assumption?\n\n''Proposition 1 shows that an E-invariant representation will perform no worse on the counterfactual\ntest data (extrapolation samples from (Y, G (cf) N(cf))) than on a test dataset having the same environment distribution as the training data (samples from (Y, G (obs) N(obs))).''  Well, this is apparently wrong? Evidence? \n\n''Other notions of E-invariant representations are possible (Arjovsky et al., 2019; Scholkopf, 2019), but ours \u2014through coupling\u2014 provides a direct relationship with how we learn graph representations from a single training environment.''  Not convincing? Evidence? Well, Arjovsky et al., 2019; Scholkopf, 2019 can be applied to graphs too? You are also missing a great amount of literature on invariant models and domain adaptation techniques.\n\n''Theorem 1. Assume our graph-processing heuristic'' What does graph-processing heuristic even mean?\n\n''Theorem1.   the outputs of ge1 and ge2 of Equation (1) can only differ in their attributes \u2200e1, e2'' What does this even mean? Seems too contrived?\n\n''Theorem 1. Deleting a random vertex n from G (obs)n |W, and the distribution of the trimmed graph is the same as the distribution of G (obs)n\u22121|W, with G (obs) 1|W as a trivial graph with a single vertex for all W'' Over-complicated?\n\n''For every 1 < k < n, the subgraphs of G (obs) n |W induced by {1, . . . , k} and {k + 1, . . . , n} are independent random variables'' Why does this hold? Evidence?\n\n''Then, the variable W can be equivalently defined as W = (W0, C0E), where W0 is a random variable defined over the family of symmetric measurable functions W0\n: [0, 1]2 \u2192 [0, 1], i.e., W0 is a random graphon function, and, if the graph has attributes, C0 E is an environment-dependent random\nvariable that defines vertex and edge attributes, otherwise, C0E = \u00d8 is defined as the constant null.'' Unclear what conclusion one can draw from Theorem. Doesn't seem to have useful implications. \n\n''It is possible to guarantee that a graph representation is E-invariant even when the training data contains just one environment.'' This reads apparently wrong? Evidence? \n\n''inj(F, G) be the number of injective homomorphisms of F into a larger unattributed graph G'' Expensive to evaluate? Justification?\n\n''1one-hot{Fk0 , F\u2264k} be the one-hot vector with a one at the index of Fk0 in F\u2264k and zeros elsewhere'' How do you construct this? Not well motivated? \n\n$\\textbf{Trivial and unmotivated modeling}$\n\nThe proposed method (Section 3.2) is not well-motivated and is ambiguous. No clear algorithm is described either, making it impossible to reproduce.\n\n''Hence, our proposal replaces the one-hot vector 1one-hot{Fk0 , F\u2264k} with a GNN applied to Fk0 : ''  What is this one-hot vector? What is GNN? Never defined? Replacing one hot by GNN seems trivial? \n\n''ta-inj(Fk0 , Gn)'' Not well-defined? Algorithm to compute this?\n\n''Unfortunately, GNNs are not most-expressive representations of graphs (Morris et al., 2019; Murphy et al., 2019b; Xu et al., 2018a) and thus \u0393GNN(\u00b7) is less expressive than \u03931-hot(\u00b7) for unattributed graphs.'' What does this even mean? Then why do you use GNN (which is not defined anyways)?\n\n\n$\\textbf{Unconvincing experiments}$\n\nThe proposed model is only evaluated on two toy datasets.\n\nA large amount of baselines on invariant models, causal models, domain adaptation techniques are missing. Just to name a few,\n\nhttps://arxiv.org/abs/1907.02893\n\nhttps://arxiv.org/abs/2003.00688\n\nhttps://arxiv.org/abs/2002.04692\n\nhttps://arxiv.org/abs/1505.07818\n\nhttps://arxiv.org/abs/1911.00804\n\nhttps://arxiv.org/abs/2006.07500\n\nhttps://arxiv.org/abs/2010.07922v1\n\n\nThe proposed model only slightly improves upon four basic baselines on the toy datasets. \n\nThe experiments do not corroborate the theorems (which are inconclusive anyways). \n\n\n$\\textbf{Poor writing and mathematical rigor}$\n\nThe paper is full of jargons that are unexplained and undefined.  Many claims are stated without evidence.\n\n''graphs are simply representations of a natural process rather than the true state''. What does this even mean? Evidence?\n\n'E \u2208 Z+ that describes the graph-processing environment''.  Graph-processing environment is never defined. What is that?\n\n''supervised task over a graph input Gn(n \u2265 2) and its corresponding output Y''. Problem is undefined. What is graph classification or regression?  Is the response variable over graph, edge, vertex? Is input one graph or many graphs?\n\n''graph generation function g : Z+ \u00d7 D \u00d7 D \u2192 \u2126 n\u00d7n'' D is never defined. What is D?\n\n''in some canonical order'' what is the canonical order?\n\n''graphs are simple, meaning all pairs of vertices have at most one edge'' This is a wrong definition of simple graphs?\n\n''Erdos-Renyi example (part 1)''  The problem setting is described by an example. A rigorous definition of problem setting is expected. \n\n''Figure 1: (a) The DAG of the structural causal model (SCM) of our graph extrapolation tasks where hashed (white) vertices'' Hashed (white) vertices do not exist in Figure 1 (a)? What is sampled permutation?\n\n''Illustrates the relationship between expressive model families and most-expressive extrapolation families'' How is this even related?\n\nSCM is never defined? While I know what a SCM is, this presents yet another example of poor writing.\n\n''Single-environment graph extrapolation task''. What does this even mean?  Can you formally define it? Isn't the paper studying invariant models?  https://en.wikipedia.org/wiki/Extrapolation  extrapolation is used in a confusing way, different from wikipedia? \n\n''the value Y = W in Equation (3), which is also the edge probability p'' Well, isn't this too contrived?\n\n''Hence, traditional (interpolation) methods can pick-up this correlation, which prevents the learnt model from extrapolating over environments different than the. ones provided in the training data (or even over different P(E) distributions).'' Well, this is not your contribution, so you need to properly add citation.\n\n''we need a backdoor adjustment'' What is backdoor adjustment? Undefined? Well, although I know what it is, it shows yet another example of lack of mathematical rigor.\n\n''Definition 1 (Counterfactual coupling (CFC)).'' This definition is simply confusing and contrived. How can you even evaluate over all permutations? This is NP-hard?  The independence assumption is also strong? How is this different from standard definitions? Never explained?  \n\n''Proposition 1. Let P(Y |G(obs)\nN(obs) = G\n(obs)\nn(obs)) and P(Y |G(cf)\nN(cf) = G\n(cf)\nn(cf)) be the conditional target distributions ''  Proposition 1 seems to be only stating definitions, how is this a proposition? What do you even mean?  \n\n''Proposition 1. a link function \u03c1(\u00b7, \u00b7) such that'' link function p is never defined?\n\n''Theorem 1. Assume our graph-processing heuristic'' What does graph-processing heuristic even mean?\n\n'' the outputs of ge1 and ge2 of Equation (1) can only differ in their attributes \u2200e1, e2'' What does this even mean? ", "rating": "3: Clear rejection", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}, "signatures": ["ICLR.cc/2021/Conference/Paper2605/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2605/AnonReviewer1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "On Single-environment Extrapolations in Graph Classification and Regression Tasks", "authorids": ["~Beatrice_Bevilacqua1", "~Yangze_Zhou1", "~Ryan_L_Murphy1", "~Bruno_Ribeiro1"], "authors": ["Beatrice Bevilacqua", "Yangze Zhou", "Ryan L Murphy", "Bruno Ribeiro"], "keywords": ["Extrapolation", "Graphs", "GNNs", "SCM", "Causality", "Counterfactual Inference"], "abstract": "Extrapolation in graph classification/regression remains an underexplored area of an otherwise rapidly developing field. Our work contributes to a growing literature by providing the first systematic counterfactual modeling framework for extrapolations in graph classification/regression tasks. To show that extrapolation from a single training environment is possible, we develop a connection between certain extrapolation tasks on graph sizes and Lovasz's characterization of graph limits. For these extrapolations, standard graph neural networks (GNNs) will fail, while classifiers using induced homomorphism densities succeed, but mostly on unattributed graphs. Generalizing these density features through a GNN subgraph decomposition allows them to also succeed in more complex attributed graph extrapolation tasks. Finally, our experiments validate our theoretical results and showcase some shortcomings of common (interpolation) methods in the literature.", "one-sentence_summary": "To the best of our knowledge, this is the first work to formalize extrapolation in graph classification tasks using counterfactual inference, showing that extrapolation in graph tasks is possible even if given a single environment in training.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "bevilacqua|on_singleenvironment_extrapolations_in_graph_classification_and_regression_tasks", "pdf": "/pdf/2ff7e3b7be9531ec6770a9c5ba4eaac1a14f4f52.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=QXz4LpWzSg", "_bibtex": "@misc{\nbevilacqua2021on,\ntitle={On Single-environment Extrapolations in Graph Classification and Regression Tasks},\nauthor={Beatrice Bevilacqua and Yangze Zhou and Ryan L Murphy and Bruno Ribeiro},\nyear={2021},\nurl={https://openreview.net/forum?id=wXBt-7VM2JE}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq . ***Please remember to file the Code-of-Ethics report. Once you submitted the review, a link to the report will be visible in the bottom right corner of your review.***", "required": true, "markdown": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}, "forum": "wXBt-7VM2JE", "replyto": "wXBt-7VM2JE", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"], "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper2605/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1607428800000, "duedate": 1606752000000, "multiReply": false, "readers": ["everyone"], "tcdate": 1602538092570, "tmdate": 1606915796802, "super": "ICLR.cc/2021/Conference/-/Official_Review", "signatures": ["OpenReview.net"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Paper2605/Reviewers", "OpenReview.net/Support"], "id": "ICLR.cc/2021/Conference/Paper2605/-/Official_Review"}}}, {"id": "6Ej_jMM_z6t", "original": null, "number": 4, "cdate": 1605673653347, "ddate": null, "tcdate": 1605673653347, "tmdate": 1605677119449, "tddate": null, "forum": "wXBt-7VM2JE", "replyto": "kYv-z7ZEUQ", "invitation": "ICLR.cc/2021/Conference/Paper2605/-/Official_Comment", "content": {"title": "Thanks for detailed comments, but review is unfair (see replies and updated manuscript for clarifications) Part 5/7 ", "comment": "#### Clarifications\n\n(fair) Q20. ''Theorem 1. Deleting a random vertex n from G (obs)n |W, and the distribution of the trimmed graph is the same as the distribution of G (obs)n\u22121|W, with G (obs) 1|W as a trivial graph with a single vertex for all W'' Over-complicated?\n\n''For every 1 < k < n, the subgraphs of G (obs) n |W induced by {1, . . . , k} and {k + 1, . . . , n} are independent random variables'' Why does this hold? Evidence?\n\nA20. Thank you for the comment. These are not as contrived as it may appear, and we do not invent them for our purposes.  Rather they are shown to be satisfied by a wide class of random graph models in https://arxiv.org/pdf/math/0408173.pdf, please see Theorem 2.7.  We can observe that the original authors argue their generality.  Many familiar models satisfy this, including Erdos-Renyi, Stochastic Block models, motivating our example.  We have made this clearer in the updated manuscript.\n\n(clarification) Q21a. ''Single-environment graph extrapolation task''. What does this even mean? Can you formally define it? Isn't the paper studying invariant models? \n\nA21a. We have made the definition more salient and explicit in our updated manuscript.  To answer formally, please refer to the structural causal model in the paper.  The environment is an integer-valued random variable E, and when we say \u201csingle environment\u201d, we suppose the observed training data were all generated when E took on one specific value.  To give an example, brain graphs generated by measurements all at the same lab, who invoke the same measurement and pre-processing to all subject data.  A detailed explanation of this can be found in the Appendix description of our Schizophrenia experiments in the submitted manuscript.\n\n(unfair) Q21b. https://en.wikipedia.org/wiki/Extrapolation extrapolation is used in a confusing way, different from wikipedia?\n\nA21b. In the first sentence of Section 2, we acknowledge that reasoning beyond the convex hull of the training data is a common way to define extrapolation and provide several references.  This is in essence the definition provided by Wikipedia.  Our following sentences explain and justify why we invoke another perspective.  \n\n(clarification) Q22. ''graph generation function g : Z+ \u00d7 D \u00d7 D \u2192 \u2126 n\u00d7n'' D is never defined. What is D? \n\nA22. [Data generating process] Thank you for pointing this out, we have clarified it and defined the space in the updated manuscript.  We are formalizing our model by supposing that graph data arise from several random variables: (1) an underlying environment E that determines, say, the graph size, (2) a variable W that determines the structure, and (3) irreducible measurement noise.  We are saying that the function g takes in samples from all three random variables and produces a graph.  In our Erdos-Renyi example, if we have many samples from a Bernoulli random variable, then g would place an edge whenever a 1 ( a \u201csuccess\u201d) was sampled.\n\n(fair) Q23. ''Hence, traditional (interpolation) methods can pick-up this correlation, which prevents the learnt model from extrapolating over environments different than the. ones provided in the training data (or even over different P(E) distributions).'' Well, this is not your contribution, so you need to properly add citation.\n\nA23. Thank you. We added references in the updated manuscript.\n\n(fair) Q24. ''Proposition 1. a link function \u03c1(\u00b7, \u00b7) such that'' link function p is never defined\n\nA24. Thank you, a link function is simply a learnable function that outputs the probability of $y$ given the graph. We have changed this definition in the updated manuscript in Proposition 1.\n\n(fair) Q25. ''assume Y \u2208 Y is discrete'' What about regression?\n\nA25. The continuous case is similar but requires significantly more complex measure theory definitions. We added a comment in the updated manuscript in Proposition 1.\n\n(clarification) Q26. ''Theorem 1. Assume our graph-processing heuristic'' What does graph-processing heuristic even mean?\n\nA26. Please see answer A5. We have defined it in the second paragraph of Section 1.\n\n(fair) Q27. ''Theorem1. the outputs of ge1 and ge2 of Equation (1) can only differ in their attributes \u2200e1, e2'' What does this even mean? Seems too contrived?\n\nA27. Thank you, we have removed this sentence in the updated manuscript for better clarity. We have also changed Theorem 1 to unattributed graphs to be more consistent with Theorem 2.7 in https://arxiv.org/pdf/math/0408173.pdf and discussed attributed random graphs in Definition 3 in the updated manuscript."}, "signatures": ["ICLR.cc/2021/Conference/Paper2605/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2605/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "On Single-environment Extrapolations in Graph Classification and Regression Tasks", "authorids": ["~Beatrice_Bevilacqua1", "~Yangze_Zhou1", "~Ryan_L_Murphy1", "~Bruno_Ribeiro1"], "authors": ["Beatrice Bevilacqua", "Yangze Zhou", "Ryan L Murphy", "Bruno Ribeiro"], "keywords": ["Extrapolation", "Graphs", "GNNs", "SCM", "Causality", "Counterfactual Inference"], "abstract": "Extrapolation in graph classification/regression remains an underexplored area of an otherwise rapidly developing field. Our work contributes to a growing literature by providing the first systematic counterfactual modeling framework for extrapolations in graph classification/regression tasks. To show that extrapolation from a single training environment is possible, we develop a connection between certain extrapolation tasks on graph sizes and Lovasz's characterization of graph limits. For these extrapolations, standard graph neural networks (GNNs) will fail, while classifiers using induced homomorphism densities succeed, but mostly on unattributed graphs. Generalizing these density features through a GNN subgraph decomposition allows them to also succeed in more complex attributed graph extrapolation tasks. Finally, our experiments validate our theoretical results and showcase some shortcomings of common (interpolation) methods in the literature.", "one-sentence_summary": "To the best of our knowledge, this is the first work to formalize extrapolation in graph classification tasks using counterfactual inference, showing that extrapolation in graph tasks is possible even if given a single environment in training.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "bevilacqua|on_singleenvironment_extrapolations_in_graph_classification_and_regression_tasks", "pdf": "/pdf/2ff7e3b7be9531ec6770a9c5ba4eaac1a14f4f52.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=QXz4LpWzSg", "_bibtex": "@misc{\nbevilacqua2021on,\ntitle={On Single-environment Extrapolations in Graph Classification and Regression Tasks},\nauthor={Beatrice Bevilacqua and Yangze Zhou and Ryan L Murphy and Bruno Ribeiro},\nyear={2021},\nurl={https://openreview.net/forum?id=wXBt-7VM2JE}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "wXBt-7VM2JE", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper2605/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper2605/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper2605/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper2605/Authors|ICLR.cc/2021/Conference/Paper2605/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2605/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923846419, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper2605/-/Official_Comment"}}}, {"id": "kTwO-NpRi2E", "original": null, "number": 11, "cdate": 1605675762970, "ddate": null, "tcdate": 1605675762970, "tmdate": 1605676638447, "tddate": null, "forum": "wXBt-7VM2JE", "replyto": "fVwoKer8rRp", "invitation": "ICLR.cc/2021/Conference/Paper2605/-/Official_Comment", "content": {"title": "Thanks for positive comments (added clarifications in updated manuscript) Part 2/3 ", "comment": "\nQ4) \u201cTheorem 1 then introduces certain assumptions under which it is possible. I could not understand the conclusions in this theorem. The assumptions basically mean that subgraphs of $G^{obs}$ can be seen as sampled from smaller $n$. Does that mean different $E$ is already available by just sampling subgraphs of the observed data?\u201d\n\nA4) Without attributes, the conditions in Theorem 1 are the necessary and sufficient conditions for a random graphon model as described in the proof of Theorem 1 in the appendix. It is an extension of Theorem 2.7 in https://arxiv.org/abs/math/0408173. Here $W\u2019: [0,1]^2 \\rightarrow [0,1]$ is defined as the graphon function. To be more specific, a graphon is understood as defining an exchangeable random graph model according to the following scheme:\n\n1. For each vertex $j$ in the graph, we assign an independent random value $u_j \\sim U(0,1)$;\n2. Then we assign an edge between vertices $i$ and $j$ with probability $W(u_i,u_j)$ for all pairs of vertices $i$ and $j$.\n\nIn the updated manuscript, we have made Theorem 1 clearer by limiting it to unattributed graphs and we have provided definitions for attributed random graphs we consider in Definition 3.\n\nAs stated in paragraph 1 in Section 3 in the original manuscript, some characteristics of graphs can be stable as their size grows and we want to use graphon concentration inequalities to prove following theorems. It is true that given $G^{(obs)}\\_{n^{(obs)}}$ we can sample subgraphs using vertices less than $n$ to understand how it behaves under different environments $E$. However, in the paper, we will only use training data $G^{(obs)}_{n^{(obs)}}$, and treat observed subgraph densities up to size $k$ ($k\\ll n$) as features for the random graph family and are also stable as further proved in Theorem 2. \nThe purpose of Theorem 1 is to provide conditions for the graph families we are interested in and connect to the random graphon family and how we can formulate them into the structural causal model we have been talked about.\n\nQ5) \u201cUsing these assumptions the authors prove in Theorem 2 that a certain manuscript of subgraph counting provides such an $E$-invariant function. Again the definitions in this Section (3.1) were unclear.\u201d\n\nA5) We formally defined the injected homomorphisms densities in Equation (6) in the original manuscript, and treat the observed densities up to size $k$ as the representation. Now we have rewrote Section 3 for better clarity, and defined the induced homomorphism densities in Section 3.1. We prove in Theorem 2 that this representation is stable for different sizes $N^{\\text{train}},N^{\\text{train}}$ and provide bounds. The representation is not E-invariant but approximately E-invariant as stated in the paper. \n\nQ6) \u201cThey also discuss an extension to graphs with features using some common GNN architectures in Section 3.2. I found this section also hard to follow.\u201d\n\nA6) In the updated manuscript, we have modified the whole Section 3 and added a regularization term for $\\Gamma_{GNN}$ approaches. We describe our motivations better there. Hopefully it is clearer to read.\n\nQ7) \u201cA more concrete concern I had is that I was under the impression that the type of assumption required (in Theorem 1) for building $E$-invariant representations basically means that we have access to different size graphs (through the sub-graph assumptions)  and therefore extrapolation to smaller sizes is possible. I would be interested to know if we can extrapolate to larger graphs in this case.\u201d\n\nA7) As stated in the answers for Q4, in the paper, we will only use training data $G^{(obs)}_{n^{(obs)}}$, and treat observed subgraph densities up to size $k$ ($k\\ll n$) as features for the random graph family and are also stable as proved in Theorem 2. Then, when training data only contains graphs generated by a single environment $E$ (a single size $n$), we are able to extrapolate to any size $n\u2019$ we want since the representation is approximately E-invariant, no matter if $n\u2019$ is larger or smaller. \n\nIn experiments on unattributed graphs, we mainly cared about extrapolation to larger graphs, and we show we can successfully extrapolate to larger graphs in Section 5. We have also added a new stochastic block model task and consider extrapolations based on vertex attributes, and extrapolate to larger sizes (from 20 in training to 40 in test)."}, "signatures": ["ICLR.cc/2021/Conference/Paper2605/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2605/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "On Single-environment Extrapolations in Graph Classification and Regression Tasks", "authorids": ["~Beatrice_Bevilacqua1", "~Yangze_Zhou1", "~Ryan_L_Murphy1", "~Bruno_Ribeiro1"], "authors": ["Beatrice Bevilacqua", "Yangze Zhou", "Ryan L Murphy", "Bruno Ribeiro"], "keywords": ["Extrapolation", "Graphs", "GNNs", "SCM", "Causality", "Counterfactual Inference"], "abstract": "Extrapolation in graph classification/regression remains an underexplored area of an otherwise rapidly developing field. Our work contributes to a growing literature by providing the first systematic counterfactual modeling framework for extrapolations in graph classification/regression tasks. To show that extrapolation from a single training environment is possible, we develop a connection between certain extrapolation tasks on graph sizes and Lovasz's characterization of graph limits. For these extrapolations, standard graph neural networks (GNNs) will fail, while classifiers using induced homomorphism densities succeed, but mostly on unattributed graphs. Generalizing these density features through a GNN subgraph decomposition allows them to also succeed in more complex attributed graph extrapolation tasks. Finally, our experiments validate our theoretical results and showcase some shortcomings of common (interpolation) methods in the literature.", "one-sentence_summary": "To the best of our knowledge, this is the first work to formalize extrapolation in graph classification tasks using counterfactual inference, showing that extrapolation in graph tasks is possible even if given a single environment in training.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "bevilacqua|on_singleenvironment_extrapolations_in_graph_classification_and_regression_tasks", "pdf": "/pdf/2ff7e3b7be9531ec6770a9c5ba4eaac1a14f4f52.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=QXz4LpWzSg", "_bibtex": "@misc{\nbevilacqua2021on,\ntitle={On Single-environment Extrapolations in Graph Classification and Regression Tasks},\nauthor={Beatrice Bevilacqua and Yangze Zhou and Ryan L Murphy and Bruno Ribeiro},\nyear={2021},\nurl={https://openreview.net/forum?id=wXBt-7VM2JE}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "wXBt-7VM2JE", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper2605/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper2605/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper2605/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper2605/Authors|ICLR.cc/2021/Conference/Paper2605/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2605/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923846419, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper2605/-/Official_Comment"}}}, {"id": "UGDdepY7X9D", "original": null, "number": 12, "cdate": 1605675967286, "ddate": null, "tcdate": 1605675967286, "tmdate": 1605675967286, "tddate": null, "forum": "wXBt-7VM2JE", "replyto": "fVwoKer8rRp", "invitation": "ICLR.cc/2021/Conference/Paper2605/-/Official_Comment", "content": {"title": "Thanks for positive comments (added clarifications in updated manuscript) Part 1/3", "comment": "\nWe thank the reviewer for all the comments and suggestions. Due to the page limit, we did not include much details about the background knowledge, such as causal inference, coupling, graph limits theorem. We have uploaded an edited manuscript (in blue) to improve readability. In the updated manuscript, we rewrote Section 3, introduced a regularization method, and added another experiment for attributed graphs using stochastic block model in Section 5.\n\nNow we will address all the concerns and questions that the reviewer has one by one:\n\nQ1) \u201cThen the authors move to define counterfactual coupling of $G^{obs}$ and $Y$. They actually mention equation 1 but i assume this is a mistake and they mean equation 2.\u201d\n\nA1) This is not a typo. In Definition 1, we stated it is the counterfactual coupling of Equations (1) to (3) not just Equation (1), since Equations (1) to (3) together define the graph generation process defined in Figure 1. We have further clarified this point in the updated manuscript.\n\nQ2) \u201cAlso, why $\\tilde{E}$ is used as a regular variable inside $g$? The definition is confusing to me since the event the indicator defines does not necessarily mean $G^{obs}=G^{cf}$. Anyway, I could not really understand what is the object that is defined here.\u201d\n\nA2) Thank you for pointing it out. We had a typo in the equation, where $g_E(W,Z_X)$ was supposed to be $g(E,W,Z_x)$, and $E$ is an input to the function $g$. We have changed it in the updated manuscript.\n\n$G^{obs} \\neq G^{cf}$ but only because of the difference between the environment variables $E$ and $\\tilde{E}$. The trick is coupling the random variables for further proof of Proposition 1. The coupling of two independent variables $D_1$ and $D_2$ is a proof technique that creates a random vector $(D_1^\\dagger,D_2^\\dagger)$, such that $D_i$ and $D_i^\\dagger$ have the same marginal distributions, $i=1,2$, but $D_1^\\dagger$ and $D_2^\\dagger$ are structurally dependent.\nFor instance, if $D_1$ and $D_2$ are independent 6-sided die rolls, then $D_1^\\dagger =  (D + 2) \\text{ mod } 6 + 1$ and $D_2^\\dagger = (D + 1) \\text{ mod } 6 + 1$ are coupled variables corresponding to $D_1$ and $D_2$, respectively, where $D$ is a 6-sided die roll.\n\nIn the Definition 1, we couple $Y, \\mathcal{G}\\_{N^{(obs)}}^{(obs)}$ and $\\mathcal{G}\\_{N^{(cf)}}^{(cf)}$ using common noises $Z_X,Z_Y$ and $W,\\pi$ to describe the whole joint probability and the graph generation process, since a graph generation process takes fixed $Z_X,Z_Y,W,\\pi$ and $E$. The counterfactual setting here is that the counterfactual graph is generated with the same noises but only a different environment $\\tilde{E}$. Note the marginal distribution of $Y, \\mathcal{G}\\_{N^{(obs)}}^{(obs)}$ and $\\mathcal{G}\\_{N^{(cf)}}^{(cf)}$ using this definition is the same as defined in Equations (1) to (3).\n\nQ3) \u201cIn Proposition 1, if I understand correctly, the main point is that given a function $\\Gamma$ that is (almost everywhere) invariant to the environment parameter then good generalization error of this function would also imply good extrapolation error. This feels natural, however, if this is indeed the case, I find it hard to understand the formulation of the difference equations in Prop 1. In particular the equalities between the different $G$, and what is a link function? The definition of $E$-invariant should be defined properly; e.g. , what does \"can be sampled\" mean?\u201d\n\nA3) The review\u2019s understanding is basically correct for Proposition 1. But we need to explain more about the difference between the generalization (interpolation) error and extrapolation error. The equality is based on the Definition 1 which we explained in the previous answer A2, specifically, $\\mathcal{G}\\_{N^{(obs)}}^{(obs)}, \\mathcal{G}\\_{N^{(cf)}}^{(cf)}$ are the random variables, and $G_{n^{(obs)}}^{(obs)}, G\\_{n^{(cf)}}^{(cf)}$ are samples for the random variables.\n\nWe said \u201ccan be sampled\u201d in the original manuscript because we use coupling in Definition 1. As we said, coupling is a definition from Markov Chain. Here \u201ccan be sampled\u201d means $G_{n^{(obs)}}^{(obs)}, G_{n^{(cf)}}^{(cf)}$ are generated using the same $W,Z_X,Z_Y,\\pi$ but only with different environments $E$ and $\\tilde{E}$. In this case, the E-invariant representation $\\Gamma$ should be same for all pairs of $G_{n^{(obs)}}^{(obs)}, G_{n^{(cf)}}^{(cf)}$ that \u201ccan be sampled\u201d.\n\nIn the updated manuscript, we removed this line and said \u201cwhere a.s. (almost surely) means $\\Gamma(G^\\text{(obs)}\\_{n^\\text{(obs)}}) =\\Gamma(G^\\text{(cf)}\\_{n^\\text{(cf)}})$, except for a set of graphs $\\{G^\\text{(obs)}\\_{n^\\text{(obs)}}\\}$ and $\\{G^\\text{(cf)}\\_{n^\\text{(cf)}}\\}$ with zero probability (measure).\u201d for better clarity.\n\nA link function is simply a learnable function that outputs the probability of $y$ given the graph. We have changed this definition in the updated manuscript.\n"}, "signatures": ["ICLR.cc/2021/Conference/Paper2605/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2605/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "On Single-environment Extrapolations in Graph Classification and Regression Tasks", "authorids": ["~Beatrice_Bevilacqua1", "~Yangze_Zhou1", "~Ryan_L_Murphy1", "~Bruno_Ribeiro1"], "authors": ["Beatrice Bevilacqua", "Yangze Zhou", "Ryan L Murphy", "Bruno Ribeiro"], "keywords": ["Extrapolation", "Graphs", "GNNs", "SCM", "Causality", "Counterfactual Inference"], "abstract": "Extrapolation in graph classification/regression remains an underexplored area of an otherwise rapidly developing field. Our work contributes to a growing literature by providing the first systematic counterfactual modeling framework for extrapolations in graph classification/regression tasks. To show that extrapolation from a single training environment is possible, we develop a connection between certain extrapolation tasks on graph sizes and Lovasz's characterization of graph limits. For these extrapolations, standard graph neural networks (GNNs) will fail, while classifiers using induced homomorphism densities succeed, but mostly on unattributed graphs. Generalizing these density features through a GNN subgraph decomposition allows them to also succeed in more complex attributed graph extrapolation tasks. Finally, our experiments validate our theoretical results and showcase some shortcomings of common (interpolation) methods in the literature.", "one-sentence_summary": "To the best of our knowledge, this is the first work to formalize extrapolation in graph classification tasks using counterfactual inference, showing that extrapolation in graph tasks is possible even if given a single environment in training.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "bevilacqua|on_singleenvironment_extrapolations_in_graph_classification_and_regression_tasks", "pdf": "/pdf/2ff7e3b7be9531ec6770a9c5ba4eaac1a14f4f52.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=QXz4LpWzSg", "_bibtex": "@misc{\nbevilacqua2021on,\ntitle={On Single-environment Extrapolations in Graph Classification and Regression Tasks},\nauthor={Beatrice Bevilacqua and Yangze Zhou and Ryan L Murphy and Bruno Ribeiro},\nyear={2021},\nurl={https://openreview.net/forum?id=wXBt-7VM2JE}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "wXBt-7VM2JE", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper2605/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper2605/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper2605/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper2605/Authors|ICLR.cc/2021/Conference/Paper2605/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2605/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923846419, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper2605/-/Official_Comment"}}}, {"id": "1j3mkcANcL5", "original": null, "number": 9, "cdate": 1605674868775, "ddate": null, "tcdate": 1605674868775, "tmdate": 1605675795020, "tddate": null, "forum": "wXBt-7VM2JE", "replyto": "ySpcK1G8eQo", "invitation": "ICLR.cc/2021/Conference/Paper2605/-/Official_Comment", "content": {"title": "Thanks for positive comments (added clarifications in updated manuscript)", "comment": "We thank the reviewer for the positive comments and the suggestions to improve readability. We have uploaded a modified manuscript (in blue) that significantly elaborates on those points. In the updated manuscript, we rewrote Section 3, introduced a regularization term for GNN-based approaches and added a new experiment to better support the theory for attributed graph tasks.\n\nQ1) I recommend elaborating on the graphon function $W\u2019$ defined in Theorem 1 and its relation to graph topology.\n\nA1) In Theorem 1, $W\u2019: [0,1]^2 \\rightarrow [0,1]$ is defined as the graphon function. To be more specific, a graphon is understood as defining an exchangeable random graph model according to the following scheme:\n1. For each vertex j in the graph, we assign an independent random value $u_j \\sim U(0,1)$\n2. Then we assign edge between vertices i and j with probability $W(u_i,u_j)$ for all pairs of vertices i and j ($i \\neq j$)\n\nWe have added a description of a graphon model in our updated manuscript (in blue) and we have modified Theorem 1 by limiting it to the unattributed graphs to be more consistent as in Theorem 2.7 of https://arxiv.org/abs/math/0408173. Then we discuss attributed random graphs in Definition 3.\n\nQ2) Are the conditions of Theorem 1 violated by any large class of graph models, such as MRFs?\n\nA2) The conditions of Theorem 1 are shown to be satisfied by a wide class of random graph models (see Lovasz and Szegedy, 2004) https://arxiv.org/pdf/math/0408173.pdf. Our approach should satisfy graph models such as Exponential random graph models (ERGMs), which are energy-based graph models (EBM) (Holland & ,Leinhardt, 1981), as long as the EBM can describe graphs of any size (e.g., Chatterjee & Diaconis, 2013). We added a note to the updated manuscript. Unfortunately, MRFs do not fall in this category.\n\n\nHolland, P. W., and Leinhardt, S. (1981), An Exponential Family of Probability Distributions for Directed Graphs, J. Am. Stat. Assoc., 76, 33-50\n\nChatterjee, Sourav, and Persi Diaconis. \"Estimating and understanding exponential random graph models.\" The Annals of Statistics 41, no. 5 (2013): 2428-2461.\n"}, "signatures": ["ICLR.cc/2021/Conference/Paper2605/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2605/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "On Single-environment Extrapolations in Graph Classification and Regression Tasks", "authorids": ["~Beatrice_Bevilacqua1", "~Yangze_Zhou1", "~Ryan_L_Murphy1", "~Bruno_Ribeiro1"], "authors": ["Beatrice Bevilacqua", "Yangze Zhou", "Ryan L Murphy", "Bruno Ribeiro"], "keywords": ["Extrapolation", "Graphs", "GNNs", "SCM", "Causality", "Counterfactual Inference"], "abstract": "Extrapolation in graph classification/regression remains an underexplored area of an otherwise rapidly developing field. Our work contributes to a growing literature by providing the first systematic counterfactual modeling framework for extrapolations in graph classification/regression tasks. To show that extrapolation from a single training environment is possible, we develop a connection between certain extrapolation tasks on graph sizes and Lovasz's characterization of graph limits. For these extrapolations, standard graph neural networks (GNNs) will fail, while classifiers using induced homomorphism densities succeed, but mostly on unattributed graphs. Generalizing these density features through a GNN subgraph decomposition allows them to also succeed in more complex attributed graph extrapolation tasks. Finally, our experiments validate our theoretical results and showcase some shortcomings of common (interpolation) methods in the literature.", "one-sentence_summary": "To the best of our knowledge, this is the first work to formalize extrapolation in graph classification tasks using counterfactual inference, showing that extrapolation in graph tasks is possible even if given a single environment in training.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "bevilacqua|on_singleenvironment_extrapolations_in_graph_classification_and_regression_tasks", "pdf": "/pdf/2ff7e3b7be9531ec6770a9c5ba4eaac1a14f4f52.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=QXz4LpWzSg", "_bibtex": "@misc{\nbevilacqua2021on,\ntitle={On Single-environment Extrapolations in Graph Classification and Regression Tasks},\nauthor={Beatrice Bevilacqua and Yangze Zhou and Ryan L Murphy and Bruno Ribeiro},\nyear={2021},\nurl={https://openreview.net/forum?id=wXBt-7VM2JE}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "wXBt-7VM2JE", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper2605/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper2605/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper2605/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper2605/Authors|ICLR.cc/2021/Conference/Paper2605/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2605/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923846419, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper2605/-/Official_Comment"}}}, {"id": "wAwnFhm_yJ1", "original": null, "number": 10, "cdate": 1605675376361, "ddate": null, "tcdate": 1605675376361, "tmdate": 1605675376361, "tddate": null, "forum": "wXBt-7VM2JE", "replyto": "fVwoKer8rRp", "invitation": "ICLR.cc/2021/Conference/Paper2605/-/Official_Comment", "content": {"title": "Thanks for positive comments (added clarifications in updated manuscript) Part 3/3", "comment": "Q8) \u201cLastly, subgraph counting is computationally and memory demanding. Maybe empirically quantifying the cost (k?)-extrapolation trade off could be useful.\u201d\n\nA8) The cost is really in pre-processing the graphs. There is no cost in training for estimating the induced homomorphism densities. Specifically, we pre-process each graph beforehand and save the obtained estimated induced homomorphism densities for all of our proposed methods. The cost of preprocessing a graph depends on the used algorithms, as detailed in \u201cPractical Considerations\u201d in Section 3. ESCAPE (Pinar et al., 2017) is extremely efficient, but it is limited to unattributed subgraphs of size $\\leq 5$. To pre-process an attributed graph we used R-GPM (Teixeira et al., 2018), which takes 20 minutes per graph, but graphs can be pre-processed in parallel. For a comprehensive discussion, see (Teixeira et al, 2018) https://arxiv.org/abs/1809.05241."}, "signatures": ["ICLR.cc/2021/Conference/Paper2605/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2605/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "On Single-environment Extrapolations in Graph Classification and Regression Tasks", "authorids": ["~Beatrice_Bevilacqua1", "~Yangze_Zhou1", "~Ryan_L_Murphy1", "~Bruno_Ribeiro1"], "authors": ["Beatrice Bevilacqua", "Yangze Zhou", "Ryan L Murphy", "Bruno Ribeiro"], "keywords": ["Extrapolation", "Graphs", "GNNs", "SCM", "Causality", "Counterfactual Inference"], "abstract": "Extrapolation in graph classification/regression remains an underexplored area of an otherwise rapidly developing field. Our work contributes to a growing literature by providing the first systematic counterfactual modeling framework for extrapolations in graph classification/regression tasks. To show that extrapolation from a single training environment is possible, we develop a connection between certain extrapolation tasks on graph sizes and Lovasz's characterization of graph limits. For these extrapolations, standard graph neural networks (GNNs) will fail, while classifiers using induced homomorphism densities succeed, but mostly on unattributed graphs. Generalizing these density features through a GNN subgraph decomposition allows them to also succeed in more complex attributed graph extrapolation tasks. Finally, our experiments validate our theoretical results and showcase some shortcomings of common (interpolation) methods in the literature.", "one-sentence_summary": "To the best of our knowledge, this is the first work to formalize extrapolation in graph classification tasks using counterfactual inference, showing that extrapolation in graph tasks is possible even if given a single environment in training.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "bevilacqua|on_singleenvironment_extrapolations_in_graph_classification_and_regression_tasks", "pdf": "/pdf/2ff7e3b7be9531ec6770a9c5ba4eaac1a14f4f52.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=QXz4LpWzSg", "_bibtex": "@misc{\nbevilacqua2021on,\ntitle={On Single-environment Extrapolations in Graph Classification and Regression Tasks},\nauthor={Beatrice Bevilacqua and Yangze Zhou and Ryan L Murphy and Bruno Ribeiro},\nyear={2021},\nurl={https://openreview.net/forum?id=wXBt-7VM2JE}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "wXBt-7VM2JE", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper2605/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper2605/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper2605/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper2605/Authors|ICLR.cc/2021/Conference/Paper2605/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2605/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923846419, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper2605/-/Official_Comment"}}}, {"id": "v2SqvPZyr0T", "original": null, "number": 8, "cdate": 1605674319929, "ddate": null, "tcdate": 1605674319929, "tmdate": 1605674319929, "tddate": null, "forum": "wXBt-7VM2JE", "replyto": "kYv-z7ZEUQ", "invitation": "ICLR.cc/2021/Conference/Paper2605/-/Official_Comment", "content": {"title": "Thanks for detailed comments, but review is unfair (see replies and updated manuscript for clarifications) Part 1/7", "comment": "**Overall comments**\n\n We thank the reviewer for taking the time to write the comments. The reviewer raises some points about clarity but also makes a number of unfair comments. Overall, we expected the wild varying scores, since our work starts a discussion about extrapolations in Graph Representation Learning.\n\n(Domain Adaptation can\u2019t work in our setting) First, a clear confusion (and the paper has a paragraph about this): Domain Adaptation methods are not counterfactual methods. In covariate shifts (domain adaptation over the input x), one must be given input examples from the test distribution. These are *very* different things (only in very specific settings they are related https://arxiv.org/pdf/1605.03661.pdf). Domain adaptation cannot be used in our setting. We can write a proof in the appendix if the reviewer is not convinced.\n\n(Invariant Risk Minimization can\u2019t work in our setting) First, the reviewer cites other works related to Invariant Risk Minimization. We cited some but not all IRM work since they all make the same assumptions: Training data has multiple environments. In this paper, as we stated, we are interested in extrapolation from a *single environment*.  The reviewer\u2019s reaction to Proposition 1: \u201cWell, this is apparently wrong? Evidence?\u201d shows that extrapolating from a single environment is counter-intuitive. Consider our graphon extrapolation scenario. Learning a sufficient statistic of the graphon is enough to extrapolate to any size distribution in the test, even if training provides only a single size.\n\n(Misunderstanding the goal of our experiments) Our goal is to provide empirical verification of our theoretical predictions. We do not show more benchmark datasets or \u201creal world\u201d datasets as (1) to the best of our knowledge, and after an extensive literature search, we were unable to find any suitable ones to illustrate our problem of single-environment extrapolation, (2) our focus is not to propose a new architecture but a new perspective and framework for extrapolations on graphs invoking causality and graph limit theory.  Our experiments were thus designed to isolate the specific phenomena that we studied.  For instance, the Erdos-Renyi and the (new) Stochastic Block Model tasks were chosen as this random graph family.  We were more interested in the **extrapolation** behavior of methods under our framework and those that are not rather than the **generalization/interpolation** raw performance, as our results show. \n\nWe have uploaded a modified manuscript (in blue) that significantly elaborates on the confusing points raised by the reviewer. In the updated manuscript, we rewrote Section 3 to improve readability, introduced a regularization term for GNN-based approaches, and added another experiment for attributed graphs using stochastic block model in Section 5."}, "signatures": ["ICLR.cc/2021/Conference/Paper2605/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2605/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "On Single-environment Extrapolations in Graph Classification and Regression Tasks", "authorids": ["~Beatrice_Bevilacqua1", "~Yangze_Zhou1", "~Ryan_L_Murphy1", "~Bruno_Ribeiro1"], "authors": ["Beatrice Bevilacqua", "Yangze Zhou", "Ryan L Murphy", "Bruno Ribeiro"], "keywords": ["Extrapolation", "Graphs", "GNNs", "SCM", "Causality", "Counterfactual Inference"], "abstract": "Extrapolation in graph classification/regression remains an underexplored area of an otherwise rapidly developing field. Our work contributes to a growing literature by providing the first systematic counterfactual modeling framework for extrapolations in graph classification/regression tasks. To show that extrapolation from a single training environment is possible, we develop a connection between certain extrapolation tasks on graph sizes and Lovasz's characterization of graph limits. For these extrapolations, standard graph neural networks (GNNs) will fail, while classifiers using induced homomorphism densities succeed, but mostly on unattributed graphs. Generalizing these density features through a GNN subgraph decomposition allows them to also succeed in more complex attributed graph extrapolation tasks. Finally, our experiments validate our theoretical results and showcase some shortcomings of common (interpolation) methods in the literature.", "one-sentence_summary": "To the best of our knowledge, this is the first work to formalize extrapolation in graph classification tasks using counterfactual inference, showing that extrapolation in graph tasks is possible even if given a single environment in training.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "bevilacqua|on_singleenvironment_extrapolations_in_graph_classification_and_regression_tasks", "pdf": "/pdf/2ff7e3b7be9531ec6770a9c5ba4eaac1a14f4f52.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=QXz4LpWzSg", "_bibtex": "@misc{\nbevilacqua2021on,\ntitle={On Single-environment Extrapolations in Graph Classification and Regression Tasks},\nauthor={Beatrice Bevilacqua and Yangze Zhou and Ryan L Murphy and Bruno Ribeiro},\nyear={2021},\nurl={https://openreview.net/forum?id=wXBt-7VM2JE}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "wXBt-7VM2JE", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper2605/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper2605/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper2605/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper2605/Authors|ICLR.cc/2021/Conference/Paper2605/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2605/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923846419, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper2605/-/Official_Comment"}}}, {"id": "_dItrVoHJHI", "original": null, "number": 7, "cdate": 1605674215888, "ddate": null, "tcdate": 1605674215888, "tmdate": 1605674215888, "tddate": null, "forum": "wXBt-7VM2JE", "replyto": "kYv-z7ZEUQ", "invitation": "ICLR.cc/2021/Conference/Paper2605/-/Official_Comment", "content": {"title": "Thanks for detailed comments, but review is unfair (see replies and updated manuscript for clarifications) Part 2/7", "comment": "**Detailed Comments**\n\nWe proceed comment-by-comment to offer explanations to sources of confusion. We also use this section to better understand which criticisms are fair, arise from unfamiliarity, or are unfair.  Some answers are tagged so that they can be referred to.\n\n(unfair) Q1. \u201c Consider a permutation-invariant graph representation \u0393 : \u222a\u221e n=1\u2126 n\u00d7n \u2192 R d'' How is this even possible? Permutation-invariant graph representation is such a strong assumption?\u201d\n\nA1. Nearly all graph representation learning papers make this same \u201cassumption\u201d (it is actually an inductive bias).  We recommend the reviews by Bloem-Reddy and Teh https://www.jmlr.org/papers/volume21/19-322/19-322.pdf  and Battaglia et al https://arxiv.org/abs/1806.01261 for a deeper understanding of the role of permutation invariance on graph representation learning. \n\n(unfair) Q2. \u201c''Definition 1 (Counterfactual coupling (CFC)).'' This definition is simply confusing and contrived. How can you even evaluate over all permutations? This is NP-hard? The independence assumption is also strong? How is this different from standard definitions? Never explained?\u201d \n\nA2. Some of the confusion seems to arise from the fact that Definition 1 characterizes \u201cA counterfactual coupling of **Equations (1) to (3)**\u201d, and reviewing these equations is necessary to appreciate the definition.  These make the (natural) indepence structures clear, and we do not impose extra independence assumptions in the definition.\n\nAs is often the case, computation need not follow the definition literally, and we do not need to average over all permutations.  As explained throughout the paper, we utilize permutation-invariant graph representations (as is standard practice), so we do not need to evaluate over all permutations. Thus the concern of NP-Hardness does not apply to this definition.\n\nRegarding the reason for the definition, standard counterfactual definitions use the \u201cdo\u201d operator, but to define $\\Gamma(X^{(obs)}) a.s. = \\Gamma(X^{(cf)})$ in our paper this would need it to be defined through the structural equation models since the do() operator does not automatically couple the random variables. We find our notation simpler. We acknowledge that the concept of the counterfactual coupling is non-trivial and we have added more detailed descriptions for the counterfactual coupling in Section 2 above the Definition 1 in the updated manuscript.\n\nWe made it clear that, to the best of our knowledge, this is the first paper taking a causality-motivated approach to extrapolation in graphs and we included comments throughout as to why we are taking the perspectives we do (e.g. first paragraph of Section 2). \n\n(unfair) Q3. \u201cNo clear algorithm process or code is given\u201d \n\nA3. Not true. The paper has a link to the code in Section 5. We just accessed our 4open.science link and it was up. Instantiations of our method were shown in Equations (7) to (9) in the updated manuscript ((8) to (10) in the original one). The \u201cpractical considerations\u201d in Section 3.3 in the original manuscript discussed implementation issues such as efficiently estimating the induced homomorphism densities. We moved the discussion to Section 3.1 in the updated manuscript.\n\n(unfair) Q4. \u201cState-of-the-art models such as IRM, REx, domain invariant models are missing from the comparison\u201d \n\nA4. These don\u2019t apply since we have only one environment in testing and no access to the test distribution. We discussed this in Section 1. In the updated manuscript, we have also added a definition of single-environment extrapolation.  \n\n(unfair) Q5. \u201c'E \u2208 Z+ that describes the graph-processing environment''. Graph-processing environment is never defined. What is that?\u201d \n\nA5. [graph processing environment] In the first line of the second paragraph in Section 1, we define \u201cgraph-processing environment as the collection of heuristics and other data curation processes that gave us the observed graph from the true state of the process under consideration.\u201d More specifically, we provided examples of how data curation processes and other heuristics are applied to extract graphs from true underlying processes, from functional brain connectomes to social networks in the first paragraph of Section 1."}, "signatures": ["ICLR.cc/2021/Conference/Paper2605/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2605/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "On Single-environment Extrapolations in Graph Classification and Regression Tasks", "authorids": ["~Beatrice_Bevilacqua1", "~Yangze_Zhou1", "~Ryan_L_Murphy1", "~Bruno_Ribeiro1"], "authors": ["Beatrice Bevilacqua", "Yangze Zhou", "Ryan L Murphy", "Bruno Ribeiro"], "keywords": ["Extrapolation", "Graphs", "GNNs", "SCM", "Causality", "Counterfactual Inference"], "abstract": "Extrapolation in graph classification/regression remains an underexplored area of an otherwise rapidly developing field. Our work contributes to a growing literature by providing the first systematic counterfactual modeling framework for extrapolations in graph classification/regression tasks. To show that extrapolation from a single training environment is possible, we develop a connection between certain extrapolation tasks on graph sizes and Lovasz's characterization of graph limits. For these extrapolations, standard graph neural networks (GNNs) will fail, while classifiers using induced homomorphism densities succeed, but mostly on unattributed graphs. Generalizing these density features through a GNN subgraph decomposition allows them to also succeed in more complex attributed graph extrapolation tasks. Finally, our experiments validate our theoretical results and showcase some shortcomings of common (interpolation) methods in the literature.", "one-sentence_summary": "To the best of our knowledge, this is the first work to formalize extrapolation in graph classification tasks using counterfactual inference, showing that extrapolation in graph tasks is possible even if given a single environment in training.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "bevilacqua|on_singleenvironment_extrapolations_in_graph_classification_and_regression_tasks", "pdf": "/pdf/2ff7e3b7be9531ec6770a9c5ba4eaac1a14f4f52.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=QXz4LpWzSg", "_bibtex": "@misc{\nbevilacqua2021on,\ntitle={On Single-environment Extrapolations in Graph Classification and Regression Tasks},\nauthor={Beatrice Bevilacqua and Yangze Zhou and Ryan L Murphy and Bruno Ribeiro},\nyear={2021},\nurl={https://openreview.net/forum?id=wXBt-7VM2JE}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "wXBt-7VM2JE", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper2605/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper2605/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper2605/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper2605/Authors|ICLR.cc/2021/Conference/Paper2605/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2605/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923846419, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper2605/-/Official_Comment"}}}, {"id": "JvJM6LUfvyf", "original": null, "number": 6, "cdate": 1605674012479, "ddate": null, "tcdate": 1605674012479, "tmdate": 1605674012479, "tddate": null, "forum": "wXBt-7VM2JE", "replyto": "kYv-z7ZEUQ", "invitation": "ICLR.cc/2021/Conference/Paper2605/-/Official_Comment", "content": {"title": "Thanks for detailed comments, but review is unfair (see replies and updated manuscript for clarifications) Part 3/7", "comment": "\n(unfair) Q6. ''Proposition 1. Let P(Y |G(obs) N(obs) = G (obs) n(obs)) and P(Y |G(cf) N(cf) = G (cf) n(cf)) be the conditional target distributions '' Proposition 1 seems to be only stating definitions (generalization error etc), how is this even a proposition?\u201d\n\nA6. In the first line of the paragraph under Proposition 1, we described the role of Proposition 1 . More specifically, Proposition 1 defines the generalization error, interpolation error and an environment-invariant representation under our framework. Then it shows that an environment-invariant representation will perform no worse on the counterfactual test data (samples from the extrapolation environment which is different from the training environment) than on a test dataset having the same environment distribution as the training data. Obviously, it is not just a definition.\n\n(unfair) Q7. ''supervised task over a graph input Gn(n \u2265 2) and its corresponding output Y''. Problem is undefined. What is graph classification or regression? Is the response variable over graph, edge, vertex? Is input one graph or many graphs?\u201d\n\nA7. Using the terminology that graph classification refers to a graph-level response, in contrast with vertex- or edge-level responses, is common practice to a point where we did not feel any more needed to be said.  See, for instance: https://arxiv.org/pdf/1812.04202.pdf.  Our paragraph heading, to name one instance, makes it clear that we are referring to graph classification.\n\n(unfair) Q8. ''Proposition 1 shows that an E-invariant representation will perform no worse on the counterfactual test data (extrapolation samples from (Y, G (cf) N(cf))) than on a test dataset having the same environment distribution as the training data (samples from (Y, G (obs) N(obs))).'' Well, this is apparently wrong? Evidence? \n\nA8. The evidence is Proposition 1 itself, which asserts that an E-invariant representation incurs an extrapolation error no bigger than the interpolation error. It is somewhat counterintuitive but true (the proof is in Appendix 1).\n\n(unfair) Q9. ''Other notions of E-invariant representations are possible (Arjovsky et al., 2019; Scholkopf, 2019), but ours \u2014through coupling\u2014 provides a direct relationship with how we learn graph representations from a single training environment.'' Not convincing? Evidence? Well, Arjovsky et al., 2019; Scholkopf, 2019 can be applied to graphs too? You are also missing a great amount of literature on invariant models and domain adaptation techniques.  \n\nA9. We have stated in the Introduction that graph datasets largely contain only a single environment, while common E-invariant representation methods require training data from multiple environments (Arjovsky et al., 2019; Scholkopf, 2019). We expanded this literature in the introduction section, the related work section, and the extended related work in the appendix. In the updated manuscript, we have added the definition of single-environment extrapolation in Section 2.\n\n(unfair) Q10. ''ta-inj(Fk0 , Gn)'' Not well-defined? Algorithm to compute this?  \n\nA10. Not true. This is defined in the first paragraph of Section 3.2 by extending Eq 6 in the original manuscript. We mentioned algorithms to compute it in practice in the second paragraph of Section 3.3 in the original manuscript. To avoid confusion, we have rewritten Section 3 and removed $t_{\\text{a-inj}}(F_k,G_n)$ in the updated manuscript.\n\n(unfair) Q11. SCM is never defined? While I know what a SCM is, this presents yet another example of poor writing. \n\nA11. Not true. From the last line in the second paragraph of Section 2 we cited \u201cstructural causal model (SCM) (Pearl, 2009, Definition 7.1.1).\u201d\n\n(unfair) Q12. ''we need a backdoor adjustment'' What is backdoor adjustment? Undefined? Well, although I know what it is, it shows yet another example of lack of mathematical rigor. \n\nA12. Not true. In Section 2 we cited a textbook and a specific theorem to refer to \u201cwe need a backdoor adjustment (Pearl,  2009, Theorem 3.3.2)\u201d.\n"}, "signatures": ["ICLR.cc/2021/Conference/Paper2605/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2605/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "On Single-environment Extrapolations in Graph Classification and Regression Tasks", "authorids": ["~Beatrice_Bevilacqua1", "~Yangze_Zhou1", "~Ryan_L_Murphy1", "~Bruno_Ribeiro1"], "authors": ["Beatrice Bevilacqua", "Yangze Zhou", "Ryan L Murphy", "Bruno Ribeiro"], "keywords": ["Extrapolation", "Graphs", "GNNs", "SCM", "Causality", "Counterfactual Inference"], "abstract": "Extrapolation in graph classification/regression remains an underexplored area of an otherwise rapidly developing field. Our work contributes to a growing literature by providing the first systematic counterfactual modeling framework for extrapolations in graph classification/regression tasks. To show that extrapolation from a single training environment is possible, we develop a connection between certain extrapolation tasks on graph sizes and Lovasz's characterization of graph limits. For these extrapolations, standard graph neural networks (GNNs) will fail, while classifiers using induced homomorphism densities succeed, but mostly on unattributed graphs. Generalizing these density features through a GNN subgraph decomposition allows them to also succeed in more complex attributed graph extrapolation tasks. Finally, our experiments validate our theoretical results and showcase some shortcomings of common (interpolation) methods in the literature.", "one-sentence_summary": "To the best of our knowledge, this is the first work to formalize extrapolation in graph classification tasks using counterfactual inference, showing that extrapolation in graph tasks is possible even if given a single environment in training.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "bevilacqua|on_singleenvironment_extrapolations_in_graph_classification_and_regression_tasks", "pdf": "/pdf/2ff7e3b7be9531ec6770a9c5ba4eaac1a14f4f52.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=QXz4LpWzSg", "_bibtex": "@misc{\nbevilacqua2021on,\ntitle={On Single-environment Extrapolations in Graph Classification and Regression Tasks},\nauthor={Beatrice Bevilacqua and Yangze Zhou and Ryan L Murphy and Bruno Ribeiro},\nyear={2021},\nurl={https://openreview.net/forum?id=wXBt-7VM2JE}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "wXBt-7VM2JE", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper2605/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper2605/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper2605/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper2605/Authors|ICLR.cc/2021/Conference/Paper2605/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2605/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923846419, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper2605/-/Official_Comment"}}}, {"id": "yugM_O1zSz", "original": null, "number": 5, "cdate": 1605673861693, "ddate": null, "tcdate": 1605673861693, "tmdate": 1605673861693, "tddate": null, "forum": "wXBt-7VM2JE", "replyto": "kYv-z7ZEUQ", "invitation": "ICLR.cc/2021/Conference/Paper2605/-/Official_Comment", "content": {"title": "Thanks for detailed comments, but review is unfair (see replies and updated manuscript for clarifications) Part 4/7", "comment": "(unfair) Q13. ''the value Y = W in Equation (3), which is also the edge probability p'' Well, isn't this too contrived?  \n\nA13. We respectfully disagree that this is contrived.  We are not sure what is meant, so we provide a few answers:\n\n1. \u201cit is contrived to have $Y = p$\u201d. We are not supposing that $Y$ always equals $p$ in Equation (3).  This example is given to fix ideas.\n\n2. \u201cit is too simple to suppose $W$ can be the edge probability\u201d.  In our model, $W$ controls the topology of the graph.  In Erdos Renyi graphs, the topology is completely characterized by the edge-formation probability $p$.  \n\n3. \u201cit is contrived to suppose the response $Y$ is the same as $W$ (and therefore $p$)\u201d. This is simply an example we provided to make our notation concrete.  It is not our intention to make it appear practical.  It is common practice in graph literature to characterize expressive power as the ability to predict simple properties that are easy to describe and analyze, and we have references in the paper.  If it is deemed by some to be uninteresting, it does not undermine the validity of our method.  \n\n(unfair) Q14. ''Then, the variable W can be equivalently defined as W = (W0, C0E), where W0 is a random variable defined over the family of symmetric measurable functions W0 : [0, 1]2 \u2192 [0, 1], i.e., W0 is a random graphon function, and, if the graph has attributes, C0 E is an environment-dependent random variable that defines vertex and edge attributes, otherwise, C0E = \u00d8 is defined as the constant null.'' Unclear what conclusion one can draw from Theorem. Doesn't seem to have useful implications. \n\nA14. We have modified and elaborated Theorem 1 more clearly in the updated manuscript. The purpose of Theorem 1 is to provide conditions for our framework, and how we can rewrite the random graph family in a way that can be further used to achieve E-invariant representations.\n\n(unfair) Q15. ''graphs are simply representations of a natural process rather than the true state''. What does this even mean? Evidence?\n\nA15. The first paragraph of our Introduction provided three examples as evidence.  Please also see our answer to Q5 which talks about \u201cgraph processing environment\u201d.\n\n(unfair) Q16. ''Erdos-Renyi example (part 1)'' The problem setting is described by an example. A rigorous definition of problem setting is expected.\n\nA16. We formally defined the problem setting in Section 2 from Equations (1) to (3), specifically in the paragraphs \u201cA structural causal model \u2026\u201d, \u201cSCM target variable\u201d, and in Figure 1(a) at the top of page 2, of which the example is but a part.  Indeed, we split the example into two parts -- each part coming *after* the formal introduction of part of our framework -- to fix ideas as we went along.\n\n(unclear what is asked) Q17. ''Figure 1: (a) The DAG of the structural causal model (SCM) of our graph extrapolation tasks where hashed (white) vertices'' Hashed (white) vertices do not exist in Figure 1 (a)? \n\nA17. We are not sure what is meant, so we answer two possible interpretations:\n\n1. \u201cThere are no vertices of the style \u201chashed (white)\u201d.  Our figure has both white vertices that are not filled in and grey vertices that are filled in with hash marks.  \n\n2. \u201cThere is some confusion with the wording\u201d. We have added \u201cresp\u201d so our sentence that reads \u201c... where hashed (white) vertices represent observed (hidden) variables\u201d now reads \u201c.. where hashed (resp. white) vertices represent observed (resp. hidden) variables\u201d.\n\n(unfair) Q18. What is sampled permutation?\n\nA18. A sampled permutation is discussed in the line under Equation 2. It is a uniform permutation of the vertex indices.\n\n(unfair) Q19. ''Illustrates the relationship between expressive model families and most-expressive extrapolation families'' How is this even related?\n\nA19. The relationship is discussed at the end of Section 2 in the paragraph \u201cA comment on most-expressive graph representations, interpolations and extrapolations.\u201d The Figure 1(b) defines regions of different model families and how they are connected.\n"}, "signatures": ["ICLR.cc/2021/Conference/Paper2605/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2605/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "On Single-environment Extrapolations in Graph Classification and Regression Tasks", "authorids": ["~Beatrice_Bevilacqua1", "~Yangze_Zhou1", "~Ryan_L_Murphy1", "~Bruno_Ribeiro1"], "authors": ["Beatrice Bevilacqua", "Yangze Zhou", "Ryan L Murphy", "Bruno Ribeiro"], "keywords": ["Extrapolation", "Graphs", "GNNs", "SCM", "Causality", "Counterfactual Inference"], "abstract": "Extrapolation in graph classification/regression remains an underexplored area of an otherwise rapidly developing field. Our work contributes to a growing literature by providing the first systematic counterfactual modeling framework for extrapolations in graph classification/regression tasks. To show that extrapolation from a single training environment is possible, we develop a connection between certain extrapolation tasks on graph sizes and Lovasz's characterization of graph limits. For these extrapolations, standard graph neural networks (GNNs) will fail, while classifiers using induced homomorphism densities succeed, but mostly on unattributed graphs. Generalizing these density features through a GNN subgraph decomposition allows them to also succeed in more complex attributed graph extrapolation tasks. Finally, our experiments validate our theoretical results and showcase some shortcomings of common (interpolation) methods in the literature.", "one-sentence_summary": "To the best of our knowledge, this is the first work to formalize extrapolation in graph classification tasks using counterfactual inference, showing that extrapolation in graph tasks is possible even if given a single environment in training.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "bevilacqua|on_singleenvironment_extrapolations_in_graph_classification_and_regression_tasks", "pdf": "/pdf/2ff7e3b7be9531ec6770a9c5ba4eaac1a14f4f52.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=QXz4LpWzSg", "_bibtex": "@misc{\nbevilacqua2021on,\ntitle={On Single-environment Extrapolations in Graph Classification and Regression Tasks},\nauthor={Beatrice Bevilacqua and Yangze Zhou and Ryan L Murphy and Bruno Ribeiro},\nyear={2021},\nurl={https://openreview.net/forum?id=wXBt-7VM2JE}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "wXBt-7VM2JE", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper2605/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper2605/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper2605/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper2605/Authors|ICLR.cc/2021/Conference/Paper2605/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2605/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923846419, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper2605/-/Official_Comment"}}}, {"id": "jV-BdSVWaz", "original": null, "number": 3, "cdate": 1605673341453, "ddate": null, "tcdate": 1605673341453, "tmdate": 1605673341453, "tddate": null, "forum": "wXBt-7VM2JE", "replyto": "kYv-z7ZEUQ", "invitation": "ICLR.cc/2021/Conference/Paper2605/-/Official_Comment", "content": {"title": "Thanks for detailed comments, but review is unfair (see replies and updated manuscript for clarifications) Part 6/7", "comment": "(clarification) Q28. ''It is possible to guarantee that a graph representation is E-invariant even when the training data contains just one environment.'' This reads apparently wrong? Evidence? \n\nA28. The ability to extrapolate from a single-environment is a challenging, perhaps seemingly impossible, problem. Answering this is indeed a motivation and contribution of our work as, to the best of our knowledge, this important question has not been addressed in the literature.  We put forth a framework for analyzing this question by invoking causality and drawing ties to the theory of graph limits. This motivates a few concrete schemes for single-environment graph extrapolation. Please see our answers elsewhere that our assumptions are not as contrived as it may seem.  \n\nWe have revised the manuscript to make the question statement, proposed formulation, and contribution clearer.\n\n(clarification) Q29. ''inj(F, G) be the number of injective homomorphisms of F into a larger unattributed graph G'' Expensive to evaluate? Justification?\n\nA29. This follows from https://arxiv.org/abs/math/0408173. We use it for theoretical purposes. In Section 3.3 in the original manuscript, we clarified since there is a bijection between induced and injective homomorphism densities, we use existing algorithms to estimate the induced homomorphism densities as discussed there. In the updated manuscript, the \u201cpractical considerations\u201d are in Section 3.1 and we cited efficient algorithms to estimate the induced homomorphism densities.\n\n(clarification) Q30. ''1one-hot{Fk0 , F\u2264k} be the one-hot vector with a one at the index of Fk0 in F\u2264k and zeros elsewhere'' How do you construct this? Not well motivated? \n\nA30. [one hot subgraph vector] Take unattributed graphs as an example, we first assign some index to each connected graph of size k; for example Pinar et al (2017) assign 3-stars a \u201c1\u201d, 3-paths a \u201c2\u201d and so on.  Then, the one-hot vector for 3-stars is (1, 0, \u2026, 0), for 3-paths (0, 1, 0, \u2026, 0), and so on. To explain it better, we have added examples in Section 3.1 in the updated manuscript that may help the reader.\n\n(clarification) Q31a. ''Hence, our proposal replaces the one-hot vector 1one-hot{Fk0 , F\u2264k} with a GNN applied to Fk0 : '' What is this one-hot vector?  What is GNN? Never defined?...\n\nA31a. The one-hot vector is defined above in A30, [one hot subgraph vector]. We have updated the manuscript with a better explanation of GNNs in the appendix.  Unfortunately, due to limitations on space and the amount of room needed to completely introduce a new framework, we were not able to provide a comprehensive explanation. We proceeded with a brief note in the body and great detail in the appendix E.  \n\n(unfair) Q31b. \u201c...Replacing one hot by GNN seems trivial?\n\nA31b.  We do not claim that replacing one-hot vectors with GNNs is a key contribution of this paper.  The one-hot vector plays two roles.  First, as exposition, the representation obtained by one-hot vector is most expressive as highlighted in our theory and experiments.  Second, one-hot vectors could be used and performed well in unattributed cases as our experiments show. \n\nWe clarified these points in the updated manuscript. The idea of replacing the one hot with GNN ties to our definitions of attributed random graph models in Definition 3 and Theorem 2 (see the updated manuscript). Using GNNs helps us to better deal with attributed graphs as discussed in Section 3. More importantly, GNN and $\\text{GNN}^+$ representations allow us to increase their E-invariance by adding a penalty (discussed in Section 3) for having different representations of two graphs $F_{k'}$ and $F\u2019_{k'}$ with the same topology but different vertex attributes. \n\n(clarification) Q32. ''Unfortunately, GNNs are not most-expressive representations of graphs (Morris et al., 2019; Murphy et al., 2019b; Xu et al., 2018a) and thus \u0393GNN(\u00b7) is less expressive than \u03931-hot(\u00b7) for unattributed graphs.'' What does this even mean? Then why do you use GNN (which is not defined anyways)?\n\nA32.  First, note that greater expressiveness does not imply better extrapolation as discussed in the last few paragraphs of Section 2. Second, as always, there are multiple valid statistical approaches to a problem and one chooses the best for the given task.  Third, we introduce GNNs for the purposes of extrapolation as discussed in A31b.\n\nOur updated manuscript makes all the points much more explicitly and in greater detail, and includes a new set of experiments based on Stochastic Block models with our attribute-regularization term.\n"}, "signatures": ["ICLR.cc/2021/Conference/Paper2605/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2605/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "On Single-environment Extrapolations in Graph Classification and Regression Tasks", "authorids": ["~Beatrice_Bevilacqua1", "~Yangze_Zhou1", "~Ryan_L_Murphy1", "~Bruno_Ribeiro1"], "authors": ["Beatrice Bevilacqua", "Yangze Zhou", "Ryan L Murphy", "Bruno Ribeiro"], "keywords": ["Extrapolation", "Graphs", "GNNs", "SCM", "Causality", "Counterfactual Inference"], "abstract": "Extrapolation in graph classification/regression remains an underexplored area of an otherwise rapidly developing field. Our work contributes to a growing literature by providing the first systematic counterfactual modeling framework for extrapolations in graph classification/regression tasks. To show that extrapolation from a single training environment is possible, we develop a connection between certain extrapolation tasks on graph sizes and Lovasz's characterization of graph limits. For these extrapolations, standard graph neural networks (GNNs) will fail, while classifiers using induced homomorphism densities succeed, but mostly on unattributed graphs. Generalizing these density features through a GNN subgraph decomposition allows them to also succeed in more complex attributed graph extrapolation tasks. Finally, our experiments validate our theoretical results and showcase some shortcomings of common (interpolation) methods in the literature.", "one-sentence_summary": "To the best of our knowledge, this is the first work to formalize extrapolation in graph classification tasks using counterfactual inference, showing that extrapolation in graph tasks is possible even if given a single environment in training.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "bevilacqua|on_singleenvironment_extrapolations_in_graph_classification_and_regression_tasks", "pdf": "/pdf/2ff7e3b7be9531ec6770a9c5ba4eaac1a14f4f52.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=QXz4LpWzSg", "_bibtex": "@misc{\nbevilacqua2021on,\ntitle={On Single-environment Extrapolations in Graph Classification and Regression Tasks},\nauthor={Beatrice Bevilacqua and Yangze Zhou and Ryan L Murphy and Bruno Ribeiro},\nyear={2021},\nurl={https://openreview.net/forum?id=wXBt-7VM2JE}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "wXBt-7VM2JE", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper2605/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper2605/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper2605/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper2605/Authors|ICLR.cc/2021/Conference/Paper2605/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2605/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923846419, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper2605/-/Official_Comment"}}}, {"id": "yXJLeP8W6TR", "original": null, "number": 2, "cdate": 1605673075130, "ddate": null, "tcdate": 1605673075130, "tmdate": 1605673075130, "tddate": null, "forum": "wXBt-7VM2JE", "replyto": "kYv-z7ZEUQ", "invitation": "ICLR.cc/2021/Conference/Paper2605/-/Official_Comment", "content": {"title": "Thanks for detailed comments, but review is unfair (see replies and updated manuscript for clarifications) Part 7/7", "comment": "(fair) Q33. ''in some canonical order'' what is the canonical order? \n\nA33. As far as the definition, canonicalization refers to a well-defined operation that imposes some kind of consistent ordering to the vertices in a graph, see https://link.springer.com/chapter/10.1007/978-1-4612-4478-3_5 (Immerman & Lander, 1990).  Note that the \u201cordering\u201d of vertices refers to permutations, (aka labelings or isomorphisms) of the vertex set.  An example could be sorting by degree and breaking ties in a consistent manner.  In the paper, we essentially suppose the data generating process generates graphs in some kind of canonical form.  Later on, we write that vertices are permuted.  This is a formalism of the intuitive statement that vertex labelings in the data don\u2019t actually carry any information.  We don\u2019t actually permute vertices.\n\n(fair) Q34. ''graphs are simple, meaning all pairs of vertices have at most one edge'' This is a wrong definition of simple graphs?\n\nA34. It should say ''graphs are simple, meaning all pairs of vertices have at most one edge and no self-loops are present'' and it has been fixed in the updated manuscript."}, "signatures": ["ICLR.cc/2021/Conference/Paper2605/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2605/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "On Single-environment Extrapolations in Graph Classification and Regression Tasks", "authorids": ["~Beatrice_Bevilacqua1", "~Yangze_Zhou1", "~Ryan_L_Murphy1", "~Bruno_Ribeiro1"], "authors": ["Beatrice Bevilacqua", "Yangze Zhou", "Ryan L Murphy", "Bruno Ribeiro"], "keywords": ["Extrapolation", "Graphs", "GNNs", "SCM", "Causality", "Counterfactual Inference"], "abstract": "Extrapolation in graph classification/regression remains an underexplored area of an otherwise rapidly developing field. Our work contributes to a growing literature by providing the first systematic counterfactual modeling framework for extrapolations in graph classification/regression tasks. To show that extrapolation from a single training environment is possible, we develop a connection between certain extrapolation tasks on graph sizes and Lovasz's characterization of graph limits. For these extrapolations, standard graph neural networks (GNNs) will fail, while classifiers using induced homomorphism densities succeed, but mostly on unattributed graphs. Generalizing these density features through a GNN subgraph decomposition allows them to also succeed in more complex attributed graph extrapolation tasks. Finally, our experiments validate our theoretical results and showcase some shortcomings of common (interpolation) methods in the literature.", "one-sentence_summary": "To the best of our knowledge, this is the first work to formalize extrapolation in graph classification tasks using counterfactual inference, showing that extrapolation in graph tasks is possible even if given a single environment in training.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "bevilacqua|on_singleenvironment_extrapolations_in_graph_classification_and_regression_tasks", "pdf": "/pdf/2ff7e3b7be9531ec6770a9c5ba4eaac1a14f4f52.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=QXz4LpWzSg", "_bibtex": "@misc{\nbevilacqua2021on,\ntitle={On Single-environment Extrapolations in Graph Classification and Regression Tasks},\nauthor={Beatrice Bevilacqua and Yangze Zhou and Ryan L Murphy and Bruno Ribeiro},\nyear={2021},\nurl={https://openreview.net/forum?id=wXBt-7VM2JE}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "wXBt-7VM2JE", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper2605/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper2605/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper2605/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper2605/Authors|ICLR.cc/2021/Conference/Paper2605/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2605/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923846419, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper2605/-/Official_Comment"}}}, {"id": "fVwoKer8rRp", "original": null, "number": 1, "cdate": 1603799808271, "ddate": null, "tcdate": 1603799808271, "tmdate": 1605024171709, "tddate": null, "forum": "wXBt-7VM2JE", "replyto": "wXBt-7VM2JE", "invitation": "ICLR.cc/2021/Conference/Paper2605/-/Official_Review", "content": {"title": "Interesting paper, rough exposition ", "review": "This paper formulates a theoretical model for testing extrapolation abilities of graph learning tasks, and suggests some practical feature maps to achieve good extrapolation properties empirically. In more detail, this paper introduces a model, a so-called structural causal model, for graphs where the graph creation process is modeled as a random variable that depends on different independent factors:  environment $E$, which is used to model the graph size $n$; graph property $W$, which is used for example to model the probability of edge existence; and random seed $Z_X$. The created graph is also scrambled by a random permutation to yield the observed graph $G^{\\text{obs}}$. The ground truth labels of the graph $Y$ are functions of two factors $W$, the graph property, and $Z_Y$ random seed. \n\nThe authors claim that a problem with learning data of the form $(G^{\\text{obs}},Y)$ is that $Y$ is not independent of $E$ given that we see $G^{\\text{obs}}$ and therefore standard learning techniques can overfit certain environments and fail to extrapolate. These dependencies are referred to as backdoor paths. Then the authors move to define counterfactual coupling of $G^{\\text{obs}}$ and $Y$. They actually mention equation 1 but i assume this is a mistake and they mean equation 2. Also, why $\\tilde{E}$ is used as regular variable inside $g$? The definition is confusing to me since the event the indicator defines does not necessarily mean $G^{\\text{obs}}=G^{\\text{cf}}$. Anyway, I could not really understand what is the object that is defined here. My best guess was that there is a new random variable $G^{\\text{cf}}$ defined with a new environment $\\tilde{E}$, and the counterfactual coupling is their joint probability function.  \nIn Proposition 1, if I understand correctly, the main point is that given a function $\\Gamma$ that is (almost everywhere) invariant to the environment parameter then good generalization error of this function would also imply good extrapolation error. This feels natural, however, if this is indeed the case, I find it hard to understand the formulation of the difference equations in Prop 1. In particular the equalities between the different $G$, and what is a link function? The definition of E-invariant should be defined properly; e.g. , what does \"can be sampled\" mean? \n\nThe authors then turn to look for $E$-invariant graph functions $\\Gamma$. Theorem 1 then introduces certain assumptions under which it is possible. I could not understand the conclusions in this theorem. The assumptions basically mean that subgraphs of $G^{\\text{obs}}$ can be seen as sampled from smaller $n$. Does that mean different $E$ is already available by just sampling subgraphs of the observed data? Using these assumptions the authors prove in Theorem 2 that a certain version of subgraph counting provides such an $E$-invariant function. Again the definitions in this Section (3.1) were unclear. They also discuss an extension to graphs with features using some common GNN architectures in Section 3.2. I found this section also hard to follow. The paper concludes with experiments using these feature maps to demonstrate extrapolation properties.\n\nI think this paper presents a potentially interesting model and some initial results as to what kind of conditions allow extrapolation. However, this paper suffers from what I find as a bad exposition. It assumes familiarity with causality theory, and lacks clear definitions, statements, claims and explanations. I really struggled understanding the different parts and cannot say I fully understand them. I needed to guess many details and I am not sure i got it right. I think that to make this paper useful for the community a rather complete rewrite should be done. \n\nA more concrete concern I had is that I was under the impression that the type of assumption required (in Theorem 1) for building $E$-invariant representations basically means that we have access to different size graphs (through the sub-graph assumptions)  and therefore extrapolation to smaller sizes is possible. I would be interested to know if we can extrapolate to larger graphs in this case. \nLastly, subgraph counting is computationally and memory demanding. Maybe empirically quantifying the cost ($k$?)-extrapolation tradeoff could be useful. \n", "rating": "5: Marginally below acceptance threshold", "confidence": "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper"}, "signatures": ["ICLR.cc/2021/Conference/Paper2605/AnonReviewer4"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2605/AnonReviewer4"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "On Single-environment Extrapolations in Graph Classification and Regression Tasks", "authorids": ["~Beatrice_Bevilacqua1", "~Yangze_Zhou1", "~Ryan_L_Murphy1", "~Bruno_Ribeiro1"], "authors": ["Beatrice Bevilacqua", "Yangze Zhou", "Ryan L Murphy", "Bruno Ribeiro"], "keywords": ["Extrapolation", "Graphs", "GNNs", "SCM", "Causality", "Counterfactual Inference"], "abstract": "Extrapolation in graph classification/regression remains an underexplored area of an otherwise rapidly developing field. Our work contributes to a growing literature by providing the first systematic counterfactual modeling framework for extrapolations in graph classification/regression tasks. To show that extrapolation from a single training environment is possible, we develop a connection between certain extrapolation tasks on graph sizes and Lovasz's characterization of graph limits. For these extrapolations, standard graph neural networks (GNNs) will fail, while classifiers using induced homomorphism densities succeed, but mostly on unattributed graphs. Generalizing these density features through a GNN subgraph decomposition allows them to also succeed in more complex attributed graph extrapolation tasks. Finally, our experiments validate our theoretical results and showcase some shortcomings of common (interpolation) methods in the literature.", "one-sentence_summary": "To the best of our knowledge, this is the first work to formalize extrapolation in graph classification tasks using counterfactual inference, showing that extrapolation in graph tasks is possible even if given a single environment in training.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "bevilacqua|on_singleenvironment_extrapolations_in_graph_classification_and_regression_tasks", "pdf": "/pdf/2ff7e3b7be9531ec6770a9c5ba4eaac1a14f4f52.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=QXz4LpWzSg", "_bibtex": "@misc{\nbevilacqua2021on,\ntitle={On Single-environment Extrapolations in Graph Classification and Regression Tasks},\nauthor={Beatrice Bevilacqua and Yangze Zhou and Ryan L Murphy and Bruno Ribeiro},\nyear={2021},\nurl={https://openreview.net/forum?id=wXBt-7VM2JE}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq . ***Please remember to file the Code-of-Ethics report. Once you submitted the review, a link to the report will be visible in the bottom right corner of your review.***", "required": true, "markdown": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}, "forum": "wXBt-7VM2JE", "replyto": "wXBt-7VM2JE", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"], "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper2605/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1607428800000, "duedate": 1606752000000, "multiReply": false, "readers": ["everyone"], "tcdate": 1602538092570, "tmdate": 1606915796802, "super": "ICLR.cc/2021/Conference/-/Official_Review", "signatures": ["OpenReview.net"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Paper2605/Reviewers", "OpenReview.net/Support"], "id": "ICLR.cc/2021/Conference/Paper2605/-/Official_Review"}}}, {"id": "ySpcK1G8eQo", "original": null, "number": 2, "cdate": 1603848144648, "ddate": null, "tcdate": 1603848144648, "tmdate": 1605024171630, "tddate": null, "forum": "wXBt-7VM2JE", "replyto": "wXBt-7VM2JE", "invitation": "ICLR.cc/2021/Conference/Paper2605/-/Official_Review", "content": {"title": "Interesting contribution to graph size extrapolation ", "review": "The paper explores the problem of extrapolation in graph classification tasks and by leveraging Lovasz\u2019s graph limit theory, provides graph representations and related theoretical guarantees on graph size extrapolation in the context of unattributed graphs. Specifically, it is shown that the graph representations characterized by induced homomorphism densities are size-invariant under certain conditions. The theoretical claims are validated by empirical evaluation of classifiers trained on the proposed graph representations. \n\nOverall, I find the contributions of the paper solid and of interest to many researchers. \n\nPros: The paper is well written with an appropriate focus on motivating the problem at hand. The experiments seem convincing enough to establish the implications of theoretical guarantees. \n\nCons: I don't see any major issues in the paper. \n\nElaborating on a few points will help improve the readability:\n\n1. I recommend elaborating on the graphon function $W'$ defined in Theorem 1 and its relation to graph topology. \n\n2. Are the conditions of Theorem 1 violated by any large class of graph models, such as MRFs?\n\n\n", "rating": "8: Top 50% of accepted papers, clear accept", "confidence": "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper"}, "signatures": ["ICLR.cc/2021/Conference/Paper2605/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2605/AnonReviewer3"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "On Single-environment Extrapolations in Graph Classification and Regression Tasks", "authorids": ["~Beatrice_Bevilacqua1", "~Yangze_Zhou1", "~Ryan_L_Murphy1", "~Bruno_Ribeiro1"], "authors": ["Beatrice Bevilacqua", "Yangze Zhou", "Ryan L Murphy", "Bruno Ribeiro"], "keywords": ["Extrapolation", "Graphs", "GNNs", "SCM", "Causality", "Counterfactual Inference"], "abstract": "Extrapolation in graph classification/regression remains an underexplored area of an otherwise rapidly developing field. Our work contributes to a growing literature by providing the first systematic counterfactual modeling framework for extrapolations in graph classification/regression tasks. To show that extrapolation from a single training environment is possible, we develop a connection between certain extrapolation tasks on graph sizes and Lovasz's characterization of graph limits. For these extrapolations, standard graph neural networks (GNNs) will fail, while classifiers using induced homomorphism densities succeed, but mostly on unattributed graphs. Generalizing these density features through a GNN subgraph decomposition allows them to also succeed in more complex attributed graph extrapolation tasks. Finally, our experiments validate our theoretical results and showcase some shortcomings of common (interpolation) methods in the literature.", "one-sentence_summary": "To the best of our knowledge, this is the first work to formalize extrapolation in graph classification tasks using counterfactual inference, showing that extrapolation in graph tasks is possible even if given a single environment in training.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "bevilacqua|on_singleenvironment_extrapolations_in_graph_classification_and_regression_tasks", "pdf": "/pdf/2ff7e3b7be9531ec6770a9c5ba4eaac1a14f4f52.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=QXz4LpWzSg", "_bibtex": "@misc{\nbevilacqua2021on,\ntitle={On Single-environment Extrapolations in Graph Classification and Regression Tasks},\nauthor={Beatrice Bevilacqua and Yangze Zhou and Ryan L Murphy and Bruno Ribeiro},\nyear={2021},\nurl={https://openreview.net/forum?id=wXBt-7VM2JE}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq . ***Please remember to file the Code-of-Ethics report. Once you submitted the review, a link to the report will be visible in the bottom right corner of your review.***", "required": true, "markdown": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}, "forum": "wXBt-7VM2JE", "replyto": "wXBt-7VM2JE", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"], "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper2605/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1607428800000, "duedate": 1606752000000, "multiReply": false, "readers": ["everyone"], "tcdate": 1602538092570, "tmdate": 1606915796802, "super": "ICLR.cc/2021/Conference/-/Official_Review", "signatures": ["OpenReview.net"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Paper2605/Reviewers", "OpenReview.net/Support"], "id": "ICLR.cc/2021/Conference/Paper2605/-/Official_Review"}}}], "count": 19}