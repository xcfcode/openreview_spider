{"notes": [{"id": "SJlKrkSFPH", "original": "rklXvfTdPB", "number": 1699, "cdate": 1569439552907, "ddate": null, "tcdate": 1569439552907, "tmdate": 1583912036148, "tddate": null, "forum": "SJlKrkSFPH", "replyto": null, "invitation": "ICLR.cc/2020/Conference/-/Blind_Submission", "content": {"authorids": ["dvij@google.com", "j.hayes@cs.ucl.ac.uk", "bballe@google.com", "zkolter@cs.cmu.edu", "chongliqin@google.com", "agyorgy@google.com", "kaix@mit.edu", "sgowal@google.com", "pushmeet@google.com"], "title": "A FRAMEWORK  FOR ROBUSTNESS CERTIFICATION  OF SMOOTHED CLASSIFIERS USING  F-DIVERGENCES", "authors": ["Krishnamurthy (Dj) Dvijotham", "Jamie Hayes", "Borja Balle", "Zico Kolter", "Chongli Qin", "Andras Gyorgy", "Kai Xiao", "Sven Gowal", "Pushmeet Kohli"], "pdf": "/pdf/5c744888eae162e715f7635b283ff4545aee828d.pdf", "TL;DR": "Develop a general framework to establish certified robustness of ML models against various classes of adversarial perturbations", "abstract": "Formal verification techniques that compute provable guarantees on properties of machine learning models, like robustness to norm-bounded adversarial perturbations, have yielded impressive results. Although most techniques developed so far require knowledge of the architecture of the machine learning model and remain hard to scale to complex prediction pipelines, the method of randomized smoothing has been shown to overcome many of these obstacles. By requiring only black-box access to the underlying model, randomized smoothing scales to large architectures and is agnostic to the internals of the network. However, past work on randomized smoothing has focused on restricted classes of smoothing measures or perturbations (like Gaussian or discrete) and has only been able to prove robustness with respect to simple norm bounds. In this paper we introduce a general framework for proving robustness properties of smoothed machine learning models in the black-box setting. Specifically, we extend randomized smoothing procedures to handle arbitrary smoothing measures and prove robustness of the smoothed classifier by using f-divergences. Our methodology improves upon the state of the art in terms of computation time or certified robustness on several image classification tasks and an audio classification task, with respect to several classes of adversarial perturbations. ", "keywords": ["verification of machine learning", "certified robustness of neural networks"], "paperhash": "dvijotham|a_framework_for_robustness_certification_of_smoothed_classifiers_using_fdivergences", "_bibtex": "@inproceedings{\nDvijotham2020A,\ntitle={A FRAMEWORK  FOR ROBUSTNESS CERTIFICATION  OF SMOOTHED CLASSIFIERS USING  F-DIVERGENCES},\nauthor={Krishnamurthy (Dj) Dvijotham and Jamie Hayes and Borja Balle and Zico Kolter and Chongli Qin and Andras Gyorgy and Kai Xiao and Sven Gowal and Pushmeet Kohli},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=SJlKrkSFPH}\n}", "full_presentation_video": "", "original_pdf": "/attachment/4a7b75373f2ba1374547cb1ff42c0df98f6be1ce.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "signatures": ["ICLR.cc/2020/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference"], "details": {"replyCount": 13, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"reply": {"readers": {"values-regex": ".*"}, "writers": {"values": ["ICLR.cc/2020/Conference"]}, "signatures": {"values": ["ICLR.cc/2020/Conference"]}, "content": {"spotlight_video": {"value-regex": ".*"}, "full_presentation_video": {"value-regex": ".*"}, "original_pdf": {"required": false, "description": "Upload a PDF file that ends with .pdf", "value-regex": ".*"}, "appendix": {"value-regex": ".*"}, "authorids": {"values-regex": ".*"}, "poster": {"value-regex": ".*"}, "authors": {"values": ["Anonymous"]}, "slides": {"value-regex": ".*"}}}, "final": [], "signatures": ["ICLR.cc/2020/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference"], "noninvitees": [], "tcdate": 1569271260237, "tmdate": 1593459412141, "id": "ICLR.cc/2020/Conference/-/Blind_Submission"}}, "tauthor": "ICLR.cc/2020/Conference"}, {"id": "2-61ZCc3Ue", "original": null, "number": 1, "cdate": 1576798730191, "ddate": null, "tcdate": 1576798730191, "tmdate": 1576800906317, "tddate": null, "forum": "SJlKrkSFPH", "replyto": "SJlKrkSFPH", "invitation": "ICLR.cc/2020/Conference/Paper1699/-/Decision", "content": {"decision": "Accept (Poster)", "comment": "This submission proposes a black-box method for certifying the robustness of smoothed classifiers in the presence of adversarial perturbations. This work goes beyond previous works in certifying robustness for arbitrary smoothing measures.\n\nStrengths:\n-Sound formulation and theoretical justification to tackle an important problem.\n\nWeaknesses\n-Experimental comparison was at times not fair.\n-The presentation and writing could be improved.\n\nThese two weaknesses were sufficiently addressed during the discussion. All reviewers recommend acceptance.", "title": "Paper Decision"}, "signatures": ["ICLR.cc/2020/Conference/Program_Chairs"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Program_Chairs"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["dvij@google.com", "j.hayes@cs.ucl.ac.uk", "bballe@google.com", "zkolter@cs.cmu.edu", "chongliqin@google.com", "agyorgy@google.com", "kaix@mit.edu", "sgowal@google.com", "pushmeet@google.com"], "title": "A FRAMEWORK  FOR ROBUSTNESS CERTIFICATION  OF SMOOTHED CLASSIFIERS USING  F-DIVERGENCES", "authors": ["Krishnamurthy (Dj) Dvijotham", "Jamie Hayes", "Borja Balle", "Zico Kolter", "Chongli Qin", "Andras Gyorgy", "Kai Xiao", "Sven Gowal", "Pushmeet Kohli"], "pdf": "/pdf/5c744888eae162e715f7635b283ff4545aee828d.pdf", "TL;DR": "Develop a general framework to establish certified robustness of ML models against various classes of adversarial perturbations", "abstract": "Formal verification techniques that compute provable guarantees on properties of machine learning models, like robustness to norm-bounded adversarial perturbations, have yielded impressive results. Although most techniques developed so far require knowledge of the architecture of the machine learning model and remain hard to scale to complex prediction pipelines, the method of randomized smoothing has been shown to overcome many of these obstacles. By requiring only black-box access to the underlying model, randomized smoothing scales to large architectures and is agnostic to the internals of the network. However, past work on randomized smoothing has focused on restricted classes of smoothing measures or perturbations (like Gaussian or discrete) and has only been able to prove robustness with respect to simple norm bounds. In this paper we introduce a general framework for proving robustness properties of smoothed machine learning models in the black-box setting. Specifically, we extend randomized smoothing procedures to handle arbitrary smoothing measures and prove robustness of the smoothed classifier by using f-divergences. Our methodology improves upon the state of the art in terms of computation time or certified robustness on several image classification tasks and an audio classification task, with respect to several classes of adversarial perturbations. ", "keywords": ["verification of machine learning", "certified robustness of neural networks"], "paperhash": "dvijotham|a_framework_for_robustness_certification_of_smoothed_classifiers_using_fdivergences", "_bibtex": "@inproceedings{\nDvijotham2020A,\ntitle={A FRAMEWORK  FOR ROBUSTNESS CERTIFICATION  OF SMOOTHED CLASSIFIERS USING  F-DIVERGENCES},\nauthor={Krishnamurthy (Dj) Dvijotham and Jamie Hayes and Borja Balle and Zico Kolter and Chongli Qin and Andras Gyorgy and Kai Xiao and Sven Gowal and Pushmeet Kohli},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=SJlKrkSFPH}\n}", "full_presentation_video": "", "original_pdf": "/attachment/4a7b75373f2ba1374547cb1ff42c0df98f6be1ce.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "tags": [], "invitation": {"reply": {"writers": {"description": "How your identity will be displayed.", "values-regex": ["ICLR.cc/2020/Conference/Program_Chairs"]}, "signatures": {"values": ["ICLR.cc/2020/Conference/Program_Chairs"], "description": "How your identity will be displayed."}, "content": {"decision": {"value-radio": ["Accept (Spotlight)", "Accept (Talk)", "Accept (Poster)", "Reject"], "description": "Decision", "required": true, "order": 2}, "title": {"value": "Paper Decision", "required": true, "order": 1}, "comment": {"value-regex": "[\\S\\s]{0,5000}", "description": "", "required": false, "order": 3}}, "forum": "SJlKrkSFPH", "replyto": "SJlKrkSFPH", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}}, "expdate": 1576854540000, "duedate": 1576853940000, "multiReply": false, "readers": ["everyone"], "invitees": ["ICLR.cc/2020/Conference/Program_Chairs"], "tcdate": 1576795718451, "tmdate": 1576800268934, "super": "ICLR.cc/2020/Conference/-/Decision", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper1699/-/Decision"}}}, {"id": "SylnaDVqYr", "original": null, "number": 1, "cdate": 1571600324201, "ddate": null, "tcdate": 1571600324201, "tmdate": 1574426839068, "tddate": null, "forum": "SJlKrkSFPH", "replyto": "SJlKrkSFPH", "invitation": "ICLR.cc/2020/Conference/Paper1699/-/Official_Review", "content": {"experience_assessment": "I have read many papers in this area.", "rating": "6: Weak Accept", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "title": "Official Blind Review #1", "review": "The paper introduces a generalization of the randomized smoothing approach for certifying robustness of black-box classifiers, allowing the smoothing measure to be an arbitrary distribution (whereas previous work almost exclusively focused on Gaussian noise), and facilitating the certification with respect to different metrics under the same framework.\n\nGiven the wide interest in certified robustness based on randomized smoothing, the generalizations considered in this paper could have a high potential. I found the motivation, the definition of the framework and the statement of the main theoretical results, up to Section 3.2, very clear. The following sections were not as well organized, in my opinion, and need improvement. In particular, I found it not very clear how the framework can applied to recover previous results, in particular the results from Cohen et al. (2019). All the ingredients seem to be there, among Theorem 3, the result from Balle & Wang (2018), and Corollary 5, but the arguments could be presented in a better organized way.\n\nWhat I also found is missing is a clear descriptions of practical algorithms for applying the framework. Again, most of the ingredients seem to be there (e.g. Table 1 in the main body, Lemma 6 as well as the discussion about sampling mechanism in the Appendix), but they are not well organized. Presumably, the same statistical methodology as in Cohen et al. is used to obtain estimates of theta_a and theta_b, but this doesn't seem to be clearly stated anywhere. How is certification practically performed for intersections of contraint sets as introduced at the end of section 2? How the full-information certification can be applied based on empirical estimates is unclear to me, too.\n\nFinally, the description of the experiments need improvements: For instance, in Section 5.1, which smoothing measure was used? Was the ResNet classifier trained using samples from this measure? Which sets of f-divergences were used? What does Figure 3 (a) exactly show? Do the blue points correspond to the 50 data samples? The number of random samples for computing empirical estimates and the confidence bounds are missing.\nIn Figure 4 (a), as the l_0 norm counts the number of altered pixels I don't understand why the certified accuracy varies e.g. for epsilon *between* 0 and 1.\nThe experiment on the Librispeech model seems interesting, but the paper does not contain sufficient information to understand and assess the experimental set-up or the results.\n\nIn summary, while I believe that the generalizations proposed in this paper have potential, in its present form the manuscript doesn't describe clearly and accurately enough how the framework can be applied to recover previous theoretical results or perform certification in practice.\n\n----------\n\nI acknowledge I have read the authors' response. As it addresses my main concerns I have changed my rating from \"weak reject\" to \"weak accept\".\n", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory."}, "signatures": ["ICLR.cc/2020/Conference/Paper1699/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1699/AnonReviewer1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["dvij@google.com", "j.hayes@cs.ucl.ac.uk", "bballe@google.com", "zkolter@cs.cmu.edu", "chongliqin@google.com", "agyorgy@google.com", "kaix@mit.edu", "sgowal@google.com", "pushmeet@google.com"], "title": "A FRAMEWORK  FOR ROBUSTNESS CERTIFICATION  OF SMOOTHED CLASSIFIERS USING  F-DIVERGENCES", "authors": ["Krishnamurthy (Dj) Dvijotham", "Jamie Hayes", "Borja Balle", "Zico Kolter", "Chongli Qin", "Andras Gyorgy", "Kai Xiao", "Sven Gowal", "Pushmeet Kohli"], "pdf": "/pdf/5c744888eae162e715f7635b283ff4545aee828d.pdf", "TL;DR": "Develop a general framework to establish certified robustness of ML models against various classes of adversarial perturbations", "abstract": "Formal verification techniques that compute provable guarantees on properties of machine learning models, like robustness to norm-bounded adversarial perturbations, have yielded impressive results. Although most techniques developed so far require knowledge of the architecture of the machine learning model and remain hard to scale to complex prediction pipelines, the method of randomized smoothing has been shown to overcome many of these obstacles. By requiring only black-box access to the underlying model, randomized smoothing scales to large architectures and is agnostic to the internals of the network. However, past work on randomized smoothing has focused on restricted classes of smoothing measures or perturbations (like Gaussian or discrete) and has only been able to prove robustness with respect to simple norm bounds. In this paper we introduce a general framework for proving robustness properties of smoothed machine learning models in the black-box setting. Specifically, we extend randomized smoothing procedures to handle arbitrary smoothing measures and prove robustness of the smoothed classifier by using f-divergences. Our methodology improves upon the state of the art in terms of computation time or certified robustness on several image classification tasks and an audio classification task, with respect to several classes of adversarial perturbations. ", "keywords": ["verification of machine learning", "certified robustness of neural networks"], "paperhash": "dvijotham|a_framework_for_robustness_certification_of_smoothed_classifiers_using_fdivergences", "_bibtex": "@inproceedings{\nDvijotham2020A,\ntitle={A FRAMEWORK  FOR ROBUSTNESS CERTIFICATION  OF SMOOTHED CLASSIFIERS USING  F-DIVERGENCES},\nauthor={Krishnamurthy (Dj) Dvijotham and Jamie Hayes and Borja Balle and Zico Kolter and Chongli Qin and Andras Gyorgy and Kai Xiao and Sven Gowal and Pushmeet Kohli},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=SJlKrkSFPH}\n}", "full_presentation_video": "", "original_pdf": "/attachment/4a7b75373f2ba1374547cb1ff42c0df98f6be1ce.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "SJlKrkSFPH", "replyto": "SJlKrkSFPH", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper1699/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper1699/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1575468659775, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper1699/Reviewers"], "noninvitees": [], "tcdate": 1570237733568, "tmdate": 1575468659787, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper1699/-/Official_Review"}}}, {"id": "r1eYLSiotr", "original": null, "number": 2, "cdate": 1571693905334, "ddate": null, "tcdate": 1571693905334, "tmdate": 1573772921366, "tddate": null, "forum": "SJlKrkSFPH", "replyto": "SJlKrkSFPH", "invitation": "ICLR.cc/2020/Conference/Paper1699/-/Official_Review", "content": {"experience_assessment": "I have read many papers in this area.", "rating": "6: Weak Accept", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "title": "Official Blind Review #3", "review": "Summary: This submission proposes a unified framework for black-box adversarial certification. Based on cohen's and lee's result, it extends the \\lambda_TV distance to more general f-divergence. Besides, some other techniques, e.g. reference distribution, are also included in the framework. For L_0 and L_1 perturbation, the proposed framework comes to better results than all the related methods.\n\nStrengths:\n[+] Detailed analysis and theorem.\n[+] Describing the background and conclusions clearly.\n\nWeaknesses:\n[-] In the experiment section, for ImageNet, baselines use ResNet-50 but the authors use ResNet-152. I wonder whether this is fair enough.\n[-] Renyi divergence is not a proper f-divergence. Therefore, maybe the title should be changed.\n[-] The theorem part contains too many details and some important parts (e.g. tightness) are in appendix. It should be re-organized.\n\nQuestions:\n[.] In Appendix A.7, Lagrangian strong-duality has been used to show the tightness, but I wonder whether the tightness holds for any kind f-divergence? If the authors can write down some theorem about the tightness, it will be better.\n\np.s. Could you give me some quick responses to my questions (e.g. ResNet-152 v.s. ResNet-50) ? Once you convince me, I would revise the score to 6. If not, I will turn down the score to 3. ", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory."}, "signatures": ["ICLR.cc/2020/Conference/Paper1699/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1699/AnonReviewer3"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["dvij@google.com", "j.hayes@cs.ucl.ac.uk", "bballe@google.com", "zkolter@cs.cmu.edu", "chongliqin@google.com", "agyorgy@google.com", "kaix@mit.edu", "sgowal@google.com", "pushmeet@google.com"], "title": "A FRAMEWORK  FOR ROBUSTNESS CERTIFICATION  OF SMOOTHED CLASSIFIERS USING  F-DIVERGENCES", "authors": ["Krishnamurthy (Dj) Dvijotham", "Jamie Hayes", "Borja Balle", "Zico Kolter", "Chongli Qin", "Andras Gyorgy", "Kai Xiao", "Sven Gowal", "Pushmeet Kohli"], "pdf": "/pdf/5c744888eae162e715f7635b283ff4545aee828d.pdf", "TL;DR": "Develop a general framework to establish certified robustness of ML models against various classes of adversarial perturbations", "abstract": "Formal verification techniques that compute provable guarantees on properties of machine learning models, like robustness to norm-bounded adversarial perturbations, have yielded impressive results. Although most techniques developed so far require knowledge of the architecture of the machine learning model and remain hard to scale to complex prediction pipelines, the method of randomized smoothing has been shown to overcome many of these obstacles. By requiring only black-box access to the underlying model, randomized smoothing scales to large architectures and is agnostic to the internals of the network. However, past work on randomized smoothing has focused on restricted classes of smoothing measures or perturbations (like Gaussian or discrete) and has only been able to prove robustness with respect to simple norm bounds. In this paper we introduce a general framework for proving robustness properties of smoothed machine learning models in the black-box setting. Specifically, we extend randomized smoothing procedures to handle arbitrary smoothing measures and prove robustness of the smoothed classifier by using f-divergences. Our methodology improves upon the state of the art in terms of computation time or certified robustness on several image classification tasks and an audio classification task, with respect to several classes of adversarial perturbations. ", "keywords": ["verification of machine learning", "certified robustness of neural networks"], "paperhash": "dvijotham|a_framework_for_robustness_certification_of_smoothed_classifiers_using_fdivergences", "_bibtex": "@inproceedings{\nDvijotham2020A,\ntitle={A FRAMEWORK  FOR ROBUSTNESS CERTIFICATION  OF SMOOTHED CLASSIFIERS USING  F-DIVERGENCES},\nauthor={Krishnamurthy (Dj) Dvijotham and Jamie Hayes and Borja Balle and Zico Kolter and Chongli Qin and Andras Gyorgy and Kai Xiao and Sven Gowal and Pushmeet Kohli},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=SJlKrkSFPH}\n}", "full_presentation_video": "", "original_pdf": "/attachment/4a7b75373f2ba1374547cb1ff42c0df98f6be1ce.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "SJlKrkSFPH", "replyto": "SJlKrkSFPH", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper1699/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper1699/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1575468659775, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper1699/Reviewers"], "noninvitees": [], "tcdate": 1570237733568, "tmdate": 1575468659787, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper1699/-/Official_Review"}}}, {"id": "BygdAZ9_jH", "original": null, "number": 4, "cdate": 1573589456236, "ddate": null, "tcdate": 1573589456236, "tmdate": 1573723693359, "tddate": null, "forum": "SJlKrkSFPH", "replyto": "SJlKrkSFPH", "invitation": "ICLR.cc/2020/Conference/Paper1699/-/Official_Comment", "content": {"title": "Summary of rebuttal", "comment": "We thank the blind reviewers as well as authors of the public comments for their careful reviews and feedback on our paper. We have made the following changes to our paper in response:\n1. We have organized the technical material in the paper into three sections:\n       Section 3: The main certification theorems, followed by descriptions of practical certification algorithms that follow from the theorems\n       Section 4: Theoretical analysis of the certification algorithms\n       Section 5: Comparisons to prior work, including a table comparing the contributions of our work relative to prior work (table 1) and detailed explanations relating our work to prior work\n2. We have amended the abstract and contributions sections of our paper to better reflect our contributions relative to prior work and motivate the use of the perturbation measures (l0, l1 and l2) used.\n3. We have rerun experiments on l0 certification to ensure an experimental protocol that is consistent with prior work ensuring fair comparisons can be made. We have expanded the descriptions in the experiments section to clarify precise details of our experimental protocol and highlight novel contributions from our work.\n"}, "signatures": ["ICLR.cc/2020/Conference/Paper1699/Authors"], "readers": ["ICLR.cc/2020/Conference/Paper1699/Authors", "ICLR.cc/2020/Conference/Paper1699/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper1699/Area_Chairs", "everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1699/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["dvij@google.com", "j.hayes@cs.ucl.ac.uk", "bballe@google.com", "zkolter@cs.cmu.edu", "chongliqin@google.com", "agyorgy@google.com", "kaix@mit.edu", "sgowal@google.com", "pushmeet@google.com"], "title": "A FRAMEWORK  FOR ROBUSTNESS CERTIFICATION  OF SMOOTHED CLASSIFIERS USING  F-DIVERGENCES", "authors": ["Krishnamurthy (Dj) Dvijotham", "Jamie Hayes", "Borja Balle", "Zico Kolter", "Chongli Qin", "Andras Gyorgy", "Kai Xiao", "Sven Gowal", "Pushmeet Kohli"], "pdf": "/pdf/5c744888eae162e715f7635b283ff4545aee828d.pdf", "TL;DR": "Develop a general framework to establish certified robustness of ML models against various classes of adversarial perturbations", "abstract": "Formal verification techniques that compute provable guarantees on properties of machine learning models, like robustness to norm-bounded adversarial perturbations, have yielded impressive results. Although most techniques developed so far require knowledge of the architecture of the machine learning model and remain hard to scale to complex prediction pipelines, the method of randomized smoothing has been shown to overcome many of these obstacles. By requiring only black-box access to the underlying model, randomized smoothing scales to large architectures and is agnostic to the internals of the network. However, past work on randomized smoothing has focused on restricted classes of smoothing measures or perturbations (like Gaussian or discrete) and has only been able to prove robustness with respect to simple norm bounds. In this paper we introduce a general framework for proving robustness properties of smoothed machine learning models in the black-box setting. Specifically, we extend randomized smoothing procedures to handle arbitrary smoothing measures and prove robustness of the smoothed classifier by using f-divergences. Our methodology improves upon the state of the art in terms of computation time or certified robustness on several image classification tasks and an audio classification task, with respect to several classes of adversarial perturbations. ", "keywords": ["verification of machine learning", "certified robustness of neural networks"], "paperhash": "dvijotham|a_framework_for_robustness_certification_of_smoothed_classifiers_using_fdivergences", "_bibtex": "@inproceedings{\nDvijotham2020A,\ntitle={A FRAMEWORK  FOR ROBUSTNESS CERTIFICATION  OF SMOOTHED CLASSIFIERS USING  F-DIVERGENCES},\nauthor={Krishnamurthy (Dj) Dvijotham and Jamie Hayes and Borja Balle and Zico Kolter and Chongli Qin and Andras Gyorgy and Kai Xiao and Sven Gowal and Pushmeet Kohli},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=SJlKrkSFPH}\n}", "full_presentation_video": "", "original_pdf": "/attachment/4a7b75373f2ba1374547cb1ff42c0df98f6be1ce.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "SJlKrkSFPH", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper1699/Authors", "ICLR.cc/2020/Conference/Paper1699/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper1699/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper1699/Reviewers", "ICLR.cc/2020/Conference/Paper1699/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper1699/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper1699/Authors|ICLR.cc/2020/Conference/Paper1699/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504152175, "tmdate": 1576860538694, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper1699/Authors", "ICLR.cc/2020/Conference/Paper1699/Reviewers", "ICLR.cc/2020/Conference/Paper1699/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper1699/-/Official_Comment"}}}, {"id": "rklUqQ9dsB", "original": null, "number": 8, "cdate": 1573589902480, "ddate": null, "tcdate": 1573589902480, "tmdate": 1573723597985, "tddate": null, "forum": "SJlKrkSFPH", "replyto": "SylnaDVqYr", "invitation": "ICLR.cc/2020/Conference/Paper1699/-/Official_Comment", "content": {"title": "Thank you for your comments", "comment": "We thank the reviewer for the careful review and encouraging feedback and hope that our updated draft and the following clarifications address the concerns raised by the reviewer.\n\nClarification on connection to Cohen et al: We have significantly revised Section 5 (Connections to prior work) and clarified the steps involved in deriving the Cohen et al result as a special case of our framework. We refer to the paragraph titled \"Cohen et al 2019\" below table 1 in the revised draft.\n\nClarification on practical certification algorithms: We have revised section 3 of the paper \nso that theorems 1 and 2 are immediately followed by descriptions of practical certification algorithms that derive from these theorems - we refer the reviewer to algorithm 2 (for the information-limited case) and algorithm 1 (for the full-information case). We have also added section 2.3 on obtaining bounds on f-divergences.\n\nClarification on experiments: \n1. Full-information vs Information limited setting:  We have revised definitions 2.1 and 2.2 to better reflect this distinction. We added section 4.2 where we prove that the full-information certificates are provably tighter than the information-limited ones when smoothing probabilistic classifiers. We have added section 6.1 in the experiments that clarifies the details of the experiment comparing the full-information setting with the limited-information setting for l2 perturbations.\n2. L0 certification: To address the issue of fractional l0 values in the plot, we have removed the plots and produced tables that document the certified robustness as a function of the radius of the l0 perturbation (tables 2 and 3).\n3. Librispeech: We have expanded the experiments section to add more details about the Librispeech dataset as well as motivation for performing these experiments in section 6.3. We are happy to answer any further questions on this.\n"}, "signatures": ["ICLR.cc/2020/Conference/Paper1699/Authors"], "readers": ["ICLR.cc/2020/Conference/Paper1699/Authors", "ICLR.cc/2020/Conference/Paper1699/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper1699/Area_Chairs", "everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1699/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["dvij@google.com", "j.hayes@cs.ucl.ac.uk", "bballe@google.com", "zkolter@cs.cmu.edu", "chongliqin@google.com", "agyorgy@google.com", "kaix@mit.edu", "sgowal@google.com", "pushmeet@google.com"], "title": "A FRAMEWORK  FOR ROBUSTNESS CERTIFICATION  OF SMOOTHED CLASSIFIERS USING  F-DIVERGENCES", "authors": ["Krishnamurthy (Dj) Dvijotham", "Jamie Hayes", "Borja Balle", "Zico Kolter", "Chongli Qin", "Andras Gyorgy", "Kai Xiao", "Sven Gowal", "Pushmeet Kohli"], "pdf": "/pdf/5c744888eae162e715f7635b283ff4545aee828d.pdf", "TL;DR": "Develop a general framework to establish certified robustness of ML models against various classes of adversarial perturbations", "abstract": "Formal verification techniques that compute provable guarantees on properties of machine learning models, like robustness to norm-bounded adversarial perturbations, have yielded impressive results. Although most techniques developed so far require knowledge of the architecture of the machine learning model and remain hard to scale to complex prediction pipelines, the method of randomized smoothing has been shown to overcome many of these obstacles. By requiring only black-box access to the underlying model, randomized smoothing scales to large architectures and is agnostic to the internals of the network. However, past work on randomized smoothing has focused on restricted classes of smoothing measures or perturbations (like Gaussian or discrete) and has only been able to prove robustness with respect to simple norm bounds. In this paper we introduce a general framework for proving robustness properties of smoothed machine learning models in the black-box setting. Specifically, we extend randomized smoothing procedures to handle arbitrary smoothing measures and prove robustness of the smoothed classifier by using f-divergences. Our methodology improves upon the state of the art in terms of computation time or certified robustness on several image classification tasks and an audio classification task, with respect to several classes of adversarial perturbations. ", "keywords": ["verification of machine learning", "certified robustness of neural networks"], "paperhash": "dvijotham|a_framework_for_robustness_certification_of_smoothed_classifiers_using_fdivergences", "_bibtex": "@inproceedings{\nDvijotham2020A,\ntitle={A FRAMEWORK  FOR ROBUSTNESS CERTIFICATION  OF SMOOTHED CLASSIFIERS USING  F-DIVERGENCES},\nauthor={Krishnamurthy (Dj) Dvijotham and Jamie Hayes and Borja Balle and Zico Kolter and Chongli Qin and Andras Gyorgy and Kai Xiao and Sven Gowal and Pushmeet Kohli},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=SJlKrkSFPH}\n}", "full_presentation_video": "", "original_pdf": "/attachment/4a7b75373f2ba1374547cb1ff42c0df98f6be1ce.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "SJlKrkSFPH", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper1699/Authors", "ICLR.cc/2020/Conference/Paper1699/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper1699/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper1699/Reviewers", "ICLR.cc/2020/Conference/Paper1699/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper1699/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper1699/Authors|ICLR.cc/2020/Conference/Paper1699/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504152175, "tmdate": 1576860538694, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper1699/Authors", "ICLR.cc/2020/Conference/Paper1699/Reviewers", "ICLR.cc/2020/Conference/Paper1699/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper1699/-/Official_Comment"}}}, {"id": "HyxxTiecsB", "original": null, "number": 9, "cdate": 1573682104365, "ddate": null, "tcdate": 1573682104365, "tmdate": 1573723587693, "tddate": null, "forum": "SJlKrkSFPH", "replyto": "r1eYLSiotr", "invitation": "ICLR.cc/2020/Conference/Paper1699/-/Official_Comment", "content": {"title": "p.s. clarification and score revision", "comment": "We would like to follow up on the p.s request from the reviewer - we believe that this has been addressed in our revision (section 6.2, table 2) and are happy to provide any further clarifications the reviewer seeks.\n\n"}, "signatures": ["ICLR.cc/2020/Conference/Paper1699/Authors"], "readers": ["ICLR.cc/2020/Conference/Paper1699/Authors", "ICLR.cc/2020/Conference/Paper1699/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper1699/Area_Chairs", "everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1699/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["dvij@google.com", "j.hayes@cs.ucl.ac.uk", "bballe@google.com", "zkolter@cs.cmu.edu", "chongliqin@google.com", "agyorgy@google.com", "kaix@mit.edu", "sgowal@google.com", "pushmeet@google.com"], "title": "A FRAMEWORK  FOR ROBUSTNESS CERTIFICATION  OF SMOOTHED CLASSIFIERS USING  F-DIVERGENCES", "authors": ["Krishnamurthy (Dj) Dvijotham", "Jamie Hayes", "Borja Balle", "Zico Kolter", "Chongli Qin", "Andras Gyorgy", "Kai Xiao", "Sven Gowal", "Pushmeet Kohli"], "pdf": "/pdf/5c744888eae162e715f7635b283ff4545aee828d.pdf", "TL;DR": "Develop a general framework to establish certified robustness of ML models against various classes of adversarial perturbations", "abstract": "Formal verification techniques that compute provable guarantees on properties of machine learning models, like robustness to norm-bounded adversarial perturbations, have yielded impressive results. Although most techniques developed so far require knowledge of the architecture of the machine learning model and remain hard to scale to complex prediction pipelines, the method of randomized smoothing has been shown to overcome many of these obstacles. By requiring only black-box access to the underlying model, randomized smoothing scales to large architectures and is agnostic to the internals of the network. However, past work on randomized smoothing has focused on restricted classes of smoothing measures or perturbations (like Gaussian or discrete) and has only been able to prove robustness with respect to simple norm bounds. In this paper we introduce a general framework for proving robustness properties of smoothed machine learning models in the black-box setting. Specifically, we extend randomized smoothing procedures to handle arbitrary smoothing measures and prove robustness of the smoothed classifier by using f-divergences. Our methodology improves upon the state of the art in terms of computation time or certified robustness on several image classification tasks and an audio classification task, with respect to several classes of adversarial perturbations. ", "keywords": ["verification of machine learning", "certified robustness of neural networks"], "paperhash": "dvijotham|a_framework_for_robustness_certification_of_smoothed_classifiers_using_fdivergences", "_bibtex": "@inproceedings{\nDvijotham2020A,\ntitle={A FRAMEWORK  FOR ROBUSTNESS CERTIFICATION  OF SMOOTHED CLASSIFIERS USING  F-DIVERGENCES},\nauthor={Krishnamurthy (Dj) Dvijotham and Jamie Hayes and Borja Balle and Zico Kolter and Chongli Qin and Andras Gyorgy and Kai Xiao and Sven Gowal and Pushmeet Kohli},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=SJlKrkSFPH}\n}", "full_presentation_video": "", "original_pdf": "/attachment/4a7b75373f2ba1374547cb1ff42c0df98f6be1ce.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "SJlKrkSFPH", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper1699/Authors", "ICLR.cc/2020/Conference/Paper1699/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper1699/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper1699/Reviewers", "ICLR.cc/2020/Conference/Paper1699/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper1699/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper1699/Authors|ICLR.cc/2020/Conference/Paper1699/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504152175, "tmdate": 1576860538694, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper1699/Authors", "ICLR.cc/2020/Conference/Paper1699/Reviewers", "ICLR.cc/2020/Conference/Paper1699/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper1699/-/Official_Comment"}}}, {"id": "rkxA4Q9uoS", "original": null, "number": 7, "cdate": 1573589813752, "ddate": null, "tcdate": 1573589813752, "tmdate": 1573723580130, "tddate": null, "forum": "SJlKrkSFPH", "replyto": "r1eYLSiotr", "invitation": "ICLR.cc/2020/Conference/Paper1699/-/Official_Comment", "content": {"title": "Thank you for your comments", "comment": "We thank the reviewer for the careful review and encouraging feedback. We address the comments of the reviewer below:\n1. We have re-run the experiments with ResNet-50 for ImageNet. We took the model trained by Lee et al and ran comparisons between our certification procedure and those from Lee et al, the results are shown in Table 2.\n2. Yes, the Renyi divergence is not an f-divergence but is related via 1-1 mapping to an f-divergence. We have further reflected this in the paper see Section 2.2, paragraph titled \u201cRelaxations using f-divergence\u201d. Further, we have theoretical results (theorem 4) and experimental results (section 6.1) that use the hockey-stick divergence, and hence we think f-divergences is an appropriate unifying title.\n3. We have reorganized sections 3 and 4 in the paper and now have a full statement of the tightness result in theorem 4 in the paper. \n4. As shown in theorem 4, the tightness result in the information-limited holds specifically for the case of hockey-stick divergences. However, since it is not easy to compute hockey-stick divergences in general (Gaussians being a notable exception), it is also valuable to have certification procedures that use other f-divergences. We are happy to provide any further clarifications the reviewer seeks in this regard.\n"}, "signatures": ["ICLR.cc/2020/Conference/Paper1699/Authors"], "readers": ["ICLR.cc/2020/Conference/Paper1699/Authors", "ICLR.cc/2020/Conference/Paper1699/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper1699/Area_Chairs", "everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1699/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["dvij@google.com", "j.hayes@cs.ucl.ac.uk", "bballe@google.com", "zkolter@cs.cmu.edu", "chongliqin@google.com", "agyorgy@google.com", "kaix@mit.edu", "sgowal@google.com", "pushmeet@google.com"], "title": "A FRAMEWORK  FOR ROBUSTNESS CERTIFICATION  OF SMOOTHED CLASSIFIERS USING  F-DIVERGENCES", "authors": ["Krishnamurthy (Dj) Dvijotham", "Jamie Hayes", "Borja Balle", "Zico Kolter", "Chongli Qin", "Andras Gyorgy", "Kai Xiao", "Sven Gowal", "Pushmeet Kohli"], "pdf": "/pdf/5c744888eae162e715f7635b283ff4545aee828d.pdf", "TL;DR": "Develop a general framework to establish certified robustness of ML models against various classes of adversarial perturbations", "abstract": "Formal verification techniques that compute provable guarantees on properties of machine learning models, like robustness to norm-bounded adversarial perturbations, have yielded impressive results. Although most techniques developed so far require knowledge of the architecture of the machine learning model and remain hard to scale to complex prediction pipelines, the method of randomized smoothing has been shown to overcome many of these obstacles. By requiring only black-box access to the underlying model, randomized smoothing scales to large architectures and is agnostic to the internals of the network. However, past work on randomized smoothing has focused on restricted classes of smoothing measures or perturbations (like Gaussian or discrete) and has only been able to prove robustness with respect to simple norm bounds. In this paper we introduce a general framework for proving robustness properties of smoothed machine learning models in the black-box setting. Specifically, we extend randomized smoothing procedures to handle arbitrary smoothing measures and prove robustness of the smoothed classifier by using f-divergences. Our methodology improves upon the state of the art in terms of computation time or certified robustness on several image classification tasks and an audio classification task, with respect to several classes of adversarial perturbations. ", "keywords": ["verification of machine learning", "certified robustness of neural networks"], "paperhash": "dvijotham|a_framework_for_robustness_certification_of_smoothed_classifiers_using_fdivergences", "_bibtex": "@inproceedings{\nDvijotham2020A,\ntitle={A FRAMEWORK  FOR ROBUSTNESS CERTIFICATION  OF SMOOTHED CLASSIFIERS USING  F-DIVERGENCES},\nauthor={Krishnamurthy (Dj) Dvijotham and Jamie Hayes and Borja Balle and Zico Kolter and Chongli Qin and Andras Gyorgy and Kai Xiao and Sven Gowal and Pushmeet Kohli},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=SJlKrkSFPH}\n}", "full_presentation_video": "", "original_pdf": "/attachment/4a7b75373f2ba1374547cb1ff42c0df98f6be1ce.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "SJlKrkSFPH", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper1699/Authors", "ICLR.cc/2020/Conference/Paper1699/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper1699/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper1699/Reviewers", "ICLR.cc/2020/Conference/Paper1699/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper1699/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper1699/Authors|ICLR.cc/2020/Conference/Paper1699/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504152175, "tmdate": 1576860538694, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper1699/Authors", "ICLR.cc/2020/Conference/Paper1699/Reviewers", "ICLR.cc/2020/Conference/Paper1699/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper1699/-/Official_Comment"}}}, {"id": "BJgnDzc_or", "original": null, "number": 5, "cdate": 1573589603844, "ddate": null, "tcdate": 1573589603844, "tmdate": 1573723568648, "tddate": null, "forum": "SJlKrkSFPH", "replyto": "BkealMyptB", "invitation": "ICLR.cc/2020/Conference/Paper1699/-/Official_Comment", "content": {"title": "Thank you for your comments", "comment": "We thank the reviewer for the careful review and encouraging feedback. We respond to individual comments below:\nTechnical\nOn the distinction between information-limited and full-information certificates: We have updated the paper to clarify this distinction and refer the reviewer to section 2 (definitions 2.1 and 2.2) - we have updated the definitions. Further, section 4.1 shows theoretically how the full-information setting improves upon the information-limited setting and section 6.1 verifies this experimentally.\n\nExperiments: We have added more details to experiments (section 6 in the updated draft). The remaining comments are address below:\n1. Solution of convex optimization problems: We use an off-the-shelf solver CVXPY to solve the convex optimization problems for the experiments in section 6.1. We have documented the certification running times in section 6.1 for this procedure as well (see caption of Figure 2). In the information-limited setting considered in sections 6.2 and 6.3, we can simply use the closed-form certificates computed in the table 4 (appendix section A.6).\n2. CIFAR-10: We have added results for l1 certification on CIFAR-10 in appendix section A11. \n3. Sec 5.1:We thank the reviewer for pointing this out, we have updated the paper to reflect this (it is now Fig. 2 in section 6.1). Please refer to the updated draft.\n4. Sec 5.2: For L2 perturbations, the optimal certificate in the information limited setting can be obtained from Cohen et al, which is a special case of our framework that uses M=2 Hockey-Stick divergences (section 4, Corollary 5). We have removed this figure due to space constraints in the revised draft.\n5. Comparison to [1]: The contribution of our paper is a general flexible framework for certifying robustness of smoothed classifiers while [1] focuses on using the certification method from (Cohen et al 2019) but improving the training so as to obtain classifiers with high certified accuracy. Thus, the contributions of our paper and [1] can be considered to be orthogonal, and indeed combining them is an interesting future research direction.\n6. Sec 5.3: We have revised these results so that the model used for both certification procedures is the same and thus the clean accuracy is also the same. We have further clarified this in the paper (see Table 2, section 6.2).\n7. Motivation behind librispeech experiments: We have added clarifying text in section 6.3 in the revised draft on the motivation.\n\nComments on writing:\nWe thank the reviewer for these suggestions and have incorporated them into the revised text. We have revised the abstract and contributions sections in the paper to make the specific contributions of the paper clear. The contributions section also now contains justification for the perturbations studied in the paper.\n"}, "signatures": ["ICLR.cc/2020/Conference/Paper1699/Authors"], "readers": ["ICLR.cc/2020/Conference/Paper1699/Authors", "ICLR.cc/2020/Conference/Paper1699/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper1699/Area_Chairs", "everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1699/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["dvij@google.com", "j.hayes@cs.ucl.ac.uk", "bballe@google.com", "zkolter@cs.cmu.edu", "chongliqin@google.com", "agyorgy@google.com", "kaix@mit.edu", "sgowal@google.com", "pushmeet@google.com"], "title": "A FRAMEWORK  FOR ROBUSTNESS CERTIFICATION  OF SMOOTHED CLASSIFIERS USING  F-DIVERGENCES", "authors": ["Krishnamurthy (Dj) Dvijotham", "Jamie Hayes", "Borja Balle", "Zico Kolter", "Chongli Qin", "Andras Gyorgy", "Kai Xiao", "Sven Gowal", "Pushmeet Kohli"], "pdf": "/pdf/5c744888eae162e715f7635b283ff4545aee828d.pdf", "TL;DR": "Develop a general framework to establish certified robustness of ML models against various classes of adversarial perturbations", "abstract": "Formal verification techniques that compute provable guarantees on properties of machine learning models, like robustness to norm-bounded adversarial perturbations, have yielded impressive results. Although most techniques developed so far require knowledge of the architecture of the machine learning model and remain hard to scale to complex prediction pipelines, the method of randomized smoothing has been shown to overcome many of these obstacles. By requiring only black-box access to the underlying model, randomized smoothing scales to large architectures and is agnostic to the internals of the network. However, past work on randomized smoothing has focused on restricted classes of smoothing measures or perturbations (like Gaussian or discrete) and has only been able to prove robustness with respect to simple norm bounds. In this paper we introduce a general framework for proving robustness properties of smoothed machine learning models in the black-box setting. Specifically, we extend randomized smoothing procedures to handle arbitrary smoothing measures and prove robustness of the smoothed classifier by using f-divergences. Our methodology improves upon the state of the art in terms of computation time or certified robustness on several image classification tasks and an audio classification task, with respect to several classes of adversarial perturbations. ", "keywords": ["verification of machine learning", "certified robustness of neural networks"], "paperhash": "dvijotham|a_framework_for_robustness_certification_of_smoothed_classifiers_using_fdivergences", "_bibtex": "@inproceedings{\nDvijotham2020A,\ntitle={A FRAMEWORK  FOR ROBUSTNESS CERTIFICATION  OF SMOOTHED CLASSIFIERS USING  F-DIVERGENCES},\nauthor={Krishnamurthy (Dj) Dvijotham and Jamie Hayes and Borja Balle and Zico Kolter and Chongli Qin and Andras Gyorgy and Kai Xiao and Sven Gowal and Pushmeet Kohli},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=SJlKrkSFPH}\n}", "full_presentation_video": "", "original_pdf": "/attachment/4a7b75373f2ba1374547cb1ff42c0df98f6be1ce.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "SJlKrkSFPH", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper1699/Authors", "ICLR.cc/2020/Conference/Paper1699/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper1699/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper1699/Reviewers", "ICLR.cc/2020/Conference/Paper1699/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper1699/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper1699/Authors|ICLR.cc/2020/Conference/Paper1699/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504152175, "tmdate": 1576860538694, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper1699/Authors", "ICLR.cc/2020/Conference/Paper1699/Reviewers", "ICLR.cc/2020/Conference/Paper1699/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper1699/-/Official_Comment"}}}, {"id": "B1gCq_6Msr", "original": null, "number": 3, "cdate": 1573210261909, "ddate": null, "tcdate": 1573210261909, "tmdate": 1573210261909, "tddate": null, "forum": "SJlKrkSFPH", "replyto": "rklQRwcfsr", "invitation": "ICLR.cc/2020/Conference/Paper1699/-/Official_Comment", "content": {"title": "Thank you for the clarification", "comment": "Dear Guang-He,\n\nThank you for taking time to read our paper and pointing out these concerns.\n\nThe goal of our paper is to develop a general framework for certifying smoothed classifiers that allows arbitrary smoothing measures and perturbations. Indeed, in the case of l0 perturbations, the method from [1] is optimal. We will clarify this in our updated draft and change the experiments to better reflect this.\n\nMore concretely, we plan to make the following changes:\n\n1. Experiments: Regarding the experimental protocol, you are correct in pointing out the differences. We will rectify this by rerunning our experiments with a consistent experimental protocol, and if possible within the time constraints of the rebuttal period, with the same models (since our code is in tensorflow, it may take some time to convert the pytorch models and rerun the experiments).\n\n2. We agree that the O(d^3) computation is a one-time computation for a given smoothing measure and dataset. We will clarify this in the text. We would like to point that the quicker computation time in our approach allowed us to experiment with a broader range of smoothing measures which indeed can improve model performance significantly.\n\n3. We will change the sentence \u201cFinally, these works are both restricted to the information-limited black-box verification setting where only \u03b8a, \u03b8b are known.\u201d to clarify that [1] indeed looked at using more information to obtain better certificates.  We would like to point out that our full-information certificates are still black-box (and hence apply to arbitrary classifiers including deep nets) and do not require access to the internals of the classifier, unlike the decision tree results obtained in [1].\n\n4.  (\u03b8a, \u03b8b) are estimated using the same procedure as Cohen et al (the Clopper-Pearson CI test). We use 10M samples for MNIST, 1M samples for CIFAR-10 and 100K samples for ImageNet - these are sampled independently for every image."}, "signatures": ["ICLR.cc/2020/Conference/Paper1699/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1699/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["dvij@google.com", "j.hayes@cs.ucl.ac.uk", "bballe@google.com", "zkolter@cs.cmu.edu", "chongliqin@google.com", "agyorgy@google.com", "kaix@mit.edu", "sgowal@google.com", "pushmeet@google.com"], "title": "A FRAMEWORK  FOR ROBUSTNESS CERTIFICATION  OF SMOOTHED CLASSIFIERS USING  F-DIVERGENCES", "authors": ["Krishnamurthy (Dj) Dvijotham", "Jamie Hayes", "Borja Balle", "Zico Kolter", "Chongli Qin", "Andras Gyorgy", "Kai Xiao", "Sven Gowal", "Pushmeet Kohli"], "pdf": "/pdf/5c744888eae162e715f7635b283ff4545aee828d.pdf", "TL;DR": "Develop a general framework to establish certified robustness of ML models against various classes of adversarial perturbations", "abstract": "Formal verification techniques that compute provable guarantees on properties of machine learning models, like robustness to norm-bounded adversarial perturbations, have yielded impressive results. Although most techniques developed so far require knowledge of the architecture of the machine learning model and remain hard to scale to complex prediction pipelines, the method of randomized smoothing has been shown to overcome many of these obstacles. By requiring only black-box access to the underlying model, randomized smoothing scales to large architectures and is agnostic to the internals of the network. However, past work on randomized smoothing has focused on restricted classes of smoothing measures or perturbations (like Gaussian or discrete) and has only been able to prove robustness with respect to simple norm bounds. In this paper we introduce a general framework for proving robustness properties of smoothed machine learning models in the black-box setting. Specifically, we extend randomized smoothing procedures to handle arbitrary smoothing measures and prove robustness of the smoothed classifier by using f-divergences. Our methodology improves upon the state of the art in terms of computation time or certified robustness on several image classification tasks and an audio classification task, with respect to several classes of adversarial perturbations. ", "keywords": ["verification of machine learning", "certified robustness of neural networks"], "paperhash": "dvijotham|a_framework_for_robustness_certification_of_smoothed_classifiers_using_fdivergences", "_bibtex": "@inproceedings{\nDvijotham2020A,\ntitle={A FRAMEWORK  FOR ROBUSTNESS CERTIFICATION  OF SMOOTHED CLASSIFIERS USING  F-DIVERGENCES},\nauthor={Krishnamurthy (Dj) Dvijotham and Jamie Hayes and Borja Balle and Zico Kolter and Chongli Qin and Andras Gyorgy and Kai Xiao and Sven Gowal and Pushmeet Kohli},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=SJlKrkSFPH}\n}", "full_presentation_video": "", "original_pdf": "/attachment/4a7b75373f2ba1374547cb1ff42c0df98f6be1ce.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "SJlKrkSFPH", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper1699/Authors", "ICLR.cc/2020/Conference/Paper1699/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper1699/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper1699/Reviewers", "ICLR.cc/2020/Conference/Paper1699/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper1699/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper1699/Authors|ICLR.cc/2020/Conference/Paper1699/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504152175, "tmdate": 1576860538694, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper1699/Authors", "ICLR.cc/2020/Conference/Paper1699/Reviewers", "ICLR.cc/2020/Conference/Paper1699/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper1699/-/Official_Comment"}}}, {"id": "rkged9hGsr", "original": null, "number": 2, "cdate": 1573206631682, "ddate": null, "tcdate": 1573206631682, "tmdate": 1573206631682, "tddate": null, "forum": "SJlKrkSFPH", "replyto": "rygigJwkjH", "invitation": "ICLR.cc/2020/Conference/Paper1699/-/Official_Comment", "content": {"title": "Thanks for pointing this out", "comment": "Dear Bai,\nThank you for bringing this work to our attention. \n\nWe agree that the Renyi divergence case is indeed closely related and we are preparing an updated draft clarifying the distinction and relationship with [1].\n\nIn particular, we believe that our work generalizes [1] in three ways:\n1. Our framework handles arbitrary smoothing measures (not just Gaussian and Laplacian).\n2. We allow arbitrary f-divergence measures. In particular, for certifying l2 perturbations using Gaussian smoothing, we show that the hockey-stick divergences are necessary to obtain optimal certificates (recovering the work of Cohen et al).\n3. Even in the specific case of Renyi divergences, we can obtain better certificates by using convex combinations of Renyi divergences.\n\nWe will update the draft to reflect this and are happy to answer any other questions.\n\nRegards,\nAuthors\n\n"}, "signatures": ["ICLR.cc/2020/Conference/Paper1699/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1699/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["dvij@google.com", "j.hayes@cs.ucl.ac.uk", "bballe@google.com", "zkolter@cs.cmu.edu", "chongliqin@google.com", "agyorgy@google.com", "kaix@mit.edu", "sgowal@google.com", "pushmeet@google.com"], "title": "A FRAMEWORK  FOR ROBUSTNESS CERTIFICATION  OF SMOOTHED CLASSIFIERS USING  F-DIVERGENCES", "authors": ["Krishnamurthy (Dj) Dvijotham", "Jamie Hayes", "Borja Balle", "Zico Kolter", "Chongli Qin", "Andras Gyorgy", "Kai Xiao", "Sven Gowal", "Pushmeet Kohli"], "pdf": "/pdf/5c744888eae162e715f7635b283ff4545aee828d.pdf", "TL;DR": "Develop a general framework to establish certified robustness of ML models against various classes of adversarial perturbations", "abstract": "Formal verification techniques that compute provable guarantees on properties of machine learning models, like robustness to norm-bounded adversarial perturbations, have yielded impressive results. Although most techniques developed so far require knowledge of the architecture of the machine learning model and remain hard to scale to complex prediction pipelines, the method of randomized smoothing has been shown to overcome many of these obstacles. By requiring only black-box access to the underlying model, randomized smoothing scales to large architectures and is agnostic to the internals of the network. However, past work on randomized smoothing has focused on restricted classes of smoothing measures or perturbations (like Gaussian or discrete) and has only been able to prove robustness with respect to simple norm bounds. In this paper we introduce a general framework for proving robustness properties of smoothed machine learning models in the black-box setting. Specifically, we extend randomized smoothing procedures to handle arbitrary smoothing measures and prove robustness of the smoothed classifier by using f-divergences. Our methodology improves upon the state of the art in terms of computation time or certified robustness on several image classification tasks and an audio classification task, with respect to several classes of adversarial perturbations. ", "keywords": ["verification of machine learning", "certified robustness of neural networks"], "paperhash": "dvijotham|a_framework_for_robustness_certification_of_smoothed_classifiers_using_fdivergences", "_bibtex": "@inproceedings{\nDvijotham2020A,\ntitle={A FRAMEWORK  FOR ROBUSTNESS CERTIFICATION  OF SMOOTHED CLASSIFIERS USING  F-DIVERGENCES},\nauthor={Krishnamurthy (Dj) Dvijotham and Jamie Hayes and Borja Balle and Zico Kolter and Chongli Qin and Andras Gyorgy and Kai Xiao and Sven Gowal and Pushmeet Kohli},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=SJlKrkSFPH}\n}", "full_presentation_video": "", "original_pdf": "/attachment/4a7b75373f2ba1374547cb1ff42c0df98f6be1ce.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "SJlKrkSFPH", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper1699/Authors", "ICLR.cc/2020/Conference/Paper1699/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper1699/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper1699/Reviewers", "ICLR.cc/2020/Conference/Paper1699/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper1699/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper1699/Authors|ICLR.cc/2020/Conference/Paper1699/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504152175, "tmdate": 1576860538694, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper1699/Authors", "ICLR.cc/2020/Conference/Paper1699/Reviewers", "ICLR.cc/2020/Conference/Paper1699/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper1699/-/Official_Comment"}}}, {"id": "rklQRwcfsr", "original": null, "number": 2, "cdate": 1573197771372, "ddate": null, "tcdate": 1573197771372, "tmdate": 1573197771372, "tddate": null, "forum": "SJlKrkSFPH", "replyto": "SJlKrkSFPH", "invitation": "ICLR.cc/2020/Conference/Paper1699/-/Public_Comment", "content": {"title": "Some comments", "comment": "Dear Authors,\n\nThank you for the effort in preparing this work, but we have some questions and concerns about the paper.\n\nTaking numbers directly from another paper [1] for comparison is appropriate only if the protocol was the same. This doesn\u2019t seem to be the case. For example, [1] used 0.999 confidence level with 100K samples, while in this paper confidence level is 0.99 with 10M samples. So one could get improvements even with exactly the same certification algorithm. Also, since the difference is really the certification algorithms rather than models, are the models the same?\n\nBesides, we would like to clarify your descriptions of [1]. For instance, \u201cthey require an O(d^3) computation (where d is the input dimension) to certify smoothness to L0 perturbations (in addition to the cost of estimating \u03b8a, \u03b8b by sampling).\u201d The O(d^3) computation only requires to be done once for any given dataset. After the computation is done once, the certification takes constant time for any input data and model for the dataset: testing whether \u03b8a > some pre-computed threshold.\n\nThe description \u201cFinally, these works are both restricted to the information-limited black-box verification setting where only \u03b8a, \u03b8b are known.\u201d is incorrect. To our best knowledge, [1] is the first one to extend robustness certificates for randomized smoothing beyond only knowing \u03b8a, \u03b8b. For example, given a decision tree predictor under the smoothed distribution, [1] showed that the exact certificate can be efficiently computed.\n\nFinally, could you please explain how (\u03b8a, \u03b8b) are estimated in the experiments? For each image, did you use the same 10M samples for estimating \u03b8a and \u03b8b?\n\n[1] \u201cTight Certificates of Adversarial Robustness for Randomly Smoothed Classifiers.\u201d (The old title is \u201cA Stratified Approach to Robustness for Randomly Smoothed Classifiers\u201d), NeurIPS 2019."}, "signatures": ["~Guang-He_Lee1"], "readers": ["everyone"], "nonreaders": [], "writers": ["~Guang-He_Lee1", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["dvij@google.com", "j.hayes@cs.ucl.ac.uk", "bballe@google.com", "zkolter@cs.cmu.edu", "chongliqin@google.com", "agyorgy@google.com", "kaix@mit.edu", "sgowal@google.com", "pushmeet@google.com"], "title": "A FRAMEWORK  FOR ROBUSTNESS CERTIFICATION  OF SMOOTHED CLASSIFIERS USING  F-DIVERGENCES", "authors": ["Krishnamurthy (Dj) Dvijotham", "Jamie Hayes", "Borja Balle", "Zico Kolter", "Chongli Qin", "Andras Gyorgy", "Kai Xiao", "Sven Gowal", "Pushmeet Kohli"], "pdf": "/pdf/5c744888eae162e715f7635b283ff4545aee828d.pdf", "TL;DR": "Develop a general framework to establish certified robustness of ML models against various classes of adversarial perturbations", "abstract": "Formal verification techniques that compute provable guarantees on properties of machine learning models, like robustness to norm-bounded adversarial perturbations, have yielded impressive results. Although most techniques developed so far require knowledge of the architecture of the machine learning model and remain hard to scale to complex prediction pipelines, the method of randomized smoothing has been shown to overcome many of these obstacles. By requiring only black-box access to the underlying model, randomized smoothing scales to large architectures and is agnostic to the internals of the network. However, past work on randomized smoothing has focused on restricted classes of smoothing measures or perturbations (like Gaussian or discrete) and has only been able to prove robustness with respect to simple norm bounds. In this paper we introduce a general framework for proving robustness properties of smoothed machine learning models in the black-box setting. Specifically, we extend randomized smoothing procedures to handle arbitrary smoothing measures and prove robustness of the smoothed classifier by using f-divergences. Our methodology improves upon the state of the art in terms of computation time or certified robustness on several image classification tasks and an audio classification task, with respect to several classes of adversarial perturbations. ", "keywords": ["verification of machine learning", "certified robustness of neural networks"], "paperhash": "dvijotham|a_framework_for_robustness_certification_of_smoothed_classifiers_using_fdivergences", "_bibtex": "@inproceedings{\nDvijotham2020A,\ntitle={A FRAMEWORK  FOR ROBUSTNESS CERTIFICATION  OF SMOOTHED CLASSIFIERS USING  F-DIVERGENCES},\nauthor={Krishnamurthy (Dj) Dvijotham and Jamie Hayes and Borja Balle and Zico Kolter and Chongli Qin and Andras Gyorgy and Kai Xiao and Sven Gowal and Pushmeet Kohli},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=SJlKrkSFPH}\n}", "full_presentation_video": "", "original_pdf": "/attachment/4a7b75373f2ba1374547cb1ff42c0df98f6be1ce.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "SJlKrkSFPH", "readers": {"values": ["everyone"], "description": "User groups that will be able to read this comment."}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "~.*"}}, "readers": ["everyone"], "tcdate": 1569504191034, "tmdate": 1576860572358, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["everyone"], "noninvitees": ["ICLR.cc/2020/Conference/Paper1699/Authors", "ICLR.cc/2020/Conference/Paper1699/Reviewers", "ICLR.cc/2020/Conference/Paper1699/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper1699/-/Public_Comment"}}}, {"id": "rygigJwkjH", "original": null, "number": 1, "cdate": 1572986611244, "ddate": null, "tcdate": 1572986611244, "tmdate": 1572986611244, "tddate": null, "forum": "SJlKrkSFPH", "replyto": "SJlKrkSFPH", "invitation": "ICLR.cc/2020/Conference/Paper1699/-/Public_Comment", "content": {"title": "Closely Related Previous Work", "comment": "Dear Authors,\n\nThank you for the interesting work. I would like to point out that using Renyi divergence to calculate certified bound for randomized smoothing has been extensively studied in https://arxiv.org/abs/1809.03113 [1].\n\nAlthough this paper aims to generalize the framework to general f-divergence, Renyi divergence is particularly used in the experiments, which is the exact focus of [1]. The comparison of Renyi divergence based bound and the one obtained from PixelDP has also been done in [1].\n\nI suggest the authors discuss the connection and distinction between their work and [1] for the comprehensiveness.\n\n[1] Li, B., Chen, C., Wang, W., & Carin, L. (2018). Certified Adversarial Robustness with Additive Noise. arXiv preprint arXiv:1809.03113."}, "signatures": ["~Bai_Li1"], "readers": ["everyone"], "nonreaders": [], "writers": ["~Bai_Li1", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["dvij@google.com", "j.hayes@cs.ucl.ac.uk", "bballe@google.com", "zkolter@cs.cmu.edu", "chongliqin@google.com", "agyorgy@google.com", "kaix@mit.edu", "sgowal@google.com", "pushmeet@google.com"], "title": "A FRAMEWORK  FOR ROBUSTNESS CERTIFICATION  OF SMOOTHED CLASSIFIERS USING  F-DIVERGENCES", "authors": ["Krishnamurthy (Dj) Dvijotham", "Jamie Hayes", "Borja Balle", "Zico Kolter", "Chongli Qin", "Andras Gyorgy", "Kai Xiao", "Sven Gowal", "Pushmeet Kohli"], "pdf": "/pdf/5c744888eae162e715f7635b283ff4545aee828d.pdf", "TL;DR": "Develop a general framework to establish certified robustness of ML models against various classes of adversarial perturbations", "abstract": "Formal verification techniques that compute provable guarantees on properties of machine learning models, like robustness to norm-bounded adversarial perturbations, have yielded impressive results. Although most techniques developed so far require knowledge of the architecture of the machine learning model and remain hard to scale to complex prediction pipelines, the method of randomized smoothing has been shown to overcome many of these obstacles. By requiring only black-box access to the underlying model, randomized smoothing scales to large architectures and is agnostic to the internals of the network. However, past work on randomized smoothing has focused on restricted classes of smoothing measures or perturbations (like Gaussian or discrete) and has only been able to prove robustness with respect to simple norm bounds. In this paper we introduce a general framework for proving robustness properties of smoothed machine learning models in the black-box setting. Specifically, we extend randomized smoothing procedures to handle arbitrary smoothing measures and prove robustness of the smoothed classifier by using f-divergences. Our methodology improves upon the state of the art in terms of computation time or certified robustness on several image classification tasks and an audio classification task, with respect to several classes of adversarial perturbations. ", "keywords": ["verification of machine learning", "certified robustness of neural networks"], "paperhash": "dvijotham|a_framework_for_robustness_certification_of_smoothed_classifiers_using_fdivergences", "_bibtex": "@inproceedings{\nDvijotham2020A,\ntitle={A FRAMEWORK  FOR ROBUSTNESS CERTIFICATION  OF SMOOTHED CLASSIFIERS USING  F-DIVERGENCES},\nauthor={Krishnamurthy (Dj) Dvijotham and Jamie Hayes and Borja Balle and Zico Kolter and Chongli Qin and Andras Gyorgy and Kai Xiao and Sven Gowal and Pushmeet Kohli},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=SJlKrkSFPH}\n}", "full_presentation_video": "", "original_pdf": "/attachment/4a7b75373f2ba1374547cb1ff42c0df98f6be1ce.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "SJlKrkSFPH", "readers": {"values": ["everyone"], "description": "User groups that will be able to read this comment."}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "~.*"}}, "readers": ["everyone"], "tcdate": 1569504191034, "tmdate": 1576860572358, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["everyone"], "noninvitees": ["ICLR.cc/2020/Conference/Paper1699/Authors", "ICLR.cc/2020/Conference/Paper1699/Reviewers", "ICLR.cc/2020/Conference/Paper1699/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper1699/-/Public_Comment"}}}, {"id": "BkealMyptB", "original": null, "number": 3, "cdate": 1571774964535, "ddate": null, "tcdate": 1571774964535, "tmdate": 1572972434589, "tddate": null, "forum": "SJlKrkSFPH", "replyto": "SJlKrkSFPH", "invitation": "ICLR.cc/2020/Conference/Paper1699/-/Official_Review", "content": {"experience_assessment": "I do not know much about this area.", "rating": "6: Weak Accept", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #2", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "This paper extends existing work on certified robustness using smoothed classifier.  \nThe fundamental contribution is a framework that allows for arbitrary smoothing measure, in which certificates can be obtained by convex optimization.  \nA good number of technical contributions\nFramework for certificate under arbitrary smoothing measure -> Theorem 1, and proof in A.4 (good use of duality)\nFull calculation/result of certificates under different divergneces in Table 1.\nReasonable set of empirical evidence. \n\nOverall a lot of good things to be said, below are some questions/comments that could improve the paper:\n*Technical*\nPersonally, I cannot get a lot of value out of the distinction between full-information and information-limited certification.  It\u2019d be great if I can get some clarification on this.  \n*Experiments*\nGenerally, more details of the experiments should be included.  \nHow are the convex optimization problems actually solved (e.g., what methods/tools)?  \nHow much more computational overhead is there?\nOddly, seems like we\u2019re missing CIFAR10 results completely. \n\nSec 5.1., \nWhat does each dot in Figure 3a represent?\nSec 5.2, \nSomewhat strangely, Figure 3b is results on l0 perturbation, but not l2.  What happens for l2 when we use M>1?  How does this compare to other extensions (likely the SOTA) like [1]?\nSec 5.3,\nIt is unclear from the writing whether the comparisons to previous works were done on the same ResNet architecutre with the same clean accuracy.  Please clarify. \nI\u2019m not sure why we need the Librispeech results.  It\u2019s not motivated clearly.  Also, from writing it seems the adversary zeros out a segment.  It\u2019s unclear if this is a reasonable kind of attack to expect on speech.  If I block out a segment of the speaker, we probably don\u2019t expect any system to do well on speaker recognition.  I suggest removing this result, or somehow make it a lot more better motivated/conducted.  Clarify if I missed reasons why simply showing your method works on speech is impressive.\n\nHere are suggestions on writing:\nContribution --- in both the abstract and introduction, the experimental results should be stated clearer.  Be more specific, e.g., \u201cShow SOTA certified l2 robustness on X,Y,Z, establish first certified robustness on Librispeech, and first results on certified l0, l1 robustness on A,B,C.\u201d\nMore broadly in the introduction, please motivate why \u201cadversarial attacks as measured by other smoothing measure is important\u201d.  Past studies focus on l2-norm not just because they are do-able, but also white noise (which is naturally measured by l2-norm) is something to expect in practice.  Justify why l0, l1 would also be important.\n\nI recommend accepting this paper, but would do so with more passion if some of the comments/questions can be addressed.\n\nBest,\n\nReference:\n[1] https://arxiv.org/abs/1906.04584\n"}, "signatures": ["ICLR.cc/2020/Conference/Paper1699/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1699/AnonReviewer2"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["dvij@google.com", "j.hayes@cs.ucl.ac.uk", "bballe@google.com", "zkolter@cs.cmu.edu", "chongliqin@google.com", "agyorgy@google.com", "kaix@mit.edu", "sgowal@google.com", "pushmeet@google.com"], "title": "A FRAMEWORK  FOR ROBUSTNESS CERTIFICATION  OF SMOOTHED CLASSIFIERS USING  F-DIVERGENCES", "authors": ["Krishnamurthy (Dj) Dvijotham", "Jamie Hayes", "Borja Balle", "Zico Kolter", "Chongli Qin", "Andras Gyorgy", "Kai Xiao", "Sven Gowal", "Pushmeet Kohli"], "pdf": "/pdf/5c744888eae162e715f7635b283ff4545aee828d.pdf", "TL;DR": "Develop a general framework to establish certified robustness of ML models against various classes of adversarial perturbations", "abstract": "Formal verification techniques that compute provable guarantees on properties of machine learning models, like robustness to norm-bounded adversarial perturbations, have yielded impressive results. Although most techniques developed so far require knowledge of the architecture of the machine learning model and remain hard to scale to complex prediction pipelines, the method of randomized smoothing has been shown to overcome many of these obstacles. By requiring only black-box access to the underlying model, randomized smoothing scales to large architectures and is agnostic to the internals of the network. However, past work on randomized smoothing has focused on restricted classes of smoothing measures or perturbations (like Gaussian or discrete) and has only been able to prove robustness with respect to simple norm bounds. In this paper we introduce a general framework for proving robustness properties of smoothed machine learning models in the black-box setting. Specifically, we extend randomized smoothing procedures to handle arbitrary smoothing measures and prove robustness of the smoothed classifier by using f-divergences. Our methodology improves upon the state of the art in terms of computation time or certified robustness on several image classification tasks and an audio classification task, with respect to several classes of adversarial perturbations. ", "keywords": ["verification of machine learning", "certified robustness of neural networks"], "paperhash": "dvijotham|a_framework_for_robustness_certification_of_smoothed_classifiers_using_fdivergences", "_bibtex": "@inproceedings{\nDvijotham2020A,\ntitle={A FRAMEWORK  FOR ROBUSTNESS CERTIFICATION  OF SMOOTHED CLASSIFIERS USING  F-DIVERGENCES},\nauthor={Krishnamurthy (Dj) Dvijotham and Jamie Hayes and Borja Balle and Zico Kolter and Chongli Qin and Andras Gyorgy and Kai Xiao and Sven Gowal and Pushmeet Kohli},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=SJlKrkSFPH}\n}", "full_presentation_video": "", "original_pdf": "/attachment/4a7b75373f2ba1374547cb1ff42c0df98f6be1ce.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "SJlKrkSFPH", "replyto": "SJlKrkSFPH", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper1699/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper1699/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1575468659775, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper1699/Reviewers"], "noninvitees": [], "tcdate": 1570237733568, "tmdate": 1575468659787, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper1699/-/Official_Review"}}}], "count": 14}