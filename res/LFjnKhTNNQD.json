{"notes": [{"id": "LFjnKhTNNQD", "original": "yB0CPVjKJ3-", "number": 2087, "cdate": 1601308229957, "ddate": null, "tcdate": 1601308229957, "tmdate": 1614985716588, "tddate": null, "forum": "LFjnKhTNNQD", "replyto": null, "invitation": "ICLR.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Prepare for the Worst: Generalizing across Domain Shifts with Adversarial Batch Normalization", "authorids": ["~Manli_Shu1", "~Zuxuan_Wu1", "~Micah_Goldblum1", "~Tom_Goldstein1"], "authors": ["Manli Shu", "Zuxuan Wu", "Micah Goldblum", "Tom Goldstein"], "keywords": ["adversarial training", "distributional shifts"], "abstract": "Adversarial training is the industry standard for producing models that are robust to small adversarial perturbations.  However, machine learning practitioners need models that are robust to other kinds of changes that occur naturally, such as changes in the style or illumination of input images. Such changes in input distribution have been effectively modeled as shifts in the mean and variance of deep image features.   We adapt adversarial training by adversarially perturbing these feature statistics, rather than image pixels, to produce models that are robust to distributional shifts. We also visualize images from adversarially crafted distributions. Our method, Adversarial Batch Normalization (AdvBN), significantly improves the performance of ResNet-50 on ImageNet-C (+8.1%), Stylized-ImageNet (+6.7%), and ImageNet-Instagram (+3.9%) over standard training practices.  In addition, we demonstrate that AdvBN can also improve generalization on semantic segmentation.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "shu|prepare_for_the_worst_generalizing_across_domain_shifts_with_adversarial_batch_normalization", "one-sentence_summary": "This work proposes a feature space adversarial training method based on Batchnorm statistics, to attain generalization to distributional shifted data.", "pdf": "/pdf/b8131b0f600444e3e9c4a2df7b2c00abdc97c641.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=HD0dWMzp2", "_bibtex": "@misc{\nshu2021prepare,\ntitle={Prepare for the Worst: Generalizing across Domain Shifts with Adversarial Batch Normalization},\nauthor={Manli Shu and Zuxuan Wu and Micah Goldblum and Tom Goldstein},\nyear={2021},\nurl={https://openreview.net/forum?id=LFjnKhTNNQD}\n}"}, "signatures": ["ICLR.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference"], "details": {"replyCount": 16, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"reply": {"readers": {"values-regex": ".*"}, "writers": {"values": ["ICLR.cc/2021/Conference"]}, "signatures": {"values": ["ICLR.cc/2021/Conference"]}, "content": {"authors": {"values": ["Anonymous"]}, "authorids": {"values-regex": ".*"}, "reviewed_version_(pdf)": {"required": false, "description": "Upload a PDF file that ends with .pdf", "value-regex": ".*"}}}, "signatures": ["ICLR.cc/2021/Conference"], "readers": ["everyone"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["~", "OpenReview.net/Support"], "tcdate": 1601308008205, "tmdate": 1614984599368, "id": "ICLR.cc/2021/Conference/-/Blind_Submission"}}, "tauthor": "OpenReview.net"}, {"id": "5oAcPhx7rrC", "original": null, "number": 1, "cdate": 1610040426126, "ddate": null, "tcdate": 1610040426126, "tmdate": 1610474025572, "tddate": null, "forum": "LFjnKhTNNQD", "replyto": "LFjnKhTNNQD", "invitation": "ICLR.cc/2021/Conference/Paper2087/-/Decision", "content": {"title": "Final Decision", "decision": "Reject", "comment": "This work proposes a novel, interesting and simple technique to improve the model robustness to distribution shift. The proposed method is called Adversarial Batch Normalization (AdvBN) which is based on adversarial perturbation of BN statistics. Authors provide extensive experiments to show the effectiveness of AdvBN. All reviewers agree that the proposed method is interesting and novel. The main concern of reviewers is about the some of the details of the empirical evaluation of the proposed methods which makes its effectiveness less clear. In particular, the following concerns are shared among the reviewers:\n\n1- Authors give different treatments to Stylized-ImageNet compare to other tasks by using auxiliary BN at inference time instead of standard BN and further results provided by authors show that the improvement over previous methods disappear if they use standard BN for inference on Stylized-ImageNet. I think authors could mitigate this issue by further investigation or providing a better explanation on why they have a different treatment for Stylized-ImageNet (other than the fact that auxiliary BN has a better performance on that task). The other potential remedy is to come up with an automatic way to decide which one to use at the inference time using a batch of \"unlabeled\" validation data.\n\n2- The improvement of AdvBN over AugMix and AdvProp (which was added during the rebuttal) is not clear. In particular, both methods improve over AdvBN on ImageNet-C. If standard BN is used for AdvBN on Stylized-ImageNet, then both AugMix and AdvProp improve over AdvBN. That only leaves ImageNet-Instagram as an ImageNet variant where AdvBN shows a clear improvement over AdvBN and AugMix. A potential solution is to try combining AugMix and AdvBN (not sure if AdvProp could be combined effectively) to see if there is a way to get maximum benefit out of these methods.\n\n3- The empirical section could be improved by doing experiments in a systematic way. That is for any choices made in the experiment design, there should be a reason that is explained clearly. For example: 1) applying the same type of data-augmentation on all methods (or reporting all methods with and without data-augmentation). 2) compare to all baselines on ResNet-50 and then pick the top 2 baselines (say AugMix and AdvProp) and then compare them on DenseNet and EfficientNet. 3) comparing with the same baselines as (2) on the segmentation task.\n\nFinally, I want to thank authors for engaging with reviewers, running many experiments during the rebuttal period and updating the paper accordingly. I also want to reassure authors that my final evaluation of the paper is based on: 1) reading all reviews and responses 2) weighing the reviews based on their substance, quality and engagement of reviewers 3) looking at the initial and final revision of the paper. In particular, even though the average score of this paper is low, in my opinion it is a borderline paper. After taking all of the above into account, my decision is to recommend rejection. Even though the proposed method is very interesting, there are three clear valid concerns all of which can be addressed as I suggested above. Without addressing those concerns, the empirical advantage of the proposed method is not demonstrated properly. I think after addressing those concerns this paper will be in a much better shape, more useful for ML community and hence receives the attention it deserves. I sympathize with authors that their efforts during the rebuttal period did not result in improving reviewers' scores but I want to emphasize that I did take all those updates into account when making my recommendation for this paper.\n"}, "signatures": ["ICLR.cc/2021/Conference/Program_Chairs"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference/Program_Chairs"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Prepare for the Worst: Generalizing across Domain Shifts with Adversarial Batch Normalization", "authorids": ["~Manli_Shu1", "~Zuxuan_Wu1", "~Micah_Goldblum1", "~Tom_Goldstein1"], "authors": ["Manli Shu", "Zuxuan Wu", "Micah Goldblum", "Tom Goldstein"], "keywords": ["adversarial training", "distributional shifts"], "abstract": "Adversarial training is the industry standard for producing models that are robust to small adversarial perturbations.  However, machine learning practitioners need models that are robust to other kinds of changes that occur naturally, such as changes in the style or illumination of input images. Such changes in input distribution have been effectively modeled as shifts in the mean and variance of deep image features.   We adapt adversarial training by adversarially perturbing these feature statistics, rather than image pixels, to produce models that are robust to distributional shifts. We also visualize images from adversarially crafted distributions. Our method, Adversarial Batch Normalization (AdvBN), significantly improves the performance of ResNet-50 on ImageNet-C (+8.1%), Stylized-ImageNet (+6.7%), and ImageNet-Instagram (+3.9%) over standard training practices.  In addition, we demonstrate that AdvBN can also improve generalization on semantic segmentation.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "shu|prepare_for_the_worst_generalizing_across_domain_shifts_with_adversarial_batch_normalization", "one-sentence_summary": "This work proposes a feature space adversarial training method based on Batchnorm statistics, to attain generalization to distributional shifted data.", "pdf": "/pdf/b8131b0f600444e3e9c4a2df7b2c00abdc97c641.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=HD0dWMzp2", "_bibtex": "@misc{\nshu2021prepare,\ntitle={Prepare for the Worst: Generalizing across Domain Shifts with Adversarial Batch Normalization},\nauthor={Manli Shu and Zuxuan Wu and Micah Goldblum and Tom Goldstein},\nyear={2021},\nurl={https://openreview.net/forum?id=LFjnKhTNNQD}\n}"}, "tags": [], "invitation": {"reply": {"forum": "LFjnKhTNNQD", "replyto": "LFjnKhTNNQD", "readers": {"values": ["everyone"]}, "writers": {"values": ["ICLR.cc/2021/Conference/Program_Chairs"]}, "signatures": {"values": ["ICLR.cc/2021/Conference/Program_Chairs"]}, "content": {"title": {"value": "Final Decision"}, "decision": {"value-radio": ["Accept (Oral)", "Accept (Spotlight)", "Accept (Poster)", "Reject"]}, "comment": {"value-regex": "[\\S\\s]{0,50000}", "markdown": true}}}, "multiReply": false, "signatures": ["ICLR.cc/2021/Conference"], "readers": ["everyone"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Program_Chairs"], "tcdate": 1610040426112, "tmdate": 1610474025555, "id": "ICLR.cc/2021/Conference/Paper2087/-/Decision"}}}, {"id": "WgtjiBvLRfi", "original": null, "number": 1, "cdate": 1603780219040, "ddate": null, "tcdate": 1603780219040, "tmdate": 1606812805113, "tddate": null, "forum": "LFjnKhTNNQD", "replyto": "LFjnKhTNNQD", "invitation": "ICLR.cc/2021/Conference/Paper2087/-/Official_Review", "content": {"title": "A straightforward approach", "review": "This paper proposes an algorithm for generalization to unseen domains. The algorithm performs adversarial training on the batch normalization coefficients. The authors provides experimental results showing the benefits of the proposed algorithm and also provides ablation study.\n\nStrength:\nI think the algorithm in this paper is simple and straightforward and the paper is easy to follow. The authors provided experiments on large scale dataset, some ImageNet-based datasets.\n\nWeakness:\nMy major concern is that the experimental results does not fully validate the effectiveness of the proposed algorithm. For example, in Table 1, the results are very close to Augmix on Imagenet-C and Imagenet-Instagram. Only on Stylized-Imagenet, the proposed method shows benefits.\nI have a hypothesis that the proposed AdvBN method may bias the model to be more robust to image style change (the images in Figure 2 and 3 kind of show this), but may not improve the robustness to other types of corruptions. Overall, it is not convincing that the proposed method can provide universal robustness gain to all kinds of corruption/domain changes.\n\nRecommendations:\nI would like to see more discussion on how the proposed algorithm affects different types of corruptions.  For example, there are 15 different types of image corruptions in Imagenet-C, and I suggest the authors to provide the test results on each type of corruption, so that the readers can better understand what types of corruption this method is more effective on.\nIf the authors cannot show that AdvBN provides universal robustness, I would like to suggest that the authors change the claims in the paper that the AdvBN improves the robustness to all the corruptions (or preparing for the worst), to a more gentle claim that the method is effective for some particular types of corruptions.\nIf possible, I would also like to see some experimental comparison between this method and distributional robust optimization, which I think is a more principled approach to getting general robustness. For example, can the authors compare with:\nVolpi, et al, Generalizing to Unseen Domains via Adversarial Data Augmentation?\n\n\n=======\n\nAfter author response: I would like to thank the authors for providing the details of each corruption in ImageNet-C dataset. I understand that it might be hard to compare with Volpi et al due to lack of implementation details. However, I still feel that this submission is a bit lack of depth and thus it may not be a good contribution to the ICLR community. I would like to see more theoretical or experimental evidence that can help us get a deeper understanding of this approach. Overall I decided to keep my score.\n", "rating": "5: Marginally below acceptance threshold", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["ICLR.cc/2021/Conference/Paper2087/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2087/AnonReviewer2"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Prepare for the Worst: Generalizing across Domain Shifts with Adversarial Batch Normalization", "authorids": ["~Manli_Shu1", "~Zuxuan_Wu1", "~Micah_Goldblum1", "~Tom_Goldstein1"], "authors": ["Manli Shu", "Zuxuan Wu", "Micah Goldblum", "Tom Goldstein"], "keywords": ["adversarial training", "distributional shifts"], "abstract": "Adversarial training is the industry standard for producing models that are robust to small adversarial perturbations.  However, machine learning practitioners need models that are robust to other kinds of changes that occur naturally, such as changes in the style or illumination of input images. Such changes in input distribution have been effectively modeled as shifts in the mean and variance of deep image features.   We adapt adversarial training by adversarially perturbing these feature statistics, rather than image pixels, to produce models that are robust to distributional shifts. We also visualize images from adversarially crafted distributions. Our method, Adversarial Batch Normalization (AdvBN), significantly improves the performance of ResNet-50 on ImageNet-C (+8.1%), Stylized-ImageNet (+6.7%), and ImageNet-Instagram (+3.9%) over standard training practices.  In addition, we demonstrate that AdvBN can also improve generalization on semantic segmentation.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "shu|prepare_for_the_worst_generalizing_across_domain_shifts_with_adversarial_batch_normalization", "one-sentence_summary": "This work proposes a feature space adversarial training method based on Batchnorm statistics, to attain generalization to distributional shifted data.", "pdf": "/pdf/b8131b0f600444e3e9c4a2df7b2c00abdc97c641.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=HD0dWMzp2", "_bibtex": "@misc{\nshu2021prepare,\ntitle={Prepare for the Worst: Generalizing across Domain Shifts with Adversarial Batch Normalization},\nauthor={Manli Shu and Zuxuan Wu and Micah Goldblum and Tom Goldstein},\nyear={2021},\nurl={https://openreview.net/forum?id=LFjnKhTNNQD}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq . ***Please remember to file the Code-of-Ethics report. Once you submitted the review, a link to the report will be visible in the bottom right corner of your review.***", "required": true, "markdown": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}, "forum": "LFjnKhTNNQD", "replyto": "LFjnKhTNNQD", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"], "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper2087/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1607428800000, "duedate": 1606752000000, "multiReply": false, "readers": ["everyone"], "tcdate": 1602538104365, "tmdate": 1606915779819, "super": "ICLR.cc/2021/Conference/-/Official_Review", "signatures": ["OpenReview.net"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Paper2087/Reviewers", "OpenReview.net/Support"], "id": "ICLR.cc/2021/Conference/Paper2087/-/Official_Review"}}}, {"id": "M5WNIwUqrn", "original": null, "number": 3, "cdate": 1604032154053, "ddate": null, "tcdate": 1604032154053, "tmdate": 1606771862907, "tddate": null, "forum": "LFjnKhTNNQD", "replyto": "LFjnKhTNNQD", "invitation": "ICLR.cc/2021/Conference/Paper2087/-/Official_Review", "content": {"title": "A good new approach to generalization through normalization", "review": "The authors present an approach for tackling the generalization problem in neural network classifiers based on a new method of batch normalization.  The authors go on to apply this normalization in an autoencoder arrangement in order to show the relationship between the effect of the normalizer on the features and the image that they represent.  Finally, the method is evaluated by pre-training on imagenet, finetuning with the proposed batch normalization, and testing on three versions of imagenet with global transformations applied.  \n\nPros: \nNovel application of normalization idea\nClear presentation \nUseful and relevant to the conference\nVery good quantity and relevance of experimentation \n\nCons: \nWould like to see more introspection on the results \n\nAll in all, I think this is a strong paper with only minor issues and would be a great addition to ICLR.  The idea presented is simple but also seemingly very strong in principle and I appreciate that it does not require much in the way of algorithmically complex calculations.  I am most happy about the presented level of experimentation which the authors have done a good job of a) contrasting to the state of the art, b) exploring their own model, and c) exploring other applications.  On that note, however, to explain more the \u201ccon\u201d which I have listed, the main contribution here being the experimentation which proves the authors\u2019 idea it would be very nice to have a discussion about what the results mean deeper than answering, \u201cDoes this prove the method?\u201d either in the main paper or an appendix.  I have some examples listed below.  That to me would be something that could elevate the paper to the top 50% or more of papers.\n\nQuestions for the authors: \nWhy is AdvBN not improving on AugMix for imagenet-c but does for the other datasets does this indicate some drawbacks for the method?  \nWhy does performance appear to get better in the ablation study on $\\epsilon$ but then get worse after a certain threshold? \n\nPost-rebuttal updates:\nI thank the Authors for their response. After reading all the reviews and comments I feel that there are aspects of the proposed approach that are not fully understood, despite the improvements. For example, those related to AugMix, and providing fully symmetric comparisons between Cityscapes and GTA5, as several reviewers have pointed out. For these reasons, I have decided to revise my ratings as I also recognize the importance of these observations. ", "rating": "6: Marginally above acceptance threshold", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["ICLR.cc/2021/Conference/Paper2087/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2087/AnonReviewer1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Prepare for the Worst: Generalizing across Domain Shifts with Adversarial Batch Normalization", "authorids": ["~Manli_Shu1", "~Zuxuan_Wu1", "~Micah_Goldblum1", "~Tom_Goldstein1"], "authors": ["Manli Shu", "Zuxuan Wu", "Micah Goldblum", "Tom Goldstein"], "keywords": ["adversarial training", "distributional shifts"], "abstract": "Adversarial training is the industry standard for producing models that are robust to small adversarial perturbations.  However, machine learning practitioners need models that are robust to other kinds of changes that occur naturally, such as changes in the style or illumination of input images. Such changes in input distribution have been effectively modeled as shifts in the mean and variance of deep image features.   We adapt adversarial training by adversarially perturbing these feature statistics, rather than image pixels, to produce models that are robust to distributional shifts. We also visualize images from adversarially crafted distributions. Our method, Adversarial Batch Normalization (AdvBN), significantly improves the performance of ResNet-50 on ImageNet-C (+8.1%), Stylized-ImageNet (+6.7%), and ImageNet-Instagram (+3.9%) over standard training practices.  In addition, we demonstrate that AdvBN can also improve generalization on semantic segmentation.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "shu|prepare_for_the_worst_generalizing_across_domain_shifts_with_adversarial_batch_normalization", "one-sentence_summary": "This work proposes a feature space adversarial training method based on Batchnorm statistics, to attain generalization to distributional shifted data.", "pdf": "/pdf/b8131b0f600444e3e9c4a2df7b2c00abdc97c641.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=HD0dWMzp2", "_bibtex": "@misc{\nshu2021prepare,\ntitle={Prepare for the Worst: Generalizing across Domain Shifts with Adversarial Batch Normalization},\nauthor={Manli Shu and Zuxuan Wu and Micah Goldblum and Tom Goldstein},\nyear={2021},\nurl={https://openreview.net/forum?id=LFjnKhTNNQD}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq . ***Please remember to file the Code-of-Ethics report. Once you submitted the review, a link to the report will be visible in the bottom right corner of your review.***", "required": true, "markdown": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}, "forum": "LFjnKhTNNQD", "replyto": "LFjnKhTNNQD", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"], "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper2087/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1607428800000, "duedate": 1606752000000, "multiReply": false, "readers": ["everyone"], "tcdate": 1602538104365, "tmdate": 1606915779819, "super": "ICLR.cc/2021/Conference/-/Official_Review", "signatures": ["OpenReview.net"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Paper2087/Reviewers", "OpenReview.net/Support"], "id": "ICLR.cc/2021/Conference/Paper2087/-/Official_Review"}}}, {"id": "V1VXCJEVdLR", "original": null, "number": 2, "cdate": 1603866823817, "ddate": null, "tcdate": 1603866823817, "tmdate": 1606707078473, "tddate": null, "forum": "LFjnKhTNNQD", "replyto": "LFjnKhTNNQD", "invitation": "ICLR.cc/2021/Conference/Paper2087/-/Official_Review", "content": {"title": "Official Blind Review #3", "review": "This paper proposes adversarial batch normalization (ABN) to perturb feature statistics. It is to makes CNNs more robust to image style or appearance changes. An ABN layer can plug into the middle of a CNN to finetune a pre-trained model. The CNN layers after the ABN layer can learn more robust representations from the perturbed features. It uses two groups of batch normalizations in the later layers: one for the adversarial features and the other for clean features. Experiments show it can improve robustness on image classification and segmentation.\n\nPros\n1. Applying adversarial training to batch normalization statistics is well-motivated for image style robustness.\n2. The method looks simple to implement.\n3. Experiments show its effectiveness on two tasks: classification and segmentation.\n\nCons\n1. Some typos exist in the paper, e.g., \"additional compute\" and \"training times\" in the last paragraph of Section 4.\n2. The meaning of the last line in Table 2 is not clear. I have read the paragraph describing this ablation study (AutoAugment*) but still do not understand it. Does it mean ABN in Table 1 is with AutoAugment during the finetuning?\n3. It is not clear whether ABN applies in conjunction with AugMix to further lower the corruption error. The current corruption error is close to AugMix.\n4. Experiments only use one model, ResNet-50, which is insufficient. The layer ablation study does not explore the first network block and input. It is not clear whether the optimal layer changes if the network architecture changes.\n5. The domain generalization setting from Cityscapes to GTA5 is unconvincing because Cityscapes are realistic data, while GTA5 consists of synthetic data. The opposite generalization makes more sense in practice.\n6. The paper emphasizes the finetuning efficiency when compared with other methods trained from scratch. I think the pre-trained time also needs to be considered. For a new task, there is usually no well-known pre-trained models. This raises another question: how does the method perform to train a model from scratch?\n\nIn summary, the proposed ABN is simple and effective in improving model robustness to style changes. My main concern is that the experiments are insufficient and have some space for improvements. See points 2-6 in the above for details. Thus, I tend to rate it below the acceptance threshold.\n\nPost-rebuttal updates\n\nThank the authors for the great efforts in addressing the concerns. The new experiments on two new backbones DenseNet-121 and EfficientNet-B0 show the method can work well with multiple backbones, which is good. However, my other concerns remain unsolved. \n\n1. Combination with AugMix seems necessary to demonstrate state-of-the-art performance and its orthogonality. \n\n2. I still think the generalization from GTA5 -> CityScape should be listed together with CityScape -> GTA5. \n\n3. The running time comparison should take the model's pre-trained time into account in Table 8.\n\n4. Regarding the blocks in the ablation study, I remember a ResNet50 for ImageNet has 4 blocks. Table 3 only lists 3 blocks (2,3,4). So the first block is not the first convolution layer. \n\nTherefore, I still keep my original rating.", "rating": "5: Marginally below acceptance threshold", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["ICLR.cc/2021/Conference/Paper2087/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2087/AnonReviewer3"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Prepare for the Worst: Generalizing across Domain Shifts with Adversarial Batch Normalization", "authorids": ["~Manli_Shu1", "~Zuxuan_Wu1", "~Micah_Goldblum1", "~Tom_Goldstein1"], "authors": ["Manli Shu", "Zuxuan Wu", "Micah Goldblum", "Tom Goldstein"], "keywords": ["adversarial training", "distributional shifts"], "abstract": "Adversarial training is the industry standard for producing models that are robust to small adversarial perturbations.  However, machine learning practitioners need models that are robust to other kinds of changes that occur naturally, such as changes in the style or illumination of input images. Such changes in input distribution have been effectively modeled as shifts in the mean and variance of deep image features.   We adapt adversarial training by adversarially perturbing these feature statistics, rather than image pixels, to produce models that are robust to distributional shifts. We also visualize images from adversarially crafted distributions. Our method, Adversarial Batch Normalization (AdvBN), significantly improves the performance of ResNet-50 on ImageNet-C (+8.1%), Stylized-ImageNet (+6.7%), and ImageNet-Instagram (+3.9%) over standard training practices.  In addition, we demonstrate that AdvBN can also improve generalization on semantic segmentation.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "shu|prepare_for_the_worst_generalizing_across_domain_shifts_with_adversarial_batch_normalization", "one-sentence_summary": "This work proposes a feature space adversarial training method based on Batchnorm statistics, to attain generalization to distributional shifted data.", "pdf": "/pdf/b8131b0f600444e3e9c4a2df7b2c00abdc97c641.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=HD0dWMzp2", "_bibtex": "@misc{\nshu2021prepare,\ntitle={Prepare for the Worst: Generalizing across Domain Shifts with Adversarial Batch Normalization},\nauthor={Manli Shu and Zuxuan Wu and Micah Goldblum and Tom Goldstein},\nyear={2021},\nurl={https://openreview.net/forum?id=LFjnKhTNNQD}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq . ***Please remember to file the Code-of-Ethics report. Once you submitted the review, a link to the report will be visible in the bottom right corner of your review.***", "required": true, "markdown": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}, "forum": "LFjnKhTNNQD", "replyto": "LFjnKhTNNQD", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"], "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper2087/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1607428800000, "duedate": 1606752000000, "multiReply": false, "readers": ["everyone"], "tcdate": 1602538104365, "tmdate": 1606915779819, "super": "ICLR.cc/2021/Conference/-/Official_Review", "signatures": ["OpenReview.net"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Paper2087/Reviewers", "OpenReview.net/Support"], "id": "ICLR.cc/2021/Conference/Paper2087/-/Official_Review"}}}, {"id": "1bZ_BOEhZ3G", "original": null, "number": 15, "cdate": 1606272974034, "ddate": null, "tcdate": 1606272974034, "tmdate": 1606272974034, "tddate": null, "forum": "LFjnKhTNNQD", "replyto": "Byemp1qoIlH", "invitation": "ICLR.cc/2021/Conference/Paper2087/-/Official_Comment", "content": {"title": "Results of segmentation using AdvProp", "comment": "Thank you for the suggestion. We understand your concern, and see possible way to improve our experiment section.           \nWe would like to compare to AdvProp in the fine-tuning scenario, and given more time, we will include it in the next version of this work. Also, we think it is a good point that you mentioned *\"The results on segmentation in Table 5 and 6 are promising, but it could be that a similar gain potentially can be achieved also with Lp adversarial training.\"*, and we are also interested to see whether this is the case.     \nGiven pre-trained baseline models on hand, we are able to fine-tune a segmentation model on one of the Synthia dataset with the AdvProp method, using same amount of epochs as for AdvBN. Given limited time we have, we ran one setting using the epsilon value that is supposed to be optimal for EfficientNet-B0 found by authors of the AdvProp in Table 2 of Xie, et al, *Adversarial Examples Improve Image Recognition*.     \nWe summarize the results below:     \n\n|          |      |      | Highway |        |        |\n|:--------:|------|:----:|:---------:|:------:|:------:|\n|          | Dawn |  Fog | Night   | Spring | Winter |\n| baseline | 18.6 | 21.0 | 16.9    |  21.6  |  15.3  |\n|  AdvProp | 12.1 | 19.7 | 10.5    |  21.7  |  18.4  |\n|   AdvBN  | 21.6 | 24.2 | 22.2    |  27.2  |  19.8  |\n\nThis table corresponds to the right-hand side table in Table 6. All three models are trained/fine-tuned on the N.Y. Like C./Spring dataset, and the metric we use here is mean IOU.\nWe believe our method is well motivated, that perturbing BN statistics would be a fast and straightforward way to improve generalization ability. "}, "signatures": ["ICLR.cc/2021/Conference/Paper2087/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2087/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Prepare for the Worst: Generalizing across Domain Shifts with Adversarial Batch Normalization", "authorids": ["~Manli_Shu1", "~Zuxuan_Wu1", "~Micah_Goldblum1", "~Tom_Goldstein1"], "authors": ["Manli Shu", "Zuxuan Wu", "Micah Goldblum", "Tom Goldstein"], "keywords": ["adversarial training", "distributional shifts"], "abstract": "Adversarial training is the industry standard for producing models that are robust to small adversarial perturbations.  However, machine learning practitioners need models that are robust to other kinds of changes that occur naturally, such as changes in the style or illumination of input images. Such changes in input distribution have been effectively modeled as shifts in the mean and variance of deep image features.   We adapt adversarial training by adversarially perturbing these feature statistics, rather than image pixels, to produce models that are robust to distributional shifts. We also visualize images from adversarially crafted distributions. Our method, Adversarial Batch Normalization (AdvBN), significantly improves the performance of ResNet-50 on ImageNet-C (+8.1%), Stylized-ImageNet (+6.7%), and ImageNet-Instagram (+3.9%) over standard training practices.  In addition, we demonstrate that AdvBN can also improve generalization on semantic segmentation.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "shu|prepare_for_the_worst_generalizing_across_domain_shifts_with_adversarial_batch_normalization", "one-sentence_summary": "This work proposes a feature space adversarial training method based on Batchnorm statistics, to attain generalization to distributional shifted data.", "pdf": "/pdf/b8131b0f600444e3e9c4a2df7b2c00abdc97c641.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=HD0dWMzp2", "_bibtex": "@misc{\nshu2021prepare,\ntitle={Prepare for the Worst: Generalizing across Domain Shifts with Adversarial Batch Normalization},\nauthor={Manli Shu and Zuxuan Wu and Micah Goldblum and Tom Goldstein},\nyear={2021},\nurl={https://openreview.net/forum?id=LFjnKhTNNQD}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "LFjnKhTNNQD", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper2087/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper2087/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper2087/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper2087/Authors|ICLR.cc/2021/Conference/Paper2087/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2087/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923852426, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper2087/-/Official_Comment"}}}, {"id": "Byemp1qoIlH", "original": null, "number": 14, "cdate": 1606258037280, "ddate": null, "tcdate": 1606258037280, "tmdate": 1606258037280, "tddate": null, "forum": "LFjnKhTNNQD", "replyto": "k2P3Co7IhtT", "invitation": "ICLR.cc/2021/Conference/Paper2087/-/Official_Comment", "content": {"title": "Overall comparison with AdvProp is not in favor of AdvBN (although there are differences in the number of epochs)", "comment": "I see that it's hard to make a proper comparison with the original AdvProp given limited computational resources and time. Perhaps, another option is to fine-tune AdvProp from a standardly trained model also for 20 epochs similarly to what you do with your method for a fair comparison (with a grid search over the Linf epsilon).\n\nTo conclude, despite the proposed approach is conceptually interesting, I think there is not enough evidence to say that it outperforms simple Lp adversarial training which is a natural baseline if one sticks to a single BatchNorm at test time. The results on segmentation in Table 5 and 6 are promising, but it could be that a similar gain potentially can be achieved also with Lp adversarial training. This makes me keep the original score 5/10."}, "signatures": ["ICLR.cc/2021/Conference/Paper2087/AnonReviewer5"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2087/AnonReviewer5"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Prepare for the Worst: Generalizing across Domain Shifts with Adversarial Batch Normalization", "authorids": ["~Manli_Shu1", "~Zuxuan_Wu1", "~Micah_Goldblum1", "~Tom_Goldstein1"], "authors": ["Manli Shu", "Zuxuan Wu", "Micah Goldblum", "Tom Goldstein"], "keywords": ["adversarial training", "distributional shifts"], "abstract": "Adversarial training is the industry standard for producing models that are robust to small adversarial perturbations.  However, machine learning practitioners need models that are robust to other kinds of changes that occur naturally, such as changes in the style or illumination of input images. Such changes in input distribution have been effectively modeled as shifts in the mean and variance of deep image features.   We adapt adversarial training by adversarially perturbing these feature statistics, rather than image pixels, to produce models that are robust to distributional shifts. We also visualize images from adversarially crafted distributions. Our method, Adversarial Batch Normalization (AdvBN), significantly improves the performance of ResNet-50 on ImageNet-C (+8.1%), Stylized-ImageNet (+6.7%), and ImageNet-Instagram (+3.9%) over standard training practices.  In addition, we demonstrate that AdvBN can also improve generalization on semantic segmentation.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "shu|prepare_for_the_worst_generalizing_across_domain_shifts_with_adversarial_batch_normalization", "one-sentence_summary": "This work proposes a feature space adversarial training method based on Batchnorm statistics, to attain generalization to distributional shifted data.", "pdf": "/pdf/b8131b0f600444e3e9c4a2df7b2c00abdc97c641.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=HD0dWMzp2", "_bibtex": "@misc{\nshu2021prepare,\ntitle={Prepare for the Worst: Generalizing across Domain Shifts with Adversarial Batch Normalization},\nauthor={Manli Shu and Zuxuan Wu and Micah Goldblum and Tom Goldstein},\nyear={2021},\nurl={https://openreview.net/forum?id=LFjnKhTNNQD}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "LFjnKhTNNQD", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper2087/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper2087/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper2087/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper2087/Authors|ICLR.cc/2021/Conference/Paper2087/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2087/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923852426, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper2087/-/Official_Comment"}}}, {"id": "k2P3Co7IhtT", "original": null, "number": 13, "cdate": 1606257217222, "ddate": null, "tcdate": 1606257217222, "tmdate": 1606257217222, "tddate": null, "forum": "LFjnKhTNNQD", "replyto": "DcgmcNqKxLp", "invitation": "ICLR.cc/2021/Conference/Paper2087/-/Official_Comment", "content": {"title": "Thank you for the reply. We provide you with the additional results. ", "comment": "Thank you for your interest in our results. We tested our models on ImageNet-Stylized dataset and found that, for ResNet 50, the top-1 accuracy using *standard BN* is 9.7%, and for EfficientNet-B0 this accuracy is 13.5%. We expect this performance to drop, because we assume ImageNet-Stylized dataset has extremely different distribution from others. Compared to other models in Table 1, we assume our model rely more on the normalization layers (with proper BN statistics) to achieve better performance on ImageNet-Stylized because model parameters have only been trained with augmented features for 20 epochs, while for other methods, for example AugMix, the model is trained with augmented data for 180 epochs. We assume good normalizations can help ease the distributional difference between datasets and this benefit can be more obvious on Stylized ImageNet with our model, where the data is extremely far away from the standard data distribution, while our model are relatively close to a standard trained model.      \nIn addition, we want to mention that our segmentation results in Table 5 and Table 6 are obtained without auto augmentation in the input space, and only use the *standard BN* during inference. It shows that the *standard BN* can generalize well to various domain shifts that we consider practical while not as extreme as Stylized ImageNet.        \nAs for the comparison to AdvProp, we expect our model to achieve better results if we fine-tune the EfficientNet model for a number of epochs that is proportional to its training scheme, which trains the model from scratch for over 300 epochs. (This experiment is ongoing.)  In other words, the model we use for comparing to AdvProp in Table 3, is only fine-tuned for 20 epochs, while an AdvProp model is trained for over 300 epochs.         "}, "signatures": ["ICLR.cc/2021/Conference/Paper2087/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2087/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Prepare for the Worst: Generalizing across Domain Shifts with Adversarial Batch Normalization", "authorids": ["~Manli_Shu1", "~Zuxuan_Wu1", "~Micah_Goldblum1", "~Tom_Goldstein1"], "authors": ["Manli Shu", "Zuxuan Wu", "Micah Goldblum", "Tom Goldstein"], "keywords": ["adversarial training", "distributional shifts"], "abstract": "Adversarial training is the industry standard for producing models that are robust to small adversarial perturbations.  However, machine learning practitioners need models that are robust to other kinds of changes that occur naturally, such as changes in the style or illumination of input images. Such changes in input distribution have been effectively modeled as shifts in the mean and variance of deep image features.   We adapt adversarial training by adversarially perturbing these feature statistics, rather than image pixels, to produce models that are robust to distributional shifts. We also visualize images from adversarially crafted distributions. Our method, Adversarial Batch Normalization (AdvBN), significantly improves the performance of ResNet-50 on ImageNet-C (+8.1%), Stylized-ImageNet (+6.7%), and ImageNet-Instagram (+3.9%) over standard training practices.  In addition, we demonstrate that AdvBN can also improve generalization on semantic segmentation.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "shu|prepare_for_the_worst_generalizing_across_domain_shifts_with_adversarial_batch_normalization", "one-sentence_summary": "This work proposes a feature space adversarial training method based on Batchnorm statistics, to attain generalization to distributional shifted data.", "pdf": "/pdf/b8131b0f600444e3e9c4a2df7b2c00abdc97c641.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=HD0dWMzp2", "_bibtex": "@misc{\nshu2021prepare,\ntitle={Prepare for the Worst: Generalizing across Domain Shifts with Adversarial Batch Normalization},\nauthor={Manli Shu and Zuxuan Wu and Micah Goldblum and Tom Goldstein},\nyear={2021},\nurl={https://openreview.net/forum?id=LFjnKhTNNQD}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "LFjnKhTNNQD", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper2087/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper2087/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper2087/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper2087/Authors|ICLR.cc/2021/Conference/Paper2087/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2087/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923852426, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper2087/-/Official_Comment"}}}, {"id": "DcgmcNqKxLp", "original": null, "number": 12, "cdate": 1606252846770, "ddate": null, "tcdate": 1606252846770, "tmdate": 1606252927449, "tddate": null, "forum": "LFjnKhTNNQD", "replyto": "APHnce683l4", "invitation": "ICLR.cc/2021/Conference/Paper2087/-/Official_Comment", "content": {"title": "Comparison with AdvProp is helpful, but the concern with the auxiliary vs standard BN remains", "comment": "Thanks for the detailed answer, extra experiments, and improving the typos/mistakes in the text.\n\n1. *\"To address this concern, we add another comparison with the AdvProp method, which is based on Lp PGD adversarial training but their models are tuned for better generalization cross domains.\"*\n\nThanks for adding this comparison. As far as I understand, AdvProp also used AutoAugment during training, so this comparison sounds fair. Although it's unclear which method performs better since the improvement on Imagenet-Instagram and ImageNet-Stylized over AdvProp seem to be relatively small (+0.7% and +1.1%), while on ImageNet-C the performance is worse (-2.5%).\n\n-----\n\n2. *\"It is true that different BN statistics work well with different domain shifts, but we find that \"clean\" BNs are more potent in practice, given that we use it during inference for all domains in both classification and segmentation, except for the Stylized-ImageNet dataset.\"*\n\nI still don't see how this approach can be meaningful. I see that *\"we choose to use one certain set of Batch normalizations before doing inference\"*, but then it's precisely the problem -- you assume you know the domain shift and you use a different model for it. But how do you know which domain shift are you going to encounter on your next image? **I would be very curious to know the performance of AdvBN on ImageNet-Stylized using the standard BN instead of the auxiliary one.** This part seems critical to me.\n\n-----\n\n3. Thanks for clarifying this. It's not a major concern for me, but just something that conceptually complicates the method.\n\n----\n\n4. Good to see that, I think providing a full ablation study for gamma would definitely be helpful.\n\n----\n\nSo far I keep my current score 5/10 but I would be willing to increase it if the authors provide favorable results of AdvBN on ImageNet-Stylized using the *standard BN* instead of the auxiliary one (I know that there is not so much time left until the end of the rebuttal, but the authors' response came quite late; and hopefully this evaluation can be done relatively fast as it doesn't require retraining a model, just plugging in a different set of BN parameters). Moreover, the comparison should include both ResNet-50 (to compare to other entries in Table 1) and EfficientNet-B0 (to compare to AdvProp with the same network). \n\nFor me, the main problem currently is that because of the auxiliary BN issue, it's still unclear whether the proposed method is more effective than simple Linf adversarial training used in AdvProp.\n"}, "signatures": ["ICLR.cc/2021/Conference/Paper2087/AnonReviewer5"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2087/AnonReviewer5"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Prepare for the Worst: Generalizing across Domain Shifts with Adversarial Batch Normalization", "authorids": ["~Manli_Shu1", "~Zuxuan_Wu1", "~Micah_Goldblum1", "~Tom_Goldstein1"], "authors": ["Manli Shu", "Zuxuan Wu", "Micah Goldblum", "Tom Goldstein"], "keywords": ["adversarial training", "distributional shifts"], "abstract": "Adversarial training is the industry standard for producing models that are robust to small adversarial perturbations.  However, machine learning practitioners need models that are robust to other kinds of changes that occur naturally, such as changes in the style or illumination of input images. Such changes in input distribution have been effectively modeled as shifts in the mean and variance of deep image features.   We adapt adversarial training by adversarially perturbing these feature statistics, rather than image pixels, to produce models that are robust to distributional shifts. We also visualize images from adversarially crafted distributions. Our method, Adversarial Batch Normalization (AdvBN), significantly improves the performance of ResNet-50 on ImageNet-C (+8.1%), Stylized-ImageNet (+6.7%), and ImageNet-Instagram (+3.9%) over standard training practices.  In addition, we demonstrate that AdvBN can also improve generalization on semantic segmentation.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "shu|prepare_for_the_worst_generalizing_across_domain_shifts_with_adversarial_batch_normalization", "one-sentence_summary": "This work proposes a feature space adversarial training method based on Batchnorm statistics, to attain generalization to distributional shifted data.", "pdf": "/pdf/b8131b0f600444e3e9c4a2df7b2c00abdc97c641.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=HD0dWMzp2", "_bibtex": "@misc{\nshu2021prepare,\ntitle={Prepare for the Worst: Generalizing across Domain Shifts with Adversarial Batch Normalization},\nauthor={Manli Shu and Zuxuan Wu and Micah Goldblum and Tom Goldstein},\nyear={2021},\nurl={https://openreview.net/forum?id=LFjnKhTNNQD}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "LFjnKhTNNQD", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper2087/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper2087/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper2087/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper2087/Authors|ICLR.cc/2021/Conference/Paper2087/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2087/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923852426, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper2087/-/Official_Comment"}}}, {"id": "WYAd8AIfao", "original": null, "number": 11, "cdate": 1606172508411, "ddate": null, "tcdate": 1606172508411, "tmdate": 1606172508411, "tddate": null, "forum": "LFjnKhTNNQD", "replyto": "WgtjiBvLRfi", "invitation": "ICLR.cc/2021/Conference/Paper2087/-/Official_Comment", "content": {"title": "Thank you for your feedback and recommendations.", "comment": "We appreciate your constructive recommendations and we provide additional experimental results to support our method.     \nAs for your major concerns pointed out as the weakness of our work, our method indeed shows a larger margin on stylized images, but we wouldn't say a method is not effective because it has very close performance to state-of-the-art methods like AugMix on some task. We add detailed test results of AdvBN on the 15 categories of ImageNet-C corruptions in the appendix, and show that it provides improvements for 14 of the corruption types.      \n\nAs for the related work you refer to, we agree that it is a more principled approach. We try to compare to *Volpi, et al, Generalizing to Unseen Domains via Adversarial Data Augmentation* on their semantic segmentation results on SYNTHIA, because we want to see whether AdvBN can generalize well across different weather and lightning conditions. However, with limited implementation details given in that paper (e.g., how they split the training and testing data; what is the  learning rate, etc.) and no official segmentation code available, we are not able to reproduce the baseline model they use. With the same ResNet-50 + FCN architecture, our baseline model performs better than theirs by around 10% using the same training framework we use for Cityscapes. We understand that the comparison would thus be unfair, and we provide this result simply as an additional experiment to show the generalization ability of our method. We are working on comparing AdvBN with this method on classification tasks, and look forward to including it in the next version of this work.     \n"}, "signatures": ["ICLR.cc/2021/Conference/Paper2087/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2087/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Prepare for the Worst: Generalizing across Domain Shifts with Adversarial Batch Normalization", "authorids": ["~Manli_Shu1", "~Zuxuan_Wu1", "~Micah_Goldblum1", "~Tom_Goldstein1"], "authors": ["Manli Shu", "Zuxuan Wu", "Micah Goldblum", "Tom Goldstein"], "keywords": ["adversarial training", "distributional shifts"], "abstract": "Adversarial training is the industry standard for producing models that are robust to small adversarial perturbations.  However, machine learning practitioners need models that are robust to other kinds of changes that occur naturally, such as changes in the style or illumination of input images. Such changes in input distribution have been effectively modeled as shifts in the mean and variance of deep image features.   We adapt adversarial training by adversarially perturbing these feature statistics, rather than image pixels, to produce models that are robust to distributional shifts. We also visualize images from adversarially crafted distributions. Our method, Adversarial Batch Normalization (AdvBN), significantly improves the performance of ResNet-50 on ImageNet-C (+8.1%), Stylized-ImageNet (+6.7%), and ImageNet-Instagram (+3.9%) over standard training practices.  In addition, we demonstrate that AdvBN can also improve generalization on semantic segmentation.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "shu|prepare_for_the_worst_generalizing_across_domain_shifts_with_adversarial_batch_normalization", "one-sentence_summary": "This work proposes a feature space adversarial training method based on Batchnorm statistics, to attain generalization to distributional shifted data.", "pdf": "/pdf/b8131b0f600444e3e9c4a2df7b2c00abdc97c641.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=HD0dWMzp2", "_bibtex": "@misc{\nshu2021prepare,\ntitle={Prepare for the Worst: Generalizing across Domain Shifts with Adversarial Batch Normalization},\nauthor={Manli Shu and Zuxuan Wu and Micah Goldblum and Tom Goldstein},\nyear={2021},\nurl={https://openreview.net/forum?id=LFjnKhTNNQD}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "LFjnKhTNNQD", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper2087/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper2087/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper2087/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper2087/Authors|ICLR.cc/2021/Conference/Paper2087/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2087/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923852426, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper2087/-/Official_Comment"}}}, {"id": "tc_i8p11ZVY", "original": null, "number": 10, "cdate": 1606172247752, "ddate": null, "tcdate": 1606172247752, "tmdate": 1606172247752, "tddate": null, "forum": "LFjnKhTNNQD", "replyto": "V1VXCJEVdLR", "invitation": "ICLR.cc/2021/Conference/Paper2087/-/Official_Comment", "content": {"title": "Thank you for your feedback and suggestions.", "comment": "First we appreciate your careful reading, and we have fixed the typos in the updated version.     \nAs for your concerns:     \n1. *\"Does it mean ABN in Table 1 is with AutoAugment during the finetuning?\"*:     \nYes, we use a fixed set of augmentation operations that are found by the auto augmentation method. We agree that the total performance gain we show comes from both the image space data augmentation and AdvBN. We chose to present our results this way because we want to take advantage of another merit of our method, that it is orthogonal to image space data augmentation techniques, and that we can further improve these methods like what we are doing with auto augmentation. To address your possible further concern, we temporarily provide a plain AdvBN result (without Auto Augment) with the same hyperparameter settings we use for Auto Augmentation + AdvBN in appendix E, as we currently don\u2019t have the time and resource to do a thorough search for hyperparameter of the plain AdvBN.     \n2. *\"It is not clear whether ABN applies in conjunction with AugMix to further lower the corruption error. The current corruption error is close to AugMix.\"*:     \nThank you for the suggestion. We think combining AugMix and AdvBN is worth exploring. The fact that AdvBN can further improve auto augmentation gives us confidence that AdvBN can also work well with AugMix.      \n3. *\"Experiments only use one model, ResNet-50, which is insufficient. \"*:    \nWe now add two other models fine-tuned with AdvBN: DenseNet-121 and EfficientNet-B0, and prove that AdvBN can also improve the performance of these models. The results may be further improved, given that we don\u2019t have time to do hyperparameter tuning for new architectures.      \n4. *\"It is not clear whether the optimal layer changes if the network architecture changes.\"*:     \nWe explored different layers with EfficientNet-B0, and found the optimal layer of this architecture has one thing in common with ResNet-50, that they all output features with resolution (H/4 x W/4), where H and W are the height and width of the input image. However, this is not conclusive yet. We will include additional architectures and ablations in our final version.     \n5. *\"The layer ablation study does not explore the first network block and input.\"*:    \nWe regard our method as a \"feature space\" adversarial training method. Input layer is not within our consideration.  Note that our method is motivated by an observation that the mean and variance of features maps encode style information, in which the feature extractor needs to have the ability to process the input to a certain level of abstraction. The first network block in ResNet-50, however,  is a single convolution layer, for which we assume it cannot work well as a feature extractor for AdvBN.      \n6. *\"The domain generalization setting from Cityscapes to GTA5 is unconvincing\"*:      \nWe agree that the opposite direction may be more useful in many applications.  However, our method works best for eliminating the reliance of models on fine textural features and color.  Thus, it makes sense to use this method trained on Cityscapes and evaluated on GTA5, where high frequency textural information has been removed. We have additionally added results of semantic segmentation on another dataset more suitable for our case, the SYNTHIA datasets, where we train models on one specific weather condition, and test on others. We demonstrate that AdvBN can constantly improve mIOU in this case by including detailed results in our updated paper.     \n7. *\"For a new task, there are usually no well-known pre-trained models. This raises another question: how does the method perform to train a model from scratch?\"*:    \nWe put forward our method as a simple and universal \u201cadditional step\u201d to strengthen CNN models. Considering that AdvBN introduces noise to intermediate features, we think training with AdvBN can benefit from a relatively stable pre-trained model rather than training from scratch. Due to the limitation of time and resources, we have not obtained a converged model trained with AdvBN from scratch.  A practitioner can always approach a new task by pre-training in the standard fashion and then fine-tuning using AdvBN.\n\n"}, "signatures": ["ICLR.cc/2021/Conference/Paper2087/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2087/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Prepare for the Worst: Generalizing across Domain Shifts with Adversarial Batch Normalization", "authorids": ["~Manli_Shu1", "~Zuxuan_Wu1", "~Micah_Goldblum1", "~Tom_Goldstein1"], "authors": ["Manli Shu", "Zuxuan Wu", "Micah Goldblum", "Tom Goldstein"], "keywords": ["adversarial training", "distributional shifts"], "abstract": "Adversarial training is the industry standard for producing models that are robust to small adversarial perturbations.  However, machine learning practitioners need models that are robust to other kinds of changes that occur naturally, such as changes in the style or illumination of input images. Such changes in input distribution have been effectively modeled as shifts in the mean and variance of deep image features.   We adapt adversarial training by adversarially perturbing these feature statistics, rather than image pixels, to produce models that are robust to distributional shifts. We also visualize images from adversarially crafted distributions. Our method, Adversarial Batch Normalization (AdvBN), significantly improves the performance of ResNet-50 on ImageNet-C (+8.1%), Stylized-ImageNet (+6.7%), and ImageNet-Instagram (+3.9%) over standard training practices.  In addition, we demonstrate that AdvBN can also improve generalization on semantic segmentation.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "shu|prepare_for_the_worst_generalizing_across_domain_shifts_with_adversarial_batch_normalization", "one-sentence_summary": "This work proposes a feature space adversarial training method based on Batchnorm statistics, to attain generalization to distributional shifted data.", "pdf": "/pdf/b8131b0f600444e3e9c4a2df7b2c00abdc97c641.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=HD0dWMzp2", "_bibtex": "@misc{\nshu2021prepare,\ntitle={Prepare for the Worst: Generalizing across Domain Shifts with Adversarial Batch Normalization},\nauthor={Manli Shu and Zuxuan Wu and Micah Goldblum and Tom Goldstein},\nyear={2021},\nurl={https://openreview.net/forum?id=LFjnKhTNNQD}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "LFjnKhTNNQD", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper2087/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper2087/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper2087/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper2087/Authors|ICLR.cc/2021/Conference/Paper2087/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2087/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923852426, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper2087/-/Official_Comment"}}}, {"id": "_LBuh7YBF7Y", "original": null, "number": 9, "cdate": 1606171765136, "ddate": null, "tcdate": 1606171765136, "tmdate": 1606171765136, "tddate": null, "forum": "LFjnKhTNNQD", "replyto": "M5WNIwUqrn", "invitation": "ICLR.cc/2021/Conference/Paper2087/-/Official_Comment", "content": {"title": "Thank you for your interest in our work.", "comment": "Thank you for the suggestion, we agree and will include more introspection on the results in the future version of this work.    \nHere are our response to your questions:    \n1. *\"Why is AdvBN not improving on AugMix for imagenet-c but does for the other datasets does this indicate some drawbacks for the method?\"*:    \nThe result of AdvBN we show is independent of AugMix. We have not explored using AdvBN to improve on AugMix, but we think it is worth trying in the future. As for our results, we find AdvBN achieves comparable results to AugMix on ImageNet-C and performs better on Instagram-ImageNet and Stylized-ImageNet. We think it is possible for a method like AdvBN that is designed for \u201cunseen\u201d domain generalization to not outperform some other methods on a specific dataset. In addition, we add a table in the appendix to show a detailed comparison to AugMix in terms of each severity degree on each corruption type of ImageNet-C.     \n2. *\"Why does performance appear to get better in the ablation study on \\epsilon but then get worse after a certain threshold?\"*:    \nWe assume the magnitude of perturbation, which is controlled by \\epsilon, can be \u201ctoo small\u201d or \u201ctoo large\u201d.  Too small perturbations may cause AdvBN to produce insufficient robustness, as the perturbed data distribution is nearly identical to the original.  Meanwhile, perturbations that are too large can result in features so corrupted that they are far beyond what is experienced at test time.  Like in standard adversarial training, there appears to be some compromise between robustness and accuracy.  A model trained with very large epsilon can be robust against extreme corruptions, but this robustness comes at the cost of lower accuracy on weaker corruptions and clean data.     "}, "signatures": ["ICLR.cc/2021/Conference/Paper2087/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2087/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Prepare for the Worst: Generalizing across Domain Shifts with Adversarial Batch Normalization", "authorids": ["~Manli_Shu1", "~Zuxuan_Wu1", "~Micah_Goldblum1", "~Tom_Goldstein1"], "authors": ["Manli Shu", "Zuxuan Wu", "Micah Goldblum", "Tom Goldstein"], "keywords": ["adversarial training", "distributional shifts"], "abstract": "Adversarial training is the industry standard for producing models that are robust to small adversarial perturbations.  However, machine learning practitioners need models that are robust to other kinds of changes that occur naturally, such as changes in the style or illumination of input images. Such changes in input distribution have been effectively modeled as shifts in the mean and variance of deep image features.   We adapt adversarial training by adversarially perturbing these feature statistics, rather than image pixels, to produce models that are robust to distributional shifts. We also visualize images from adversarially crafted distributions. Our method, Adversarial Batch Normalization (AdvBN), significantly improves the performance of ResNet-50 on ImageNet-C (+8.1%), Stylized-ImageNet (+6.7%), and ImageNet-Instagram (+3.9%) over standard training practices.  In addition, we demonstrate that AdvBN can also improve generalization on semantic segmentation.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "shu|prepare_for_the_worst_generalizing_across_domain_shifts_with_adversarial_batch_normalization", "one-sentence_summary": "This work proposes a feature space adversarial training method based on Batchnorm statistics, to attain generalization to distributional shifted data.", "pdf": "/pdf/b8131b0f600444e3e9c4a2df7b2c00abdc97c641.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=HD0dWMzp2", "_bibtex": "@misc{\nshu2021prepare,\ntitle={Prepare for the Worst: Generalizing across Domain Shifts with Adversarial Batch Normalization},\nauthor={Manli Shu and Zuxuan Wu and Micah Goldblum and Tom Goldstein},\nyear={2021},\nurl={https://openreview.net/forum?id=LFjnKhTNNQD}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "LFjnKhTNNQD", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper2087/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper2087/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper2087/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper2087/Authors|ICLR.cc/2021/Conference/Paper2087/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2087/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923852426, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper2087/-/Official_Comment"}}}, {"id": "gYtLf08NHBQ", "original": null, "number": 8, "cdate": 1606171273083, "ddate": null, "tcdate": 1606171273083, "tmdate": 1606171273083, "tddate": null, "forum": "LFjnKhTNNQD", "replyto": "aqe8CZjV0Gd", "invitation": "ICLR.cc/2021/Conference/Paper2087/-/Official_Comment", "content": {"title": "Thank you for the feedback.  We hope to clarify a few points.", "comment": "1. *\"It is unclear to me why the quiet related AdvProp model is not evaluated here.\"*:    \nThe goal of AdvBN is very different from AdvProp.  The latter which uses adversarial examples as a data augmentation strategy to improve natural training. Instead, our approach aims to generalize to unseen domains during testing. Also, our proposed AdvBN does adversarial perturbation to the style/batch-norm values, which AdvProp does adversarial perturbations to image pixels.  Furthermore, in Table 1, all methods we compared to have released their official ResNet-50 models, but this is not the case with AdvProp.     \nTo address your concern, we add a separate table (Table 3 in the updated paper) solely to compare the results of our method with AdvProp on EfficientNet-B0 (Because it takes the least time to train, among all EfficientNet variants). We found that AdvBN outperforms AdvProp on ImageNet-Instagram and Stylized-ImageNet.    \n2. *\"Same with the Noisy Student L2 model which doesn't have any sort of adversarially perturbation and performs much better on ImageNet-C than the best number reported here.\"*:    \nWe don\u2019t think it is fair to compare the Noisy Student method with any of the methods in Table 1. All methods in Table 1 only use the original ImageNet images for training, which has approximately 1 million images. However, training a Noisy Student model requires access to 300 million additional images from an unpublished dataset.    \nAlso, we consider the Noisy Student method as a very different approach to solve the generalization problem, which is beyond the scope of data augmentation or adversarial training.     \nAdditionally, like the AdvProp method, the Noisy Student method has not yet provided official ResNet-50 models for a general comparison with other methods.     \n3. *\"it seems inexcusable to only have 5 arbitrary comparison points, especially when there are models with significantly better accuracy.\"*:     \nWe find that the models you refer to as significantly better are actually obtained on significantly stronger baseline models. For example, a standard trained EfficientNet-B1 model (one of the baseline models of both methods you mentioned) already has better performance on ImageNet-C than that of \u201cResNet-50 + AugMix\u201d.     \nIn addition, we wouldn't say our comparison points are arbitrary: we choose the most relevant methods to compare with, and we explain their relevance to our methods when introducing them in section 5.2.  We do this comparison to show that our improvement over baseline is non-trivial.     \n4. *\"what a resnet50 simply fine-tuned on those distributions look like\"*:     \nIn this paper, we are interested in improving universal generalization ability to \"unseen\" domains without access to their label information, which addresses the more realistic case where domain information is unknown at train time. Fine-tuning on a specific test distribution will undoubtedly achieve better results than any of the other methods considered in this paper - this is the equivalent of  \u201ctraining on the test set\u201d for domain generalization.    \nStill, we see how one might want to know what is achievable by training on these sets. Our test result shows that a Stylized-ImageNet fine-tuned ResNet-50 can achieve 57.0% top-1 accuracy on the corresponding validation set. For ImageNet-Instagram, we have the result directly from *Wu, et al, Recognizing Instagram Filtered Images with Feature De-stylization*, that a ImageNet-Instagram fine-tuned ResNet-50 can have 74.5% top-1 accuracy on the corresponding validation set. For ImageNet-C, the ImageNet-testbed proposed in *Taori, et al, Measuring Robustness to Natural Distribution Shifts in Image Classification*, summarizes the performances of a broad range of models on a broad range of datasets, in which we can find how a ResNet-50 trained with a single corruption type from ImageNet-C performs on that corruption type. For example, a ResNet-50 trained with motion blur corruption can achieve Corrupted Error of 47.2 on the single motion blur corruption test data.     \n5. *\"Next on the distribution shift side, I'd also like to see more than just 3 distribution shifts.\"*:    \nWe have presented our results on semantic segmentation in the original submission. Additionally, we now add results of semantic segmentation on a new dataset, SYNTHIA.    \n\n"}, "signatures": ["ICLR.cc/2021/Conference/Paper2087/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2087/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Prepare for the Worst: Generalizing across Domain Shifts with Adversarial Batch Normalization", "authorids": ["~Manli_Shu1", "~Zuxuan_Wu1", "~Micah_Goldblum1", "~Tom_Goldstein1"], "authors": ["Manli Shu", "Zuxuan Wu", "Micah Goldblum", "Tom Goldstein"], "keywords": ["adversarial training", "distributional shifts"], "abstract": "Adversarial training is the industry standard for producing models that are robust to small adversarial perturbations.  However, machine learning practitioners need models that are robust to other kinds of changes that occur naturally, such as changes in the style or illumination of input images. Such changes in input distribution have been effectively modeled as shifts in the mean and variance of deep image features.   We adapt adversarial training by adversarially perturbing these feature statistics, rather than image pixels, to produce models that are robust to distributional shifts. We also visualize images from adversarially crafted distributions. Our method, Adversarial Batch Normalization (AdvBN), significantly improves the performance of ResNet-50 on ImageNet-C (+8.1%), Stylized-ImageNet (+6.7%), and ImageNet-Instagram (+3.9%) over standard training practices.  In addition, we demonstrate that AdvBN can also improve generalization on semantic segmentation.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "shu|prepare_for_the_worst_generalizing_across_domain_shifts_with_adversarial_batch_normalization", "one-sentence_summary": "This work proposes a feature space adversarial training method based on Batchnorm statistics, to attain generalization to distributional shifted data.", "pdf": "/pdf/b8131b0f600444e3e9c4a2df7b2c00abdc97c641.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=HD0dWMzp2", "_bibtex": "@misc{\nshu2021prepare,\ntitle={Prepare for the Worst: Generalizing across Domain Shifts with Adversarial Batch Normalization},\nauthor={Manli Shu and Zuxuan Wu and Micah Goldblum and Tom Goldstein},\nyear={2021},\nurl={https://openreview.net/forum?id=LFjnKhTNNQD}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "LFjnKhTNNQD", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper2087/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper2087/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper2087/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper2087/Authors|ICLR.cc/2021/Conference/Paper2087/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2087/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923852426, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper2087/-/Official_Comment"}}}, {"id": "APHnce683l4", "original": null, "number": 7, "cdate": 1606170852394, "ddate": null, "tcdate": 1606170852394, "tmdate": 1606170852394, "tddate": null, "forum": "LFjnKhTNNQD", "replyto": "NbWVm8zxbfD", "invitation": "ICLR.cc/2021/Conference/Paper2087/-/Official_Comment", "content": {"title": "We appreciate that you recognize the effectiveness and simplicity of our proposed method. ", "comment": "Thank you for your feedback and suggestions.        \nAs for your major concern, we agree that the total performance gain we show comes from both the image space data augmentation and AdvBN. We chose to present our results this way because we want to take advantage of another merit of our method, that it is orthogonal to image space data augmentation techniques, and that we can apply it on top of a range of methods including auto augmentation. To address your concern, we provide a plain AdvBN result with the same hyperparameter settings we use for Auto Augmentation + AdvBN in Appendix E, as we currently don\u2019t have the time and resources to do a thorough search for hyperparameter for the plain AdvBN. We look forward to including properly reported results in the updated version of this work.     \nAs for you other concerns: \n1. *\"Comparison with Lp PGD\"* :    \nThe fact that the Lp PGD method is not proposed to solve the domain shifts problem makes our comparison with PGD seem incomplete. We include it this way because we are trying to use official off-the-shelf models. To address this concern, we add another comparison with the AdvProp method, which is based on Lp PGD adversarial training but their models are tuned for better generalization cross domains.      \n2. *\"Which of the 2 models to apply at test time\"*:    \nInstead of 2 separate models, models fine-tuned with AdvBN contain two sets of batch normalization layers inside this single model: \u201cclean\u201d BNs that tracks and stores statistics of \u201cclean\u201d feature, and \u201cadversarial\u201d BNs that tracks and stores statistics of features perturbed by AdvBN.  We choose to use one certain set of Batch normalizations before doing inference, which in the implementation level, is controlled by a parameter of the forward function. It is true that different BN statistics work well with different domain shifts, but we find that \"clean\" BNs are more potent in practice, given that we use it during inference for all domains in both classification and segmentation, except for the Stylized-ImageNet dataset.     \n3. *\"the perturbation set that you aim to be robust against depends on the current batch of images\"*:       \nWe agree that this dependence applies in the visualization scenario, where we only go through the dataset once. During training, however, samples are randomly shuffled for each epoch and models will be trained for many epochs, so the dependence on batch grouping is lessened. We do find your suggestion helpful, and we are interested in working with batch-independent normalization schemes.      \n4. *\"equal weights for both terms may be suboptimal.\"*:    \nWe agree. We have done limited search for the weight settings and temporarily included it in the appendix E, as we need more thorough searches (and compute time) to reach conclusions.  Computations are ongoing.    \n5. *\"The ablation is inconclusive\"*:\nIn the ablation study, we are trying to show how single factors affect the performance respectively, so we keep the epsilon to be the same when showing the results. We have tried other epsilon values for the case of conv3_4 and conv4_6, and we observed that the differences are relatively small and all results for these layers are not as good as conv2_3.    \n\n"}, "signatures": ["ICLR.cc/2021/Conference/Paper2087/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2087/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Prepare for the Worst: Generalizing across Domain Shifts with Adversarial Batch Normalization", "authorids": ["~Manli_Shu1", "~Zuxuan_Wu1", "~Micah_Goldblum1", "~Tom_Goldstein1"], "authors": ["Manli Shu", "Zuxuan Wu", "Micah Goldblum", "Tom Goldstein"], "keywords": ["adversarial training", "distributional shifts"], "abstract": "Adversarial training is the industry standard for producing models that are robust to small adversarial perturbations.  However, machine learning practitioners need models that are robust to other kinds of changes that occur naturally, such as changes in the style or illumination of input images. Such changes in input distribution have been effectively modeled as shifts in the mean and variance of deep image features.   We adapt adversarial training by adversarially perturbing these feature statistics, rather than image pixels, to produce models that are robust to distributional shifts. We also visualize images from adversarially crafted distributions. Our method, Adversarial Batch Normalization (AdvBN), significantly improves the performance of ResNet-50 on ImageNet-C (+8.1%), Stylized-ImageNet (+6.7%), and ImageNet-Instagram (+3.9%) over standard training practices.  In addition, we demonstrate that AdvBN can also improve generalization on semantic segmentation.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "shu|prepare_for_the_worst_generalizing_across_domain_shifts_with_adversarial_batch_normalization", "one-sentence_summary": "This work proposes a feature space adversarial training method based on Batchnorm statistics, to attain generalization to distributional shifted data.", "pdf": "/pdf/b8131b0f600444e3e9c4a2df7b2c00abdc97c641.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=HD0dWMzp2", "_bibtex": "@misc{\nshu2021prepare,\ntitle={Prepare for the Worst: Generalizing across Domain Shifts with Adversarial Batch Normalization},\nauthor={Manli Shu and Zuxuan Wu and Micah Goldblum and Tom Goldstein},\nyear={2021},\nurl={https://openreview.net/forum?id=LFjnKhTNNQD}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "LFjnKhTNNQD", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper2087/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper2087/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper2087/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper2087/Authors|ICLR.cc/2021/Conference/Paper2087/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2087/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923852426, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper2087/-/Official_Comment"}}}, {"id": "IQGat5RcxZA", "original": null, "number": 6, "cdate": 1606170343149, "ddate": null, "tcdate": 1606170343149, "tmdate": 1606170343149, "tddate": null, "forum": "LFjnKhTNNQD", "replyto": "LFjnKhTNNQD", "invitation": "ICLR.cc/2021/Conference/Paper2087/-/Official_Comment", "content": {"title": "Paper Revision: Added ImageNet results on more network architectures; added semantic segmentation result on new dataset. ", "comment": "Firstly, we want to thank all reviewers for providing feedback and constructive suggestions for improving the experiment section. We\u2019ve updated our paper by providing more experimental results:\n* Applied AdvBN to DenseNet-121 and EfficientNet-B0 for ImageNet classification. \n* Evaluated AdvBN on traffic scene semantic segmentation across different weather/illumination/season conditions on the Synthia dataset.\n* Compared with AdvProp on EfficientNet-B0. \n* Provided detailed performance on ImageNet-C in Appendix D by including corrupted error on each severity degree of each corruption type. \n\nNote that our results for DenseNet and EfficientNet may be updated later given more time for tuning hyperparameters. We also look forward to including more architectures.     \nSecond, we thank the reviewers for carefully reading our work, pointing out typos, and presenting possible ways to improve notation. We have changed notation in Eq(4) by adding the maximization, and we fixed the typo in the condition of the outer loop of the algorithm, as well as typos in Section 4.     \nAdditionally, in order to meet the page limits, we move the ablation study on \u201cadditive noise\u201d to the appendix. "}, "signatures": ["ICLR.cc/2021/Conference/Paper2087/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2087/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Prepare for the Worst: Generalizing across Domain Shifts with Adversarial Batch Normalization", "authorids": ["~Manli_Shu1", "~Zuxuan_Wu1", "~Micah_Goldblum1", "~Tom_Goldstein1"], "authors": ["Manli Shu", "Zuxuan Wu", "Micah Goldblum", "Tom Goldstein"], "keywords": ["adversarial training", "distributional shifts"], "abstract": "Adversarial training is the industry standard for producing models that are robust to small adversarial perturbations.  However, machine learning practitioners need models that are robust to other kinds of changes that occur naturally, such as changes in the style or illumination of input images. Such changes in input distribution have been effectively modeled as shifts in the mean and variance of deep image features.   We adapt adversarial training by adversarially perturbing these feature statistics, rather than image pixels, to produce models that are robust to distributional shifts. We also visualize images from adversarially crafted distributions. Our method, Adversarial Batch Normalization (AdvBN), significantly improves the performance of ResNet-50 on ImageNet-C (+8.1%), Stylized-ImageNet (+6.7%), and ImageNet-Instagram (+3.9%) over standard training practices.  In addition, we demonstrate that AdvBN can also improve generalization on semantic segmentation.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "shu|prepare_for_the_worst_generalizing_across_domain_shifts_with_adversarial_batch_normalization", "one-sentence_summary": "This work proposes a feature space adversarial training method based on Batchnorm statistics, to attain generalization to distributional shifted data.", "pdf": "/pdf/b8131b0f600444e3e9c4a2df7b2c00abdc97c641.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=HD0dWMzp2", "_bibtex": "@misc{\nshu2021prepare,\ntitle={Prepare for the Worst: Generalizing across Domain Shifts with Adversarial Batch Normalization},\nauthor={Manli Shu and Zuxuan Wu and Micah Goldblum and Tom Goldstein},\nyear={2021},\nurl={https://openreview.net/forum?id=LFjnKhTNNQD}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "LFjnKhTNNQD", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper2087/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper2087/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper2087/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper2087/Authors|ICLR.cc/2021/Conference/Paper2087/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2087/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923852426, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper2087/-/Official_Comment"}}}, {"id": "aqe8CZjV0Gd", "original": null, "number": 4, "cdate": 1604198400452, "ddate": null, "tcdate": 1604198400452, "tmdate": 1605024292450, "tddate": null, "forum": "LFjnKhTNNQD", "replyto": "LFjnKhTNNQD", "invitation": "ICLR.cc/2021/Conference/Paper2087/-/Official_Review", "content": {"title": "Choice of distribution shifts seems odd and sparse and performance improvements seem relatively small.", "review": "This paper introduces a method for improving robustness of neural networks to domain shifts by adversarially perturbing the feature statistics. This is a very interesting idea, by playing a middle ground between the worst case of PGD and not doing anything. My main problem about the paper is the evaluation and particularly the lack of evaluation of certain models and certain datasets.  \nLets talk models first. It is unclear to me why the quite related AdvProp model is not evaluated here. Even if they are difficult to train the pre-trained models are available here: https://github.com/rwightman/pytorch-image-models. Same with the Noisy Student L2 model which doesn't have any sort of adversarially perturbation and performs much better on ImageNet-C than the best number reported here. For reference pretrained weights for both model types are available in the above link. With the availability of pretrained models it seems inexcusable to only have 5 arbitrary comparison points, especially when there are models with significantly better accuracy.  \n\nFurthermore, for stylized ImageNet and Instagram I would like to see what a resnet50 simply fine-tuned on those distributions look like. \n\nNext on the distribution shift side, I'd also like to see more than just 3 distribution shifts. There have been two recent papers that do a metastudy of many distribution shifts: https://arxiv.org/abs/2007.08558 and https://arxiv.org/abs/2007.00644. A thorough evaluation on other distribution shifts can give a more complete picture of the advantage of the proposed approach to distribution shift rather than just 3 numbers out of context.\n\nFor these reasons I recommend rejection.\n\n", "rating": "3: Clear rejection", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}, "signatures": ["ICLR.cc/2021/Conference/Paper2087/AnonReviewer4"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2087/AnonReviewer4"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Prepare for the Worst: Generalizing across Domain Shifts with Adversarial Batch Normalization", "authorids": ["~Manli_Shu1", "~Zuxuan_Wu1", "~Micah_Goldblum1", "~Tom_Goldstein1"], "authors": ["Manli Shu", "Zuxuan Wu", "Micah Goldblum", "Tom Goldstein"], "keywords": ["adversarial training", "distributional shifts"], "abstract": "Adversarial training is the industry standard for producing models that are robust to small adversarial perturbations.  However, machine learning practitioners need models that are robust to other kinds of changes that occur naturally, such as changes in the style or illumination of input images. Such changes in input distribution have been effectively modeled as shifts in the mean and variance of deep image features.   We adapt adversarial training by adversarially perturbing these feature statistics, rather than image pixels, to produce models that are robust to distributional shifts. We also visualize images from adversarially crafted distributions. Our method, Adversarial Batch Normalization (AdvBN), significantly improves the performance of ResNet-50 on ImageNet-C (+8.1%), Stylized-ImageNet (+6.7%), and ImageNet-Instagram (+3.9%) over standard training practices.  In addition, we demonstrate that AdvBN can also improve generalization on semantic segmentation.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "shu|prepare_for_the_worst_generalizing_across_domain_shifts_with_adversarial_batch_normalization", "one-sentence_summary": "This work proposes a feature space adversarial training method based on Batchnorm statistics, to attain generalization to distributional shifted data.", "pdf": "/pdf/b8131b0f600444e3e9c4a2df7b2c00abdc97c641.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=HD0dWMzp2", "_bibtex": "@misc{\nshu2021prepare,\ntitle={Prepare for the Worst: Generalizing across Domain Shifts with Adversarial Batch Normalization},\nauthor={Manli Shu and Zuxuan Wu and Micah Goldblum and Tom Goldstein},\nyear={2021},\nurl={https://openreview.net/forum?id=LFjnKhTNNQD}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq . ***Please remember to file the Code-of-Ethics report. Once you submitted the review, a link to the report will be visible in the bottom right corner of your review.***", "required": true, "markdown": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}, "forum": "LFjnKhTNNQD", "replyto": "LFjnKhTNNQD", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"], "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper2087/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1607428800000, "duedate": 1606752000000, "multiReply": false, "readers": ["everyone"], "tcdate": 1602538104365, "tmdate": 1606915779819, "super": "ICLR.cc/2021/Conference/-/Official_Review", "signatures": ["OpenReview.net"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Paper2087/Reviewers", "OpenReview.net/Support"], "id": "ICLR.cc/2021/Conference/Paper2087/-/Official_Review"}}}, {"id": "NbWVm8zxbfD", "original": null, "number": 5, "cdate": 1604745126508, "ddate": null, "tcdate": 1604745126508, "tmdate": 1605024292324, "tddate": null, "forum": "LFjnKhTNNQD", "replyto": "LFjnKhTNNQD", "invitation": "ICLR.cc/2021/Conference/Paper2087/-/Official_Review", "content": {"title": "Interesting idea of using BN for robust optimization, but the experimental part has many flaws", "review": "**Summary:**\nThe paper proposes a new adversarial training procedure that finds worst-case batch normalization (BN) parameters in some Linf-ball around the identity BN parameters. The authors show that this approach combined with AutoAugment significantly improves the accuracy on challenging datasets with domain shifts like ImageNet-C, Stylized Image-Net, and ImageNet-Instagram. Moreover, the authors show improved results on a semantic segmentation task. However, some experimental details presented in the paper require a further clarification.\n\n**Pros:**\n- The approach consistently improves on different datasets that measure robustness towards domain shifts (ImageNet-C, ImageNet Instagram, Stylized ImageNet).\n- The approach doesn\u2019t require any extra data (labeled or unlabeled).\n- The approach also leads to better results for semantic segmentation.\n\n**Cons:**\n- Misleading presentation of the AdvBN results. In particular, in Table 1, \u201cAdvBN\u201d rather refers to \u201cAdvBN + AutoAugment\u201d. But it\u2019s clear that adding AutoAugment to any other competing method would also improve them. Thus, one has to separately report results for \u201cAdvBN (without AutoAugment)\u201d and \u201cAdvBN + AutoAugment\u201d to allow a clearer comparison. Table 2 shows the results of *AutoAugment alone* (and apparently, there is a benefit of combining AutoAugment with AdvBN), but what one really needs to know is the performance of *AdvBN alone*.\n- Comparison to Lp PGD training is incomplete. First of all, it\u2019s not specified which model was used (L2- or Linf-trained and under which epsilon). Second, one should always do a grid search over the Lp-epsilon similarly as you did for the proposed AdvBN method in Table 2, and to report the best model. Otherwise it\u2019s not even clear whether the proposed AdvBN method is better than standard Lp PGD training. Any Lp-robust models from Engstrom et al. (2019) is clearly suboptimal for the tasks considered in this paper since these models have much lower clean accuracy. \n- I couldn\u2019t find a discussion on this, so I assume you used AutoAugment with **all** its data augmentations including those that are present in ImageNet-C. If it\u2019s true, then the comparison to AugMix is unfair as in their method they have removed all overlapping corruptions.\n- This is a very important detail that should\u2019ve been clearly discussed in the main part and not just in the appendix: *\u201cThe results we report in previous sections with regard to ImageNet, ImageNet-C and ImageNet-Instagram are obtained by using BN statistics corresponding to original features. We only use auxiliary BNs, which keep the batch statistics of adversarial features, to test performance on Stylized-ImageNet in Table 1.\u201d*\nAnd then I\u2019m not sure what the results in Table 1 for AdvBN+AutoAugment tell us: that there exist 2 models obtained via AdvBN, and one of them is good on one domain shift, and another is good on another one? But how do you know at test time which of the 2 models to apply? \n- The paper has multiple mistakes in the presentation of the proposed method: \n    - Equation (4): maximization over the BN parameters is missing. It\u2019s written that: *\u201cThis optimization problem contains a maximization problem inside the BNadv layer.\u201d* But I don\u2019t see how it can be true since the maximization should be done in front of the loss. Moreover, the expectation in Eq. (4) should be taken not with respect to pairs $(x, y) \\sim D$, but rather with respect to batches $(x_i, y_i)_{i=1}^B$ to reflect the fact that adversarial BN introduces the dependency of the perturbation set on the sampled batch of points.\n    - Algorithm 1 has multiple mistakes: (1) an additional loop over batches is missing, (2) not clear how $\\delta_\\mu$ and $\\delta_\\sigma$ are initialized, (3) *\u201cMinimize the total loss w.r.t. network parameter\u201d* -- argmin there seems to be inappropriate, I think what was rather meant is doing *one* step of gradient descent wrt $\\theta$, (4) in the same place: there should be a clear distinction regarding when the loss is taken wrt a single data point, and when wrt a batch of points (this is particularly important since AdvBN introduces the dependency of the perturbation set on the batch).\n\n**Suggestions:**\n- First paragraph of Intro: what you refer to as \u201cadversarial training\u201d would be better to call specifically \u201cLp adversarial training\u201d: *\u201cWhile adversarial training makes networks robust to adversarial perturbations, it does not address other forms of brittleness that plague vision systems.\u201d* \nBecause what you propose is also adversarial training but just with respect to a different perturbation set, and I assume you suggest that it does \u201caddress some other forms of brittleness\u201d.\n- *\u201cAdditionally, note that this module acts on a per-batch basis so that features corresponding to an individual image may be perturbed differently depending on the batch the image is in.\u201d*\nFor me it sounds a bit strange that the perturbation set that you aim to be robust against depends on the current batch of images. I wonder if some batch-independent normalization schemes can be applied here with equal success?\n- Equation (4): equal weights for both terms may be suboptimal. Thus, it would be good to include the weighting coefficient between the two terms of the objective in the ablation study.\n- Table 2: the ablation regarding where to put the AdvBN layer is inconclusive since it had to be done with respect to different epsilons. It seems that the selected epsilon was just too high for conv3_4 and conv4_6 since the clean accuracy becomes worse than that of the standard model. The same also applies to \u201cadditive $\\delta$\u201d, it\u2019s not clear what a single number tells us, there should be a grid search over the epsilon.\n\n**Score:**\n5/10. The paper proposes an interesting approach that can help to improve robustness towards domain shifts without requiring any extra data. I would be willing to increase the score if the paper improves its experimental part, in particular by properly reporting the results of AdvBN (see **Cons**) and its baselines.", "rating": "5: Marginally below acceptance threshold", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["ICLR.cc/2021/Conference/Paper2087/AnonReviewer5"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2087/AnonReviewer5"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Prepare for the Worst: Generalizing across Domain Shifts with Adversarial Batch Normalization", "authorids": ["~Manli_Shu1", "~Zuxuan_Wu1", "~Micah_Goldblum1", "~Tom_Goldstein1"], "authors": ["Manli Shu", "Zuxuan Wu", "Micah Goldblum", "Tom Goldstein"], "keywords": ["adversarial training", "distributional shifts"], "abstract": "Adversarial training is the industry standard for producing models that are robust to small adversarial perturbations.  However, machine learning practitioners need models that are robust to other kinds of changes that occur naturally, such as changes in the style or illumination of input images. Such changes in input distribution have been effectively modeled as shifts in the mean and variance of deep image features.   We adapt adversarial training by adversarially perturbing these feature statistics, rather than image pixels, to produce models that are robust to distributional shifts. We also visualize images from adversarially crafted distributions. Our method, Adversarial Batch Normalization (AdvBN), significantly improves the performance of ResNet-50 on ImageNet-C (+8.1%), Stylized-ImageNet (+6.7%), and ImageNet-Instagram (+3.9%) over standard training practices.  In addition, we demonstrate that AdvBN can also improve generalization on semantic segmentation.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "shu|prepare_for_the_worst_generalizing_across_domain_shifts_with_adversarial_batch_normalization", "one-sentence_summary": "This work proposes a feature space adversarial training method based on Batchnorm statistics, to attain generalization to distributional shifted data.", "pdf": "/pdf/b8131b0f600444e3e9c4a2df7b2c00abdc97c641.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=HD0dWMzp2", "_bibtex": "@misc{\nshu2021prepare,\ntitle={Prepare for the Worst: Generalizing across Domain Shifts with Adversarial Batch Normalization},\nauthor={Manli Shu and Zuxuan Wu and Micah Goldblum and Tom Goldstein},\nyear={2021},\nurl={https://openreview.net/forum?id=LFjnKhTNNQD}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq . ***Please remember to file the Code-of-Ethics report. Once you submitted the review, a link to the report will be visible in the bottom right corner of your review.***", "required": true, "markdown": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}, "forum": "LFjnKhTNNQD", "replyto": "LFjnKhTNNQD", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"], "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper2087/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1607428800000, "duedate": 1606752000000, "multiReply": false, "readers": ["everyone"], "tcdate": 1602538104365, "tmdate": 1606915779819, "super": "ICLR.cc/2021/Conference/-/Official_Review", "signatures": ["OpenReview.net"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Paper2087/Reviewers", "OpenReview.net/Support"], "id": "ICLR.cc/2021/Conference/Paper2087/-/Official_Review"}}}], "count": 17}