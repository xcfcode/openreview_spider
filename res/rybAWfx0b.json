{"notes": [{"tddate": null, "ddate": null, "tmdate": 1518730184960, "tcdate": 1509069256563, "number": 221, "cdate": 1518730184946, "id": "rybAWfx0b", "invitation": "ICLR.cc/2018/Conference/-/Blind_Submission", "forum": "rybAWfx0b", "original": "HJxAZGlCW", "signatures": ["ICLR.cc/2018/Conference"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Conference"], "content": {"title": "COLD FUSION: TRAINING SEQ2SEQ MODELS TOGETHER WITH LANGUAGE MODELS", "abstract": "Sequence-to-sequence (Seq2Seq) models with attention have excelled at tasks which involve generating natural language sentences such as machine translation, image captioning and speech recognition. Performance has further been improved by leveraging unlabeled data, often in the form of a language model. In this work, we present the Cold Fusion method, which leverages a pre-trained language model during training, and show its effectiveness on the speech recognition task. We show that Seq2Seq models with Cold Fusion are able to better utilize language information enjoying i) faster convergence and better generalization, and ii) almost complete transfer to a new domain while using less than 10% of the labeled training data.", "pdf": "/pdf/b683baa101e58773bed8d984f95a1fdc7e8c207c.pdf", "TL;DR": "We introduce a novel method to train Seq2Seq models with language models that converge faster, generalize better and can almost completely transfer to a new domain using less than 10% of labeled data.", "paperhash": "sriram|cold_fusion_training_seq2seq_models_together_with_language_models", "_bibtex": "@misc{\nsriram2018cold,\ntitle={{COLD} {FUSION}: {TRAINING} {SEQ}2{SEQ} {MODELS} {TOGETHER} {WITH} {LANGUAGE} {MODELS}},\nauthor={Anuroop Sriram and Heewoo Jun and Sanjeev Satheesh and Adam Coates},\nyear={2018},\nurl={https://openreview.net/forum?id=rybAWfx0b},\n}", "keywords": ["Sequence-to-Sequence Models", "Speech Recognition", "Language Models"], "authors": ["Anuroop Sriram", "Heewoo Jun", "Sanjeev Satheesh", "Adam Coates"], "authorids": ["anuroop.sriram@gmail.com", "junheewoo@baidu.com", "sanjeevsatheesh@baidu.com", "adamcoates@baidu.com"]}, "nonreaders": [], "details": {"replyCount": 4, "writable": false, "overwriting": ["Syor6PRLf"], "revisions": true, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "tmdate": 1506717071958, "id": "ICLR.cc/2018/Conference/-/Blind_Submission", "writers": ["ICLR.cc/2018/Conference"], "signatures": ["ICLR.cc/2018/Conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2018/Conference"], "reply": {"forum": null, "replyto": null, "writers": {"values": ["ICLR.cc/2018/Conference"]}, "signatures": {"description": "How your identity will be displayed with the above content.", "values": ["ICLR.cc/2018/Conference"]}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"authors": {"required": false, "order": 1, "values-regex": ".*", "description": "Comma separated list of author names, as they appear in the paper."}, "authorids": {"required": false, "order": 2, "values-regex": ".*", "description": "Comma separated list of author email addresses, in the same order as above."}}}, "nonreaders": [], "noninvitees": [], "cdate": 1506717071958}}, "tauthor": "ICLR.cc/2018/Conference"}, {"tddate": null, "ddate": null, "original": null, "tmdate": 1517260090849, "tcdate": 1517249648952, "number": 387, "cdate": 1517249648933, "id": "HJKd4ypHz", "invitation": "ICLR.cc/2018/Conference/-/Acceptance_Decision", "forum": "rybAWfx0b", "replyto": "rybAWfx0b", "signatures": ["ICLR.cc/2018/Conference/Program_Chairs"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Conference/Program_Chairs"], "content": {"title": "ICLR 2018 Conference Acceptance Decision", "comment": "Pros\n-- A novel way to incorporate LM into an end-to-end model, with good adaptation results.\n\nCons\n-- Lacks results on public corpora or results are not close to SOTA (e.g., for Librispeech).\n\nGiven the reviews, it is clear that the experimental evaluations can be improved. But the presented approach is novel and interesting. Therefore I am recommending the paper to the workshop track.", "decision": "Invite to Workshop Track"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "COLD FUSION: TRAINING SEQ2SEQ MODELS TOGETHER WITH LANGUAGE MODELS", "abstract": "Sequence-to-sequence (Seq2Seq) models with attention have excelled at tasks which involve generating natural language sentences such as machine translation, image captioning and speech recognition. Performance has further been improved by leveraging unlabeled data, often in the form of a language model. In this work, we present the Cold Fusion method, which leverages a pre-trained language model during training, and show its effectiveness on the speech recognition task. We show that Seq2Seq models with Cold Fusion are able to better utilize language information enjoying i) faster convergence and better generalization, and ii) almost complete transfer to a new domain while using less than 10% of the labeled training data.", "pdf": "/pdf/b683baa101e58773bed8d984f95a1fdc7e8c207c.pdf", "TL;DR": "We introduce a novel method to train Seq2Seq models with language models that converge faster, generalize better and can almost completely transfer to a new domain using less than 10% of labeled data.", "paperhash": "sriram|cold_fusion_training_seq2seq_models_together_with_language_models", "_bibtex": "@misc{\nsriram2018cold,\ntitle={{COLD} {FUSION}: {TRAINING} {SEQ}2{SEQ} {MODELS} {TOGETHER} {WITH} {LANGUAGE} {MODELS}},\nauthor={Anuroop Sriram and Heewoo Jun and Sanjeev Satheesh and Adam Coates},\nyear={2018},\nurl={https://openreview.net/forum?id=rybAWfx0b},\n}", "keywords": ["Sequence-to-Sequence Models", "Speech Recognition", "Language Models"], "authors": ["Anuroop Sriram", "Heewoo Jun", "Sanjeev Satheesh", "Adam Coates"], "authorids": ["anuroop.sriram@gmail.com", "junheewoo@baidu.com", "sanjeevsatheesh@baidu.com", "adamcoates@baidu.com"]}, "tags": [], "invitation": {"id": "ICLR.cc/2018/Conference/-/Acceptance_Decision", "rdate": null, "ddate": null, "expdate": 1541175629000, "duedate": null, "tmdate": 1541177635767, "tddate": null, "super": null, "final": null, "reply": {"forum": null, "replyto": null, "invitation": "ICLR.cc/2018/Conference/-/Blind_Submission", "writers": {"values": ["ICLR.cc/2018/Conference/Program_Chairs"]}, "signatures": {"description": "How your identity will be displayed with the above content.", "values": ["ICLR.cc/2018/Conference/Program_Chairs"]}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["ICLR.cc/2018/Conference/Program_Chairs", "everyone"]}, "content": {"title": {"required": true, "order": 1, "value": "ICLR 2018 Conference Acceptance Decision"}, "comment": {"required": false, "order": 3, "description": "(optional) Comment on this decision.", "value-regex": "[\\S\\s]{0,5000}"}, "decision": {"required": true, "order": 2, "value-dropdown": ["Accept (Oral)", "Accept (Poster)", "Reject", "Invite to Workshop Track"]}}}, "signatures": ["ICLR.cc/2018/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": [], "noninvitees": [], "writers": ["ICLR.cc/2018/Conference"], "multiReply": null, "taskCompletionCount": null, "transform": null, "cdate": 1541177635767}}}, {"tddate": null, "ddate": null, "original": null, "tmdate": 1515642411152, "tcdate": 1511539189778, "number": 1, "cdate": 1511539189778, "id": "Sy0xMaHlG", "invitation": "ICLR.cc/2018/Conference/-/Paper221/Official_Review", "forum": "rybAWfx0b", "replyto": "rybAWfx0b", "signatures": ["ICLR.cc/2018/Conference/Paper221/AnonReviewer1"], "readers": ["everyone"], "content": {"title": "review", "rating": "5: Marginally below acceptance threshold", "review": "The paper proposes a novel approach to integrate a language model (LM) to a seq2seq based speech recognition system (ASR). The LM is pretrained on separate data (presumably larger, potentially not the same exact distribution). It has a similar flavor as DeepFusion (DF), a previous work which also integrated an LM to a ASR in a similar way, but where the fusion is also trained. This paper argues this is not good as the ASR decoder and LM are trying to solve the same problem. Instead, ColdFusion first trains the LM, then fixes it and trains the ASR, so it can concentrate on what the LM doesn't do. This makes a lot of sense.\n\nExperiments on private data show that the ColdFusion approach works better than the DeepFusion approach. Sadly these experiments are done on private data and it is thus hard to compare with benchmark models and datasets.\n\nFor instance, it is possible that the relative capacity (number of layers, number of cells, etc) for each of the blocs need to vary differently between the baseline, the ColdFusion approach and the DeepFusion approach. It is hard to say with results on private data only, as it cannot be compared with strong baselines available in the literature.\n\nUnless a second series of experiments on known benchmarks is provided, I cannot propose this paper for acceptance.\n\n***********\nI have read the revised version. I applaud the use of a public dataset to\ndemonstrate some of the results of the new algorithm, and for this I am raising\nmy score. I am concerned, though, that while ColdFusion is indeed better than\nDeepFusion on LibriSpeech, both of them are significantly worse than the\nresults provided by Wav2Letter on word error rates (although better on\ncharacter error rates, which are usually not as important in that literature).\nIs there any reason for this?\n\n", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}, "writers": [], "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": true, "forumContent": {"title": "COLD FUSION: TRAINING SEQ2SEQ MODELS TOGETHER WITH LANGUAGE MODELS", "abstract": "Sequence-to-sequence (Seq2Seq) models with attention have excelled at tasks which involve generating natural language sentences such as machine translation, image captioning and speech recognition. Performance has further been improved by leveraging unlabeled data, often in the form of a language model. In this work, we present the Cold Fusion method, which leverages a pre-trained language model during training, and show its effectiveness on the speech recognition task. We show that Seq2Seq models with Cold Fusion are able to better utilize language information enjoying i) faster convergence and better generalization, and ii) almost complete transfer to a new domain while using less than 10% of the labeled training data.", "pdf": "/pdf/b683baa101e58773bed8d984f95a1fdc7e8c207c.pdf", "TL;DR": "We introduce a novel method to train Seq2Seq models with language models that converge faster, generalize better and can almost completely transfer to a new domain using less than 10% of labeled data.", "paperhash": "sriram|cold_fusion_training_seq2seq_models_together_with_language_models", "_bibtex": "@misc{\nsriram2018cold,\ntitle={{COLD} {FUSION}: {TRAINING} {SEQ}2{SEQ} {MODELS} {TOGETHER} {WITH} {LANGUAGE} {MODELS}},\nauthor={Anuroop Sriram and Heewoo Jun and Sanjeev Satheesh and Adam Coates},\nyear={2018},\nurl={https://openreview.net/forum?id=rybAWfx0b},\n}", "keywords": ["Sequence-to-Sequence Models", "Speech Recognition", "Language Models"], "authors": ["Anuroop Sriram", "Heewoo Jun", "Sanjeev Satheesh", "Adam Coates"], "authorids": ["anuroop.sriram@gmail.com", "junheewoo@baidu.com", "sanjeevsatheesh@baidu.com", "adamcoates@baidu.com"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1511845199000, "tmdate": 1515642411059, "id": "ICLR.cc/2018/Conference/-/Paper221/Official_Review", "writers": ["ICLR.cc/2018/Conference"], "signatures": ["ICLR.cc/2018/Conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2018/Conference/Paper221/Reviewers"], "noninvitees": ["ICLR.cc/2018/Conference/Paper221/AnonReviewer1", "ICLR.cc/2018/Conference/Paper221/AnonReviewer2", "ICLR.cc/2018/Conference/Paper221/AnonReviewer3"], "reply": {"forum": "rybAWfx0b", "replyto": "rybAWfx0b", "writers": {"values": []}, "signatures": {"values-regex": "ICLR.cc/2018/Conference/Paper221/AnonReviewer[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"required": true, "order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"required": true, "order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "value-regex": "[\\S\\s]{1,200000}"}, "rating": {"required": true, "order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"required": true, "order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1519621199000, "cdate": 1515642411059}}}, {"tddate": null, "ddate": null, "original": null, "tmdate": 1515642411115, "tcdate": 1511715865734, "number": 2, "cdate": 1511715865734, "id": "ryGQ4uugM", "invitation": "ICLR.cc/2018/Conference/-/Paper221/Official_Review", "forum": "rybAWfx0b", "replyto": "rybAWfx0b", "signatures": ["ICLR.cc/2018/Conference/Paper221/AnonReviewer2"], "readers": ["everyone"], "content": {"title": "Better integration of language models into sequence 2 sequence networks.", "rating": "6: Marginally above acceptance threshold", "review": "The paper proposes a new way of integrating a language model into a seq2seq network: instead of adding the language model only during decoding, the model has access to a pretrained language model during training too. This makes the training and testing conditions more similar. Moreover, only the logits of the pretrained language model are used, making it possible to swap language models post-training.\n\nThe experiments show that the proposed language model fusion is effective, and works well even when different, domain-dependent language models are used during training and testing. Further experiments indicate that through the integration of a language model at training time the seq2seq's decoder can be smaller as it is relieved of language modeling.\n\nQuality:\nThe paper is well executed, the experiments do basic validation of the model (ablation plus a specially designed task to show model effectiveness)\n\nClarity:\nWell written, easy to understand.\n\nOriginality:\nThe main idea is new.\n\nSignificance:\nBetter language model integration and easier adaptation to new domains of seq2seq models is important.\n\nPros and cons:\npros : see above\n\ncons:\nMy problem with the paper is lack of experiments on public datasets. The efficacy of the method is shown on only one task on a proprietary corpus engineered for domain mismatch and the method may be not so efficient under other circumstances.  Besides presenting results on publicly available data, the paper would also be improved by adding a baseline in which the logits of the language model are added to the logits of the seq2seq decoder at training time. Similarly to cold-fusion, this baseline also allows swapping of language models at test time. In contrast, the baselines presented in the paper are weaker because they don't use a language model during training time.", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}, "writers": [], "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "COLD FUSION: TRAINING SEQ2SEQ MODELS TOGETHER WITH LANGUAGE MODELS", "abstract": "Sequence-to-sequence (Seq2Seq) models with attention have excelled at tasks which involve generating natural language sentences such as machine translation, image captioning and speech recognition. Performance has further been improved by leveraging unlabeled data, often in the form of a language model. In this work, we present the Cold Fusion method, which leverages a pre-trained language model during training, and show its effectiveness on the speech recognition task. We show that Seq2Seq models with Cold Fusion are able to better utilize language information enjoying i) faster convergence and better generalization, and ii) almost complete transfer to a new domain while using less than 10% of the labeled training data.", "pdf": "/pdf/b683baa101e58773bed8d984f95a1fdc7e8c207c.pdf", "TL;DR": "We introduce a novel method to train Seq2Seq models with language models that converge faster, generalize better and can almost completely transfer to a new domain using less than 10% of labeled data.", "paperhash": "sriram|cold_fusion_training_seq2seq_models_together_with_language_models", "_bibtex": "@misc{\nsriram2018cold,\ntitle={{COLD} {FUSION}: {TRAINING} {SEQ}2{SEQ} {MODELS} {TOGETHER} {WITH} {LANGUAGE} {MODELS}},\nauthor={Anuroop Sriram and Heewoo Jun and Sanjeev Satheesh and Adam Coates},\nyear={2018},\nurl={https://openreview.net/forum?id=rybAWfx0b},\n}", "keywords": ["Sequence-to-Sequence Models", "Speech Recognition", "Language Models"], "authors": ["Anuroop Sriram", "Heewoo Jun", "Sanjeev Satheesh", "Adam Coates"], "authorids": ["anuroop.sriram@gmail.com", "junheewoo@baidu.com", "sanjeevsatheesh@baidu.com", "adamcoates@baidu.com"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1511845199000, "tmdate": 1515642411059, "id": "ICLR.cc/2018/Conference/-/Paper221/Official_Review", "writers": ["ICLR.cc/2018/Conference"], "signatures": ["ICLR.cc/2018/Conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2018/Conference/Paper221/Reviewers"], "noninvitees": ["ICLR.cc/2018/Conference/Paper221/AnonReviewer1", "ICLR.cc/2018/Conference/Paper221/AnonReviewer2", "ICLR.cc/2018/Conference/Paper221/AnonReviewer3"], "reply": {"forum": "rybAWfx0b", "replyto": "rybAWfx0b", "writers": {"values": []}, "signatures": {"values-regex": "ICLR.cc/2018/Conference/Paper221/AnonReviewer[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"required": true, "order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"required": true, "order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "value-regex": "[\\S\\s]{1,200000}"}, "rating": {"required": true, "order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"required": true, "order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1519621199000, "cdate": 1515642411059}}}, {"tddate": null, "ddate": null, "original": null, "tmdate": 1515642411075, "tcdate": 1511772630427, "number": 3, "cdate": 1511772630427, "id": "B10RWItgz", "invitation": "ICLR.cc/2018/Conference/-/Paper221/Official_Review", "forum": "rybAWfx0b", "replyto": "rybAWfx0b", "signatures": ["ICLR.cc/2018/Conference/Paper221/AnonReviewer3"], "readers": ["everyone"], "content": {"title": "Review", "rating": "5: Marginally below acceptance threshold", "review": "This paper present a simple but effective approach to utilize language model information in a seq2seq framework. The experimental results show improvement for both baseline and adaptation scenarios.\n\nPros:\nThe approach is adapted from deep fusion but the results are promising, especially for the off-domain setup. The analysis also well-motivated about why cold-fusion outperform deep-fusion.\n\nCons:\n(1) I have some question about the baseline. Why the decoder is single layer but for LM it is 2 layer? I suspect the LM may add something to it.  For my own Seq2seq model, 2 layer decoder always better than one. Also, what is HMM/DNN/CTC baseline ? Since they use a internal dataset, it's hard to know how was the seq2seq numbers. The author also didn't compare with re-scoring method.\n\n(2) It would be more interesting to test it on more standard speech corpus, for example, SWB (conversational based) and librispeech (reading task). Then it's easier to reproduce and measure the quality of the model.\n\n(3) This paper only report results on speech recognition. It would be more interesting to test it on more area, e.g. Machine Translation. \n\nMissing citation: In (https://arxiv.org/pdf/1706.02737.pdf) section 3.3, they also pre-trained RNN-LM on more standard speech corpus. Also, need to compare with this type of shallow fusion.\n\nUpdates: \n\nhttps://arxiv.org/pdf/1712.01769.pdf (Google's End2End system) use 2-layer LSTM decoder. \nhttps://arxiv.org/abs/1612.02695,  https://arxiv.org/abs/1707.07413 and https://arxiv.org/abs/1506.07503) are small task. \nBattenberg et al. paper (https://arxiv.org/abs/1707.07413) use Seq2Seq as a baseline and didn't show any combined results of different #decoder layer vs. different LM integration method. My point is how a stronger decoder affect the results with different LM integration methods. In the paper, it still only compared with deep fusion with one decoder layer. \n\nAlso, why it only compared shallow fusion w/ CTC model? I suspect deep decoder + shallow fusion already could provide good results. Or the gain is additive?\n\nThanks a lot adding Librispeech results. But why use Wav2Letter paper (instead of refer to a peer reviewed paper)? The Wav2letter paper didn't compare with any baseline on librispeech (probably because librispeech isn't a common dataset, but at least the Kaldi baseline is there). \n\nIn short, I'm still think this is a good paper but still slightly below the acceptance threshold.", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}, "writers": [], "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": true, "forumContent": {"title": "COLD FUSION: TRAINING SEQ2SEQ MODELS TOGETHER WITH LANGUAGE MODELS", "abstract": "Sequence-to-sequence (Seq2Seq) models with attention have excelled at tasks which involve generating natural language sentences such as machine translation, image captioning and speech recognition. Performance has further been improved by leveraging unlabeled data, often in the form of a language model. In this work, we present the Cold Fusion method, which leverages a pre-trained language model during training, and show its effectiveness on the speech recognition task. We show that Seq2Seq models with Cold Fusion are able to better utilize language information enjoying i) faster convergence and better generalization, and ii) almost complete transfer to a new domain while using less than 10% of the labeled training data.", "pdf": "/pdf/b683baa101e58773bed8d984f95a1fdc7e8c207c.pdf", "TL;DR": "We introduce a novel method to train Seq2Seq models with language models that converge faster, generalize better and can almost completely transfer to a new domain using less than 10% of labeled data.", "paperhash": "sriram|cold_fusion_training_seq2seq_models_together_with_language_models", "_bibtex": "@misc{\nsriram2018cold,\ntitle={{COLD} {FUSION}: {TRAINING} {SEQ}2{SEQ} {MODELS} {TOGETHER} {WITH} {LANGUAGE} {MODELS}},\nauthor={Anuroop Sriram and Heewoo Jun and Sanjeev Satheesh and Adam Coates},\nyear={2018},\nurl={https://openreview.net/forum?id=rybAWfx0b},\n}", "keywords": ["Sequence-to-Sequence Models", "Speech Recognition", "Language Models"], "authors": ["Anuroop Sriram", "Heewoo Jun", "Sanjeev Satheesh", "Adam Coates"], "authorids": ["anuroop.sriram@gmail.com", "junheewoo@baidu.com", "sanjeevsatheesh@baidu.com", "adamcoates@baidu.com"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1511845199000, "tmdate": 1515642411059, "id": "ICLR.cc/2018/Conference/-/Paper221/Official_Review", "writers": ["ICLR.cc/2018/Conference"], "signatures": ["ICLR.cc/2018/Conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2018/Conference/Paper221/Reviewers"], "noninvitees": ["ICLR.cc/2018/Conference/Paper221/AnonReviewer1", "ICLR.cc/2018/Conference/Paper221/AnonReviewer2", "ICLR.cc/2018/Conference/Paper221/AnonReviewer3"], "reply": {"forum": "rybAWfx0b", "replyto": "rybAWfx0b", "writers": {"values": []}, "signatures": {"values-regex": "ICLR.cc/2018/Conference/Paper221/AnonReviewer[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"required": true, "order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"required": true, "order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "value-regex": "[\\S\\s]{1,200000}"}, "rating": {"required": true, "order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"required": true, "order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1519621199000, "cdate": 1515642411059}}}], "count": 5}