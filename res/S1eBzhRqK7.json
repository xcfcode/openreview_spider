{"notes": [{"id": "S1eBzhRqK7", "original": "ByxjA-0ctm", "number": 1261, "cdate": 1538087948889, "ddate": null, "tcdate": 1538087948889, "tmdate": 1545355378714, "tddate": null, "forum": "S1eBzhRqK7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Evolutionary-Neural Hybrid Agents for Architecture Search", "abstract": "Neural Architecture Search has recently shown potential to automate the design of Neural Networks. The use of Neural Network agents trained with Reinforcement Learning can offer the possibility to learn complex patterns, as well as the ability to explore a vast and compositional search space. On the other hand, evolutionary algorithms offer the greediness and sample efficiency needed for such an application, as each sample requires a considerable amount of resources. We propose a class of Evolutionary-Neural hybrid agents (Evo-NAS), that retain the best qualities of the two approaches. We show that the Evo-NAS agent can outperform both Neural and Evolutionary agents, both on a synthetic task, and on architecture search for a suite of text classification datasets.", "keywords": ["Evolutionary", "Architecture Search", "NAS"], "authorids": ["kmaziarz@google.com", "akhorlin@google.com", "underflow@google.com", "agesmundo@google.com"], "authors": ["Krzysztof Maziarz", "Andrey Khorlin", "Quentin de Laroussilhe", "Andrea Gesmundo"], "TL;DR": "We propose a class of Evolutionary-Neural hybrid agents, that retain the best qualities of the two approaches.", "pdf": "/pdf/9974bcace4c723c6b05b6bda8c6fbdcfc0a0ab61.pdf", "paperhash": "maziarz|evolutionaryneural_hybrid_agents_for_architecture_search", "_bibtex": "@misc{\nmaziarz2019evolutionaryneural,\ntitle={Evolutionary-Neural Hybrid Agents for Architecture Search},\nauthor={Krzysztof Maziarz and Andrey Khorlin and Quentin de Laroussilhe and Andrea Gesmundo},\nyear={2019},\nurl={https://openreview.net/forum?id=S1eBzhRqK7},\n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"replyCount": 5, "writable": false, "overwriting": [], "revisions": false, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Blind_Submission", "rdate": null, "ddate": null, "expdate": null, "duedate": 1538085600000, "tmdate": 1538142958393, "tddate": null, "super": null, "final": null, "reply": {"signatures": {"values": ["ICLR.cc/2019/Conference"]}, "forum": null, "readers": {"values": ["everyone"]}, "replyto": null, "content": {"authorids": {"values-regex": ".*"}, "authors": {"values": ["Anonymous"]}}, "writers": {"values": ["ICLR.cc/2019/Conference"]}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["~"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": null, "taskCompletionCount": null, "transform": null, "cdate": 1538142958393}}, "tauthor": "OpenReview.net"}, {"id": "rJlU4O2WeV", "original": null, "number": 1, "cdate": 1544828973643, "ddate": null, "tcdate": 1544828973643, "tmdate": 1545354530432, "tddate": null, "forum": "S1eBzhRqK7", "replyto": "S1eBzhRqK7", "invitation": "ICLR.cc/2019/Conference/-/Paper1261/Meta_Review", "content": {"metareview": "Reviewers are in a consensus and recommended to reject after engaging with the authors. Please take reviewers' comments into consideration to improve your submission should you decide to resubmit.\n", "confidence": "4: The area chair is confident but not absolutely certain", "recommendation": "Reject", "title": "Paper decision"}, "signatures": ["ICLR.cc/2019/Conference/Paper1261/Area_Chair1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference/Paper1261/Area_Chair1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Evolutionary-Neural Hybrid Agents for Architecture Search", "abstract": "Neural Architecture Search has recently shown potential to automate the design of Neural Networks. The use of Neural Network agents trained with Reinforcement Learning can offer the possibility to learn complex patterns, as well as the ability to explore a vast and compositional search space. On the other hand, evolutionary algorithms offer the greediness and sample efficiency needed for such an application, as each sample requires a considerable amount of resources. We propose a class of Evolutionary-Neural hybrid agents (Evo-NAS), that retain the best qualities of the two approaches. We show that the Evo-NAS agent can outperform both Neural and Evolutionary agents, both on a synthetic task, and on architecture search for a suite of text classification datasets.", "keywords": ["Evolutionary", "Architecture Search", "NAS"], "authorids": ["kmaziarz@google.com", "akhorlin@google.com", "underflow@google.com", "agesmundo@google.com"], "authors": ["Krzysztof Maziarz", "Andrey Khorlin", "Quentin de Laroussilhe", "Andrea Gesmundo"], "TL;DR": "We propose a class of Evolutionary-Neural hybrid agents, that retain the best qualities of the two approaches.", "pdf": "/pdf/9974bcace4c723c6b05b6bda8c6fbdcfc0a0ab61.pdf", "paperhash": "maziarz|evolutionaryneural_hybrid_agents_for_architecture_search", "_bibtex": "@misc{\nmaziarz2019evolutionaryneural,\ntitle={Evolutionary-Neural Hybrid Agents for Architecture Search},\nauthor={Krzysztof Maziarz and Andrey Khorlin and Quentin de Laroussilhe and Andrea Gesmundo},\nyear={2019},\nurl={https://openreview.net/forum?id=S1eBzhRqK7},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper1261/Meta_Review", "rdate": null, "ddate": null, "expdate": null, "duedate": 1541548800000, "tmdate": 1545352902696, "tddate": null, "super": null, "final": null, "reply": {"forum": "S1eBzhRqK7", "replyto": "S1eBzhRqK7", "readers": {"description": "Select all user groups that should be able to read this comment. Selecting 'All Users' will allow paper authors, reviewers, area chairs, and program chairs to view this comment.", "values": ["everyone"]}, "signatures": {"description": "How your identity will be displayed with the above content.", "values-regex": "ICLR.cc/2019/Conference/Paper1261/Area_Chair[0-9]+"}, "writers": {"description": "Users that may modify this record.", "values-regex": "ICLR.cc/2019/Conference/Paper1261/Area_Chair[0-9]+"}, "content": {"title": {"order": 1, "value-regex": ".{1,500}", "description": "Brief summary of your review.", "required": true}, "metareview": {"order": 2, "value-regex": "[\\S\\s]{1,5000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "required": true}, "recommendation": {"order": 3, "value-dropdown": ["Accept (Oral)", "Accept (Poster)", "Reject"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The area chair is absolutely certain", "4: The area chair is confident but not absolutely certain", "3: The area chair is somewhat confident", "2: The area chair is not sure", "1: The area chair's evaluation is an educated guess"], "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper1261/Area_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": false, "taskCompletionCount": null, "transform": null, "cdate": 1545352902696}}}, {"id": "B1lCfqNOh7", "original": null, "number": 1, "cdate": 1541061141785, "ddate": null, "tcdate": 1541061141785, "tmdate": 1542593406479, "tddate": null, "forum": "S1eBzhRqK7", "replyto": "S1eBzhRqK7", "invitation": "ICLR.cc/2019/Conference/-/Paper1261/Official_Review", "content": {"title": "Intuitive idea, unclear explanation. ", "review": "The paper proposes a class of Evolutionary-Neural hybrid agents (Evo-NAS) to take advantage of both evolutionary algorithms and reinforcement learning algorithms for efficient neural architecture search. \n\n1. Doesn't explain how exactly the mutation action is learned, and missing the explanation of how RL acts on its modification on NAS (Evo-NAS). \n2. Very poor explanation on LEARN TO COUNT experiment. The experiment contains difficult setups on a toy data, which makes it difficult to repeat. In figure 3, the paper says that the sample efficiency of the Evo-NAS strongly outperforms both the evolutionary and the neural agent. However, where the strength comes from is not discussed in detail. In figure 2, the paper claims that PQT outperforms Reinforce for both the Neural and the Evo-NAS agent. For the Evo-NAS agent, the gain is especially pronounced at the beginning of the experiment. Thus, the paper concludes that PQT can provide a stronger training signal than Reinforce. However, how much stronger training signal can obtain of the proposed method is not discussed. Because the experiments of 5.1 is setup on a toy data with complicated parameters. The conclusions based on this data set is not convincing. It would be better to add comparative results on the CIFAR and Imagenet data for convenient comparisons with state-of-the-art. \n3. Confusing notation and experimental setup. In 5.1, the sequence a is first defined as <a1, a2, .., an>. Then, after eq.2, the sequence a is given as a=<1, 2, ..., n>. It would be better to use different symbols here. ", "rating": "4: Ok but not good enough - rejection", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["ICLR.cc/2019/Conference/Paper1261/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": true, "forumContent": {"title": "Evolutionary-Neural Hybrid Agents for Architecture Search", "abstract": "Neural Architecture Search has recently shown potential to automate the design of Neural Networks. The use of Neural Network agents trained with Reinforcement Learning can offer the possibility to learn complex patterns, as well as the ability to explore a vast and compositional search space. On the other hand, evolutionary algorithms offer the greediness and sample efficiency needed for such an application, as each sample requires a considerable amount of resources. We propose a class of Evolutionary-Neural hybrid agents (Evo-NAS), that retain the best qualities of the two approaches. We show that the Evo-NAS agent can outperform both Neural and Evolutionary agents, both on a synthetic task, and on architecture search for a suite of text classification datasets.", "keywords": ["Evolutionary", "Architecture Search", "NAS"], "authorids": ["kmaziarz@google.com", "akhorlin@google.com", "underflow@google.com", "agesmundo@google.com"], "authors": ["Krzysztof Maziarz", "Andrey Khorlin", "Quentin de Laroussilhe", "Andrea Gesmundo"], "TL;DR": "We propose a class of Evolutionary-Neural hybrid agents, that retain the best qualities of the two approaches.", "pdf": "/pdf/9974bcace4c723c6b05b6bda8c6fbdcfc0a0ab61.pdf", "paperhash": "maziarz|evolutionaryneural_hybrid_agents_for_architecture_search", "_bibtex": "@misc{\nmaziarz2019evolutionaryneural,\ntitle={Evolutionary-Neural Hybrid Agents for Architecture Search},\nauthor={Krzysztof Maziarz and Andrey Khorlin and Quentin de Laroussilhe and Andrea Gesmundo},\nyear={2019},\nurl={https://openreview.net/forum?id=S1eBzhRqK7},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper1261/Official_Review", "cdate": 1542234268773, "expdate": 1552335264000, "duedate": 1541196000000, "reply": {"forum": "S1eBzhRqK7", "replyto": "S1eBzhRqK7", "readers": {"description": "The users who will be allowed to read the reply content.", "values": ["everyone"]}, "nonreaders": {"values": []}, "signatures": {"description": "How your identity will be displayed with the above content.", "values-regex": "ICLR.cc/2019/Conference/Paper1261/AnonReviewer[0-9]+"}, "writers": {"description": "Users that may modify this record.", "values": ["ICLR.cc/2019/Conference"]}, "content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "required": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}}, "multiReply": false, "tcdate": 1552335908232, "tmdate": 1552335908232, "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "invitees": ["ICLR.cc/2019/Conference/Paper1261/Reviewers"], "noninvitees": [], "signatures": ["ICLR.cc/2019/Conference"]}}}, {"id": "SygXI27VTQ", "original": null, "number": 2, "cdate": 1541844043173, "ddate": null, "tcdate": 1541844043173, "tmdate": 1541844043173, "tddate": null, "forum": "S1eBzhRqK7", "replyto": "B1lCfqNOh7", "invitation": "ICLR.cc/2019/Conference/-/Paper1261/Official_Comment", "content": {"title": "Response to AnonReviewer3", "comment": "Thank you so much for your feedback!\n\nWe tried to write everything as clearly as possible, could you please tell us exactly which things were unclear? We would be especially interested in hearing what you meant in points 2 and 3 in your review."}, "signatures": ["ICLR.cc/2019/Conference/Paper1261/Authors"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper1261/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper1261/Authors", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Evolutionary-Neural Hybrid Agents for Architecture Search", "abstract": "Neural Architecture Search has recently shown potential to automate the design of Neural Networks. The use of Neural Network agents trained with Reinforcement Learning can offer the possibility to learn complex patterns, as well as the ability to explore a vast and compositional search space. On the other hand, evolutionary algorithms offer the greediness and sample efficiency needed for such an application, as each sample requires a considerable amount of resources. We propose a class of Evolutionary-Neural hybrid agents (Evo-NAS), that retain the best qualities of the two approaches. We show that the Evo-NAS agent can outperform both Neural and Evolutionary agents, both on a synthetic task, and on architecture search for a suite of text classification datasets.", "keywords": ["Evolutionary", "Architecture Search", "NAS"], "authorids": ["kmaziarz@google.com", "akhorlin@google.com", "underflow@google.com", "agesmundo@google.com"], "authors": ["Krzysztof Maziarz", "Andrey Khorlin", "Quentin de Laroussilhe", "Andrea Gesmundo"], "TL;DR": "We propose a class of Evolutionary-Neural hybrid agents, that retain the best qualities of the two approaches.", "pdf": "/pdf/9974bcace4c723c6b05b6bda8c6fbdcfc0a0ab61.pdf", "paperhash": "maziarz|evolutionaryneural_hybrid_agents_for_architecture_search", "_bibtex": "@misc{\nmaziarz2019evolutionaryneural,\ntitle={Evolutionary-Neural Hybrid Agents for Architecture Search},\nauthor={Krzysztof Maziarz and Andrey Khorlin and Quentin de Laroussilhe and Andrea Gesmundo},\nyear={2019},\nurl={https://openreview.net/forum?id=S1eBzhRqK7},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper1261/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621625904, "tddate": null, "super": null, "final": null, "reply": {"forum": "S1eBzhRqK7", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper1261/Authors", "ICLR.cc/2019/Conference/Paper1261/Reviewers", "ICLR.cc/2019/Conference/Paper1261/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper1261/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper1261/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper1261/Authors|ICLR.cc/2019/Conference/Paper1261/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper1261/Reviewers", "ICLR.cc/2019/Conference/Paper1261/Authors", "ICLR.cc/2019/Conference/Paper1261/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621625904}}}, {"id": "BklviPgZ6Q", "original": null, "number": 3, "cdate": 1541633950661, "ddate": null, "tcdate": 1541633950661, "tmdate": 1541633950661, "tddate": null, "forum": "S1eBzhRqK7", "replyto": "S1eBzhRqK7", "invitation": "ICLR.cc/2019/Conference/-/Paper1261/Official_Review", "content": {"title": "Simple and intuitive idea, insufficiently convincing results", "review": "Review: \nThe paper introduces a novel way to do architecture search that uses an RNN to guide the mutation operation. The method and the motivation of the idea as long with the related work are all clearly described. However, the experiments section does not show a big uplift of the method versus the baselines and the number of types of tasks is relatively small (artificial and text). \n\nCons:\n- No image task\n- No large scale task to show the scalability\n- No baselines that are not coming from AUTO-ML to show the relative performance of a classical method", "rating": "5: Marginally below acceptance threshold", "confidence": "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper"}, "signatures": ["ICLR.cc/2019/Conference/Paper1261/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Evolutionary-Neural Hybrid Agents for Architecture Search", "abstract": "Neural Architecture Search has recently shown potential to automate the design of Neural Networks. The use of Neural Network agents trained with Reinforcement Learning can offer the possibility to learn complex patterns, as well as the ability to explore a vast and compositional search space. On the other hand, evolutionary algorithms offer the greediness and sample efficiency needed for such an application, as each sample requires a considerable amount of resources. We propose a class of Evolutionary-Neural hybrid agents (Evo-NAS), that retain the best qualities of the two approaches. We show that the Evo-NAS agent can outperform both Neural and Evolutionary agents, both on a synthetic task, and on architecture search for a suite of text classification datasets.", "keywords": ["Evolutionary", "Architecture Search", "NAS"], "authorids": ["kmaziarz@google.com", "akhorlin@google.com", "underflow@google.com", "agesmundo@google.com"], "authors": ["Krzysztof Maziarz", "Andrey Khorlin", "Quentin de Laroussilhe", "Andrea Gesmundo"], "TL;DR": "We propose a class of Evolutionary-Neural hybrid agents, that retain the best qualities of the two approaches.", "pdf": "/pdf/9974bcace4c723c6b05b6bda8c6fbdcfc0a0ab61.pdf", "paperhash": "maziarz|evolutionaryneural_hybrid_agents_for_architecture_search", "_bibtex": "@misc{\nmaziarz2019evolutionaryneural,\ntitle={Evolutionary-Neural Hybrid Agents for Architecture Search},\nauthor={Krzysztof Maziarz and Andrey Khorlin and Quentin de Laroussilhe and Andrea Gesmundo},\nyear={2019},\nurl={https://openreview.net/forum?id=S1eBzhRqK7},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper1261/Official_Review", "cdate": 1542234268773, "expdate": 1552335264000, "duedate": 1541196000000, "reply": {"forum": "S1eBzhRqK7", "replyto": "S1eBzhRqK7", "readers": {"description": "The users who will be allowed to read the reply content.", "values": ["everyone"]}, "nonreaders": {"values": []}, "signatures": {"description": "How your identity will be displayed with the above content.", "values-regex": "ICLR.cc/2019/Conference/Paper1261/AnonReviewer[0-9]+"}, "writers": {"description": "Users that may modify this record.", "values": ["ICLR.cc/2019/Conference"]}, "content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "required": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}}, "multiReply": false, "tcdate": 1552335908232, "tmdate": 1552335908232, "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "invitees": ["ICLR.cc/2019/Conference/Paper1261/Reviewers"], "noninvitees": [], "signatures": ["ICLR.cc/2019/Conference"]}}}, {"id": "Syxf0zQch7", "original": null, "number": 2, "cdate": 1541186250381, "ddate": null, "tcdate": 1541186250381, "tmdate": 1541533286914, "tddate": null, "forum": "S1eBzhRqK7", "replyto": "S1eBzhRqK7", "invitation": "ICLR.cc/2019/Conference/-/Paper1261/Official_Review", "content": {"title": "Interesting method. However, empirical results are not convincing enough.", "review": "Summary:\n\nThe paper proposes a hybrid approach which combines evolution and RL. The key idea is to conduct tournament selection over a population of architectures with learned mutations. The mutations are defined as the output of an RNN controller which either reuses or alters the sequence descriptor of the parent at each step. The proposed hybrid architect is evaluated on both synthetic and text classification tasks and then compared against pure evolutionary and RL-based agents.\n\nPros:\n\n* The method can be viewed as a generalization of conventional evolution by replacing the handcrafted (uniform) distribution of mutations with a learned one. On the one hand, this should hopefully improve the sample efficiency of pure genetic methods since the population can evolve towards more meaningful directions, assuming useful patterns can be learned by the mutation controller. On the other hand, mutating existing architectures seem a easier task than sampling the entire architecture from scratch.\n* The synthetic experiment is interesting, though it's hard to draw any conclusions based a single task.\n\nCons:\n\n* To my knowledge, all text classification tasks used in 5.2 are quite small. There is no evidence that the method can scale to and work well on large-scale tasks, where improving the sample efficiency becomes truly crucial and challenging. \n* It is good to see comparisons against pure evo and RL within the authors' own search space. However, the advantage of the proposed evo-NAS, especially when evaluated on real-world text classification tasks, does not seem significant enough. In particular, there is a clear overlap between the performance of architectures found by NAS, evo and evo-NAS (Figure 4). The advantage of evo-NAS is even smaller if we compare the very best model (as can be read from Figure 4) instead of the average among the top 10 (as reported in Table 2). In my option, performance of the strongest model is arguably more interesting than the averaged one in practice.\n* Since no results on CIFAR or ImageNet are provided as in most prior works in the literature, it is impossible to empirically compare the method with the state-of-the-art. The experiments would be more convincing if a comparison can be provided on those benchmarks. Otherwise, it is possible that the current search space & hyperparameters are tailored towards evo-NAS and it remains unclear whether the method can generalize well to other domains and/or search spaces.\n", "rating": "4: Ok but not good enough - rejection", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["ICLR.cc/2019/Conference/Paper1261/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Evolutionary-Neural Hybrid Agents for Architecture Search", "abstract": "Neural Architecture Search has recently shown potential to automate the design of Neural Networks. The use of Neural Network agents trained with Reinforcement Learning can offer the possibility to learn complex patterns, as well as the ability to explore a vast and compositional search space. On the other hand, evolutionary algorithms offer the greediness and sample efficiency needed for such an application, as each sample requires a considerable amount of resources. We propose a class of Evolutionary-Neural hybrid agents (Evo-NAS), that retain the best qualities of the two approaches. We show that the Evo-NAS agent can outperform both Neural and Evolutionary agents, both on a synthetic task, and on architecture search for a suite of text classification datasets.", "keywords": ["Evolutionary", "Architecture Search", "NAS"], "authorids": ["kmaziarz@google.com", "akhorlin@google.com", "underflow@google.com", "agesmundo@google.com"], "authors": ["Krzysztof Maziarz", "Andrey Khorlin", "Quentin de Laroussilhe", "Andrea Gesmundo"], "TL;DR": "We propose a class of Evolutionary-Neural hybrid agents, that retain the best qualities of the two approaches.", "pdf": "/pdf/9974bcace4c723c6b05b6bda8c6fbdcfc0a0ab61.pdf", "paperhash": "maziarz|evolutionaryneural_hybrid_agents_for_architecture_search", "_bibtex": "@misc{\nmaziarz2019evolutionaryneural,\ntitle={Evolutionary-Neural Hybrid Agents for Architecture Search},\nauthor={Krzysztof Maziarz and Andrey Khorlin and Quentin de Laroussilhe and Andrea Gesmundo},\nyear={2019},\nurl={https://openreview.net/forum?id=S1eBzhRqK7},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper1261/Official_Review", "cdate": 1542234268773, "expdate": 1552335264000, "duedate": 1541196000000, "reply": {"forum": "S1eBzhRqK7", "replyto": "S1eBzhRqK7", "readers": {"description": "The users who will be allowed to read the reply content.", "values": ["everyone"]}, "nonreaders": {"values": []}, "signatures": {"description": "How your identity will be displayed with the above content.", "values-regex": "ICLR.cc/2019/Conference/Paper1261/AnonReviewer[0-9]+"}, "writers": {"description": "Users that may modify this record.", "values": ["ICLR.cc/2019/Conference"]}, "content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "required": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}}, "multiReply": false, "tcdate": 1552335908232, "tmdate": 1552335908232, "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "invitees": ["ICLR.cc/2019/Conference/Paper1261/Reviewers"], "noninvitees": [], "signatures": ["ICLR.cc/2019/Conference"]}}}], "count": 6}