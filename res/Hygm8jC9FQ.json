{"notes": [{"id": "Hygm8jC9FQ", "original": "r1eCVibOYQ", "number": 158, "cdate": 1538087754592, "ddate": null, "tcdate": 1538087754592, "tmdate": 1545355416566, "tddate": null, "forum": "Hygm8jC9FQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "FAVAE: SEQUENCE DISENTANGLEMENT USING IN- FORMATION BOTTLENECK PRINCIPLE", "abstract": "A state-of-the-art generative model, a \u201dfactorized action variational autoencoder (FAVAE),\u201d is presented for learning disentangled and interpretable representations from sequential data via the information bottleneck without supervision. The purpose of disentangled representation learning is to obtain interpretable and transferable representations from data. We focused on the disentangled representation of sequential data because there is a wide range of potential applications if disentanglement representation is extended to sequential data such as video, speech, and stock price data. Sequential data is characterized by dynamic factors and static factors: dynamic factors are time-dependent, and static factors are independent of time. Previous works succeed in disentangling static factors and dynamic factors by explicitly modeling the priors of latent variables to distinguish between static and dynamic factors. However, this model can not disentangle representations between dynamic factors, such as disentangling \u201dpicking\u201d and \u201dthrowing\u201d in robotic tasks. In this paper, we propose new model that can disentangle multiple dynamic factors. Since our method does not require modeling priors, it is capable of disentangling \u201dbetween\u201d dynamic factors. In experiments, we show that FAVAE can extract the disentangled dynamic factors.", "keywords": ["disentangled representation learning"], "authorids": ["yamada0224@gmail.com", "h-kim@isi.imi.i.u-tokyo.ac.jp", "miyoshi@narr.jp", "hiroshi_yamakawa@dwango.co.jp"], "authors": ["Masanori Yamada", "Kim Heecheol", "Kosuke Miyoshi", "Hiroshi Yamakawa"], "TL;DR": "We propose new model that can disentangle multiple dynamic factors in sequential data", "pdf": "/pdf/a004e4cd56b0a7d6abe227b276f3fcf920f51763.pdf", "paperhash": "yamada|favae_sequence_disentanglement_using_in_formation_bottleneck_principle", "_bibtex": "@misc{\nyamada2019favae,\ntitle={{FAVAE}: {SEQUENCE} {DISENTANGLEMENT} {USING} {IN}- {FORMATION} {BOTTLENECK} {PRINCIPLE}},\nauthor={Masanori Yamada and Kim Heecheol and Kosuke Miyoshi and Hiroshi Yamakawa},\nyear={2019},\nurl={https://openreview.net/forum?id=Hygm8jC9FQ},\n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"replyCount": 11, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Blind_Submission", "rdate": null, "ddate": null, "expdate": null, "duedate": 1538085600000, "tmdate": 1538142958393, "tddate": null, "super": null, "final": null, "reply": {"signatures": {"values": ["ICLR.cc/2019/Conference"]}, "forum": null, "readers": {"values": ["everyone"]}, "replyto": null, "content": {"authorids": {"values-regex": ".*"}, "authors": {"values": ["Anonymous"]}}, "writers": {"values": ["ICLR.cc/2019/Conference"]}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["~"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": null, "taskCompletionCount": null, "transform": null, "cdate": 1538142958393}}, "tauthor": "OpenReview.net"}, {"id": "HyxwAYPh1V", "original": null, "number": 1, "cdate": 1544481230806, "ddate": null, "tcdate": 1544481230806, "tmdate": 1545354498315, "tddate": null, "forum": "Hygm8jC9FQ", "replyto": "Hygm8jC9FQ", "invitation": "ICLR.cc/2019/Conference/-/Paper158/Meta_Review", "content": {"metareview": "This paper introduces an autoencoder architecture that can handle sequences of data, and attempts to automatically disentangle multiple static and dynamic factors.\n\nQuality:  The main idea is relatively well-motivated.  However the motivation for the particular technical choices made seems a little lacking, and the complexity of the proposed model put a lot of strain on the experiments.  A lot of important updates were made by the authors in the rebuttal period, however I feel the number of changes are a lot to ask the reviewers to re-evaluate.\n\nClarity:  The English of the paper isn't great, including the title (should be \"Using an ...\" or \"Using the ...\").  The intro is clear enough, but belabors a relatively simple point about how an image model can't model factors in video.  There were some concerning parts where major issues seemed to be glossed over.  E.g. \"FHVAE model uses label information to disentangle time series data, which is different setup with our FAVAE model.\"  As far as I understand, they both are trained from unsupervised data.\n \nOriginality:  This paper does a good job of citing related work, but seems incremental in relation to the FHVAE.  But the main problem is that the proposed method makes a lot of changes from a standard time-series VAE, and the limited number of experiments means it's hard to say what the important factor in this model's performance is.\n\nSignificance:  Ultimately it's hard to say what the takeaway from this paper is.  The authors motivated and evaluated a new model, but the work wasn't done in a systematic enough way to make an strong conclusions.  What conclusion were asserted seem specious and overly general, e.g. \" Since dynamic factors have the same time dependency, these models cannot disentangle dynamic factors.\".  Why not?  Why can't a dynamic model learn the time-scales of each of its factors automatically?\n", "confidence": "3: The area chair is somewhat confident", "recommendation": "Reject", "title": "Close, but a few foundational issues, and too many major changes to re-evaluate"}, "signatures": ["ICLR.cc/2019/Conference/Paper158/Area_Chair1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference/Paper158/Area_Chair1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "FAVAE: SEQUENCE DISENTANGLEMENT USING IN- FORMATION BOTTLENECK PRINCIPLE", "abstract": "A state-of-the-art generative model, a \u201dfactorized action variational autoencoder (FAVAE),\u201d is presented for learning disentangled and interpretable representations from sequential data via the information bottleneck without supervision. The purpose of disentangled representation learning is to obtain interpretable and transferable representations from data. We focused on the disentangled representation of sequential data because there is a wide range of potential applications if disentanglement representation is extended to sequential data such as video, speech, and stock price data. Sequential data is characterized by dynamic factors and static factors: dynamic factors are time-dependent, and static factors are independent of time. Previous works succeed in disentangling static factors and dynamic factors by explicitly modeling the priors of latent variables to distinguish between static and dynamic factors. However, this model can not disentangle representations between dynamic factors, such as disentangling \u201dpicking\u201d and \u201dthrowing\u201d in robotic tasks. In this paper, we propose new model that can disentangle multiple dynamic factors. Since our method does not require modeling priors, it is capable of disentangling \u201dbetween\u201d dynamic factors. In experiments, we show that FAVAE can extract the disentangled dynamic factors.", "keywords": ["disentangled representation learning"], "authorids": ["yamada0224@gmail.com", "h-kim@isi.imi.i.u-tokyo.ac.jp", "miyoshi@narr.jp", "hiroshi_yamakawa@dwango.co.jp"], "authors": ["Masanori Yamada", "Kim Heecheol", "Kosuke Miyoshi", "Hiroshi Yamakawa"], "TL;DR": "We propose new model that can disentangle multiple dynamic factors in sequential data", "pdf": "/pdf/a004e4cd56b0a7d6abe227b276f3fcf920f51763.pdf", "paperhash": "yamada|favae_sequence_disentanglement_using_in_formation_bottleneck_principle", "_bibtex": "@misc{\nyamada2019favae,\ntitle={{FAVAE}: {SEQUENCE} {DISENTANGLEMENT} {USING} {IN}- {FORMATION} {BOTTLENECK} {PRINCIPLE}},\nauthor={Masanori Yamada and Kim Heecheol and Kosuke Miyoshi and Hiroshi Yamakawa},\nyear={2019},\nurl={https://openreview.net/forum?id=Hygm8jC9FQ},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper158/Meta_Review", "rdate": null, "ddate": null, "expdate": null, "duedate": 1541548800000, "tmdate": 1545353315644, "tddate": null, "super": null, "final": null, "reply": {"forum": "Hygm8jC9FQ", "replyto": "Hygm8jC9FQ", "readers": {"description": "Select all user groups that should be able to read this comment. Selecting 'All Users' will allow paper authors, reviewers, area chairs, and program chairs to view this comment.", "values": ["everyone"]}, "signatures": {"description": "How your identity will be displayed with the above content.", "values-regex": "ICLR.cc/2019/Conference/Paper158/Area_Chair[0-9]+"}, "writers": {"description": "Users that may modify this record.", "values-regex": "ICLR.cc/2019/Conference/Paper158/Area_Chair[0-9]+"}, "content": {"title": {"order": 1, "value-regex": ".{1,500}", "description": "Brief summary of your review.", "required": true}, "metareview": {"order": 2, "value-regex": "[\\S\\s]{1,5000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "required": true}, "recommendation": {"order": 3, "value-dropdown": ["Accept (Oral)", "Accept (Poster)", "Reject"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The area chair is absolutely certain", "4: The area chair is confident but not absolutely certain", "3: The area chair is somewhat confident", "2: The area chair is not sure", "1: The area chair's evaluation is an educated guess"], "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper158/Area_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": false, "taskCompletionCount": null, "transform": null, "cdate": 1545353315644}}}, {"id": "BkeRc0ZYAm", "original": null, "number": 7, "cdate": 1543212694257, "ddate": null, "tcdate": 1543212694257, "tmdate": 1543212694257, "tddate": null, "forum": "Hygm8jC9FQ", "replyto": "rJerpy-PA7", "invitation": "ICLR.cc/2019/Conference/-/Paper158/Official_Comment", "content": {"title": "Thank you for kindly comments.", "comment": "> 3) Figure 5 is now clearer, thanks. Figure 4 is nicer too, but I\u2019m not extremely sure what point you\u2019re trying to put across with it. Does it inform your choice of beta? It is not clear from reading the text.\n\nIn the 3rd paragraph in Sec 7.2, we state that it is better to use C because when increasing Beta without introducing C, reconstruction loss gets bigger.\n\n> 4)\tI think your results on the Sprites dataset are really promising, and actually fit the paper much better than your previous Gripper experiment. They do seem early though, so I\u2019d recommend continuing on them, and try to give a better overview of the effect of the latents, and of which levels of \u201csemantic factors\u201d are captured by the different ladder levels. I think with some work and clean up they could make really strong points.\n\nWe added the explanation how the semantic factors were extracted into certain ladders in the Sprite dataset experiments. However, as far as we tried in our experiments, we couldn't see the tendency that certain factor concentrates in certain ladder. We think that this is because it is not clear that Sprite dataset is composed of multiple abstract levels of dynamic factors.\n\n\n> 5)\tRelated to that, I think it is still unclear in the current version exactly what is the effect/responsibilities of each ladder layer. Fig 7 goes in the good direction, but I was confused by Table 2 in Appendix B, it does not really tell a simple story of \u201chighest/slowest ladder controls the longer-term/constant factors, vs lowest ladder controls the details of the trajectory\u201d. At least the text does not currently express that simply. \n\nWe modified the texts in Appendix B. Here we state that the long time dependency is expressed in the 3rd ladder which passes time convolution the most, and short time dependency is expressed in the 1st ladder. In 2D Wavy Reaching dataset, there is distinct difference between factors of long and short time dependency. The goal of the trajectory is the factor which affect the entire trajectory, and other factors affect half length of the trajectory (Fig. 9). In our experiment the goal of the trajectory which affect the entire trajectory tended to be expressed in the 3rd ladder."}, "signatures": ["ICLR.cc/2019/Conference/Paper158/Authors"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper158/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper158/Authors", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "FAVAE: SEQUENCE DISENTANGLEMENT USING IN- FORMATION BOTTLENECK PRINCIPLE", "abstract": "A state-of-the-art generative model, a \u201dfactorized action variational autoencoder (FAVAE),\u201d is presented for learning disentangled and interpretable representations from sequential data via the information bottleneck without supervision. The purpose of disentangled representation learning is to obtain interpretable and transferable representations from data. We focused on the disentangled representation of sequential data because there is a wide range of potential applications if disentanglement representation is extended to sequential data such as video, speech, and stock price data. Sequential data is characterized by dynamic factors and static factors: dynamic factors are time-dependent, and static factors are independent of time. Previous works succeed in disentangling static factors and dynamic factors by explicitly modeling the priors of latent variables to distinguish between static and dynamic factors. However, this model can not disentangle representations between dynamic factors, such as disentangling \u201dpicking\u201d and \u201dthrowing\u201d in robotic tasks. In this paper, we propose new model that can disentangle multiple dynamic factors. Since our method does not require modeling priors, it is capable of disentangling \u201dbetween\u201d dynamic factors. In experiments, we show that FAVAE can extract the disentangled dynamic factors.", "keywords": ["disentangled representation learning"], "authorids": ["yamada0224@gmail.com", "h-kim@isi.imi.i.u-tokyo.ac.jp", "miyoshi@narr.jp", "hiroshi_yamakawa@dwango.co.jp"], "authors": ["Masanori Yamada", "Kim Heecheol", "Kosuke Miyoshi", "Hiroshi Yamakawa"], "TL;DR": "We propose new model that can disentangle multiple dynamic factors in sequential data", "pdf": "/pdf/a004e4cd56b0a7d6abe227b276f3fcf920f51763.pdf", "paperhash": "yamada|favae_sequence_disentanglement_using_in_formation_bottleneck_principle", "_bibtex": "@misc{\nyamada2019favae,\ntitle={{FAVAE}: {SEQUENCE} {DISENTANGLEMENT} {USING} {IN}- {FORMATION} {BOTTLENECK} {PRINCIPLE}},\nauthor={Masanori Yamada and Kim Heecheol and Kosuke Miyoshi and Hiroshi Yamakawa},\nyear={2019},\nurl={https://openreview.net/forum?id=Hygm8jC9FQ},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper158/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621611696, "tddate": null, "super": null, "final": null, "reply": {"forum": "Hygm8jC9FQ", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper158/Authors", "ICLR.cc/2019/Conference/Paper158/Reviewers", "ICLR.cc/2019/Conference/Paper158/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper158/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper158/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper158/Authors|ICLR.cc/2019/Conference/Paper158/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper158/Reviewers", "ICLR.cc/2019/Conference/Paper158/Authors", "ICLR.cc/2019/Conference/Paper158/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621611696}}}, {"id": "rJerpy-PA7", "original": null, "number": 6, "cdate": 1543077820631, "ddate": null, "tcdate": 1543077820631, "tmdate": 1543077873315, "tddate": null, "forum": "Hygm8jC9FQ", "replyto": "HJl_zTbtaQ", "invitation": "ICLR.cc/2019/Conference/-/Paper158/Official_Comment", "content": {"title": "Good improvements!", "comment": "Thanks to the authors for their responses and hard work in improving their results.\n\n1)\tThe new versions of sections 2, 3 and 4 are much improved, great work!\n2)\tI still think Figure 1 is too much space for not a very important point to make, no-one should expect Beta-VAE in its standard form to extract temporal information. It is less problematic now however.\n3)\tFigure 5 is now clearer, thanks. Figure 4 is nicer too, but I\u2019m not extremely sure what point you\u2019re trying to put across with it. Does it inform your choice of beta? It is not clear from reading the text.\n4)\tI think your results on the Sprites dataset are really promising, and actually fit the paper much better than your previous Gripper experiment. They do seem early though, so I\u2019d recommend continuing on them, and try to give a better overview of the effect of the latents, and of which levels of \u201csemantic factors\u201d are captured by the different ladder levels. I think with some work and clean up they could make really strong points.\n5)\tRelated to that, I think it is still unclear in the current version exactly what is the effect/responsibilities of each ladder layer. Fig 7 goes in the good direction, but I was confused by Table 2 in Appendix B, it does not really tell a simple story of \u201chighest/slowest ladder controls the longer-term/constant factors, vs lowest ladder controls the details of the trajectory\u201d. At least the text does not currently express that simply.\n\nOverall, I think this is a nice contribution, but it would still use some more work to get it to an appropriate level for publication."}, "signatures": ["ICLR.cc/2019/Conference/Paper158/AnonReviewer2"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper158/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper158/AnonReviewer2", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "FAVAE: SEQUENCE DISENTANGLEMENT USING IN- FORMATION BOTTLENECK PRINCIPLE", "abstract": "A state-of-the-art generative model, a \u201dfactorized action variational autoencoder (FAVAE),\u201d is presented for learning disentangled and interpretable representations from sequential data via the information bottleneck without supervision. The purpose of disentangled representation learning is to obtain interpretable and transferable representations from data. We focused on the disentangled representation of sequential data because there is a wide range of potential applications if disentanglement representation is extended to sequential data such as video, speech, and stock price data. Sequential data is characterized by dynamic factors and static factors: dynamic factors are time-dependent, and static factors are independent of time. Previous works succeed in disentangling static factors and dynamic factors by explicitly modeling the priors of latent variables to distinguish between static and dynamic factors. However, this model can not disentangle representations between dynamic factors, such as disentangling \u201dpicking\u201d and \u201dthrowing\u201d in robotic tasks. In this paper, we propose new model that can disentangle multiple dynamic factors. Since our method does not require modeling priors, it is capable of disentangling \u201dbetween\u201d dynamic factors. In experiments, we show that FAVAE can extract the disentangled dynamic factors.", "keywords": ["disentangled representation learning"], "authorids": ["yamada0224@gmail.com", "h-kim@isi.imi.i.u-tokyo.ac.jp", "miyoshi@narr.jp", "hiroshi_yamakawa@dwango.co.jp"], "authors": ["Masanori Yamada", "Kim Heecheol", "Kosuke Miyoshi", "Hiroshi Yamakawa"], "TL;DR": "We propose new model that can disentangle multiple dynamic factors in sequential data", "pdf": "/pdf/a004e4cd56b0a7d6abe227b276f3fcf920f51763.pdf", "paperhash": "yamada|favae_sequence_disentanglement_using_in_formation_bottleneck_principle", "_bibtex": "@misc{\nyamada2019favae,\ntitle={{FAVAE}: {SEQUENCE} {DISENTANGLEMENT} {USING} {IN}- {FORMATION} {BOTTLENECK} {PRINCIPLE}},\nauthor={Masanori Yamada and Kim Heecheol and Kosuke Miyoshi and Hiroshi Yamakawa},\nyear={2019},\nurl={https://openreview.net/forum?id=Hygm8jC9FQ},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper158/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621611696, "tddate": null, "super": null, "final": null, "reply": {"forum": "Hygm8jC9FQ", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper158/Authors", "ICLR.cc/2019/Conference/Paper158/Reviewers", "ICLR.cc/2019/Conference/Paper158/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper158/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper158/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper158/Authors|ICLR.cc/2019/Conference/Paper158/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper158/Reviewers", "ICLR.cc/2019/Conference/Paper158/Authors", "ICLR.cc/2019/Conference/Paper158/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621611696}}}, {"id": "SygiuCX8Rm", "original": null, "number": 5, "cdate": 1543024242715, "ddate": null, "tcdate": 1543024242715, "tmdate": 1543024385462, "tddate": null, "forum": "Hygm8jC9FQ", "replyto": "SkxgX2bKpQ", "invitation": "ICLR.cc/2019/Conference/-/Paper158/Official_Comment", "content": {"title": "Reply common questions to all reviewers[2]", "comment": "> 1. On the concern that the baseline model is weak.\n> We will update the Table1 by using FHVAE model.\n\nWe added FHVAE baseline comparison in Appendix C.\nFor 2D Reacing, FHVAE shows better MIG result with large error and in 2D Wavy Reaching FAVAE showed better MIG result than FHVAE even without label supervision input.\n\n> 2. About experiments on more complicated data sets as video.\n> We are experimenting with the recommended Sprites data set, used in (Li and Mandt 2018). \n\nWe added experiment with Sprites dataset as recomended. While this dataset has several motions, they are not composed of multiple explicit dynamic factors. This dataset was used for extracting disentangled representation between static factors and dynamic factors in the Sprites dataset, used in (Li and Mandt 2018). We confirmed that our model can disentangle static and dynamic factors using this dataset.\n\n> 3. About a role of ladder network\n> We will add results to check that the Ladder network is doing different abstraction of time.\n\nWe confirmed how FAVAE acquires disentangled representations at different levels of abstraction and added the results in Appendex B.\nThe factor like goal position tends to appear in ladder3 and factor like trajectory shape tends to appear in ladder 1 and 2."}, "signatures": ["ICLR.cc/2019/Conference/Paper158/Authors"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper158/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper158/Authors", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "FAVAE: SEQUENCE DISENTANGLEMENT USING IN- FORMATION BOTTLENECK PRINCIPLE", "abstract": "A state-of-the-art generative model, a \u201dfactorized action variational autoencoder (FAVAE),\u201d is presented for learning disentangled and interpretable representations from sequential data via the information bottleneck without supervision. The purpose of disentangled representation learning is to obtain interpretable and transferable representations from data. We focused on the disentangled representation of sequential data because there is a wide range of potential applications if disentanglement representation is extended to sequential data such as video, speech, and stock price data. Sequential data is characterized by dynamic factors and static factors: dynamic factors are time-dependent, and static factors are independent of time. Previous works succeed in disentangling static factors and dynamic factors by explicitly modeling the priors of latent variables to distinguish between static and dynamic factors. However, this model can not disentangle representations between dynamic factors, such as disentangling \u201dpicking\u201d and \u201dthrowing\u201d in robotic tasks. In this paper, we propose new model that can disentangle multiple dynamic factors. Since our method does not require modeling priors, it is capable of disentangling \u201dbetween\u201d dynamic factors. In experiments, we show that FAVAE can extract the disentangled dynamic factors.", "keywords": ["disentangled representation learning"], "authorids": ["yamada0224@gmail.com", "h-kim@isi.imi.i.u-tokyo.ac.jp", "miyoshi@narr.jp", "hiroshi_yamakawa@dwango.co.jp"], "authors": ["Masanori Yamada", "Kim Heecheol", "Kosuke Miyoshi", "Hiroshi Yamakawa"], "TL;DR": "We propose new model that can disentangle multiple dynamic factors in sequential data", "pdf": "/pdf/a004e4cd56b0a7d6abe227b276f3fcf920f51763.pdf", "paperhash": "yamada|favae_sequence_disentanglement_using_in_formation_bottleneck_principle", "_bibtex": "@misc{\nyamada2019favae,\ntitle={{FAVAE}: {SEQUENCE} {DISENTANGLEMENT} {USING} {IN}- {FORMATION} {BOTTLENECK} {PRINCIPLE}},\nauthor={Masanori Yamada and Kim Heecheol and Kosuke Miyoshi and Hiroshi Yamakawa},\nyear={2019},\nurl={https://openreview.net/forum?id=Hygm8jC9FQ},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper158/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621611696, "tddate": null, "super": null, "final": null, "reply": {"forum": "Hygm8jC9FQ", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper158/Authors", "ICLR.cc/2019/Conference/Paper158/Reviewers", "ICLR.cc/2019/Conference/Paper158/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper158/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper158/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper158/Authors|ICLR.cc/2019/Conference/Paper158/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper158/Reviewers", "ICLR.cc/2019/Conference/Paper158/Authors", "ICLR.cc/2019/Conference/Paper158/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621611696}}}, {"id": "SkxgX2bKpQ", "original": null, "number": 1, "cdate": 1542163479588, "ddate": null, "tcdate": 1542163479588, "tmdate": 1542612725953, "tddate": null, "forum": "Hygm8jC9FQ", "replyto": "Hygm8jC9FQ", "invitation": "ICLR.cc/2019/Conference/-/Paper158/Official_Comment", "content": {"title": "Reply common questions to all reviewers[1]", "comment": "Thank you for a lot of constructive comments. We want to provide information as much as possible.\n\n1. On the concern that the baseline model is weak.\n\nWe will update the Table1 by using FHVAE model.\nIt was not possible to disentangle in 2D Reaching and 2D wavy using Baseline. This is because lstm is used in the model of FHVAE and it can not learn a very long sequence length (sequence length 1000).\n\nFor a fair comparison with the baseline we are re-experimenting on Table 1 with 2D Reaching (sequence length 100), 2 Dwavy (sequence length 100). Note that the optimal hyperparameter of FAVAE also changed in sequence length 100, so it will be described in the Appendix.\n\n\n2. About experiments on more complicated data sets as video.\n\nWe are experimenting with the recommended Sprites data set, used in (Li and Mandt 2018). We'd like to add results if we can make it in time.\n\n3. About a role of ladder network\n\nWe will add results to check that the Ladder network is doing different abstraction of time. \n\n4. About MIE metric.\n\nWe introduced MIE to avoid the problem that MIG becomes very low value when one factor is decomposed into two latent variables. This is because MIG measures only the difference between the top two latent variables with the highest mutual information. But in our experiment MIG did not have any problem now so wel deleted the MIE section for space."}, "signatures": ["ICLR.cc/2019/Conference/Paper158/Authors"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper158/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper158/Authors", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "FAVAE: SEQUENCE DISENTANGLEMENT USING IN- FORMATION BOTTLENECK PRINCIPLE", "abstract": "A state-of-the-art generative model, a \u201dfactorized action variational autoencoder (FAVAE),\u201d is presented for learning disentangled and interpretable representations from sequential data via the information bottleneck without supervision. The purpose of disentangled representation learning is to obtain interpretable and transferable representations from data. We focused on the disentangled representation of sequential data because there is a wide range of potential applications if disentanglement representation is extended to sequential data such as video, speech, and stock price data. Sequential data is characterized by dynamic factors and static factors: dynamic factors are time-dependent, and static factors are independent of time. Previous works succeed in disentangling static factors and dynamic factors by explicitly modeling the priors of latent variables to distinguish between static and dynamic factors. However, this model can not disentangle representations between dynamic factors, such as disentangling \u201dpicking\u201d and \u201dthrowing\u201d in robotic tasks. In this paper, we propose new model that can disentangle multiple dynamic factors. Since our method does not require modeling priors, it is capable of disentangling \u201dbetween\u201d dynamic factors. In experiments, we show that FAVAE can extract the disentangled dynamic factors.", "keywords": ["disentangled representation learning"], "authorids": ["yamada0224@gmail.com", "h-kim@isi.imi.i.u-tokyo.ac.jp", "miyoshi@narr.jp", "hiroshi_yamakawa@dwango.co.jp"], "authors": ["Masanori Yamada", "Kim Heecheol", "Kosuke Miyoshi", "Hiroshi Yamakawa"], "TL;DR": "We propose new model that can disentangle multiple dynamic factors in sequential data", "pdf": "/pdf/a004e4cd56b0a7d6abe227b276f3fcf920f51763.pdf", "paperhash": "yamada|favae_sequence_disentanglement_using_in_formation_bottleneck_principle", "_bibtex": "@misc{\nyamada2019favae,\ntitle={{FAVAE}: {SEQUENCE} {DISENTANGLEMENT} {USING} {IN}- {FORMATION} {BOTTLENECK} {PRINCIPLE}},\nauthor={Masanori Yamada and Kim Heecheol and Kosuke Miyoshi and Hiroshi Yamakawa},\nyear={2019},\nurl={https://openreview.net/forum?id=Hygm8jC9FQ},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper158/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621611696, "tddate": null, "super": null, "final": null, "reply": {"forum": "Hygm8jC9FQ", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper158/Authors", "ICLR.cc/2019/Conference/Paper158/Reviewers", "ICLR.cc/2019/Conference/Paper158/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper158/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper158/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper158/Authors|ICLR.cc/2019/Conference/Paper158/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper158/Reviewers", "ICLR.cc/2019/Conference/Paper158/Authors", "ICLR.cc/2019/Conference/Paper158/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621611696}}}, {"id": "BJg64TbKpQ", "original": null, "number": 4, "cdate": 1542163764519, "ddate": null, "tcdate": 1542163764519, "tmdate": 1542172904497, "tddate": null, "forum": "Hygm8jC9FQ", "replyto": "ryxaDZN9n7", "invitation": "ICLR.cc/2019/Conference/-/Paper158/Official_Comment", "content": {"title": "Reply to Reviewer 3", "comment": "\n1. > Equation 7 presents a model that seems to have only a latent variable z without time dependence, but how can dynamic and static factors be separately controlled?\n\nSince x_1: T is encoded in z, compress both static factors and dynamic factors to z. Total correlation of z decreases according to 2nd term of eq.5. That is, z is pressured to become independent. If the dynamic factor and the static factor are independent, it is possible to separate the static factor and the dynamic factor. Since FAVAE is automatically separated by pressure, separation cannot be controlled, but there is a merit that there is no need to give label information like FHVAE.\n\n2. We reply common to all reviewers: comment 1 and 2."}, "signatures": ["ICLR.cc/2019/Conference/Paper158/Authors"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper158/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper158/Authors", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "FAVAE: SEQUENCE DISENTANGLEMENT USING IN- FORMATION BOTTLENECK PRINCIPLE", "abstract": "A state-of-the-art generative model, a \u201dfactorized action variational autoencoder (FAVAE),\u201d is presented for learning disentangled and interpretable representations from sequential data via the information bottleneck without supervision. The purpose of disentangled representation learning is to obtain interpretable and transferable representations from data. We focused on the disentangled representation of sequential data because there is a wide range of potential applications if disentanglement representation is extended to sequential data such as video, speech, and stock price data. Sequential data is characterized by dynamic factors and static factors: dynamic factors are time-dependent, and static factors are independent of time. Previous works succeed in disentangling static factors and dynamic factors by explicitly modeling the priors of latent variables to distinguish between static and dynamic factors. However, this model can not disentangle representations between dynamic factors, such as disentangling \u201dpicking\u201d and \u201dthrowing\u201d in robotic tasks. In this paper, we propose new model that can disentangle multiple dynamic factors. Since our method does not require modeling priors, it is capable of disentangling \u201dbetween\u201d dynamic factors. In experiments, we show that FAVAE can extract the disentangled dynamic factors.", "keywords": ["disentangled representation learning"], "authorids": ["yamada0224@gmail.com", "h-kim@isi.imi.i.u-tokyo.ac.jp", "miyoshi@narr.jp", "hiroshi_yamakawa@dwango.co.jp"], "authors": ["Masanori Yamada", "Kim Heecheol", "Kosuke Miyoshi", "Hiroshi Yamakawa"], "TL;DR": "We propose new model that can disentangle multiple dynamic factors in sequential data", "pdf": "/pdf/a004e4cd56b0a7d6abe227b276f3fcf920f51763.pdf", "paperhash": "yamada|favae_sequence_disentanglement_using_in_formation_bottleneck_principle", "_bibtex": "@misc{\nyamada2019favae,\ntitle={{FAVAE}: {SEQUENCE} {DISENTANGLEMENT} {USING} {IN}- {FORMATION} {BOTTLENECK} {PRINCIPLE}},\nauthor={Masanori Yamada and Kim Heecheol and Kosuke Miyoshi and Hiroshi Yamakawa},\nyear={2019},\nurl={https://openreview.net/forum?id=Hygm8jC9FQ},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper158/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621611696, "tddate": null, "super": null, "final": null, "reply": {"forum": "Hygm8jC9FQ", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper158/Authors", "ICLR.cc/2019/Conference/Paper158/Reviewers", "ICLR.cc/2019/Conference/Paper158/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper158/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper158/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper158/Authors|ICLR.cc/2019/Conference/Paper158/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper158/Reviewers", "ICLR.cc/2019/Conference/Paper158/Authors", "ICLR.cc/2019/Conference/Paper158/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621611696}}}, {"id": "HJl_zTbtaQ", "original": null, "number": 3, "cdate": 1542163727532, "ddate": null, "tcdate": 1542163727532, "tmdate": 1542172896157, "tddate": null, "forum": "Hygm8jC9FQ", "replyto": "Syl0S_Iihm", "invitation": "ICLR.cc/2019/Conference/-/Paper158/Official_Comment", "content": {"title": "Reply to Reviewer 2", "comment": "\n1) We reply common to all reviewers: comment 1. We show Fig. 1 and 3 to clarify that the FAVAE extract disentangled representations and beta-VAE extract disentangled representations are different. The baseline model in quantitative evaluation experiment is compared with sequential model(Time convolution AE).\n2) reply common to all reviewers:1. \n3) > The main point you want to put across is that you want to have your \u201cz\u201d compress a full trajectory x_1:T, under a single KL pressure (i.e. last sentence of Section 4).\n\nWe agree with the advice. We will modify for space.\n\n4) Since sample trajectory is confusing, we will delete it in Fig. 3.\n5) Thank you for pointing out the mistake. We modified eq. 15. Our model does not use causal convolution, 1D convolution is used. The reason why Causal convolution is not used is because 1D conv is reasonable as it can use the information of the previous and subsequent time steps. Also we do not need to use x_t for recurrent at generation, so we can use without causal convolution.\n\n6) We use the value such as position in Gripper dataset, not the image. We added information on Gripper input x to Appendix B.2. We should clarify that there is a difference between the image and position input, so we added to Sec. 7.3 that we don't use images as input.\n7) Yes, The scheduling c is originally proposed in Burgess et al 2018. We linear scheduling from 0 to target c as [20,1,5] in 10000 step (all experiments same). We used the same C in the same ladder(e.g. 1st ladder has 8 z dimension, it's c=20. 2nd ladder has 4 z dimension, it's c=1, 3rd ladder has 2 z dimension, it's c=5) \n8) We reply common to all reviewers: comment 4.\n9) We improve the cation in Fig. 7.\n10) C is an indicator of how much information is left when compressing data. Since 2D Reaching was small in dataset information, the optimum value of C was almost 0. So for simple data FAVAE will be not bad results with C = 0.\n11) We reply common to all reviewers: comment 3.\n12) Does it mean that it is easier to understand by plotting in detail about \u03b2 = 100 in Fig. 4B?\n13) Added explanation of factor of 2D wavy Reaching dataset in Fig. 5.\n14) > Figure 6 MIE scores look all within noise between models considered. How sensitive is the metric to actual differences in the disentanglement?\nIn Fig. 6, only at higher ladder 1 have large error case (there was a case like loss> 57 although loss = 0.8 in general). We show the average of loss and MIG in each case (7 out of 10 succeeded). \n\n||loss|MIG|\n|:--:|:--:|:--:|\n|success(7)|0.85|0.17|\n|fail(3)|57.3|0.071239|"}, "signatures": ["ICLR.cc/2019/Conference/Paper158/Authors"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper158/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper158/Authors", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "FAVAE: SEQUENCE DISENTANGLEMENT USING IN- FORMATION BOTTLENECK PRINCIPLE", "abstract": "A state-of-the-art generative model, a \u201dfactorized action variational autoencoder (FAVAE),\u201d is presented for learning disentangled and interpretable representations from sequential data via the information bottleneck without supervision. The purpose of disentangled representation learning is to obtain interpretable and transferable representations from data. We focused on the disentangled representation of sequential data because there is a wide range of potential applications if disentanglement representation is extended to sequential data such as video, speech, and stock price data. Sequential data is characterized by dynamic factors and static factors: dynamic factors are time-dependent, and static factors are independent of time. Previous works succeed in disentangling static factors and dynamic factors by explicitly modeling the priors of latent variables to distinguish between static and dynamic factors. However, this model can not disentangle representations between dynamic factors, such as disentangling \u201dpicking\u201d and \u201dthrowing\u201d in robotic tasks. In this paper, we propose new model that can disentangle multiple dynamic factors. Since our method does not require modeling priors, it is capable of disentangling \u201dbetween\u201d dynamic factors. In experiments, we show that FAVAE can extract the disentangled dynamic factors.", "keywords": ["disentangled representation learning"], "authorids": ["yamada0224@gmail.com", "h-kim@isi.imi.i.u-tokyo.ac.jp", "miyoshi@narr.jp", "hiroshi_yamakawa@dwango.co.jp"], "authors": ["Masanori Yamada", "Kim Heecheol", "Kosuke Miyoshi", "Hiroshi Yamakawa"], "TL;DR": "We propose new model that can disentangle multiple dynamic factors in sequential data", "pdf": "/pdf/a004e4cd56b0a7d6abe227b276f3fcf920f51763.pdf", "paperhash": "yamada|favae_sequence_disentanglement_using_in_formation_bottleneck_principle", "_bibtex": "@misc{\nyamada2019favae,\ntitle={{FAVAE}: {SEQUENCE} {DISENTANGLEMENT} {USING} {IN}- {FORMATION} {BOTTLENECK} {PRINCIPLE}},\nauthor={Masanori Yamada and Kim Heecheol and Kosuke Miyoshi and Hiroshi Yamakawa},\nyear={2019},\nurl={https://openreview.net/forum?id=Hygm8jC9FQ},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper158/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621611696, "tddate": null, "super": null, "final": null, "reply": {"forum": "Hygm8jC9FQ", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper158/Authors", "ICLR.cc/2019/Conference/Paper158/Reviewers", "ICLR.cc/2019/Conference/Paper158/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper158/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper158/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper158/Authors|ICLR.cc/2019/Conference/Paper158/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper158/Reviewers", "ICLR.cc/2019/Conference/Paper158/Authors", "ICLR.cc/2019/Conference/Paper158/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621611696}}}, {"id": "S1eQKn-K6Q", "original": null, "number": 2, "cdate": 1542163579251, "ddate": null, "tcdate": 1542163579251, "tmdate": 1542172878069, "tddate": null, "forum": "Hygm8jC9FQ", "replyto": "rkgGc0nah7", "invitation": "ICLR.cc/2019/Conference/-/Paper158/Official_Comment", "content": {"title": "Reply to Reviewer 1", "comment": "\n1) We would like to compare with LSTM and GRU case, but we failed to reconsturct timeseries data with recurrent neural network, so we could not make meaningful comparison.\nThe reason for using time convolution is to combine several models with ladder + time conversion + CCI-VAE or beta-VAE, so we want to simplify time series processing.\n\n2) We reply common to all reviewers: comment 4.\n3) We reply common to all reviewers: comment 2.\n4) We reply common to all reviewers: comment 3.\n5) We agree with the opinion that it is important to estimate the effects of beta, c and ladder individually. We add beta=1, C=0 case in Table 1.\n6) We add information of standard error in Table1 (the number of seed is 10). Unfortunately, we could not discuss statistically significant differences here.\n7) Added explanation of factor of 2D wavy Reaching dataset in Fig. 5.\n8) Does it mean that it is easier to understand by plotting in detail about \u03b2 = 100 in Fig. 4B?\nWe used logarithmic scales because we wanted to claim the result that reconstruction worsens as \u03b2 is increased and MIG worsens as a result, unless c is adjusted to the optimum value. If the figure on the linear scale near \u03b2 = 100 is better, update Fig. 4B (Should we also update fig 4A?)."}, "signatures": ["ICLR.cc/2019/Conference/Paper158/Authors"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper158/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper158/Authors", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "FAVAE: SEQUENCE DISENTANGLEMENT USING IN- FORMATION BOTTLENECK PRINCIPLE", "abstract": "A state-of-the-art generative model, a \u201dfactorized action variational autoencoder (FAVAE),\u201d is presented for learning disentangled and interpretable representations from sequential data via the information bottleneck without supervision. The purpose of disentangled representation learning is to obtain interpretable and transferable representations from data. We focused on the disentangled representation of sequential data because there is a wide range of potential applications if disentanglement representation is extended to sequential data such as video, speech, and stock price data. Sequential data is characterized by dynamic factors and static factors: dynamic factors are time-dependent, and static factors are independent of time. Previous works succeed in disentangling static factors and dynamic factors by explicitly modeling the priors of latent variables to distinguish between static and dynamic factors. However, this model can not disentangle representations between dynamic factors, such as disentangling \u201dpicking\u201d and \u201dthrowing\u201d in robotic tasks. In this paper, we propose new model that can disentangle multiple dynamic factors. Since our method does not require modeling priors, it is capable of disentangling \u201dbetween\u201d dynamic factors. In experiments, we show that FAVAE can extract the disentangled dynamic factors.", "keywords": ["disentangled representation learning"], "authorids": ["yamada0224@gmail.com", "h-kim@isi.imi.i.u-tokyo.ac.jp", "miyoshi@narr.jp", "hiroshi_yamakawa@dwango.co.jp"], "authors": ["Masanori Yamada", "Kim Heecheol", "Kosuke Miyoshi", "Hiroshi Yamakawa"], "TL;DR": "We propose new model that can disentangle multiple dynamic factors in sequential data", "pdf": "/pdf/a004e4cd56b0a7d6abe227b276f3fcf920f51763.pdf", "paperhash": "yamada|favae_sequence_disentanglement_using_in_formation_bottleneck_principle", "_bibtex": "@misc{\nyamada2019favae,\ntitle={{FAVAE}: {SEQUENCE} {DISENTANGLEMENT} {USING} {IN}- {FORMATION} {BOTTLENECK} {PRINCIPLE}},\nauthor={Masanori Yamada and Kim Heecheol and Kosuke Miyoshi and Hiroshi Yamakawa},\nyear={2019},\nurl={https://openreview.net/forum?id=Hygm8jC9FQ},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper158/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621611696, "tddate": null, "super": null, "final": null, "reply": {"forum": "Hygm8jC9FQ", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper158/Authors", "ICLR.cc/2019/Conference/Paper158/Reviewers", "ICLR.cc/2019/Conference/Paper158/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper158/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper158/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper158/Authors|ICLR.cc/2019/Conference/Paper158/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper158/Reviewers", "ICLR.cc/2019/Conference/Paper158/Authors", "ICLR.cc/2019/Conference/Paper158/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621611696}}}, {"id": "rkgGc0nah7", "original": null, "number": 3, "cdate": 1541422729582, "ddate": null, "tcdate": 1541422729582, "tmdate": 1541534234399, "tddate": null, "forum": "Hygm8jC9FQ", "replyto": "Hygm8jC9FQ", "invitation": "ICLR.cc/2019/Conference/-/Paper158/Official_Review", "content": {"title": "Good potential but needs more work", "review": "This paper presents a new approach to learning disentangled representations of sequential data. The model, FAVAE, is based on the information bottleneck framework (Alemi et al, 2016; Achille et al, 2016) and extends the recent beta-VAE (Higgins et al, 2017) and CCI-VAE (Burgess et al, 2017) work by changing the encoder/decoder to a Quasi-Recurrent Neural Network (QRNN) and adding multiple latents through a ladder VAE approach (Zhao et al, 2017). The authors demonstrate that their approach is able to learn a more disentangled representation than the limited set of baselines on three toy datasets.\n\nThe authors address a very important problem, since the ability to learn disentangled representations of sequential data can have far reaching consequences, as the authors rightfully point out in their introduction. I also like the approach that the authors are taking, which appears to be very general and does not seem to involve the need to have any domain knowledge. However, the paper could be improved by clarifying certain key parts and extending the experimental section, which is currently not quite as convincing as I would have hoped.\n\nThe summary of my concerns is the following: \n\nI would like to see more baseline comparisons 1) to an FAVAE with a different recurrent encoder/decoder; 2) to at least one other approach to disentangled representation learning on sequences; 3) an FAVAE without the capacity increase. I would also like to see all the baselines run on a non toy dataset of video data. Finally, I would like to see an expanded discussion of what the different latent variables at the different levels of the ladder architecture are learning. I recommend that the authors remove the MIE metric and shorten Section 3 to make space for the expanded experiments section.\n\nI do hope that the authors are able to address my concerns, because their method has a lot of potential and I am excited to see where they take it during the rebuttal period. Please see the more detailed comments below:\n\n1) Section 4.2 should be expanded to include a more detailed description of QRNN. This is one of the key modifications of FAVAE compared to CCI-VAE or beta-VAE, and it is currently not clear how QRNN works unless one reads the original paper referenced. The current paper needs to be self contained. It would also be nice to get a better understanding why QRNN was chosen over an LSTM or a GRU. It would be useful to see the results of the baseline experiments with an LSTM compared to the equivalent QRNN-based version of FAVAE.\n\n2) Why do the authors introduce the new MIE metric? The reported results do not show a significant problem with the MIG metric, and the need for the new MIE metric is not well motivated. If the authors insist on introducing this new metric, it is important to demonstrate cases where MIG fails and MIE performs better. Otherwise I would advise removing the new metric and using the space to expand section 4.2 instead. \n\nAnother point on the metric, Eq. 16 seems to be missing a term that goes over latents z_j. I assume there should be either a max_j or a mean_j in front of the I(z_j; v_k) term in the first part of Eq. 16?\n\n3) The related work section should be re-worded. Currently it reads as if the other approaches do not optimise a loss function at all. It would also be good to include one of the mentioned models as a baseline, and to run both FAVAE and one of the previously introduced models for disentangled sequential representation learning on a more complex dataset of video data.\n\n4) In section 7.1, it would be good to expand the discussion of how latent traversal plots are obtained. In particular, I do not understand how the different latent variables in the ladder architecture of FAVAE are traversed. In general, it would also be nice to expand the discussion of what the different latents at the different ladder stages learn, and how the number of ladder stages affects the nature of learnt representations.\n\n5) In terms of the baselines, it would be good to see the full ablation study. The way I see it, FAVAE has three modifications on the standard variational approaches: 1) the use of a recurrent encoder/decoder (R); 2) the use of the ladder architecture (L); and 3) the use of the capacity constraint objective (C). Currently the authors show the results of the R--, R-C, and RLC conditions. I would also like to see the results of the RL- condition (where beta=1 and C=0).\n\n6) In terms of the results presented in Tbl. 1, it would be nice to include the hyperparameters that the authors have swept over in the appendix, as well as a table of the architecture parameters and the best hyperparameters found for the models presented in the Experiments section. In Tbl.1 it is currently unclear how many seeds the authors used to calculate the standard deviations. The units of the standard deviations presented are also not clear. Finally, it is not clear whether the differences presented in the table are significant.\n\n7) It would be useful to include some details of the 2D Wavy Reaching dataset in the main text, even if it is just listing the nature of the 5 factors.\n\n8) It would be useful to expand the section that talks about the different settings of C explored (page 7, paragraph 2). Currently the point that the authors are trying to make in that paragraph and Fig. 4 is not clear. I would also recommend having beta in Fig. 4 on linear rather than log scale, as the log scale seems to be somewhat confusing.\n\n\n\n\nMinor points:\n\n-- Page 2/paragraph 2: used disentangle -> used to disentangle\n-- P4/p5: FAVAE is disentangled representation -> is for(?) disentangled representation\n-- P6/p1: the priors time dependency -> the priors' time dependency\n-- P7/p1: scores for2D -> scores for 2D\n-- P7/p4: MIE score (gray curve) -> MIE score (green(?) curve)", "rating": "5: Marginally below acceptance threshold", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["ICLR.cc/2019/Conference/Paper158/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "FAVAE: SEQUENCE DISENTANGLEMENT USING IN- FORMATION BOTTLENECK PRINCIPLE", "abstract": "A state-of-the-art generative model, a \u201dfactorized action variational autoencoder (FAVAE),\u201d is presented for learning disentangled and interpretable representations from sequential data via the information bottleneck without supervision. The purpose of disentangled representation learning is to obtain interpretable and transferable representations from data. We focused on the disentangled representation of sequential data because there is a wide range of potential applications if disentanglement representation is extended to sequential data such as video, speech, and stock price data. Sequential data is characterized by dynamic factors and static factors: dynamic factors are time-dependent, and static factors are independent of time. Previous works succeed in disentangling static factors and dynamic factors by explicitly modeling the priors of latent variables to distinguish between static and dynamic factors. However, this model can not disentangle representations between dynamic factors, such as disentangling \u201dpicking\u201d and \u201dthrowing\u201d in robotic tasks. In this paper, we propose new model that can disentangle multiple dynamic factors. Since our method does not require modeling priors, it is capable of disentangling \u201dbetween\u201d dynamic factors. In experiments, we show that FAVAE can extract the disentangled dynamic factors.", "keywords": ["disentangled representation learning"], "authorids": ["yamada0224@gmail.com", "h-kim@isi.imi.i.u-tokyo.ac.jp", "miyoshi@narr.jp", "hiroshi_yamakawa@dwango.co.jp"], "authors": ["Masanori Yamada", "Kim Heecheol", "Kosuke Miyoshi", "Hiroshi Yamakawa"], "TL;DR": "We propose new model that can disentangle multiple dynamic factors in sequential data", "pdf": "/pdf/a004e4cd56b0a7d6abe227b276f3fcf920f51763.pdf", "paperhash": "yamada|favae_sequence_disentanglement_using_in_formation_bottleneck_principle", "_bibtex": "@misc{\nyamada2019favae,\ntitle={{FAVAE}: {SEQUENCE} {DISENTANGLEMENT} {USING} {IN}- {FORMATION} {BOTTLENECK} {PRINCIPLE}},\nauthor={Masanori Yamada and Kim Heecheol and Kosuke Miyoshi and Hiroshi Yamakawa},\nyear={2019},\nurl={https://openreview.net/forum?id=Hygm8jC9FQ},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper158/Official_Review", "cdate": 1542234525261, "expdate": 1552335264000, "duedate": 1541196000000, "reply": {"forum": "Hygm8jC9FQ", "replyto": "Hygm8jC9FQ", "readers": {"description": "The users who will be allowed to read the reply content.", "values": ["everyone"]}, "nonreaders": {"values": []}, "signatures": {"description": "How your identity will be displayed with the above content.", "values-regex": "ICLR.cc/2019/Conference/Paper158/AnonReviewer[0-9]+"}, "writers": {"description": "Users that may modify this record.", "values": ["ICLR.cc/2019/Conference"]}, "content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "required": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}}, "multiReply": false, "tcdate": 1552335661774, "tmdate": 1552335661774, "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "invitees": ["ICLR.cc/2019/Conference/Paper158/Reviewers"], "noninvitees": [], "signatures": ["ICLR.cc/2019/Conference"]}}}, {"id": "Syl0S_Iihm", "original": null, "number": 2, "cdate": 1541265478272, "ddate": null, "tcdate": 1541265478272, "tmdate": 1541534234167, "tddate": null, "forum": "Hygm8jC9FQ", "replyto": "Hygm8jC9FQ", "invitation": "ICLR.cc/2019/Conference/-/Paper158/Official_Review", "content": {"title": "Interesting and valuable model extension, but with rather early results", "review": "This paper proposes an extension to VAE to model sequential datasets and extract disentangled representations of their evolution.\nIt consists of a straight extension of CCI-VAE (Burgess et al 2018) to accept sequential data, combining it with a Ladder VAE architecture (VLAE, Zhao et al 2017).\nThey show early results on fitting toy domains involving 2D points moving in space (reaching, reaching in sub-sequences with complex dynamics, gripper domain).\n\nOverall, I think this is an interesting piece of work, which proposes a good model extension and assessment of its characteristics. The model is well presented, the different components are sufficiently motivated and they perform just enough experiments to showcase the effectiveness of their method, although with some reservations.\n\nCritics:\n1.\tThe comparison to Beta-VAE is a straw man, and I\u2019m not sure it\u2019s a valid way to introduce your model. You are basically saying that treating sequential data as if it was non-sequential is bad, which is clearly not surprising? Hence any comparison with Beta-VAE that you show, Figure 1 and Figure 3, are not appropriate (the caption of Fig 1 is particularly bad in that aspect). A more correct comparison would be to directly feed x_1:T to a Beta-VAE and see what happens, maybe with a causal time-convolution as well if you want to avoid 3D filters.\n2.\tYou are also not comparing to the FHVAE model you present in your Introduction, which would have been nice to see, given that your model is simpler and requires less supervision. Does FAVAE perform better than these?\n3.\tSection 3 could use a citation to Esmaeili et al 2018, which breaks out the ELBO even further and compares multiple models in a really nice way (e.g. Table A.2). Overall Section 2 and 3 feel a bit long and pedantic, you could just point people to the original papers and move some of the justification to Appendix (e.g. the IB arguments are not that required for your model. ). \u2028The main point you want to put across is that you want to have your \u201cz\u201d compress a full trajectory x_1:T, under a single KL pressure (i.e. last sentence of Section 4).\n4.\tFigure 3 was hard to interpret at first, specifically for panels b and c. Maybe if you showed the \u201csampled trajectory\u201d only once in another plot it would make it clearer.\n5.\tTime-convolution seems to wrongly be using the opposite indexing? With z_tk = \\sum_{p=0}^{H} x_{t+p}, you have an anti-causal filter which looks at the future x_t\u2019 for a z_t? That does not sound right? Also, you should call these \u201ccausal convolutions\u201d, which is the more standard term.\n6.\tThe exact format of the observations was never clearly explained. From 7.1 I understood that you input 2D positions into the models, but what about the Gripper? \u2028As you\u2019re aware, Beta-VAE and others usually get RGB images as inputs, hence you should make that difference rather clear. This is a much simpler setting you\u2019re working in.\n7.\tDid you anneal the C as was originally proposed in Burgess et al 2018? With which schedule? This was not clear to me. The exact choices of C for the different Ladder levels lacked support as well. An overall section in the Appendix about the parameter ranges you tried, the architectures, the observation specifications, the optimisation schedule etc etc would be useful.\n8.\tI appreciate the introduction of the MIE metric, which seems to slightly improve over MIG in a meaningful way. However, it would be good to show situations where the two metrics disagree and why MIE is better, because in the current experiments this is unclear.\n9.\tOverall the Gripper experiments seem to merit a more complete assessment. Figure 7 was hard to understand, and I am not sure it shows clearly any disentangled factors. Its caption was strange too (what are the \u201c(1, 8)\u201d, \u201c(2, 1)\u201d things referring to?). \n10.\tI would have liked more interpretation and comments on why the Ladder is needed, and why FAVAE (without Ladder and C) does so badly in Table 1.\n11.\tIt would be good to know if you really find that the different levels of the Ladder end up extracting different time scales, as you originally claim it can. There are no results supporting this assumption in the current version.\n12.\tFigure 4B uses a bad scale, which makes it hard to assess what happens between the two C conditions for Beta \\approx 100, where they seem to differ the most in Fig 4A.\n13.\tFigure 5 could use titles/labels indicating which \u201cgenerative factors\u201d you think are being represented. Just compare them to your Figure 8 in Appendix.\n14.\tFigure 6 MIE scores look all within noise between models considered. How sensitive is the metric to actual differences in the disentanglement?\n\nOverall, I think this is an interesting improvement to disentangled representations learning, but suffers a bit from early experimental results. I would still like it to be shown at ICLR though as it really fits the venue.\nI'm happy to improve my score given some improvements on the points mentioned above.\n\nReferences:\n-\tBurgess et al., 2018: https://arxiv.org/abs/1804.03599\n-\tZhao et al., 2017: https://arxiv.org/abs/1702.08396 \n-\tEsmaeili et al., 2018: https://arxiv.org/abs/1804.02086 \n", "rating": "6: Marginally above acceptance threshold", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}, "signatures": ["ICLR.cc/2019/Conference/Paper158/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "FAVAE: SEQUENCE DISENTANGLEMENT USING IN- FORMATION BOTTLENECK PRINCIPLE", "abstract": "A state-of-the-art generative model, a \u201dfactorized action variational autoencoder (FAVAE),\u201d is presented for learning disentangled and interpretable representations from sequential data via the information bottleneck without supervision. The purpose of disentangled representation learning is to obtain interpretable and transferable representations from data. We focused on the disentangled representation of sequential data because there is a wide range of potential applications if disentanglement representation is extended to sequential data such as video, speech, and stock price data. Sequential data is characterized by dynamic factors and static factors: dynamic factors are time-dependent, and static factors are independent of time. Previous works succeed in disentangling static factors and dynamic factors by explicitly modeling the priors of latent variables to distinguish between static and dynamic factors. However, this model can not disentangle representations between dynamic factors, such as disentangling \u201dpicking\u201d and \u201dthrowing\u201d in robotic tasks. In this paper, we propose new model that can disentangle multiple dynamic factors. Since our method does not require modeling priors, it is capable of disentangling \u201dbetween\u201d dynamic factors. In experiments, we show that FAVAE can extract the disentangled dynamic factors.", "keywords": ["disentangled representation learning"], "authorids": ["yamada0224@gmail.com", "h-kim@isi.imi.i.u-tokyo.ac.jp", "miyoshi@narr.jp", "hiroshi_yamakawa@dwango.co.jp"], "authors": ["Masanori Yamada", "Kim Heecheol", "Kosuke Miyoshi", "Hiroshi Yamakawa"], "TL;DR": "We propose new model that can disentangle multiple dynamic factors in sequential data", "pdf": "/pdf/a004e4cd56b0a7d6abe227b276f3fcf920f51763.pdf", "paperhash": "yamada|favae_sequence_disentanglement_using_in_formation_bottleneck_principle", "_bibtex": "@misc{\nyamada2019favae,\ntitle={{FAVAE}: {SEQUENCE} {DISENTANGLEMENT} {USING} {IN}- {FORMATION} {BOTTLENECK} {PRINCIPLE}},\nauthor={Masanori Yamada and Kim Heecheol and Kosuke Miyoshi and Hiroshi Yamakawa},\nyear={2019},\nurl={https://openreview.net/forum?id=Hygm8jC9FQ},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper158/Official_Review", "cdate": 1542234525261, "expdate": 1552335264000, "duedate": 1541196000000, "reply": {"forum": "Hygm8jC9FQ", "replyto": "Hygm8jC9FQ", "readers": {"description": "The users who will be allowed to read the reply content.", "values": ["everyone"]}, "nonreaders": {"values": []}, "signatures": {"description": "How your identity will be displayed with the above content.", "values-regex": "ICLR.cc/2019/Conference/Paper158/AnonReviewer[0-9]+"}, "writers": {"description": "Users that may modify this record.", "values": ["ICLR.cc/2019/Conference"]}, "content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "required": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}}, "multiReply": false, "tcdate": 1552335661774, "tmdate": 1552335661774, "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "invitees": ["ICLR.cc/2019/Conference/Paper158/Reviewers"], "noninvitees": [], "signatures": ["ICLR.cc/2019/Conference"]}}}, {"id": "ryxaDZN9n7", "original": null, "number": 1, "cdate": 1541189989362, "ddate": null, "tcdate": 1541189989362, "tmdate": 1541534233926, "tddate": null, "forum": "Hygm8jC9FQ", "replyto": "Hygm8jC9FQ", "invitation": "ICLR.cc/2019/Conference/-/Paper158/Official_Review", "content": {"title": "Interesting, but not clear enough.", "review": "The paper proposes the factorized action variational autoencoder (FAVAE) as a new model for learning disentangled representations in high-dimensional sequences, such as videos. In contrast to earlier work that encouraged disentanglement through a carefully-designed dynamical prior, the authors propose a different encoder-decoder architecture combined with a modified loss function (Beta-VAE with a \u201cshift C scheme\u201d). As a result, the authors claim that their approach leads to useful disentangled representation learning in toy video data, and in data taken from a robotic task.\n\nThe paper appears to combine multiple ideas, which are not cleanly studied in isolation from each other. Several claims may be a bit oversold, such as potential applications for stock price data. But more importantly, the reasons why I don\u2019t recommend accepting the paper are the following ones:\n\nLack of clarity:\nI found that the paper lacks clarity in its presentation. Equation 7 presents a model that seems to have only a latent variable z without time dependence, but how can dynamic and static factors be separately controlled? I don't see this question addressed in the experiments. Also, what is the significance of the model architecture (ladder network) as compared to the modified loss function?  Furthermore, Fig. 7 is hard to read.\n\nLack of Experiments:\nThe currently presented experiments are all on rather simple data. I recommend extending the experiments to the Sprites data set, used in (Li and Mandt 2018), or to speech data. Also, the paper lacks comparisons to the recently proposed disentangled representation learning models (FHVAE and Disentangled Sequential Autoencoder).\n\nWhile it is apparent that the model achieved some clustering, it is unclear to me if the final goal of separately controlling for static and dynamic aspects was really reached.\n", "rating": "4: Ok but not good enough - rejection", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["ICLR.cc/2019/Conference/Paper158/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "FAVAE: SEQUENCE DISENTANGLEMENT USING IN- FORMATION BOTTLENECK PRINCIPLE", "abstract": "A state-of-the-art generative model, a \u201dfactorized action variational autoencoder (FAVAE),\u201d is presented for learning disentangled and interpretable representations from sequential data via the information bottleneck without supervision. The purpose of disentangled representation learning is to obtain interpretable and transferable representations from data. We focused on the disentangled representation of sequential data because there is a wide range of potential applications if disentanglement representation is extended to sequential data such as video, speech, and stock price data. Sequential data is characterized by dynamic factors and static factors: dynamic factors are time-dependent, and static factors are independent of time. Previous works succeed in disentangling static factors and dynamic factors by explicitly modeling the priors of latent variables to distinguish between static and dynamic factors. However, this model can not disentangle representations between dynamic factors, such as disentangling \u201dpicking\u201d and \u201dthrowing\u201d in robotic tasks. In this paper, we propose new model that can disentangle multiple dynamic factors. Since our method does not require modeling priors, it is capable of disentangling \u201dbetween\u201d dynamic factors. In experiments, we show that FAVAE can extract the disentangled dynamic factors.", "keywords": ["disentangled representation learning"], "authorids": ["yamada0224@gmail.com", "h-kim@isi.imi.i.u-tokyo.ac.jp", "miyoshi@narr.jp", "hiroshi_yamakawa@dwango.co.jp"], "authors": ["Masanori Yamada", "Kim Heecheol", "Kosuke Miyoshi", "Hiroshi Yamakawa"], "TL;DR": "We propose new model that can disentangle multiple dynamic factors in sequential data", "pdf": "/pdf/a004e4cd56b0a7d6abe227b276f3fcf920f51763.pdf", "paperhash": "yamada|favae_sequence_disentanglement_using_in_formation_bottleneck_principle", "_bibtex": "@misc{\nyamada2019favae,\ntitle={{FAVAE}: {SEQUENCE} {DISENTANGLEMENT} {USING} {IN}- {FORMATION} {BOTTLENECK} {PRINCIPLE}},\nauthor={Masanori Yamada and Kim Heecheol and Kosuke Miyoshi and Hiroshi Yamakawa},\nyear={2019},\nurl={https://openreview.net/forum?id=Hygm8jC9FQ},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper158/Official_Review", "cdate": 1542234525261, "expdate": 1552335264000, "duedate": 1541196000000, "reply": {"forum": "Hygm8jC9FQ", "replyto": "Hygm8jC9FQ", "readers": {"description": "The users who will be allowed to read the reply content.", "values": ["everyone"]}, "nonreaders": {"values": []}, "signatures": {"description": "How your identity will be displayed with the above content.", "values-regex": "ICLR.cc/2019/Conference/Paper158/AnonReviewer[0-9]+"}, "writers": {"description": "Users that may modify this record.", "values": ["ICLR.cc/2019/Conference"]}, "content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "required": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}}, "multiReply": false, "tcdate": 1552335661774, "tmdate": 1552335661774, "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "invitees": ["ICLR.cc/2019/Conference/Paper158/Reviewers"], "noninvitees": [], "signatures": ["ICLR.cc/2019/Conference"]}}}], "count": 12}