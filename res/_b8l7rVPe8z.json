{"notes": [{"id": "_b8l7rVPe8z", "original": "WAq5cnqjQOJ", "number": 248, "cdate": 1601308036066, "ddate": null, "tcdate": 1601308036066, "tmdate": 1614985703352, "tddate": null, "forum": "_b8l7rVPe8z", "replyto": null, "invitation": "ICLR.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Relevance Attack on Detectors", "authorids": ["~Sizhe_Chen1", "hf-inspire@sjtu.edu.cn", "~Xiaolin_Huang1", "~Kun_Zhang1"], "authors": ["Sizhe Chen", "Fan He", "Xiaolin Huang", "Kun Zhang"], "keywords": ["adversarial attack", "relevance map", "object detection", "transferability", "black-box attack"], "abstract": "This paper focuses on high-transferable adversarial attacks on detectors, which are hard to attack in a black-box manner, because of their multiple-output characteristics and the diversity across architectures. To pursue a high attack transferability, one plausible way is to find a common property across detectors, which facilitates the discovery of common weaknesses. We are the first to suggest that the relevance map for detectors is such a property. Based on it, we design a Relevance Attack on Detectors (RAD), which achieves a state-of-the-art transferability, exceeding existing results by above 20%. On MS COCO, the detection mAPs for all 8 black-box architectures are more than halved and the segmentation mAPs are also significantly influenced. Given the great transferability of RAD, we generate the first adversarial dataset for object detection, i.e., Adversarial Objects in COntext (AOCO), which helps to quickly evaluate and improve the robustness of detectors.", "one-sentence_summary": "We design a Relevance Attack on Detectors, a high-transferable attack framework with the state-of-the-art performance.", "pdf": "/pdf/745d9d6e4d46aa97ba592384bcd8aaa803f38d90.pdf", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "chen|relevance_attack_on_detectors", "supplementary_material": "/attachment/af3b9ac9017f0b304cf44fface903c7950ab9ffc.zip", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=K9mMva6mYW", "_bibtex": "@misc{\nchen2021relevance,\ntitle={Relevance Attack on Detectors},\nauthor={Sizhe Chen and Fan He and Xiaolin Huang and Kun Zhang},\nyear={2021},\nurl={https://openreview.net/forum?id=_b8l7rVPe8z}\n}"}, "signatures": ["ICLR.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference"], "details": {"replyCount": 12, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"reply": {"readers": {"values-regex": ".*"}, "writers": {"values": ["ICLR.cc/2021/Conference"]}, "signatures": {"values": ["ICLR.cc/2021/Conference"]}, "content": {"authors": {"values": ["Anonymous"]}, "authorids": {"values-regex": ".*"}, "reviewed_version_(pdf)": {"required": false, "description": "Upload a PDF file that ends with .pdf", "value-regex": ".*"}}}, "signatures": ["ICLR.cc/2021/Conference"], "readers": ["everyone"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["~", "OpenReview.net/Support"], "tcdate": 1601308008205, "tmdate": 1614984599368, "id": "ICLR.cc/2021/Conference/-/Blind_Submission"}}, "tauthor": "OpenReview.net"}, {"id": "kC5dD21qBI", "original": null, "number": 1, "cdate": 1610040441123, "ddate": null, "tcdate": 1610040441123, "tmdate": 1610474042121, "tddate": null, "forum": "_b8l7rVPe8z", "replyto": "_b8l7rVPe8z", "invitation": "ICLR.cc/2021/Conference/Paper248/-/Decision", "content": {"title": "Final Decision", "decision": "Reject", "comment": "This paper proposes a transferable adversarial attack method for object detection by using the relevance map. Four reviewers provided detailed reviews: 2 of them rated \u201cOk but not good enough - rejection\u201d, 1 rated \u201cMarginally below\u201d and 1 rated \u201cMarginally above\u201d. While reviewers consider the paper well written and using relevance map novel, a number of concerns are raised, including limited novelty, the lack of theoretical results, no use of the proposed dataset, insufficient ablation, etc. During the rebuttal, the authors made efforts to response to all reviewers\u2019 comments. However, the major concerns remain, and the rating were not changed. The ACs concur these major concerns and agree that the paper can not be accepted at its current state."}, "signatures": ["ICLR.cc/2021/Conference/Program_Chairs"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference/Program_Chairs"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Relevance Attack on Detectors", "authorids": ["~Sizhe_Chen1", "hf-inspire@sjtu.edu.cn", "~Xiaolin_Huang1", "~Kun_Zhang1"], "authors": ["Sizhe Chen", "Fan He", "Xiaolin Huang", "Kun Zhang"], "keywords": ["adversarial attack", "relevance map", "object detection", "transferability", "black-box attack"], "abstract": "This paper focuses on high-transferable adversarial attacks on detectors, which are hard to attack in a black-box manner, because of their multiple-output characteristics and the diversity across architectures. To pursue a high attack transferability, one plausible way is to find a common property across detectors, which facilitates the discovery of common weaknesses. We are the first to suggest that the relevance map for detectors is such a property. Based on it, we design a Relevance Attack on Detectors (RAD), which achieves a state-of-the-art transferability, exceeding existing results by above 20%. On MS COCO, the detection mAPs for all 8 black-box architectures are more than halved and the segmentation mAPs are also significantly influenced. Given the great transferability of RAD, we generate the first adversarial dataset for object detection, i.e., Adversarial Objects in COntext (AOCO), which helps to quickly evaluate and improve the robustness of detectors.", "one-sentence_summary": "We design a Relevance Attack on Detectors, a high-transferable attack framework with the state-of-the-art performance.", "pdf": "/pdf/745d9d6e4d46aa97ba592384bcd8aaa803f38d90.pdf", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "chen|relevance_attack_on_detectors", "supplementary_material": "/attachment/af3b9ac9017f0b304cf44fface903c7950ab9ffc.zip", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=K9mMva6mYW", "_bibtex": "@misc{\nchen2021relevance,\ntitle={Relevance Attack on Detectors},\nauthor={Sizhe Chen and Fan He and Xiaolin Huang and Kun Zhang},\nyear={2021},\nurl={https://openreview.net/forum?id=_b8l7rVPe8z}\n}"}, "tags": [], "invitation": {"reply": {"forum": "_b8l7rVPe8z", "replyto": "_b8l7rVPe8z", "readers": {"values": ["everyone"]}, "writers": {"values": ["ICLR.cc/2021/Conference/Program_Chairs"]}, "signatures": {"values": ["ICLR.cc/2021/Conference/Program_Chairs"]}, "content": {"title": {"value": "Final Decision"}, "decision": {"value-radio": ["Accept (Oral)", "Accept (Spotlight)", "Accept (Poster)", "Reject"]}, "comment": {"value-regex": "[\\S\\s]{0,50000}", "markdown": true}}}, "multiReply": false, "signatures": ["ICLR.cc/2021/Conference"], "readers": ["everyone"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Program_Chairs"], "tcdate": 1610040441109, "tmdate": 1610474042106, "id": "ICLR.cc/2021/Conference/Paper248/-/Decision"}}}, {"id": "BYjkq8bf2ot", "original": null, "number": 8, "cdate": 1606116513905, "ddate": null, "tcdate": 1606116513905, "tmdate": 1606116513905, "tddate": null, "forum": "_b8l7rVPe8z", "replyto": "_b8l7rVPe8z", "invitation": "ICLR.cc/2021/Conference/Paper248/-/Official_Comment", "content": {"title": "Summary of changes in the updated submission", "comment": "Dear Program Chairs, Area Chairs, and Reviewers,\n\nFirst of all, we would like to thank you for your time, constructive critiques, and valuable suggestions. Your input contributed to a significant improvement of the paper and to our proposed method as well. We did our best to address your comments on our revised manuscript. For each reviewer, we give a detailed response to each of your comments. Major changes made to the previously submitted document are summarized below for you.\n* The calculation of attack gradients from the relevance maps is described in detail in Appendix A.\n* More black-boxes (EfficientDet, M9, see Tables) and white-boxes (Mask R-CNN, RetinaNet, see Appendix D) are attacked.\n* The value of AOCO dataset is clarified in Section 5.\n* Important related works are discussed in Section 2.\n\nSincerely yours,\n\nICLR 2021 Paper248 Authors"}, "signatures": ["ICLR.cc/2021/Conference/Paper248/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper248/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Relevance Attack on Detectors", "authorids": ["~Sizhe_Chen1", "hf-inspire@sjtu.edu.cn", "~Xiaolin_Huang1", "~Kun_Zhang1"], "authors": ["Sizhe Chen", "Fan He", "Xiaolin Huang", "Kun Zhang"], "keywords": ["adversarial attack", "relevance map", "object detection", "transferability", "black-box attack"], "abstract": "This paper focuses on high-transferable adversarial attacks on detectors, which are hard to attack in a black-box manner, because of their multiple-output characteristics and the diversity across architectures. To pursue a high attack transferability, one plausible way is to find a common property across detectors, which facilitates the discovery of common weaknesses. We are the first to suggest that the relevance map for detectors is such a property. Based on it, we design a Relevance Attack on Detectors (RAD), which achieves a state-of-the-art transferability, exceeding existing results by above 20%. On MS COCO, the detection mAPs for all 8 black-box architectures are more than halved and the segmentation mAPs are also significantly influenced. Given the great transferability of RAD, we generate the first adversarial dataset for object detection, i.e., Adversarial Objects in COntext (AOCO), which helps to quickly evaluate and improve the robustness of detectors.", "one-sentence_summary": "We design a Relevance Attack on Detectors, a high-transferable attack framework with the state-of-the-art performance.", "pdf": "/pdf/745d9d6e4d46aa97ba592384bcd8aaa803f38d90.pdf", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "chen|relevance_attack_on_detectors", "supplementary_material": "/attachment/af3b9ac9017f0b304cf44fface903c7950ab9ffc.zip", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=K9mMva6mYW", "_bibtex": "@misc{\nchen2021relevance,\ntitle={Relevance Attack on Detectors},\nauthor={Sizhe Chen and Fan He and Xiaolin Huang and Kun Zhang},\nyear={2021},\nurl={https://openreview.net/forum?id=_b8l7rVPe8z}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "_b8l7rVPe8z", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper248/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper248/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper248/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper248/Authors|ICLR.cc/2021/Conference/Paper248/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper248/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923873066, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper248/-/Official_Comment"}}}, {"id": "9gvSGcW_XCr", "original": null, "number": 2, "cdate": 1605797034387, "ddate": null, "tcdate": 1605797034387, "tmdate": 1606116165763, "tddate": null, "forum": "_b8l7rVPe8z", "replyto": "TJmcGcoKjnY", "invitation": "ICLR.cc/2021/Conference/Paper248/-/Official_Comment", "content": {"title": "Response to Reviewer3", "comment": "We would like to thank reviewer 3 for the thoughtful comments and efforts towards improving our manuscript.\n\n\nQuestion 1. Unfair comparison may occur when update techniques are not applied to baselines.\n\nAnswer 1. We very much appreciate reviewer 3 for the thoughtful comments towards experimental design. It is notable that without update techniques, RAD also outperforms baselines as in Tables 2 and 3. Accordingly, we believe that advantages of RAD are validated fairly. We do not combine these two tables because the choice of update technique is a part of the RAD design presented in method part. Transferable update techniques are adopted in PGD baselines in Table 3.\n\n\nQuestion 2. The adversarial loss and corresponding gradients for optimization is not clear.\n\nAnswer 2. We are grateful to this constructive review. The adversarial loss is the relevance map h(x, T) as in (3). The calculation of the attack gradients has been described in the updated submission in Appendix A for reproductivity. Also, we attach the source code as supplementary materials.\n\n\nQuestion 3. The difference between RAD and [1, 2] should be discussed.\n\nAnswer 3. We thank the reviewer for pointing out these related works. The difference between RAD and these works are listed below and added to the updated submission in the last paragraph of Section 2. RAD misleads detectors by suppressing relevance maps. In contrast, [1] misleads the relevance maps while keeping the prediction unchanged. [2] also misleads DNNs, but it keeps the relevance maps unchanged."}, "signatures": ["ICLR.cc/2021/Conference/Paper248/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper248/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Relevance Attack on Detectors", "authorids": ["~Sizhe_Chen1", "hf-inspire@sjtu.edu.cn", "~Xiaolin_Huang1", "~Kun_Zhang1"], "authors": ["Sizhe Chen", "Fan He", "Xiaolin Huang", "Kun Zhang"], "keywords": ["adversarial attack", "relevance map", "object detection", "transferability", "black-box attack"], "abstract": "This paper focuses on high-transferable adversarial attacks on detectors, which are hard to attack in a black-box manner, because of their multiple-output characteristics and the diversity across architectures. To pursue a high attack transferability, one plausible way is to find a common property across detectors, which facilitates the discovery of common weaknesses. We are the first to suggest that the relevance map for detectors is such a property. Based on it, we design a Relevance Attack on Detectors (RAD), which achieves a state-of-the-art transferability, exceeding existing results by above 20%. On MS COCO, the detection mAPs for all 8 black-box architectures are more than halved and the segmentation mAPs are also significantly influenced. Given the great transferability of RAD, we generate the first adversarial dataset for object detection, i.e., Adversarial Objects in COntext (AOCO), which helps to quickly evaluate and improve the robustness of detectors.", "one-sentence_summary": "We design a Relevance Attack on Detectors, a high-transferable attack framework with the state-of-the-art performance.", "pdf": "/pdf/745d9d6e4d46aa97ba592384bcd8aaa803f38d90.pdf", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "chen|relevance_attack_on_detectors", "supplementary_material": "/attachment/af3b9ac9017f0b304cf44fface903c7950ab9ffc.zip", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=K9mMva6mYW", "_bibtex": "@misc{\nchen2021relevance,\ntitle={Relevance Attack on Detectors},\nauthor={Sizhe Chen and Fan He and Xiaolin Huang and Kun Zhang},\nyear={2021},\nurl={https://openreview.net/forum?id=_b8l7rVPe8z}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "_b8l7rVPe8z", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper248/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper248/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper248/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper248/Authors|ICLR.cc/2021/Conference/Paper248/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper248/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923873066, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper248/-/Official_Comment"}}}, {"id": "qo7nn2IJay", "original": null, "number": 3, "cdate": 1605797240394, "ddate": null, "tcdate": 1605797240394, "tmdate": 1606116142043, "tddate": null, "forum": "_b8l7rVPe8z", "replyto": "F-pJXaTIQb2", "invitation": "ICLR.cc/2021/Conference/Paper248/-/Official_Comment", "content": {"title": "Response to Reviewer1", "comment": "We would like to thank reviewer 1 for the thoughtful comments and efforts towards improving our manuscript.\n\n\nQuestion 1. Authors should refer to [a, b, c].\n\nAnswer 1. We thank the reviewer for pointing these related works. These papers are referred in the updated submission in the second paragraph of Section 2. They conduct white-box attack in physical world. In contrast, we conduct black-box attack on digital images. Accordingly, they target at transferability across scenes, and we aim at transferability across models. Our goals differ in essence.\n\n\nQuestion 2. It is not clear how to obtain the attack gradients.\n\nAnswer 2. Thanks for pointing out the vagueness. The calculation of the attack gradients has been described in the updated submission in Section 3.3.\n\n\nQuestion 3. The dataset is not useful.\n\nAnswer 3. AOCO dataset serves as a potential benchmark to evaluate the robustness of detectors, which will be beneficial to network designers. It will also be useful for adversarial training, as the most effective practice to clearly improve the robustness of DNNs [d, e, f]. Notice that there is no other adversarial dataset for detection at all. This is not because the dataset is useless, but due to the low transferability of attack methods such that the examples are detector-dependent. Now we have achieved high transferability and can then make such an adversarial dataset publicly available. \n\n\nQuestion 4. The ablation study is not sufficient.\n\nAnswer 4. We sincerely appreciate this constructive review. Below we explain why we choose SGLRP and the attack budget. SGLRP [g] is of the latest visualization methods compared to Grad-CAM [h], which, if adopted in RAD, requires the time-consuming second-order gradients and limits the usage. Besides, SGLRP excels in discriminating ability against irrelevant regions of a certain target node. Accordingly, SGLRP is adopted in our RAD. The attack budget follows the setting in [i, j, k], where 16 is validated to be an ideal threshold for the trade-off between effectiveness and imperceptibility in attack. Besides hyperparameters, we also conduct ablation study to add large random noise. Results in Table 3 show that the transferability comes from attack rather than large perturbations.\n\n\nQuestion 5. It would be more informative to attack other surrogate models.\n\nAnswer 5. Thanks to your constructive suggestions, we have added the results of attacking Mask-RCNN and RetinaNet in the updated submission in Appendix D.\n\n\nQuestion 6. Authors provide no proper explanation, limiting the novelty of RAD.\n\nAnswer 6. We are grateful to reviewer 1 for the thoughtful comments. To the best of our knowledge, we are the first to propose that one plausible way to improve the transferability of detector attacks is to find common properties across them, which facilitates the discovery of common weaknesses. Based on them, the designed attack can threaten variable victims. RAD focuses on relevance maps, and attacking other common properties might also be possible, which is an implicit contribution of RAD. Indeed, the above is only some heuristic guess. Providing convincing theoretical explanations is hard but will certainly be our next focus.\n\nQuestion 7. The presentation could be improved.\n\nAnswer 7. Thanks for your careful reading. The presentation of paper has been improved in the updated submission.\n\n\n[d] Mitigating adversarial effects through randomization, ICLR 2018.\n\n[e] Ensemble adversarial training: Attacks and defenses, ICLR 2018.\n\n[f] Adversarial training for free!, NeurIPS 2019.\n\n[g] Explaining convolutional neural networks using softmax gradient layer-wise relevance propagation, ICCV Workshop, 2019.\n\n[h] Grad-CAM: Visual Explanations from Deep Networks via Gradient-based Localization, CVPR 2017.\n\n[i] Evading defenses to transferable adversarial examples by translation-invariant attacks, CVPR 2019.\n\n[j] Improving transferability of adversarial examples with input diversity, CVPR 2019.\n\n[k] Nesterov accelerated gradient and scale invariance for adversarial attacks, ICLR 2020.\n"}, "signatures": ["ICLR.cc/2021/Conference/Paper248/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper248/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Relevance Attack on Detectors", "authorids": ["~Sizhe_Chen1", "hf-inspire@sjtu.edu.cn", "~Xiaolin_Huang1", "~Kun_Zhang1"], "authors": ["Sizhe Chen", "Fan He", "Xiaolin Huang", "Kun Zhang"], "keywords": ["adversarial attack", "relevance map", "object detection", "transferability", "black-box attack"], "abstract": "This paper focuses on high-transferable adversarial attacks on detectors, which are hard to attack in a black-box manner, because of their multiple-output characteristics and the diversity across architectures. To pursue a high attack transferability, one plausible way is to find a common property across detectors, which facilitates the discovery of common weaknesses. We are the first to suggest that the relevance map for detectors is such a property. Based on it, we design a Relevance Attack on Detectors (RAD), which achieves a state-of-the-art transferability, exceeding existing results by above 20%. On MS COCO, the detection mAPs for all 8 black-box architectures are more than halved and the segmentation mAPs are also significantly influenced. Given the great transferability of RAD, we generate the first adversarial dataset for object detection, i.e., Adversarial Objects in COntext (AOCO), which helps to quickly evaluate and improve the robustness of detectors.", "one-sentence_summary": "We design a Relevance Attack on Detectors, a high-transferable attack framework with the state-of-the-art performance.", "pdf": "/pdf/745d9d6e4d46aa97ba592384bcd8aaa803f38d90.pdf", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "chen|relevance_attack_on_detectors", "supplementary_material": "/attachment/af3b9ac9017f0b304cf44fface903c7950ab9ffc.zip", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=K9mMva6mYW", "_bibtex": "@misc{\nchen2021relevance,\ntitle={Relevance Attack on Detectors},\nauthor={Sizhe Chen and Fan He and Xiaolin Huang and Kun Zhang},\nyear={2021},\nurl={https://openreview.net/forum?id=_b8l7rVPe8z}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "_b8l7rVPe8z", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper248/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper248/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper248/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper248/Authors|ICLR.cc/2021/Conference/Paper248/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper248/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923873066, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper248/-/Official_Comment"}}}, {"id": "oUbfVy-y-iT", "original": null, "number": 7, "cdate": 1606115947293, "ddate": null, "tcdate": 1606115947293, "tmdate": 1606115947293, "tddate": null, "forum": "_b8l7rVPe8z", "replyto": "TlSlDOWd71X", "invitation": "ICLR.cc/2021/Conference/Paper248/-/Official_Comment", "content": {"title": "Further Response to Reviewer1", "comment": "We sincerely thank reviewer 1 for the additional comments and efforts towards improving our work. According to your insightful comments, we have revised our submission again. Below is our further response.\n\n\nComment 2. I still do not understand how Eq. 3 is used in calculating the attack gradients in Eq 4. It is mentioned that iNNvestigate library is used, but that is not an explanation of how the gradients are computed with respect to SGLRP relevant maps (which itself is an iterative process). Are second-order gradients used (gradients of gradients)?\n\nAnswer 2. We are grateful to this constructive comment. The calculation of the attack gradients has been described in the updated submission in Appendix A, where we specify the rules of calculating relevance maps, which naturally result in the gradients. Actually, SGLRP back-propagates the relevance only ONCE with the certain specified rules, so it is not a computation-consuming iterative process. Also, according to the rules, RAD requires no costly calculation of second-order gradients, which is needed if CAM is adopted.\n\n\nComment 3. The dataset is useful in essence, but the authors did not showcase its usefulness. Will training Mask RCNN on this proposed dataset improve its robustness to the proposed RAD attacks and all other attacks?\n\nAnswer 3. We very much appreciate reviewer 1 for the thoughtful comments towards experimental design. Since we received the review, we have been trying to conduct adversarial training. However, due to the time limitation, we cannot report the results at this moment. Actually, good adversarial training requires specific researches, for which the dataset will be always a basis. As an analogy, there are many advanced methods for adversarial training for classification tasks [e, f]. \n\n\nComment 4. I respectfully disagree with the authors that is an ideal threshold. Just because some papers conveniently used it on ImageNet classifiers doesn't imply it is best to use it on MSCOCO detectors. In fact, the formal and proper way to present attack results is to show the entire plot of performance (mAP in this case) vs the attack budget as pointed out by the pioneers of adversarial attacks (Carlini, Madry, Goodfellow, and others) in their seminal work (\u201cOn Evaluating Adversarial Robustness\u201d).\n\nAnswer 4. Thanks to your detailed comments. The epsilon setting was following published literature [i, j, k] but we also respect the reviewer\u2019s opinion that discussing the influences of the attack budget is important. After receiving this comment, we immediately conduct ablation study on the transferability when RAD adopts an attack budget of 4, 8, 12, 16, 20. The corresponding results have been reported in Figure 7 in the updated submission."}, "signatures": ["ICLR.cc/2021/Conference/Paper248/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper248/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Relevance Attack on Detectors", "authorids": ["~Sizhe_Chen1", "hf-inspire@sjtu.edu.cn", "~Xiaolin_Huang1", "~Kun_Zhang1"], "authors": ["Sizhe Chen", "Fan He", "Xiaolin Huang", "Kun Zhang"], "keywords": ["adversarial attack", "relevance map", "object detection", "transferability", "black-box attack"], "abstract": "This paper focuses on high-transferable adversarial attacks on detectors, which are hard to attack in a black-box manner, because of their multiple-output characteristics and the diversity across architectures. To pursue a high attack transferability, one plausible way is to find a common property across detectors, which facilitates the discovery of common weaknesses. We are the first to suggest that the relevance map for detectors is such a property. Based on it, we design a Relevance Attack on Detectors (RAD), which achieves a state-of-the-art transferability, exceeding existing results by above 20%. On MS COCO, the detection mAPs for all 8 black-box architectures are more than halved and the segmentation mAPs are also significantly influenced. Given the great transferability of RAD, we generate the first adversarial dataset for object detection, i.e., Adversarial Objects in COntext (AOCO), which helps to quickly evaluate and improve the robustness of detectors.", "one-sentence_summary": "We design a Relevance Attack on Detectors, a high-transferable attack framework with the state-of-the-art performance.", "pdf": "/pdf/745d9d6e4d46aa97ba592384bcd8aaa803f38d90.pdf", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "chen|relevance_attack_on_detectors", "supplementary_material": "/attachment/af3b9ac9017f0b304cf44fface903c7950ab9ffc.zip", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=K9mMva6mYW", "_bibtex": "@misc{\nchen2021relevance,\ntitle={Relevance Attack on Detectors},\nauthor={Sizhe Chen and Fan He and Xiaolin Huang and Kun Zhang},\nyear={2021},\nurl={https://openreview.net/forum?id=_b8l7rVPe8z}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "_b8l7rVPe8z", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper248/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper248/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper248/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper248/Authors|ICLR.cc/2021/Conference/Paper248/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper248/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923873066, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper248/-/Official_Comment"}}}, {"id": "TlSlDOWd71X", "original": null, "number": 6, "cdate": 1605883923716, "ddate": null, "tcdate": 1605883923716, "tmdate": 1605884829076, "tddate": null, "forum": "_b8l7rVPe8z", "replyto": "qo7nn2IJay", "invitation": "ICLR.cc/2021/Conference/Paper248/-/Official_Comment", "content": {"title": "more issues to be resolved ", "comment": "I would like to thank the authors for providing a good rebuttal for my concerns. Here are my comments.\n\n*Answer 2. Thanks for pointing out the vagueness. The calculation of the attack gradients has been described in the updated submission in Section 3.3.*\n\nComment 2. I still do not understand how Eq. 3 is used in calculating the attack gradients in Eq 4. It is mentioned that iNNvestigate library is used, but that is not an explanation of **how** the gradients are computed with respect to SGLRP relevant maps ( which itself is an iterative process). Are second-order gradients used (gradients of gradients )?  \n\n*Answer 3. AOCO dataset serves as a potential benchmark to evaluate the robustness of detectors, which will be beneficial to network designers. It will also be useful for adversarial training, as the most effective practice to clearly improve the robustness of DNNs [d, e, f]. Notice that there is no other adversarial dataset for detection at all. This is not because the dataset is useless, but due to the low transferability of attack methods such that the examples are detector-dependent. Now we have achieved high transferability and can then make such an adversarial dataset publicly available.*\n\nComment 3. The dataset is useful in essence, but the authors did not showcase its usefulness. Will training MaskRCNN on this proposed dataset improve its robustness to the proposed RAD attacks and all other attacks?\n\n*Answer 4. We sincerely appreciate this constructive review. Below we explain why we choose SGLRP and the attack budget. SGLRP [g] is of the latest visualization methods compared to Grad-CAM [h], which requires the DNN to have a specific structure and limits the usage. Besides, SGLRP excels in discriminating ability against irrelevant regions of a certain target node. Accordingly, SGLRP is adopted in our RAD. The attack budget follows the setting in [i, j, k], where 16 is validated to be an ideal threshold for the trade-off between effectiveness and imperceptibility in the attack. Besides hyperparameters, we also conduct ablation study to add large random noise. Results in Table 3 show that the transferability comes from attack rather than large perturbations.*\n\ncomment 4. I respectfully disagree with the authors that $\\epsilon = 16$ is an *ideal* threshold. Just because some papers conveniently used it on ImageNet classifiers doesn't imply it is best to use it on MSCOCO detectors. In fact, the formal and proper way to present attack results is to show the entire plot of performance (mAP in this case) vs the attack budget ( $\\epsilon$) as pointed out by the pioneers of adversarial attacks ( Carlini,  Madry, Goodfellow, and others ) in their seminal work [a] .   \n\n[a]  \"On Evaluating Adversarial Robustness\". Nicholas Carlini, Anish Athalye, Nicolas Papernot, Wieland Brendel, Jonas Rauber, Dimitris Tsipras, Ian Goodfellow, Aleksander Madry, Alexey Kurakin;  Arxive 2019"}, "signatures": ["ICLR.cc/2021/Conference/Paper248/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper248/AnonReviewer1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Relevance Attack on Detectors", "authorids": ["~Sizhe_Chen1", "hf-inspire@sjtu.edu.cn", "~Xiaolin_Huang1", "~Kun_Zhang1"], "authors": ["Sizhe Chen", "Fan He", "Xiaolin Huang", "Kun Zhang"], "keywords": ["adversarial attack", "relevance map", "object detection", "transferability", "black-box attack"], "abstract": "This paper focuses on high-transferable adversarial attacks on detectors, which are hard to attack in a black-box manner, because of their multiple-output characteristics and the diversity across architectures. To pursue a high attack transferability, one plausible way is to find a common property across detectors, which facilitates the discovery of common weaknesses. We are the first to suggest that the relevance map for detectors is such a property. Based on it, we design a Relevance Attack on Detectors (RAD), which achieves a state-of-the-art transferability, exceeding existing results by above 20%. On MS COCO, the detection mAPs for all 8 black-box architectures are more than halved and the segmentation mAPs are also significantly influenced. Given the great transferability of RAD, we generate the first adversarial dataset for object detection, i.e., Adversarial Objects in COntext (AOCO), which helps to quickly evaluate and improve the robustness of detectors.", "one-sentence_summary": "We design a Relevance Attack on Detectors, a high-transferable attack framework with the state-of-the-art performance.", "pdf": "/pdf/745d9d6e4d46aa97ba592384bcd8aaa803f38d90.pdf", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "chen|relevance_attack_on_detectors", "supplementary_material": "/attachment/af3b9ac9017f0b304cf44fface903c7950ab9ffc.zip", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=K9mMva6mYW", "_bibtex": "@misc{\nchen2021relevance,\ntitle={Relevance Attack on Detectors},\nauthor={Sizhe Chen and Fan He and Xiaolin Huang and Kun Zhang},\nyear={2021},\nurl={https://openreview.net/forum?id=_b8l7rVPe8z}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "_b8l7rVPe8z", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper248/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper248/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper248/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper248/Authors|ICLR.cc/2021/Conference/Paper248/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper248/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923873066, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper248/-/Official_Comment"}}}, {"id": "F-pJXaTIQb2", "original": null, "number": 3, "cdate": 1603942232535, "ddate": null, "tcdate": 1603942232535, "tmdate": 1605884641586, "tddate": null, "forum": "_b8l7rVPe8z", "replyto": "_b8l7rVPe8z", "invitation": "ICLR.cc/2021/Conference/Paper248/-/Official_Review", "content": {"title": "large room for improvement", "review": "**Summary**:\nThis work proposes to attack object detectors by targeting their relevance maps of the different detected objects. The proposed RAD attack shows better black box transferability across different detectors on MSCOCO dataset. The relevance maps are calculated based on SGLRP act as an attention mechanism to the attack to focus on relevant regions in the more meaningful image and hence produce more transferable attacks. \n\n**Strengths** :\n- Good attack performance and transferability between detectors, which poses a security threat for SDV applications that use object detectors\n- Eight different detectors and three segmentation models are used in the RAD attack, which shows good generalization.\n\n**Weaknesses**:\n- Missing important references [a,b,c]. All of these works attack object detectors and target transferability.\n- The paper is poorly written and ambiguous. Variables are introduced without proper definitions. It is not clear how to obtain the gradients in eq(3) with respect to the relevance maps.\n- No use of the proposed dataset. The authors propose a new dataset of adversarial objects but never mention or showcase the dataset's usefulness. A straightforward way to show the dataset's usefulness is by performing adversarial training and making robust detectors against the proposed attacks. \n- No enough ablation is performed. The only ablation to the proposed method is in table 7 regarding the way to pick the detection target. The relevance maps based on LRP are expensive and worse than recent saliency maps like CAM and grad-CAM. The attack budget $\\epsilon =16$ picked in the experiments is not justified ( it might be big or small for attack success ), and a plot of mAP vs. $\\epsilon$ for different detectors would give more information about the effect of the attack.\n- All the attacks in the paper are performed on YOLOv3 and transferred to other models. It would be more informative to show transferability matrices of attacks performed on all models and transferred to all others.\n- The novelty of the proposed methodology is limited. While the use of relevance maps to improve the transferability of attacks on object detectors is novel, no proper explanation is provided. The attacks are based on PGD, and the relevance map is adapted from SGLRP. The paper offers no theoretical results or exciting insights. \n\n\n\n[a] Huang et al. \"Universal Physical Camouflage Attacks on Object Detectors\", ( CVPR 2020)\n[b] Wu et al. \"Making an Invisibility Cloak: Real World Adversarial Attacks on Object Detectors\", (ECCV 2020 )\n[c] Xu et al. \"Adversarial T-shirt! Evading Person Detectors in A Physical World\" (ECCV 2020).\n\n\nMinor issues :\n- Many grammar mistakes:\" because they possess multiple-output.\", \"Among the classification attacks and detection ones, cross-domain attack (Naseer et al. (2019)) is the most effective, but RAD is more aggressive\" ..etc.\n- No question marks in titles 3.1-3.5.\n- Table 2-5 could have been visualized better by using a bar chart, for example, to observe the relative performance of attacks and defenses. \n", "rating": "4: Ok but not good enough - rejection", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "signatures": ["ICLR.cc/2021/Conference/Paper248/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper248/AnonReviewer1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Relevance Attack on Detectors", "authorids": ["~Sizhe_Chen1", "hf-inspire@sjtu.edu.cn", "~Xiaolin_Huang1", "~Kun_Zhang1"], "authors": ["Sizhe Chen", "Fan He", "Xiaolin Huang", "Kun Zhang"], "keywords": ["adversarial attack", "relevance map", "object detection", "transferability", "black-box attack"], "abstract": "This paper focuses on high-transferable adversarial attacks on detectors, which are hard to attack in a black-box manner, because of their multiple-output characteristics and the diversity across architectures. To pursue a high attack transferability, one plausible way is to find a common property across detectors, which facilitates the discovery of common weaknesses. We are the first to suggest that the relevance map for detectors is such a property. Based on it, we design a Relevance Attack on Detectors (RAD), which achieves a state-of-the-art transferability, exceeding existing results by above 20%. On MS COCO, the detection mAPs for all 8 black-box architectures are more than halved and the segmentation mAPs are also significantly influenced. Given the great transferability of RAD, we generate the first adversarial dataset for object detection, i.e., Adversarial Objects in COntext (AOCO), which helps to quickly evaluate and improve the robustness of detectors.", "one-sentence_summary": "We design a Relevance Attack on Detectors, a high-transferable attack framework with the state-of-the-art performance.", "pdf": "/pdf/745d9d6e4d46aa97ba592384bcd8aaa803f38d90.pdf", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "chen|relevance_attack_on_detectors", "supplementary_material": "/attachment/af3b9ac9017f0b304cf44fface903c7950ab9ffc.zip", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=K9mMva6mYW", "_bibtex": "@misc{\nchen2021relevance,\ntitle={Relevance Attack on Detectors},\nauthor={Sizhe Chen and Fan He and Xiaolin Huang and Kun Zhang},\nyear={2021},\nurl={https://openreview.net/forum?id=_b8l7rVPe8z}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq . ***Please remember to file the Code-of-Ethics report. Once you submitted the review, a link to the report will be visible in the bottom right corner of your review.***", "required": true, "markdown": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}, "forum": "_b8l7rVPe8z", "replyto": "_b8l7rVPe8z", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"], "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper248/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1607428800000, "duedate": 1606752000000, "multiReply": false, "readers": ["everyone"], "tcdate": 1602538147246, "tmdate": 1606915784079, "super": "ICLR.cc/2021/Conference/-/Official_Review", "signatures": ["OpenReview.net"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Paper248/Reviewers", "OpenReview.net/Support"], "id": "ICLR.cc/2021/Conference/Paper248/-/Official_Review"}}}, {"id": "SGVPSZPND3h", "original": null, "number": 5, "cdate": 1605797389446, "ddate": null, "tcdate": 1605797389446, "tmdate": 1605797389446, "tddate": null, "forum": "_b8l7rVPe8z", "replyto": "Adlnb8Kbl2o", "invitation": "ICLR.cc/2021/Conference/Paper248/-/Official_Comment", "content": {"title": "Response to Reviewer 2", "comment": "We would like to thank reviewer 2 for the thoughtful comments and efforts towards improving our manuscript.\n\n\nQuestion 1. The major contribution is modifying SGLRP, which is limited.\n\nAnswer 1. We sincerely appreciate this constructive review. RAD is a complete attack framework, including the design of Multi-Node SGLRP, a proper choice of target nodes, and a suitable update approach. Simply extending SGLRP to Multi-Node SGLRP does not work as empirically validated in Table 1. In-depth analysis and trial also contribute to RAD\u2019s great performance.\n\n\nQuestion 2. It is unclear why gradients from the relevance maps are required in black-box attack.\n\nAnswer 2. We are grateful to the reviewer for pointing out the vagueness. In transfer-based black-box attack, one attacks a surrogate model in a white-box manner and sends the adversarial samples to attack black boxes. Thus, the gradients of the white-box model (and its relevance maps in RAD) are required.\n\n\nQuestion 3. Authors are expected to attack more SOTA black-box models.\n\nAnswer 3. Thanks for this thoughtful review. We have attacked Cascade R-CNN (M6) in the previous submission, and the performance of EfficientDet (M9) is reported in all tables in the updated submission."}, "signatures": ["ICLR.cc/2021/Conference/Paper248/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper248/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Relevance Attack on Detectors", "authorids": ["~Sizhe_Chen1", "hf-inspire@sjtu.edu.cn", "~Xiaolin_Huang1", "~Kun_Zhang1"], "authors": ["Sizhe Chen", "Fan He", "Xiaolin Huang", "Kun Zhang"], "keywords": ["adversarial attack", "relevance map", "object detection", "transferability", "black-box attack"], "abstract": "This paper focuses on high-transferable adversarial attacks on detectors, which are hard to attack in a black-box manner, because of their multiple-output characteristics and the diversity across architectures. To pursue a high attack transferability, one plausible way is to find a common property across detectors, which facilitates the discovery of common weaknesses. We are the first to suggest that the relevance map for detectors is such a property. Based on it, we design a Relevance Attack on Detectors (RAD), which achieves a state-of-the-art transferability, exceeding existing results by above 20%. On MS COCO, the detection mAPs for all 8 black-box architectures are more than halved and the segmentation mAPs are also significantly influenced. Given the great transferability of RAD, we generate the first adversarial dataset for object detection, i.e., Adversarial Objects in COntext (AOCO), which helps to quickly evaluate and improve the robustness of detectors.", "one-sentence_summary": "We design a Relevance Attack on Detectors, a high-transferable attack framework with the state-of-the-art performance.", "pdf": "/pdf/745d9d6e4d46aa97ba592384bcd8aaa803f38d90.pdf", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "chen|relevance_attack_on_detectors", "supplementary_material": "/attachment/af3b9ac9017f0b304cf44fface903c7950ab9ffc.zip", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=K9mMva6mYW", "_bibtex": "@misc{\nchen2021relevance,\ntitle={Relevance Attack on Detectors},\nauthor={Sizhe Chen and Fan He and Xiaolin Huang and Kun Zhang},\nyear={2021},\nurl={https://openreview.net/forum?id=_b8l7rVPe8z}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "_b8l7rVPe8z", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper248/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper248/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper248/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper248/Authors|ICLR.cc/2021/Conference/Paper248/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper248/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923873066, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper248/-/Official_Comment"}}}, {"id": "AHqOsybtVLN", "original": null, "number": 4, "cdate": 1605797336152, "ddate": null, "tcdate": 1605797336152, "tmdate": 1605797336152, "tddate": null, "forum": "_b8l7rVPe8z", "replyto": "M1non0gR8rB", "invitation": "ICLR.cc/2021/Conference/Paper248/-/Official_Comment", "content": {"title": "Response to Reviewer 4", "comment": "We would like to thank reviewer 4 for the thoughtful comments and efforts towards improving our manuscript.\n\n\nQuestion 1. More baselines are necessary.\n\nAnswer 1. We sincerely appreciate this constructive review. Since we received the review, we have been trying to conduct more comparative experiments. However, due to the time limitation, we cannot report the results at this moment. We thank the reviewer for pointing this related work, which has been discussed in the updated submission in the second paragraph of Section 2.\n\n\nQuestion 2. Update approaches for transferability in attacking classifiers could be adopted.\n\nAnswer 2. Thanks for pointing out that. Actually, related discussions on update approaches are in Section 3.5, e.g., MI stands for momentum update and DI is for input diversity. Empirically, SI is most suitable for RAD and therefore chosen.\n\n\nQuestion 3. The value of dataset is unclear.\n\nAnswer 3. We would like to thank reviewer 4 for the thoughtful comments. There is no dataset containing adversarial samples for detectors only, not because the dataset is useless, but because existing methods are not capable of conducting high-transferable attack and the resulting samples are detector-dependent. Given that RAD achieves high transferability, we could provide such an adversarial dataset. With the dataset, RAD benefits the community very directly, because designers could easily use AOCO to evaluate and improve the robustness of detectors. "}, "signatures": ["ICLR.cc/2021/Conference/Paper248/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper248/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Relevance Attack on Detectors", "authorids": ["~Sizhe_Chen1", "hf-inspire@sjtu.edu.cn", "~Xiaolin_Huang1", "~Kun_Zhang1"], "authors": ["Sizhe Chen", "Fan He", "Xiaolin Huang", "Kun Zhang"], "keywords": ["adversarial attack", "relevance map", "object detection", "transferability", "black-box attack"], "abstract": "This paper focuses on high-transferable adversarial attacks on detectors, which are hard to attack in a black-box manner, because of their multiple-output characteristics and the diversity across architectures. To pursue a high attack transferability, one plausible way is to find a common property across detectors, which facilitates the discovery of common weaknesses. We are the first to suggest that the relevance map for detectors is such a property. Based on it, we design a Relevance Attack on Detectors (RAD), which achieves a state-of-the-art transferability, exceeding existing results by above 20%. On MS COCO, the detection mAPs for all 8 black-box architectures are more than halved and the segmentation mAPs are also significantly influenced. Given the great transferability of RAD, we generate the first adversarial dataset for object detection, i.e., Adversarial Objects in COntext (AOCO), which helps to quickly evaluate and improve the robustness of detectors.", "one-sentence_summary": "We design a Relevance Attack on Detectors, a high-transferable attack framework with the state-of-the-art performance.", "pdf": "/pdf/745d9d6e4d46aa97ba592384bcd8aaa803f38d90.pdf", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "chen|relevance_attack_on_detectors", "supplementary_material": "/attachment/af3b9ac9017f0b304cf44fface903c7950ab9ffc.zip", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=K9mMva6mYW", "_bibtex": "@misc{\nchen2021relevance,\ntitle={Relevance Attack on Detectors},\nauthor={Sizhe Chen and Fan He and Xiaolin Huang and Kun Zhang},\nyear={2021},\nurl={https://openreview.net/forum?id=_b8l7rVPe8z}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "_b8l7rVPe8z", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper248/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper248/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper248/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper248/Authors|ICLR.cc/2021/Conference/Paper248/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper248/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923873066, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper248/-/Official_Comment"}}}, {"id": "Adlnb8Kbl2o", "original": null, "number": 1, "cdate": 1603612186754, "ddate": null, "tcdate": 1603612186754, "tmdate": 1605024731658, "tddate": null, "forum": "_b8l7rVPe8z", "replyto": "_b8l7rVPe8z", "invitation": "ICLR.cc/2021/Conference/Paper248/-/Official_Review", "content": {"title": "A relevance map proposed for adversarial attack on object detection. The overall contribution seems limited.", "review": "A transferable adversarial attack method is proposed for object detection. A relevance map is used to discover the common weakness of existing detectors. An adversarial dataset for object detection is created for experimental validation.\n\nThe relevance map proposed indeed derives from SGLRP as mentioned in Sec. 3.3. The only modification is to change a single node target t to the average of a set of nodes.  As the major contribution claimed is on the relevance map, the minor modification makes the contribution limited.\n\nThe relevance map is computed by back-propagating the relevance R from the final layer to the input following rules as illustrated in Sec. 3.3. However, the proposed method is claimed to perform a black-box transferable attack. Also, the gradients are utilized to update the relevance map. It is thus not clear how this relevance map correlates to the black-box transferable attack.  \n\nIn the experiments, the proposed attack method shall be compared to sota detection or segmentation-based methods (e.g., EfficientDet, Cascade-RCNN, Libra-RCNN). \n", "rating": "4: Ok but not good enough - rejection", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["ICLR.cc/2021/Conference/Paper248/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper248/AnonReviewer2"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Relevance Attack on Detectors", "authorids": ["~Sizhe_Chen1", "hf-inspire@sjtu.edu.cn", "~Xiaolin_Huang1", "~Kun_Zhang1"], "authors": ["Sizhe Chen", "Fan He", "Xiaolin Huang", "Kun Zhang"], "keywords": ["adversarial attack", "relevance map", "object detection", "transferability", "black-box attack"], "abstract": "This paper focuses on high-transferable adversarial attacks on detectors, which are hard to attack in a black-box manner, because of their multiple-output characteristics and the diversity across architectures. To pursue a high attack transferability, one plausible way is to find a common property across detectors, which facilitates the discovery of common weaknesses. We are the first to suggest that the relevance map for detectors is such a property. Based on it, we design a Relevance Attack on Detectors (RAD), which achieves a state-of-the-art transferability, exceeding existing results by above 20%. On MS COCO, the detection mAPs for all 8 black-box architectures are more than halved and the segmentation mAPs are also significantly influenced. Given the great transferability of RAD, we generate the first adversarial dataset for object detection, i.e., Adversarial Objects in COntext (AOCO), which helps to quickly evaluate and improve the robustness of detectors.", "one-sentence_summary": "We design a Relevance Attack on Detectors, a high-transferable attack framework with the state-of-the-art performance.", "pdf": "/pdf/745d9d6e4d46aa97ba592384bcd8aaa803f38d90.pdf", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "chen|relevance_attack_on_detectors", "supplementary_material": "/attachment/af3b9ac9017f0b304cf44fface903c7950ab9ffc.zip", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=K9mMva6mYW", "_bibtex": "@misc{\nchen2021relevance,\ntitle={Relevance Attack on Detectors},\nauthor={Sizhe Chen and Fan He and Xiaolin Huang and Kun Zhang},\nyear={2021},\nurl={https://openreview.net/forum?id=_b8l7rVPe8z}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq . ***Please remember to file the Code-of-Ethics report. Once you submitted the review, a link to the report will be visible in the bottom right corner of your review.***", "required": true, "markdown": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}, "forum": "_b8l7rVPe8z", "replyto": "_b8l7rVPe8z", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"], "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper248/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1607428800000, "duedate": 1606752000000, "multiReply": false, "readers": ["everyone"], "tcdate": 1602538147246, "tmdate": 1606915784079, "super": "ICLR.cc/2021/Conference/-/Official_Review", "signatures": ["OpenReview.net"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Paper248/Reviewers", "OpenReview.net/Support"], "id": "ICLR.cc/2021/Conference/Paper248/-/Official_Review"}}}, {"id": "M1non0gR8rB", "original": null, "number": 2, "cdate": 1603852469705, "ddate": null, "tcdate": 1603852469705, "tmdate": 1605024731599, "tddate": null, "forum": "_b8l7rVPe8z", "replyto": "_b8l7rVPe8z", "invitation": "ICLR.cc/2021/Conference/Paper248/-/Official_Review", "content": {"title": "The Topic is not very valuable", "review": "Summary:\nThe paper found a new way, called Relevance Attack on Detectors (RAD),  to generate high transferability adversarial examples against detectors by suppressing the multi-node relevance.\nMoreover, a dataset generated by this attacking method is introduced.\n\nPros:\n1. The designed RAD is new and technically sound.\n2. The experimental results on multiple detectors, like YOLOv3,  RetinaNet, Mask R-CNN, etc. are promising.\n\nCons:\n1. It's not surprising that the object detectors can be attacked together.  One naive way is that using the ensemble attack by average the negative CE loss like the paper \"Making an Invisibility Cloak: Real World Adversarial Attacks on Object Detectors\" proposed. So I think some baselines need to be added in experiments. \n2.  By imposing diversity transformation on input image can also improve transferability (\"Boosting Adversarial Attacks with Momentum\"). Similar rules also can be applied in detectors.\n3. I cannot see a very significant value of the generated dataset. Like in the image classification dataset, one can generate adversarial examples easily, but there is not an individual dataset that only contains generated adversarial examples generated by one specific method. Some famous dataset like imagenet-C (\"Benchmarking Neural Network Robustness to Common Corruptions and Perturbations\") is designed by natural perturbations.", "rating": "5: Marginally below acceptance threshold", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "signatures": ["ICLR.cc/2021/Conference/Paper248/AnonReviewer4"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper248/AnonReviewer4"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Relevance Attack on Detectors", "authorids": ["~Sizhe_Chen1", "hf-inspire@sjtu.edu.cn", "~Xiaolin_Huang1", "~Kun_Zhang1"], "authors": ["Sizhe Chen", "Fan He", "Xiaolin Huang", "Kun Zhang"], "keywords": ["adversarial attack", "relevance map", "object detection", "transferability", "black-box attack"], "abstract": "This paper focuses on high-transferable adversarial attacks on detectors, which are hard to attack in a black-box manner, because of their multiple-output characteristics and the diversity across architectures. To pursue a high attack transferability, one plausible way is to find a common property across detectors, which facilitates the discovery of common weaknesses. We are the first to suggest that the relevance map for detectors is such a property. Based on it, we design a Relevance Attack on Detectors (RAD), which achieves a state-of-the-art transferability, exceeding existing results by above 20%. On MS COCO, the detection mAPs for all 8 black-box architectures are more than halved and the segmentation mAPs are also significantly influenced. Given the great transferability of RAD, we generate the first adversarial dataset for object detection, i.e., Adversarial Objects in COntext (AOCO), which helps to quickly evaluate and improve the robustness of detectors.", "one-sentence_summary": "We design a Relevance Attack on Detectors, a high-transferable attack framework with the state-of-the-art performance.", "pdf": "/pdf/745d9d6e4d46aa97ba592384bcd8aaa803f38d90.pdf", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "chen|relevance_attack_on_detectors", "supplementary_material": "/attachment/af3b9ac9017f0b304cf44fface903c7950ab9ffc.zip", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=K9mMva6mYW", "_bibtex": "@misc{\nchen2021relevance,\ntitle={Relevance Attack on Detectors},\nauthor={Sizhe Chen and Fan He and Xiaolin Huang and Kun Zhang},\nyear={2021},\nurl={https://openreview.net/forum?id=_b8l7rVPe8z}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq . ***Please remember to file the Code-of-Ethics report. Once you submitted the review, a link to the report will be visible in the bottom right corner of your review.***", "required": true, "markdown": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}, "forum": "_b8l7rVPe8z", "replyto": "_b8l7rVPe8z", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"], "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper248/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1607428800000, "duedate": 1606752000000, "multiReply": false, "readers": ["everyone"], "tcdate": 1602538147246, "tmdate": 1606915784079, "super": "ICLR.cc/2021/Conference/-/Official_Review", "signatures": ["OpenReview.net"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Paper248/Reviewers", "OpenReview.net/Support"], "id": "ICLR.cc/2021/Conference/Paper248/-/Official_Review"}}}, {"id": "TJmcGcoKjnY", "original": null, "number": 4, "cdate": 1604247153894, "ddate": null, "tcdate": 1604247153894, "tmdate": 1605024731481, "tddate": null, "forum": "_b8l7rVPe8z", "replyto": "_b8l7rVPe8z", "invitation": "ICLR.cc/2021/Conference/Paper248/-/Official_Review", "content": {"title": "interesting idea with good transferrability", "review": "This paper presents a method for adversarial attacks on object detectors by exploiting relevance maps that are originally intended for model interpretation. Unlike most of the existing methods that attack detection scores directly, the proposed approach focuses on suppressing the relevance map associated with target objects by image perturbation. The idea is interesting and demonstrates good transferability on the tasks of object detection and segmentation. \n\nThe paper is mostly well written and easy to follow. The adversarial object dataset can also be helpful to the research community.\n\nThe main downside of the paper is that some of the comparisons are not apple-to-apple in the experiments. For example, the proposed approach applies update techniques (i.e. Translation-Invariant) to improve transferability. However, it is not my impression that this was done on the baseline methods, which leads to unfair comparison.\n\nSome technical details need to be better articulated in the paper. For example, there is no mentioning of the adversarial loss function and how it is optimized. As pointed out in [2], attacking CNN interpretations is not trivial. Without the details of how to update the gradients of the relevance map, It would make reproducibility difficult.\n\nWhile focusing on a different problem,  the proposed approach shares some similarities with methods designed to attack model interpretations such as [1] and [2], which should be discussed as related work.\n\n[1] Amirata Ghorbani, Abubakar Abid, and James Zou. Interpretation of neural networks is fragile. In Proceedings of the AAAI Conference on Artificial Intelligence, volume 33, pp. 3681\u20133688, 2019\n[2] Xinyang Zhang, Ningfei Wang  Hua Shen, Shouling Ji, Xiapu Luo,Ting Wang, Interpretable Deep Learning under Fire, USENIX Security '20\n", "rating": "6: Marginally above acceptance threshold", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["ICLR.cc/2021/Conference/Paper248/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper248/AnonReviewer3"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Relevance Attack on Detectors", "authorids": ["~Sizhe_Chen1", "hf-inspire@sjtu.edu.cn", "~Xiaolin_Huang1", "~Kun_Zhang1"], "authors": ["Sizhe Chen", "Fan He", "Xiaolin Huang", "Kun Zhang"], "keywords": ["adversarial attack", "relevance map", "object detection", "transferability", "black-box attack"], "abstract": "This paper focuses on high-transferable adversarial attacks on detectors, which are hard to attack in a black-box manner, because of their multiple-output characteristics and the diversity across architectures. To pursue a high attack transferability, one plausible way is to find a common property across detectors, which facilitates the discovery of common weaknesses. We are the first to suggest that the relevance map for detectors is such a property. Based on it, we design a Relevance Attack on Detectors (RAD), which achieves a state-of-the-art transferability, exceeding existing results by above 20%. On MS COCO, the detection mAPs for all 8 black-box architectures are more than halved and the segmentation mAPs are also significantly influenced. Given the great transferability of RAD, we generate the first adversarial dataset for object detection, i.e., Adversarial Objects in COntext (AOCO), which helps to quickly evaluate and improve the robustness of detectors.", "one-sentence_summary": "We design a Relevance Attack on Detectors, a high-transferable attack framework with the state-of-the-art performance.", "pdf": "/pdf/745d9d6e4d46aa97ba592384bcd8aaa803f38d90.pdf", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "chen|relevance_attack_on_detectors", "supplementary_material": "/attachment/af3b9ac9017f0b304cf44fface903c7950ab9ffc.zip", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=K9mMva6mYW", "_bibtex": "@misc{\nchen2021relevance,\ntitle={Relevance Attack on Detectors},\nauthor={Sizhe Chen and Fan He and Xiaolin Huang and Kun Zhang},\nyear={2021},\nurl={https://openreview.net/forum?id=_b8l7rVPe8z}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq . ***Please remember to file the Code-of-Ethics report. Once you submitted the review, a link to the report will be visible in the bottom right corner of your review.***", "required": true, "markdown": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}, "forum": "_b8l7rVPe8z", "replyto": "_b8l7rVPe8z", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"], "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper248/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1607428800000, "duedate": 1606752000000, "multiReply": false, "readers": ["everyone"], "tcdate": 1602538147246, "tmdate": 1606915784079, "super": "ICLR.cc/2021/Conference/-/Official_Review", "signatures": ["OpenReview.net"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Paper248/Reviewers", "OpenReview.net/Support"], "id": "ICLR.cc/2021/Conference/Paper248/-/Official_Review"}}}], "count": 13}