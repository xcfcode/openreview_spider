{"notes": [{"id": "B1xewR4KvH", "original": "r1eoJBP_wr", "number": 1162, "cdate": 1569439319889, "ddate": null, "tcdate": 1569439319889, "tmdate": 1577168234847, "tddate": null, "forum": "B1xewR4KvH", "replyto": null, "invitation": "ICLR.cc/2020/Conference/-/Blind_Submission", "content": {"title": "MANIFOLD FORESTS: CLOSING THE GAP ON NEURAL NETWORKS", "authors": ["Ronan Perry", "Tyler M. Tomita", "Jesse Patsolic", "Benjamin Falk", "Joshua Vogelstein"], "authorids": ["rperry27@jhu.edu", "ttomita2@jhmi.edu", "jpatsolic@jhu.edu", "falk.ben@jhu.edu", "jovo@jhu.edu"], "keywords": ["machine learning", "structured learning", "projections", "structured data", "images", "classification"], "TL;DR": "Classification accuracy of decision forests on structured data, data in which the feature indices matter, can be improved using a specific projection distribution.", "abstract": "Decision forests (DF), in particular random forests and gradient boosting trees, have  demonstrated state-of-the-art accuracy compared to other methods in many supervised learning scenarios. In particular, DFs dominate other methods in tabular data, that is, when the feature space is unstructured, so that the signal is invariant to permuting feature indices.  However, in structured data lying on a manifold---such as images, text, and speech---neural nets (NN) tend to outperform DFs. We conjecture that at least part of the reason for this is that the input to NN is not simply the feature magnitudes, but also their indices (for example, the convolution operation uses ``feature locality). In contrast, naive DF implementations fail to explicitly consider feature indices. A recently proposed DF approach demonstrates that DFs, for each node, implicitly sample a random matrix from some specific distribution.  Here, we build on that to show that one can choose distributions in a manifold aware fashion. For example, for image classification, rather than randomly selecting pixels, one can randomly select contiguous patches. We demonstrate the empirical performance of  data living on three different manifolds: images, time-series, and a torus. In all three cases, our Manifold Forest (Mf) algorithm empirically dominates other state-of-the-art approaches that ignore feature space structure, achieving a lower classification error on all sample sizes. This dominance extends to the MNIST data set as well. Moreover, both training and test time is significantly faster for manifold forests as compared to deep nets. This approach, therefore, has promise to enable DFs and other machine learning methods to close the gap with deep nets on manifold-valued data. ", "pdf": "/pdf/d886b43b85f5aee5abc86a8963c8f170b6d6f1ca.pdf", "paperhash": "perry|manifold_forests_closing_the_gap_on_neural_networks", "original_pdf": "/attachment/d886b43b85f5aee5abc86a8963c8f170b6d6f1ca.pdf", "_bibtex": "@misc{\nperry2020manifold,\ntitle={{\\{}MANIFOLD{\\}} {\\{}FORESTS{\\}}: {\\{}CLOSING{\\}} {\\{}THE{\\}} {\\{}GAP{\\}} {\\{}ON{\\}} {\\{}NEURAL{\\}} {\\{}NETWORKS{\\}}},\nauthor={Ronan Perry and Tyler M. Tomita and Jesse Patsolic and Benjamin Falk and Joshua Vogelstein},\nyear={2020},\nurl={https://openreview.net/forum?id=B1xewR4KvH}\n}"}, "signatures": ["ICLR.cc/2020/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference"], "details": {"replyCount": 4, "writable": false, "overwriting": [], "revisions": false, "tags": [], "invitation": {"reply": {"readers": {"values-regex": ".*"}, "writers": {"values": ["ICLR.cc/2020/Conference"]}, "signatures": {"values": ["ICLR.cc/2020/Conference"]}, "content": {"spotlight_video": {"value-regex": ".*"}, "full_presentation_video": {"value-regex": ".*"}, "original_pdf": {"required": false, "description": "Upload a PDF file that ends with .pdf", "value-regex": ".*"}, "appendix": {"value-regex": ".*"}, "authorids": {"values-regex": ".*"}, "poster": {"value-regex": ".*"}, "authors": {"values": ["Anonymous"]}, "slides": {"value-regex": ".*"}}}, "final": [], "signatures": ["ICLR.cc/2020/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference"], "noninvitees": [], "tcdate": 1569271260237, "tmdate": 1593459412141, "id": "ICLR.cc/2020/Conference/-/Blind_Submission"}}, "tauthor": "OpenReview.net"}, {"id": "-55OfVU8qF", "original": null, "number": 1, "cdate": 1576798716145, "ddate": null, "tcdate": 1576798716145, "tmdate": 1576800920364, "tddate": null, "forum": "B1xewR4KvH", "replyto": "B1xewR4KvH", "invitation": "ICLR.cc/2020/Conference/Paper1162/-/Decision", "content": {"decision": "Reject", "comment": "This work explores how to leverage structure of this input in decision trees, the way this is done for example in convolutional networks.\nAll reviewers agree that the experimental validation of the method as presented is extremely weak. Authors have not provided a response to answer the many concerns raised by reviewers.\nTherefore, we recommend rejection.", "title": "Paper Decision"}, "signatures": ["ICLR.cc/2020/Conference/Program_Chairs"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Program_Chairs"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "MANIFOLD FORESTS: CLOSING THE GAP ON NEURAL NETWORKS", "authors": ["Ronan Perry", "Tyler M. Tomita", "Jesse Patsolic", "Benjamin Falk", "Joshua Vogelstein"], "authorids": ["rperry27@jhu.edu", "ttomita2@jhmi.edu", "jpatsolic@jhu.edu", "falk.ben@jhu.edu", "jovo@jhu.edu"], "keywords": ["machine learning", "structured learning", "projections", "structured data", "images", "classification"], "TL;DR": "Classification accuracy of decision forests on structured data, data in which the feature indices matter, can be improved using a specific projection distribution.", "abstract": "Decision forests (DF), in particular random forests and gradient boosting trees, have  demonstrated state-of-the-art accuracy compared to other methods in many supervised learning scenarios. In particular, DFs dominate other methods in tabular data, that is, when the feature space is unstructured, so that the signal is invariant to permuting feature indices.  However, in structured data lying on a manifold---such as images, text, and speech---neural nets (NN) tend to outperform DFs. We conjecture that at least part of the reason for this is that the input to NN is not simply the feature magnitudes, but also their indices (for example, the convolution operation uses ``feature locality). In contrast, naive DF implementations fail to explicitly consider feature indices. A recently proposed DF approach demonstrates that DFs, for each node, implicitly sample a random matrix from some specific distribution.  Here, we build on that to show that one can choose distributions in a manifold aware fashion. For example, for image classification, rather than randomly selecting pixels, one can randomly select contiguous patches. We demonstrate the empirical performance of  data living on three different manifolds: images, time-series, and a torus. In all three cases, our Manifold Forest (Mf) algorithm empirically dominates other state-of-the-art approaches that ignore feature space structure, achieving a lower classification error on all sample sizes. This dominance extends to the MNIST data set as well. Moreover, both training and test time is significantly faster for manifold forests as compared to deep nets. This approach, therefore, has promise to enable DFs and other machine learning methods to close the gap with deep nets on manifold-valued data. ", "pdf": "/pdf/d886b43b85f5aee5abc86a8963c8f170b6d6f1ca.pdf", "paperhash": "perry|manifold_forests_closing_the_gap_on_neural_networks", "original_pdf": "/attachment/d886b43b85f5aee5abc86a8963c8f170b6d6f1ca.pdf", "_bibtex": "@misc{\nperry2020manifold,\ntitle={{\\{}MANIFOLD{\\}} {\\{}FORESTS{\\}}: {\\{}CLOSING{\\}} {\\{}THE{\\}} {\\{}GAP{\\}} {\\{}ON{\\}} {\\{}NEURAL{\\}} {\\{}NETWORKS{\\}}},\nauthor={Ronan Perry and Tyler M. Tomita and Jesse Patsolic and Benjamin Falk and Joshua Vogelstein},\nyear={2020},\nurl={https://openreview.net/forum?id=B1xewR4KvH}\n}"}, "tags": [], "invitation": {"reply": {"writers": {"description": "How your identity will be displayed.", "values-regex": ["ICLR.cc/2020/Conference/Program_Chairs"]}, "signatures": {"values": ["ICLR.cc/2020/Conference/Program_Chairs"], "description": "How your identity will be displayed."}, "content": {"decision": {"value-radio": ["Accept (Spotlight)", "Accept (Talk)", "Accept (Poster)", "Reject"], "description": "Decision", "required": true, "order": 2}, "title": {"value": "Paper Decision", "required": true, "order": 1}, "comment": {"value-regex": "[\\S\\s]{0,5000}", "description": "", "required": false, "order": 3}}, "forum": "B1xewR4KvH", "replyto": "B1xewR4KvH", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}}, "expdate": 1576854540000, "duedate": 1576853940000, "multiReply": false, "readers": ["everyone"], "invitees": ["ICLR.cc/2020/Conference/Program_Chairs"], "tcdate": 1576795727567, "tmdate": 1576800279828, "super": "ICLR.cc/2020/Conference/-/Decision", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper1162/-/Decision"}}}, {"id": "SyeMINIucB", "original": null, "number": 3, "cdate": 1572525129992, "ddate": null, "tcdate": 1572525129992, "tmdate": 1574254344100, "tddate": null, "forum": "B1xewR4KvH", "replyto": "B1xewR4KvH", "invitation": "ICLR.cc/2020/Conference/Paper1162/-/Official_Review", "content": {"experience_assessment": "I have published one or two papers in this area.", "rating": "3: Weak Reject", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "title": "Official Blind Review #4", "review": "\n\n====== Post Rebuttal ======\n\nNo rebuttal was provided and all reviewers have raised issues. Therefore, I will maintain the original rating.\n\n====== Summary====== \n\nThe paper puts forward a potential issue with the standard decision tree and tries to remedy it. The issue is that standard decision trees, by independently picking the split feature(s), virtually discard the structure of the input features (if any). In this work, structure essentially refers to ordered input features such as sequences, signals, and images. The work is motivated by the fact that convolutional networks (ConvNet) exploit this structure thanks to its local convolution operation. The idea of this work is to bridge this gap by constraining the split feature selection to follow the local structures of the input where each split feature would correspond to a local bounding box of the input feature. Applying this idea to random forests, it demonstrates significant improvements over unstructured split features, on a few synthesized datasets as well as MNIST dataset. The performance is also compared to one ConvNet architecture which demonstrates similar performance on synthesized datasets while being considerably slower than the proposed random forests.\n\n\n====== Strengths and Weaknesses ====== \n\n+ The motivation to make random forests respect the input structure similar to ConvNets is well-grounded and important since random forests are still being used in certain applications where computational complexity and/or interpretability are crucial factors.\n+ It proposes a simple technique to add locality to the split criterion which brings significant improvements over the standard random forest.\n\n- I believe the paper\u2019s title should be closing the gap to *convolutional* neural networks since fully-connected networks are not local in the first place. \n- continuing on the previous point, the proposed method pushes the decision forests closer to \u201clocally-connected\u201d networks where, although the features are local, they are not shared across different locations in the input. The additional \u201csharing\u201d property which takes locally-connected networks to convolutional networks is an important property of ConvNets since it brings translation equivariance for the representations. The proposed random forest method is not translation-equivariant by design and is only local. \n- regarding the previous point, a larger difference between ConvNet and the proposed method is more imminent if one goes to datasets with \u201cnon-aligned\u201d observations. This already becomes more evident in the MNIST (which contains mostly aligned digits) where ConvNet clearly outperform MORF but would likely become more significant when going to real-world datasets, e.g. CIFAR.\n\n- the proposed method is very similar to patch-based random forest image recognition methods. For instance, several variants exist that are used for object or part detection in a given image where a patch is selected from the image for the split criterion. This patch will respect locality in a similar way to the proposed MORF\u2019s bounding boxes. For instance, see \u201ctomography scans\u201d example of Criminisi et al. 2012 (section 4.5).\n\n- The paper is missing to provide many important details\n- what are the actual hyperparameter (hp) values used for the different methods in figure 1,2, and 3. This includes the hp relevant for the random forests including the number of decision trees, the stopping criterion, the random data partitioning method, number of random projections, as well as h_min, h_max, w_min, and w_max. It also does not discuss the hyper parameters of the baseline methods including k for KNN, distance measure for KNN, penalty cost for SVM, variance for the RBF kernel, ConvNet architecture, etc.\n- more importantly, it is not mentioned how these hp are optimized for the different baselines as well as the proposed method. What algorithm has been used (e.g. grid search)? How much hp optimization budget is used for different baselines? Is there a validation set put aside for hp optimization?\n- from the description in the start of page 4, it seems that the atoms for the proposed MORF are vectors of binary dimensions while for the general SPORF each atom\u2019s element can be -1 as well (page 3). Why is this choice made despite the fact that it reduces the capacity of the model?\n\n- the bounding box sampling seems biased as presented. That is, bounding boxes closer (than h_max and/or w_max) to the right and/or lower borders are more likely since the number of valid boxes will be lower. \n\n\n====== Final Decision ====== \n\nI think it will be very interesting to bridge the gap between ConvNets and random forests since the latter comes with attractive properties. While I find all the concerns that are listed above important, my rating is mainly due to the novelty of this work compared to the prior patch-based random forest techniques for image analysis.\n\n\n====== Points of improvements ====== \n\nI believe it\u2019s important to disentangle the two main properties of convolution operation in ConvNets being shared and local parameters. Then, accordingly propose strategies to bring these properties to a decision tree.\n\n", "review_assessment:_checking_correctness_of_derivations_and_theory": "I carefully checked the derivations and theory."}, "signatures": ["ICLR.cc/2020/Conference/Paper1162/AnonReviewer4"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1162/AnonReviewer4"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "MANIFOLD FORESTS: CLOSING THE GAP ON NEURAL NETWORKS", "authors": ["Ronan Perry", "Tyler M. Tomita", "Jesse Patsolic", "Benjamin Falk", "Joshua Vogelstein"], "authorids": ["rperry27@jhu.edu", "ttomita2@jhmi.edu", "jpatsolic@jhu.edu", "falk.ben@jhu.edu", "jovo@jhu.edu"], "keywords": ["machine learning", "structured learning", "projections", "structured data", "images", "classification"], "TL;DR": "Classification accuracy of decision forests on structured data, data in which the feature indices matter, can be improved using a specific projection distribution.", "abstract": "Decision forests (DF), in particular random forests and gradient boosting trees, have  demonstrated state-of-the-art accuracy compared to other methods in many supervised learning scenarios. In particular, DFs dominate other methods in tabular data, that is, when the feature space is unstructured, so that the signal is invariant to permuting feature indices.  However, in structured data lying on a manifold---such as images, text, and speech---neural nets (NN) tend to outperform DFs. We conjecture that at least part of the reason for this is that the input to NN is not simply the feature magnitudes, but also their indices (for example, the convolution operation uses ``feature locality). In contrast, naive DF implementations fail to explicitly consider feature indices. A recently proposed DF approach demonstrates that DFs, for each node, implicitly sample a random matrix from some specific distribution.  Here, we build on that to show that one can choose distributions in a manifold aware fashion. For example, for image classification, rather than randomly selecting pixels, one can randomly select contiguous patches. We demonstrate the empirical performance of  data living on three different manifolds: images, time-series, and a torus. In all three cases, our Manifold Forest (Mf) algorithm empirically dominates other state-of-the-art approaches that ignore feature space structure, achieving a lower classification error on all sample sizes. This dominance extends to the MNIST data set as well. Moreover, both training and test time is significantly faster for manifold forests as compared to deep nets. This approach, therefore, has promise to enable DFs and other machine learning methods to close the gap with deep nets on manifold-valued data. ", "pdf": "/pdf/d886b43b85f5aee5abc86a8963c8f170b6d6f1ca.pdf", "paperhash": "perry|manifold_forests_closing_the_gap_on_neural_networks", "original_pdf": "/attachment/d886b43b85f5aee5abc86a8963c8f170b6d6f1ca.pdf", "_bibtex": "@misc{\nperry2020manifold,\ntitle={{\\{}MANIFOLD{\\}} {\\{}FORESTS{\\}}: {\\{}CLOSING{\\}} {\\{}THE{\\}} {\\{}GAP{\\}} {\\{}ON{\\}} {\\{}NEURAL{\\}} {\\{}NETWORKS{\\}}},\nauthor={Ronan Perry and Tyler M. Tomita and Jesse Patsolic and Benjamin Falk and Joshua Vogelstein},\nyear={2020},\nurl={https://openreview.net/forum?id=B1xewR4KvH}\n}"}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "B1xewR4KvH", "replyto": "B1xewR4KvH", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper1162/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper1162/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1575866168748, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper1162/Reviewers"], "noninvitees": [], "tcdate": 1570237741439, "tmdate": 1575866168764, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper1162/-/Official_Review"}}}, {"id": "SkxVEsCjKB", "original": null, "number": 1, "cdate": 1571707692304, "ddate": null, "tcdate": 1571707692304, "tmdate": 1572972504657, "tddate": null, "forum": "B1xewR4KvH", "replyto": "B1xewR4KvH", "invitation": "ICLR.cc/2020/Conference/Paper1162/-/Official_Review", "content": {"rating": "3: Weak Reject", "experience_assessment": "I have published in this field for several years.", "review_assessment:_checking_correctness_of_derivations_and_theory": "I did not assess the derivations or theory.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #2", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review": "This paper proposed a new method called manifold forest to improve decision forest (DF) classification results. It is motivated by that, natural data is often in some manifold but not randomly distributed. It showed how to use the 2D spatial structures of natural images by constructing structured atoms. Results on 3 toy examples and MNIST showed the better performance than standard RF and SPORF.\n\nOverall, the paper is easy to follow and well written. The idea is intuitive: using structured 2D information to improve the classification results. But there are some issues with the implemetation.\n\n1. In image classification, we definitely need 2D structure information. This is normally extracted by the descriptors such as SIFT, GIST, where the 2D information has been included. It is rare to use the pixel values as the features directly for classification.   In this case, the benefit of the proposed method is very weak. This is the main issue of the paper. No results on real features.\n\n2. The results are weak too. The real data is MNIST, which is also a very toy dataset. It would be good to include some real world image dataset, such as CIFAR, ImageNet etc.\n\n3. The algorithm is somehow incremental compared with SPORF. \n"}, "signatures": ["ICLR.cc/2020/Conference/Paper1162/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1162/AnonReviewer2"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "MANIFOLD FORESTS: CLOSING THE GAP ON NEURAL NETWORKS", "authors": ["Ronan Perry", "Tyler M. Tomita", "Jesse Patsolic", "Benjamin Falk", "Joshua Vogelstein"], "authorids": ["rperry27@jhu.edu", "ttomita2@jhmi.edu", "jpatsolic@jhu.edu", "falk.ben@jhu.edu", "jovo@jhu.edu"], "keywords": ["machine learning", "structured learning", "projections", "structured data", "images", "classification"], "TL;DR": "Classification accuracy of decision forests on structured data, data in which the feature indices matter, can be improved using a specific projection distribution.", "abstract": "Decision forests (DF), in particular random forests and gradient boosting trees, have  demonstrated state-of-the-art accuracy compared to other methods in many supervised learning scenarios. In particular, DFs dominate other methods in tabular data, that is, when the feature space is unstructured, so that the signal is invariant to permuting feature indices.  However, in structured data lying on a manifold---such as images, text, and speech---neural nets (NN) tend to outperform DFs. We conjecture that at least part of the reason for this is that the input to NN is not simply the feature magnitudes, but also their indices (for example, the convolution operation uses ``feature locality). In contrast, naive DF implementations fail to explicitly consider feature indices. A recently proposed DF approach demonstrates that DFs, for each node, implicitly sample a random matrix from some specific distribution.  Here, we build on that to show that one can choose distributions in a manifold aware fashion. For example, for image classification, rather than randomly selecting pixels, one can randomly select contiguous patches. We demonstrate the empirical performance of  data living on three different manifolds: images, time-series, and a torus. In all three cases, our Manifold Forest (Mf) algorithm empirically dominates other state-of-the-art approaches that ignore feature space structure, achieving a lower classification error on all sample sizes. This dominance extends to the MNIST data set as well. Moreover, both training and test time is significantly faster for manifold forests as compared to deep nets. This approach, therefore, has promise to enable DFs and other machine learning methods to close the gap with deep nets on manifold-valued data. ", "pdf": "/pdf/d886b43b85f5aee5abc86a8963c8f170b6d6f1ca.pdf", "paperhash": "perry|manifold_forests_closing_the_gap_on_neural_networks", "original_pdf": "/attachment/d886b43b85f5aee5abc86a8963c8f170b6d6f1ca.pdf", "_bibtex": "@misc{\nperry2020manifold,\ntitle={{\\{}MANIFOLD{\\}} {\\{}FORESTS{\\}}: {\\{}CLOSING{\\}} {\\{}THE{\\}} {\\{}GAP{\\}} {\\{}ON{\\}} {\\{}NEURAL{\\}} {\\{}NETWORKS{\\}}},\nauthor={Ronan Perry and Tyler M. Tomita and Jesse Patsolic and Benjamin Falk and Joshua Vogelstein},\nyear={2020},\nurl={https://openreview.net/forum?id=B1xewR4KvH}\n}"}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "B1xewR4KvH", "replyto": "B1xewR4KvH", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper1162/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper1162/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1575866168748, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper1162/Reviewers"], "noninvitees": [], "tcdate": 1570237741439, "tmdate": 1575866168764, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper1162/-/Official_Review"}}}, {"id": "HyeFQ5Kb9B", "original": null, "number": 2, "cdate": 1572080160711, "ddate": null, "tcdate": 1572080160711, "tmdate": 1572972504622, "tddate": null, "forum": "B1xewR4KvH", "replyto": "B1xewR4KvH", "invitation": "ICLR.cc/2020/Conference/Paper1162/-/Official_Review", "content": {"experience_assessment": "I have published one or two papers in this area.", "rating": "1: Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #1", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "The goal of the paper is clear. However, the proposed method has only a very incremental novelty compared to SPORF and the previous approaches in computer vision (e.g., Shotton et al., 2011). Although the authors claim the method can take advantage of structure in all kinds of data, the only conducted experiment is on the image data which is fairly limited.\n\nIn Fig. 1, they claim MORF outperforms other methods given fewer training data. However, for classifying\u00a0Orthogonal Bars, CNN still outperforms MORF when few training data are given. The results on MNIST is also not impressive. CNN is still much better compared to other tree-based methods. Moreover, no other real-world dataset has been conducted experiments on.\n\nIn general, the paper's goal is clear and interesting. But the authors failed to propose a novel method and the results are not convincing. Hence, I recommend rejection.\n"}, "signatures": ["ICLR.cc/2020/Conference/Paper1162/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1162/AnonReviewer1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "MANIFOLD FORESTS: CLOSING THE GAP ON NEURAL NETWORKS", "authors": ["Ronan Perry", "Tyler M. Tomita", "Jesse Patsolic", "Benjamin Falk", "Joshua Vogelstein"], "authorids": ["rperry27@jhu.edu", "ttomita2@jhmi.edu", "jpatsolic@jhu.edu", "falk.ben@jhu.edu", "jovo@jhu.edu"], "keywords": ["machine learning", "structured learning", "projections", "structured data", "images", "classification"], "TL;DR": "Classification accuracy of decision forests on structured data, data in which the feature indices matter, can be improved using a specific projection distribution.", "abstract": "Decision forests (DF), in particular random forests and gradient boosting trees, have  demonstrated state-of-the-art accuracy compared to other methods in many supervised learning scenarios. In particular, DFs dominate other methods in tabular data, that is, when the feature space is unstructured, so that the signal is invariant to permuting feature indices.  However, in structured data lying on a manifold---such as images, text, and speech---neural nets (NN) tend to outperform DFs. We conjecture that at least part of the reason for this is that the input to NN is not simply the feature magnitudes, but also their indices (for example, the convolution operation uses ``feature locality). In contrast, naive DF implementations fail to explicitly consider feature indices. A recently proposed DF approach demonstrates that DFs, for each node, implicitly sample a random matrix from some specific distribution.  Here, we build on that to show that one can choose distributions in a manifold aware fashion. For example, for image classification, rather than randomly selecting pixels, one can randomly select contiguous patches. We demonstrate the empirical performance of  data living on three different manifolds: images, time-series, and a torus. In all three cases, our Manifold Forest (Mf) algorithm empirically dominates other state-of-the-art approaches that ignore feature space structure, achieving a lower classification error on all sample sizes. This dominance extends to the MNIST data set as well. Moreover, both training and test time is significantly faster for manifold forests as compared to deep nets. This approach, therefore, has promise to enable DFs and other machine learning methods to close the gap with deep nets on manifold-valued data. ", "pdf": "/pdf/d886b43b85f5aee5abc86a8963c8f170b6d6f1ca.pdf", "paperhash": "perry|manifold_forests_closing_the_gap_on_neural_networks", "original_pdf": "/attachment/d886b43b85f5aee5abc86a8963c8f170b6d6f1ca.pdf", "_bibtex": "@misc{\nperry2020manifold,\ntitle={{\\{}MANIFOLD{\\}} {\\{}FORESTS{\\}}: {\\{}CLOSING{\\}} {\\{}THE{\\}} {\\{}GAP{\\}} {\\{}ON{\\}} {\\{}NEURAL{\\}} {\\{}NETWORKS{\\}}},\nauthor={Ronan Perry and Tyler M. Tomita and Jesse Patsolic and Benjamin Falk and Joshua Vogelstein},\nyear={2020},\nurl={https://openreview.net/forum?id=B1xewR4KvH}\n}"}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "B1xewR4KvH", "replyto": "B1xewR4KvH", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper1162/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper1162/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1575866168748, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper1162/Reviewers"], "noninvitees": [], "tcdate": 1570237741439, "tmdate": 1575866168764, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper1162/-/Official_Review"}}}], "count": 5}