{"notes": [{"id": "HlptuA5gQf", "original": null, "number": 9, "cdate": 1581616713233, "ddate": null, "tcdate": 1581616713233, "tmdate": 1581616823222, "tddate": null, "forum": "ryghPCVYvH", "replyto": "7Qys7zNwP", "invitation": "ICLR.cc/2020/Conference/Paper1189/-/Official_Comment", "content": {"title": "Author Response", "comment": "We thank the meta-reviewer for the comments. Here we would like to express our concerns with the statements in the decision comment:\n\n1). We propose to use kernel methods for multi-view generation \u2018and\u2019 uncorrelated feature learning.\n\n2). The points are not mapped into a common subspace. Rather, they are mapped to the feature-spaces and the eigendecomposition of the concatenated kernel matrices represents the common subspace.\n\n3). Moreover, all 3 reviewers agree that the \u2018paper is easy to read\u2019.\n\n4). The reference \u201cImposter Networks\u201d is not particularly relevant in this regard (it focuses on classification tasks for low-power devices). As opposed to Imposter Networks, the kernel in our model is not an additional layer to the network, rather it is inherent to the model.\n\n5). Generation is very fast when using explicit feature-maps. In this case, it just means decoding the latent-vectors (by passing through the transposed-CNN) and it scales linearly with the desired number of generated samples. However, when using implicit feature-maps, pre-image problem needs to be solved and depending on the method chosen, the generation time would vary.\n\n6). Benefits include new synergy between (deep) neural networks and kernel methods, modelling a common subspace from different data sources enabling multi-view generation and disentangled (uncorrelated due to PCA in feature space) feature learning, all within the same model. These are validated through various experiments (qualitative & quantitative).\n\n7). Lastly, Rev #4 upgraded the score based on our updates, Rev #2 was the most positive but never responded post-rebuttal (the last response was Nov 5) and Rev #1 was asking for classification performance, which is not in the scope of this current work (unsupervised learning/generative modelling)."}, "signatures": ["ICLR.cc/2020/Conference/Paper1189/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1189/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["arun.pandey@esat.kuleuven.be", "joachim.schreurs@esat.kuleuven.be", "johan.suykens@esat.kuleuven.be"], "title": "Generative Restricted Kernel Machines", "authors": ["Arun Pandey", "Joachim Schreurs", "Johan A.K. Suykens"], "pdf": "/pdf/a3f86a68c57e352ef8915f18b3c53a11a455ddc8.pdf", "TL;DR": "Gen-RKM: a novel framework for generative models using Restricted Kernel Machines with multi-view generation and uncorrelated feature learning.", "abstract": "We introduce a novel framework for generative models based on Restricted Kernel Machines (RKMs) with multi-view generation and uncorrelated feature learning capabilities, called Gen-RKM. To incorporate multi-view generation, this mechanism uses a shared representation of data from various views. The mechanism is flexible to incorporate both kernel-based, (deep) neural network and convolutional based models within the same setting. To update the parameters of the network, we propose a novel training procedure which jointly learns the features and shared representation. Experiments demonstrate the potential of the framework through qualitative evaluation of generated samples.", "keywords": ["Generative models", "Kernel methods", "Deep learning"], "paperhash": "pandey|generative_restricted_kernel_machines", "original_pdf": "/attachment/d986a95eb14b9a0dd3b1d52128df981f71ab86ca.pdf", "_bibtex": "@misc{\npandey2020generative,\ntitle={Generative Restricted Kernel Machines},\nauthor={Arun Pandey and Joachim Schreurs and Johan A.K. Suykens},\nyear={2020},\nurl={https://openreview.net/forum?id=ryghPCVYvH}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "ryghPCVYvH", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper1189/Authors", "ICLR.cc/2020/Conference/Paper1189/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper1189/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper1189/Reviewers", "ICLR.cc/2020/Conference/Paper1189/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper1189/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper1189/Authors|ICLR.cc/2020/Conference/Paper1189/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504159862, "tmdate": 1576860535323, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper1189/Authors", "ICLR.cc/2020/Conference/Paper1189/Reviewers", "ICLR.cc/2020/Conference/Paper1189/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper1189/-/Official_Comment"}}}, {"id": "ryghPCVYvH", "original": "BJen0KPOPr", "number": 1189, "cdate": 1569439331866, "ddate": null, "tcdate": 1569439331866, "tmdate": 1577168280348, "tddate": null, "forum": "ryghPCVYvH", "replyto": null, "invitation": "ICLR.cc/2020/Conference/-/Blind_Submission", "content": {"authorids": ["arun.pandey@esat.kuleuven.be", "joachim.schreurs@esat.kuleuven.be", "johan.suykens@esat.kuleuven.be"], "title": "Generative Restricted Kernel Machines", "authors": ["Arun Pandey", "Joachim Schreurs", "Johan A.K. Suykens"], "pdf": "/pdf/a3f86a68c57e352ef8915f18b3c53a11a455ddc8.pdf", "TL;DR": "Gen-RKM: a novel framework for generative models using Restricted Kernel Machines with multi-view generation and uncorrelated feature learning.", "abstract": "We introduce a novel framework for generative models based on Restricted Kernel Machines (RKMs) with multi-view generation and uncorrelated feature learning capabilities, called Gen-RKM. To incorporate multi-view generation, this mechanism uses a shared representation of data from various views. The mechanism is flexible to incorporate both kernel-based, (deep) neural network and convolutional based models within the same setting. To update the parameters of the network, we propose a novel training procedure which jointly learns the features and shared representation. Experiments demonstrate the potential of the framework through qualitative evaluation of generated samples.", "keywords": ["Generative models", "Kernel methods", "Deep learning"], "paperhash": "pandey|generative_restricted_kernel_machines", "original_pdf": "/attachment/d986a95eb14b9a0dd3b1d52128df981f71ab86ca.pdf", "_bibtex": "@misc{\npandey2020generative,\ntitle={Generative Restricted Kernel Machines},\nauthor={Arun Pandey and Joachim Schreurs and Johan A.K. Suykens},\nyear={2020},\nurl={https://openreview.net/forum?id=ryghPCVYvH}\n}"}, "signatures": ["ICLR.cc/2020/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference"], "details": {"replyCount": 10, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"reply": {"readers": {"values-regex": ".*"}, "writers": {"values": ["ICLR.cc/2020/Conference"]}, "signatures": {"values": ["ICLR.cc/2020/Conference"]}, "content": {"spotlight_video": {"value-regex": ".*"}, "full_presentation_video": {"value-regex": ".*"}, "original_pdf": {"required": false, "description": "Upload a PDF file that ends with .pdf", "value-regex": ".*"}, "appendix": {"value-regex": ".*"}, "authorids": {"values-regex": ".*"}, "poster": {"value-regex": ".*"}, "authors": {"values": ["Anonymous"]}, "slides": {"value-regex": ".*"}}}, "final": [], "signatures": ["ICLR.cc/2020/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference"], "noninvitees": [], "tcdate": 1569271260237, "tmdate": 1593459412141, "id": "ICLR.cc/2020/Conference/-/Blind_Submission"}}, "tauthor": "OpenReview.net"}, {"id": "7Qys7zNwP", "original": null, "number": 1, "cdate": 1576798716878, "ddate": null, "tcdate": 1576798716878, "tmdate": 1576800919660, "tddate": null, "forum": "ryghPCVYvH", "replyto": "ryghPCVYvH", "invitation": "ICLR.cc/2020/Conference/Paper1189/-/Decision", "content": {"decision": "Reject", "comment": "The paper proposes a way to use kernel method for multi-view generation. The points are mapped into a common subspace (with CNN feature extractor and kernel on top), and then a generation procedure from a latent point is given. \nI found the paper not easy to ready and follow; the idea of using CNN + kernel methods have been around for some years (for example, see \"Impostor networks\" by Lebedev et. al), and explicit feature map shows that kernel is just an additional layer to the network. Overall, the approach is straightforward, the generation can be quite slow and the benefits are not clear. The reviewers are mildly negative, so I think this time this paper can not be accepted.", "title": "Paper Decision"}, "signatures": ["ICLR.cc/2020/Conference/Program_Chairs"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Program_Chairs"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["arun.pandey@esat.kuleuven.be", "joachim.schreurs@esat.kuleuven.be", "johan.suykens@esat.kuleuven.be"], "title": "Generative Restricted Kernel Machines", "authors": ["Arun Pandey", "Joachim Schreurs", "Johan A.K. Suykens"], "pdf": "/pdf/a3f86a68c57e352ef8915f18b3c53a11a455ddc8.pdf", "TL;DR": "Gen-RKM: a novel framework for generative models using Restricted Kernel Machines with multi-view generation and uncorrelated feature learning.", "abstract": "We introduce a novel framework for generative models based on Restricted Kernel Machines (RKMs) with multi-view generation and uncorrelated feature learning capabilities, called Gen-RKM. To incorporate multi-view generation, this mechanism uses a shared representation of data from various views. The mechanism is flexible to incorporate both kernel-based, (deep) neural network and convolutional based models within the same setting. To update the parameters of the network, we propose a novel training procedure which jointly learns the features and shared representation. Experiments demonstrate the potential of the framework through qualitative evaluation of generated samples.", "keywords": ["Generative models", "Kernel methods", "Deep learning"], "paperhash": "pandey|generative_restricted_kernel_machines", "original_pdf": "/attachment/d986a95eb14b9a0dd3b1d52128df981f71ab86ca.pdf", "_bibtex": "@misc{\npandey2020generative,\ntitle={Generative Restricted Kernel Machines},\nauthor={Arun Pandey and Joachim Schreurs and Johan A.K. Suykens},\nyear={2020},\nurl={https://openreview.net/forum?id=ryghPCVYvH}\n}"}, "tags": [], "invitation": {"reply": {"writers": {"description": "How your identity will be displayed.", "values-regex": ["ICLR.cc/2020/Conference/Program_Chairs"]}, "signatures": {"values": ["ICLR.cc/2020/Conference/Program_Chairs"], "description": "How your identity will be displayed."}, "content": {"decision": {"value-radio": ["Accept (Spotlight)", "Accept (Talk)", "Accept (Poster)", "Reject"], "description": "Decision", "required": true, "order": 2}, "title": {"value": "Paper Decision", "required": true, "order": 1}, "comment": {"value-regex": "[\\S\\s]{0,5000}", "description": "", "required": false, "order": 3}}, "forum": "ryghPCVYvH", "replyto": "ryghPCVYvH", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}}, "expdate": 1576854540000, "duedate": 1576853940000, "multiReply": false, "readers": ["everyone"], "invitees": ["ICLR.cc/2020/Conference/Program_Chairs"], "tcdate": 1576795708458, "tmdate": 1576800256884, "super": "ICLR.cc/2020/Conference/-/Decision", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper1189/-/Decision"}}}, {"id": "BJly_2s4cB", "original": null, "number": 3, "cdate": 1572285542573, "ddate": null, "tcdate": 1572285542573, "tmdate": 1574617642778, "tddate": null, "forum": "ryghPCVYvH", "replyto": "ryghPCVYvH", "invitation": "ICLR.cc/2020/Conference/Paper1189/-/Official_Review", "content": {"experience_assessment": "I have published one or two papers in this area.", "rating": "6: Weak Accept", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "title": "Official Blind Review #4", "review": "There exists two papers:\n[1] Multimodal Learning with Deep Boltzmann Machines, http://jmlr.org/papers/volume15/srivastava14b/srivastava14b.pdf\n[2] Deep Restricted Kernel Machines Using Conjugate Feature Duality, ftp://ftp.esat.kuleuven.ac.be/stadius/suykens/reports/deepRKM1.pdf\n\nIn particular [2] considers a model, which is similar to a Boltzmann machine, but at the same time it is based on kernel features, and uses structure of the corresponding optimization problem to obtain a solution in a semi-explicit way.\n\nThe authors of the considered paper \n1) generalise a multimodal variant of the Boltzmann machine from [1] (which uses a special cross-product term to take into account dependency between modalities) to the case of kernel machines,\n2) demonstrate on several typical datasets that using explicit deep network features it is possible to model images and data with two modalities (faces/textual description of faces).\n\nComments:\n- From the description of the functionals L1 and L2 (bottom of page 4 and top of the page 5) the reader can think that the authors tune parameters (zeta_1,theta_1) and (zeta_2,theta_2) for each sample point separately\n- The authors claimed that the experiments were done both for kernel features and for explicit features based on neural networks. However, in the experimental section there are no results obtained when using implicit kernels. Nothings is told on how to select kernel parameters\n- The authors claimed that thanks to PCA-like definition of latent vectors they are orthogonal which is similar to disentangle representations. However, there are no any empirical evidences whether it is possible to benefit somehow from that orthogonal property, as well as there is no comparison with approaches to construct disentangle\u0432 latent representation for other types of generative models.\n\nConclusions:\n- In general the text is accurately written, the work is well organised.\n- Still I was not able to understand the main idea of the paper. \na) if the main idea of the paper that the authors propose some new method for generative modeling of multi-modal data, then the authors should make significantly more diverse experiments and ablation studies. Actually, this is not the case of the current work. The authors did not provide any quantitate measure and comparison with existing approaches;\nb) if the main idea is to present a new approach, then still I would not call the approach completely new, as it is based on well-known ideas and its benefits are completely not obvious.\n\nI guess that the paper can be published, but only after issues in a) are addressed.", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory."}, "signatures": ["ICLR.cc/2020/Conference/Paper1189/AnonReviewer4"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1189/AnonReviewer4"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["arun.pandey@esat.kuleuven.be", "joachim.schreurs@esat.kuleuven.be", "johan.suykens@esat.kuleuven.be"], "title": "Generative Restricted Kernel Machines", "authors": ["Arun Pandey", "Joachim Schreurs", "Johan A.K. Suykens"], "pdf": "/pdf/a3f86a68c57e352ef8915f18b3c53a11a455ddc8.pdf", "TL;DR": "Gen-RKM: a novel framework for generative models using Restricted Kernel Machines with multi-view generation and uncorrelated feature learning.", "abstract": "We introduce a novel framework for generative models based on Restricted Kernel Machines (RKMs) with multi-view generation and uncorrelated feature learning capabilities, called Gen-RKM. To incorporate multi-view generation, this mechanism uses a shared representation of data from various views. The mechanism is flexible to incorporate both kernel-based, (deep) neural network and convolutional based models within the same setting. To update the parameters of the network, we propose a novel training procedure which jointly learns the features and shared representation. Experiments demonstrate the potential of the framework through qualitative evaluation of generated samples.", "keywords": ["Generative models", "Kernel methods", "Deep learning"], "paperhash": "pandey|generative_restricted_kernel_machines", "original_pdf": "/attachment/d986a95eb14b9a0dd3b1d52128df981f71ab86ca.pdf", "_bibtex": "@misc{\npandey2020generative,\ntitle={Generative Restricted Kernel Machines},\nauthor={Arun Pandey and Joachim Schreurs and Johan A.K. Suykens},\nyear={2020},\nurl={https://openreview.net/forum?id=ryghPCVYvH}\n}"}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "ryghPCVYvH", "replyto": "ryghPCVYvH", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper1189/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper1189/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1575633590007, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper1189/Reviewers"], "noninvitees": [], "tcdate": 1570237741037, "tmdate": 1575633590020, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper1189/-/Official_Review"}}}, {"id": "HJgqjEXpFH", "original": null, "number": 1, "cdate": 1571792033998, "ddate": null, "tcdate": 1571792033998, "tmdate": 1574347497454, "tddate": null, "forum": "ryghPCVYvH", "replyto": "ryghPCVYvH", "invitation": "ICLR.cc/2020/Conference/Paper1189/-/Official_Review", "content": {"experience_assessment": "I do not know much about this area.", "rating": "3: Weak Reject", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "title": "Official Blind Review #1", "review": "This paper presents a model and training framework for generating samples based on restricted kernel machines. It is extended to multi-view generation and uncorrelated feature representation learning. \n\n- The paper is well-written and well-organized. Notations and claims are clear.\n\n- The idea of a multi-view generation model based on restricted kernel machines is interesting. However, the paper seems to be limited to model definition and algorithm overview without a performance evaluating analysis. \n\n\n- The experimental evaluations are not satisfactory. Although it is claimed in the paper that the model is able to generate high quality images, it is very hard to be confirmed with these experiments. There is no concrete attempt at comparing the performance of the model to the other used methodologies. Generating high quality images with multiple views is an interesting problem, and there are good works in the field addressing the issues. To name a few:\nZhu, Z., Luo, P., Wang, X., Tang, X.: Multi-view perceptron: a deep model for learning face identity and view representations. In: Advances in Neural Information Processing Systems (NIPS). pp. 217\u2013225, (2014)\nKan, M., Shan, S., Chen, X.: Multi-view deep network for cross-view classification. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR). pp. 4847\u20134855, (2016) \nYin, X., Liu, X.: Multi-task convolutional neural network for pose-invariant face recognition. IEEE Transactions on Image Processing (2017) \nYim, J., Jung, H., Yoo, B., Choi, C., Park, D., Kim, J.: Rotating your face using multitask deep neural network. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR). pp. 676\u2013684, (2015)\nYu Tian,\u00a0Xi Peng\u00a0,\u00a0Long Zhao,\u00a0Shaoting Zhang\u00a0,\u00a0,Dimitris N. Metaxas , CR-GAN: Learning Complete Representations for Multi-view Generation, arXiv: 1806.11191, 2018.\n\nThere might be differences between these works and the paper, it is common to evaluate the quality of the generation to other models in terms of accuracy or in the classification tasks. Unfortunately, there is no such quantitative analysis in the paper. So the advantages of the proposed model is not very clear since there is not enough quantitative performance analysis. It would be interesting to see complexity analysis to evaluate the computational costs.\n\nOverall, I do not recommend this paper for publication. The experimental results are not satisfactory, and the paper needs improvements in that regard.\n\n** update:\nI would like to thank the authors for their comments. However, I still see major issues in the paper unresolved and my review remains the same. ", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory."}, "signatures": ["ICLR.cc/2020/Conference/Paper1189/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1189/AnonReviewer1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["arun.pandey@esat.kuleuven.be", "joachim.schreurs@esat.kuleuven.be", "johan.suykens@esat.kuleuven.be"], "title": "Generative Restricted Kernel Machines", "authors": ["Arun Pandey", "Joachim Schreurs", "Johan A.K. Suykens"], "pdf": "/pdf/a3f86a68c57e352ef8915f18b3c53a11a455ddc8.pdf", "TL;DR": "Gen-RKM: a novel framework for generative models using Restricted Kernel Machines with multi-view generation and uncorrelated feature learning.", "abstract": "We introduce a novel framework for generative models based on Restricted Kernel Machines (RKMs) with multi-view generation and uncorrelated feature learning capabilities, called Gen-RKM. To incorporate multi-view generation, this mechanism uses a shared representation of data from various views. The mechanism is flexible to incorporate both kernel-based, (deep) neural network and convolutional based models within the same setting. To update the parameters of the network, we propose a novel training procedure which jointly learns the features and shared representation. Experiments demonstrate the potential of the framework through qualitative evaluation of generated samples.", "keywords": ["Generative models", "Kernel methods", "Deep learning"], "paperhash": "pandey|generative_restricted_kernel_machines", "original_pdf": "/attachment/d986a95eb14b9a0dd3b1d52128df981f71ab86ca.pdf", "_bibtex": "@misc{\npandey2020generative,\ntitle={Generative Restricted Kernel Machines},\nauthor={Arun Pandey and Joachim Schreurs and Johan A.K. Suykens},\nyear={2020},\nurl={https://openreview.net/forum?id=ryghPCVYvH}\n}"}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "ryghPCVYvH", "replyto": "ryghPCVYvH", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper1189/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper1189/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1575633590007, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper1189/Reviewers"], "noninvitees": [], "tcdate": 1570237741037, "tmdate": 1575633590020, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper1189/-/Official_Review"}}}, {"id": "H1xxIIE3sr", "original": null, "number": 6, "cdate": 1573828168196, "ddate": null, "tcdate": 1573828168196, "tmdate": 1573828168196, "tddate": null, "forum": "ryghPCVYvH", "replyto": "HJgqjEXpFH", "invitation": "ICLR.cc/2020/Conference/Paper1189/-/Official_Comment", "content": {"title": "Response reviewer 1", "comment": "We\u2019d like to thank the reviewer for their review and helpful suggestions.\n\n1) \u201cThe experimental evaluations are not satisfactory. Although it is claimed in the paper that the model is able to generate high quality images, it is very hard to be confirmed with these experiments. There is no concrete attempt at comparing the performance of the model to the other used methodologies.\u201d\n\nWe thank the reviewer for the feedback and agree with the statement . We extended the experimental section with additional experiments. The details are discussed in point 5 in the response to Reviewer 4.\n\n\n2) \u201c There might be differences between these works and the paper, it is common to evaluate the quality of the generation to other models in terms of accuracy or in the classification tasks. Unfortunately, there is no such quantitative analysis in the paper.\u201d\n\nUsing the classification accuracy to assess the performance is an interesting approach. This however requires delicate fine-tuning of the parameters of the classifier and generative models. We therefore feel that other metrics are more suitable (see above comment) and leave the evaluation of the classification performance for future work as it requires a seperate in-depth study.\n\n3) \u201cIt would be interesting to see complexity analysis to evaluate the computational costs.\u201d\n\nWe discuss the computational costs of the algorithm in Section 4. Scalability is known to be an issue for kernel PCA, where the SVD has a complexity O(n^3) with n the size of the dataset. This was hedged using mini-batches, which results in a complexity O(m^3) with m the size of the mini-batch. If the size of the mini-batch is still too large, we propose to use the covariance matrix instead of the kernel matrix, the complexity is now O(d^3), with d the size of the final layer of the feature map. If both the mini-batch size and the final layer are large, the method is rather slow (still cubic complexity). \n\nWe hope this addresses the reviewer\u2019s concerns.\n"}, "signatures": ["ICLR.cc/2020/Conference/Paper1189/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1189/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["arun.pandey@esat.kuleuven.be", "joachim.schreurs@esat.kuleuven.be", "johan.suykens@esat.kuleuven.be"], "title": "Generative Restricted Kernel Machines", "authors": ["Arun Pandey", "Joachim Schreurs", "Johan A.K. Suykens"], "pdf": "/pdf/a3f86a68c57e352ef8915f18b3c53a11a455ddc8.pdf", "TL;DR": "Gen-RKM: a novel framework for generative models using Restricted Kernel Machines with multi-view generation and uncorrelated feature learning.", "abstract": "We introduce a novel framework for generative models based on Restricted Kernel Machines (RKMs) with multi-view generation and uncorrelated feature learning capabilities, called Gen-RKM. To incorporate multi-view generation, this mechanism uses a shared representation of data from various views. The mechanism is flexible to incorporate both kernel-based, (deep) neural network and convolutional based models within the same setting. To update the parameters of the network, we propose a novel training procedure which jointly learns the features and shared representation. Experiments demonstrate the potential of the framework through qualitative evaluation of generated samples.", "keywords": ["Generative models", "Kernel methods", "Deep learning"], "paperhash": "pandey|generative_restricted_kernel_machines", "original_pdf": "/attachment/d986a95eb14b9a0dd3b1d52128df981f71ab86ca.pdf", "_bibtex": "@misc{\npandey2020generative,\ntitle={Generative Restricted Kernel Machines},\nauthor={Arun Pandey and Joachim Schreurs and Johan A.K. Suykens},\nyear={2020},\nurl={https://openreview.net/forum?id=ryghPCVYvH}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "ryghPCVYvH", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper1189/Authors", "ICLR.cc/2020/Conference/Paper1189/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper1189/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper1189/Reviewers", "ICLR.cc/2020/Conference/Paper1189/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper1189/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper1189/Authors|ICLR.cc/2020/Conference/Paper1189/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504159862, "tmdate": 1576860535323, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper1189/Authors", "ICLR.cc/2020/Conference/Paper1189/Reviewers", "ICLR.cc/2020/Conference/Paper1189/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper1189/-/Official_Comment"}}}, {"id": "HklIe8N3jr", "original": null, "number": 5, "cdate": 1573828078254, "ddate": null, "tcdate": 1573828078254, "tmdate": 1573828078254, "tddate": null, "forum": "ryghPCVYvH", "replyto": "BJgubSH1qS", "invitation": "ICLR.cc/2020/Conference/Paper1189/-/Official_Comment", "content": {"title": "Response reviewer 2", "comment": "We\u2019d like to thank the reviewer for their review and helpful suggestions.\n\n1) \u201cThis is a very good paper, building on the idea of Restricted Kernel Machines (drawing a nice parallel between Restricted Bolzman Machines and tools available in the Kernel modelling literature). In this manuscript, the author(s) extend the work to a generative model setting to achieve multi-view generation -- a generative model that can explain correlated variables from a common subspace. The manuscript is well-written and easy to follow and the algorithmic details are clear. Image generation is illustrated on standard datasets (MNIST / CIFAR / CelebA).\u201d\n\nWe thank you for the appreciation.\n\n2) \u201cLatent variable-based generative modes such as this (and this is motivated in the introduction to the paper) should be judged on if they can extract anything useful about the problem domain in the latent representations that we can interpret.\u201d\n\nThe interpretation of the latent space was addressed in point 3 in the response to Reviewer 4.\n\n3) \u201cWhen one ought to resort to this approach and not a sample from the plethora of variants of VAE we read about.\u201d\n\nThe comparison between Gen-RKM and the different VAE variants was done in point 4 in the response to Reviewer 4.\n\n4) \u201cNo critical appraisal is given about when the models might fail\u201d\n\n4.1) Scalability towards large datasets could be an issue as the computational complexity of the SVD is O(n^3) with n the size of the dataset. This was hedged using mini-batches, which results in a complexity O(m^3) with m the size of the mini-batch. If the size of the mini-batch is still too large, we propose to use the covariance matrix instead of the kernel matrix, the complexity is now O(d^3), with d the size of the final layer of the feature map. If both the mini-batch size and the final layer are large, the method is rather slow (still cubic complexity).\n4.2) The model has difficulties converging when the eigenvalue spectrum of the kernel matrix decreases rapidly, which means that most information is captured in a few principal components, while the rest of the components are noise. The presence of this noise hinders the convergence of the method as these eigenvectors can change drastically without affecting the reconstruction loss (small eigenvalue). It is therefore important to select the number of latent variables in proportion with the size of the mini-batch and the corresponding spectrum of the kernel matrix (the diversity within a mini-batch affects the eigenvalue spectrum of the kernel matrix).\n\n5) \u201cFrom the above empirical results point of view, I do not think this manuscript is ready for publication, despite what I see as the elegance of the framework.\u201d\n\nWe agree with the comment and extended the experimental section with multiple comparisons. The details are discussed in point 5 in the response to Reviewer 4.\n\nWe hope this addresses the reviewer\u2019s concerns.\n"}, "signatures": ["ICLR.cc/2020/Conference/Paper1189/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1189/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["arun.pandey@esat.kuleuven.be", "joachim.schreurs@esat.kuleuven.be", "johan.suykens@esat.kuleuven.be"], "title": "Generative Restricted Kernel Machines", "authors": ["Arun Pandey", "Joachim Schreurs", "Johan A.K. Suykens"], "pdf": "/pdf/a3f86a68c57e352ef8915f18b3c53a11a455ddc8.pdf", "TL;DR": "Gen-RKM: a novel framework for generative models using Restricted Kernel Machines with multi-view generation and uncorrelated feature learning.", "abstract": "We introduce a novel framework for generative models based on Restricted Kernel Machines (RKMs) with multi-view generation and uncorrelated feature learning capabilities, called Gen-RKM. To incorporate multi-view generation, this mechanism uses a shared representation of data from various views. The mechanism is flexible to incorporate both kernel-based, (deep) neural network and convolutional based models within the same setting. To update the parameters of the network, we propose a novel training procedure which jointly learns the features and shared representation. Experiments demonstrate the potential of the framework through qualitative evaluation of generated samples.", "keywords": ["Generative models", "Kernel methods", "Deep learning"], "paperhash": "pandey|generative_restricted_kernel_machines", "original_pdf": "/attachment/d986a95eb14b9a0dd3b1d52128df981f71ab86ca.pdf", "_bibtex": "@misc{\npandey2020generative,\ntitle={Generative Restricted Kernel Machines},\nauthor={Arun Pandey and Joachim Schreurs and Johan A.K. Suykens},\nyear={2020},\nurl={https://openreview.net/forum?id=ryghPCVYvH}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "ryghPCVYvH", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper1189/Authors", "ICLR.cc/2020/Conference/Paper1189/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper1189/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper1189/Reviewers", "ICLR.cc/2020/Conference/Paper1189/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper1189/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper1189/Authors|ICLR.cc/2020/Conference/Paper1189/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504159862, "tmdate": 1576860535323, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper1189/Authors", "ICLR.cc/2020/Conference/Paper1189/Reviewers", "ICLR.cc/2020/Conference/Paper1189/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper1189/-/Official_Comment"}}}, {"id": "rJeetrEhsH", "original": null, "number": 4, "cdate": 1573827960197, "ddate": null, "tcdate": 1573827960197, "tmdate": 1573827984724, "tddate": null, "forum": "ryghPCVYvH", "replyto": "BJly_2s4cB", "invitation": "ICLR.cc/2020/Conference/Paper1189/-/Official_Comment", "content": {"title": "Response reviewer 4: Part 2", "comment": "\n4) \u201cThe main idea of the paper.\u201d\n\nA novel multi-view generative model based on the RKM framework where multiple views of the data can be generated simultaneously. The model incorporates the best of both worlds i.e. kernel methods and neural networks (e.g. convolutional layers). This is done based on the RKM framework. The model gives us uncorrelated latent variables, which gives an indication that the Gen-RKM could resemble a disentangled representation. The example on Figure 5 supports the latter.\n\nThere is also an intuitive connection between Gen-RKM and autoencoders.\nNamely, the  properties of kernel PCA resemble the objective of the 3 variations of an autoencoder: standard [4], VAE [6] and beta-VAE [7].\n4.1) Similar to an autoencoder, when using an explicit feature map Gen-RKM tries to minimize the reconstruction error in the loss function (see Eq. 9), where kernel PCA acts as a denoiser (the information is compressed in the first components). \n4.2) By interpreting kernel PCA in the LS-SVM setting, the kernel PCA analysis can take the interpretation of a one-class modeling problem with zero target value around which one maximizes the variance [5]. When choosing a good feature map, one thus expects the latent variables to be Gaussian distributed around zero (We also observed this in the experiments). This resembles the added regularization term in the objective of the VAE [6],  which is expressed as the Kullback-Leibler divergence between the returned distribution and a standard Gaussian, i.e. we want the latent variables of the VAE to be Gaussian distributed.\n4.3) Kernel PCA gives us uncorrelated components in feature space. While it was already shown that linear PCA does not give a good disentangled representation for images [7,8], we feel that this is not a fair comparison as a linear kernel is not appropriate for image data. By designing a good kernel (e.g. Convolutional layers) and doing kernel PCA with an explicit feature map, it is possible to get a disentangled representation for images as we show on the example in Figure 5. \n    \nBy resembling the components of the 3 variations of the autoencoder, the \nGen-RKM performs comparably on the 3 objectives simultaneously : \nreconstruction, generation and disentanglement. We added a small paragraph \nto highlight these differences.\n\n5) \u201cThe authors did not provide any quantitative measure and comparison with existing approaches;\u201d\n\nWe thank you for the suggestion and agree with the comment. We added the \nfollowing experiments:\n5.1) To assess the quality of generation, we compare Gen-RKM with standard VAE [6] on the MNIST and celebA dataset. To have a fair comparison, the models have the same encoder/decoder, optimization parameters and the same loss function: binary cross-entropy. Both models were trained until convergence. The performance is evaluated qualitatively by comparing reconstruction and random sampling (similar to the experiments in [10]). Quantitatively, we compare the models using the Fr\u00e9chet Inception Distance (FID) [9], which is a common metric to evaluate quality of generation. We observed empirically that FID scores are better for the Gen-RKM when using the same encoder/decoder architecture and small latent dimension. This is confirmed by a qualitatively evaluation, where the VAE generates more smoothed images. \n5.2) To assess the disentanglement, we compare Gen-RKM with VAE [6] and beta-VAE [8] on the Dsprites [11] and Teapot dataset [7]. Again, the 3 models have the same size of the encoder and decoder architectures, same number of latent variables,.... The  performance is measured by the proposed framework of Eastwood et al. [7], which gives 3 measures: disentanglement, completeness and informativeness. We observe empirically that the Gen-RKM has good performance when the latent space dimension is well chosen.  \n\nWe hope this addresses the reviewer\u2019s concerns.\n"}, "signatures": ["ICLR.cc/2020/Conference/Paper1189/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1189/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["arun.pandey@esat.kuleuven.be", "joachim.schreurs@esat.kuleuven.be", "johan.suykens@esat.kuleuven.be"], "title": "Generative Restricted Kernel Machines", "authors": ["Arun Pandey", "Joachim Schreurs", "Johan A.K. Suykens"], "pdf": "/pdf/a3f86a68c57e352ef8915f18b3c53a11a455ddc8.pdf", "TL;DR": "Gen-RKM: a novel framework for generative models using Restricted Kernel Machines with multi-view generation and uncorrelated feature learning.", "abstract": "We introduce a novel framework for generative models based on Restricted Kernel Machines (RKMs) with multi-view generation and uncorrelated feature learning capabilities, called Gen-RKM. To incorporate multi-view generation, this mechanism uses a shared representation of data from various views. The mechanism is flexible to incorporate both kernel-based, (deep) neural network and convolutional based models within the same setting. To update the parameters of the network, we propose a novel training procedure which jointly learns the features and shared representation. Experiments demonstrate the potential of the framework through qualitative evaluation of generated samples.", "keywords": ["Generative models", "Kernel methods", "Deep learning"], "paperhash": "pandey|generative_restricted_kernel_machines", "original_pdf": "/attachment/d986a95eb14b9a0dd3b1d52128df981f71ab86ca.pdf", "_bibtex": "@misc{\npandey2020generative,\ntitle={Generative Restricted Kernel Machines},\nauthor={Arun Pandey and Joachim Schreurs and Johan A.K. Suykens},\nyear={2020},\nurl={https://openreview.net/forum?id=ryghPCVYvH}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "ryghPCVYvH", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper1189/Authors", "ICLR.cc/2020/Conference/Paper1189/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper1189/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper1189/Reviewers", "ICLR.cc/2020/Conference/Paper1189/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper1189/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper1189/Authors|ICLR.cc/2020/Conference/Paper1189/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504159862, "tmdate": 1576860535323, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper1189/Authors", "ICLR.cc/2020/Conference/Paper1189/Reviewers", "ICLR.cc/2020/Conference/Paper1189/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper1189/-/Official_Comment"}}}, {"id": "H1xJDr4hsr", "original": null, "number": 3, "cdate": 1573827927094, "ddate": null, "tcdate": 1573827927094, "tmdate": 1573827927094, "tddate": null, "forum": "ryghPCVYvH", "replyto": "BJly_2s4cB", "invitation": "ICLR.cc/2020/Conference/Paper1189/-/Official_Comment", "content": {"title": "Response reviewer 4: Part 1", "comment": "We would like to thank the reviewer for the review and helpful suggestions.\n\n1) \u201cFrom the description of the functionals L1 and L2 (bottom of page 4 and top of the page 5) the reader can think that the authors tune parameters (zeta_1,theta_1) and (zeta_2,theta_2) for each sample point separately\u201d \n\nWe thank the reviewer for pointing this out, this is a typo and we changed this in the paper. \n\n2) \u201cThe authors claimed that the experiments were done both for kernel features and for explicit features based on neural networks. However, in the experimental section there are no results obtained when using implicit kernels. Nothings is told on how to select kernel parameters.\u201d\n\nExperiments with implicit feature maps where already shown on Figure 4a. Table 1 in the appendix shows the hyperparameters used for the experiments. The bandwidth of the Gaussian kernel for generation corresponds to the bandwidth that gave the best performance determined by cross-validation on the MNIST classification problem. \n\n3) \u201cThe authors claimed that thanks to PCA-like definition of latent vectors they are orthogonal which is similar to disentangle representations. However, there are no any empirical evidence whether it is possible to benefit somehow from that orthogonal property, as well as there is no comparison with approaches to construct disentangle\u0432 latent representation for other types of generative models.\u201d\n\nThe definition of disentanglement in the literature is not that precise. However many believe that a representation with statistically independent variables is a good starting point [1,2]. This already gives an indication that the model could resemble a disentangled representation. This is confirmed by the empirical evidence on Figure 5. We explore the learned uncorrelated-features by traversing along the (orthogonal) eigenvectors on the celebA and Dsprites dataset. These are common datasets to demonstrate disentanglement, where we repeat the experiments of [3] for the proposed Gen-RKM. For the Dsprites dataset, notice that the first and second components correspond to the y and x positions respectively. Rows 3 and 4 show the same for hearts. On the celebA dataset, rows 5 and 6 shows the reconstructed images while traversing along the principal components. When moving along the first component from left-to-right, the hair-color of the woman changes, while preserving the face structure. Whereas traversal along the second component, transforms a man to woman while preserving the orientation. When the number of principal components were 2 while training, the brightness and background light-source corresponds to the two largest variances in the dataset. This small example demonstrates how we can interpret the different components of the latent representation learned by the Gen-RKM. The latent space dimension in the RKM setting has a similar interpretation as the number of hidden units in a restricted Boltzmann machine, where in the specific case of the RKM these hidden units are uncorrelated. \n\n"}, "signatures": ["ICLR.cc/2020/Conference/Paper1189/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1189/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["arun.pandey@esat.kuleuven.be", "joachim.schreurs@esat.kuleuven.be", "johan.suykens@esat.kuleuven.be"], "title": "Generative Restricted Kernel Machines", "authors": ["Arun Pandey", "Joachim Schreurs", "Johan A.K. Suykens"], "pdf": "/pdf/a3f86a68c57e352ef8915f18b3c53a11a455ddc8.pdf", "TL;DR": "Gen-RKM: a novel framework for generative models using Restricted Kernel Machines with multi-view generation and uncorrelated feature learning.", "abstract": "We introduce a novel framework for generative models based on Restricted Kernel Machines (RKMs) with multi-view generation and uncorrelated feature learning capabilities, called Gen-RKM. To incorporate multi-view generation, this mechanism uses a shared representation of data from various views. The mechanism is flexible to incorporate both kernel-based, (deep) neural network and convolutional based models within the same setting. To update the parameters of the network, we propose a novel training procedure which jointly learns the features and shared representation. Experiments demonstrate the potential of the framework through qualitative evaluation of generated samples.", "keywords": ["Generative models", "Kernel methods", "Deep learning"], "paperhash": "pandey|generative_restricted_kernel_machines", "original_pdf": "/attachment/d986a95eb14b9a0dd3b1d52128df981f71ab86ca.pdf", "_bibtex": "@misc{\npandey2020generative,\ntitle={Generative Restricted Kernel Machines},\nauthor={Arun Pandey and Joachim Schreurs and Johan A.K. Suykens},\nyear={2020},\nurl={https://openreview.net/forum?id=ryghPCVYvH}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "ryghPCVYvH", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper1189/Authors", "ICLR.cc/2020/Conference/Paper1189/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper1189/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper1189/Reviewers", "ICLR.cc/2020/Conference/Paper1189/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper1189/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper1189/Authors|ICLR.cc/2020/Conference/Paper1189/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504159862, "tmdate": 1576860535323, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper1189/Authors", "ICLR.cc/2020/Conference/Paper1189/Reviewers", "ICLR.cc/2020/Conference/Paper1189/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper1189/-/Official_Comment"}}}, {"id": "ryg6GNNniB", "original": null, "number": 2, "cdate": 1573827604771, "ddate": null, "tcdate": 1573827604771, "tmdate": 1573827604771, "tddate": null, "forum": "ryghPCVYvH", "replyto": "ryghPCVYvH", "invitation": "ICLR.cc/2020/Conference/Paper1189/-/Official_Comment", "content": {"title": "Response to all reviewers", "comment": "We would like to thank the reviewers for their review and helpful suggestions.\n\nBased on the comments, we made the following additions to the paper:\n1) An intuitive connection between Gen-RKM and autoencoders.\n\n2) To assess the quality of generation, we compared Gen-RKM with standard VAE [6] on the MNIST and celebA dataset. The comparison is done qualitatively, along with a quantitative comparison using the Fr\u00e9chet Inception Distance (FID) [9]. We observed empirically that the FID scores are better for the Gen-RKM when using the same encoder/decoder architecture and small latent space dimension. This is confirmed by the qualitatively evaluation, where the VAE generates smoother images.\n\n3) To assess the disentanglement, we compared Gen-RKM with VAE [6] and beta-VAE [8] on the Dsprites [11] and Teapot dataset [7]. The performance is measured by the proposed framework of Eastwood et al. [7], which gives 3 measures: Disentanglement, Completeness and Informativeness. We observe empirically that the Gen-RKM has good performance when the latent space dimension is well chosen.  \n\nWe hope this addresses the reviewers\u2019 concerns.\n\nReferences used in all responses:\n[1] Schmidhuber, J\u00fcrgen. \"Learning factorial codes by predictability minimization.\" Neural Computation 4.6 (1992): 863-879.\n[2] Karl Ridgeway. A survey of inductive biases for factorial representation-learning. CoRR, abs/1612.05299, 2016.\n[3] Higgins, Irina, et al. beta-VAE: Learning Basic Visual Concepts with a Constrained Variational Framework. ICLR, 2017, 2.5: 6.\n[4] Kramer, Mark A. \"Nonlinear principal component analysis using autoassociative neural networks.\" AIChE journal 37.2 (1991): 233-243.\n[5] Suykens, Johan AK, et al. \"A support vector machine formulation to PCA analysis and its kernel version.\" IEEE Transactions on neural networks 14.2 (2003): 447-450.\n[6] Diederik P. Kingma and Max Welling. Auto-Encoding Variational Bayes. In 2nd International Conference on Learning Representations, ICLR 2014, Banff, AB, Canada, April 14-16, 2014.\n[7] Eastwood, Cian, and Christopher KI Williams. \"A framework for the quantitative evaluation of disentangled representations.\" (2018).\n[8] Higgins, Irina, et al. \"beta-VAE: Learning Basic Visual Concepts with a Constrained Variational Framework.\" ICLR 2.5 (2017): 6.\n[9] Heusel, Martin, et al. \"GANs trained by a two time-scale update rule converge to a local Nash equilibrium.\" Advances in Neural Information Processing Systems. 2017.\n[10] Tolstikhin, Ilya, et al. \"Wasserstein auto-encoders.\" arXiv preprint arXiv:1711.01558 (2017).\n[11] Matthey, Loic, et al. \"Dsprites: Disentanglement testing sprites dataset.\" URL https://github. com/deepmind/dsprites-dataset/.[Accessed on: 2018-05-08] (2017).\n"}, "signatures": ["ICLR.cc/2020/Conference/Paper1189/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1189/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["arun.pandey@esat.kuleuven.be", "joachim.schreurs@esat.kuleuven.be", "johan.suykens@esat.kuleuven.be"], "title": "Generative Restricted Kernel Machines", "authors": ["Arun Pandey", "Joachim Schreurs", "Johan A.K. Suykens"], "pdf": "/pdf/a3f86a68c57e352ef8915f18b3c53a11a455ddc8.pdf", "TL;DR": "Gen-RKM: a novel framework for generative models using Restricted Kernel Machines with multi-view generation and uncorrelated feature learning.", "abstract": "We introduce a novel framework for generative models based on Restricted Kernel Machines (RKMs) with multi-view generation and uncorrelated feature learning capabilities, called Gen-RKM. To incorporate multi-view generation, this mechanism uses a shared representation of data from various views. The mechanism is flexible to incorporate both kernel-based, (deep) neural network and convolutional based models within the same setting. To update the parameters of the network, we propose a novel training procedure which jointly learns the features and shared representation. Experiments demonstrate the potential of the framework through qualitative evaluation of generated samples.", "keywords": ["Generative models", "Kernel methods", "Deep learning"], "paperhash": "pandey|generative_restricted_kernel_machines", "original_pdf": "/attachment/d986a95eb14b9a0dd3b1d52128df981f71ab86ca.pdf", "_bibtex": "@misc{\npandey2020generative,\ntitle={Generative Restricted Kernel Machines},\nauthor={Arun Pandey and Joachim Schreurs and Johan A.K. Suykens},\nyear={2020},\nurl={https://openreview.net/forum?id=ryghPCVYvH}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "ryghPCVYvH", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper1189/Authors", "ICLR.cc/2020/Conference/Paper1189/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper1189/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper1189/Reviewers", "ICLR.cc/2020/Conference/Paper1189/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper1189/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper1189/Authors|ICLR.cc/2020/Conference/Paper1189/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504159862, "tmdate": 1576860535323, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper1189/Authors", "ICLR.cc/2020/Conference/Paper1189/Reviewers", "ICLR.cc/2020/Conference/Paper1189/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper1189/-/Official_Comment"}}}, {"id": "BJgubSH1qS", "original": null, "number": 2, "cdate": 1571931392491, "ddate": null, "tcdate": 1571931392491, "tmdate": 1572972500961, "tddate": null, "forum": "ryghPCVYvH", "replyto": "ryghPCVYvH", "invitation": "ICLR.cc/2020/Conference/Paper1189/-/Official_Review", "content": {"experience_assessment": "I have read many papers in this area.", "rating": "3: Weak Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #2", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "This is a very good paper, building on the idea of Restricted Kernel Machines (drawing a nice parallel between Restricted Bolzman Machines and tools available in the Kernel modelling literature). In this manuscript, the author(s) extend the work to a generative model setting to achieve multi-view generation -- a generative model that can explain correlated variables from a common subspace. The manuscript is well-written and easy to follow and the algorithmic details are clear. Image generation is illustrated on standard datasets (MNIST / CIFAR / CelebA). \nWhile the framework and learning algorithm are good, and novel extensions to what appears to be previous work of the authors, I am less persuaded by the empirical work. Latent variable-based generative modes such as this (and this is motivated in the introduction to the paper) should be judged on if they can extract anything useful about the problem domain in the latent representations that we can interpret. This is not the case here --  the results presented are examples of images that the models can generate. No critical appraisal is given about when the models might fail or when one ought to resort to this approach and not a sample from the plethora of variants of VAE we read about. What have we learnt about images / hand-written characters / faces of popular people from a study like this?\nFrom the above empirical results point of view, I do not think this manuscript is ready for publication, despite what I see as the elegance of the framework. "}, "signatures": ["ICLR.cc/2020/Conference/Paper1189/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1189/AnonReviewer2"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["arun.pandey@esat.kuleuven.be", "joachim.schreurs@esat.kuleuven.be", "johan.suykens@esat.kuleuven.be"], "title": "Generative Restricted Kernel Machines", "authors": ["Arun Pandey", "Joachim Schreurs", "Johan A.K. Suykens"], "pdf": "/pdf/a3f86a68c57e352ef8915f18b3c53a11a455ddc8.pdf", "TL;DR": "Gen-RKM: a novel framework for generative models using Restricted Kernel Machines with multi-view generation and uncorrelated feature learning.", "abstract": "We introduce a novel framework for generative models based on Restricted Kernel Machines (RKMs) with multi-view generation and uncorrelated feature learning capabilities, called Gen-RKM. To incorporate multi-view generation, this mechanism uses a shared representation of data from various views. The mechanism is flexible to incorporate both kernel-based, (deep) neural network and convolutional based models within the same setting. To update the parameters of the network, we propose a novel training procedure which jointly learns the features and shared representation. Experiments demonstrate the potential of the framework through qualitative evaluation of generated samples.", "keywords": ["Generative models", "Kernel methods", "Deep learning"], "paperhash": "pandey|generative_restricted_kernel_machines", "original_pdf": "/attachment/d986a95eb14b9a0dd3b1d52128df981f71ab86ca.pdf", "_bibtex": "@misc{\npandey2020generative,\ntitle={Generative Restricted Kernel Machines},\nauthor={Arun Pandey and Joachim Schreurs and Johan A.K. Suykens},\nyear={2020},\nurl={https://openreview.net/forum?id=ryghPCVYvH}\n}"}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "ryghPCVYvH", "replyto": "ryghPCVYvH", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper1189/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper1189/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1575633590007, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper1189/Reviewers"], "noninvitees": [], "tcdate": 1570237741037, "tmdate": 1575633590020, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper1189/-/Official_Review"}}}], "count": 11}