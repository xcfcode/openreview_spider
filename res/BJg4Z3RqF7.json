{"notes": [{"id": "BJg4Z3RqF7", "original": "H1ekHTp5t7", "number": 1163, "cdate": 1538087932159, "ddate": null, "tcdate": 1538087932159, "tmdate": 1549629023593, "tddate": null, "forum": "BJg4Z3RqF7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Unsupervised Adversarial Image Reconstruction", "abstract": "We address the problem of recovering an underlying signal from lossy, inaccurate observations in an unsupervised setting. Typically, we consider situations where there is little to no background knowledge on the structure of the underlying signal, no access to signal-measurement pairs, nor even unpaired signal-measurement data. The only available information is provided by the observations and the measurement process statistics. We cast the problem as finding the \\textit{maximum a posteriori} estimate of the signal given each measurement, and propose a general framework for the reconstruction problem. We use a formulation of generative adversarial networks, where the generator takes as input a corrupted observation in order to produce realistic reconstructions, and add a penalty term tying the reconstruction to the associated observation. We evaluate our reconstructions on several image datasets with different types of corruptions. The proposed approach yields better results than alternative baselines, and comparable performance with model variants trained with additional supervision.", "keywords": ["Deep Learning", "Adversarial", "MAP", "GAN", "neural networks"], "authorids": ["arthur.pajot@lip6.fr", "emmanuel.de-bezenac@lip6.fr", "patrick.gallinari@lip6.fr"], "authors": ["Arthur Pajot", "Emmanuel de Bezenac", "Patrick Gallinari"], "pdf": "/pdf/8952a5ef40ce737be3059e78feb4dd0b7f297219.pdf", "paperhash": "pajot|unsupervised_adversarial_image_reconstruction", "_bibtex": "@inproceedings{\npajot2018unsupervised,\ntitle={Unsupervised Adversarial Image Reconstruction},\nauthor={Arthur Pajot and Emmanuel de Bezenac and Patrick Gallinari},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=BJg4Z3RqF7},\n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"replyCount": 11, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Blind_Submission", "rdate": null, "ddate": null, "expdate": null, "duedate": 1538085600000, "tmdate": 1538142958393, "tddate": null, "super": null, "final": null, "reply": {"signatures": {"values": ["ICLR.cc/2019/Conference"]}, "forum": null, "readers": {"values": ["everyone"]}, "replyto": null, "content": {"authorids": {"values-regex": ".*"}, "authors": {"values": ["Anonymous"]}}, "writers": {"values": ["ICLR.cc/2019/Conference"]}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["~"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": null, "taskCompletionCount": null, "transform": null, "cdate": 1538142958393}}, "tauthor": "OpenReview.net"}, {"id": "Byg9LP8XlV", "original": null, "number": 1, "cdate": 1544935250127, "ddate": null, "tcdate": 1544935250127, "tmdate": 1545354491362, "tddate": null, "forum": "BJg4Z3RqF7", "replyto": "BJg4Z3RqF7", "invitation": "ICLR.cc/2019/Conference/-/Paper1163/Meta_Review", "content": {"metareview": "This paper proposes a GAN-based method to recover images from a noisy version of it. The paper builds upon existing works on AmbientGAN and CS-GAN. By combining the two approaches, the work finds a new method that performs better than existing approaches.\n\nThe paper clearly has new interesting ideas which have been executed well. Two of the reviewers have voted in favour of acceptance, with one of the reviewer providing an extensive and detailed review. The third reviewer however has some doubts which were not resolved completely after the rebuttal.\n\nUpon reading the work myself, I am convinced that this will be interesting to the community. However, I will recommend the authors to take the comments of Reviewer 2 into account and do whatever it takes to resolve issues pointed by the reviewer.\n\nDuring the review process, another related work was found to be very similar to the approach discussed in this work. This work should be cited in the paper, as a prior work that the authors were unaware of. \nhttps://arxiv.org/abs/1812.04744\nPlease also discuss any new insights this work offers on top of this existing work.\n\nGiven that the above suggestions are taken into account, I recommend to accept this paper.\n", "confidence": "3: The area chair is somewhat confident", "recommendation": "Accept (Poster)", "title": "Good work, but a few issues should be addressed in the camera-ready version."}, "signatures": ["ICLR.cc/2019/Conference/Paper1163/Area_Chair1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference/Paper1163/Area_Chair1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Unsupervised Adversarial Image Reconstruction", "abstract": "We address the problem of recovering an underlying signal from lossy, inaccurate observations in an unsupervised setting. Typically, we consider situations where there is little to no background knowledge on the structure of the underlying signal, no access to signal-measurement pairs, nor even unpaired signal-measurement data. The only available information is provided by the observations and the measurement process statistics. We cast the problem as finding the \\textit{maximum a posteriori} estimate of the signal given each measurement, and propose a general framework for the reconstruction problem. We use a formulation of generative adversarial networks, where the generator takes as input a corrupted observation in order to produce realistic reconstructions, and add a penalty term tying the reconstruction to the associated observation. We evaluate our reconstructions on several image datasets with different types of corruptions. The proposed approach yields better results than alternative baselines, and comparable performance with model variants trained with additional supervision.", "keywords": ["Deep Learning", "Adversarial", "MAP", "GAN", "neural networks"], "authorids": ["arthur.pajot@lip6.fr", "emmanuel.de-bezenac@lip6.fr", "patrick.gallinari@lip6.fr"], "authors": ["Arthur Pajot", "Emmanuel de Bezenac", "Patrick Gallinari"], "pdf": "/pdf/8952a5ef40ce737be3059e78feb4dd0b7f297219.pdf", "paperhash": "pajot|unsupervised_adversarial_image_reconstruction", "_bibtex": "@inproceedings{\npajot2018unsupervised,\ntitle={Unsupervised Adversarial Image Reconstruction},\nauthor={Arthur Pajot and Emmanuel de Bezenac and Patrick Gallinari},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=BJg4Z3RqF7},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper1163/Meta_Review", "rdate": null, "ddate": null, "expdate": null, "duedate": 1541548800000, "tmdate": 1545352942394, "tddate": null, "super": null, "final": null, "reply": {"forum": "BJg4Z3RqF7", "replyto": "BJg4Z3RqF7", "readers": {"description": "Select all user groups that should be able to read this comment. Selecting 'All Users' will allow paper authors, reviewers, area chairs, and program chairs to view this comment.", "values": ["everyone"]}, "signatures": {"description": "How your identity will be displayed with the above content.", "values-regex": "ICLR.cc/2019/Conference/Paper1163/Area_Chair[0-9]+"}, "writers": {"description": "Users that may modify this record.", "values-regex": "ICLR.cc/2019/Conference/Paper1163/Area_Chair[0-9]+"}, "content": {"title": {"order": 1, "value-regex": ".{1,500}", "description": "Brief summary of your review.", "required": true}, "metareview": {"order": 2, "value-regex": "[\\S\\s]{1,5000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "required": true}, "recommendation": {"order": 3, "value-dropdown": ["Accept (Oral)", "Accept (Poster)", "Reject"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The area chair is absolutely certain", "4: The area chair is confident but not absolutely certain", "3: The area chair is somewhat confident", "2: The area chair is not sure", "1: The area chair's evaluation is an educated guess"], "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper1163/Area_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": false, "taskCompletionCount": null, "transform": null, "cdate": 1545352942394}}}, {"id": "HkgUbQ_WgN", "original": null, "number": 17, "cdate": 1544811262286, "ddate": null, "tcdate": 1544811262286, "tmdate": 1544811262286, "tddate": null, "forum": "BJg4Z3RqF7", "replyto": "BJg4Z3RqF7", "invitation": "ICLR.cc/2019/Conference/-/Paper1163/Official_Comment", "content": {"title": "Code Release", "comment": "We have released the code used in this paper : https://github.com/UNIR-Anonymous/UNIR"}, "signatures": ["ICLR.cc/2019/Conference/Paper1163/Authors"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper1163/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper1163/Authors", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Unsupervised Adversarial Image Reconstruction", "abstract": "We address the problem of recovering an underlying signal from lossy, inaccurate observations in an unsupervised setting. Typically, we consider situations where there is little to no background knowledge on the structure of the underlying signal, no access to signal-measurement pairs, nor even unpaired signal-measurement data. The only available information is provided by the observations and the measurement process statistics. We cast the problem as finding the \\textit{maximum a posteriori} estimate of the signal given each measurement, and propose a general framework for the reconstruction problem. We use a formulation of generative adversarial networks, where the generator takes as input a corrupted observation in order to produce realistic reconstructions, and add a penalty term tying the reconstruction to the associated observation. We evaluate our reconstructions on several image datasets with different types of corruptions. The proposed approach yields better results than alternative baselines, and comparable performance with model variants trained with additional supervision.", "keywords": ["Deep Learning", "Adversarial", "MAP", "GAN", "neural networks"], "authorids": ["arthur.pajot@lip6.fr", "emmanuel.de-bezenac@lip6.fr", "patrick.gallinari@lip6.fr"], "authors": ["Arthur Pajot", "Emmanuel de Bezenac", "Patrick Gallinari"], "pdf": "/pdf/8952a5ef40ce737be3059e78feb4dd0b7f297219.pdf", "paperhash": "pajot|unsupervised_adversarial_image_reconstruction", "_bibtex": "@inproceedings{\npajot2018unsupervised,\ntitle={Unsupervised Adversarial Image Reconstruction},\nauthor={Arthur Pajot and Emmanuel de Bezenac and Patrick Gallinari},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=BJg4Z3RqF7},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper1163/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621615447, "tddate": null, "super": null, "final": null, "reply": {"forum": "BJg4Z3RqF7", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper1163/Authors", "ICLR.cc/2019/Conference/Paper1163/Reviewers", "ICLR.cc/2019/Conference/Paper1163/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper1163/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper1163/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper1163/Authors|ICLR.cc/2019/Conference/Paper1163/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper1163/Reviewers", "ICLR.cc/2019/Conference/Paper1163/Authors", "ICLR.cc/2019/Conference/Paper1163/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621615447}}}, {"id": "rJesRWZs1V", "original": null, "number": 12, "cdate": 1544389075404, "ddate": null, "tcdate": 1544389075404, "tmdate": 1544389075404, "tddate": null, "forum": "BJg4Z3RqF7", "replyto": "BklnQfJjJN", "invitation": "ICLR.cc/2019/Conference/-/Paper1163/Official_Comment", "content": {"title": "post rebuttal comments", "comment": "The authors have addressed my comments well. \nI think the paper is a great contribution on solving inverse problems using GANs and I think it should be accepted. \n\nI am also concerned by the behavior of Anonreviewer3 who is ignoring the requests of the area chairs (and myself) to write a detailed review and I will request that the TPC chairs to take this into consideration for the future. "}, "signatures": ["ICLR.cc/2019/Conference/Paper1163/AnonReviewer1"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper1163/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper1163/AnonReviewer1", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Unsupervised Adversarial Image Reconstruction", "abstract": "We address the problem of recovering an underlying signal from lossy, inaccurate observations in an unsupervised setting. Typically, we consider situations where there is little to no background knowledge on the structure of the underlying signal, no access to signal-measurement pairs, nor even unpaired signal-measurement data. The only available information is provided by the observations and the measurement process statistics. We cast the problem as finding the \\textit{maximum a posteriori} estimate of the signal given each measurement, and propose a general framework for the reconstruction problem. We use a formulation of generative adversarial networks, where the generator takes as input a corrupted observation in order to produce realistic reconstructions, and add a penalty term tying the reconstruction to the associated observation. We evaluate our reconstructions on several image datasets with different types of corruptions. The proposed approach yields better results than alternative baselines, and comparable performance with model variants trained with additional supervision.", "keywords": ["Deep Learning", "Adversarial", "MAP", "GAN", "neural networks"], "authorids": ["arthur.pajot@lip6.fr", "emmanuel.de-bezenac@lip6.fr", "patrick.gallinari@lip6.fr"], "authors": ["Arthur Pajot", "Emmanuel de Bezenac", "Patrick Gallinari"], "pdf": "/pdf/8952a5ef40ce737be3059e78feb4dd0b7f297219.pdf", "paperhash": "pajot|unsupervised_adversarial_image_reconstruction", "_bibtex": "@inproceedings{\npajot2018unsupervised,\ntitle={Unsupervised Adversarial Image Reconstruction},\nauthor={Arthur Pajot and Emmanuel de Bezenac and Patrick Gallinari},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=BJg4Z3RqF7},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper1163/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621615447, "tddate": null, "super": null, "final": null, "reply": {"forum": "BJg4Z3RqF7", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper1163/Authors", "ICLR.cc/2019/Conference/Paper1163/Reviewers", "ICLR.cc/2019/Conference/Paper1163/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper1163/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper1163/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper1163/Authors|ICLR.cc/2019/Conference/Paper1163/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper1163/Reviewers", "ICLR.cc/2019/Conference/Paper1163/Authors", "ICLR.cc/2019/Conference/Paper1163/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621615447}}}, {"id": "BJguc0OE0Q", "original": null, "number": 7, "cdate": 1542913679947, "ddate": null, "tcdate": 1542913679947, "tmdate": 1542913679947, "tddate": null, "forum": "BJg4Z3RqF7", "replyto": "SklY001CnQ", "invitation": "ICLR.cc/2019/Conference/-/Paper1163/Official_Comment", "content": {"title": "Response to comments", "comment": "Thank you for your feedback. We have taken note of your comments and have been actively working to take them into account.\nYou raised two main questions , one concerning the measurement process and the second one concerning the need to test the model on additional datasets.\n\nConcerning the first question, we have rewritten the sections explaining to the measurement process (please, see also the general comments about the measurement process above). Below is an extract from Section 2.1. \u201cProblem Setting\u201d of the updated paper version:\n\n\u201cSuppose there exists a signal X ~ p_X we wish to acquire, but we only have access to this signal through lossy, inaccurate observation Y ~ p_Y. The measurement process is modeled through a stochastic operator F mapping signals X to their associated observations Y. We will refer to F as the measurement process, which corrupts the input signal. F is parameterized by a random variable \\Theta ~ p_\\Theta following an underlying distribution p_\\Theta we can sample from, which represents the factors of corruption. Thus, given a specific signal x, we can simulate its measurement by first sampling \\theta from p_\\Theta, and then computing F(x; \\theta). Additional sources of uncertainty, e.g. due to unknown factors, can be modeled using additive i.i.d. Gaussian noise \\Eps ~ \\mathcal{N}(0, \\sigma^2 I), so that the overall acquisition process becomes: \nDifferent instances of F will be considered, e.g. like random occlusions, information acquisition from a sparse subset of the signal, overly smoothing out and corrupting the original distribution with additive noise, etc... In such cases, the factors of corruption \\Theta might respectively represent the position of the occlusion, the coordinates of the acquired information, or simply the values of the additive noise.\u201d\n\n\nFor different measurement processes instances, also called corruptions, please refer to the Corruptions section (4.2) in the Experiments Section.\n\nAs for the second remark, we have added experiments conducted on two additional datasets: LSUN Bedrooms, and Recipe1M. The results are provided in section 5 and in appendix 3. Overall this confirms the good results of the model already obtained on the first dataset.\n"}, "signatures": ["ICLR.cc/2019/Conference/Paper1163/Authors"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper1163/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper1163/Authors", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Unsupervised Adversarial Image Reconstruction", "abstract": "We address the problem of recovering an underlying signal from lossy, inaccurate observations in an unsupervised setting. Typically, we consider situations where there is little to no background knowledge on the structure of the underlying signal, no access to signal-measurement pairs, nor even unpaired signal-measurement data. The only available information is provided by the observations and the measurement process statistics. We cast the problem as finding the \\textit{maximum a posteriori} estimate of the signal given each measurement, and propose a general framework for the reconstruction problem. We use a formulation of generative adversarial networks, where the generator takes as input a corrupted observation in order to produce realistic reconstructions, and add a penalty term tying the reconstruction to the associated observation. We evaluate our reconstructions on several image datasets with different types of corruptions. The proposed approach yields better results than alternative baselines, and comparable performance with model variants trained with additional supervision.", "keywords": ["Deep Learning", "Adversarial", "MAP", "GAN", "neural networks"], "authorids": ["arthur.pajot@lip6.fr", "emmanuel.de-bezenac@lip6.fr", "patrick.gallinari@lip6.fr"], "authors": ["Arthur Pajot", "Emmanuel de Bezenac", "Patrick Gallinari"], "pdf": "/pdf/8952a5ef40ce737be3059e78feb4dd0b7f297219.pdf", "paperhash": "pajot|unsupervised_adversarial_image_reconstruction", "_bibtex": "@inproceedings{\npajot2018unsupervised,\ntitle={Unsupervised Adversarial Image Reconstruction},\nauthor={Arthur Pajot and Emmanuel de Bezenac and Patrick Gallinari},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=BJg4Z3RqF7},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper1163/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621615447, "tddate": null, "super": null, "final": null, "reply": {"forum": "BJg4Z3RqF7", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper1163/Authors", "ICLR.cc/2019/Conference/Paper1163/Reviewers", "ICLR.cc/2019/Conference/Paper1163/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper1163/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper1163/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper1163/Authors|ICLR.cc/2019/Conference/Paper1163/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper1163/Reviewers", "ICLR.cc/2019/Conference/Paper1163/Authors", "ICLR.cc/2019/Conference/Paper1163/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621615447}}}, {"id": "BJlcvR_VRm", "original": null, "number": 6, "cdate": 1542913633925, "ddate": null, "tcdate": 1542913633925, "tmdate": 1542913633925, "tddate": null, "forum": "BJg4Z3RqF7", "replyto": "BylSgJYp2Q", "invitation": "ICLR.cc/2019/Conference/-/Paper1163/Official_Comment", "content": {"title": "Thank your for your feedback", "comment": "Thank you very much for your review and comments : they are very much appreciated. \n\n\u201cIf I understand correctly, this is the 'Conditional AmbientGAN' approach that is used as a baseline. This is a sensible approach given prior work. However, the authors show that their method ('Unpaired Supervision') performs significantly better compared to the Conditional AmbientGAN baseline. This is very surprising and interesting to me. Please discuss this a bit more ? As far as I understand the proposed method is a merging of AmbientGAN and CS-GAN, but much better than the naive separation. Could you give a bit more intuition on why ?\u201d\n\n\nIndeed, this is correct. The conditional AmbientGan baseline combines the approaches of AmbientGan and CS-GAN. First, a generative model G of the data is learned without having access to samples of the signal distribution using the AmbientGAN framework. Then, in order to reconstruct the signal from a corrupted measurement y, we look for an input vector z of G that produces a simulated measurement G(z) that looks like y, by minimizing the Euclidean distance between G(z) and y. This method suffers from several drawbacks, which we believe can explain the poor results:\n\n* First drawback: suboptimality of the Generator. In theory, if the generator was optimal, under suitable conditions for the measurement process F, it would generate outputs belonging to the manifold of uncorrupted images (that we shall name M). Thus, projecting a measurement onto M should recover an uncorrupted image. However, this is never the case: in practice, GANs suffer from a number of problems. This means that it is possible that images from the manifold of generated images do not correspond to true samples: applying gradient descent to minimize the aforementioned distances, tend to generate  images similar to the corrupted images y, and not to uncorrupted images x. Our model does not suffer from this problem because it maximizes the log-likelihood and the prior term jointly. If G generates a signal that does not belong to M in order to maximize the log-likelihood term (similarly to what happens with the ConditionalAmbientGan baseline), the discriminator will easily be able to detect this and consequently, the reconstruction network G is corrected in order to avoid this behaviour.\n\n* Second drawback : Euclidean distance used in ConditionalAmbientGan is not adapted in the general case considered in the paper. The natural thing to do would be to find a reconstruction from M that maximizes the likelihood p(y|x). If the corruption in the measurement process corresponds to iid additive noise, it is possible to show that the problem reduces to minimizing the euclidean distance between x and y, like in ConditionalAmbientGan. However, this is not necessarily the case for other measurement processes. Indeed, in the general formulation, the likelihood is intractable;it requires marginalizing on the noise variables \\theta, and for each SGD step we would need to approximate it, which would be very costly. Our likelihood term in the cost functions better reflects the true likelihood.\n\n\n\nIn the appendix where is the proposed method in fig 5- 8 ?\nFig 5-8  (now 11-14 )are samples from our baselines. The corresponding samples from our model were in figure 9 to 14. We are adding our model to figures 5-8 (11-14). Notes that we are now providing samples from other datasets (see general comments).\n\nDoes the proposed method outperform Deep Image Prior ? \n\nOur experiments show that for strong corruption function DIP yields poor results compared to our model (see figure 11-14). One of the main explanation is that it does not capture semantic information from the other images of the dataset. \n\nFor the measurement process Patch-Band, Remove-Pixel and Remove-Pixel-Channel, Deep Image Prior (DIP) has access to the corruption parameter \\theta of the associated measurement (we have used the inpainting formulation of DIP). In other words, it has access to the mask, as opposed to our model. We have conducted experiments where DIP does not have the mask (normal formulation of DIP), and have observed very poor results (which were actually quite similar to the poor results in Conditional AmbientGAN). \n"}, "signatures": ["ICLR.cc/2019/Conference/Paper1163/Authors"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper1163/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper1163/Authors", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Unsupervised Adversarial Image Reconstruction", "abstract": "We address the problem of recovering an underlying signal from lossy, inaccurate observations in an unsupervised setting. Typically, we consider situations where there is little to no background knowledge on the structure of the underlying signal, no access to signal-measurement pairs, nor even unpaired signal-measurement data. The only available information is provided by the observations and the measurement process statistics. We cast the problem as finding the \\textit{maximum a posteriori} estimate of the signal given each measurement, and propose a general framework for the reconstruction problem. We use a formulation of generative adversarial networks, where the generator takes as input a corrupted observation in order to produce realistic reconstructions, and add a penalty term tying the reconstruction to the associated observation. We evaluate our reconstructions on several image datasets with different types of corruptions. The proposed approach yields better results than alternative baselines, and comparable performance with model variants trained with additional supervision.", "keywords": ["Deep Learning", "Adversarial", "MAP", "GAN", "neural networks"], "authorids": ["arthur.pajot@lip6.fr", "emmanuel.de-bezenac@lip6.fr", "patrick.gallinari@lip6.fr"], "authors": ["Arthur Pajot", "Emmanuel de Bezenac", "Patrick Gallinari"], "pdf": "/pdf/8952a5ef40ce737be3059e78feb4dd0b7f297219.pdf", "paperhash": "pajot|unsupervised_adversarial_image_reconstruction", "_bibtex": "@inproceedings{\npajot2018unsupervised,\ntitle={Unsupervised Adversarial Image Reconstruction},\nauthor={Arthur Pajot and Emmanuel de Bezenac and Patrick Gallinari},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=BJg4Z3RqF7},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper1163/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621615447, "tddate": null, "super": null, "final": null, "reply": {"forum": "BJg4Z3RqF7", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper1163/Authors", "ICLR.cc/2019/Conference/Paper1163/Reviewers", "ICLR.cc/2019/Conference/Paper1163/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper1163/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper1163/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper1163/Authors|ICLR.cc/2019/Conference/Paper1163/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper1163/Reviewers", "ICLR.cc/2019/Conference/Paper1163/Authors", "ICLR.cc/2019/Conference/Paper1163/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621615447}}}, {"id": "H1xoXRON0m", "original": null, "number": 5, "cdate": 1542913571019, "ddate": null, "tcdate": 1542913571019, "tmdate": 1542913571019, "tddate": null, "forum": "BJg4Z3RqF7", "replyto": "B1lziIvI3m", "invitation": "ICLR.cc/2019/Conference/-/Paper1163/Official_Comment", "content": {"title": "We address the questions and add clarifications, which are also reflected in the updated draft", "comment": "Thank you for the review. We are sorry that you found the overall presentation confusing, and we have been actively working on trying to make the paper much clearer. We have thus submitted a revised version of the paper taking into account your comments and answering your questions. Please see also the general comments. Typically, we have:\n*  Rewritten Section 2.1 (Problem Setting) describing the abstract measurement process and the role of theta, taking into account your comments.\n* Modified the Method section (Section 3) in order to make the explanations more straightforward and less abstract. Typically, we moved some mathematical results in the appendix for a more fluent reading.\n* Added experiments on two additional datasets: LSUN and Recipe-1M (Section 4.1 + appendix C). They illustrate the behavior of the model and of the baselines on image datasets with different characteristics and confirm the good results obtained by our model.\n* Provided additional details on the hyperparameters and the architecture for overall  reproducibility (Section 4.1). Note that we will be releasing the code shortly.\n* Added details regarding the specific measurement instances (also called corruptions) used in the experiments (Section 4.2 Corruptions),\n* Added details on the different baselines in Section 4.3. (+ Figures visually describing them in appendix ) \n\nTo answer your question regarding the structure of the measurement process: the measurement (or corruption) process described in equation (1) is assumed known. This means that, as in most of the problem formulations for signal recovery, the structure of the stochastic function F is known. For example, let us consider the additive Gaussian noise case. F(X, \\Theta) = X + \\Theta, where X is the signal random variable to be recovered, and \\Theta is the noise random variable (also called corruption parameter) whose underlying distribution p_\\Theta is Gaussian. This distribution  p_\\Theta is assumed known, although for a specific measurement, we do not know the precise value \\theta that contributed to its corruption. In other cases, typically when the measurement process induces a more structured corruption such as in our Patch Band corruption, that randomly places a band occluding the original image (introduced in Section 4.2), \\Theta follows a uniform distribution taking its values from the space of pixel coordinates. To simulate this corruption process, one samples a \\theta from the prior p_\\Theta, and uses it to corrupt the signal x, resulting in measurement y = F(x, \\theta). In this case, F places a band using \\theta as the position of the top of the band. This is exactly the same formulation as the one used for AmbientGan: the associated corruptions parameter \\Theta for \u201cDropPatch\u201d which is very similar to our \u201cPatchBand\u201d, corresponds to the position of the occluding patch (refer to the official implementation [1]). Note that it would also be possible to sample the size of the box, if its size varies in the corrupted data. \n\nPaired/Unpaired variant explanation :\n\n\nFor the two model variants that use the additional information, *Unpaired and Paired Variant* we have added additional details in the Baseline Section 4.3, and additional Figures describing them in the Baseline appendix C. Below is an extract of the Baselines Section of the updated paper:\n\nUnpaired Variant:\n\u201cHere, we have access to samples of the signal distribution p_X. This means that although we have no paired  samples from the joint p_X,Y, we have access to unpaired samples from p_X and p_Y. This baseline is similar to our model although, instead of discriminating between a measurement from the data y and a simulated measurement \\hat{y}, we directly discriminate between samples from the signal distribution and the output of the reconstruction network \\hat{x}.\u201d\n\nPaired Variant:\n\u201cThis baseline has access to signal measurement pairs (y, x) from the joint distribution p_X,Y. Given input measurement y, the reconstruction is obtained by regressing to the associated signal x using a MSE loss. In order to avoid blurry samples, we add an adversarial term in the objective in order to constrain G to produce realistic samples, as in Pix2Pix [2]. The model is trained using the same architectures as our model, and the hyperparameters have been found using cross-validation. \u201d\n\n\n[1]: https://github.com/AshishBora/ambient-gan/blob/master/src/commons/measure.py#L176\n[2]: https://phillipi.github.io/pix2pix/\n"}, "signatures": ["ICLR.cc/2019/Conference/Paper1163/Authors"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper1163/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper1163/Authors", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Unsupervised Adversarial Image Reconstruction", "abstract": "We address the problem of recovering an underlying signal from lossy, inaccurate observations in an unsupervised setting. Typically, we consider situations where there is little to no background knowledge on the structure of the underlying signal, no access to signal-measurement pairs, nor even unpaired signal-measurement data. The only available information is provided by the observations and the measurement process statistics. We cast the problem as finding the \\textit{maximum a posteriori} estimate of the signal given each measurement, and propose a general framework for the reconstruction problem. We use a formulation of generative adversarial networks, where the generator takes as input a corrupted observation in order to produce realistic reconstructions, and add a penalty term tying the reconstruction to the associated observation. We evaluate our reconstructions on several image datasets with different types of corruptions. The proposed approach yields better results than alternative baselines, and comparable performance with model variants trained with additional supervision.", "keywords": ["Deep Learning", "Adversarial", "MAP", "GAN", "neural networks"], "authorids": ["arthur.pajot@lip6.fr", "emmanuel.de-bezenac@lip6.fr", "patrick.gallinari@lip6.fr"], "authors": ["Arthur Pajot", "Emmanuel de Bezenac", "Patrick Gallinari"], "pdf": "/pdf/8952a5ef40ce737be3059e78feb4dd0b7f297219.pdf", "paperhash": "pajot|unsupervised_adversarial_image_reconstruction", "_bibtex": "@inproceedings{\npajot2018unsupervised,\ntitle={Unsupervised Adversarial Image Reconstruction},\nauthor={Arthur Pajot and Emmanuel de Bezenac and Patrick Gallinari},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=BJg4Z3RqF7},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper1163/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621615447, "tddate": null, "super": null, "final": null, "reply": {"forum": "BJg4Z3RqF7", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper1163/Authors", "ICLR.cc/2019/Conference/Paper1163/Reviewers", "ICLR.cc/2019/Conference/Paper1163/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper1163/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper1163/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper1163/Authors|ICLR.cc/2019/Conference/Paper1163/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper1163/Reviewers", "ICLR.cc/2019/Conference/Paper1163/Authors", "ICLR.cc/2019/Conference/Paper1163/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621615447}}}, {"id": "H1xo8T_4RQ", "original": null, "number": 4, "cdate": 1542913363274, "ddate": null, "tcdate": 1542913363274, "tmdate": 1542913363274, "tddate": null, "forum": "BJg4Z3RqF7", "replyto": "BJg4Z3RqF7", "invitation": "ICLR.cc/2019/Conference/-/Paper1163/Official_Comment", "content": {"title": "General Comments and Paper Revision", "comment": "Thanks to all the reviewers for their comments and suggestions. We tried to take all of them into account, we reorganized the paper accordingly and hope to provide now all the required precisions. We address below some general comments/ questions raised by the reviewers and then give detailed answers for each review.\n\nThe model presentation as been rewritten, highlighting the main ideas and results (section 3) while deferring some mathematical details to Appendix A. We have added figures illustrating the different components of the model (Fig. 1, 2, 3).\nDetails on the model parameters used for the experiments are provided in section 4.1, details on the corruption processes used for the experiments in section 4.2 and the baselines used for comparison are described quite extensively in section 4.3.\nWe performed tests on two additional datasets (LSUN Bedrooms and Recipe-1M). The three datasets have different characteristics, these experiments thus illustrate the model behavior for these different contexts. In the initial version, tests were performed on the CelebA dataset only, and two reviewers mentioned that this was too limited.\n Finally, the reviewers raised questions on the nature of the perturbation mechanism (the F(x;theta) function in the text). We agree that the description might have been unclear. This is now fully described in section 2.1. In a few words, we suppose that there exists a signal x we wish to reconstruct, but we only have access to x through lossy measurements y. The measurement process is modeled by a stochastic function with corruption parameters theta associated to a prior distribution p_Theta. The observations y are then supposed to be  generated as y = F(x; theta). We have added discussions in the text, explaining the instances of F and p_Theta associated to the different types of corruptions used in the experiments.\n"}, "signatures": ["ICLR.cc/2019/Conference/Paper1163/Authors"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper1163/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper1163/Authors", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Unsupervised Adversarial Image Reconstruction", "abstract": "We address the problem of recovering an underlying signal from lossy, inaccurate observations in an unsupervised setting. Typically, we consider situations where there is little to no background knowledge on the structure of the underlying signal, no access to signal-measurement pairs, nor even unpaired signal-measurement data. The only available information is provided by the observations and the measurement process statistics. We cast the problem as finding the \\textit{maximum a posteriori} estimate of the signal given each measurement, and propose a general framework for the reconstruction problem. We use a formulation of generative adversarial networks, where the generator takes as input a corrupted observation in order to produce realistic reconstructions, and add a penalty term tying the reconstruction to the associated observation. We evaluate our reconstructions on several image datasets with different types of corruptions. The proposed approach yields better results than alternative baselines, and comparable performance with model variants trained with additional supervision.", "keywords": ["Deep Learning", "Adversarial", "MAP", "GAN", "neural networks"], "authorids": ["arthur.pajot@lip6.fr", "emmanuel.de-bezenac@lip6.fr", "patrick.gallinari@lip6.fr"], "authors": ["Arthur Pajot", "Emmanuel de Bezenac", "Patrick Gallinari"], "pdf": "/pdf/8952a5ef40ce737be3059e78feb4dd0b7f297219.pdf", "paperhash": "pajot|unsupervised_adversarial_image_reconstruction", "_bibtex": "@inproceedings{\npajot2018unsupervised,\ntitle={Unsupervised Adversarial Image Reconstruction},\nauthor={Arthur Pajot and Emmanuel de Bezenac and Patrick Gallinari},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=BJg4Z3RqF7},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper1163/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621615447, "tddate": null, "super": null, "final": null, "reply": {"forum": "BJg4Z3RqF7", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper1163/Authors", "ICLR.cc/2019/Conference/Paper1163/Reviewers", "ICLR.cc/2019/Conference/Paper1163/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper1163/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper1163/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper1163/Authors|ICLR.cc/2019/Conference/Paper1163/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper1163/Reviewers", "ICLR.cc/2019/Conference/Paper1163/Authors", "ICLR.cc/2019/Conference/Paper1163/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621615447}}}, {"id": "BylDLypM0X", "original": null, "number": 3, "cdate": 1542799183512, "ddate": null, "tcdate": 1542799183512, "tmdate": 1542799183512, "tddate": null, "forum": "BJg4Z3RqF7", "replyto": "rJg2jSxRhQ", "invitation": "ICLR.cc/2019/Conference/-/Paper1163/Official_Comment", "content": {"title": "please write a detailed review", "comment": "Reviewer 3, your review is in my opinion below the threshold needed for a top scientific conference. \nPlease read the paper more carefully and write a detailed quality review. We are all working very hard to make the noisy review process better. "}, "signatures": ["ICLR.cc/2019/Conference/Paper1163/AnonReviewer1"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper1163/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper1163/AnonReviewer1", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Unsupervised Adversarial Image Reconstruction", "abstract": "We address the problem of recovering an underlying signal from lossy, inaccurate observations in an unsupervised setting. Typically, we consider situations where there is little to no background knowledge on the structure of the underlying signal, no access to signal-measurement pairs, nor even unpaired signal-measurement data. The only available information is provided by the observations and the measurement process statistics. We cast the problem as finding the \\textit{maximum a posteriori} estimate of the signal given each measurement, and propose a general framework for the reconstruction problem. We use a formulation of generative adversarial networks, where the generator takes as input a corrupted observation in order to produce realistic reconstructions, and add a penalty term tying the reconstruction to the associated observation. We evaluate our reconstructions on several image datasets with different types of corruptions. The proposed approach yields better results than alternative baselines, and comparable performance with model variants trained with additional supervision.", "keywords": ["Deep Learning", "Adversarial", "MAP", "GAN", "neural networks"], "authorids": ["arthur.pajot@lip6.fr", "emmanuel.de-bezenac@lip6.fr", "patrick.gallinari@lip6.fr"], "authors": ["Arthur Pajot", "Emmanuel de Bezenac", "Patrick Gallinari"], "pdf": "/pdf/8952a5ef40ce737be3059e78feb4dd0b7f297219.pdf", "paperhash": "pajot|unsupervised_adversarial_image_reconstruction", "_bibtex": "@inproceedings{\npajot2018unsupervised,\ntitle={Unsupervised Adversarial Image Reconstruction},\nauthor={Arthur Pajot and Emmanuel de Bezenac and Patrick Gallinari},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=BJg4Z3RqF7},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper1163/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621615447, "tddate": null, "super": null, "final": null, "reply": {"forum": "BJg4Z3RqF7", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper1163/Authors", "ICLR.cc/2019/Conference/Paper1163/Reviewers", "ICLR.cc/2019/Conference/Paper1163/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper1163/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper1163/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper1163/Authors|ICLR.cc/2019/Conference/Paper1163/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper1163/Reviewers", "ICLR.cc/2019/Conference/Paper1163/Authors", "ICLR.cc/2019/Conference/Paper1163/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621615447}}}, {"id": "SklY001CnQ", "original": null, "number": 3, "cdate": 1541435089198, "ddate": null, "tcdate": 1541435089198, "tmdate": 1541533369127, "tddate": null, "forum": "BJg4Z3RqF7", "replyto": "BJg4Z3RqF7", "invitation": "ICLR.cc/2019/Conference/-/Paper1163/Official_Review", "content": {"title": "UNSUPERVISED ADVERSARIAL IMAGE RECONSTRUCTION", "review": "The authors address the problem of recovering an underlying signal from lossy and inaccurate measurements in an unsupervised fashion. They use a GAN framework to recover plausible signals from the measurements in the data. \n\n* Authors need to test other datasets, CelebA dataset is too limited. \n* Similarly, the experiment with different corruption processes are required. \n* What is a definition of F. It is not clear \"measurement process\".\n", "rating": "6: Marginally above acceptance threshold", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "signatures": ["ICLR.cc/2019/Conference/Paper1163/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Unsupervised Adversarial Image Reconstruction", "abstract": "We address the problem of recovering an underlying signal from lossy, inaccurate observations in an unsupervised setting. Typically, we consider situations where there is little to no background knowledge on the structure of the underlying signal, no access to signal-measurement pairs, nor even unpaired signal-measurement data. The only available information is provided by the observations and the measurement process statistics. We cast the problem as finding the \\textit{maximum a posteriori} estimate of the signal given each measurement, and propose a general framework for the reconstruction problem. We use a formulation of generative adversarial networks, where the generator takes as input a corrupted observation in order to produce realistic reconstructions, and add a penalty term tying the reconstruction to the associated observation. We evaluate our reconstructions on several image datasets with different types of corruptions. The proposed approach yields better results than alternative baselines, and comparable performance with model variants trained with additional supervision.", "keywords": ["Deep Learning", "Adversarial", "MAP", "GAN", "neural networks"], "authorids": ["arthur.pajot@lip6.fr", "emmanuel.de-bezenac@lip6.fr", "patrick.gallinari@lip6.fr"], "authors": ["Arthur Pajot", "Emmanuel de Bezenac", "Patrick Gallinari"], "pdf": "/pdf/8952a5ef40ce737be3059e78feb4dd0b7f297219.pdf", "paperhash": "pajot|unsupervised_adversarial_image_reconstruction", "_bibtex": "@inproceedings{\npajot2018unsupervised,\ntitle={Unsupervised Adversarial Image Reconstruction},\nauthor={Arthur Pajot and Emmanuel de Bezenac and Patrick Gallinari},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=BJg4Z3RqF7},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper1163/Official_Review", "cdate": 1542234290990, "expdate": 1552335264000, "duedate": 1541196000000, "reply": {"forum": "BJg4Z3RqF7", "replyto": "BJg4Z3RqF7", "readers": {"description": "The users who will be allowed to read the reply content.", "values": ["everyone"]}, "nonreaders": {"values": []}, "signatures": {"description": "How your identity will be displayed with the above content.", "values-regex": "ICLR.cc/2019/Conference/Paper1163/AnonReviewer[0-9]+"}, "writers": {"description": "Users that may modify this record.", "values": ["ICLR.cc/2019/Conference"]}, "content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "required": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}}, "multiReply": false, "tcdate": 1552335886656, "tmdate": 1552335886656, "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "invitees": ["ICLR.cc/2019/Conference/Paper1163/Reviewers"], "noninvitees": [], "signatures": ["ICLR.cc/2019/Conference"]}}}, {"id": "BylSgJYp2Q", "original": null, "number": 2, "cdate": 1541406445185, "ddate": null, "tcdate": 1541406445185, "tmdate": 1541533368842, "tddate": null, "forum": "BJg4Z3RqF7", "replyto": "BJg4Z3RqF7", "invitation": "ICLR.cc/2019/Conference/-/Paper1163/Official_Review", "content": {"title": "image reconstruction from noisy samples ", "review": "This is a very interesting paper that achieves something that seems initially impossible: \nto learn to reconstruct clear images from only seeing noisy or blurry images. \n\nThe paper builds on the closely related prior work AmbientGAN which shows that it is possible to learn the *distribution* of uncorrupted samples using only corrupted samples, again a very surprising finding. \nHowever, AmbientGAN does not try to reconstruct a single image, only to to learn the clear image distribution. The key idea that makes this is possible is knowledge of the statistics of the corruption process: the generator tries to create images that *after they have been corrupted* they look indistinguishable from real corrupted images. This surprisingly works and provably recovers the true distribution under a very wide set of corruption distributions, but tells us nothing about reconstructing an actual image from measurements. \n\nGiven access to a generative model for clear images, an image can be reconstructed from measurements by maximizing the likelihood term. This method (CS-GAN) was introduced by Bora et al. in 2017. Therefore one approach to solve the problem that this paper tackles is to first use AmbientGAN to get a generative model for clear images and then use CS-GAN using the learned GAN. If I understand correctly, this is the 'Conditional AmbientGAN' approach that is used as a baseline. This is a sensible approach given prior work. However, the authors show that their method ('Unpaired Supervision') performs significantly better compared to the Conditional AmbientGAN baseline. This is very surprising and interesting to me. Please discuss this a bit more ? As far as I understand the proposed method is a merging of AmbientGAN and CS-GAN, but much better than the naive separation. Could you give a bit more intuition on why ?\n\nI would like to add also that the authors can use their approach to learn a better AmbientGAN. After getting their denoised images, these can be used to train a new AmbientGAN, with cleaner images as input , which should be even better no ?\n\nIn the appendix where is the proposed method in fig 5- 8 ?\n\nDoes the proposed method outperform Deep Image Prior ? \n\n\n", "rating": "8: Top 50% of accepted papers, clear accept", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["ICLR.cc/2019/Conference/Paper1163/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Unsupervised Adversarial Image Reconstruction", "abstract": "We address the problem of recovering an underlying signal from lossy, inaccurate observations in an unsupervised setting. Typically, we consider situations where there is little to no background knowledge on the structure of the underlying signal, no access to signal-measurement pairs, nor even unpaired signal-measurement data. The only available information is provided by the observations and the measurement process statistics. We cast the problem as finding the \\textit{maximum a posteriori} estimate of the signal given each measurement, and propose a general framework for the reconstruction problem. We use a formulation of generative adversarial networks, where the generator takes as input a corrupted observation in order to produce realistic reconstructions, and add a penalty term tying the reconstruction to the associated observation. We evaluate our reconstructions on several image datasets with different types of corruptions. The proposed approach yields better results than alternative baselines, and comparable performance with model variants trained with additional supervision.", "keywords": ["Deep Learning", "Adversarial", "MAP", "GAN", "neural networks"], "authorids": ["arthur.pajot@lip6.fr", "emmanuel.de-bezenac@lip6.fr", "patrick.gallinari@lip6.fr"], "authors": ["Arthur Pajot", "Emmanuel de Bezenac", "Patrick Gallinari"], "pdf": "/pdf/8952a5ef40ce737be3059e78feb4dd0b7f297219.pdf", "paperhash": "pajot|unsupervised_adversarial_image_reconstruction", "_bibtex": "@inproceedings{\npajot2018unsupervised,\ntitle={Unsupervised Adversarial Image Reconstruction},\nauthor={Arthur Pajot and Emmanuel de Bezenac and Patrick Gallinari},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=BJg4Z3RqF7},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper1163/Official_Review", "cdate": 1542234290990, "expdate": 1552335264000, "duedate": 1541196000000, "reply": {"forum": "BJg4Z3RqF7", "replyto": "BJg4Z3RqF7", "readers": {"description": "The users who will be allowed to read the reply content.", "values": ["everyone"]}, "nonreaders": {"values": []}, "signatures": {"description": "How your identity will be displayed with the above content.", "values-regex": "ICLR.cc/2019/Conference/Paper1163/AnonReviewer[0-9]+"}, "writers": {"description": "Users that may modify this record.", "values": ["ICLR.cc/2019/Conference"]}, "content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "required": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}}, "multiReply": false, "tcdate": 1552335886656, "tmdate": 1552335886656, "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "invitees": ["ICLR.cc/2019/Conference/Paper1163/Reviewers"], "noninvitees": [], "signatures": ["ICLR.cc/2019/Conference"]}}}, {"id": "B1lziIvI3m", "original": null, "number": 1, "cdate": 1540941465582, "ddate": null, "tcdate": 1540941465582, "tmdate": 1541533368547, "tddate": null, "forum": "BJg4Z3RqF7", "replyto": "BJg4Z3RqF7", "invitation": "ICLR.cc/2019/Conference/-/Paper1163/Official_Review", "content": {"title": "Interesting but confusing", "review": "This paper presents a method to reconstruct images using only noisy measurements. This problem is practically interesting, since the noiseless signal may be unavailable in many applications. The approach combines ideas from recent development in compressed sensing and GANs. However, the model\u2019s presentation is confusing, and many important details of the experiments are missing.\n\nPros:\n\n* The problem is interesting and important\n* The combination of compressed sensing and GANs for image reconstruction is novel\n\nCons:\n\n* The model structure is unclear: for example, what is the role of the variable \\theta? Section 2.1 says it is known, but the algorithm samples from its prior(?). Since there is no further explanation with respect to the experiments, I am not sure how the values of \\theta or its distributions were determined. Although \\theta is formally similar to the \\theta parameters of the measurement function in ambientGANs, this interpretation is at odds with the example given in the paper (below eq.1, saying \\theta can be positions or sizes).\n* A few important details of the model are missing. For example, what is the exact structure of the measurement function F?\n* The baseline models are a bit confusing. More detail about unpaired vs paired supervision would also be helpful for understanding how these baseline models use the additional information.\n* Although the paper mentioned parameters are obtained from cross-validation, it would still be helpful to describe a few important ones (e.g., neural network size, weight \\lambda) for comparison with other models.The experiments on only CelebA dataset are too limited.", "rating": "4: Ok but not good enough - rejection", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "signatures": ["ICLR.cc/2019/Conference/Paper1163/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Unsupervised Adversarial Image Reconstruction", "abstract": "We address the problem of recovering an underlying signal from lossy, inaccurate observations in an unsupervised setting. Typically, we consider situations where there is little to no background knowledge on the structure of the underlying signal, no access to signal-measurement pairs, nor even unpaired signal-measurement data. The only available information is provided by the observations and the measurement process statistics. We cast the problem as finding the \\textit{maximum a posteriori} estimate of the signal given each measurement, and propose a general framework for the reconstruction problem. We use a formulation of generative adversarial networks, where the generator takes as input a corrupted observation in order to produce realistic reconstructions, and add a penalty term tying the reconstruction to the associated observation. We evaluate our reconstructions on several image datasets with different types of corruptions. The proposed approach yields better results than alternative baselines, and comparable performance with model variants trained with additional supervision.", "keywords": ["Deep Learning", "Adversarial", "MAP", "GAN", "neural networks"], "authorids": ["arthur.pajot@lip6.fr", "emmanuel.de-bezenac@lip6.fr", "patrick.gallinari@lip6.fr"], "authors": ["Arthur Pajot", "Emmanuel de Bezenac", "Patrick Gallinari"], "pdf": "/pdf/8952a5ef40ce737be3059e78feb4dd0b7f297219.pdf", "paperhash": "pajot|unsupervised_adversarial_image_reconstruction", "_bibtex": "@inproceedings{\npajot2018unsupervised,\ntitle={Unsupervised Adversarial Image Reconstruction},\nauthor={Arthur Pajot and Emmanuel de Bezenac and Patrick Gallinari},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=BJg4Z3RqF7},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper1163/Official_Review", "cdate": 1542234290990, "expdate": 1552335264000, "duedate": 1541196000000, "reply": {"forum": "BJg4Z3RqF7", "replyto": "BJg4Z3RqF7", "readers": {"description": "The users who will be allowed to read the reply content.", "values": ["everyone"]}, "nonreaders": {"values": []}, "signatures": {"description": "How your identity will be displayed with the above content.", "values-regex": "ICLR.cc/2019/Conference/Paper1163/AnonReviewer[0-9]+"}, "writers": {"description": "Users that may modify this record.", "values": ["ICLR.cc/2019/Conference"]}, "content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "required": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}}, "multiReply": false, "tcdate": 1552335886656, "tmdate": 1552335886656, "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "invitees": ["ICLR.cc/2019/Conference/Paper1163/Reviewers"], "noninvitees": [], "signatures": ["ICLR.cc/2019/Conference"]}}}], "count": 12}