{"notes": [{"id": "1IBgFQbj7y", "original": "y529T7tEef", "number": 2504, "cdate": 1601308276793, "ddate": null, "tcdate": 1601308276793, "tmdate": 1614985663624, "tddate": null, "forum": "1IBgFQbj7y", "replyto": null, "invitation": "ICLR.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Maximum Categorical Cross Entropy (MCCE): A noise-robust alternative loss function to mitigate racial bias in Convolutional Neural Networks (CNNs) by reducing overfitting", "authorids": ["~Nidhi_Gowdra1", "rsinha@aut.ac.nz", "stephen.macdonell@aut.ac.nz", "weiqi.yan@aut.ac.nz"], "authors": ["Nidhi Gowdra", "Roopak Sinha", "Stephen MacDonell", "WeiQi Yan"], "keywords": [], "abstract": "Categorical Cross Entropy (CCE) is the most commonly used loss function in deep neural networks such as Convolutional Neural Networks (CNNs) for multi-class classification problems. In spite of the fact that CCE is highly susceptible to noise; CNN models trained without accounting for the unique noise characteristics of the input data, or noise introduced during model training, invariably suffer from overfitting affecting model generalizability. The lack of generalizability becomes especially apparent in the context of ethnicity/racial image classification problems encountered in the domain of computer vision. One such problem is the unintended discriminatory racial bias that CNN models trained using CCE fail to adequately address. In other words, CNN models trained using CCE offer a skewed representation of classification performance favoring lighter skin tones.\n\nIn this paper, we propose and empirically validate a novel noise-robust extension to the existing CCE loss function called Maximum Categorical Cross-Entropy (MCCE), which utilizes CCE loss and a novel reconstruction loss, calculated using the Maximum Entropy (ME) measures of the convolutional kernel weights and input training dataset. We compare the use of MCCE with CCE-trained models on two benchmarking datasets, colorFERET and UTKFace, using a Residual Network (ResNet) CNN architecture. MCCE-trained models reduce overfitting by 5.85% and 4.3% on colorFERET and UTKFace datasets respectively. In cross-validation testing, MCCE-trained models outperform CCE-trained models by 8.8% and 25.16% on the colorFERET and UTKFace datasets respectively. MCCE addresses and mitigates the persistent problem of inadvertent racial bias for facial recognition problems in the domain of computer vision.", "pdf": "/pdf/97e2075b1c04f38335f58ed00b6326a00bcc1c00.pdf", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "gowdra|maximum_categorical_cross_entropy_mcce_a_noiserobust_alternative_loss_function_to_mitigate_racial_bias_in_convolutional_neural_networks_cnns_by_reducing_overfitting", "supplementary_material": "/attachment/336a3e22416872b1679c1e01d45acd7c48a3b0d8.zip", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=Sj8aM-VKRn", "_bibtex": "@misc{\ngowdra2021maximum,\ntitle={Maximum Categorical Cross Entropy ({\\{}MCCE{\\}}): A noise-robust alternative loss function to mitigate racial bias in Convolutional Neural Networks ({\\{}CNN{\\}}s) by reducing overfitting},\nauthor={Nidhi Gowdra and Roopak Sinha and Stephen MacDonell and WeiQi Yan},\nyear={2021},\nurl={https://openreview.net/forum?id=1IBgFQbj7y}\n}"}, "signatures": ["ICLR.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference"], "details": {"replyCount": 6, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"reply": {"readers": {"values-regex": ".*"}, "writers": {"values": ["ICLR.cc/2021/Conference"]}, "signatures": {"values": ["ICLR.cc/2021/Conference"]}, "content": {"authors": {"values": ["Anonymous"]}, "authorids": {"values-regex": ".*"}, "reviewed_version_(pdf)": {"required": false, "description": "Upload a PDF file that ends with .pdf", "value-regex": ".*"}}}, "signatures": ["ICLR.cc/2021/Conference"], "readers": ["everyone"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["~", "OpenReview.net/Support"], "tcdate": 1601308008205, "tmdate": 1614984599368, "id": "ICLR.cc/2021/Conference/-/Blind_Submission"}}, "tauthor": "OpenReview.net"}, {"id": "Ih_2IdD6U8", "original": null, "number": 1, "cdate": 1610040498001, "ddate": null, "tcdate": 1610040498001, "tmdate": 1610474104477, "tddate": null, "forum": "1IBgFQbj7y", "replyto": "1IBgFQbj7y", "invitation": "ICLR.cc/2021/Conference/Paper2504/-/Decision", "content": {"title": "Final Decision", "decision": "Reject", "comment": "The paper introduces a new loss, Maximum Categorical Cross-Entropy, which combines the usual cross-entropy loss with a maximum entropy regularisation term on the convolutional kernels, and is evaluated on image classification. The authors have trained a face classification algorithm on two datasets: UTKFace (https://susanqq.github.io/UTKFace/) and NIST colorFERET (https://www.nist.gov/itl/products-and-services/color-feret-database). The labels consisted in, respectively: White, Black, Indian, Asian, Others (over 18k images) and Asian, Asian-Middle-Easter, Black-of-African-American, White, Hispanic (over 11k images) (see section 4.1 of the paper).\n\nFrom the meta-reviewer's perspective:\nAs stated in the title, abstract and in paragraph 3 of section 1, the motivation of the paper is to reduce model overfitting and racial bias towards one category. However, there is no further discussion about any \"ethical, societal and practical concerns when dealing with facial datasets, especially for the task of race or gender classification\". It seems to me that a paper that implements a \"race classification\" algorithm should at least devote a substantially long part of the discussion on the validity of such a task and of such a labelling process, as well as question the motivations and potential misuses. Who labeled these faces and based on what visual characteristics? Were the subjects of the photographs consenting and did they self-declare their ethnicities? Are the authors simply reproducing discredited phrenology assumptions about ethnicities and about \"race\", which is increasingly defined as a mere social construct? Given that there is nothing specific to face classification in the loss function, I wonder why did the authors decide to focus on ethnicity features? What exactly could a visual ethnicity classifier be used for? Given the sheer amount of questions raised by the paper, we have submitted it for review by the Ethics Board.\n\nSummary of the reviews:\nReviewers gave scores scores 3, 4, 5, 5 (without rebuttal from the authors), raising concerns about the novelty and contribution of the method (as it is simply combining maximum entropy with cross-entropy), clarity of the explanation of the method, missing related work and baselines and evaluation metrics.\n\nBased on the low scores, unfavourable reviews and an ongoing Ethics Board investigation, I recommend for this paper to be rejected.\n\n\n\nWhile this paper is likely to be rejected (, I believe that these concerns should be raised and potentially reviewed by the Ethics Board (unless this is an obvious rejection). Thank you in advance for your time."}, "signatures": ["ICLR.cc/2021/Conference/Program_Chairs"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference/Program_Chairs"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Maximum Categorical Cross Entropy (MCCE): A noise-robust alternative loss function to mitigate racial bias in Convolutional Neural Networks (CNNs) by reducing overfitting", "authorids": ["~Nidhi_Gowdra1", "rsinha@aut.ac.nz", "stephen.macdonell@aut.ac.nz", "weiqi.yan@aut.ac.nz"], "authors": ["Nidhi Gowdra", "Roopak Sinha", "Stephen MacDonell", "WeiQi Yan"], "keywords": [], "abstract": "Categorical Cross Entropy (CCE) is the most commonly used loss function in deep neural networks such as Convolutional Neural Networks (CNNs) for multi-class classification problems. In spite of the fact that CCE is highly susceptible to noise; CNN models trained without accounting for the unique noise characteristics of the input data, or noise introduced during model training, invariably suffer from overfitting affecting model generalizability. The lack of generalizability becomes especially apparent in the context of ethnicity/racial image classification problems encountered in the domain of computer vision. One such problem is the unintended discriminatory racial bias that CNN models trained using CCE fail to adequately address. In other words, CNN models trained using CCE offer a skewed representation of classification performance favoring lighter skin tones.\n\nIn this paper, we propose and empirically validate a novel noise-robust extension to the existing CCE loss function called Maximum Categorical Cross-Entropy (MCCE), which utilizes CCE loss and a novel reconstruction loss, calculated using the Maximum Entropy (ME) measures of the convolutional kernel weights and input training dataset. We compare the use of MCCE with CCE-trained models on two benchmarking datasets, colorFERET and UTKFace, using a Residual Network (ResNet) CNN architecture. MCCE-trained models reduce overfitting by 5.85% and 4.3% on colorFERET and UTKFace datasets respectively. In cross-validation testing, MCCE-trained models outperform CCE-trained models by 8.8% and 25.16% on the colorFERET and UTKFace datasets respectively. MCCE addresses and mitigates the persistent problem of inadvertent racial bias for facial recognition problems in the domain of computer vision.", "pdf": "/pdf/97e2075b1c04f38335f58ed00b6326a00bcc1c00.pdf", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "gowdra|maximum_categorical_cross_entropy_mcce_a_noiserobust_alternative_loss_function_to_mitigate_racial_bias_in_convolutional_neural_networks_cnns_by_reducing_overfitting", "supplementary_material": "/attachment/336a3e22416872b1679c1e01d45acd7c48a3b0d8.zip", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=Sj8aM-VKRn", "_bibtex": "@misc{\ngowdra2021maximum,\ntitle={Maximum Categorical Cross Entropy ({\\{}MCCE{\\}}): A noise-robust alternative loss function to mitigate racial bias in Convolutional Neural Networks ({\\{}CNN{\\}}s) by reducing overfitting},\nauthor={Nidhi Gowdra and Roopak Sinha and Stephen MacDonell and WeiQi Yan},\nyear={2021},\nurl={https://openreview.net/forum?id=1IBgFQbj7y}\n}"}, "tags": [], "invitation": {"reply": {"forum": "1IBgFQbj7y", "replyto": "1IBgFQbj7y", "readers": {"values": ["everyone"]}, "writers": {"values": ["ICLR.cc/2021/Conference/Program_Chairs"]}, "signatures": {"values": ["ICLR.cc/2021/Conference/Program_Chairs"]}, "content": {"title": {"value": "Final Decision"}, "decision": {"value-radio": ["Accept (Oral)", "Accept (Spotlight)", "Accept (Poster)", "Reject"]}, "comment": {"value-regex": "[\\S\\s]{0,50000}", "markdown": true}}}, "multiReply": false, "signatures": ["ICLR.cc/2021/Conference"], "readers": ["everyone"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Program_Chairs"], "tcdate": 1610040497987, "tmdate": 1610474104461, "id": "ICLR.cc/2021/Conference/Paper2504/-/Decision"}}}, {"id": "RB8oV50_yx-", "original": null, "number": 1, "cdate": 1609948520204, "ddate": null, "tcdate": 1609948520204, "tmdate": 1609948520204, "tddate": null, "forum": "1IBgFQbj7y", "replyto": "1IBgFQbj7y", "invitation": "ICLR.cc/2021/Conference/Paper2504/-/Ethics_Meta_Review", "content": {"decision": "No judgement (proceed with normal process)", "ethics_review": "This paper was flagged for evaluation by the ethics board based on the following:\n1.\tthe motivation of the paper is to reduce model overfitting and racial bias towards one category. However, there is no further discussion about any \"ethical, societal and practical concerns when dealing with facial datasets, especially for the task of race or gender classification\".\n\nThe primary concern regarding race bias in computer vision applications has been the question of whether systems that perform face recognition (recognizing a known person from a novel image of that person) or face attribute prediction (e.g., predicting gender or age) perform worse on some racial groups such as people with darker skin. This paper does not address that question. Instead, it trains a classifier to predict the race of the person. While this may tell us something about how classifiers can confuse different racial groups, it doesn\u2019t tell us anything about how race biases performance on other tasks.\n\nTo study the efficacy of their MCCE loss function, the authors selected two facial image datasets consisting of various racial/ethnicity classes (e.g. White, Hispanic, Black, Asian, etc.) but with either a balanced or unbalanced number of images across classes (in one dataset authors have aggregated classes on the basis of already biased datasets due to the \u201cvery limited images\u201d for particular classes). They then illustrated the impact of these datasets on classification performance. The authors claim that \u201cimplicit biases with respect to the training set significantly corrupts the final results\u201d. However, there is no reason to blame \u201cimplicit biases\u201d. The observed results could simply be due to class imbalance, which is completely explicit, not implicit. It is possible that the MCCE loss function would reduce racial bias, as it appears to do a better job of normalizing image features. But the present paper cannot distinguish \nthis from the class imbalance hypothesis. Furthermore, the fact that CCE does pretty well when trained on a balanced dataset provides additional evidence that class imbalance is the primary culprit. To separate these two potential explanations, the authors need to separately vary race and class imbalance. For that purpose, it would be best to focus on a different primary prediction task (e.g., gender or age classification) and then compare class imbalance to changes in racial composition (e.g., all images from a single race vs. from multiple races). \n\nThe authors state that UTKFace dataset is imbalanced, but they do not provide statistics on the imbalance (nor does the original paper that created the dataset). Based on the confusion matrix results, I\u2019m guessing that White faces form a huge majority class in this dataset. Every other class is confused with the White class (by the CCE loss). \n\nThe authors are claiming that they are mitigating racial bias, but because they do not demonstrate a task that exhibits racial bias (e.g., face recognition or face gender or age prediction), this claim is not supported. We recommend that they remove this claim from the paper. Instead, their results would appear to support claims of (a) improved accuracy in the presence of class imbalance and (b) improved domain generalization. Both of these claims are plausible results of their improved loss function. \n\nIf the authors do want to make a claim of reducing racial bias, then they should study a task such as face recognition or face attribute detection and measure how performance on those tasks varies with race (e.g., along the lines of the famous Gender Shades paper, Buolamwini, J., & Gebru, T. (2018). Gender Shades: Intersectional Accuracy Disparities in Commercial Gender Classification. Proceedings of Machine Learning Research, 81, 1\u201315.). Furthermore, as in the Buolamwini & Gebru paper, they should use an objective measure of skin darkness/lightness rather than relying on race labels whose meaning can vary greatly.\n\nThe questions being studied in this paper are important for improving the fairness of computer vision systems and do not raise ethical concerns. Rather, we find that the authors have not demonstrated that they are making progress on those issues. \n\nDecision: No Concern (i.e. no judgement as indicated)"}, "signatures": ["ICLR.cc/2021/Conference/Paper2504/Ethics_Committee"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference/Paper2504/Ethics_Committee"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Maximum Categorical Cross Entropy (MCCE): A noise-robust alternative loss function to mitigate racial bias in Convolutional Neural Networks (CNNs) by reducing overfitting", "authorids": ["~Nidhi_Gowdra1", "rsinha@aut.ac.nz", "stephen.macdonell@aut.ac.nz", "weiqi.yan@aut.ac.nz"], "authors": ["Nidhi Gowdra", "Roopak Sinha", "Stephen MacDonell", "WeiQi Yan"], "keywords": [], "abstract": "Categorical Cross Entropy (CCE) is the most commonly used loss function in deep neural networks such as Convolutional Neural Networks (CNNs) for multi-class classification problems. In spite of the fact that CCE is highly susceptible to noise; CNN models trained without accounting for the unique noise characteristics of the input data, or noise introduced during model training, invariably suffer from overfitting affecting model generalizability. The lack of generalizability becomes especially apparent in the context of ethnicity/racial image classification problems encountered in the domain of computer vision. One such problem is the unintended discriminatory racial bias that CNN models trained using CCE fail to adequately address. In other words, CNN models trained using CCE offer a skewed representation of classification performance favoring lighter skin tones.\n\nIn this paper, we propose and empirically validate a novel noise-robust extension to the existing CCE loss function called Maximum Categorical Cross-Entropy (MCCE), which utilizes CCE loss and a novel reconstruction loss, calculated using the Maximum Entropy (ME) measures of the convolutional kernel weights and input training dataset. We compare the use of MCCE with CCE-trained models on two benchmarking datasets, colorFERET and UTKFace, using a Residual Network (ResNet) CNN architecture. MCCE-trained models reduce overfitting by 5.85% and 4.3% on colorFERET and UTKFace datasets respectively. In cross-validation testing, MCCE-trained models outperform CCE-trained models by 8.8% and 25.16% on the colorFERET and UTKFace datasets respectively. MCCE addresses and mitigates the persistent problem of inadvertent racial bias for facial recognition problems in the domain of computer vision.", "pdf": "/pdf/97e2075b1c04f38335f58ed00b6326a00bcc1c00.pdf", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "gowdra|maximum_categorical_cross_entropy_mcce_a_noiserobust_alternative_loss_function_to_mitigate_racial_bias_in_convolutional_neural_networks_cnns_by_reducing_overfitting", "supplementary_material": "/attachment/336a3e22416872b1679c1e01d45acd7c48a3b0d8.zip", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=Sj8aM-VKRn", "_bibtex": "@misc{\ngowdra2021maximum,\ntitle={Maximum Categorical Cross Entropy ({\\{}MCCE{\\}}): A noise-robust alternative loss function to mitigate racial bias in Convolutional Neural Networks ({\\{}CNN{\\}}s) by reducing overfitting},\nauthor={Nidhi Gowdra and Roopak Sinha and Stephen MacDonell and WeiQi Yan},\nyear={2021},\nurl={https://openreview.net/forum?id=1IBgFQbj7y}\n}"}, "tags": [], "invitation": {"reply": {"forum": "1IBgFQbj7y", "replyto": "1IBgFQbj7y", "readers": {"values": ["everyone"]}, "writers": {"values": ["ICLR.cc/2021/Conference/Paper2504/Ethics_Committee"]}, "signatures": {"values": ["ICLR.cc/2021/Conference/Paper2504/Ethics_Committee"]}, "content": {"decision": {"value-radio": ["Significant concerns (Do not publish)", "Concerns raised (can publish with adjustment)", "No judgement (proceed with normal process)"], "order": 1, "required": true}, "ethics_review": {"order": 2, "value-regex": "[\\S\\s]{1,5000}", "description": "Your review (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}}, "duedate": 1607702400000, "multiReply": false, "signatures": ["ICLR.cc/2021/Conference"], "readers": ["everyone"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Paper2504/Ethics_Committee"], "tcdate": 1607614819518, "tmdate": 1607614819517, "id": "ICLR.cc/2021/Conference/Paper2504/-/Ethics_Meta_Review"}}}, {"id": "DeG6T8ri8tJ", "original": null, "number": 2, "cdate": 1603809148516, "ddate": null, "tcdate": 1603809148516, "tmdate": 1605024196514, "tddate": null, "forum": "1IBgFQbj7y", "replyto": "1IBgFQbj7y", "invitation": "ICLR.cc/2021/Conference/Paper2504/-/Official_Review", "content": {"title": "This paper proposes an extension to the traditional Categorical Cross Entropy Loss known as the Maximum Categorical Cross Entropy (MCCE) Loss. ", "review": "Pros:\n\n1.The authors propose an extension of the CE loss to reduce classification bias that occurs in present methods and datasets. They calculate Maximum Entropy (ME) for images on the entire training dataset and then calculate the reconstruction loss between this and the ME for convolutional kernels during training. Their experiments results show that minimizing this reconstruction loss along with CE speeds up convergence. \n2.The paper is thoroughly written with minor typos and is easy to follow.\n\n\nCons:\n\n1.How does minimizing Maximum Entropy in the form of reconstruction error help to improve the weights learned by the model more suited for unbiased performance ? As shown it might help in faster learning but it\u2019s not very clear how and why it learns good feature maps? \n2.How is the ME entropy calculated? It is good to briefly discuss the method/formula to calculate that. \n3.In Algorithm 1, is there an error in line 5, it should be mu instead of gamma? The 1D interpolation seems like a good way to normalize, but is it the only way or the best way? \nAlso discuss some experimental results with per-class accuracy/precision/recall in case of unbalanced datasets.\n4.It seems like this loss acta as a regularizer on the CE loss only training, but does that also help as a prior knowledge or information to learn better information as discussed in paper several times. Some evaluation on this either comparing feature activations or particularly which category improves more compared to CE might give a better intuition.  \n5.Please discuss some related work  or compare against as baselines with papers also trying to reduce classification bias. \n", "rating": "5: Marginally below acceptance threshold", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["ICLR.cc/2021/Conference/Paper2504/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2504/AnonReviewer1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Maximum Categorical Cross Entropy (MCCE): A noise-robust alternative loss function to mitigate racial bias in Convolutional Neural Networks (CNNs) by reducing overfitting", "authorids": ["~Nidhi_Gowdra1", "rsinha@aut.ac.nz", "stephen.macdonell@aut.ac.nz", "weiqi.yan@aut.ac.nz"], "authors": ["Nidhi Gowdra", "Roopak Sinha", "Stephen MacDonell", "WeiQi Yan"], "keywords": [], "abstract": "Categorical Cross Entropy (CCE) is the most commonly used loss function in deep neural networks such as Convolutional Neural Networks (CNNs) for multi-class classification problems. In spite of the fact that CCE is highly susceptible to noise; CNN models trained without accounting for the unique noise characteristics of the input data, or noise introduced during model training, invariably suffer from overfitting affecting model generalizability. The lack of generalizability becomes especially apparent in the context of ethnicity/racial image classification problems encountered in the domain of computer vision. One such problem is the unintended discriminatory racial bias that CNN models trained using CCE fail to adequately address. In other words, CNN models trained using CCE offer a skewed representation of classification performance favoring lighter skin tones.\n\nIn this paper, we propose and empirically validate a novel noise-robust extension to the existing CCE loss function called Maximum Categorical Cross-Entropy (MCCE), which utilizes CCE loss and a novel reconstruction loss, calculated using the Maximum Entropy (ME) measures of the convolutional kernel weights and input training dataset. We compare the use of MCCE with CCE-trained models on two benchmarking datasets, colorFERET and UTKFace, using a Residual Network (ResNet) CNN architecture. MCCE-trained models reduce overfitting by 5.85% and 4.3% on colorFERET and UTKFace datasets respectively. In cross-validation testing, MCCE-trained models outperform CCE-trained models by 8.8% and 25.16% on the colorFERET and UTKFace datasets respectively. MCCE addresses and mitigates the persistent problem of inadvertent racial bias for facial recognition problems in the domain of computer vision.", "pdf": "/pdf/97e2075b1c04f38335f58ed00b6326a00bcc1c00.pdf", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "gowdra|maximum_categorical_cross_entropy_mcce_a_noiserobust_alternative_loss_function_to_mitigate_racial_bias_in_convolutional_neural_networks_cnns_by_reducing_overfitting", "supplementary_material": "/attachment/336a3e22416872b1679c1e01d45acd7c48a3b0d8.zip", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=Sj8aM-VKRn", "_bibtex": "@misc{\ngowdra2021maximum,\ntitle={Maximum Categorical Cross Entropy ({\\{}MCCE{\\}}): A noise-robust alternative loss function to mitigate racial bias in Convolutional Neural Networks ({\\{}CNN{\\}}s) by reducing overfitting},\nauthor={Nidhi Gowdra and Roopak Sinha and Stephen MacDonell and WeiQi Yan},\nyear={2021},\nurl={https://openreview.net/forum?id=1IBgFQbj7y}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq . ***Please remember to file the Code-of-Ethics report. Once you submitted the review, a link to the report will be visible in the bottom right corner of your review.***", "required": true, "markdown": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}, "forum": "1IBgFQbj7y", "replyto": "1IBgFQbj7y", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"], "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper2504/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1607428800000, "duedate": 1606752000000, "multiReply": false, "readers": ["everyone"], "tcdate": 1602538094903, "tmdate": 1606915799590, "super": "ICLR.cc/2021/Conference/-/Official_Review", "signatures": ["OpenReview.net"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Paper2504/Reviewers", "OpenReview.net/Support"], "id": "ICLR.cc/2021/Conference/Paper2504/-/Official_Review"}}}, {"id": "9IejdRQSqEs", "original": null, "number": 3, "cdate": 1603837727150, "ddate": null, "tcdate": 1603837727150, "tmdate": 1605024196454, "tddate": null, "forum": "1IBgFQbj7y", "replyto": "1IBgFQbj7y", "invitation": "ICLR.cc/2021/Conference/Paper2504/-/Official_Review", "content": {"title": "The current write up is unclear and needs improvement", "review": "Summary: the paper proposes a new loss function, called MCCE to reduce the effect of overfitting to noisy examples. This involves calculating the Maximum Entropy (ME) of the input images as well as the filters (?). Experiments are conducted on standard datasets to validate the claims. \n\nReview: I find the current state of the paper very confusing and unclear. Specifically, it is unclear what the method is trying to optimize (other than adding some form of regularization term based on entropy). The only technical development of the algorithm is given in Alg. 1 and no justification is provided for the design choices (such as: how is mu = ME(w) used in the algorithm? What does convolutional reconstruction loss amount to? What is the purpose of the interpolation? ...). The general discussion up to Section 2 can be shortened significantly and devoted to the development of the method. Overall, the paper is poorly written on the technical side. \n\nAdditionally, it is not clear why the authors attribute the bias in the predictions to noisy examples. For instance, a poorly trained model or a model which overfits to certain examples can produce biased predictions. A number of recent work also aim to reduce the effect of overfitting to noisy examples. For instance, (Amid et al. 2019a) generalizes the GCE loss (Zhang and Sabuncu 2018) by introducing two temperatures t1 and t2 which recovers GCE when t1 = q and t2 = 1. A more recent work, called the bi-tempered loss (Amid et al. 2019b) extends these methods by introducing a proper (unbiased) generalization of the CE loss and is shown to be extremely effective in reducing the effect of noisy examples. Also, (Yang and Guo 2020) proposes peer-loss (which can be combined with CE, bi-tempered, etc. loss) for handling noise. Please consider referencing/comparing to these SOTA methods.\n\nAdditional references:\n\n(Amid et al. 2019a) Amid et al. \"Two-temperature logistic regression based on the Tsallis divergence.\" In The 22nd International Conference on Artificial Intelligence and Statistics, 2019.\n\n(Amid et al. 2019b) Amid et al. \"Robust bi-tempered logistic loss based on Bregman divergences.\" In Advances in Neural Information Processing Systems, 2019.\n\n(Yang and Guo 2020) Yang and Guo. \"Peer Loss Functions: Learning from Noisy Labels without Knowing Noise Rates.\" In International Conference on Machine Learning, 2020.", "rating": "4: Ok but not good enough - rejection", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}, "signatures": ["ICLR.cc/2021/Conference/Paper2504/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2504/AnonReviewer2"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Maximum Categorical Cross Entropy (MCCE): A noise-robust alternative loss function to mitigate racial bias in Convolutional Neural Networks (CNNs) by reducing overfitting", "authorids": ["~Nidhi_Gowdra1", "rsinha@aut.ac.nz", "stephen.macdonell@aut.ac.nz", "weiqi.yan@aut.ac.nz"], "authors": ["Nidhi Gowdra", "Roopak Sinha", "Stephen MacDonell", "WeiQi Yan"], "keywords": [], "abstract": "Categorical Cross Entropy (CCE) is the most commonly used loss function in deep neural networks such as Convolutional Neural Networks (CNNs) for multi-class classification problems. In spite of the fact that CCE is highly susceptible to noise; CNN models trained without accounting for the unique noise characteristics of the input data, or noise introduced during model training, invariably suffer from overfitting affecting model generalizability. The lack of generalizability becomes especially apparent in the context of ethnicity/racial image classification problems encountered in the domain of computer vision. One such problem is the unintended discriminatory racial bias that CNN models trained using CCE fail to adequately address. In other words, CNN models trained using CCE offer a skewed representation of classification performance favoring lighter skin tones.\n\nIn this paper, we propose and empirically validate a novel noise-robust extension to the existing CCE loss function called Maximum Categorical Cross-Entropy (MCCE), which utilizes CCE loss and a novel reconstruction loss, calculated using the Maximum Entropy (ME) measures of the convolutional kernel weights and input training dataset. We compare the use of MCCE with CCE-trained models on two benchmarking datasets, colorFERET and UTKFace, using a Residual Network (ResNet) CNN architecture. MCCE-trained models reduce overfitting by 5.85% and 4.3% on colorFERET and UTKFace datasets respectively. In cross-validation testing, MCCE-trained models outperform CCE-trained models by 8.8% and 25.16% on the colorFERET and UTKFace datasets respectively. MCCE addresses and mitigates the persistent problem of inadvertent racial bias for facial recognition problems in the domain of computer vision.", "pdf": "/pdf/97e2075b1c04f38335f58ed00b6326a00bcc1c00.pdf", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "gowdra|maximum_categorical_cross_entropy_mcce_a_noiserobust_alternative_loss_function_to_mitigate_racial_bias_in_convolutional_neural_networks_cnns_by_reducing_overfitting", "supplementary_material": "/attachment/336a3e22416872b1679c1e01d45acd7c48a3b0d8.zip", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=Sj8aM-VKRn", "_bibtex": "@misc{\ngowdra2021maximum,\ntitle={Maximum Categorical Cross Entropy ({\\{}MCCE{\\}}): A noise-robust alternative loss function to mitigate racial bias in Convolutional Neural Networks ({\\{}CNN{\\}}s) by reducing overfitting},\nauthor={Nidhi Gowdra and Roopak Sinha and Stephen MacDonell and WeiQi Yan},\nyear={2021},\nurl={https://openreview.net/forum?id=1IBgFQbj7y}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq . ***Please remember to file the Code-of-Ethics report. Once you submitted the review, a link to the report will be visible in the bottom right corner of your review.***", "required": true, "markdown": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}, "forum": "1IBgFQbj7y", "replyto": "1IBgFQbj7y", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"], "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper2504/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1607428800000, "duedate": 1606752000000, "multiReply": false, "readers": ["everyone"], "tcdate": 1602538094903, "tmdate": 1606915799590, "super": "ICLR.cc/2021/Conference/-/Official_Review", "signatures": ["OpenReview.net"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Paper2504/Reviewers", "OpenReview.net/Support"], "id": "ICLR.cc/2021/Conference/Paper2504/-/Official_Review"}}}, {"id": "u6Y-6ZtfR7q", "original": null, "number": 1, "cdate": 1603765723846, "ddate": null, "tcdate": 1603765723846, "tmdate": 1605024196392, "tddate": null, "forum": "1IBgFQbj7y", "replyto": "1IBgFQbj7y", "invitation": "ICLR.cc/2021/Conference/Paper2504/-/Official_Review", "content": {"title": "review for \"Maximum Categorical Cross Entropy (MCCE): A noise-robust alternative loss function to mitigate racial bias in Convolutional Neural Networks (CNNs) by reducing overfitting\"\"", "review": "In this paper, the author studies the bias problem in race classification task with face data. Specifically, it first analyses the influence of kernel regularization and batch normalization to categorical cross-entropy loss and proposes a maximum categorical cross-entropy loss. Experiments on two face datasets colorFERET and UTKFace demonstrate the effectiveness of the proposed method. \n\nFrom the ethical aspect, the topic of this paper is important and interesting. But it seems the proposed loss is not specially designed for the racial bias problem, please consider evaluate the proposed loss on general image classification tasks. There have some losses for imbalanced training can be used in this topic (e.g. Focal loss, GHM-C loss). In this paper, the author only compares their approach with the traditional CCE loss which is not convincing. And also, to show the proposed approach can mitigate the bias problem in the race classification task, the author should show the accuracy for different races rather than an averaged accuracy. Overall, I think this paper\u2019s topic is important but the approach seems not make sense and less relevant to the racial bias problem.\n\nPros.\n1.\tThe bias problem that this paper studied is an important problem for image classification, especially for race classification.\n2.\tThe results in the experiment section could partially demonstrate the effectiveness of the proposed MCCE loss.\n\nCons.\n1.\tThe writing of this paper is bad and hard to follow. The author uses several subsections (Section 2.1~2.3, 3.2) to introduce the cross-entropy loss, kernel regularization, batch normalization, and linear interpolation which are redundant.\n2.\tAlgorithm 1 is not aligned with the paper. The variable \\mu is not used in the algorithm but seems to be very important to the method (see Section 3). \n3.\tAccuracy, the key evaluation metric in the experiment part, cannot fully demonstrate the effectiveness of the proposed method. Please consider adding confusion matrix or per-class accuracy.\n4.\tThe discussion section (Section 5) seems not clear. The figures in that section (ME measures, loss curve, training accuracy) cannot support the conclusions.\n5.\tThere are some formatting problems in the paper (Page 7 Line 1 & 5). The figures in the paper look like screenshots from Excel which are not very clear. Please consider inserting the figures in a vectorized format.\n\nOverall,  I think this paper is far more below the ICLR acceptance bar.\n", "rating": "3: Clear rejection", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["ICLR.cc/2021/Conference/Paper2504/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2504/AnonReviewer3"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Maximum Categorical Cross Entropy (MCCE): A noise-robust alternative loss function to mitigate racial bias in Convolutional Neural Networks (CNNs) by reducing overfitting", "authorids": ["~Nidhi_Gowdra1", "rsinha@aut.ac.nz", "stephen.macdonell@aut.ac.nz", "weiqi.yan@aut.ac.nz"], "authors": ["Nidhi Gowdra", "Roopak Sinha", "Stephen MacDonell", "WeiQi Yan"], "keywords": [], "abstract": "Categorical Cross Entropy (CCE) is the most commonly used loss function in deep neural networks such as Convolutional Neural Networks (CNNs) for multi-class classification problems. In spite of the fact that CCE is highly susceptible to noise; CNN models trained without accounting for the unique noise characteristics of the input data, or noise introduced during model training, invariably suffer from overfitting affecting model generalizability. The lack of generalizability becomes especially apparent in the context of ethnicity/racial image classification problems encountered in the domain of computer vision. One such problem is the unintended discriminatory racial bias that CNN models trained using CCE fail to adequately address. In other words, CNN models trained using CCE offer a skewed representation of classification performance favoring lighter skin tones.\n\nIn this paper, we propose and empirically validate a novel noise-robust extension to the existing CCE loss function called Maximum Categorical Cross-Entropy (MCCE), which utilizes CCE loss and a novel reconstruction loss, calculated using the Maximum Entropy (ME) measures of the convolutional kernel weights and input training dataset. We compare the use of MCCE with CCE-trained models on two benchmarking datasets, colorFERET and UTKFace, using a Residual Network (ResNet) CNN architecture. MCCE-trained models reduce overfitting by 5.85% and 4.3% on colorFERET and UTKFace datasets respectively. In cross-validation testing, MCCE-trained models outperform CCE-trained models by 8.8% and 25.16% on the colorFERET and UTKFace datasets respectively. MCCE addresses and mitigates the persistent problem of inadvertent racial bias for facial recognition problems in the domain of computer vision.", "pdf": "/pdf/97e2075b1c04f38335f58ed00b6326a00bcc1c00.pdf", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "gowdra|maximum_categorical_cross_entropy_mcce_a_noiserobust_alternative_loss_function_to_mitigate_racial_bias_in_convolutional_neural_networks_cnns_by_reducing_overfitting", "supplementary_material": "/attachment/336a3e22416872b1679c1e01d45acd7c48a3b0d8.zip", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=Sj8aM-VKRn", "_bibtex": "@misc{\ngowdra2021maximum,\ntitle={Maximum Categorical Cross Entropy ({\\{}MCCE{\\}}): A noise-robust alternative loss function to mitigate racial bias in Convolutional Neural Networks ({\\{}CNN{\\}}s) by reducing overfitting},\nauthor={Nidhi Gowdra and Roopak Sinha and Stephen MacDonell and WeiQi Yan},\nyear={2021},\nurl={https://openreview.net/forum?id=1IBgFQbj7y}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq . ***Please remember to file the Code-of-Ethics report. Once you submitted the review, a link to the report will be visible in the bottom right corner of your review.***", "required": true, "markdown": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}, "forum": "1IBgFQbj7y", "replyto": "1IBgFQbj7y", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"], "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper2504/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1607428800000, "duedate": 1606752000000, "multiReply": false, "readers": ["everyone"], "tcdate": 1602538094903, "tmdate": 1606915799590, "super": "ICLR.cc/2021/Conference/-/Official_Review", "signatures": ["OpenReview.net"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Paper2504/Reviewers", "OpenReview.net/Support"], "id": "ICLR.cc/2021/Conference/Paper2504/-/Official_Review"}}}, {"id": "3e_OHtMARuz", "original": null, "number": 4, "cdate": 1603941831633, "ddate": null, "tcdate": 1603941831633, "tmdate": 1605024196336, "tddate": null, "forum": "1IBgFQbj7y", "replyto": "1IBgFQbj7y", "invitation": "ICLR.cc/2021/Conference/Paper2504/-/Official_Review", "content": {"title": "an extension to the categorical cross entropy to reduce overfitting", "review": "The paper proposes a new extension to the categorical cross-entropy using maximum entropy (MCCE) loss function to reduce model overfitting. The goal is to stabilize the training with respect to overfitting and generalizability. \nStrengths:\n+The proposed method is simple and elegant. It is theoretically well-founded and easily implemented.\n+The paper provides good initial results, and the experiments are conducted on the various dataset: colorFERET and UTKFace.\n\nWeakness:\n+ The proposed method is not novel and just a combining of maximum entropy with cross-entropy.\n+ The authors claimed to upload the supplementary material, but it's missing.\n+ The authors should describe the detailed CNN models implemented with MCCE. And should report the computation cost for each experiment.\n+  More generalization analysis would be beneficial.", "rating": "5: Marginally below acceptance threshold", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "signatures": ["ICLR.cc/2021/Conference/Paper2504/AnonReviewer4"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2504/AnonReviewer4"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Maximum Categorical Cross Entropy (MCCE): A noise-robust alternative loss function to mitigate racial bias in Convolutional Neural Networks (CNNs) by reducing overfitting", "authorids": ["~Nidhi_Gowdra1", "rsinha@aut.ac.nz", "stephen.macdonell@aut.ac.nz", "weiqi.yan@aut.ac.nz"], "authors": ["Nidhi Gowdra", "Roopak Sinha", "Stephen MacDonell", "WeiQi Yan"], "keywords": [], "abstract": "Categorical Cross Entropy (CCE) is the most commonly used loss function in deep neural networks such as Convolutional Neural Networks (CNNs) for multi-class classification problems. In spite of the fact that CCE is highly susceptible to noise; CNN models trained without accounting for the unique noise characteristics of the input data, or noise introduced during model training, invariably suffer from overfitting affecting model generalizability. The lack of generalizability becomes especially apparent in the context of ethnicity/racial image classification problems encountered in the domain of computer vision. One such problem is the unintended discriminatory racial bias that CNN models trained using CCE fail to adequately address. In other words, CNN models trained using CCE offer a skewed representation of classification performance favoring lighter skin tones.\n\nIn this paper, we propose and empirically validate a novel noise-robust extension to the existing CCE loss function called Maximum Categorical Cross-Entropy (MCCE), which utilizes CCE loss and a novel reconstruction loss, calculated using the Maximum Entropy (ME) measures of the convolutional kernel weights and input training dataset. We compare the use of MCCE with CCE-trained models on two benchmarking datasets, colorFERET and UTKFace, using a Residual Network (ResNet) CNN architecture. MCCE-trained models reduce overfitting by 5.85% and 4.3% on colorFERET and UTKFace datasets respectively. In cross-validation testing, MCCE-trained models outperform CCE-trained models by 8.8% and 25.16% on the colorFERET and UTKFace datasets respectively. MCCE addresses and mitigates the persistent problem of inadvertent racial bias for facial recognition problems in the domain of computer vision.", "pdf": "/pdf/97e2075b1c04f38335f58ed00b6326a00bcc1c00.pdf", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "gowdra|maximum_categorical_cross_entropy_mcce_a_noiserobust_alternative_loss_function_to_mitigate_racial_bias_in_convolutional_neural_networks_cnns_by_reducing_overfitting", "supplementary_material": "/attachment/336a3e22416872b1679c1e01d45acd7c48a3b0d8.zip", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=Sj8aM-VKRn", "_bibtex": "@misc{\ngowdra2021maximum,\ntitle={Maximum Categorical Cross Entropy ({\\{}MCCE{\\}}): A noise-robust alternative loss function to mitigate racial bias in Convolutional Neural Networks ({\\{}CNN{\\}}s) by reducing overfitting},\nauthor={Nidhi Gowdra and Roopak Sinha and Stephen MacDonell and WeiQi Yan},\nyear={2021},\nurl={https://openreview.net/forum?id=1IBgFQbj7y}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq . ***Please remember to file the Code-of-Ethics report. Once you submitted the review, a link to the report will be visible in the bottom right corner of your review.***", "required": true, "markdown": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}, "forum": "1IBgFQbj7y", "replyto": "1IBgFQbj7y", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"], "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper2504/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1607428800000, "duedate": 1606752000000, "multiReply": false, "readers": ["everyone"], "tcdate": 1602538094903, "tmdate": 1606915799590, "super": "ICLR.cc/2021/Conference/-/Official_Review", "signatures": ["OpenReview.net"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Paper2504/Reviewers", "OpenReview.net/Support"], "id": "ICLR.cc/2021/Conference/Paper2504/-/Official_Review"}}}], "count": 7}