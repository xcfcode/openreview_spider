{"notes": [{"id": "om1guSP_ray", "original": "kyj_FXGz2h", "number": 645, "cdate": 1601308076790, "ddate": null, "tcdate": 1601308076790, "tmdate": 1614985624845, "tddate": null, "forum": "om1guSP_ray", "replyto": null, "invitation": "ICLR.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Graph Pooling by Edge Cut", "authorids": ["~Alexis_Galland1", "~marc_lelarge1"], "authors": ["Alexis Galland", "marc lelarge"], "keywords": ["graph", "deep", "learning", "pooling"], "abstract": "Graph neural networks (GNNs) are very efficient at solving several tasks in graphs such as node classification or graph classification. They come from an adaptation of convolutional neural networks on images to graph structured data. These models are very effective at finding patterns in images that can discriminate images from each others. Another aspect leading to their success is their ability to uncover hierarchical structures. This comes from the pooling operation that produces different versions of the input image at different scales. The same way, we want to identify patterns at different scales in graphs in order to improve the classification accuracy. Compared to the case of images, it is not trivial to develop a pooling layer on graphs. This is mainly due to the fact that in graphs nodes are not ordered and have irregular neighborhoods. To aleviate this issue, we propose a pooling layer based on edge cuts in graphs. This pooling layer works by computing edge scores that correspond to the importance of edges in the process of information propagation of the GNN. Moreover, we define a regularization function that aims at producing edge scores that minimize the minCUT problem. Finally, through extensive experiments we show that this architecture can compete with state-of- the-art methods.", "one-sentence_summary": "A pooling layer for graph neural networks based on edge cuts.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "galland|graph_pooling_by_edge_cut", "supplementary_material": "/attachment/a04b8e41b100b1917a74af06167832d554da7bfd.zip", "pdf": "/pdf/d893a32b0837da6ed0d81a5e6b8da9fc042c3486.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=fcCSXbFjZZ", "_bibtex": "@misc{\ngalland2021graph,\ntitle={Graph Pooling by Edge Cut},\nauthor={Alexis Galland and marc lelarge},\nyear={2021},\nurl={https://openreview.net/forum?id=om1guSP_ray}\n}"}, "signatures": ["ICLR.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference"], "details": {"replyCount": 5, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"reply": {"readers": {"values-regex": ".*"}, "writers": {"values": ["ICLR.cc/2021/Conference"]}, "signatures": {"values": ["ICLR.cc/2021/Conference"]}, "content": {"authors": {"values": ["Anonymous"]}, "authorids": {"values-regex": ".*"}, "reviewed_version_(pdf)": {"required": false, "description": "Upload a PDF file that ends with .pdf", "value-regex": ".*"}}}, "signatures": ["ICLR.cc/2021/Conference"], "readers": ["everyone"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["~", "OpenReview.net/Support"], "tcdate": 1601308008205, "tmdate": 1614984599368, "id": "ICLR.cc/2021/Conference/-/Blind_Submission"}}, "tauthor": "OpenReview.net"}, {"id": "izj0ZRIyCDA", "original": null, "number": 1, "cdate": 1610040534884, "ddate": null, "tcdate": 1610040534884, "tmdate": 1610474144803, "tddate": null, "forum": "om1guSP_ray", "replyto": "om1guSP_ray", "invitation": "ICLR.cc/2021/Conference/Paper645/-/Decision", "content": {"title": "Final Decision", "decision": "Reject", "comment": "This paper proposes a graph pooling mechanism based on adaptive edge scores that are then fed into a min-cut procedure. \nReviewers acknowledged that this is an important topic of study, but all agreed that the current manuscript does not provide enough evidence about the significance and novelty of their proposed approach. \nThe AC recommends rejection at this time, and encourages the authors to build from the reviewers feedback to improve upon their current work. "}, "signatures": ["ICLR.cc/2021/Conference/Program_Chairs"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference/Program_Chairs"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Graph Pooling by Edge Cut", "authorids": ["~Alexis_Galland1", "~marc_lelarge1"], "authors": ["Alexis Galland", "marc lelarge"], "keywords": ["graph", "deep", "learning", "pooling"], "abstract": "Graph neural networks (GNNs) are very efficient at solving several tasks in graphs such as node classification or graph classification. They come from an adaptation of convolutional neural networks on images to graph structured data. These models are very effective at finding patterns in images that can discriminate images from each others. Another aspect leading to their success is their ability to uncover hierarchical structures. This comes from the pooling operation that produces different versions of the input image at different scales. The same way, we want to identify patterns at different scales in graphs in order to improve the classification accuracy. Compared to the case of images, it is not trivial to develop a pooling layer on graphs. This is mainly due to the fact that in graphs nodes are not ordered and have irregular neighborhoods. To aleviate this issue, we propose a pooling layer based on edge cuts in graphs. This pooling layer works by computing edge scores that correspond to the importance of edges in the process of information propagation of the GNN. Moreover, we define a regularization function that aims at producing edge scores that minimize the minCUT problem. Finally, through extensive experiments we show that this architecture can compete with state-of- the-art methods.", "one-sentence_summary": "A pooling layer for graph neural networks based on edge cuts.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "galland|graph_pooling_by_edge_cut", "supplementary_material": "/attachment/a04b8e41b100b1917a74af06167832d554da7bfd.zip", "pdf": "/pdf/d893a32b0837da6ed0d81a5e6b8da9fc042c3486.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=fcCSXbFjZZ", "_bibtex": "@misc{\ngalland2021graph,\ntitle={Graph Pooling by Edge Cut},\nauthor={Alexis Galland and marc lelarge},\nyear={2021},\nurl={https://openreview.net/forum?id=om1guSP_ray}\n}"}, "tags": [], "invitation": {"reply": {"forum": "om1guSP_ray", "replyto": "om1guSP_ray", "readers": {"values": ["everyone"]}, "writers": {"values": ["ICLR.cc/2021/Conference/Program_Chairs"]}, "signatures": {"values": ["ICLR.cc/2021/Conference/Program_Chairs"]}, "content": {"title": {"value": "Final Decision"}, "decision": {"value-radio": ["Accept (Oral)", "Accept (Spotlight)", "Accept (Poster)", "Reject"]}, "comment": {"value-regex": "[\\S\\s]{0,50000}", "markdown": true}}}, "multiReply": false, "signatures": ["ICLR.cc/2021/Conference"], "readers": ["everyone"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Program_Chairs"], "tcdate": 1610040534871, "tmdate": 1610474144787, "id": "ICLR.cc/2021/Conference/Paper645/-/Decision"}}}, {"id": "zg4YDOBqtkj", "original": null, "number": 1, "cdate": 1603886861759, "ddate": null, "tcdate": 1603886861759, "tmdate": 1605024639742, "tddate": null, "forum": "om1guSP_ray", "replyto": "om1guSP_ray", "invitation": "ICLR.cc/2021/Conference/Paper645/-/Official_Review", "content": {"title": "Interesting approach for the pooling layer of GNNs. Issues with the theoretical justification and empirical evaluation.", "review": "The paper proposes a novel pooling layer for graph neural networks. Pooling in GNNs amounts to merging nodes that are very similar through the layers. Specifically, the paper proposes to merge nodes whose edges have a high score according to the edge cuts. The edge score in practice is computed in each layer using an attention mechanism on the concatenated representations of the edge\u2019s nodes from that layer. The authors then choose a fixed ratio r of the top edges to keep, in an effort to remove edges of nodes from distant communities. The edge score matrix which is n x n stores all the scores and is truncated based on the aforementioned threshold, renormalized, and used to extract the connected components simply from disconnected areas of the matrix. In the following layer, the clusters form super-nodes and their representations are a weighted combination of each individual node\u2019s representation.\n\nStrong points:\n\n--- The overall idea is very interesting as it is utilizing the minCUT algorithm in the context of GNN, and coarsening could indeed be a promising approach to better GNN\u2019s accuracy.\n\n--- The paper is well-written and the different concepts are clearly presented.\n\nConcerns:\n\n--- There are several concerns, the main being about the novelty of the approach since the minCUT problem has been addressed already in a previous work (as the authors also mention). In this case, the authors should describe in detail how Eq. 6 and the computation of S and C result in minimizing the graph cut to underline the difference from the previous work and show that this work is not derivative.\n\n--- The second problem adheres to the experimental section. The authors utilize very few datasets for evaluation. There is a plethora of graph classification and node semi-supervised learning datasets, ranging from OGB (https://ogb.stanford.edu/) to the Dortmunt repository (https://ls11-www.cs.tu-dortmund.de/staff/morris/graphkerneldatasets).  It is also sensible to test the model in larger networks as the coarsening may be less effective due to giant components and the distribution of edges\n\n--- Moreover, the results do not surpass the benchmarks, even seminal ones like GAT, which calls into question the usefulness of the approach. Is there any justification for that?\n\n--- Finally, there is a hyperparameter r which needs at least a strategy to choose it from and a sensitivity analysis to understand its effect on the final outcome.", "rating": "4: Ok but not good enough - rejection", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["ICLR.cc/2021/Conference/Paper645/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper645/AnonReviewer2"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Graph Pooling by Edge Cut", "authorids": ["~Alexis_Galland1", "~marc_lelarge1"], "authors": ["Alexis Galland", "marc lelarge"], "keywords": ["graph", "deep", "learning", "pooling"], "abstract": "Graph neural networks (GNNs) are very efficient at solving several tasks in graphs such as node classification or graph classification. They come from an adaptation of convolutional neural networks on images to graph structured data. These models are very effective at finding patterns in images that can discriminate images from each others. Another aspect leading to their success is their ability to uncover hierarchical structures. This comes from the pooling operation that produces different versions of the input image at different scales. The same way, we want to identify patterns at different scales in graphs in order to improve the classification accuracy. Compared to the case of images, it is not trivial to develop a pooling layer on graphs. This is mainly due to the fact that in graphs nodes are not ordered and have irregular neighborhoods. To aleviate this issue, we propose a pooling layer based on edge cuts in graphs. This pooling layer works by computing edge scores that correspond to the importance of edges in the process of information propagation of the GNN. Moreover, we define a regularization function that aims at producing edge scores that minimize the minCUT problem. Finally, through extensive experiments we show that this architecture can compete with state-of- the-art methods.", "one-sentence_summary": "A pooling layer for graph neural networks based on edge cuts.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "galland|graph_pooling_by_edge_cut", "supplementary_material": "/attachment/a04b8e41b100b1917a74af06167832d554da7bfd.zip", "pdf": "/pdf/d893a32b0837da6ed0d81a5e6b8da9fc042c3486.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=fcCSXbFjZZ", "_bibtex": "@misc{\ngalland2021graph,\ntitle={Graph Pooling by Edge Cut},\nauthor={Alexis Galland and marc lelarge},\nyear={2021},\nurl={https://openreview.net/forum?id=om1guSP_ray}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq . ***Please remember to file the Code-of-Ethics report. Once you submitted the review, a link to the report will be visible in the bottom right corner of your review.***", "required": true, "markdown": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}, "forum": "om1guSP_ray", "replyto": "om1guSP_ray", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"], "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper645/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1607428800000, "duedate": 1606752000000, "multiReply": false, "readers": ["everyone"], "tcdate": 1602538138461, "tmdate": 1606915809758, "super": "ICLR.cc/2021/Conference/-/Official_Review", "signatures": ["OpenReview.net"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Paper645/Reviewers", "OpenReview.net/Support"], "id": "ICLR.cc/2021/Conference/Paper645/-/Official_Review"}}}, {"id": "K58H8p9iIec", "original": null, "number": 3, "cdate": 1603902238610, "ddate": null, "tcdate": 1603902238610, "tmdate": 1605024639684, "tddate": null, "forum": "om1guSP_ray", "replyto": "om1guSP_ray", "invitation": "ICLR.cc/2021/Conference/Paper645/-/Official_Review", "content": {"title": "Straightforward idea and weak empirical results", "review": "Summary:\n\nThis paper presents a graph pooling operator by first predicting scores on edges, then performing min-cut to separate subgraphs, and finally construct coarsened graphs. Authors perform experiments on several small datasets to verify their claims.\n\nPros:\n\n1, The problem of defining pooling operators on graphs is important. The proposed idea is straightforward and easy to follow.\n\n2, The writing of the paper is smooth.\n\nCons & Questions & Suggestions:\n\n1, The idea is not novel. Normalized cut type of methods for graph coarsening have been investigated by quite a few works, e.g., [2]. The proposed pooling operator is not fully differentiable since the gradient through the min-cut optimization is not exploited. Therefore, it is less appealing compared to methods like diff-pool. Moreover, the empirical performance is only comparable to diff-pool on few datasets. I am further concerned about the efficiency of the proposed method since min-cut on large-scale graphs is slow which would significantly slow down the inference of GNNs. However, this part is not discussed or empirically investigated.\n\n2, The experiment section is not that convincing. First, the performances are worse compared to other baselines. For example, the numbers in Table 1 are worse than g-U-nets consistently (I do not know why authors bold their results which are clearly not the best). Second, authors should include more graph pooling baselines, e.g., the ones with similar min-cut objectives like [2]. At last, it would be great to extensively test the proposed method on a wider range of datasets since the ones used for now are small-scale and many baselines achieve similar performances anyway.\n\n3, I think it is necessary to discuss or at least mention the original GNN paper [1] in the literature review. \n\n[1] Scarselli, F., Gori, M., Tsoi, A.C., Hagenbuchner, M. and Monfardini, G., 2008. The graph neural network model. IEEE Transactions on Neural Networks, 20(1), pp.61-80.\n\n[2] Defferrard, M., Bresson, X. and Vandergheynst, P., 2016. Convolutional neural networks on graphs with fast localized spectral filtering. In NeurIPS.\n\nConclusion: Overall, I do not think the paper is ready for being published.", "rating": "3: Clear rejection", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}, "signatures": ["ICLR.cc/2021/Conference/Paper645/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper645/AnonReviewer1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Graph Pooling by Edge Cut", "authorids": ["~Alexis_Galland1", "~marc_lelarge1"], "authors": ["Alexis Galland", "marc lelarge"], "keywords": ["graph", "deep", "learning", "pooling"], "abstract": "Graph neural networks (GNNs) are very efficient at solving several tasks in graphs such as node classification or graph classification. They come from an adaptation of convolutional neural networks on images to graph structured data. These models are very effective at finding patterns in images that can discriminate images from each others. Another aspect leading to their success is their ability to uncover hierarchical structures. This comes from the pooling operation that produces different versions of the input image at different scales. The same way, we want to identify patterns at different scales in graphs in order to improve the classification accuracy. Compared to the case of images, it is not trivial to develop a pooling layer on graphs. This is mainly due to the fact that in graphs nodes are not ordered and have irregular neighborhoods. To aleviate this issue, we propose a pooling layer based on edge cuts in graphs. This pooling layer works by computing edge scores that correspond to the importance of edges in the process of information propagation of the GNN. Moreover, we define a regularization function that aims at producing edge scores that minimize the minCUT problem. Finally, through extensive experiments we show that this architecture can compete with state-of- the-art methods.", "one-sentence_summary": "A pooling layer for graph neural networks based on edge cuts.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "galland|graph_pooling_by_edge_cut", "supplementary_material": "/attachment/a04b8e41b100b1917a74af06167832d554da7bfd.zip", "pdf": "/pdf/d893a32b0837da6ed0d81a5e6b8da9fc042c3486.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=fcCSXbFjZZ", "_bibtex": "@misc{\ngalland2021graph,\ntitle={Graph Pooling by Edge Cut},\nauthor={Alexis Galland and marc lelarge},\nyear={2021},\nurl={https://openreview.net/forum?id=om1guSP_ray}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq . ***Please remember to file the Code-of-Ethics report. Once you submitted the review, a link to the report will be visible in the bottom right corner of your review.***", "required": true, "markdown": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}, "forum": "om1guSP_ray", "replyto": "om1guSP_ray", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"], "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper645/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1607428800000, "duedate": 1606752000000, "multiReply": false, "readers": ["everyone"], "tcdate": 1602538138461, "tmdate": 1606915809758, "super": "ICLR.cc/2021/Conference/-/Official_Review", "signatures": ["OpenReview.net"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Paper645/Reviewers", "OpenReview.net/Support"], "id": "ICLR.cc/2021/Conference/Paper645/-/Official_Review"}}}, {"id": "M5RLQ1eMDJV", "original": null, "number": 4, "cdate": 1603966984893, "ddate": null, "tcdate": 1603966984893, "tmdate": 1605024639617, "tddate": null, "forum": "om1guSP_ray", "replyto": "om1guSP_ray", "invitation": "ICLR.cc/2021/Conference/Paper645/-/Official_Review", "content": {"title": "Unclear explanations and limited contributions", "review": "This manuscript proposes a new pooling layer in Graph Neural Networks (GNN). By computing certain scores on edges which indicate the importance of edges in the process of information propagation, top r% edges are selected and a pooled graph is constructed by considering the connected components to be super nodes. The authors tried to explain some connection between their pooled graph and the normalized cut problem, which is not clearly stated in the manuscript. Even though the manuscript explores an interesting and timely topic, their approach is not technically appealing and the explanations are not enough to thoroughly understand the authors' ideas. My main concerns and major questions are as follows:\n\n#1. In Section 3.1 (page 4), how $W_{pool}$ and $a$ can be considered as trainable variables and how these variables are actually trained are not clear. \n\n#2. Even though the authors argue that the number of clusters needs not be specified in advance, one should determine $r$ in their method instead.  In the experiments, the authors just tried several values for this $r$ value. There should be some rules to appropriately set this $r$ value. I'm wondering if it is possible to look at the distributions of edge scores and determine an appropriate $r$ value.\n\n#3. The descriptions about the relationship between their clustering approach (i.e., forming super nodes by taking the connected components) described in Section 3.1 and the graph normalized cut problem described in Section 3.2 are not clear. Where and how $L_{reg}$ is used in their proposed method?\n\n#4. Experimental results do not support that the proposed method is better than existing methods. Given this limited empirical contributions, I'm wondering if the proposed method has any theoretical benefits over existing methods.", "rating": "3: Clear rejection", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}, "signatures": ["ICLR.cc/2021/Conference/Paper645/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper645/AnonReviewer3"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Graph Pooling by Edge Cut", "authorids": ["~Alexis_Galland1", "~marc_lelarge1"], "authors": ["Alexis Galland", "marc lelarge"], "keywords": ["graph", "deep", "learning", "pooling"], "abstract": "Graph neural networks (GNNs) are very efficient at solving several tasks in graphs such as node classification or graph classification. They come from an adaptation of convolutional neural networks on images to graph structured data. These models are very effective at finding patterns in images that can discriminate images from each others. Another aspect leading to their success is their ability to uncover hierarchical structures. This comes from the pooling operation that produces different versions of the input image at different scales. The same way, we want to identify patterns at different scales in graphs in order to improve the classification accuracy. Compared to the case of images, it is not trivial to develop a pooling layer on graphs. This is mainly due to the fact that in graphs nodes are not ordered and have irregular neighborhoods. To aleviate this issue, we propose a pooling layer based on edge cuts in graphs. This pooling layer works by computing edge scores that correspond to the importance of edges in the process of information propagation of the GNN. Moreover, we define a regularization function that aims at producing edge scores that minimize the minCUT problem. Finally, through extensive experiments we show that this architecture can compete with state-of- the-art methods.", "one-sentence_summary": "A pooling layer for graph neural networks based on edge cuts.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "galland|graph_pooling_by_edge_cut", "supplementary_material": "/attachment/a04b8e41b100b1917a74af06167832d554da7bfd.zip", "pdf": "/pdf/d893a32b0837da6ed0d81a5e6b8da9fc042c3486.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=fcCSXbFjZZ", "_bibtex": "@misc{\ngalland2021graph,\ntitle={Graph Pooling by Edge Cut},\nauthor={Alexis Galland and marc lelarge},\nyear={2021},\nurl={https://openreview.net/forum?id=om1guSP_ray}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq . ***Please remember to file the Code-of-Ethics report. Once you submitted the review, a link to the report will be visible in the bottom right corner of your review.***", "required": true, "markdown": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}, "forum": "om1guSP_ray", "replyto": "om1guSP_ray", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"], "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper645/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1607428800000, "duedate": 1606752000000, "multiReply": false, "readers": ["everyone"], "tcdate": 1602538138461, "tmdate": 1606915809758, "super": "ICLR.cc/2021/Conference/-/Official_Review", "signatures": ["OpenReview.net"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Paper645/Reviewers", "OpenReview.net/Support"], "id": "ICLR.cc/2021/Conference/Paper645/-/Official_Review"}}}, {"id": "vlqTqWqjcaq", "original": null, "number": 2, "cdate": 1603895696689, "ddate": null, "tcdate": 1603895696689, "tmdate": 1605024639531, "tddate": null, "forum": "om1guSP_ray", "replyto": "om1guSP_ray", "invitation": "ICLR.cc/2021/Conference/Paper645/-/Official_Review", "content": {"title": "The method is novel, but the performance improvement is slight", "review": "Summarization\n\nThe authors propose a novel pooling layer based on edge cuts in graph, where a regularization function is introduced to produce edge scores via minimizing the minCUT problem. Through extensive experiments, the authors have proved the proposed EdgeCut pooling structure can achieve comparable performance in various graph analysis tasks.\n\nStrong points\n\n1) The paper is good writing and easy to understood. As far as I know, the proposed EdgeCut is a novel pooling layer based on edge cutting, which is reasonable and can explore hierarchical graph structures.\n2) The authors have provided code in supplement and the experimental results are easy to follow.\n\nWeak points\n\nThe main weakness could be the model performance and there are not enough experiments to prove the efficiency of the proposed EdgeCut.\n\n1) For graph classification in Table.1, any thought about the reason why the proposed EdgeCut is worse than g-U-Nets.  And there is no detailed experimental analysis in Section 4.1\n\n2) Similar question, for node classification in Table.3, the performance of EdgeCut is still worse than GAT in two of three datasets, and even only obtains a slight improvement compared to the most basic GCN in Table 3. Notably, the performance of EdgeCut without regulazization is even worse than GCN in both Citeseer and Pubmed datasets. The authors should provide more comprehensive experimental analysis and explain the reason why the performance improvement is so slight and even worse than the basic GCN.\n\n3) There are only two quantitative experiments in this paper, additional qualitative experiments like the visualizations of graphs after pooling should also be included to prove the model efficiency, even making use of toy data.\n\nQuestions:\n\nMy questions have been included in Weak points part\n\nAdditional Feedback:\n\n1) Can you provide time complexity comparisons for the proposed EdgeCut and other baselines", "rating": "5: Marginally below acceptance threshold", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "signatures": ["ICLR.cc/2021/Conference/Paper645/AnonReviewer4"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper645/AnonReviewer4"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Graph Pooling by Edge Cut", "authorids": ["~Alexis_Galland1", "~marc_lelarge1"], "authors": ["Alexis Galland", "marc lelarge"], "keywords": ["graph", "deep", "learning", "pooling"], "abstract": "Graph neural networks (GNNs) are very efficient at solving several tasks in graphs such as node classification or graph classification. They come from an adaptation of convolutional neural networks on images to graph structured data. These models are very effective at finding patterns in images that can discriminate images from each others. Another aspect leading to their success is their ability to uncover hierarchical structures. This comes from the pooling operation that produces different versions of the input image at different scales. The same way, we want to identify patterns at different scales in graphs in order to improve the classification accuracy. Compared to the case of images, it is not trivial to develop a pooling layer on graphs. This is mainly due to the fact that in graphs nodes are not ordered and have irregular neighborhoods. To aleviate this issue, we propose a pooling layer based on edge cuts in graphs. This pooling layer works by computing edge scores that correspond to the importance of edges in the process of information propagation of the GNN. Moreover, we define a regularization function that aims at producing edge scores that minimize the minCUT problem. Finally, through extensive experiments we show that this architecture can compete with state-of- the-art methods.", "one-sentence_summary": "A pooling layer for graph neural networks based on edge cuts.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "galland|graph_pooling_by_edge_cut", "supplementary_material": "/attachment/a04b8e41b100b1917a74af06167832d554da7bfd.zip", "pdf": "/pdf/d893a32b0837da6ed0d81a5e6b8da9fc042c3486.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=fcCSXbFjZZ", "_bibtex": "@misc{\ngalland2021graph,\ntitle={Graph Pooling by Edge Cut},\nauthor={Alexis Galland and marc lelarge},\nyear={2021},\nurl={https://openreview.net/forum?id=om1guSP_ray}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq . ***Please remember to file the Code-of-Ethics report. Once you submitted the review, a link to the report will be visible in the bottom right corner of your review.***", "required": true, "markdown": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}, "forum": "om1guSP_ray", "replyto": "om1guSP_ray", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"], "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper645/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1607428800000, "duedate": 1606752000000, "multiReply": false, "readers": ["everyone"], "tcdate": 1602538138461, "tmdate": 1606915809758, "super": "ICLR.cc/2021/Conference/-/Official_Review", "signatures": ["OpenReview.net"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Paper645/Reviewers", "OpenReview.net/Support"], "id": "ICLR.cc/2021/Conference/Paper645/-/Official_Review"}}}], "count": 6}