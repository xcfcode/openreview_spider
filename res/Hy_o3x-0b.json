{"notes": [{"tddate": null, "ddate": null, "tmdate": 1518730170827, "tcdate": 1509129375742, "number": 628, "cdate": 1518730170815, "id": "Hy_o3x-0b", "invitation": "ICLR.cc/2018/Conference/-/Blind_Submission", "forum": "Hy_o3x-0b", "original": "rJwjnx-C-", "signatures": ["ICLR.cc/2018/Conference"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Conference"], "content": {"title": "Feature Map Variational Auto-Encoders", "abstract": "There have been multiple attempts with variational auto-encoders (VAE) to learn powerful global representations of complex data using a combination of latent stochastic variables and an autoregressive model over the dimensions of the data. However, for the most challenging natural image tasks the purely autoregressive model with stochastic variables still outperform the combined stochastic autoregressive models. In this paper, we present simple additions to the VAE framework that generalize to natural images by embedding spatial information in the stochastic layers. We significantly improve the state-of-the-art results on MNIST, OMNIGLOT, CIFAR10 and ImageNet when the feature map parameterization of the stochastic variables are combined with the autoregressive PixelCNN approach. Interestingly, we also observe close to state-of-the-art results without the autoregressive part. This opens the possibility for high quality image generation with only one forward-pass.\n", "pdf": "/pdf/e6a071da6490a0996d08f3ddbc463bea39e1f913.pdf", "TL;DR": "We present a generative model that proves state-of-the-art results on gray-scale and natural images.", "paperhash": "maal\u00f8e|feature_map_variational_autoencoders", "_bibtex": "@misc{\nmaal\u00f8e2018feature,\ntitle={Feature Map Variational Auto-Encoders},\nauthor={Lars Maal\u00f8e and Ole Winther},\nyear={2018},\nurl={https://openreview.net/forum?id=Hy_o3x-0b},\n}", "keywords": ["deep learning", "representation learning", "variational auto-encoders", "variational inference", "generative models"], "authors": ["Lars Maal\u00f8e", "Ole Winther"], "authorids": ["larsma@dtu.dk", "olwi@dtu.dk"]}, "nonreaders": [], "details": {"replyCount": 23, "writable": false, "overwriting": [], "revisions": false, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "tmdate": 1506717071958, "id": "ICLR.cc/2018/Conference/-/Blind_Submission", "writers": ["ICLR.cc/2018/Conference"], "signatures": ["ICLR.cc/2018/Conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2018/Conference"], "reply": {"forum": null, "replyto": null, "writers": {"values": ["ICLR.cc/2018/Conference"]}, "signatures": {"description": "How your identity will be displayed with the above content.", "values": ["ICLR.cc/2018/Conference"]}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"authors": {"required": false, "order": 1, "values-regex": ".*", "description": "Comma separated list of author names, as they appear in the paper."}, "authorids": {"required": false, "order": 2, "values-regex": ".*", "description": "Comma separated list of author email addresses, in the same order as above."}}}, "nonreaders": [], "noninvitees": [], "cdate": 1506717071958}}, "tauthor": "ICLR.cc/2018/Conference"}, {"tddate": null, "ddate": null, "original": null, "tmdate": 1517260088250, "tcdate": 1517249754701, "number": 476, "cdate": 1517249754685, "id": "HkmySJprf", "invitation": "ICLR.cc/2018/Conference/-/Acceptance_Decision", "forum": "Hy_o3x-0b", "replyto": "Hy_o3x-0b", "signatures": ["ICLR.cc/2018/Conference/Program_Chairs"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Conference/Program_Chairs"], "content": {"decision": "Reject", "title": "ICLR 2018 Conference Acceptance Decision", "comment": "The paper proposes a VAE variant by embedding spatial information with multiple layers of latent variables. Although the paper reports state-of-the-art results on multiple datasets, some results may be due to a bug. This has been discussed, and the author acknowledges the bug. We hope the problem can be fixed, and the paper reconsidered at another venue.\n"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Feature Map Variational Auto-Encoders", "abstract": "There have been multiple attempts with variational auto-encoders (VAE) to learn powerful global representations of complex data using a combination of latent stochastic variables and an autoregressive model over the dimensions of the data. However, for the most challenging natural image tasks the purely autoregressive model with stochastic variables still outperform the combined stochastic autoregressive models. In this paper, we present simple additions to the VAE framework that generalize to natural images by embedding spatial information in the stochastic layers. We significantly improve the state-of-the-art results on MNIST, OMNIGLOT, CIFAR10 and ImageNet when the feature map parameterization of the stochastic variables are combined with the autoregressive PixelCNN approach. Interestingly, we also observe close to state-of-the-art results without the autoregressive part. This opens the possibility for high quality image generation with only one forward-pass.\n", "pdf": "/pdf/e6a071da6490a0996d08f3ddbc463bea39e1f913.pdf", "TL;DR": "We present a generative model that proves state-of-the-art results on gray-scale and natural images.", "paperhash": "maal\u00f8e|feature_map_variational_autoencoders", "_bibtex": "@misc{\nmaal\u00f8e2018feature,\ntitle={Feature Map Variational Auto-Encoders},\nauthor={Lars Maal\u00f8e and Ole Winther},\nyear={2018},\nurl={https://openreview.net/forum?id=Hy_o3x-0b},\n}", "keywords": ["deep learning", "representation learning", "variational auto-encoders", "variational inference", "generative models"], "authors": ["Lars Maal\u00f8e", "Ole Winther"], "authorids": ["larsma@dtu.dk", "olwi@dtu.dk"]}, "tags": [], "invitation": {"id": "ICLR.cc/2018/Conference/-/Acceptance_Decision", "rdate": null, "ddate": null, "expdate": 1541175629000, "duedate": null, "tmdate": 1541177635767, "tddate": null, "super": null, "final": null, "reply": {"forum": null, "replyto": null, "invitation": "ICLR.cc/2018/Conference/-/Blind_Submission", "writers": {"values": ["ICLR.cc/2018/Conference/Program_Chairs"]}, "signatures": {"description": "How your identity will be displayed with the above content.", "values": ["ICLR.cc/2018/Conference/Program_Chairs"]}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["ICLR.cc/2018/Conference/Program_Chairs", "everyone"]}, "content": {"title": {"required": true, "order": 1, "value": "ICLR 2018 Conference Acceptance Decision"}, "comment": {"required": false, "order": 3, "description": "(optional) Comment on this decision.", "value-regex": "[\\S\\s]{0,5000}"}, "decision": {"required": true, "order": 2, "value-dropdown": ["Accept (Oral)", "Accept (Poster)", "Reject", "Invite to Workshop Track"]}}}, "signatures": ["ICLR.cc/2018/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": [], "noninvitees": [], "writers": ["ICLR.cc/2018/Conference"], "multiReply": null, "taskCompletionCount": null, "transform": null, "cdate": 1541177635767}}}, {"tddate": null, "ddate": null, "original": null, "tmdate": 1515642482311, "tcdate": 1511642321027, "number": 1, "cdate": 1511642321027, "id": "HkYC48PxG", "invitation": "ICLR.cc/2018/Conference/-/Paper628/Official_Review", "forum": "Hy_o3x-0b", "replyto": "Hy_o3x-0b", "signatures": ["ICLR.cc/2018/Conference/Paper628/AnonReviewer1"], "readers": ["everyone"], "content": {"title": "Comments on the motivation, originality and experiments", "rating": "5: Marginally below acceptance threshold", "review": "The paper combines several recent advances on generative modelling including a ladder variational posterior and a PixelCNN decoder together with the proposed convolutional stochastic layers to boost the NLL results of the current VAEs. The numbers in the tables are good but I have several comments on the motivation, originality and experiments.\n\nMost parts of the paper provide a detailed review of the literature. However, the resulting model is quite like a combination of the existing advances and the main contribution of the paper, i.e. the convolution stochastic layer, is not well discussed. Why should we introduce the convolution stochastic layers? Could the layers encode the spatial information better than a deterministic convolutional layer with the same architecture? What's the exact challenge of training VAEs addressed by the convolution stochastic layer? Please strengthen the motivation and originality of the paper.\n\nThough the results are good, I still wonder what is the exact contribution of the convolutional stochastic layers to the NLL results?  Can the authors provide some results without the ladder variational posterior and the PixelCNN decoder on both the gray-scaled and the natural images?\n\nAccording to the experimental setting in the Section 3 (Page 5 Paragraph 2), \"In case of gray-scaled images the stochastic latent layers are dense with sizes 64, 32, 16, 8, 4 (equivalent to S\u00f8nderby et al. (2016)) and for the natural images they are spatial (cf. Table 1). There was no significant difference when using feature maps (as compared to dense layers) for modelling gray-scaled images.\" there is no stochastic convolutional layer.  Then is there anything new in FAME on the gray images? Furthermore, how could FAME advance the previous state-of-the-art? It seems because of other factors instead of the stochastic convolutional layer. \n\nThe results on the natural images are not complete. Please present the generation results on the ImageNet dataset and the reconstruction results on both the CIFAR10 and ImageNet datasets. The quality of the samples on the CIFAR10 dataset seems not competitive to the baseline papers listed in the table. Though the visual quality does not necessarily agree with the NLL results but such large gap is still strange. Besides, why FAME can obtain both good NLL and generation results on the MNIST and OMNIGLOT datasets when there is no stochastic convolutional layer? Meanwhile, why FAME cannot obtain good generation results on the CIFAR10 dataset? Is it because there is a lot randomness in the stochastic convolutional layer? It is better to provide further analysis and it is not safe to say that the stochastic convolutional layer helps learn better latent representations based on only the NNL results.\n\nMinor things:\n\nPlease rewrite the sentence \"When performing reconstructions during training ... while also using the stochastic latent variables z = z 1 , ..., z L.\" in the caption of Figure 1.", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "writers": [], "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Feature Map Variational Auto-Encoders", "abstract": "There have been multiple attempts with variational auto-encoders (VAE) to learn powerful global representations of complex data using a combination of latent stochastic variables and an autoregressive model over the dimensions of the data. However, for the most challenging natural image tasks the purely autoregressive model with stochastic variables still outperform the combined stochastic autoregressive models. In this paper, we present simple additions to the VAE framework that generalize to natural images by embedding spatial information in the stochastic layers. We significantly improve the state-of-the-art results on MNIST, OMNIGLOT, CIFAR10 and ImageNet when the feature map parameterization of the stochastic variables are combined with the autoregressive PixelCNN approach. Interestingly, we also observe close to state-of-the-art results without the autoregressive part. This opens the possibility for high quality image generation with only one forward-pass.\n", "pdf": "/pdf/e6a071da6490a0996d08f3ddbc463bea39e1f913.pdf", "TL;DR": "We present a generative model that proves state-of-the-art results on gray-scale and natural images.", "paperhash": "maal\u00f8e|feature_map_variational_autoencoders", "_bibtex": "@misc{\nmaal\u00f8e2018feature,\ntitle={Feature Map Variational Auto-Encoders},\nauthor={Lars Maal\u00f8e and Ole Winther},\nyear={2018},\nurl={https://openreview.net/forum?id=Hy_o3x-0b},\n}", "keywords": ["deep learning", "representation learning", "variational auto-encoders", "variational inference", "generative models"], "authors": ["Lars Maal\u00f8e", "Ole Winther"], "authorids": ["larsma@dtu.dk", "olwi@dtu.dk"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1511845199000, "tmdate": 1515642482214, "id": "ICLR.cc/2018/Conference/-/Paper628/Official_Review", "writers": ["ICLR.cc/2018/Conference"], "signatures": ["ICLR.cc/2018/Conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2018/Conference/Paper628/Reviewers"], "noninvitees": ["ICLR.cc/2018/Conference/Paper628/AnonReviewer1", "ICLR.cc/2018/Conference/Paper628/AnonReviewer3", "ICLR.cc/2018/Conference/Paper628/AnonReviewer2"], "reply": {"forum": "Hy_o3x-0b", "replyto": "Hy_o3x-0b", "writers": {"values": []}, "signatures": {"values-regex": "ICLR.cc/2018/Conference/Paper628/AnonReviewer[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"required": true, "order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"required": true, "order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "value-regex": "[\\S\\s]{1,200000}"}, "rating": {"required": true, "order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"required": true, "order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1519621199000, "cdate": 1515642482214}}}, {"tddate": null, "ddate": null, "original": null, "tmdate": 1515642482267, "tcdate": 1511818994719, "number": 2, "cdate": 1511818994719, "id": "SyjePb9gz", "invitation": "ICLR.cc/2018/Conference/-/Paper628/Official_Review", "forum": "Hy_o3x-0b", "replyto": "Hy_o3x-0b", "signatures": ["ICLR.cc/2018/Conference/Paper628/AnonReviewer3"], "readers": ["everyone"], "content": {"title": "limited novelty. possibly incorrect?", "rating": "3: Clear rejection", "review": "The description of the proposed method is very unclear. From the paper it is very difficult to make out exactly what architecture is proposed. I understand that the prior on the z_i in each layer is a pixel-cnn, but what is the posterior? Equations 8 and 9 would suggest it is of the same form (pixel-cnn) but this would be much too slow to sample during training. I'm guessing it is just a factorized Gaussian, with a separate factorized Gaussian pseudo-prior? That is, in figure 1 all solid lines are factorized Gaussians and all dashed lines are pixel-cnns?\n\n* The word \"layers\" is sometimes used to refer to latent variables z, and sometimes to parameterized neural network layers in the encoder and decoder. E.g. \"The top stochastic layer z_L in FAME is a fully-connected dense layer\". No, z_L is a vector of latent variables. Are you saying the encoder produces it using a fully-connected layer?\n* Section 2.2 starts talking about \"deterministic layers h\". Are these part of the encoder or decoder? What is meant by \"number of layers connecting the stochastic latent variables\"?\n* Section 2.3: What is meant by \"reconstruction data\"?\n\nIf my understanding of the method is correct, the novelty is limited. Autoregressive priors were used previously in e.g. the Lossy VAE by Chen et al. and IAF-VAE by Kingma et al. The reported likelihood results are very impressive though, and would be reason for acceptance if correct. However, the quality of the sampled images shown for CIFAR-10 doesn't match the reported likelihood. There are multiple possible reasons for this, but after skimming the code I believe it might be due to a faulty implementation of the variational lower bound. Instead of calculating all quantities in the log domain, the code takes explicit logs and exponents and stabilizes them by adding small quantities \"eps\": this is not guaranteed to give the right result. Please fix this and re-run your experiments. (I.e. in _loss.py don't use x/(exp(y)+eps) but instead use x*exp(-y). Don't use log(var+eps) with var=softplus(x), but instead use var=softplus(x)+eps or parameterize the variance directly in the log domain).", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "writers": [], "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Feature Map Variational Auto-Encoders", "abstract": "There have been multiple attempts with variational auto-encoders (VAE) to learn powerful global representations of complex data using a combination of latent stochastic variables and an autoregressive model over the dimensions of the data. However, for the most challenging natural image tasks the purely autoregressive model with stochastic variables still outperform the combined stochastic autoregressive models. In this paper, we present simple additions to the VAE framework that generalize to natural images by embedding spatial information in the stochastic layers. We significantly improve the state-of-the-art results on MNIST, OMNIGLOT, CIFAR10 and ImageNet when the feature map parameterization of the stochastic variables are combined with the autoregressive PixelCNN approach. Interestingly, we also observe close to state-of-the-art results without the autoregressive part. This opens the possibility for high quality image generation with only one forward-pass.\n", "pdf": "/pdf/e6a071da6490a0996d08f3ddbc463bea39e1f913.pdf", "TL;DR": "We present a generative model that proves state-of-the-art results on gray-scale and natural images.", "paperhash": "maal\u00f8e|feature_map_variational_autoencoders", "_bibtex": "@misc{\nmaal\u00f8e2018feature,\ntitle={Feature Map Variational Auto-Encoders},\nauthor={Lars Maal\u00f8e and Ole Winther},\nyear={2018},\nurl={https://openreview.net/forum?id=Hy_o3x-0b},\n}", "keywords": ["deep learning", "representation learning", "variational auto-encoders", "variational inference", "generative models"], "authors": ["Lars Maal\u00f8e", "Ole Winther"], "authorids": ["larsma@dtu.dk", "olwi@dtu.dk"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1511845199000, "tmdate": 1515642482214, "id": "ICLR.cc/2018/Conference/-/Paper628/Official_Review", "writers": ["ICLR.cc/2018/Conference"], "signatures": ["ICLR.cc/2018/Conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2018/Conference/Paper628/Reviewers"], "noninvitees": ["ICLR.cc/2018/Conference/Paper628/AnonReviewer1", "ICLR.cc/2018/Conference/Paper628/AnonReviewer3", "ICLR.cc/2018/Conference/Paper628/AnonReviewer2"], "reply": {"forum": "Hy_o3x-0b", "replyto": "Hy_o3x-0b", "writers": {"values": []}, "signatures": {"values-regex": "ICLR.cc/2018/Conference/Paper628/AnonReviewer[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"required": true, "order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"required": true, "order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "value-regex": "[\\S\\s]{1,200000}"}, "rating": {"required": true, "order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"required": true, "order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1519621199000, "cdate": 1515642482214}}}, {"tddate": null, "ddate": null, "original": null, "tmdate": 1515642482229, "tcdate": 1511820966573, "number": 3, "cdate": 1511820966573, "id": "Hkk3C-5lM", "invitation": "ICLR.cc/2018/Conference/-/Paper628/Official_Review", "forum": "Hy_o3x-0b", "replyto": "Hy_o3x-0b", "signatures": ["ICLR.cc/2018/Conference/Paper628/AnonReviewer2"], "readers": ["everyone"], "content": {"title": "Review: Impressive experimental results but low novelty", "rating": "6: Marginally above acceptance threshold", "review": "Update:  In light of Yoon Kim's retraction of replication, I've downgraded my score until the authors provide further validation (i.e. CIFAR and ImageNet samples).\n\nSummary\n\nThis paper proposes VAE modifications that allow for the use multiple layers of latent variables.  The modifications are: (1) a shared en/decoder parametrization as used in the Ladder VAE [1], (2) the latent variable parameters are functions of a CNN, and (3) use of a PixelCNN decoder [2] that is fed both the last layer of stochastic variables and the input image, as done in [3].  Negative log likelihood (NLL) results on CIFAR 10, binarized MNIST (dynamic and static), OMNIGLOT, and ImageNet (32x32) are reported.  Samples are shown for CIFAR 10, MNIST, and OMNIGLOT.        \n\n\nEvaluation\n\nPros:  The paper\u2019s primary contribution is experimental: SOTA results are achieved for nearly every benchmark image dataset (the exception being statically binarized MNIST, which is only .28 nats off).  This experimental feat is quite impressive, and moreover, in the comments on OpenReview, Yoon Kim claims to have replicated the CIFAR result.  I commend the authors for making their code available already via DropBox.  Lastly, I like how the authors isolated the effect of the concatenation via the \u2018FAME No Concatenation\u2019 results.                 \n\nCons:  The paper provides little novelty in terms of model or algorithmic design, as using a CNN to parametrize the latent variables is the only model detail unique to this paper.  In terms of experiments, the CIFAR samples look a bit blurry for the reported NLL (as others have mentioned in the OpenReview comments).  I find the authors\u2019 claim that FAME is performing superior global modeling interesting.  Is there a way to support this experimentally?  Also, I would have liked to see results w/o the CNN parametrization; how important was this choice?  \n\n\nConclusion\n\nWhile the paper's conceptual novelty is low, the engineering and experimental work required (to combine the three ideas discussed in the summary and evaluate the model on every benchmark image dataset) is commendable.  I recommend the paper\u2019s acceptance for this reason.\n\n\n[1]  C. Sonderby et al., \u201cLadder Variational Autoencoders.\u201d  NIPS 2016.\n[2]  A. van den Oord et al., \u201cConditional Image Generation with PixelCNN Decoders.\u201d ArXiv 2016.\n[3]  I. Gulrajani et al., \u201cPixelVAE: A Latent Variable Model for Natural Images.\u201d  ICLR 2017.\n", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "writers": [], "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": true, "forumContent": {"title": "Feature Map Variational Auto-Encoders", "abstract": "There have been multiple attempts with variational auto-encoders (VAE) to learn powerful global representations of complex data using a combination of latent stochastic variables and an autoregressive model over the dimensions of the data. However, for the most challenging natural image tasks the purely autoregressive model with stochastic variables still outperform the combined stochastic autoregressive models. In this paper, we present simple additions to the VAE framework that generalize to natural images by embedding spatial information in the stochastic layers. We significantly improve the state-of-the-art results on MNIST, OMNIGLOT, CIFAR10 and ImageNet when the feature map parameterization of the stochastic variables are combined with the autoregressive PixelCNN approach. Interestingly, we also observe close to state-of-the-art results without the autoregressive part. This opens the possibility for high quality image generation with only one forward-pass.\n", "pdf": "/pdf/e6a071da6490a0996d08f3ddbc463bea39e1f913.pdf", "TL;DR": "We present a generative model that proves state-of-the-art results on gray-scale and natural images.", "paperhash": "maal\u00f8e|feature_map_variational_autoencoders", "_bibtex": "@misc{\nmaal\u00f8e2018feature,\ntitle={Feature Map Variational Auto-Encoders},\nauthor={Lars Maal\u00f8e and Ole Winther},\nyear={2018},\nurl={https://openreview.net/forum?id=Hy_o3x-0b},\n}", "keywords": ["deep learning", "representation learning", "variational auto-encoders", "variational inference", "generative models"], "authors": ["Lars Maal\u00f8e", "Ole Winther"], "authorids": ["larsma@dtu.dk", "olwi@dtu.dk"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1511845199000, "tmdate": 1515642482214, "id": "ICLR.cc/2018/Conference/-/Paper628/Official_Review", "writers": ["ICLR.cc/2018/Conference"], "signatures": ["ICLR.cc/2018/Conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2018/Conference/Paper628/Reviewers"], "noninvitees": ["ICLR.cc/2018/Conference/Paper628/AnonReviewer1", "ICLR.cc/2018/Conference/Paper628/AnonReviewer3", "ICLR.cc/2018/Conference/Paper628/AnonReviewer2"], "reply": {"forum": "Hy_o3x-0b", "replyto": "Hy_o3x-0b", "writers": {"values": []}, "signatures": {"values-regex": "ICLR.cc/2018/Conference/Paper628/AnonReviewer[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"required": true, "order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"required": true, "order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "value-regex": "[\\S\\s]{1,200000}"}, "rating": {"required": true, "order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"required": true, "order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1519621199000, "cdate": 1515642482214}}}, {"tddate": null, "ddate": null, "tmdate": 1515165672892, "tcdate": 1515165672892, "number": 9, "cdate": 1515165672892, "id": "ByZxuMamf", "invitation": "ICLR.cc/2018/Conference/-/Paper628/Official_Comment", "forum": "Hy_o3x-0b", "replyto": "Hy_o3x-0b", "signatures": ["ICLR.cc/2018/Conference/Paper628/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Conference/Paper628/Authors"], "content": {"title": "Authors final comments", "comment": "Dear reviewers,\n\nThank you for all of your useful feedback. We have used this rebuttal period to investigate our results and have found that\n\n1) the grayscale MNIST and OMNIGLOT result hold and\n2) we too had a bug in the AR model part for the natural color images.\n \nWe have corrected the bug by now and the samples look much better. However, we won\u2019t be able to update the results in due time, which is why we completely understand you not accepting the paper in its current format. We plan to submit to ICML and apologize for the inconvenience."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Feature Map Variational Auto-Encoders", "abstract": "There have been multiple attempts with variational auto-encoders (VAE) to learn powerful global representations of complex data using a combination of latent stochastic variables and an autoregressive model over the dimensions of the data. However, for the most challenging natural image tasks the purely autoregressive model with stochastic variables still outperform the combined stochastic autoregressive models. In this paper, we present simple additions to the VAE framework that generalize to natural images by embedding spatial information in the stochastic layers. We significantly improve the state-of-the-art results on MNIST, OMNIGLOT, CIFAR10 and ImageNet when the feature map parameterization of the stochastic variables are combined with the autoregressive PixelCNN approach. Interestingly, we also observe close to state-of-the-art results without the autoregressive part. This opens the possibility for high quality image generation with only one forward-pass.\n", "pdf": "/pdf/e6a071da6490a0996d08f3ddbc463bea39e1f913.pdf", "TL;DR": "We present a generative model that proves state-of-the-art results on gray-scale and natural images.", "paperhash": "maal\u00f8e|feature_map_variational_autoencoders", "_bibtex": "@misc{\nmaal\u00f8e2018feature,\ntitle={Feature Map Variational Auto-Encoders},\nauthor={Lars Maal\u00f8e and Ole Winther},\nyear={2018},\nurl={https://openreview.net/forum?id=Hy_o3x-0b},\n}", "keywords": ["deep learning", "representation learning", "variational auto-encoders", "variational inference", "generative models"], "authors": ["Lars Maal\u00f8e", "Ole Winther"], "authorids": ["larsma@dtu.dk", "olwi@dtu.dk"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "tmdate": 1516825730387, "id": "ICLR.cc/2018/Conference/-/Paper628/Official_Comment", "writers": ["ICLR.cc/2018/Conference"], "signatures": ["ICLR.cc/2018/Conference"], "readers": ["everyone"], "reply": {"replyto": null, "forum": "Hy_o3x-0b", "writers": {"values-regex": "ICLR.cc/2018/Conference/Paper628/AnonReviewer[0-9]+|ICLR.cc/2018/Conference/Paper628/Authors|ICLR.cc/2018/Conference/Paper628/Area_Chair|ICLR.cc/2018/Conference/Program_Chairs"}, "signatures": {"values-regex": "ICLR.cc/2018/Conference/Paper628/AnonReviewer[0-9]+|ICLR.cc/2018/Conference/Paper628/Authors|ICLR.cc/2018/Conference/Paper628/Area_Chair|ICLR.cc/2018/Conference/Program_Chairs", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2018/Conference/Paper628/Authors_and_Higher", "ICLR.cc/2018/Conference/Paper628/Reviewers_and_Higher", "ICLR.cc/2018/Conference/Paper628/Area_Chairs_and_Higher", "ICLR.cc/2018/Conference/Program_Chairs"]}, "content": {"title": {"required": true, "order": 0, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"required": true, "order": 1, "description": "Your comment or reply (max 5000 characters).", "value-regex": "[\\S\\s]{1,5000}"}}}, "nonreaders": [], "noninvitees": [], "invitees": ["ICLR.cc/2018/Conference/Paper628/Reviewers", "ICLR.cc/2018/Conference/Paper628/Authors", "ICLR.cc/2018/Conference/Paper628/Area_Chair", "ICLR.cc/2018/Conference/Program_Chairs"], "cdate": 1516825730387}}}, {"tddate": null, "ddate": null, "tmdate": 1513359773070, "tcdate": 1513359726312, "number": 10, "cdate": 1513359726312, "id": "ryUdttWzG", "invitation": "ICLR.cc/2018/Conference/-/Paper628/Public_Comment", "forum": "Hy_o3x-0b", "replyto": "BJZQRBZMf", "signatures": ["~Yoon_Kim1"], "readers": ["everyone"], "writers": ["~Yoon_Kim1"], "content": {"title": ".", "comment": "Sure, it's incredibly silly/embarrassing: I didn't realize that unlike MNIST/OMNIGLOT, CIFAR numbers were in bits and not nats!"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Feature Map Variational Auto-Encoders", "abstract": "There have been multiple attempts with variational auto-encoders (VAE) to learn powerful global representations of complex data using a combination of latent stochastic variables and an autoregressive model over the dimensions of the data. However, for the most challenging natural image tasks the purely autoregressive model with stochastic variables still outperform the combined stochastic autoregressive models. In this paper, we present simple additions to the VAE framework that generalize to natural images by embedding spatial information in the stochastic layers. We significantly improve the state-of-the-art results on MNIST, OMNIGLOT, CIFAR10 and ImageNet when the feature map parameterization of the stochastic variables are combined with the autoregressive PixelCNN approach. Interestingly, we also observe close to state-of-the-art results without the autoregressive part. This opens the possibility for high quality image generation with only one forward-pass.\n", "pdf": "/pdf/e6a071da6490a0996d08f3ddbc463bea39e1f913.pdf", "TL;DR": "We present a generative model that proves state-of-the-art results on gray-scale and natural images.", "paperhash": "maal\u00f8e|feature_map_variational_autoencoders", "_bibtex": "@misc{\nmaal\u00f8e2018feature,\ntitle={Feature Map Variational Auto-Encoders},\nauthor={Lars Maal\u00f8e and Ole Winther},\nyear={2018},\nurl={https://openreview.net/forum?id=Hy_o3x-0b},\n}", "keywords": ["deep learning", "representation learning", "variational auto-encoders", "variational inference", "generative models"], "authors": ["Lars Maal\u00f8e", "Ole Winther"], "authorids": ["larsma@dtu.dk", "olwi@dtu.dk"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "tmdate": 1512791682816, "id": "ICLR.cc/2018/Conference/-/Paper628/Public_Comment", "writers": ["ICLR.cc/2018/Conference"], "signatures": ["ICLR.cc/2018/Conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"replyto": null, "forum": "Hy_o3x-0b", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2018/Conference/Authors_and_Higher", "ICLR.cc/2018/Conference/Reviewers_and_Higher", "ICLR.cc/2018/Conference/Area_Chairs_and_Higher", "ICLR.cc/2018/Conference/Program_Chairs"]}, "content": {"title": {"required": true, "order": 0, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"required": true, "order": 1, "description": "Your comment or reply (max 5000 characters).", "value-regex": "[\\S\\s]{1,5000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2018/Conference/Paper628/Authors", "ICLR.cc/2018/Conference/Paper628/Reviewers", "ICLR.cc/2018/Conference/Paper628/Area_Chair"], "cdate": 1512791682816}}}, {"tddate": null, "ddate": null, "tmdate": 1513344537081, "tcdate": 1513344537081, "number": 9, "cdate": 1513344537081, "id": "BJZQRBZMf", "invitation": "ICLR.cc/2018/Conference/-/Paper628/Public_Comment", "forum": "Hy_o3x-0b", "replyto": "SyaUOmUZf", "signatures": ["(anonymous)"], "readers": ["everyone"], "writers": ["(anonymous)"], "content": {"title": "The nature of the bug", "comment": "Thank you for the update. Could you say what the bug was, even if it was silly? This would allow other researchers (including the authors of the paper) to make sure that they don't have this bug in their code as well."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Feature Map Variational Auto-Encoders", "abstract": "There have been multiple attempts with variational auto-encoders (VAE) to learn powerful global representations of complex data using a combination of latent stochastic variables and an autoregressive model over the dimensions of the data. However, for the most challenging natural image tasks the purely autoregressive model with stochastic variables still outperform the combined stochastic autoregressive models. In this paper, we present simple additions to the VAE framework that generalize to natural images by embedding spatial information in the stochastic layers. We significantly improve the state-of-the-art results on MNIST, OMNIGLOT, CIFAR10 and ImageNet when the feature map parameterization of the stochastic variables are combined with the autoregressive PixelCNN approach. Interestingly, we also observe close to state-of-the-art results without the autoregressive part. This opens the possibility for high quality image generation with only one forward-pass.\n", "pdf": "/pdf/e6a071da6490a0996d08f3ddbc463bea39e1f913.pdf", "TL;DR": "We present a generative model that proves state-of-the-art results on gray-scale and natural images.", "paperhash": "maal\u00f8e|feature_map_variational_autoencoders", "_bibtex": "@misc{\nmaal\u00f8e2018feature,\ntitle={Feature Map Variational Auto-Encoders},\nauthor={Lars Maal\u00f8e and Ole Winther},\nyear={2018},\nurl={https://openreview.net/forum?id=Hy_o3x-0b},\n}", "keywords": ["deep learning", "representation learning", "variational auto-encoders", "variational inference", "generative models"], "authors": ["Lars Maal\u00f8e", "Ole Winther"], "authorids": ["larsma@dtu.dk", "olwi@dtu.dk"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "tmdate": 1512791682816, "id": "ICLR.cc/2018/Conference/-/Paper628/Public_Comment", "writers": ["ICLR.cc/2018/Conference"], "signatures": ["ICLR.cc/2018/Conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"replyto": null, "forum": "Hy_o3x-0b", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2018/Conference/Authors_and_Higher", "ICLR.cc/2018/Conference/Reviewers_and_Higher", "ICLR.cc/2018/Conference/Area_Chairs_and_Higher", "ICLR.cc/2018/Conference/Program_Chairs"]}, "content": {"title": {"required": true, "order": 0, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"required": true, "order": 1, "description": "Your comment or reply (max 5000 characters).", "value-regex": "[\\S\\s]{1,5000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2018/Conference/Paper628/Authors", "ICLR.cc/2018/Conference/Paper628/Reviewers", "ICLR.cc/2018/Conference/Paper628/Area_Chair"], "cdate": 1512791682816}}}, {"tddate": null, "ddate": null, "tmdate": 1513344221662, "tcdate": 1513344221662, "number": 8, "cdate": 1513344221662, "id": "BkUk6H-zz", "invitation": "ICLR.cc/2018/Conference/-/Paper628/Public_Comment", "forum": "Hy_o3x-0b", "replyto": "Hy_o3x-0b", "signatures": ["(anonymous)"], "readers": ["everyone"], "writers": ["(anonymous)"], "content": {"title": "Correctness and samples", "comment": "In light of the independent replication claim being retracted below, could the authors comment whether they still believe that the results reported in the paper are correct? If so, could you post some CIFAR10 and ImageNet samples obtained after fixing the sampling bug mentioned below?"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Feature Map Variational Auto-Encoders", "abstract": "There have been multiple attempts with variational auto-encoders (VAE) to learn powerful global representations of complex data using a combination of latent stochastic variables and an autoregressive model over the dimensions of the data. However, for the most challenging natural image tasks the purely autoregressive model with stochastic variables still outperform the combined stochastic autoregressive models. In this paper, we present simple additions to the VAE framework that generalize to natural images by embedding spatial information in the stochastic layers. We significantly improve the state-of-the-art results on MNIST, OMNIGLOT, CIFAR10 and ImageNet when the feature map parameterization of the stochastic variables are combined with the autoregressive PixelCNN approach. Interestingly, we also observe close to state-of-the-art results without the autoregressive part. This opens the possibility for high quality image generation with only one forward-pass.\n", "pdf": "/pdf/e6a071da6490a0996d08f3ddbc463bea39e1f913.pdf", "TL;DR": "We present a generative model that proves state-of-the-art results on gray-scale and natural images.", "paperhash": "maal\u00f8e|feature_map_variational_autoencoders", "_bibtex": "@misc{\nmaal\u00f8e2018feature,\ntitle={Feature Map Variational Auto-Encoders},\nauthor={Lars Maal\u00f8e and Ole Winther},\nyear={2018},\nurl={https://openreview.net/forum?id=Hy_o3x-0b},\n}", "keywords": ["deep learning", "representation learning", "variational auto-encoders", "variational inference", "generative models"], "authors": ["Lars Maal\u00f8e", "Ole Winther"], "authorids": ["larsma@dtu.dk", "olwi@dtu.dk"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "tmdate": 1512791682816, "id": "ICLR.cc/2018/Conference/-/Paper628/Public_Comment", "writers": ["ICLR.cc/2018/Conference"], "signatures": ["ICLR.cc/2018/Conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"replyto": null, "forum": "Hy_o3x-0b", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2018/Conference/Authors_and_Higher", "ICLR.cc/2018/Conference/Reviewers_and_Higher", "ICLR.cc/2018/Conference/Area_Chairs_and_Higher", "ICLR.cc/2018/Conference/Program_Chairs"]}, "content": {"title": {"required": true, "order": 0, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"required": true, "order": 1, "description": "Your comment or reply (max 5000 characters).", "value-regex": "[\\S\\s]{1,5000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2018/Conference/Paper628/Authors", "ICLR.cc/2018/Conference/Paper628/Reviewers", "ICLR.cc/2018/Conference/Paper628/Area_Chair"], "cdate": 1512791682816}}}, {"tddate": null, "ddate": null, "tmdate": 1512684845353, "tcdate": 1512613974841, "number": 7, "cdate": 1512613974841, "id": "SyaUOmUZf", "invitation": "ICLR.cc/2018/Conference/-/Paper628/Public_Comment", "forum": "Hy_o3x-0b", "replyto": "SyjePb9gz", "signatures": ["~Yoon_Kim1"], "readers": ["everyone"], "writers": ["~Yoon_Kim1"], "content": {"title": ".", "comment": "[EDIT]: I just realized I had a really silly bug in my implementation. Please disregard my previous posts regarding successful replication.\n\nSorry for adding noise to the process!"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Feature Map Variational Auto-Encoders", "abstract": "There have been multiple attempts with variational auto-encoders (VAE) to learn powerful global representations of complex data using a combination of latent stochastic variables and an autoregressive model over the dimensions of the data. However, for the most challenging natural image tasks the purely autoregressive model with stochastic variables still outperform the combined stochastic autoregressive models. In this paper, we present simple additions to the VAE framework that generalize to natural images by embedding spatial information in the stochastic layers. We significantly improve the state-of-the-art results on MNIST, OMNIGLOT, CIFAR10 and ImageNet when the feature map parameterization of the stochastic variables are combined with the autoregressive PixelCNN approach. Interestingly, we also observe close to state-of-the-art results without the autoregressive part. This opens the possibility for high quality image generation with only one forward-pass.\n", "pdf": "/pdf/e6a071da6490a0996d08f3ddbc463bea39e1f913.pdf", "TL;DR": "We present a generative model that proves state-of-the-art results on gray-scale and natural images.", "paperhash": "maal\u00f8e|feature_map_variational_autoencoders", "_bibtex": "@misc{\nmaal\u00f8e2018feature,\ntitle={Feature Map Variational Auto-Encoders},\nauthor={Lars Maal\u00f8e and Ole Winther},\nyear={2018},\nurl={https://openreview.net/forum?id=Hy_o3x-0b},\n}", "keywords": ["deep learning", "representation learning", "variational auto-encoders", "variational inference", "generative models"], "authors": ["Lars Maal\u00f8e", "Ole Winther"], "authorids": ["larsma@dtu.dk", "olwi@dtu.dk"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "tmdate": 1512791682816, "id": "ICLR.cc/2018/Conference/-/Paper628/Public_Comment", "writers": ["ICLR.cc/2018/Conference"], "signatures": ["ICLR.cc/2018/Conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"replyto": null, "forum": "Hy_o3x-0b", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2018/Conference/Authors_and_Higher", "ICLR.cc/2018/Conference/Reviewers_and_Higher", "ICLR.cc/2018/Conference/Area_Chairs_and_Higher", "ICLR.cc/2018/Conference/Program_Chairs"]}, "content": {"title": {"required": true, "order": 0, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"required": true, "order": 1, "description": "Your comment or reply (max 5000 characters).", "value-regex": "[\\S\\s]{1,5000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2018/Conference/Paper628/Authors", "ICLR.cc/2018/Conference/Paper628/Reviewers", "ICLR.cc/2018/Conference/Paper628/Area_Chair"], "cdate": 1512791682816}}}, {"tddate": null, "ddate": null, "tmdate": 1511798301097, "tcdate": 1511461580223, "number": 8, "cdate": 1511461580223, "id": "rJNRG94lM", "invitation": "ICLR.cc/2018/Conference/-/Paper628/Official_Comment", "forum": "Hy_o3x-0b", "replyto": "SkjKJ5Nlf", "signatures": ["ICLR.cc/2018/Conference/Paper628/AnonReviewer3"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Conference/Paper628/AnonReviewer3"], "content": {"title": "another thing to try", "comment": "ok, perhaps I was too quick there.\n\nCould you try evaluating a trained model with eps=0 in the variational bound instead of eps=1e-8? Since both the prior and posterior are learned, the model might learn to take advantage of your stability measures (this is not the best way of implementing this). If this matters (i.e. if the eps actually does something) the bound would be bad."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Feature Map Variational Auto-Encoders", "abstract": "There have been multiple attempts with variational auto-encoders (VAE) to learn powerful global representations of complex data using a combination of latent stochastic variables and an autoregressive model over the dimensions of the data. However, for the most challenging natural image tasks the purely autoregressive model with stochastic variables still outperform the combined stochastic autoregressive models. In this paper, we present simple additions to the VAE framework that generalize to natural images by embedding spatial information in the stochastic layers. We significantly improve the state-of-the-art results on MNIST, OMNIGLOT, CIFAR10 and ImageNet when the feature map parameterization of the stochastic variables are combined with the autoregressive PixelCNN approach. Interestingly, we also observe close to state-of-the-art results without the autoregressive part. This opens the possibility for high quality image generation with only one forward-pass.\n", "pdf": "/pdf/e6a071da6490a0996d08f3ddbc463bea39e1f913.pdf", "TL;DR": "We present a generative model that proves state-of-the-art results on gray-scale and natural images.", "paperhash": "maal\u00f8e|feature_map_variational_autoencoders", "_bibtex": "@misc{\nmaal\u00f8e2018feature,\ntitle={Feature Map Variational Auto-Encoders},\nauthor={Lars Maal\u00f8e and Ole Winther},\nyear={2018},\nurl={https://openreview.net/forum?id=Hy_o3x-0b},\n}", "keywords": ["deep learning", "representation learning", "variational auto-encoders", "variational inference", "generative models"], "authors": ["Lars Maal\u00f8e", "Ole Winther"], "authorids": ["larsma@dtu.dk", "olwi@dtu.dk"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "tmdate": 1516825730387, "id": "ICLR.cc/2018/Conference/-/Paper628/Official_Comment", "writers": ["ICLR.cc/2018/Conference"], "signatures": ["ICLR.cc/2018/Conference"], "readers": ["everyone"], "reply": {"replyto": null, "forum": "Hy_o3x-0b", "writers": {"values-regex": "ICLR.cc/2018/Conference/Paper628/AnonReviewer[0-9]+|ICLR.cc/2018/Conference/Paper628/Authors|ICLR.cc/2018/Conference/Paper628/Area_Chair|ICLR.cc/2018/Conference/Program_Chairs"}, "signatures": {"values-regex": "ICLR.cc/2018/Conference/Paper628/AnonReviewer[0-9]+|ICLR.cc/2018/Conference/Paper628/Authors|ICLR.cc/2018/Conference/Paper628/Area_Chair|ICLR.cc/2018/Conference/Program_Chairs", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2018/Conference/Paper628/Authors_and_Higher", "ICLR.cc/2018/Conference/Paper628/Reviewers_and_Higher", "ICLR.cc/2018/Conference/Paper628/Area_Chairs_and_Higher", "ICLR.cc/2018/Conference/Program_Chairs"]}, "content": {"title": {"required": true, "order": 0, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"required": true, "order": 1, "description": "Your comment or reply (max 5000 characters).", "value-regex": "[\\S\\s]{1,5000}"}}}, "nonreaders": [], "noninvitees": [], "invitees": ["ICLR.cc/2018/Conference/Paper628/Reviewers", "ICLR.cc/2018/Conference/Paper628/Authors", "ICLR.cc/2018/Conference/Paper628/Area_Chair", "ICLR.cc/2018/Conference/Program_Chairs"], "cdate": 1516825730387}}}, {"tddate": null, "ddate": null, "tmdate": 1511508236376, "tcdate": 1511450761053, "number": 3, "cdate": 1511450761053, "id": "HkWqOPVgf", "invitation": "ICLR.cc/2018/Conference/-/Paper628/Official_Comment", "forum": "Hy_o3x-0b", "replyto": "HksGNSfgG", "signatures": ["ICLR.cc/2018/Conference/Paper628/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Conference/Paper628/Authors"], "content": {"title": "General comments and code sharing", "comment": "Dear anonymous and AnonReviewer3,\n\n* Thank your for spotting the sub-quality sample. We have identified a possible error. We had forgotten to sample the softmax from the auto-regresssive part of the model. This of course have a negative influence on the sample quality but does not affect the test log-likelihood calculation. We will provide a follow-up on this a bit later with new samples. \n\n* We provide the complete code here (Python 3 & Tensorflow 1.2):  https://www.dropbox.com/s/wjhhxff0b0np6xi/FAME-implementation.zip?dl=0. We will also provide the code in a Github repo later. \n\n* We have trained a PixelCNN with an equivalent architecture as the one used for FAME (no R->G->B dependency) and achieved a NLL at 3.34 bits/dim. So we are confident that our code is working properly.\n\n* Finally we would like to note that we forgot to add a \u201clog\u201d in the equation following Eq. 6 in the paper.\n"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Feature Map Variational Auto-Encoders", "abstract": "There have been multiple attempts with variational auto-encoders (VAE) to learn powerful global representations of complex data using a combination of latent stochastic variables and an autoregressive model over the dimensions of the data. However, for the most challenging natural image tasks the purely autoregressive model with stochastic variables still outperform the combined stochastic autoregressive models. In this paper, we present simple additions to the VAE framework that generalize to natural images by embedding spatial information in the stochastic layers. We significantly improve the state-of-the-art results on MNIST, OMNIGLOT, CIFAR10 and ImageNet when the feature map parameterization of the stochastic variables are combined with the autoregressive PixelCNN approach. Interestingly, we also observe close to state-of-the-art results without the autoregressive part. This opens the possibility for high quality image generation with only one forward-pass.\n", "pdf": "/pdf/e6a071da6490a0996d08f3ddbc463bea39e1f913.pdf", "TL;DR": "We present a generative model that proves state-of-the-art results on gray-scale and natural images.", "paperhash": "maal\u00f8e|feature_map_variational_autoencoders", "_bibtex": "@misc{\nmaal\u00f8e2018feature,\ntitle={Feature Map Variational Auto-Encoders},\nauthor={Lars Maal\u00f8e and Ole Winther},\nyear={2018},\nurl={https://openreview.net/forum?id=Hy_o3x-0b},\n}", "keywords": ["deep learning", "representation learning", "variational auto-encoders", "variational inference", "generative models"], "authors": ["Lars Maal\u00f8e", "Ole Winther"], "authorids": ["larsma@dtu.dk", "olwi@dtu.dk"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "tmdate": 1516825730387, "id": "ICLR.cc/2018/Conference/-/Paper628/Official_Comment", "writers": ["ICLR.cc/2018/Conference"], "signatures": ["ICLR.cc/2018/Conference"], "readers": ["everyone"], "reply": {"replyto": null, "forum": "Hy_o3x-0b", "writers": {"values-regex": "ICLR.cc/2018/Conference/Paper628/AnonReviewer[0-9]+|ICLR.cc/2018/Conference/Paper628/Authors|ICLR.cc/2018/Conference/Paper628/Area_Chair|ICLR.cc/2018/Conference/Program_Chairs"}, "signatures": {"values-regex": "ICLR.cc/2018/Conference/Paper628/AnonReviewer[0-9]+|ICLR.cc/2018/Conference/Paper628/Authors|ICLR.cc/2018/Conference/Paper628/Area_Chair|ICLR.cc/2018/Conference/Program_Chairs", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2018/Conference/Paper628/Authors_and_Higher", "ICLR.cc/2018/Conference/Paper628/Reviewers_and_Higher", "ICLR.cc/2018/Conference/Paper628/Area_Chairs_and_Higher", "ICLR.cc/2018/Conference/Program_Chairs"]}, "content": {"title": {"required": true, "order": 0, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"required": true, "order": 1, "description": "Your comment or reply (max 5000 characters).", "value-regex": "[\\S\\s]{1,5000}"}}}, "nonreaders": [], "noninvitees": [], "invitees": ["ICLR.cc/2018/Conference/Paper628/Reviewers", "ICLR.cc/2018/Conference/Paper628/Authors", "ICLR.cc/2018/Conference/Paper628/Area_Chair", "ICLR.cc/2018/Conference/Program_Chairs"], "cdate": 1516825730387}}}, {"tddate": null, "ddate": null, "tmdate": 1511461044510, "tcdate": 1511460738684, "number": 7, "cdate": 1511460738684, "id": "SkjKJ5Nlf", "invitation": "ICLR.cc/2018/Conference/-/Paper628/Official_Comment", "forum": "Hy_o3x-0b", "replyto": "HyIvKY4ez", "signatures": ["ICLR.cc/2018/Conference/Paper628/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Conference/Paper628/Authors"], "content": {"title": "line 47", "comment": "Yes. In _fame.py lines: 60, 99 and 105, you can see that I call the function using the default arguments mean=0. and var=1.\n\nPlease note that there is a difference between self.mean, self.var and input_mean, input_var."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Feature Map Variational Auto-Encoders", "abstract": "There have been multiple attempts with variational auto-encoders (VAE) to learn powerful global representations of complex data using a combination of latent stochastic variables and an autoregressive model over the dimensions of the data. However, for the most challenging natural image tasks the purely autoregressive model with stochastic variables still outperform the combined stochastic autoregressive models. In this paper, we present simple additions to the VAE framework that generalize to natural images by embedding spatial information in the stochastic layers. We significantly improve the state-of-the-art results on MNIST, OMNIGLOT, CIFAR10 and ImageNet when the feature map parameterization of the stochastic variables are combined with the autoregressive PixelCNN approach. Interestingly, we also observe close to state-of-the-art results without the autoregressive part. This opens the possibility for high quality image generation with only one forward-pass.\n", "pdf": "/pdf/e6a071da6490a0996d08f3ddbc463bea39e1f913.pdf", "TL;DR": "We present a generative model that proves state-of-the-art results on gray-scale and natural images.", "paperhash": "maal\u00f8e|feature_map_variational_autoencoders", "_bibtex": "@misc{\nmaal\u00f8e2018feature,\ntitle={Feature Map Variational Auto-Encoders},\nauthor={Lars Maal\u00f8e and Ole Winther},\nyear={2018},\nurl={https://openreview.net/forum?id=Hy_o3x-0b},\n}", "keywords": ["deep learning", "representation learning", "variational auto-encoders", "variational inference", "generative models"], "authors": ["Lars Maal\u00f8e", "Ole Winther"], "authorids": ["larsma@dtu.dk", "olwi@dtu.dk"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "tmdate": 1516825730387, "id": "ICLR.cc/2018/Conference/-/Paper628/Official_Comment", "writers": ["ICLR.cc/2018/Conference"], "signatures": ["ICLR.cc/2018/Conference"], "readers": ["everyone"], "reply": {"replyto": null, "forum": "Hy_o3x-0b", "writers": {"values-regex": "ICLR.cc/2018/Conference/Paper628/AnonReviewer[0-9]+|ICLR.cc/2018/Conference/Paper628/Authors|ICLR.cc/2018/Conference/Paper628/Area_Chair|ICLR.cc/2018/Conference/Program_Chairs"}, "signatures": {"values-regex": "ICLR.cc/2018/Conference/Paper628/AnonReviewer[0-9]+|ICLR.cc/2018/Conference/Paper628/Authors|ICLR.cc/2018/Conference/Paper628/Area_Chair|ICLR.cc/2018/Conference/Program_Chairs", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2018/Conference/Paper628/Authors_and_Higher", "ICLR.cc/2018/Conference/Paper628/Reviewers_and_Higher", "ICLR.cc/2018/Conference/Paper628/Area_Chairs_and_Higher", "ICLR.cc/2018/Conference/Program_Chairs"]}, "content": {"title": {"required": true, "order": 0, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"required": true, "order": 1, "description": "Your comment or reply (max 5000 characters).", "value-regex": "[\\S\\s]{1,5000}"}}}, "nonreaders": [], "noninvitees": [], "invitees": ["ICLR.cc/2018/Conference/Paper628/Reviewers", "ICLR.cc/2018/Conference/Paper628/Authors", "ICLR.cc/2018/Conference/Paper628/Area_Chair", "ICLR.cc/2018/Conference/Program_Chairs"], "cdate": 1516825730387}}}, {"tddate": null, "ddate": null, "tmdate": 1511459165858, "tcdate": 1511459165858, "number": 6, "cdate": 1511459165858, "id": "HyIvKY4ez", "invitation": "ICLR.cc/2018/Conference/-/Paper628/Official_Comment", "forum": "Hy_o3x-0b", "replyto": "Hy0Pcd4gf", "signatures": ["ICLR.cc/2018/Conference/Paper628/AnonReviewer3"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Conference/Paper628/AnonReviewer3"], "content": {"title": "line 47", "comment": "this is line 47: eps = tf.random_normal(tf.shape(input_mean),mean=self.mean, stddev=np.sqrt(self.var), seed=self.seed, name=self.name)\n\nAre you saying self.mean=0 and self.var=1 always?\n\n"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Feature Map Variational Auto-Encoders", "abstract": "There have been multiple attempts with variational auto-encoders (VAE) to learn powerful global representations of complex data using a combination of latent stochastic variables and an autoregressive model over the dimensions of the data. However, for the most challenging natural image tasks the purely autoregressive model with stochastic variables still outperform the combined stochastic autoregressive models. In this paper, we present simple additions to the VAE framework that generalize to natural images by embedding spatial information in the stochastic layers. We significantly improve the state-of-the-art results on MNIST, OMNIGLOT, CIFAR10 and ImageNet when the feature map parameterization of the stochastic variables are combined with the autoregressive PixelCNN approach. Interestingly, we also observe close to state-of-the-art results without the autoregressive part. This opens the possibility for high quality image generation with only one forward-pass.\n", "pdf": "/pdf/e6a071da6490a0996d08f3ddbc463bea39e1f913.pdf", "TL;DR": "We present a generative model that proves state-of-the-art results on gray-scale and natural images.", "paperhash": "maal\u00f8e|feature_map_variational_autoencoders", "_bibtex": "@misc{\nmaal\u00f8e2018feature,\ntitle={Feature Map Variational Auto-Encoders},\nauthor={Lars Maal\u00f8e and Ole Winther},\nyear={2018},\nurl={https://openreview.net/forum?id=Hy_o3x-0b},\n}", "keywords": ["deep learning", "representation learning", "variational auto-encoders", "variational inference", "generative models"], "authors": ["Lars Maal\u00f8e", "Ole Winther"], "authorids": ["larsma@dtu.dk", "olwi@dtu.dk"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "tmdate": 1516825730387, "id": "ICLR.cc/2018/Conference/-/Paper628/Official_Comment", "writers": ["ICLR.cc/2018/Conference"], "signatures": ["ICLR.cc/2018/Conference"], "readers": ["everyone"], "reply": {"replyto": null, "forum": "Hy_o3x-0b", "writers": {"values-regex": "ICLR.cc/2018/Conference/Paper628/AnonReviewer[0-9]+|ICLR.cc/2018/Conference/Paper628/Authors|ICLR.cc/2018/Conference/Paper628/Area_Chair|ICLR.cc/2018/Conference/Program_Chairs"}, "signatures": {"values-regex": "ICLR.cc/2018/Conference/Paper628/AnonReviewer[0-9]+|ICLR.cc/2018/Conference/Paper628/Authors|ICLR.cc/2018/Conference/Paper628/Area_Chair|ICLR.cc/2018/Conference/Program_Chairs", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2018/Conference/Paper628/Authors_and_Higher", "ICLR.cc/2018/Conference/Paper628/Reviewers_and_Higher", "ICLR.cc/2018/Conference/Paper628/Area_Chairs_and_Higher", "ICLR.cc/2018/Conference/Program_Chairs"]}, "content": {"title": {"required": true, "order": 0, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"required": true, "order": 1, "description": "Your comment or reply (max 5000 characters).", "value-regex": "[\\S\\s]{1,5000}"}}}, "nonreaders": [], "noninvitees": [], "invitees": ["ICLR.cc/2018/Conference/Paper628/Reviewers", "ICLR.cc/2018/Conference/Paper628/Authors", "ICLR.cc/2018/Conference/Paper628/Area_Chair", "ICLR.cc/2018/Conference/Program_Chairs"], "cdate": 1516825730387}}}, {"tddate": null, "ddate": null, "tmdate": 1511455333805, "tcdate": 1511455333805, "number": 5, "cdate": 1511455333805, "id": "Hy0Pcd4gf", "invitation": "ICLR.cc/2018/Conference/-/Paper628/Official_Comment", "forum": "Hy_o3x-0b", "replyto": "HkHWP_Vef", "signatures": ["ICLR.cc/2018/Conference/Paper628/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Conference/Paper628/Authors"], "content": {"title": "Not a bug", "comment": "Dear AnonReviewer3,\n\nFirst we generate a random tensor N(0,I)->'eps' (line 47) that has the same shape as the input then we calculate z (line 51) by applying the reparameterization trick: https://arxiv.org/pdf/1312.6114.pdf."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Feature Map Variational Auto-Encoders", "abstract": "There have been multiple attempts with variational auto-encoders (VAE) to learn powerful global representations of complex data using a combination of latent stochastic variables and an autoregressive model over the dimensions of the data. However, for the most challenging natural image tasks the purely autoregressive model with stochastic variables still outperform the combined stochastic autoregressive models. In this paper, we present simple additions to the VAE framework that generalize to natural images by embedding spatial information in the stochastic layers. We significantly improve the state-of-the-art results on MNIST, OMNIGLOT, CIFAR10 and ImageNet when the feature map parameterization of the stochastic variables are combined with the autoregressive PixelCNN approach. Interestingly, we also observe close to state-of-the-art results without the autoregressive part. This opens the possibility for high quality image generation with only one forward-pass.\n", "pdf": "/pdf/e6a071da6490a0996d08f3ddbc463bea39e1f913.pdf", "TL;DR": "We present a generative model that proves state-of-the-art results on gray-scale and natural images.", "paperhash": "maal\u00f8e|feature_map_variational_autoencoders", "_bibtex": "@misc{\nmaal\u00f8e2018feature,\ntitle={Feature Map Variational Auto-Encoders},\nauthor={Lars Maal\u00f8e and Ole Winther},\nyear={2018},\nurl={https://openreview.net/forum?id=Hy_o3x-0b},\n}", "keywords": ["deep learning", "representation learning", "variational auto-encoders", "variational inference", "generative models"], "authors": ["Lars Maal\u00f8e", "Ole Winther"], "authorids": ["larsma@dtu.dk", "olwi@dtu.dk"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "tmdate": 1516825730387, "id": "ICLR.cc/2018/Conference/-/Paper628/Official_Comment", "writers": ["ICLR.cc/2018/Conference"], "signatures": ["ICLR.cc/2018/Conference"], "readers": ["everyone"], "reply": {"replyto": null, "forum": "Hy_o3x-0b", "writers": {"values-regex": "ICLR.cc/2018/Conference/Paper628/AnonReviewer[0-9]+|ICLR.cc/2018/Conference/Paper628/Authors|ICLR.cc/2018/Conference/Paper628/Area_Chair|ICLR.cc/2018/Conference/Program_Chairs"}, "signatures": {"values-regex": "ICLR.cc/2018/Conference/Paper628/AnonReviewer[0-9]+|ICLR.cc/2018/Conference/Paper628/Authors|ICLR.cc/2018/Conference/Paper628/Area_Chair|ICLR.cc/2018/Conference/Program_Chairs", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2018/Conference/Paper628/Authors_and_Higher", "ICLR.cc/2018/Conference/Paper628/Reviewers_and_Higher", "ICLR.cc/2018/Conference/Paper628/Area_Chairs_and_Higher", "ICLR.cc/2018/Conference/Program_Chairs"]}, "content": {"title": {"required": true, "order": 0, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"required": true, "order": 1, "description": "Your comment or reply (max 5000 characters).", "value-regex": "[\\S\\s]{1,5000}"}}}, "nonreaders": [], "noninvitees": [], "invitees": ["ICLR.cc/2018/Conference/Paper628/Reviewers", "ICLR.cc/2018/Conference/Paper628/Authors", "ICLR.cc/2018/Conference/Paper628/Area_Chair", "ICLR.cc/2018/Conference/Program_Chairs"], "cdate": 1516825730387}}}, {"tddate": null, "ddate": null, "tmdate": 1511454460581, "tcdate": 1511454460581, "number": 4, "cdate": 1511454460581, "id": "HkHWP_Vef", "invitation": "ICLR.cc/2018/Conference/-/Paper628/Official_Comment", "forum": "Hy_o3x-0b", "replyto": "HkWqOPVgf", "signatures": ["ICLR.cc/2018/Conference/Paper628/AnonReviewer3"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Conference/Paper628/AnonReviewer3"], "content": {"title": "spotted a bug", "comment": "Thanks for sharing the code! I went through some of the files super quickly, and I seem to spot at least 1 bug: In StochasticGaussian() you create a random distribution z ~ N(m,s), and then you produce output z' = m + s*z. Seems like you're transforming the standard normal variable twice? Let me know if I'm wrong.\n"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Feature Map Variational Auto-Encoders", "abstract": "There have been multiple attempts with variational auto-encoders (VAE) to learn powerful global representations of complex data using a combination of latent stochastic variables and an autoregressive model over the dimensions of the data. However, for the most challenging natural image tasks the purely autoregressive model with stochastic variables still outperform the combined stochastic autoregressive models. In this paper, we present simple additions to the VAE framework that generalize to natural images by embedding spatial information in the stochastic layers. We significantly improve the state-of-the-art results on MNIST, OMNIGLOT, CIFAR10 and ImageNet when the feature map parameterization of the stochastic variables are combined with the autoregressive PixelCNN approach. Interestingly, we also observe close to state-of-the-art results without the autoregressive part. This opens the possibility for high quality image generation with only one forward-pass.\n", "pdf": "/pdf/e6a071da6490a0996d08f3ddbc463bea39e1f913.pdf", "TL;DR": "We present a generative model that proves state-of-the-art results on gray-scale and natural images.", "paperhash": "maal\u00f8e|feature_map_variational_autoencoders", "_bibtex": "@misc{\nmaal\u00f8e2018feature,\ntitle={Feature Map Variational Auto-Encoders},\nauthor={Lars Maal\u00f8e and Ole Winther},\nyear={2018},\nurl={https://openreview.net/forum?id=Hy_o3x-0b},\n}", "keywords": ["deep learning", "representation learning", "variational auto-encoders", "variational inference", "generative models"], "authors": ["Lars Maal\u00f8e", "Ole Winther"], "authorids": ["larsma@dtu.dk", "olwi@dtu.dk"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "tmdate": 1516825730387, "id": "ICLR.cc/2018/Conference/-/Paper628/Official_Comment", "writers": ["ICLR.cc/2018/Conference"], "signatures": ["ICLR.cc/2018/Conference"], "readers": ["everyone"], "reply": {"replyto": null, "forum": "Hy_o3x-0b", "writers": {"values-regex": "ICLR.cc/2018/Conference/Paper628/AnonReviewer[0-9]+|ICLR.cc/2018/Conference/Paper628/Authors|ICLR.cc/2018/Conference/Paper628/Area_Chair|ICLR.cc/2018/Conference/Program_Chairs"}, "signatures": {"values-regex": "ICLR.cc/2018/Conference/Paper628/AnonReviewer[0-9]+|ICLR.cc/2018/Conference/Paper628/Authors|ICLR.cc/2018/Conference/Paper628/Area_Chair|ICLR.cc/2018/Conference/Program_Chairs", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2018/Conference/Paper628/Authors_and_Higher", "ICLR.cc/2018/Conference/Paper628/Reviewers_and_Higher", "ICLR.cc/2018/Conference/Paper628/Area_Chairs_and_Higher", "ICLR.cc/2018/Conference/Program_Chairs"]}, "content": {"title": {"required": true, "order": 0, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"required": true, "order": 1, "description": "Your comment or reply (max 5000 characters).", "value-regex": "[\\S\\s]{1,5000}"}}}, "nonreaders": [], "noninvitees": [], "invitees": ["ICLR.cc/2018/Conference/Paper628/Reviewers", "ICLR.cc/2018/Conference/Paper628/Authors", "ICLR.cc/2018/Conference/Paper628/Area_Chair", "ICLR.cc/2018/Conference/Program_Chairs"], "cdate": 1516825730387}}}, {"tddate": null, "ddate": null, "tmdate": 1511348481653, "tcdate": 1511348481653, "number": 6, "cdate": 1511348481653, "id": "Syq-KRzlz", "invitation": "ICLR.cc/2018/Conference/-/Paper628/Public_Comment", "forum": "Hy_o3x-0b", "replyto": "H19apQuyM", "signatures": ["(anonymous)"], "readers": ["everyone"], "writers": ["(anonymous)"], "content": {"title": "CIFAR10 results", "comment": "Thank you for your detailed response. The MNIST and Omniglot samples you provided look reasonable and appear consistent with the scores you report on the datasets.\n\nI'm still puzzled by the apparent discrepancy between the sample quality and the test log-likelihood estimates on CIFAR10. To me it looks like the top-left pixel in all the samples in Figure 2 is white, which suggests that something is wrong with either training or sampling. You might want to check whether your PixelCNN implementation is correct for RGB data, e.g. conditioning is consistent between training and sampling. What do the samples look like if you remove the latent variables and train just the PixelCNN component?"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Feature Map Variational Auto-Encoders", "abstract": "There have been multiple attempts with variational auto-encoders (VAE) to learn powerful global representations of complex data using a combination of latent stochastic variables and an autoregressive model over the dimensions of the data. However, for the most challenging natural image tasks the purely autoregressive model with stochastic variables still outperform the combined stochastic autoregressive models. In this paper, we present simple additions to the VAE framework that generalize to natural images by embedding spatial information in the stochastic layers. We significantly improve the state-of-the-art results on MNIST, OMNIGLOT, CIFAR10 and ImageNet when the feature map parameterization of the stochastic variables are combined with the autoregressive PixelCNN approach. Interestingly, we also observe close to state-of-the-art results without the autoregressive part. This opens the possibility for high quality image generation with only one forward-pass.\n", "pdf": "/pdf/e6a071da6490a0996d08f3ddbc463bea39e1f913.pdf", "TL;DR": "We present a generative model that proves state-of-the-art results on gray-scale and natural images.", "paperhash": "maal\u00f8e|feature_map_variational_autoencoders", "_bibtex": "@misc{\nmaal\u00f8e2018feature,\ntitle={Feature Map Variational Auto-Encoders},\nauthor={Lars Maal\u00f8e and Ole Winther},\nyear={2018},\nurl={https://openreview.net/forum?id=Hy_o3x-0b},\n}", "keywords": ["deep learning", "representation learning", "variational auto-encoders", "variational inference", "generative models"], "authors": ["Lars Maal\u00f8e", "Ole Winther"], "authorids": ["larsma@dtu.dk", "olwi@dtu.dk"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "tmdate": 1512791682816, "id": "ICLR.cc/2018/Conference/-/Paper628/Public_Comment", "writers": ["ICLR.cc/2018/Conference"], "signatures": ["ICLR.cc/2018/Conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"replyto": null, "forum": "Hy_o3x-0b", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2018/Conference/Authors_and_Higher", "ICLR.cc/2018/Conference/Reviewers_and_Higher", "ICLR.cc/2018/Conference/Area_Chairs_and_Higher", "ICLR.cc/2018/Conference/Program_Chairs"]}, "content": {"title": {"required": true, "order": 0, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"required": true, "order": 1, "description": "Your comment or reply (max 5000 characters).", "value-regex": "[\\S\\s]{1,5000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2018/Conference/Paper628/Authors", "ICLR.cc/2018/Conference/Paper628/Reviewers", "ICLR.cc/2018/Conference/Paper628/Area_Chair"], "cdate": 1512791682816}}}, {"tddate": null, "ddate": null, "tmdate": 1511310354986, "tcdate": 1511310354986, "number": 2, "cdate": 1511310354986, "id": "HksGNSfgG", "invitation": "ICLR.cc/2018/Conference/-/Paper628/Official_Comment", "forum": "Hy_o3x-0b", "replyto": "H19apQuyM", "signatures": ["ICLR.cc/2018/Conference/Paper628/AnonReviewer3"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Conference/Paper628/AnonReviewer3"], "content": {"title": "possible to share code anonymously?", "comment": "Would it be possible to somehow share the code before the review period ends? Currently I also have a very hard time believing the reported 2.75 bits per dim number on CIFAR-10."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Feature Map Variational Auto-Encoders", "abstract": "There have been multiple attempts with variational auto-encoders (VAE) to learn powerful global representations of complex data using a combination of latent stochastic variables and an autoregressive model over the dimensions of the data. However, for the most challenging natural image tasks the purely autoregressive model with stochastic variables still outperform the combined stochastic autoregressive models. In this paper, we present simple additions to the VAE framework that generalize to natural images by embedding spatial information in the stochastic layers. We significantly improve the state-of-the-art results on MNIST, OMNIGLOT, CIFAR10 and ImageNet when the feature map parameterization of the stochastic variables are combined with the autoregressive PixelCNN approach. Interestingly, we also observe close to state-of-the-art results without the autoregressive part. This opens the possibility for high quality image generation with only one forward-pass.\n", "pdf": "/pdf/e6a071da6490a0996d08f3ddbc463bea39e1f913.pdf", "TL;DR": "We present a generative model that proves state-of-the-art results on gray-scale and natural images.", "paperhash": "maal\u00f8e|feature_map_variational_autoencoders", "_bibtex": "@misc{\nmaal\u00f8e2018feature,\ntitle={Feature Map Variational Auto-Encoders},\nauthor={Lars Maal\u00f8e and Ole Winther},\nyear={2018},\nurl={https://openreview.net/forum?id=Hy_o3x-0b},\n}", "keywords": ["deep learning", "representation learning", "variational auto-encoders", "variational inference", "generative models"], "authors": ["Lars Maal\u00f8e", "Ole Winther"], "authorids": ["larsma@dtu.dk", "olwi@dtu.dk"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "tmdate": 1516825730387, "id": "ICLR.cc/2018/Conference/-/Paper628/Official_Comment", "writers": ["ICLR.cc/2018/Conference"], "signatures": ["ICLR.cc/2018/Conference"], "readers": ["everyone"], "reply": {"replyto": null, "forum": "Hy_o3x-0b", "writers": {"values-regex": "ICLR.cc/2018/Conference/Paper628/AnonReviewer[0-9]+|ICLR.cc/2018/Conference/Paper628/Authors|ICLR.cc/2018/Conference/Paper628/Area_Chair|ICLR.cc/2018/Conference/Program_Chairs"}, "signatures": {"values-regex": "ICLR.cc/2018/Conference/Paper628/AnonReviewer[0-9]+|ICLR.cc/2018/Conference/Paper628/Authors|ICLR.cc/2018/Conference/Paper628/Area_Chair|ICLR.cc/2018/Conference/Program_Chairs", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2018/Conference/Paper628/Authors_and_Higher", "ICLR.cc/2018/Conference/Paper628/Reviewers_and_Higher", "ICLR.cc/2018/Conference/Paper628/Area_Chairs_and_Higher", "ICLR.cc/2018/Conference/Program_Chairs"]}, "content": {"title": {"required": true, "order": 0, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"required": true, "order": 1, "description": "Your comment or reply (max 5000 characters).", "value-regex": "[\\S\\s]{1,5000}"}}}, "nonreaders": [], "noninvitees": [], "invitees": ["ICLR.cc/2018/Conference/Paper628/Reviewers", "ICLR.cc/2018/Conference/Paper628/Authors", "ICLR.cc/2018/Conference/Paper628/Area_Chair", "ICLR.cc/2018/Conference/Program_Chairs"], "cdate": 1516825730387}}}, {"tddate": null, "ddate": null, "tmdate": 1510649281854, "tcdate": 1510649281854, "number": 1, "cdate": 1510649281854, "id": "H19apQuyM", "invitation": "ICLR.cc/2018/Conference/-/Paper628/Official_Comment", "forum": "Hy_o3x-0b", "replyto": "SJbqRnO0b", "signatures": ["ICLR.cc/2018/Conference/Paper628/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Conference/Paper628/Authors"], "content": {"title": "Answering the questions to the results", "comment": "Dear Yoon Kim and Anonymous,\n\nThank you for your interest in the paper. We have taken the comments seriously and thoroughly reviewed the code without finding any bugs. We have retrained the models and are confident in the results given in the Tables. We actually also found slight improvements compared to the results reported.\n\nFirst of all we would like to answer the questions formulated on the 1st of November by anonymous:\n\nQ1. The Omniglot samples in Figure 4 don't look binary. Are you showing the probabilities instead of the actual samples? Which version of the Omniglot dataset did you use and how did you preprocess it?\n\nYes, we are showing the probabilities. We will include the stochastically binarized samples in the revised version. Unfortunately it is not possible to include them in this OpenReview format, so please see: https://imgur.com/gallery/NRvxO. From the plots we can see comparable results to VLAE. It is hard to distinguish whether one is better over the other by only evaluating the samples, hence the log-likelihood results in the tables should tell the full story.\n\nQ2. The MNIST samples in Figure 4 do look binary, but their edges are far too smooth for stochastically binarized MNIST. In other words, they don't actually look like the data: just compare them to samples on Figure 1 in the VLAE paper (https://arxiv.org/abs/1611.02731). Did you sample each pixel or did you just use the most probable value?\n\nYou are right, we used the most probable value. We will include the stochastically binarized samples in the revised version. Find them here: https://imgur.com/gallery/NRvxO .\n\nQ3. The CIFAR10 samples in Figure 2 have very little local detail and are not nearly sharp and structured enough to correspond to the 2.75 bits/dim result reported in the paper. In my experience, a model generating samples like this should get 3.4 bits/dim at best. What kind of test NLL estimates do you get with a single sample on CIFAR10 and ImageNet?\n\nWe do agree that these samples do not have as much local detail as the samples in VLAE and PixelCNN++. However, we have a very simple PixelCNN parameterization without the R->G->B dependency and all of the additional contributions as the PixelCNN++/VLAE papers have. In our approach the local structure is worse but the global modeling is better. We interpret the better test likelihood score as a sign that visual appeal is not the ultimate way to judge the model. We expect that including a better autoregressive model in FAME will give us the best of both worlds.\n\nFor the camera-ready version we will train FAME with a more complex autoregressive model and visualize the generated images in the final paper for both ImageNet and CIFAR10. We didn't do this experiment, since we did not have the time before the deadline and we were more interested in answering the question to why the additional VAE parameterization in PixelVAE and VLAE didn't give a better bound.\n\nLast but not least we will publish the code on Github upon publishing the paper.\n\n\n"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Feature Map Variational Auto-Encoders", "abstract": "There have been multiple attempts with variational auto-encoders (VAE) to learn powerful global representations of complex data using a combination of latent stochastic variables and an autoregressive model over the dimensions of the data. However, for the most challenging natural image tasks the purely autoregressive model with stochastic variables still outperform the combined stochastic autoregressive models. In this paper, we present simple additions to the VAE framework that generalize to natural images by embedding spatial information in the stochastic layers. We significantly improve the state-of-the-art results on MNIST, OMNIGLOT, CIFAR10 and ImageNet when the feature map parameterization of the stochastic variables are combined with the autoregressive PixelCNN approach. Interestingly, we also observe close to state-of-the-art results without the autoregressive part. This opens the possibility for high quality image generation with only one forward-pass.\n", "pdf": "/pdf/e6a071da6490a0996d08f3ddbc463bea39e1f913.pdf", "TL;DR": "We present a generative model that proves state-of-the-art results on gray-scale and natural images.", "paperhash": "maal\u00f8e|feature_map_variational_autoencoders", "_bibtex": "@misc{\nmaal\u00f8e2018feature,\ntitle={Feature Map Variational Auto-Encoders},\nauthor={Lars Maal\u00f8e and Ole Winther},\nyear={2018},\nurl={https://openreview.net/forum?id=Hy_o3x-0b},\n}", "keywords": ["deep learning", "representation learning", "variational auto-encoders", "variational inference", "generative models"], "authors": ["Lars Maal\u00f8e", "Ole Winther"], "authorids": ["larsma@dtu.dk", "olwi@dtu.dk"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "tmdate": 1516825730387, "id": "ICLR.cc/2018/Conference/-/Paper628/Official_Comment", "writers": ["ICLR.cc/2018/Conference"], "signatures": ["ICLR.cc/2018/Conference"], "readers": ["everyone"], "reply": {"replyto": null, "forum": "Hy_o3x-0b", "writers": {"values-regex": "ICLR.cc/2018/Conference/Paper628/AnonReviewer[0-9]+|ICLR.cc/2018/Conference/Paper628/Authors|ICLR.cc/2018/Conference/Paper628/Area_Chair|ICLR.cc/2018/Conference/Program_Chairs"}, "signatures": {"values-regex": "ICLR.cc/2018/Conference/Paper628/AnonReviewer[0-9]+|ICLR.cc/2018/Conference/Paper628/Authors|ICLR.cc/2018/Conference/Paper628/Area_Chair|ICLR.cc/2018/Conference/Program_Chairs", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2018/Conference/Paper628/Authors_and_Higher", "ICLR.cc/2018/Conference/Paper628/Reviewers_and_Higher", "ICLR.cc/2018/Conference/Paper628/Area_Chairs_and_Higher", "ICLR.cc/2018/Conference/Program_Chairs"]}, "content": {"title": {"required": true, "order": 0, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"required": true, "order": 1, "description": "Your comment or reply (max 5000 characters).", "value-regex": "[\\S\\s]{1,5000}"}}}, "nonreaders": [], "noninvitees": [], "invitees": ["ICLR.cc/2018/Conference/Paper628/Reviewers", "ICLR.cc/2018/Conference/Paper628/Authors", "ICLR.cc/2018/Conference/Paper628/Area_Chair", "ICLR.cc/2018/Conference/Program_Chairs"], "cdate": 1516825730387}}}, {"tddate": null, "ddate": null, "tmdate": 1510016183017, "tcdate": 1510007410678, "number": 5, "cdate": 1510007410678, "id": "ryo_Mw0Cb", "invitation": "ICLR.cc/2018/Conference/-/Paper628/Public_Comment", "forum": "Hy_o3x-0b", "replyto": "S183EOuC-", "signatures": ["~Yoon_Kim1"], "readers": ["everyone"], "writers": ["~Yoon_Kim1"], "content": {"title": ".", "comment": "Interestingly, I do find that the samples are quite a bit blurrier than other papers that achieve higher bits/dim (e.g. VLAE/PixelCNN++, etc.). \n\nAuthors: As the above poster suggested, I would be curious to see the ImageNet samples as well.\nAlso, how does the KL look for CIFAR10? What about reconstructions?\n\nIt could also mean that our intuition regarding bits/dim translating to higher quality samples is not necessarily true, e.g. due to teacher-forced training vs sampling-based generation. Or it could simply be a bug on my part... \n\nIncidentally, I was able to get the bits/dim down ~2.7 by playing around with the hyperparameters a bit more. For me these seemed to help:\n\n- learning the prior (log) variances\n- using a higher dimensional latent dimension at each stage (I use 32 at each stage, and my first latent map is at the 8 x 8 resolution)\n"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Feature Map Variational Auto-Encoders", "abstract": "There have been multiple attempts with variational auto-encoders (VAE) to learn powerful global representations of complex data using a combination of latent stochastic variables and an autoregressive model over the dimensions of the data. However, for the most challenging natural image tasks the purely autoregressive model with stochastic variables still outperform the combined stochastic autoregressive models. In this paper, we present simple additions to the VAE framework that generalize to natural images by embedding spatial information in the stochastic layers. We significantly improve the state-of-the-art results on MNIST, OMNIGLOT, CIFAR10 and ImageNet when the feature map parameterization of the stochastic variables are combined with the autoregressive PixelCNN approach. Interestingly, we also observe close to state-of-the-art results without the autoregressive part. This opens the possibility for high quality image generation with only one forward-pass.\n", "pdf": "/pdf/e6a071da6490a0996d08f3ddbc463bea39e1f913.pdf", "TL;DR": "We present a generative model that proves state-of-the-art results on gray-scale and natural images.", "paperhash": "maal\u00f8e|feature_map_variational_autoencoders", "_bibtex": "@misc{\nmaal\u00f8e2018feature,\ntitle={Feature Map Variational Auto-Encoders},\nauthor={Lars Maal\u00f8e and Ole Winther},\nyear={2018},\nurl={https://openreview.net/forum?id=Hy_o3x-0b},\n}", "keywords": ["deep learning", "representation learning", "variational auto-encoders", "variational inference", "generative models"], "authors": ["Lars Maal\u00f8e", "Ole Winther"], "authorids": ["larsma@dtu.dk", "olwi@dtu.dk"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "tmdate": 1512791682816, "id": "ICLR.cc/2018/Conference/-/Paper628/Public_Comment", "writers": ["ICLR.cc/2018/Conference"], "signatures": ["ICLR.cc/2018/Conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"replyto": null, "forum": "Hy_o3x-0b", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2018/Conference/Authors_and_Higher", "ICLR.cc/2018/Conference/Reviewers_and_Higher", "ICLR.cc/2018/Conference/Area_Chairs_and_Higher", "ICLR.cc/2018/Conference/Program_Chairs"]}, "content": {"title": {"required": true, "order": 0, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"required": true, "order": 1, "description": "Your comment or reply (max 5000 characters).", "value-regex": "[\\S\\s]{1,5000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2018/Conference/Paper628/Authors", "ICLR.cc/2018/Conference/Paper628/Reviewers", "ICLR.cc/2018/Conference/Paper628/Area_Chair"], "cdate": 1512791682816}}}, {"tddate": null, "ddate": null, "tmdate": 1509637769107, "tcdate": 1509637769107, "number": 4, "cdate": 1509637769107, "id": "SJbqRnO0b", "invitation": "ICLR.cc/2018/Conference/-/Paper628/Public_Comment", "forum": "Hy_o3x-0b", "replyto": "S183EOuC-", "signatures": ["~Yoon_Kim1"], "readers": ["everyone"], "writers": ["~Yoon_Kim1"], "content": {"title": ".", "comment": "No problem! I haven't checked the samples and I use the batchnorm statistics from the training set only.\n"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Feature Map Variational Auto-Encoders", "abstract": "There have been multiple attempts with variational auto-encoders (VAE) to learn powerful global representations of complex data using a combination of latent stochastic variables and an autoregressive model over the dimensions of the data. However, for the most challenging natural image tasks the purely autoregressive model with stochastic variables still outperform the combined stochastic autoregressive models. In this paper, we present simple additions to the VAE framework that generalize to natural images by embedding spatial information in the stochastic layers. We significantly improve the state-of-the-art results on MNIST, OMNIGLOT, CIFAR10 and ImageNet when the feature map parameterization of the stochastic variables are combined with the autoregressive PixelCNN approach. Interestingly, we also observe close to state-of-the-art results without the autoregressive part. This opens the possibility for high quality image generation with only one forward-pass.\n", "pdf": "/pdf/e6a071da6490a0996d08f3ddbc463bea39e1f913.pdf", "TL;DR": "We present a generative model that proves state-of-the-art results on gray-scale and natural images.", "paperhash": "maal\u00f8e|feature_map_variational_autoencoders", "_bibtex": "@misc{\nmaal\u00f8e2018feature,\ntitle={Feature Map Variational Auto-Encoders},\nauthor={Lars Maal\u00f8e and Ole Winther},\nyear={2018},\nurl={https://openreview.net/forum?id=Hy_o3x-0b},\n}", "keywords": ["deep learning", "representation learning", "variational auto-encoders", "variational inference", "generative models"], "authors": ["Lars Maal\u00f8e", "Ole Winther"], "authorids": ["larsma@dtu.dk", "olwi@dtu.dk"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "tmdate": 1512791682816, "id": "ICLR.cc/2018/Conference/-/Paper628/Public_Comment", "writers": ["ICLR.cc/2018/Conference"], "signatures": ["ICLR.cc/2018/Conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"replyto": null, "forum": "Hy_o3x-0b", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2018/Conference/Authors_and_Higher", "ICLR.cc/2018/Conference/Reviewers_and_Higher", "ICLR.cc/2018/Conference/Area_Chairs_and_Higher", "ICLR.cc/2018/Conference/Program_Chairs"]}, "content": {"title": {"required": true, "order": 0, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"required": true, "order": 1, "description": "Your comment or reply (max 5000 characters).", "value-regex": "[\\S\\s]{1,5000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2018/Conference/Paper628/Authors", "ICLR.cc/2018/Conference/Paper628/Reviewers", "ICLR.cc/2018/Conference/Paper628/Area_Chair"], "cdate": 1512791682816}}}, {"tddate": null, "ddate": null, "tmdate": 1509618862033, "tcdate": 1509618862033, "number": 3, "cdate": 1509618862033, "id": "S183EOuC-", "invitation": "ICLR.cc/2018/Conference/-/Paper628/Public_Comment", "forum": "Hy_o3x-0b", "replyto": "S1RfdFwRb", "signatures": ["(anonymous)"], "readers": ["everyone"], "writers": ["(anonymous)"], "content": {"title": "Computing the test NLL", "comment": "Thanks a lot for sharing your replication experience. Do your CIFAR10 samples look substantially different from the ones in the paper? When computing the test NLL estimate, do you use the batchnorm statistics from the training set or the test set? "}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Feature Map Variational Auto-Encoders", "abstract": "There have been multiple attempts with variational auto-encoders (VAE) to learn powerful global representations of complex data using a combination of latent stochastic variables and an autoregressive model over the dimensions of the data. However, for the most challenging natural image tasks the purely autoregressive model with stochastic variables still outperform the combined stochastic autoregressive models. In this paper, we present simple additions to the VAE framework that generalize to natural images by embedding spatial information in the stochastic layers. We significantly improve the state-of-the-art results on MNIST, OMNIGLOT, CIFAR10 and ImageNet when the feature map parameterization of the stochastic variables are combined with the autoregressive PixelCNN approach. Interestingly, we also observe close to state-of-the-art results without the autoregressive part. This opens the possibility for high quality image generation with only one forward-pass.\n", "pdf": "/pdf/e6a071da6490a0996d08f3ddbc463bea39e1f913.pdf", "TL;DR": "We present a generative model that proves state-of-the-art results on gray-scale and natural images.", "paperhash": "maal\u00f8e|feature_map_variational_autoencoders", "_bibtex": "@misc{\nmaal\u00f8e2018feature,\ntitle={Feature Map Variational Auto-Encoders},\nauthor={Lars Maal\u00f8e and Ole Winther},\nyear={2018},\nurl={https://openreview.net/forum?id=Hy_o3x-0b},\n}", "keywords": ["deep learning", "representation learning", "variational auto-encoders", "variational inference", "generative models"], "authors": ["Lars Maal\u00f8e", "Ole Winther"], "authorids": ["larsma@dtu.dk", "olwi@dtu.dk"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "tmdate": 1512791682816, "id": "ICLR.cc/2018/Conference/-/Paper628/Public_Comment", "writers": ["ICLR.cc/2018/Conference"], "signatures": ["ICLR.cc/2018/Conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"replyto": null, "forum": "Hy_o3x-0b", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2018/Conference/Authors_and_Higher", "ICLR.cc/2018/Conference/Reviewers_and_Higher", "ICLR.cc/2018/Conference/Area_Chairs_and_Higher", "ICLR.cc/2018/Conference/Program_Chairs"]}, "content": {"title": {"required": true, "order": 0, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"required": true, "order": 1, "description": "Your comment or reply (max 5000 characters).", "value-regex": "[\\S\\s]{1,5000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2018/Conference/Paper628/Authors", "ICLR.cc/2018/Conference/Paper628/Reviewers", "ICLR.cc/2018/Conference/Paper628/Area_Chair"], "cdate": 1512791682816}}}, {"tddate": null, "ddate": null, "tmdate": 1509558294006, "tcdate": 1509558294006, "number": 2, "cdate": 1509558294006, "id": "S1RfdFwRb", "invitation": "ICLR.cc/2018/Conference/-/Paper628/Public_Comment", "forum": "Hy_o3x-0b", "replyto": "HJc6qSwCZ", "signatures": ["~Yoon_Kim1"], "readers": ["everyone"], "writers": ["~Yoon_Kim1"], "content": {"title": ".", "comment": "I too found the CIFAR results remarkable, so I replicated it, and I was able to match the ~2.8 number (with slightly different architecture/hyperparameters than was used in the paper).\n\nReally nice work! "}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Feature Map Variational Auto-Encoders", "abstract": "There have been multiple attempts with variational auto-encoders (VAE) to learn powerful global representations of complex data using a combination of latent stochastic variables and an autoregressive model over the dimensions of the data. However, for the most challenging natural image tasks the purely autoregressive model with stochastic variables still outperform the combined stochastic autoregressive models. In this paper, we present simple additions to the VAE framework that generalize to natural images by embedding spatial information in the stochastic layers. We significantly improve the state-of-the-art results on MNIST, OMNIGLOT, CIFAR10 and ImageNet when the feature map parameterization of the stochastic variables are combined with the autoregressive PixelCNN approach. Interestingly, we also observe close to state-of-the-art results without the autoregressive part. This opens the possibility for high quality image generation with only one forward-pass.\n", "pdf": "/pdf/e6a071da6490a0996d08f3ddbc463bea39e1f913.pdf", "TL;DR": "We present a generative model that proves state-of-the-art results on gray-scale and natural images.", "paperhash": "maal\u00f8e|feature_map_variational_autoencoders", "_bibtex": "@misc{\nmaal\u00f8e2018feature,\ntitle={Feature Map Variational Auto-Encoders},\nauthor={Lars Maal\u00f8e and Ole Winther},\nyear={2018},\nurl={https://openreview.net/forum?id=Hy_o3x-0b},\n}", "keywords": ["deep learning", "representation learning", "variational auto-encoders", "variational inference", "generative models"], "authors": ["Lars Maal\u00f8e", "Ole Winther"], "authorids": ["larsma@dtu.dk", "olwi@dtu.dk"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "tmdate": 1512791682816, "id": "ICLR.cc/2018/Conference/-/Paper628/Public_Comment", "writers": ["ICLR.cc/2018/Conference"], "signatures": ["ICLR.cc/2018/Conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"replyto": null, "forum": "Hy_o3x-0b", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2018/Conference/Authors_and_Higher", "ICLR.cc/2018/Conference/Reviewers_and_Higher", "ICLR.cc/2018/Conference/Area_Chairs_and_Higher", "ICLR.cc/2018/Conference/Program_Chairs"]}, "content": {"title": {"required": true, "order": 0, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"required": true, "order": 1, "description": "Your comment or reply (max 5000 characters).", "value-regex": "[\\S\\s]{1,5000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2018/Conference/Paper628/Authors", "ICLR.cc/2018/Conference/Paper628/Reviewers", "ICLR.cc/2018/Conference/Paper628/Area_Chair"], "cdate": 1512791682816}}}, {"tddate": null, "ddate": null, "tmdate": 1509542594107, "tcdate": 1509542594107, "number": 1, "cdate": 1509542594107, "id": "HJc6qSwCZ", "invitation": "ICLR.cc/2018/Conference/-/Paper628/Public_Comment", "forum": "Hy_o3x-0b", "replyto": "Hy_o3x-0b", "signatures": ["(anonymous)"], "readers": ["everyone"], "writers": ["(anonymous)"], "content": {"title": "Questions about your results", "comment": "Intrigued by the claim of state-of-the-art results, I read the paper and noticed several things about the results that don't look right.\n\nThe Omniglot samples in Figure 4 don't look binary. Are you showing the probabilities instead of the actual samples? Which version of the Omniglot dataset did you use and how did you preprocess it?\n\nThe MNIST samples in Figure 4 do look binary, but their edges are far too smooth for stochastically binarized MNIST. In other words, they don't actually look like the data: just compare them to samples on Figure 1 in the VLAE paper (https://arxiv.org/abs/1611.02731). Did you sample each pixel or did you just use the most probable value?\n\nThe CIFAR10 samples in Figure 2 have very little local detail and are not nearly sharp and structured enough to correspond to the 2.75 bits/dim result reported in the paper. In my experience, a model generating samples like this should get 3.4 bits/dim at best. What kind of test NLL estimates do you get with a single sample on CIFAR10 and ImageNet?\n\nFinally, given that you seem to have the best 32x32 ImageNet result by a huge margin it seems odd not to include any samples from this model. Why did you omit them? While sample quality is just one aspect of model performance, in my experience a large discrepancy between sample quality and NLL in a VAE-like model usually means that there's a bug in the code."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Feature Map Variational Auto-Encoders", "abstract": "There have been multiple attempts with variational auto-encoders (VAE) to learn powerful global representations of complex data using a combination of latent stochastic variables and an autoregressive model over the dimensions of the data. However, for the most challenging natural image tasks the purely autoregressive model with stochastic variables still outperform the combined stochastic autoregressive models. In this paper, we present simple additions to the VAE framework that generalize to natural images by embedding spatial information in the stochastic layers. We significantly improve the state-of-the-art results on MNIST, OMNIGLOT, CIFAR10 and ImageNet when the feature map parameterization of the stochastic variables are combined with the autoregressive PixelCNN approach. Interestingly, we also observe close to state-of-the-art results without the autoregressive part. This opens the possibility for high quality image generation with only one forward-pass.\n", "pdf": "/pdf/e6a071da6490a0996d08f3ddbc463bea39e1f913.pdf", "TL;DR": "We present a generative model that proves state-of-the-art results on gray-scale and natural images.", "paperhash": "maal\u00f8e|feature_map_variational_autoencoders", "_bibtex": "@misc{\nmaal\u00f8e2018feature,\ntitle={Feature Map Variational Auto-Encoders},\nauthor={Lars Maal\u00f8e and Ole Winther},\nyear={2018},\nurl={https://openreview.net/forum?id=Hy_o3x-0b},\n}", "keywords": ["deep learning", "representation learning", "variational auto-encoders", "variational inference", "generative models"], "authors": ["Lars Maal\u00f8e", "Ole Winther"], "authorids": ["larsma@dtu.dk", "olwi@dtu.dk"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "tmdate": 1512791682816, "id": "ICLR.cc/2018/Conference/-/Paper628/Public_Comment", "writers": ["ICLR.cc/2018/Conference"], "signatures": ["ICLR.cc/2018/Conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"replyto": null, "forum": "Hy_o3x-0b", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2018/Conference/Authors_and_Higher", "ICLR.cc/2018/Conference/Reviewers_and_Higher", "ICLR.cc/2018/Conference/Area_Chairs_and_Higher", "ICLR.cc/2018/Conference/Program_Chairs"]}, "content": {"title": {"required": true, "order": 0, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"required": true, "order": 1, "description": "Your comment or reply (max 5000 characters).", "value-regex": "[\\S\\s]{1,5000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2018/Conference/Paper628/Authors", "ICLR.cc/2018/Conference/Paper628/Reviewers", "ICLR.cc/2018/Conference/Paper628/Area_Chair"], "cdate": 1512791682816}}}], "count": 24}