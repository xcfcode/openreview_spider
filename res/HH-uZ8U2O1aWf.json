{"notes": [{"ddate": null, "legacy_migration": true, "tmdate": 1392752400000, "tcdate": 1392752400000, "number": 1, "id": "WWsaWx95KukwB", "invitation": "ICLR.cc/2014/-/submission/conference/reply", "forum": "HH-uZ8U2O1aWf", "replyto": "KEpWdQPiWrEqF", "signatures": ["Gary Huang"], "readers": ["everyone"], "writers": ["anonymous"], "content": {"title": "", "reply": "Thank you for the comments.\r\n\r\nIt seems the main concern is that the model presented in the paper is domain specific, with limited conclusions or take-aways for researchers in other areas. We believe that our paper outlines a general strategy for researchers working on problems with large amounts of data or who are otherwise concerned with training and inference speed.\r\n\r\nThis strategy essentially is one of replacing a complex, multi-layered supervised algorithm with a simple unsupervised feature learning algorithm followed by a simpler/shallower supervised algorithm. Moreover, the unsupervised and supervised steps can be interleaved in a recursive manner to create a deeper architecture. This general strategy is more amenable to parallelization, giving both better accuracy and greatly reducing training time.\r\n\r\nWhile components of the DAWMR networks such as multi-scale and drop-out could be added to the CNN baseline or other orthodox architectures, there would still exist the difference in training time. This is especially significant because shorter training times mean that these extensions and variations can be tested more quickly, and also as training and test set sizes will only increase in the future, particularly for the neural reconstruction problem presented in the paper.\r\n\r\nLastly, although our final architecture is made of many different components, through extensive experimentation, such as those detailed in the appendix, we have tried to separate out and evaluate the contribution of each component, at least within the context of our overall framework.  For instance, we can see the relative improvement gained by incorporating multi-scale and drop-out, or as we mention in the response to the review below (cf06), we can get a sense of whether deeper processing layers or increased field of view is driving the increased performance of the recursive classifiers.  We hope that these results will be helpful to other researchers in determining which aspects of our paper may be relevant and worth pursuing in their own work."}, "nonreaders": [], "details": {"replyCount": 0, "overwriting": [], "revisions": false, "forumContent": {"title": "Deep and Wide Multiscale Recursive Networks for Robust Image Labeling", "decision": "submitted, no decision", "abstract": "Feedforward multilayer networks trained by supervised learning have recently demonstrated state of the art performance on image labeling problems such as boundary prediction and scene parsing. As even very low error rates can limit practical usage of such systems, methods that perform closer to human accuracy remain desirable. In this work, we propose a new type of network with the following properties that address what we hypothesize to be limiting aspects of existing methods: (1) a `wide' structure with thousands of features, (2) a large field of view, (3) recursive iterations that exploit statistical dependencies in label space, and (4) a parallelizable architecture that can be trained in a fraction of the time compared to benchmark multilayer convolutional networks. For the specific image labeling problem of boundary prediction, we also introduce a novel example weighting algorithm that improves segmentation accuracy. Experiments in the challenging domain of connectomic reconstruction of neural circuity from 3d electron microscopy data show that these 'Deep And Wide Multiscale Recursive' (DAWMR) networks lead to new levels of image labeling performance. The highest performing architecture has twelve layers, interwoven supervised and unsupervised stages, and uses an input field of view of 157,464 voxels ($54^3$) to make a prediction at each image location. We present an associated open source software package that enables the simple and flexible creation of DAWMR networks.", "pdf": "https://arxiv.org/abs/1310.0354", "paperhash": "huang|deep_and_wide_multiscale_recursive_networks_for_robust_image_labeling", "keywords": [], "conflicts": [], "authors": ["Gary B. Huang", "Viren Jain"], "authorids": ["huangg@janelia.hhmi.org", "jainv@janelia.hhmi.org"]}, "tags": [], "invitation": {}}}, {"ddate": null, "legacy_migration": true, "tmdate": 1392750540000, "tcdate": 1392750540000, "number": 1, "id": "ogt7uh3Y7suLd", "invitation": "ICLR.cc/2014/-/submission/conference/reply", "forum": "HH-uZ8U2O1aWf", "replyto": "9zq_LwBP3U9bA", "signatures": ["Gary Huang"], "readers": ["everyone"], "writers": ["anonymous"], "content": {"title": "", "reply": "Thank you for the comments.\r\n\r\nWe have experimented with single network classifiers that have increased field of view due to additional downsampling layers. These additional (3x, 4x) downsampling layers yield comparable performance to the multiscale (1x and 2x downsampling) architecture presented in the main paper. This suggests that the recursively stacked architectures are giving increased performance due to the increased depth rather than field of view alone.\r\n\r\nRelated to this, in A.2 of the Supplementary section, we present results using a deeper unsupervised architecture.  This has slightly larger field of view than the stacked classifiers, but somewhat worse performance, again suggesting the benefit of the recursive stacking.\r\n\r\nWe experimented with deeper MLP classifiers, and report results in the supplementary section of the paper (Table 11). Going to 2 to 3 hidden layers gives some amount of improvement.\r\n\r\nWe report number of parameters in the models used in the paper in Table 5.\r\n\r\nWe will also be releasing the data in addition to the code. One of the distinguishing features of our problem domain is the amount of data, where future data sets will require processing of data sets orders of magnitude larger than the 620^3 volumes used in the paper. Our methods were designed with scalability and fast training and inference in mind, and therefore we believe our results and paper should be of interest to other researchers working on problems similarly involving large data sets."}, "nonreaders": [], "details": {"replyCount": 0, "overwriting": [], "revisions": false, "forumContent": {"title": "Deep and Wide Multiscale Recursive Networks for Robust Image Labeling", "decision": "submitted, no decision", "abstract": "Feedforward multilayer networks trained by supervised learning have recently demonstrated state of the art performance on image labeling problems such as boundary prediction and scene parsing. As even very low error rates can limit practical usage of such systems, methods that perform closer to human accuracy remain desirable. In this work, we propose a new type of network with the following properties that address what we hypothesize to be limiting aspects of existing methods: (1) a `wide' structure with thousands of features, (2) a large field of view, (3) recursive iterations that exploit statistical dependencies in label space, and (4) a parallelizable architecture that can be trained in a fraction of the time compared to benchmark multilayer convolutional networks. For the specific image labeling problem of boundary prediction, we also introduce a novel example weighting algorithm that improves segmentation accuracy. Experiments in the challenging domain of connectomic reconstruction of neural circuity from 3d electron microscopy data show that these 'Deep And Wide Multiscale Recursive' (DAWMR) networks lead to new levels of image labeling performance. The highest performing architecture has twelve layers, interwoven supervised and unsupervised stages, and uses an input field of view of 157,464 voxels ($54^3$) to make a prediction at each image location. We present an associated open source software package that enables the simple and flexible creation of DAWMR networks.", "pdf": "https://arxiv.org/abs/1310.0354", "paperhash": "huang|deep_and_wide_multiscale_recursive_networks_for_robust_image_labeling", "keywords": [], "conflicts": [], "authors": ["Gary B. Huang", "Viren Jain"], "authorids": ["huangg@janelia.hhmi.org", "jainv@janelia.hhmi.org"]}, "tags": [], "invitation": {}}}, {"ddate": null, "legacy_migration": true, "tmdate": 1392750060000, "tcdate": 1392750060000, "number": 1, "id": "1cSPcFTqMt9Lf", "invitation": "ICLR.cc/2014/-/submission/conference/reply", "forum": "HH-uZ8U2O1aWf", "replyto": "sQS9F67Of2QaU", "signatures": ["Gary Huang"], "readers": ["everyone"], "writers": ["anonymous"], "content": {"title": "", "reply": "Thank you for the comments.\r\n\r\nOur DAWMR networks can also be applied to 2d images. However, one of the main focuses of our work was to develop a method that is scalable to very large data sets. For instance, our training and test volumes were 620^3 voxels, and we intend to scale to problems that are more than 10 times this size in each dimension. So this can preclude more sophisticated learning algorithms that are computationally tractable for smaller 2d data sets. Therefore a strict comparison against state-of-the-art 2d segmentation methods may be of limited use.\r\n\r\nOur use of multiple metrics for evaluation is motivated by the fact that our networks are often used as part of a larger pipeline, where the network output is thresholded and used to produce supervoxels, which are input to the next step of the pipeline. The ideal metric would therefore be based on the final output produced by the entire pipeline. However, we present both local edge prediction metrics as well as more global segmentation metrics to give a more complete sense of the quality of the network output and how it would likely influence the final pipeline output accuracy. We note though that the differences between competing architectures (e.g., Table 6 in the paper) are generally both large and consistent across metrics."}, "nonreaders": [], "details": {"replyCount": 0, "overwriting": [], "revisions": false, "forumContent": {"title": "Deep and Wide Multiscale Recursive Networks for Robust Image Labeling", "decision": "submitted, no decision", "abstract": "Feedforward multilayer networks trained by supervised learning have recently demonstrated state of the art performance on image labeling problems such as boundary prediction and scene parsing. As even very low error rates can limit practical usage of such systems, methods that perform closer to human accuracy remain desirable. In this work, we propose a new type of network with the following properties that address what we hypothesize to be limiting aspects of existing methods: (1) a `wide' structure with thousands of features, (2) a large field of view, (3) recursive iterations that exploit statistical dependencies in label space, and (4) a parallelizable architecture that can be trained in a fraction of the time compared to benchmark multilayer convolutional networks. For the specific image labeling problem of boundary prediction, we also introduce a novel example weighting algorithm that improves segmentation accuracy. Experiments in the challenging domain of connectomic reconstruction of neural circuity from 3d electron microscopy data show that these 'Deep And Wide Multiscale Recursive' (DAWMR) networks lead to new levels of image labeling performance. The highest performing architecture has twelve layers, interwoven supervised and unsupervised stages, and uses an input field of view of 157,464 voxels ($54^3$) to make a prediction at each image location. We present an associated open source software package that enables the simple and flexible creation of DAWMR networks.", "pdf": "https://arxiv.org/abs/1310.0354", "paperhash": "huang|deep_and_wide_multiscale_recursive_networks_for_robust_image_labeling", "keywords": [], "conflicts": [], "authors": ["Gary B. Huang", "Viren Jain"], "authorids": ["huangg@janelia.hhmi.org", "jainv@janelia.hhmi.org"]}, "tags": [], "invitation": {}}}, {"ddate": null, "legacy_migration": true, "tmdate": 1391841720000, "tcdate": 1391841720000, "number": 3, "id": "sQS9F67Of2QaU", "invitation": "ICLR.cc/2014/-/submission/conference/review", "forum": "HH-uZ8U2O1aWf", "replyto": "HH-uZ8U2O1aWf", "signatures": ["anonymous reviewer d8ff"], "readers": ["everyone"], "writers": ["anonymous"], "content": {"title": "review of Deep and Wide Multiscale Recursive Networks for Robust Image Labeling", "review": "This work presents an approach for 3d imaging analysis that tries to improve on previous work by addressing the limiting aspects of the existing methods. The paper presents 3 main contributions:\r\na fast-training wide network, a recursive approach, and a weighting scheme to pull the focus of the training towards harder cases.\r\n\r\nThis paper is well written, well structured and flows well. The results show that the methods proposed \r\nimprove performance on the 3d image annotation task. The 3 contributions are tested and stacked one-by-one and each is shown to improve performance.\r\n\r\nGenereal comment:\r\nCan the improvements proposed in this paper be applied to 2d images as well? It would have been interesting to see an application to a benchmark dataset to have a comparison with current state-of-the-art methods.\r\n\r\nPros:\r\n - Well justified improvements that show clear improvements.\r\n - Open source software is presented.\r\n\r\nCons:\r\n - Many metrics are presented, though, as a non-expert, it is hard to judge which metrics are more relevant."}, "nonreaders": [], "details": {"replyCount": 0, "overwriting": [], "revisions": false, "forumContent": {"title": "Deep and Wide Multiscale Recursive Networks for Robust Image Labeling", "decision": "submitted, no decision", "abstract": "Feedforward multilayer networks trained by supervised learning have recently demonstrated state of the art performance on image labeling problems such as boundary prediction and scene parsing. As even very low error rates can limit practical usage of such systems, methods that perform closer to human accuracy remain desirable. In this work, we propose a new type of network with the following properties that address what we hypothesize to be limiting aspects of existing methods: (1) a `wide' structure with thousands of features, (2) a large field of view, (3) recursive iterations that exploit statistical dependencies in label space, and (4) a parallelizable architecture that can be trained in a fraction of the time compared to benchmark multilayer convolutional networks. For the specific image labeling problem of boundary prediction, we also introduce a novel example weighting algorithm that improves segmentation accuracy. Experiments in the challenging domain of connectomic reconstruction of neural circuity from 3d electron microscopy data show that these 'Deep And Wide Multiscale Recursive' (DAWMR) networks lead to new levels of image labeling performance. The highest performing architecture has twelve layers, interwoven supervised and unsupervised stages, and uses an input field of view of 157,464 voxels ($54^3$) to make a prediction at each image location. We present an associated open source software package that enables the simple and flexible creation of DAWMR networks.", "pdf": "https://arxiv.org/abs/1310.0354", "paperhash": "huang|deep_and_wide_multiscale_recursive_networks_for_robust_image_labeling", "keywords": [], "conflicts": [], "authors": ["Gary B. Huang", "Viren Jain"], "authorids": ["huangg@janelia.hhmi.org", "jainv@janelia.hhmi.org"]}, "tags": [], "invitation": {}}}, {"ddate": null, "legacy_migration": true, "tmdate": 1391830680000, "tcdate": 1391830680000, "number": 2, "id": "9zq_LwBP3U9bA", "invitation": "ICLR.cc/2014/-/submission/conference/review", "forum": "HH-uZ8U2O1aWf", "replyto": "HH-uZ8U2O1aWf", "signatures": ["anonymous reviewer cf06"], "readers": ["everyone"], "writers": ["anonymous"], "content": {"title": "review of Deep and Wide Multiscale Recursive Networks for Robust Image Labeling", "review": "This paper presents the application of a composite classification system to the classification of 3D microscopy scans. \r\nThe problem is formulated as predicting an affinity graph (binary classification 'pixels belong to same foreground object' vs other cases).\r\nThe classifier is a composite construction from supervised and unsupervised methods: vector quantization, pooling, subsampling, whitening and a 1-hidden-layer neural network. \r\n\r\nAlternative classifier architectures are explored (using multiscale or single scale VQ, \r\n\r\nThese classifiers are stacked ('recursively') with the resulting classifier performing better, though it is not clear where the improvement comes: increased depth or increased field of view.\r\n\r\nHow does this work if you make the classification MLP deeper? \r\n\r\nI would like to see comparisons of the different techniques in terms of number of parameters. \r\n\r\nDescribes an interesting composite architecture on a specialist problem, with 3D data. It is interesting to see the comparison of this composite classifier approach and the effectiveness of stacking. \r\n\r\nPros: \r\nInteresting comparison of a more hand-built approach to a CNN.\r\nInteresting to see application to 3D data\r\nInteresting to see the effectiveness of stacking. \r\n\r\nCons: \r\nA somewhat specialist problem (and proprietary data) limit the audience and\r\napplicability of the results."}, "nonreaders": [], "details": {"replyCount": 0, "overwriting": [], "revisions": false, "forumContent": {"title": "Deep and Wide Multiscale Recursive Networks for Robust Image Labeling", "decision": "submitted, no decision", "abstract": "Feedforward multilayer networks trained by supervised learning have recently demonstrated state of the art performance on image labeling problems such as boundary prediction and scene parsing. As even very low error rates can limit practical usage of such systems, methods that perform closer to human accuracy remain desirable. In this work, we propose a new type of network with the following properties that address what we hypothesize to be limiting aspects of existing methods: (1) a `wide' structure with thousands of features, (2) a large field of view, (3) recursive iterations that exploit statistical dependencies in label space, and (4) a parallelizable architecture that can be trained in a fraction of the time compared to benchmark multilayer convolutional networks. For the specific image labeling problem of boundary prediction, we also introduce a novel example weighting algorithm that improves segmentation accuracy. Experiments in the challenging domain of connectomic reconstruction of neural circuity from 3d electron microscopy data show that these 'Deep And Wide Multiscale Recursive' (DAWMR) networks lead to new levels of image labeling performance. The highest performing architecture has twelve layers, interwoven supervised and unsupervised stages, and uses an input field of view of 157,464 voxels ($54^3$) to make a prediction at each image location. We present an associated open source software package that enables the simple and flexible creation of DAWMR networks.", "pdf": "https://arxiv.org/abs/1310.0354", "paperhash": "huang|deep_and_wide_multiscale_recursive_networks_for_robust_image_labeling", "keywords": [], "conflicts": [], "authors": ["Gary B. Huang", "Viren Jain"], "authorids": ["huangg@janelia.hhmi.org", "jainv@janelia.hhmi.org"]}, "tags": [], "invitation": {}}}, {"ddate": null, "legacy_migration": true, "tmdate": 1391828100000, "tcdate": 1391828100000, "number": 1, "id": "KEpWdQPiWrEqF", "invitation": "ICLR.cc/2014/-/submission/conference/review", "forum": "HH-uZ8U2O1aWf", "replyto": "HH-uZ8U2O1aWf", "signatures": ["anonymous reviewer 395a"], "readers": ["everyone"], "writers": ["anonymous"], "content": {"title": "review of Deep and Wide Multiscale Recursive Networks for Robust Image Labeling", "review": "An architecture for labeling neural components in electron microscopy images is presented based on a combination of unsupervised feature learning and supervised classification.  The proposed system learns a basic feature representation using vector quantization applied to small patches.  Several strategies for combining the extracted features into a hidden representation are proposed, and these features are passed to a supervised learning stage to predict an \u201caffinity graph\u201d which encodes the segmentation of image components.  Subsequent stages of features are generated by computing additional features from the predicted affinity graph and the original input image in the hope of learning features that better represent the output domain.  Several modifications are proposed to improve performance, including a \u201chard example mining\u201d strategy to up-weight regions of input images that are difficult to segment properly.  Results are presented on a test set, with validation numbers provided for numerous variations of the proposed architecture.  It is shown that the best system widely outperforms a baseline conv-net on many quality metrics.\r\n \r\nThis paper covers an interesting application domain that requires a reasonably scalable learning approach as well as some novel components to properly predict the structures desired.  In that direction, it may be interesting to other experts wanting to achieve maximum performance on this application.  \r\n\r\nOther than the CNN baseline, it is hard to know how difficult this problem is, since the dataset is apparently novel.  On the other hand, the paper takes a \u201ckitchen sink\u201d approach to selecting an appropriate algorithm (as evidenced by the complex pipeline and extensive appendix with additional variations).   It is, thus, difficult to know whether the improvements are coming from these particular innovations or from some other source.  For example, in some cases it is clear that the addition of multi-scale or more layers of features reduces the training error significantly and it could be that other more orthodox architectures could achieve similar results.   What insight should a reader interested in other domains distill from these results?\r\n \r\nPros:\r\n\r\nInteresting application involving a structured output, though similar to image segmentation.\r\nAuthors cover a wide search through a novel type of architecture to yield a successful labeler.  May be valuable to domain experts.\r\n\r\nCons:\r\n\r\nA complex pipeline that combines many components [from prior art], making it hard to see what is contributed outside of this particular application.\r\nDifficult for non-expert to judge quality of results.\r\n \r\nOther comments:\r\nThe addition of dropout appears to enhance generalization (along with several of the other modifications).  This might help the CN baseline as well.  It may be useful / interesting to understand what explains the improved generalization.  (E.g., is the CN overfitting, and this avoided by the use of unsupervised training?)"}, "nonreaders": [], "details": {"replyCount": 0, "overwriting": [], "revisions": false, "forumContent": {"title": "Deep and Wide Multiscale Recursive Networks for Robust Image Labeling", "decision": "submitted, no decision", "abstract": "Feedforward multilayer networks trained by supervised learning have recently demonstrated state of the art performance on image labeling problems such as boundary prediction and scene parsing. As even very low error rates can limit practical usage of such systems, methods that perform closer to human accuracy remain desirable. In this work, we propose a new type of network with the following properties that address what we hypothesize to be limiting aspects of existing methods: (1) a `wide' structure with thousands of features, (2) a large field of view, (3) recursive iterations that exploit statistical dependencies in label space, and (4) a parallelizable architecture that can be trained in a fraction of the time compared to benchmark multilayer convolutional networks. For the specific image labeling problem of boundary prediction, we also introduce a novel example weighting algorithm that improves segmentation accuracy. Experiments in the challenging domain of connectomic reconstruction of neural circuity from 3d electron microscopy data show that these 'Deep And Wide Multiscale Recursive' (DAWMR) networks lead to new levels of image labeling performance. The highest performing architecture has twelve layers, interwoven supervised and unsupervised stages, and uses an input field of view of 157,464 voxels ($54^3$) to make a prediction at each image location. We present an associated open source software package that enables the simple and flexible creation of DAWMR networks.", "pdf": "https://arxiv.org/abs/1310.0354", "paperhash": "huang|deep_and_wide_multiscale_recursive_networks_for_robust_image_labeling", "keywords": [], "conflicts": [], "authors": ["Gary B. Huang", "Viren Jain"], "authorids": ["huangg@janelia.hhmi.org", "jainv@janelia.hhmi.org"]}, "tags": [], "invitation": {}}}, {"replyto": null, "ddate": null, "legacy_migration": true, "tmdate": 1387329900000, "tcdate": 1387329900000, "number": 1, "id": "HH-uZ8U2O1aWf", "invitation": "ICLR.cc/2014/conference/-/submission", "forum": "HH-uZ8U2O1aWf", "signatures": ["huangg@janelia.hhmi.org"], "readers": ["everyone"], "content": {"title": "Deep and Wide Multiscale Recursive Networks for Robust Image Labeling", "decision": "submitted, no decision", "abstract": "Feedforward multilayer networks trained by supervised learning have recently demonstrated state of the art performance on image labeling problems such as boundary prediction and scene parsing. As even very low error rates can limit practical usage of such systems, methods that perform closer to human accuracy remain desirable. In this work, we propose a new type of network with the following properties that address what we hypothesize to be limiting aspects of existing methods: (1) a `wide' structure with thousands of features, (2) a large field of view, (3) recursive iterations that exploit statistical dependencies in label space, and (4) a parallelizable architecture that can be trained in a fraction of the time compared to benchmark multilayer convolutional networks. For the specific image labeling problem of boundary prediction, we also introduce a novel example weighting algorithm that improves segmentation accuracy. Experiments in the challenging domain of connectomic reconstruction of neural circuity from 3d electron microscopy data show that these 'Deep And Wide Multiscale Recursive' (DAWMR) networks lead to new levels of image labeling performance. The highest performing architecture has twelve layers, interwoven supervised and unsupervised stages, and uses an input field of view of 157,464 voxels ($54^3$) to make a prediction at each image location. We present an associated open source software package that enables the simple and flexible creation of DAWMR networks.", "pdf": "https://arxiv.org/abs/1310.0354", "paperhash": "huang|deep_and_wide_multiscale_recursive_networks_for_robust_image_labeling", "keywords": [], "conflicts": [], "authors": ["Gary B. Huang", "Viren Jain"], "authorids": ["huangg@janelia.hhmi.org", "jainv@janelia.hhmi.org"]}, "writers": [], "details": {"replyCount": 6, "writable": false, "overwriting": [], "revisions": false, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1369422751717, "tmdate": 1496674357195, "id": "ICLR.cc/2014/conference/-/submission", "writers": ["ICLR.cc/2014"], "signatures": ["OpenReview.net"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": null, "replyto": null, "writers": {"values-regex": "~.*"}, "signatures": {"values-regex": "~.*", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"pdf": {"required": true, "order": 5, "description": "Either upload a PDF file or provide a direct link to your PDF on ArXiv (link must begin with http(s) and end with .pdf)", "value-regex": "upload|(http|https):\\/\\/.+\\.pdf"}, "title": {"required": true, "order": 1, "description": "Title of paper.", "value-regex": ".{1,250}"}, "abstract": {"required": true, "order": 4, "description": "Abstract of paper.", "value-regex": "[\\S\\s]{1,5000}"}, "authors": {"required": true, "order": 2, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of author names, as they appear in the paper."}, "conflicts": {"required": true, "order": 100, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of email domains of people who would have a conflict of interest in reviewing this paper, (e.g., cs.umass.edu;google.com, etc.)."}, "keywords": {"order": 6, "description": "Comma separated list of keywords.", "values-dropdown": []}, "authorids": {"required": true, "order": 3, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of author email addresses, in the same order as above."}}}, "nonreaders": [], "noninvitees": [], "expdate": 1377198751717, "cdate": 1496674357195}}}], "count": 7}