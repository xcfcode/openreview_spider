{"notes": [{"id": "iWLByfvUhN", "original": "Y7Nql0d9VTS", "number": 2214, "cdate": 1601308243881, "ddate": null, "tcdate": 1601308243881, "tmdate": 1615850664405, "tddate": null, "forum": "iWLByfvUhN", "replyto": null, "invitation": "ICLR.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Decoupling Global and Local Representations via Invertible Generative Flows", "authorids": ["~Xuezhe_Ma1", "~Xiang_Kong1", "~Shanghang_Zhang4", "~Eduard_H_Hovy1"], "authors": ["Xuezhe Ma", "Xiang Kong", "Shanghang Zhang", "Eduard H Hovy"], "keywords": ["Generative Models", "Generative Flow", "Normalizing Flow", "Image Generation", "Representation Learning"], "abstract": "In this work, we propose a new generative model that is capable of automatically decoupling global and local representations of images in an entirely unsupervised setting, by embedding a generative flow in the VAE framework to model the decoder.\nSpecifically, the proposed model utilizes the variational auto-encoding framework to learn a (low-dimensional) vector of latent variables to capture the global information of an image, which is fed as a conditional input to a flow-based invertible decoder with architecture borrowed from style transfer literature.\nExperimental results on standard image benchmarks demonstrate the effectiveness of our model in terms of density estimation, image generation and unsupervised representation learning.\nImportantly, this work demonstrates that with only architectural inductive biases, a generative model with a likelihood-based objective is capable of learning decoupled representations, requiring no explicit supervision.\nThe code for our model is available at \\url{https://github.com/XuezheMax/wolf}.", "one-sentence_summary": "Generative Flow for Decoupled Representation Learning", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "ma|decoupling_global_and_local_representations_via_invertible_generative_flows", "pdf": "/pdf/f2b3766907999d10ac5b2857ad661bce8495fe3c.pdf", "supplementary_material": "", "venue": "ICLR 2021 Poster", "venueid": "ICLR.cc/2021/Conference", "_bibtex": "@inproceedings{\nma2021decoupling,\ntitle={Decoupling Global and Local Representations via Invertible Generative Flows},\nauthor={Xuezhe Ma and Xiang Kong and Shanghang Zhang and Eduard H Hovy},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=iWLByfvUhN}\n}"}, "signatures": ["ICLR.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference"], "details": {"replyCount": 13, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"reply": {"readers": {"values-regex": ".*"}, "writers": {"values": ["ICLR.cc/2021/Conference"]}, "signatures": {"values": ["ICLR.cc/2021/Conference"]}, "content": {"authors": {"values": ["Anonymous"]}, "authorids": {"values-regex": ".*"}, "reviewed_version_(pdf)": {"required": false, "description": "Upload a PDF file that ends with .pdf", "value-regex": ".*"}}}, "signatures": ["ICLR.cc/2021/Conference"], "readers": ["everyone"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["~", "OpenReview.net/Support"], "tcdate": 1601308008205, "tmdate": 1614984599368, "id": "ICLR.cc/2021/Conference/-/Blind_Submission"}}, "tauthor": "OpenReview.net"}, {"id": "-s-A0BR8y7R", "original": null, "number": 1, "cdate": 1610040376552, "ddate": null, "tcdate": 1610040376552, "tmdate": 1610473968853, "tddate": null, "forum": "iWLByfvUhN", "replyto": "iWLByfvUhN", "invitation": "ICLR.cc/2021/Conference/Paper2214/-/Decision", "content": {"title": "Final Decision", "decision": "Accept (Poster)", "comment": "The paper proposes a hybrid VAE-normalizing-flow for extracting local and global representations of images.  While the reviewers found the model itself to be \"conceptually simple\" and \"straightforward\", all were convinced by the empirical evaluation that, indeed, interesting representation learning is going on, resulting in a unanimous vote to accept."}, "signatures": ["ICLR.cc/2021/Conference/Program_Chairs"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference/Program_Chairs"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Decoupling Global and Local Representations via Invertible Generative Flows", "authorids": ["~Xuezhe_Ma1", "~Xiang_Kong1", "~Shanghang_Zhang4", "~Eduard_H_Hovy1"], "authors": ["Xuezhe Ma", "Xiang Kong", "Shanghang Zhang", "Eduard H Hovy"], "keywords": ["Generative Models", "Generative Flow", "Normalizing Flow", "Image Generation", "Representation Learning"], "abstract": "In this work, we propose a new generative model that is capable of automatically decoupling global and local representations of images in an entirely unsupervised setting, by embedding a generative flow in the VAE framework to model the decoder.\nSpecifically, the proposed model utilizes the variational auto-encoding framework to learn a (low-dimensional) vector of latent variables to capture the global information of an image, which is fed as a conditional input to a flow-based invertible decoder with architecture borrowed from style transfer literature.\nExperimental results on standard image benchmarks demonstrate the effectiveness of our model in terms of density estimation, image generation and unsupervised representation learning.\nImportantly, this work demonstrates that with only architectural inductive biases, a generative model with a likelihood-based objective is capable of learning decoupled representations, requiring no explicit supervision.\nThe code for our model is available at \\url{https://github.com/XuezheMax/wolf}.", "one-sentence_summary": "Generative Flow for Decoupled Representation Learning", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "ma|decoupling_global_and_local_representations_via_invertible_generative_flows", "pdf": "/pdf/f2b3766907999d10ac5b2857ad661bce8495fe3c.pdf", "supplementary_material": "", "venue": "ICLR 2021 Poster", "venueid": "ICLR.cc/2021/Conference", "_bibtex": "@inproceedings{\nma2021decoupling,\ntitle={Decoupling Global and Local Representations via Invertible Generative Flows},\nauthor={Xuezhe Ma and Xiang Kong and Shanghang Zhang and Eduard H Hovy},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=iWLByfvUhN}\n}"}, "tags": [], "invitation": {"reply": {"forum": "iWLByfvUhN", "replyto": "iWLByfvUhN", "readers": {"values": ["everyone"]}, "writers": {"values": ["ICLR.cc/2021/Conference/Program_Chairs"]}, "signatures": {"values": ["ICLR.cc/2021/Conference/Program_Chairs"]}, "content": {"title": {"value": "Final Decision"}, "decision": {"value-radio": ["Accept (Oral)", "Accept (Spotlight)", "Accept (Poster)", "Reject"]}, "comment": {"value-regex": "[\\S\\s]{0,50000}", "markdown": true}}}, "multiReply": false, "signatures": ["ICLR.cc/2021/Conference"], "readers": ["everyone"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Program_Chairs"], "tcdate": 1610040376538, "tmdate": 1610473968837, "id": "ICLR.cc/2021/Conference/Paper2214/-/Decision"}}}, {"id": "xFd-KbHWUUz", "original": null, "number": 10, "cdate": 1606279621671, "ddate": null, "tcdate": 1606279621671, "tmdate": 1606279621671, "tddate": null, "forum": "iWLByfvUhN", "replyto": "yGVRNhSZWC", "invitation": "ICLR.cc/2021/Conference/Paper2214/-/Official_Comment", "content": {"title": "Thanks for your feedback!", "comment": "Thanks for your feedback. We have revised the submission to fix the typos you pointed out. We will add the experiments of multiple samples from the decoder for a fixed z in later revisions."}, "signatures": ["ICLR.cc/2021/Conference/Paper2214/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2214/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Decoupling Global and Local Representations via Invertible Generative Flows", "authorids": ["~Xuezhe_Ma1", "~Xiang_Kong1", "~Shanghang_Zhang4", "~Eduard_H_Hovy1"], "authors": ["Xuezhe Ma", "Xiang Kong", "Shanghang Zhang", "Eduard H Hovy"], "keywords": ["Generative Models", "Generative Flow", "Normalizing Flow", "Image Generation", "Representation Learning"], "abstract": "In this work, we propose a new generative model that is capable of automatically decoupling global and local representations of images in an entirely unsupervised setting, by embedding a generative flow in the VAE framework to model the decoder.\nSpecifically, the proposed model utilizes the variational auto-encoding framework to learn a (low-dimensional) vector of latent variables to capture the global information of an image, which is fed as a conditional input to a flow-based invertible decoder with architecture borrowed from style transfer literature.\nExperimental results on standard image benchmarks demonstrate the effectiveness of our model in terms of density estimation, image generation and unsupervised representation learning.\nImportantly, this work demonstrates that with only architectural inductive biases, a generative model with a likelihood-based objective is capable of learning decoupled representations, requiring no explicit supervision.\nThe code for our model is available at \\url{https://github.com/XuezheMax/wolf}.", "one-sentence_summary": "Generative Flow for Decoupled Representation Learning", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "ma|decoupling_global_and_local_representations_via_invertible_generative_flows", "pdf": "/pdf/f2b3766907999d10ac5b2857ad661bce8495fe3c.pdf", "supplementary_material": "", "venue": "ICLR 2021 Poster", "venueid": "ICLR.cc/2021/Conference", "_bibtex": "@inproceedings{\nma2021decoupling,\ntitle={Decoupling Global and Local Representations via Invertible Generative Flows},\nauthor={Xuezhe Ma and Xiang Kong and Shanghang Zhang and Eduard H Hovy},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=iWLByfvUhN}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "iWLByfvUhN", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper2214/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper2214/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper2214/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper2214/Authors|ICLR.cc/2021/Conference/Paper2214/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2214/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923850975, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper2214/-/Official_Comment"}}}, {"id": "yGVRNhSZWC", "original": null, "number": 3, "cdate": 1603907546630, "ddate": null, "tcdate": 1603907546630, "tmdate": 1606263633814, "tddate": null, "forum": "iWLByfvUhN", "replyto": "iWLByfvUhN", "invitation": "ICLR.cc/2021/Conference/Paper2214/-/Official_Review", "content": {"title": "Interesting general ideas, but critical flaws in the presentation", "review": "##### Summary\n\nThis paper aims to improve a Normalizing Flow generative model, in particular\nGlow, by conditioning the flow on global information of the image in the form\nof a latent vector learned with the VAE framework. This latent vector is\ninjected at the scale and bias terms of the affine coupling layers of the flow\n(inspired by what Style-GAN does at the batchnorm layers). \n\nUnfortunately, critical aspects of the method remain unclear or unspecified. To\nthe best of my understanding, the paper lacks a clear explanation of the\ncomplete pipeline used for training the method and the final objective\nfunction. For evaluation, sampling and likelihood computation, procedures are\nnot completely specified either.\n\n##### Pros\n- The general ideas of the paper are well motivated. Combining the advantages of\n  explicit likelihood and latent variable generative models is in my opinion an\n  extremely interesting research direction.\n- The authors propose architectural improvements to Glow and craft a conditional\n  version that can effectively incorporate additional information to the flow.\n- The authors model achieves improved or competitive density estimation,\n  sampling, and downstream performance across various datasets, compared to the\n  state-of-the-art.\n- Some degree of local and global properties disentanglement is demonstrated in\n  the qualitative results, showing the proposed direction is a promising one in\n  that regard.\n\n#####  Cons\nThe main drawback is in my view the presentation of the method. The method part\nof the paper (Section 2) mixes theoretical justification with architecture\ndetails and fails to clearly explain the full pipeline and training\nobjective. This made it very difficult if not impossible to analyze it and draw\nconclusions. The second half of the paper is dedicated to experimental results,\nyet the sampling procedure and likelihood computation are not clearly explained\neither.\n\nI think the submission would have been much stronger if the authors clearly\nexplained the whole method and dedicated more of the paper to a careful analysis\nand justification of the design decisions and of some of the claims\n(e.g. avoiding posterior collapse, global/local disentanglement).\n\n \n\nGoing into detail, by reading the abstract I get the impression that the VAE\nframework is used, and the normalizing flow is used to model the generative\ndistribution $p(x|z)$. Yet the abstract also claims to only use a plain\nlog-likelihood objective as in explicit likelihood models, instead of the VAE\nELBO. Alternatively, I thought the latent code was learned with a separate VAE,\nbut the introduction states that the generative flow is \"[embedded] in the VAE\nframework to model the decoder\".\n\nAssuming that the VAE framework is used with a (conditional) normalizing flow\nfor decoder, Section 2 introduces more confusion when the authors state \"we feed\n$z$ as a conditional input to a flow-based decoder, which transforms $x$ into\nthe representation $\\nu$ with the same dimension.\" This is confusing since\ntypically the decoder input should be a low-dimensional representation, but here\nit seems to be the image as well, so the concept of decoding seems ill\nplaced. Moreover, if this is the case, what would be the point of the\nreconstruction term in the ELBO if invertibility guarantees perfect\nreconstruction? Shouldn't the flow output $\\nu$ be a stochastic latent code as\nin VAEs? Is a prior density regularization imposed on $\\nu$ as well?\n\nFinally, another option would be that everything is trained with the negative\nlog-likelihood cost of the normalizing flow. This would be consistent with the\nclaim in the abstract that only a plain log-likelihood is utilized. But in that\ncase, what is the justification for using a stochastic encoder if it is not\nregularized? How can it be guaranteed that $z$ will not be ignored? What is the\nrole of $z$ during sampling? Does the likelihood computation involve $z$ or just\n$\\nu$?\n\nI apologize for writing my internal thought process but I also wanted to convey\nthat even if the method was clarified to be some of the options I described, or\nanother one, many of the design decisions would still require extra justification\nand analysis.\n\n\nOther comments:\n- Although Figure 1 shows capturing of some global color properties, looking at\n  the interpolations in Figure 5, there seems to be little variability\n  w.r.t. $z$, so maybe the claims of learning \"decoupled\" and \"disentangled\"\n  representations require more justification.\n\n- About the initialization of the weights of the last linear layer with zeroes\n  (Section 2.1). Wouldn't this create a null output at thus a null backward\n  gradient in the first iteration? Even if a non-zero bias was used, wouldn't an\n  unbreakable symmetry condition be produced?\n\n\n************\nAfter Rebuttal:\n\nI thank the authors for their multiple clarifications, and apologize for my initial misunderstanding.\nI understand now that the flow model is used to compute $p(x|z)$ as a function of $x$ and $z$. Maybe the \"decoder\" terminology is a bit confusing here, but this is quite a nice idea overall. It would have been nice to see multiple samples from  $p(x|z)$ for a fixed $z$, to evaluate the expressiveness of the model.\n\nI'm raising my score to acceptance.\n\nPS: Some typos remain in the revised version, eg: \"varnishes\", \"tne\"\n", "rating": "6: Marginally above acceptance threshold", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["ICLR.cc/2021/Conference/Paper2214/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2214/AnonReviewer3"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Decoupling Global and Local Representations via Invertible Generative Flows", "authorids": ["~Xuezhe_Ma1", "~Xiang_Kong1", "~Shanghang_Zhang4", "~Eduard_H_Hovy1"], "authors": ["Xuezhe Ma", "Xiang Kong", "Shanghang Zhang", "Eduard H Hovy"], "keywords": ["Generative Models", "Generative Flow", "Normalizing Flow", "Image Generation", "Representation Learning"], "abstract": "In this work, we propose a new generative model that is capable of automatically decoupling global and local representations of images in an entirely unsupervised setting, by embedding a generative flow in the VAE framework to model the decoder.\nSpecifically, the proposed model utilizes the variational auto-encoding framework to learn a (low-dimensional) vector of latent variables to capture the global information of an image, which is fed as a conditional input to a flow-based invertible decoder with architecture borrowed from style transfer literature.\nExperimental results on standard image benchmarks demonstrate the effectiveness of our model in terms of density estimation, image generation and unsupervised representation learning.\nImportantly, this work demonstrates that with only architectural inductive biases, a generative model with a likelihood-based objective is capable of learning decoupled representations, requiring no explicit supervision.\nThe code for our model is available at \\url{https://github.com/XuezheMax/wolf}.", "one-sentence_summary": "Generative Flow for Decoupled Representation Learning", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "ma|decoupling_global_and_local_representations_via_invertible_generative_flows", "pdf": "/pdf/f2b3766907999d10ac5b2857ad661bce8495fe3c.pdf", "supplementary_material": "", "venue": "ICLR 2021 Poster", "venueid": "ICLR.cc/2021/Conference", "_bibtex": "@inproceedings{\nma2021decoupling,\ntitle={Decoupling Global and Local Representations via Invertible Generative Flows},\nauthor={Xuezhe Ma and Xiang Kong and Shanghang Zhang and Eduard H Hovy},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=iWLByfvUhN}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq . ***Please remember to file the Code-of-Ethics report. Once you submitted the review, a link to the report will be visible in the bottom right corner of your review.***", "required": true, "markdown": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}, "forum": "iWLByfvUhN", "replyto": "iWLByfvUhN", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"], "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper2214/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1607428800000, "duedate": 1606752000000, "multiReply": false, "readers": ["everyone"], "tcdate": 1602538101445, "tmdate": 1606915765888, "super": "ICLR.cc/2021/Conference/-/Official_Review", "signatures": ["OpenReview.net"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Paper2214/Reviewers", "OpenReview.net/Support"], "id": "ICLR.cc/2021/Conference/Paper2214/-/Official_Review"}}}, {"id": "1Sog8bgqsyJ", "original": null, "number": 9, "cdate": 1606260782475, "ddate": null, "tcdate": 1606260782475, "tmdate": 1606260782475, "tddate": null, "forum": "iWLByfvUhN", "replyto": "7dyo3WVfTHo", "invitation": "ICLR.cc/2021/Conference/Paper2214/-/Official_Comment", "content": {"title": "Thanks for your feedback", "comment": "We appreciate your swift feedback and your suggestion to explicitly add an equation of the objective function in Section 2.1. \nWe have further revised the submission to reflect your suggestion."}, "signatures": ["ICLR.cc/2021/Conference/Paper2214/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2214/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Decoupling Global and Local Representations via Invertible Generative Flows", "authorids": ["~Xuezhe_Ma1", "~Xiang_Kong1", "~Shanghang_Zhang4", "~Eduard_H_Hovy1"], "authors": ["Xuezhe Ma", "Xiang Kong", "Shanghang Zhang", "Eduard H Hovy"], "keywords": ["Generative Models", "Generative Flow", "Normalizing Flow", "Image Generation", "Representation Learning"], "abstract": "In this work, we propose a new generative model that is capable of automatically decoupling global and local representations of images in an entirely unsupervised setting, by embedding a generative flow in the VAE framework to model the decoder.\nSpecifically, the proposed model utilizes the variational auto-encoding framework to learn a (low-dimensional) vector of latent variables to capture the global information of an image, which is fed as a conditional input to a flow-based invertible decoder with architecture borrowed from style transfer literature.\nExperimental results on standard image benchmarks demonstrate the effectiveness of our model in terms of density estimation, image generation and unsupervised representation learning.\nImportantly, this work demonstrates that with only architectural inductive biases, a generative model with a likelihood-based objective is capable of learning decoupled representations, requiring no explicit supervision.\nThe code for our model is available at \\url{https://github.com/XuezheMax/wolf}.", "one-sentence_summary": "Generative Flow for Decoupled Representation Learning", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "ma|decoupling_global_and_local_representations_via_invertible_generative_flows", "pdf": "/pdf/f2b3766907999d10ac5b2857ad661bce8495fe3c.pdf", "supplementary_material": "", "venue": "ICLR 2021 Poster", "venueid": "ICLR.cc/2021/Conference", "_bibtex": "@inproceedings{\nma2021decoupling,\ntitle={Decoupling Global and Local Representations via Invertible Generative Flows},\nauthor={Xuezhe Ma and Xiang Kong and Shanghang Zhang and Eduard H Hovy},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=iWLByfvUhN}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "iWLByfvUhN", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper2214/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper2214/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper2214/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper2214/Authors|ICLR.cc/2021/Conference/Paper2214/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2214/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923850975, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper2214/-/Official_Comment"}}}, {"id": "9D_EvlFkqq", "original": null, "number": 2, "cdate": 1603891426094, "ddate": null, "tcdate": 1603891426094, "tmdate": 1605956429689, "tddate": null, "forum": "iWLByfvUhN", "replyto": "iWLByfvUhN", "invitation": "ICLR.cc/2021/Conference/Paper2214/-/Official_Review", "content": {"title": "Review for Decoupling Global and Local ....", "review": "The paper introduces a mixture of flows with the specific intent to disentangle global and local representations, to improve visual quality of samples. Architectures are borrowed from style-gan literature. The contributions are mainly architectural and empirical. The demonstrates improved visual quality over other normalizing flow methods. \n\nStrengths\nThe paper introduces a straightforward latent variable model for flows which is designed in such a way that training on NLL gives good sample quality, which is measured in FID. Even further, the model also performs quite well on the NLL objective itself. Since the focus of normalizing flow literature has been mainly on NLL, I think this paper is a nice complement to existing literature. \n\nWeaknesses:\n- The paper never puts the equations from the background section together in the final objective. It would be helpful to have an equation representing the final objective with some of the relevant variables (i.e. log p(x) >= ... with variables x, z, and v). \n- The paper does not introduce many novel theory or methods. This is not really a problem, but the paper can be better connected to existing work and clarified in this respect. The model the authors propose is very reminiscent of \"infinite mixtures of flows\" as outlined by (Papamakarios et al. \"Normalizing Flows for Probabilistic Modeling and Inference\" page 32). An example would be \"Continuously Index Flows\" by Cornish et al.. Note their method was introduced with a different intend in a different manner, so I think it would only make the paper better by citing these methods. \n- Conditioning on a context variable in flow layers is not new (see Kingma et al., \"Improved variational inference with inverse autoregressive flow.\"  and Lu et al. \"Structured Output Learning with Conditional Generative Flows.\"). This is not really a problem, but again this should be clarified. \n- How much added computation is required by the encoder model plus FCnet in eq. 7 compared to the Glow-refined model on which the proposed method is based? \n- Perhaps the naming \"compressing encoder\" is not particularly useful. It implies a direct connection to actual image compression, which is as far as I understand not the case. Other than that, this seems like a fairly standard VAE encoder other than the size difference between x and z.\n", "rating": "7: Good paper, accept", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["ICLR.cc/2021/Conference/Paper2214/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2214/AnonReviewer2"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Decoupling Global and Local Representations via Invertible Generative Flows", "authorids": ["~Xuezhe_Ma1", "~Xiang_Kong1", "~Shanghang_Zhang4", "~Eduard_H_Hovy1"], "authors": ["Xuezhe Ma", "Xiang Kong", "Shanghang Zhang", "Eduard H Hovy"], "keywords": ["Generative Models", "Generative Flow", "Normalizing Flow", "Image Generation", "Representation Learning"], "abstract": "In this work, we propose a new generative model that is capable of automatically decoupling global and local representations of images in an entirely unsupervised setting, by embedding a generative flow in the VAE framework to model the decoder.\nSpecifically, the proposed model utilizes the variational auto-encoding framework to learn a (low-dimensional) vector of latent variables to capture the global information of an image, which is fed as a conditional input to a flow-based invertible decoder with architecture borrowed from style transfer literature.\nExperimental results on standard image benchmarks demonstrate the effectiveness of our model in terms of density estimation, image generation and unsupervised representation learning.\nImportantly, this work demonstrates that with only architectural inductive biases, a generative model with a likelihood-based objective is capable of learning decoupled representations, requiring no explicit supervision.\nThe code for our model is available at \\url{https://github.com/XuezheMax/wolf}.", "one-sentence_summary": "Generative Flow for Decoupled Representation Learning", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "ma|decoupling_global_and_local_representations_via_invertible_generative_flows", "pdf": "/pdf/f2b3766907999d10ac5b2857ad661bce8495fe3c.pdf", "supplementary_material": "", "venue": "ICLR 2021 Poster", "venueid": "ICLR.cc/2021/Conference", "_bibtex": "@inproceedings{\nma2021decoupling,\ntitle={Decoupling Global and Local Representations via Invertible Generative Flows},\nauthor={Xuezhe Ma and Xiang Kong and Shanghang Zhang and Eduard H Hovy},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=iWLByfvUhN}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq . ***Please remember to file the Code-of-Ethics report. Once you submitted the review, a link to the report will be visible in the bottom right corner of your review.***", "required": true, "markdown": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}, "forum": "iWLByfvUhN", "replyto": "iWLByfvUhN", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"], "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper2214/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1607428800000, "duedate": 1606752000000, "multiReply": false, "readers": ["everyone"], "tcdate": 1602538101445, "tmdate": 1606915765888, "super": "ICLR.cc/2021/Conference/-/Official_Review", "signatures": ["OpenReview.net"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Paper2214/Reviewers", "OpenReview.net/Support"], "id": "ICLR.cc/2021/Conference/Paper2214/-/Official_Review"}}}, {"id": "7dyo3WVfTHo", "original": null, "number": 7, "cdate": 1605956411377, "ddate": null, "tcdate": 1605956411377, "tmdate": 1605956411377, "tddate": null, "forum": "iWLByfvUhN", "replyto": "kDvY6pFjE1c", "invitation": "ICLR.cc/2021/Conference/Paper2214/-/Official_Comment", "content": {"title": "Response", "comment": "I would like to thank the authors for their response and clarifications. In large part I am satisfied with the response. In my opinion having the objective more explicitly (sec 2.1) in addition to the description in text would still be preferable. I have raised my score to 7 because of the clarifications."}, "signatures": ["ICLR.cc/2021/Conference/Paper2214/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2214/AnonReviewer2"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Decoupling Global and Local Representations via Invertible Generative Flows", "authorids": ["~Xuezhe_Ma1", "~Xiang_Kong1", "~Shanghang_Zhang4", "~Eduard_H_Hovy1"], "authors": ["Xuezhe Ma", "Xiang Kong", "Shanghang Zhang", "Eduard H Hovy"], "keywords": ["Generative Models", "Generative Flow", "Normalizing Flow", "Image Generation", "Representation Learning"], "abstract": "In this work, we propose a new generative model that is capable of automatically decoupling global and local representations of images in an entirely unsupervised setting, by embedding a generative flow in the VAE framework to model the decoder.\nSpecifically, the proposed model utilizes the variational auto-encoding framework to learn a (low-dimensional) vector of latent variables to capture the global information of an image, which is fed as a conditional input to a flow-based invertible decoder with architecture borrowed from style transfer literature.\nExperimental results on standard image benchmarks demonstrate the effectiveness of our model in terms of density estimation, image generation and unsupervised representation learning.\nImportantly, this work demonstrates that with only architectural inductive biases, a generative model with a likelihood-based objective is capable of learning decoupled representations, requiring no explicit supervision.\nThe code for our model is available at \\url{https://github.com/XuezheMax/wolf}.", "one-sentence_summary": "Generative Flow for Decoupled Representation Learning", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "ma|decoupling_global_and_local_representations_via_invertible_generative_flows", "pdf": "/pdf/f2b3766907999d10ac5b2857ad661bce8495fe3c.pdf", "supplementary_material": "", "venue": "ICLR 2021 Poster", "venueid": "ICLR.cc/2021/Conference", "_bibtex": "@inproceedings{\nma2021decoupling,\ntitle={Decoupling Global and Local Representations via Invertible Generative Flows},\nauthor={Xuezhe Ma and Xiang Kong and Shanghang Zhang and Eduard H Hovy},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=iWLByfvUhN}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "iWLByfvUhN", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper2214/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper2214/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper2214/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper2214/Authors|ICLR.cc/2021/Conference/Paper2214/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2214/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923850975, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper2214/-/Official_Comment"}}}, {"id": "RDbPEvO4AV6", "original": null, "number": 6, "cdate": 1605920784268, "ddate": null, "tcdate": 1605920784268, "tmdate": 1605920784268, "tddate": null, "forum": "iWLByfvUhN", "replyto": "yGVRNhSZWC", "invitation": "ICLR.cc/2021/Conference/Paper2214/-/Official_Comment", "content": {"title": "Response to review by AnonReviewer3", "comment": "Thanks for your time and constructive comments! We appreciate your positive feedback on the good motivation, interesting research direction, architectural improvements, effective methods, and promising performance quantitatively and qualitatively. We have made several modifications to improve the presentation of our work. Please refer to the revision summary for more details: https://openreview.net/forum?id=iWLByfvUhN&noteId=Qr5bIoltAES\n\nWe respond below to your questions and comments. We kindly request that you briefly read these responses and let us know if they do not fully satisfy your concerns.\n\n>Q1: The main drawback is in my view the presentation of the method. The method part of the paper (Section 2) mixes theoretical justification with architecture details and fails to clearly explain the full pipeline and training objective. This made it very difficult if not impossible to analyze it and draw conclusions. The sampling procedure and likelihood computation are not clearly explained either.\n\nWe appreciate your suggestion to clearly explain the full pipeline and training objective. In our revised submission, we add Section 2.1 to illustrate the high-level architecture of our generative model, where we clearly say that ELBO is the training objective function. The formula of EBLO is provided in Eq. (2). \n\nWe also describe the generative process of our model in this section.\nMore explanation of sampling procedure and likelihood computation are also provided in Section 2.1\n\n>Q2: I think the submission would have been much stronger if the authors clearly explained the whole method and dedicated more of the paper to a careful analysis and justification of the design decisions and of some of the claims (e.g. avoiding posterior collapse, global/local disentanglement).\n\nWe appreciate your suggestion and have elaborated the section 2.4 to provide a high-level motivation of our model architecture design w.r.t tackling the two problems of posterior collapse in VAEs and local dependency in flows, and how the model decouples the global/local representations.\n\n>Q3: By reading the abstract I get the impression that the VAE framework is used, and the normalizing flow is used to model the generative distribution p(x|z). Yet the abstract also claims to only use a plain log-likelihood objective as in explicit likelihood models, instead of the VAE ELBO.\n\nWe apologize for the confusion. We use the VAE framework with ELBO as the training objective.\nWe have rewritten this into \u201clikelihood-based objective\u201d in the revised version to make it clearer.\n\n>Q4: Assuming that the VAE framework is used with a (conditional) normalizing flow for decoder, Section 2 introduces more confusion when the authors state \"we feed z as a conditional input to a flow-based decoder, which transforms x into the representation \u03bd with the same dimension.\" \n\nThanks for your questions. We have rewritten section 2.1 to separately describe the training and generative processes of our model. We have also added more explanations to answer your questions and make this section clearer.\n\nConcretely, In the training process, we need to compute the distribution $p(x|z)$.\nThus, X and Z are fed into the function $f$ of the flow-based decoder to compute the latent variables $\\upsilon$ of the generative flow (see section 1.2 for the introduction of generative flows).\nIn the generative process, we first sample $z$ and $\\upsilon$ from their prior distributions (typically normal distribution). Then we input $z$ and $\\upsilon$ into the inverse function $f^{-1}$ to generate an image $x = f_\\theta^{-1}(\\upsilon, z) = g_\\theta(\\upsilon, z)$.\n\n>Q5: I apologize for writing my internal thought process but I also wanted to convey that even if the method was clarified to be some of the options I described, or another one, many of the design decisions would still require extra justification and analysis.\n\nThanks for sharing your internal thoughts. We would like to point out that almost all the questions are from the presentation of our work. We have carefully revised our paper to address your concerns and added more justification and analysis in the [revised version](https://openreview.net/forum?id=iWLByfvUhN&noteId=Qr5bIoltAES). \n\n> About the initialization of the weights of the last linear layer with zeroes (Section 2.1). Wouldn't this create a null output at thus a null backward gradient in the first iteration?\n\nNote that in practice, we model $\\log \\sigma^2(x)$ instead of directly modeling $\\sigma^2(x)$. Thus, the zero-initialization produces a simple normal distribution for the posterior distribution at the beginning of training process, i.e. $\\mu(x)=0$ and $\\sigma^{2}(x) = 1$. This makes the training process much more stable at the first few updates. \n\nWe hope the above explanation and our revised paper can address your concerns and facilitate the understanding of our paper. We sincerely appreciate it if further feedback could be provided. \n\n"}, "signatures": ["ICLR.cc/2021/Conference/Paper2214/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2214/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Decoupling Global and Local Representations via Invertible Generative Flows", "authorids": ["~Xuezhe_Ma1", "~Xiang_Kong1", "~Shanghang_Zhang4", "~Eduard_H_Hovy1"], "authors": ["Xuezhe Ma", "Xiang Kong", "Shanghang Zhang", "Eduard H Hovy"], "keywords": ["Generative Models", "Generative Flow", "Normalizing Flow", "Image Generation", "Representation Learning"], "abstract": "In this work, we propose a new generative model that is capable of automatically decoupling global and local representations of images in an entirely unsupervised setting, by embedding a generative flow in the VAE framework to model the decoder.\nSpecifically, the proposed model utilizes the variational auto-encoding framework to learn a (low-dimensional) vector of latent variables to capture the global information of an image, which is fed as a conditional input to a flow-based invertible decoder with architecture borrowed from style transfer literature.\nExperimental results on standard image benchmarks demonstrate the effectiveness of our model in terms of density estimation, image generation and unsupervised representation learning.\nImportantly, this work demonstrates that with only architectural inductive biases, a generative model with a likelihood-based objective is capable of learning decoupled representations, requiring no explicit supervision.\nThe code for our model is available at \\url{https://github.com/XuezheMax/wolf}.", "one-sentence_summary": "Generative Flow for Decoupled Representation Learning", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "ma|decoupling_global_and_local_representations_via_invertible_generative_flows", "pdf": "/pdf/f2b3766907999d10ac5b2857ad661bce8495fe3c.pdf", "supplementary_material": "", "venue": "ICLR 2021 Poster", "venueid": "ICLR.cc/2021/Conference", "_bibtex": "@inproceedings{\nma2021decoupling,\ntitle={Decoupling Global and Local Representations via Invertible Generative Flows},\nauthor={Xuezhe Ma and Xiang Kong and Shanghang Zhang and Eduard H Hovy},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=iWLByfvUhN}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "iWLByfvUhN", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper2214/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper2214/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper2214/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper2214/Authors|ICLR.cc/2021/Conference/Paper2214/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2214/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923850975, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper2214/-/Official_Comment"}}}, {"id": "Qr5bIoltAES", "original": null, "number": 5, "cdate": 1605920139296, "ddate": null, "tcdate": 1605920139296, "tmdate": 1605920139296, "tddate": null, "forum": "iWLByfvUhN", "replyto": "iWLByfvUhN", "invitation": "ICLR.cc/2021/Conference/Paper2214/-/Official_Comment", "content": {"title": "Common Remarks and Summary of Revision v1", "comment": "We thank all the reviewers for their insightful and positive feedback. We are especially encouraged that they found the problem we focus on to be important and interesting (R3 & R4), and our motivation and idea to be clear, strong, and novel (R3 & R4). We are glad they found our approach to be effective and novel (R1, R2, R3 & R4), evaluated with extensive experiments (R1 & R3), convincing experiments that can justify the proposed model (R1 & R3), and achieving superior results (R1, R2, R3 & R4).\n\nWe summarize the revision as follows:\n\n1. Adding section 2.1 to illustrate the general framework of our generative model, including the training objective and the generative process. More explanation of Sampling procedure and likelihood computation are also provided.\n\n2. Revising the section 2.4 to provide a high-level motivation of our model architecture design w.r.t tackling the two problems of posterior collapse in VAEs and local dependency in flows, and how the model decouples the global/local representations.\n\n3. Adding more explanation of the method and more analysis and justification of the design and claims.\n\n4. Elaborating the section 4 of related work.\n\n5. Fixing typos and writing issues.\n\n"}, "signatures": ["ICLR.cc/2021/Conference/Paper2214/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2214/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Decoupling Global and Local Representations via Invertible Generative Flows", "authorids": ["~Xuezhe_Ma1", "~Xiang_Kong1", "~Shanghang_Zhang4", "~Eduard_H_Hovy1"], "authors": ["Xuezhe Ma", "Xiang Kong", "Shanghang Zhang", "Eduard H Hovy"], "keywords": ["Generative Models", "Generative Flow", "Normalizing Flow", "Image Generation", "Representation Learning"], "abstract": "In this work, we propose a new generative model that is capable of automatically decoupling global and local representations of images in an entirely unsupervised setting, by embedding a generative flow in the VAE framework to model the decoder.\nSpecifically, the proposed model utilizes the variational auto-encoding framework to learn a (low-dimensional) vector of latent variables to capture the global information of an image, which is fed as a conditional input to a flow-based invertible decoder with architecture borrowed from style transfer literature.\nExperimental results on standard image benchmarks demonstrate the effectiveness of our model in terms of density estimation, image generation and unsupervised representation learning.\nImportantly, this work demonstrates that with only architectural inductive biases, a generative model with a likelihood-based objective is capable of learning decoupled representations, requiring no explicit supervision.\nThe code for our model is available at \\url{https://github.com/XuezheMax/wolf}.", "one-sentence_summary": "Generative Flow for Decoupled Representation Learning", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "ma|decoupling_global_and_local_representations_via_invertible_generative_flows", "pdf": "/pdf/f2b3766907999d10ac5b2857ad661bce8495fe3c.pdf", "supplementary_material": "", "venue": "ICLR 2021 Poster", "venueid": "ICLR.cc/2021/Conference", "_bibtex": "@inproceedings{\nma2021decoupling,\ntitle={Decoupling Global and Local Representations via Invertible Generative Flows},\nauthor={Xuezhe Ma and Xiang Kong and Shanghang Zhang and Eduard H Hovy},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=iWLByfvUhN}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "iWLByfvUhN", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper2214/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper2214/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper2214/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper2214/Authors|ICLR.cc/2021/Conference/Paper2214/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2214/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923850975, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper2214/-/Official_Comment"}}}, {"id": "kDvY6pFjE1c", "original": null, "number": 4, "cdate": 1605919898602, "ddate": null, "tcdate": 1605919898602, "tmdate": 1605919898602, "tddate": null, "forum": "iWLByfvUhN", "replyto": "9D_EvlFkqq", "invitation": "ICLR.cc/2021/Conference/Paper2214/-/Official_Comment", "content": {"title": "Response to review by AnonReviewer2", "comment": "Thanks for your comments and positive feedback! \n\nWe respond below to your questions and comments. We kindly request that you briefly read these responses and let us know if they do not fully satisfy your concerns.\n\n>Q1: The paper never puts the equations from the background section together in the final objective.  It would be helpful to have an equation representing the final objective with some of the relevant variables (i.e. log p(x) >= ... with variables x, z, and v)\n\nWe appreciate your suggestion to clearly explain the training objective. In our revised submission, we have added section 2.1 to illustrate the high-level architecture of our generative model, where we clearly explain that ELBO is the training objective function. The formula of EBLO is provided in Eq. (2).\n\n>Q2: The model the authors propose is very reminiscent of \"infinite mixtures of flows\" as outlined by (Papamakarios et al. \"Normalizing Flows for Probabilistic Modeling and Inference\" page 32). An example would be \"Continuously Index Flows\" by Cornish et al. Conditioning on a context variable in flow layers is not new. This is not really a problem, but again this should be clarified.\n\nThanks for pointing out the related work we missed. We have elaborated them in the related work section of the revised version.\n\n>Q3: How much added computation is required by the encoder model plus FCnet in eq. 7 compared to the Glow-refined model on which the proposed method is based?\n\nWe have provided Table 6 in Appendix C.4 to show the comparison between different models on CIFAR-10, on the model size, the corresponding training time over one epoch (measured on four Tesla V100 GPUs), and the performance of density estimation (bits/dim). Due to introducing the encoder, our VAE-based model contains a little bit more parameters and the training speed is a little slower than the refined Glow.\n\nWe hope the above explanation answers your questions. Thanks again for your positive feedback.\n"}, "signatures": ["ICLR.cc/2021/Conference/Paper2214/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2214/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Decoupling Global and Local Representations via Invertible Generative Flows", "authorids": ["~Xuezhe_Ma1", "~Xiang_Kong1", "~Shanghang_Zhang4", "~Eduard_H_Hovy1"], "authors": ["Xuezhe Ma", "Xiang Kong", "Shanghang Zhang", "Eduard H Hovy"], "keywords": ["Generative Models", "Generative Flow", "Normalizing Flow", "Image Generation", "Representation Learning"], "abstract": "In this work, we propose a new generative model that is capable of automatically decoupling global and local representations of images in an entirely unsupervised setting, by embedding a generative flow in the VAE framework to model the decoder.\nSpecifically, the proposed model utilizes the variational auto-encoding framework to learn a (low-dimensional) vector of latent variables to capture the global information of an image, which is fed as a conditional input to a flow-based invertible decoder with architecture borrowed from style transfer literature.\nExperimental results on standard image benchmarks demonstrate the effectiveness of our model in terms of density estimation, image generation and unsupervised representation learning.\nImportantly, this work demonstrates that with only architectural inductive biases, a generative model with a likelihood-based objective is capable of learning decoupled representations, requiring no explicit supervision.\nThe code for our model is available at \\url{https://github.com/XuezheMax/wolf}.", "one-sentence_summary": "Generative Flow for Decoupled Representation Learning", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "ma|decoupling_global_and_local_representations_via_invertible_generative_flows", "pdf": "/pdf/f2b3766907999d10ac5b2857ad661bce8495fe3c.pdf", "supplementary_material": "", "venue": "ICLR 2021 Poster", "venueid": "ICLR.cc/2021/Conference", "_bibtex": "@inproceedings{\nma2021decoupling,\ntitle={Decoupling Global and Local Representations via Invertible Generative Flows},\nauthor={Xuezhe Ma and Xiang Kong and Shanghang Zhang and Eduard H Hovy},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=iWLByfvUhN}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "iWLByfvUhN", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper2214/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper2214/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper2214/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper2214/Authors|ICLR.cc/2021/Conference/Paper2214/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2214/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923850975, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper2214/-/Official_Comment"}}}, {"id": "ZMIYN5metuI", "original": null, "number": 3, "cdate": 1605919746847, "ddate": null, "tcdate": 1605919746847, "tmdate": 1605919746847, "tddate": null, "forum": "iWLByfvUhN", "replyto": "mk2fxx0XJCv", "invitation": "ICLR.cc/2021/Conference/Paper2214/-/Official_Comment", "content": {"title": "Response to review by AnonReviewer4", "comment": "Thanks for your comments and positive feedback! \n\nWe respond below to your questions and comments. We kindly request that you briefly read these responses and let us know if they do not fully satisfy your concerns.\n\n> Can you really say that the low-dimensional embedding z is capturing GLOBAL variables?\n\nFrom the two-dimensional interpolation experiments and the examples of the switch operation in Figure. 1, we see that the representation Z captures high-level features for the global properties of the image. And the results on image classification in Table 4 further justifies this observation.\n\n> The author should clearly explain the training cost function. At the end they are combining a flow generative model (typically trained using ML) with an encoder VAE like posterior approximation. I guess they optimize some soft of ELBO, but it is not clear to me yet.\n\nWe appreciate your suggestion to clearly explain the training cost function. In our revised submission, we add section 2.1 to illustrate the high-level architecture of our generative model, where we clearly say that ELBO is the training objective function. The formula of EBLO is provided in Eq. (2).\n\nWe hope the above explanation answers your questions. Thanks again for your positive feedback.\n"}, "signatures": ["ICLR.cc/2021/Conference/Paper2214/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2214/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Decoupling Global and Local Representations via Invertible Generative Flows", "authorids": ["~Xuezhe_Ma1", "~Xiang_Kong1", "~Shanghang_Zhang4", "~Eduard_H_Hovy1"], "authors": ["Xuezhe Ma", "Xiang Kong", "Shanghang Zhang", "Eduard H Hovy"], "keywords": ["Generative Models", "Generative Flow", "Normalizing Flow", "Image Generation", "Representation Learning"], "abstract": "In this work, we propose a new generative model that is capable of automatically decoupling global and local representations of images in an entirely unsupervised setting, by embedding a generative flow in the VAE framework to model the decoder.\nSpecifically, the proposed model utilizes the variational auto-encoding framework to learn a (low-dimensional) vector of latent variables to capture the global information of an image, which is fed as a conditional input to a flow-based invertible decoder with architecture borrowed from style transfer literature.\nExperimental results on standard image benchmarks demonstrate the effectiveness of our model in terms of density estimation, image generation and unsupervised representation learning.\nImportantly, this work demonstrates that with only architectural inductive biases, a generative model with a likelihood-based objective is capable of learning decoupled representations, requiring no explicit supervision.\nThe code for our model is available at \\url{https://github.com/XuezheMax/wolf}.", "one-sentence_summary": "Generative Flow for Decoupled Representation Learning", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "ma|decoupling_global_and_local_representations_via_invertible_generative_flows", "pdf": "/pdf/f2b3766907999d10ac5b2857ad661bce8495fe3c.pdf", "supplementary_material": "", "venue": "ICLR 2021 Poster", "venueid": "ICLR.cc/2021/Conference", "_bibtex": "@inproceedings{\nma2021decoupling,\ntitle={Decoupling Global and Local Representations via Invertible Generative Flows},\nauthor={Xuezhe Ma and Xiang Kong and Shanghang Zhang and Eduard H Hovy},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=iWLByfvUhN}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "iWLByfvUhN", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper2214/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper2214/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper2214/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper2214/Authors|ICLR.cc/2021/Conference/Paper2214/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2214/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923850975, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper2214/-/Official_Comment"}}}, {"id": "KuV-LJc3aM", "original": null, "number": 2, "cdate": 1605919619628, "ddate": null, "tcdate": 1605919619628, "tmdate": 1605919619628, "tddate": null, "forum": "iWLByfvUhN", "replyto": "g61Lb5RzyKq", "invitation": "ICLR.cc/2021/Conference/Paper2214/-/Official_Comment", "content": {"title": "Response to review by AnonReviewer1", "comment": "Thanks for your comments and positive feedback! \n\nWe respond below to your questions and comments. We kindly request that you briefly read these responses and let us know if they do not fully satisfy your concerns.\n\n> It\u2019s not clear to what extent each of the proposed refinements to Glow (reorganization, different splits, fine-grained multi-scale architecture) improves Glow\u2019s performance.\n\nWe have provided Table 6 in Appendix C.4 to show the comparison between the original and refined Glow in terms of model size, training speed, and the performance of density estimation. From the table, we see that the refined Glow (2nd row) has a similar number of parameters, while the training speed is much faster, and the performance of density estimation (bits/dim) is better than the original Glow (1st row). Based on our observations, the speedup of the refined Glow mainly comes from reducing the number of the invertible 1x1 convolution flows by re-organization and different splits, and the better bits/dim performances mainly come from the fine-grained multi-scale architecture. We will provide more analysis in the final version.\n\nWe hope the above explanation answers your questions. Thanks again for your positive feedback.\n"}, "signatures": ["ICLR.cc/2021/Conference/Paper2214/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2214/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Decoupling Global and Local Representations via Invertible Generative Flows", "authorids": ["~Xuezhe_Ma1", "~Xiang_Kong1", "~Shanghang_Zhang4", "~Eduard_H_Hovy1"], "authors": ["Xuezhe Ma", "Xiang Kong", "Shanghang Zhang", "Eduard H Hovy"], "keywords": ["Generative Models", "Generative Flow", "Normalizing Flow", "Image Generation", "Representation Learning"], "abstract": "In this work, we propose a new generative model that is capable of automatically decoupling global and local representations of images in an entirely unsupervised setting, by embedding a generative flow in the VAE framework to model the decoder.\nSpecifically, the proposed model utilizes the variational auto-encoding framework to learn a (low-dimensional) vector of latent variables to capture the global information of an image, which is fed as a conditional input to a flow-based invertible decoder with architecture borrowed from style transfer literature.\nExperimental results on standard image benchmarks demonstrate the effectiveness of our model in terms of density estimation, image generation and unsupervised representation learning.\nImportantly, this work demonstrates that with only architectural inductive biases, a generative model with a likelihood-based objective is capable of learning decoupled representations, requiring no explicit supervision.\nThe code for our model is available at \\url{https://github.com/XuezheMax/wolf}.", "one-sentence_summary": "Generative Flow for Decoupled Representation Learning", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "ma|decoupling_global_and_local_representations_via_invertible_generative_flows", "pdf": "/pdf/f2b3766907999d10ac5b2857ad661bce8495fe3c.pdf", "supplementary_material": "", "venue": "ICLR 2021 Poster", "venueid": "ICLR.cc/2021/Conference", "_bibtex": "@inproceedings{\nma2021decoupling,\ntitle={Decoupling Global and Local Representations via Invertible Generative Flows},\nauthor={Xuezhe Ma and Xiang Kong and Shanghang Zhang and Eduard H Hovy},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=iWLByfvUhN}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "iWLByfvUhN", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper2214/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper2214/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper2214/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper2214/Authors|ICLR.cc/2021/Conference/Paper2214/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2214/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923850975, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper2214/-/Official_Comment"}}}, {"id": "mk2fxx0XJCv", "original": null, "number": 1, "cdate": 1603810968706, "ddate": null, "tcdate": 1603810968706, "tmdate": 1605024262383, "tddate": null, "forum": "iWLByfvUhN", "replyto": "iWLByfvUhN", "invitation": "ICLR.cc/2021/Conference/Paper2214/-/Official_Review", "content": {"title": "Interesting approach, but I'm not sure about the author claims. Are you really inferring global representations?", "review": "Pros:\n\n-> I like the idea of conditional generative flows, where a low-dimensional embedding captures high-level features and a larger embedding latent space captures local representations. \n-> Use a compression encoder to enforce informative low-dimensional embeddings\n-> Good experimental results\n\nCons:\n\n-> Can you really say that the low-dimensional embedding z is capturing GLOBAL variables? To me, global variables in a generative model drives non iid samples, hence correlating samples with each other. For instance, see the paper \n\nDiane Bouchacourt, Ryota Tomioka, and Sebastian Nowozin. Multi-level variational autoencoder: Learning disentangled representations from grouped observations. In Thirty-Second AAAI Con- ference on Artificial Intelligence, 2018.\n\n-> The author should clearly explain the training cost function. At the end they are combining a flow generative model (typically trained using ML) with an encoder VAE like posterior approximation. I guess they optimize some soft of ELBO, but it is not clear to me yet.\n\nOverall, I like the paper and would like to see it accepted.", "rating": "7: Good paper, accept", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "signatures": ["ICLR.cc/2021/Conference/Paper2214/AnonReviewer4"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2214/AnonReviewer4"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Decoupling Global and Local Representations via Invertible Generative Flows", "authorids": ["~Xuezhe_Ma1", "~Xiang_Kong1", "~Shanghang_Zhang4", "~Eduard_H_Hovy1"], "authors": ["Xuezhe Ma", "Xiang Kong", "Shanghang Zhang", "Eduard H Hovy"], "keywords": ["Generative Models", "Generative Flow", "Normalizing Flow", "Image Generation", "Representation Learning"], "abstract": "In this work, we propose a new generative model that is capable of automatically decoupling global and local representations of images in an entirely unsupervised setting, by embedding a generative flow in the VAE framework to model the decoder.\nSpecifically, the proposed model utilizes the variational auto-encoding framework to learn a (low-dimensional) vector of latent variables to capture the global information of an image, which is fed as a conditional input to a flow-based invertible decoder with architecture borrowed from style transfer literature.\nExperimental results on standard image benchmarks demonstrate the effectiveness of our model in terms of density estimation, image generation and unsupervised representation learning.\nImportantly, this work demonstrates that with only architectural inductive biases, a generative model with a likelihood-based objective is capable of learning decoupled representations, requiring no explicit supervision.\nThe code for our model is available at \\url{https://github.com/XuezheMax/wolf}.", "one-sentence_summary": "Generative Flow for Decoupled Representation Learning", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "ma|decoupling_global_and_local_representations_via_invertible_generative_flows", "pdf": "/pdf/f2b3766907999d10ac5b2857ad661bce8495fe3c.pdf", "supplementary_material": "", "venue": "ICLR 2021 Poster", "venueid": "ICLR.cc/2021/Conference", "_bibtex": "@inproceedings{\nma2021decoupling,\ntitle={Decoupling Global and Local Representations via Invertible Generative Flows},\nauthor={Xuezhe Ma and Xiang Kong and Shanghang Zhang and Eduard H Hovy},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=iWLByfvUhN}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq . ***Please remember to file the Code-of-Ethics report. Once you submitted the review, a link to the report will be visible in the bottom right corner of your review.***", "required": true, "markdown": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}, "forum": "iWLByfvUhN", "replyto": "iWLByfvUhN", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"], "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper2214/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1607428800000, "duedate": 1606752000000, "multiReply": false, "readers": ["everyone"], "tcdate": 1602538101445, "tmdate": 1606915765888, "super": "ICLR.cc/2021/Conference/-/Official_Review", "signatures": ["OpenReview.net"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Paper2214/Reviewers", "OpenReview.net/Support"], "id": "ICLR.cc/2021/Conference/Paper2214/-/Official_Review"}}}, {"id": "g61Lb5RzyKq", "original": null, "number": 4, "cdate": 1603916739009, "ddate": null, "tcdate": 1603916739009, "tmdate": 1605024262189, "tddate": null, "forum": "iWLByfvUhN", "replyto": "iWLByfvUhN", "invitation": "ICLR.cc/2021/Conference/Paper2214/-/Official_Review", "content": {"title": "Official Blind Review #1", "review": "Summary: The authors propose a novel combination of VAEs and Flow models, where the decoder is modelled through a conditional flow taking as input a \u201clocal\u201d representation of the size of the input image and a \u201cglobal\u201d representation output by the encoder. The authors evaluate the proposed method on density estimation, quality of generations and linear probing on a variety of datasets and show improvement over state of the art.\n\nGreat:\n* Conceptually simple method that seems to work quite well in practice, for this class of models. \n* The linear probing experiment is quite convincing in justifying the use of \u201cglobal\u201d and \u201clocal\u201d characterizations of the learned representations. So are the interpolations.\n\nCould be improved:\n* It\u2019s not clear to what extent each of the proposed refinements to Glow (reorganization, different splits, fine-grained multi-scale architecture) improves Glow\u2019s performance. \n\nThe authors propose a novel combination of known methods, evaluate it extensively and show considerable improvements over current state of the art. A clear accept.\n", "rating": "8: Top 50% of accepted papers, clear accept", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["ICLR.cc/2021/Conference/Paper2214/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2214/AnonReviewer1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Decoupling Global and Local Representations via Invertible Generative Flows", "authorids": ["~Xuezhe_Ma1", "~Xiang_Kong1", "~Shanghang_Zhang4", "~Eduard_H_Hovy1"], "authors": ["Xuezhe Ma", "Xiang Kong", "Shanghang Zhang", "Eduard H Hovy"], "keywords": ["Generative Models", "Generative Flow", "Normalizing Flow", "Image Generation", "Representation Learning"], "abstract": "In this work, we propose a new generative model that is capable of automatically decoupling global and local representations of images in an entirely unsupervised setting, by embedding a generative flow in the VAE framework to model the decoder.\nSpecifically, the proposed model utilizes the variational auto-encoding framework to learn a (low-dimensional) vector of latent variables to capture the global information of an image, which is fed as a conditional input to a flow-based invertible decoder with architecture borrowed from style transfer literature.\nExperimental results on standard image benchmarks demonstrate the effectiveness of our model in terms of density estimation, image generation and unsupervised representation learning.\nImportantly, this work demonstrates that with only architectural inductive biases, a generative model with a likelihood-based objective is capable of learning decoupled representations, requiring no explicit supervision.\nThe code for our model is available at \\url{https://github.com/XuezheMax/wolf}.", "one-sentence_summary": "Generative Flow for Decoupled Representation Learning", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "ma|decoupling_global_and_local_representations_via_invertible_generative_flows", "pdf": "/pdf/f2b3766907999d10ac5b2857ad661bce8495fe3c.pdf", "supplementary_material": "", "venue": "ICLR 2021 Poster", "venueid": "ICLR.cc/2021/Conference", "_bibtex": "@inproceedings{\nma2021decoupling,\ntitle={Decoupling Global and Local Representations via Invertible Generative Flows},\nauthor={Xuezhe Ma and Xiang Kong and Shanghang Zhang and Eduard H Hovy},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=iWLByfvUhN}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq . ***Please remember to file the Code-of-Ethics report. Once you submitted the review, a link to the report will be visible in the bottom right corner of your review.***", "required": true, "markdown": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}, "forum": "iWLByfvUhN", "replyto": "iWLByfvUhN", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"], "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper2214/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1607428800000, "duedate": 1606752000000, "multiReply": false, "readers": ["everyone"], "tcdate": 1602538101445, "tmdate": 1606915765888, "super": "ICLR.cc/2021/Conference/-/Official_Review", "signatures": ["OpenReview.net"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Paper2214/Reviewers", "OpenReview.net/Support"], "id": "ICLR.cc/2021/Conference/Paper2214/-/Official_Review"}}}], "count": 14}