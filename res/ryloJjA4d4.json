{"notes": [{"id": "ryloJjA4d4", "original": "r1lqF80G_N", "number": 38, "cdate": 1553423074577, "ddate": null, "tcdate": 1553423074577, "tmdate": 1562082117189, "tddate": null, "forum": "ryloJjA4d4", "replyto": null, "invitation": "ICLR.cc/2019/Workshop/LLD/-/Blind_Submission", "content": {"title": "Unsupervised Scalable Representation Learning for Multivariate Time Series", "authors": ["Jean-Yves Franceschi", "Aymeric Dieuleveut", "Martin Jaggi"], "authorids": ["jean-yves.franceschi@lip6.fr", "aymeric.dieuleveut@epfl.ch", "martin.jaggi@epfl.ch"], "keywords": ["time series", "representation learning", "unsupervised learning"], "abstract": "Time series constitute a challenging data type for machine learning algorithms, due to their highly variable lengths and sparse labeling in practice. In this paper, we tackle this challenge by proposing an unsupervised method to learn universal embeddings of time series. Unlike previous works, it is scalable with respect to their length and we demonstrate the quality, transferability and practicability of the learned representations with thorough experiments and comparisons. To this end, we combine an encoder based on causal dilated convolutions with a novel triplet loss employing time-based negative sampling, obtaining general-purpose representations for variable length and multivariate time series.", "pdf": "/pdf/fea8c439d9da1cf598a1f4c49b0f28b57b500d83.pdf", "paperhash": "franceschi|unsupervised_scalable_representation_learning_for_multivariate_time_series"}, "signatures": ["ICLR.cc/2019/Workshop/LLD"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Workshop/LLD"], "details": {"replyCount": 3, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"id": "ICLR.cc/2019/Workshop/LLD/-/Blind_Submission", "cdate": 1548689671889, "reply": {"forum": null, "replyto": null, "readers": {"values-regex": ".*"}, "writers": {"values": ["ICLR.cc/2019/Workshop/LLD"]}, "signatures": {"values": ["ICLR.cc/2019/Workshop/LLD"]}, "content": {"authors": {"values-regex": ".*"}, "authorids": {"values-regex": ".*"}}}, "tcdate": 1548689671889, "tmdate": 1557933709646, "readers": ["everyone"], "writers": ["ICLR.cc/2019/Workshop/LLD"], "invitees": ["~"], "signatures": ["ICLR.cc/2019/Workshop/LLD"], "details": {"writable": true}}}, "tauthor": "OpenReview.net"}, {"id": "HkljfJVUKE", "original": null, "number": 1, "cdate": 1554558739196, "ddate": null, "tcdate": 1554558739196, "tmdate": 1555512023944, "tddate": null, "forum": "ryloJjA4d4", "replyto": "ryloJjA4d4", "invitation": "ICLR.cc/2019/Workshop/LLD/-/Paper38/Official_Review", "content": {"title": "Exciting work in a challenging and useful unsupervised setting", "review": "This paper provides an unsupervised representation learning algorithm for performing classification and regression in multivariate time series. It relies on a combination of cutting-edge techniques: triplet loss, stacked causal dilated convolutions (\u00e0 la WaveNet), weight normalization, and residual connections. Although these techniques had been published before in isolation, they had never been implemented in combination up to this paper. Therefore, the contributions of this paper are novel enough for the ICLR LLD workshop. \n\nThe discussion of prior literature is solid. However, i will point out that the claim\n\"this works is the first in the time series literature to propose a triplet loss for feature learning\"\nis wrong. The paper of Jansen et al. ICASSP 2017 \"Unsupervised learning of semantic audio representations\" (https://arxiv.org/abs/1711.02209) is one counterexample.\n\nThe rest of the paper is very clear and eloquent. I recommend this paper for acceptance.", "rating": "5: Top 15% of accepted papers, strong accept", "confidence": "2: The reviewer is fairly confident that the evaluation is correct"}, "signatures": ["ICLR.cc/2019/Workshop/LLD/Paper38/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Workshop/LLD/Paper38/AnonReviewer1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Unsupervised Scalable Representation Learning for Multivariate Time Series", "authors": ["Jean-Yves Franceschi", "Aymeric Dieuleveut", "Martin Jaggi"], "authorids": ["jean-yves.franceschi@lip6.fr", "aymeric.dieuleveut@epfl.ch", "martin.jaggi@epfl.ch"], "keywords": ["time series", "representation learning", "unsupervised learning"], "abstract": "Time series constitute a challenging data type for machine learning algorithms, due to their highly variable lengths and sparse labeling in practice. In this paper, we tackle this challenge by proposing an unsupervised method to learn universal embeddings of time series. Unlike previous works, it is scalable with respect to their length and we demonstrate the quality, transferability and practicability of the learned representations with thorough experiments and comparisons. To this end, we combine an encoder based on causal dilated convolutions with a novel triplet loss employing time-based negative sampling, obtaining general-purpose representations for variable length and multivariate time series.", "pdf": "/pdf/fea8c439d9da1cf598a1f4c49b0f28b57b500d83.pdf", "paperhash": "franceschi|unsupervised_scalable_representation_learning_for_multivariate_time_series"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Workshop/LLD/-/Paper38/Official_Review", "cdate": 1553713415575, "expdate": 1555718400000, "duedate": 1554681600000, "reply": {"forum": "ryloJjA4d4", "replyto": "ryloJjA4d4", "writers": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2019/Workshop/LLD/Paper38/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2019/Workshop/LLD/Paper38/AnonReviewer[0-9]+"}, "readers": {"values": ["everyone"], "description": "The users who will be allowed to read the above content."}, "content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "required": true}, "rating": {"order": 3, "value-dropdown": ["5: Top 15% of accepted papers, strong accept", "4: Top 50% of accepted papers, clear accept", "3: Marginally above acceptance threshold", "2: Marginally below acceptance threshold", "1: Strong rejection"], "required": true}, "confidence": {"order": 4, "value-radio": ["3: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "2: The reviewer is fairly confident that the evaluation is correct", "1: The reviewer's evaluation is an educated guess"], "required": true}}}, "tcdate": 1553713415575, "tmdate": 1555511825811, "readers": ["everyone"], "writers": ["ICLR.cc/2019/Workshop/LLD"], "invitees": ["ICLR.cc/2019/Workshop/LLD/Paper38/Reviewers"], "signatures": ["ICLR.cc/2019/Workshop/LLD"]}}}, {"id": "rJgGojoDFN", "original": null, "number": 2, "cdate": 1554656153779, "ddate": null, "tcdate": 1554656153779, "tmdate": 1555512019563, "tddate": null, "forum": "ryloJjA4d4", "replyto": "ryloJjA4d4", "invitation": "ICLR.cc/2019/Workshop/LLD/-/Paper38/Official_Review", "content": {"title": "Weak reject", "review": "Paper summary:\n\nThis paper proposes a novel unsupervised embedding for time-series. Its architecture mainly consists in a series of dilated causal convolutions, followed by a temporal averaging to obtain a representation which is independent on the length of the time-series. The authors propose a triplet loss with negative mining to train the embedding, which is novel for real-valued time-series. This method is experimentally validated on a classification and a regression task.\n\nGeneral opinion:\n\n* Pros:\n    * Good writing\n    * Detailed appendix with experimental hyperparameters, so that the results are pretty reproducible.\n    * For classification and regression, the proposed method reaches results close to the state-of-the-art.\n* Cons:\n    * The authors state that the embedding is unsupervised, but in Appendix C they acknowledge that it is trained with early-stopping based on the final classification accuracy, thereby relying on an implicit supervision.\n    * This method does not improve over the state-of-the-art on time-series classification, even though it is its natural purpose\n    * The experimental validation of the proposed method is weak (cf detailed method).\n    * I have some concerns at the conceptual level (cf detailed questions).\n\nTaking into consideration these aspects, I tend to vote for a weak rejection.\n\nDetailed questions:\n- On a conceptual level, the ideas underlying the use of a triplet loss explained in the 3rd paragraph of section 2 seems a bit incomplete to me. On the one hand, the authors state that the embedding of a sub-series should be close to the embedding of the series. On the other hand, they also state that this embedding should be far from the embedding of a randomly sampled sub-series, possibly in the same long time-series. This seems contradictory, because if they belong to the same global time-series, they are both sub-series of the global time-series and therefore should be close. Also, the fact that no scale is taken into account when defining sub-series seems quite irrealistic.\n- Why is using a *causal* embedding important for classification purposes? \n- Experimentally, what are the results when the number of negative samples, K, varies? Experiments have been performed with this parameter varying as an ensemble is taken. It is a pity that the importance of this value is not reported, as it would have provided an intuition on its importance.\n- The runtimes reported in Table 1 are a bit strange. Why does the runtime of the raw values vary so much (x30) when moving from daily to quarterly predictions, while the runtime of the representations diminishes (/3)?", "rating": "2: Marginally below acceptance threshold", "confidence": "2: The reviewer is fairly confident that the evaluation is correct"}, "signatures": ["ICLR.cc/2019/Workshop/LLD/Paper38/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Workshop/LLD/Paper38/AnonReviewer2"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Unsupervised Scalable Representation Learning for Multivariate Time Series", "authors": ["Jean-Yves Franceschi", "Aymeric Dieuleveut", "Martin Jaggi"], "authorids": ["jean-yves.franceschi@lip6.fr", "aymeric.dieuleveut@epfl.ch", "martin.jaggi@epfl.ch"], "keywords": ["time series", "representation learning", "unsupervised learning"], "abstract": "Time series constitute a challenging data type for machine learning algorithms, due to their highly variable lengths and sparse labeling in practice. In this paper, we tackle this challenge by proposing an unsupervised method to learn universal embeddings of time series. Unlike previous works, it is scalable with respect to their length and we demonstrate the quality, transferability and practicability of the learned representations with thorough experiments and comparisons. To this end, we combine an encoder based on causal dilated convolutions with a novel triplet loss employing time-based negative sampling, obtaining general-purpose representations for variable length and multivariate time series.", "pdf": "/pdf/fea8c439d9da1cf598a1f4c49b0f28b57b500d83.pdf", "paperhash": "franceschi|unsupervised_scalable_representation_learning_for_multivariate_time_series"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Workshop/LLD/-/Paper38/Official_Review", "cdate": 1553713415575, "expdate": 1555718400000, "duedate": 1554681600000, "reply": {"forum": "ryloJjA4d4", "replyto": "ryloJjA4d4", "writers": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2019/Workshop/LLD/Paper38/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2019/Workshop/LLD/Paper38/AnonReviewer[0-9]+"}, "readers": {"values": ["everyone"], "description": "The users who will be allowed to read the above content."}, "content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "required": true}, "rating": {"order": 3, "value-dropdown": ["5: Top 15% of accepted papers, strong accept", "4: Top 50% of accepted papers, clear accept", "3: Marginally above acceptance threshold", "2: Marginally below acceptance threshold", "1: Strong rejection"], "required": true}, "confidence": {"order": 4, "value-radio": ["3: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "2: The reviewer is fairly confident that the evaluation is correct", "1: The reviewer's evaluation is an educated guess"], "required": true}}}, "tcdate": 1553713415575, "tmdate": 1555511825811, "readers": ["everyone"], "writers": ["ICLR.cc/2019/Workshop/LLD"], "invitees": ["ICLR.cc/2019/Workshop/LLD/Paper38/Reviewers"], "signatures": ["ICLR.cc/2019/Workshop/LLD"]}}}, {"id": "HkxyyX43tN", "original": null, "number": 1, "cdate": 1554952918746, "ddate": null, "tcdate": 1554952918746, "tmdate": 1555510982970, "tddate": null, "forum": "ryloJjA4d4", "replyto": "ryloJjA4d4", "invitation": "ICLR.cc/2019/Workshop/LLD/-/Paper38/Decision", "content": {"title": "Acceptance Decision", "decision": "Accept", "comment": "\nThe paper presents some reasonable experiments and approaches for unsupervised time series. However as mentioned by R2 there is several issues. The paper also overclaims  a bit some of the novelty. As noted by  R1 and the metareviewer there is other works using triplet loss for timeseries, a relatively common approach in temporal dataset (e.g. video, audio), the popular causal convolution structure from wavenet is also quite well known, contributions should be more clear.\n"}, "signatures": ["ICLR.cc/2019/Workshop/LLD/Program_Chairs"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Workshop/LLD/Program_Chairs"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Unsupervised Scalable Representation Learning for Multivariate Time Series", "authors": ["Jean-Yves Franceschi", "Aymeric Dieuleveut", "Martin Jaggi"], "authorids": ["jean-yves.franceschi@lip6.fr", "aymeric.dieuleveut@epfl.ch", "martin.jaggi@epfl.ch"], "keywords": ["time series", "representation learning", "unsupervised learning"], "abstract": "Time series constitute a challenging data type for machine learning algorithms, due to their highly variable lengths and sparse labeling in practice. In this paper, we tackle this challenge by proposing an unsupervised method to learn universal embeddings of time series. Unlike previous works, it is scalable with respect to their length and we demonstrate the quality, transferability and practicability of the learned representations with thorough experiments and comparisons. To this end, we combine an encoder based on causal dilated convolutions with a novel triplet loss employing time-based negative sampling, obtaining general-purpose representations for variable length and multivariate time series.", "pdf": "/pdf/fea8c439d9da1cf598a1f4c49b0f28b57b500d83.pdf", "paperhash": "franceschi|unsupervised_scalable_representation_learning_for_multivariate_time_series"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Workshop/LLD/-/Paper38/Decision", "cdate": 1554736077045, "reply": {"forum": "ryloJjA4d4", "replyto": "ryloJjA4d4", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-regex": ["ICLR.cc/2019/Workshop/LLD/Program_Chairs"], "description": "How your identity will be displayed."}, "signatures": {"values": ["ICLR.cc/2019/Workshop/LLD/Program_Chairs"], "description": "How your identity will be displayed."}, "content": {"title": {"order": 1, "required": true, "value": "Acceptance Decision"}, "decision": {"order": 2, "required": true, "value-radio": ["Accept", "Reject"], "description": "Acceptance decision"}, "comment": {"order": 3, "required": false, "value-regex": "[\\S\\s]{0,5000}", "description": ""}}}, "tcdate": 1554736077045, "tmdate": 1555510961824, "readers": ["everyone"], "writers": ["ICLR.cc/2019/Workshop/LLD"], "invitees": ["ICLR.cc/2019/Workshop/LLD/Program_Chairs"], "signatures": ["ICLR.cc/2019/Workshop/LLD"]}}}], "count": 4}