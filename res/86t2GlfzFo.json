{"notes": [{"id": "86t2GlfzFo", "original": "w-Gv-RXx-iu", "number": 819, "cdate": 1601308094730, "ddate": null, "tcdate": 1601308094730, "tmdate": 1614985677918, "tddate": null, "forum": "86t2GlfzFo", "replyto": null, "invitation": "ICLR.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Deep Curvature Suite", "authorids": ["~Diego_Granziol1", "~Xingchen_Wan1", "~Timur_Garipov1"], "authors": ["Diego Granziol", "Xingchen Wan", "Timur Garipov"], "keywords": ["Hessian computation", "Deep Learning", "Loss Curvature", "Lanczos"], "abstract": "The curvature of the loss, provides rich information on the geometry underlying neural networks, with applications in second order optimisation and Bayesian deep learning. However, accessing curvature information is still a daunting engineering challenge, inaccessible to most practitioners. We hence provide a software package the \\textbf{Deep Curvature Suite}, which allows easy curvature evaluation for large modern neural networks. Beyond the calculation of a highly accurate moment matched approximation of the Hessian spectrum using Lanczos, our package provides: extensive \\emph{loss surface visualisation}, the calculation of the \\emph{Hessian variance} and \\emph{stochastic second order optimisers}. We further address and disprove many common misconceptions in the literature about the Lanczos algorithm, namely that it learns eigenvalues from the top down. We prove using high dimensional concentration inequalities that for specific matrices a single random vector is sufficient for accurate spectral estimation, informing our spectral visualisation method. We showcase our package practical utility on a series of examples based on realistic modern neural networks such as the VGG-$16$ and Preactivated ResNets on the CIFAR-$10$/$100$ datasets. We further detail $3$ specific potential use cases enabled by our software: research in stochastic second order optimisation for deep learning, learning rate scheduling using known optimality formulae for convex surfaces and empirical verification of deep learning theory based on comparing empirical and theoretically implied spectra.", "one-sentence_summary": "This package allows the easy computation and visualisation of curvature information for deep neural networks.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "granziol|deep_curvature_suite", "pdf": "/pdf/bd064814083e15af85a08d89abc0b7174024d8b2.pdf", "supplementary_material": "/attachment/ab11d8d035b3858dfff1c165d43dd5c6f92814db.zip", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=epykIrTh_f", "_bibtex": "@misc{\ngranziol2021deep,\ntitle={Deep Curvature Suite},\nauthor={Diego Granziol and Xingchen Wan and Timur Garipov},\nyear={2021},\nurl={https://openreview.net/forum?id=86t2GlfzFo}\n}"}, "signatures": ["ICLR.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference"], "details": {"replyCount": 5, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"reply": {"readers": {"values-regex": ".*"}, "writers": {"values": ["ICLR.cc/2021/Conference"]}, "signatures": {"values": ["ICLR.cc/2021/Conference"]}, "content": {"authors": {"values": ["Anonymous"]}, "authorids": {"values-regex": ".*"}, "reviewed_version_(pdf)": {"required": false, "description": "Upload a PDF file that ends with .pdf", "value-regex": ".*"}}}, "signatures": ["ICLR.cc/2021/Conference"], "readers": ["everyone"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["~", "OpenReview.net/Support"], "tcdate": 1601308008205, "tmdate": 1614984599368, "id": "ICLR.cc/2021/Conference/-/Blind_Submission"}}, "tauthor": "OpenReview.net"}, {"id": "3XTxiFakFK", "original": null, "number": 1, "cdate": 1610040476677, "ddate": null, "tcdate": 1610040476677, "tmdate": 1610474081269, "tddate": null, "forum": "86t2GlfzFo", "replyto": "86t2GlfzFo", "invitation": "ICLR.cc/2021/Conference/Paper819/-/Decision", "content": {"title": "Final Decision", "decision": "Reject", "comment": "This paper proposes a software package to ease and provide a standard way for Hessian-related computation, both for loss analysis and second order optimization. I think all reviewers agree with the usefulness of this work but differ in their assessment whether this work is ready for publication. Given the emphasize on providing a software package I share the view that careful testing and support of usability is important. While there is quite some spread in the scores I think in this case the average score is an appropriate way to compensate for subjective differences between reviewers. I think it is justified to encourage the authors to invest a bit more work to turn this into a fully convincing contribution.\n\n"}, "signatures": ["ICLR.cc/2021/Conference/Program_Chairs"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference/Program_Chairs"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Deep Curvature Suite", "authorids": ["~Diego_Granziol1", "~Xingchen_Wan1", "~Timur_Garipov1"], "authors": ["Diego Granziol", "Xingchen Wan", "Timur Garipov"], "keywords": ["Hessian computation", "Deep Learning", "Loss Curvature", "Lanczos"], "abstract": "The curvature of the loss, provides rich information on the geometry underlying neural networks, with applications in second order optimisation and Bayesian deep learning. However, accessing curvature information is still a daunting engineering challenge, inaccessible to most practitioners. We hence provide a software package the \\textbf{Deep Curvature Suite}, which allows easy curvature evaluation for large modern neural networks. Beyond the calculation of a highly accurate moment matched approximation of the Hessian spectrum using Lanczos, our package provides: extensive \\emph{loss surface visualisation}, the calculation of the \\emph{Hessian variance} and \\emph{stochastic second order optimisers}. We further address and disprove many common misconceptions in the literature about the Lanczos algorithm, namely that it learns eigenvalues from the top down. We prove using high dimensional concentration inequalities that for specific matrices a single random vector is sufficient for accurate spectral estimation, informing our spectral visualisation method. We showcase our package practical utility on a series of examples based on realistic modern neural networks such as the VGG-$16$ and Preactivated ResNets on the CIFAR-$10$/$100$ datasets. We further detail $3$ specific potential use cases enabled by our software: research in stochastic second order optimisation for deep learning, learning rate scheduling using known optimality formulae for convex surfaces and empirical verification of deep learning theory based on comparing empirical and theoretically implied spectra.", "one-sentence_summary": "This package allows the easy computation and visualisation of curvature information for deep neural networks.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "granziol|deep_curvature_suite", "pdf": "/pdf/bd064814083e15af85a08d89abc0b7174024d8b2.pdf", "supplementary_material": "/attachment/ab11d8d035b3858dfff1c165d43dd5c6f92814db.zip", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=epykIrTh_f", "_bibtex": "@misc{\ngranziol2021deep,\ntitle={Deep Curvature Suite},\nauthor={Diego Granziol and Xingchen Wan and Timur Garipov},\nyear={2021},\nurl={https://openreview.net/forum?id=86t2GlfzFo}\n}"}, "tags": [], "invitation": {"reply": {"forum": "86t2GlfzFo", "replyto": "86t2GlfzFo", "readers": {"values": ["everyone"]}, "writers": {"values": ["ICLR.cc/2021/Conference/Program_Chairs"]}, "signatures": {"values": ["ICLR.cc/2021/Conference/Program_Chairs"]}, "content": {"title": {"value": "Final Decision"}, "decision": {"value-radio": ["Accept (Oral)", "Accept (Spotlight)", "Accept (Poster)", "Reject"]}, "comment": {"value-regex": "[\\S\\s]{0,50000}", "markdown": true}}}, "multiReply": false, "signatures": ["ICLR.cc/2021/Conference"], "readers": ["everyone"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Program_Chairs"], "tcdate": 1610040476664, "tmdate": 1610474081250, "id": "ICLR.cc/2021/Conference/Paper819/-/Decision"}}}, {"id": "65aJb_VQByr", "original": null, "number": 3, "cdate": 1604680287528, "ddate": null, "tcdate": 1604680287528, "tmdate": 1606814904996, "tddate": null, "forum": "86t2GlfzFo", "replyto": "86t2GlfzFo", "invitation": "ICLR.cc/2021/Conference/Paper819/-/Official_Review", "content": {"title": "Useful library, paper needs major revision", "review": "### Summary\nThe paper presents a library for second-order analysis of the optimization of models implemented with PyTorch and potentially having millions of parameters. The library offers tools for easily computing and visualizing Hessian, curvature, loss landscape, and runnning simple statistics, for instance for studying the properties of local minima.\nCompared to existing tools, the proposed library is more complete and accurate, , as demonstrated by example analyses, and scales well with the number of model parameters and the dataset size.\nThe library itself seems very useful, however the paper needs major revision in order to be publishable.\n\n### Presentation\nThe paper is generally poorly written. Many concepts are not defined or not well enough, for instance:\n1. input independence, page 2, by which it is not clear if independence between features or between samples is meant;\n2. number of moments, page 3, not defined;\n3. curvature, by which it should be specified earlier it is meant the loss curvature.\n\nTo improve clarity, the paper should provide a comprehensive list of tools implemented in the library and give examples of why one would need to use each of them. The library's tools are described throughout the paper, but they are too scattered to have a complete view of the library.\nMoreover, the Lanczos algorithm, which is the central for the library, should be reported. \n\nFinally, the paper misses important parts, such as the reference page, a paragraph in page 5 and the cited and not reported Algorithm 1; it also has many typos; notations and domains are not provided for most equations and it is not clear why Equation (3) does not depend on the loss L.\n\nThe current presentation doesn't meet the standards for a conference paper.\n\n### UPDATE\nThe presentation of the paper is now convincing, with the background, contributions and concepts clearly stated. I hence increased my score. \n\nHowever, I agree with reviewer 2 that the library is not properly tested (I understand it can be hard to test the whole computation, but unit tests could be easily provided) and that it would have a higher impact if it were more modular, so that a user could easily add the loss analysis directly in her workflow.\nMoreover, I also think that the paper should be rejected given that the first submission wasn't anonymized and the paper wasn't in a state of being submitted.\n", "rating": "4: Ok but not good enough - rejection", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["ICLR.cc/2021/Conference/Paper819/AnonReviewer5"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper819/AnonReviewer5"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Deep Curvature Suite", "authorids": ["~Diego_Granziol1", "~Xingchen_Wan1", "~Timur_Garipov1"], "authors": ["Diego Granziol", "Xingchen Wan", "Timur Garipov"], "keywords": ["Hessian computation", "Deep Learning", "Loss Curvature", "Lanczos"], "abstract": "The curvature of the loss, provides rich information on the geometry underlying neural networks, with applications in second order optimisation and Bayesian deep learning. However, accessing curvature information is still a daunting engineering challenge, inaccessible to most practitioners. We hence provide a software package the \\textbf{Deep Curvature Suite}, which allows easy curvature evaluation for large modern neural networks. Beyond the calculation of a highly accurate moment matched approximation of the Hessian spectrum using Lanczos, our package provides: extensive \\emph{loss surface visualisation}, the calculation of the \\emph{Hessian variance} and \\emph{stochastic second order optimisers}. We further address and disprove many common misconceptions in the literature about the Lanczos algorithm, namely that it learns eigenvalues from the top down. We prove using high dimensional concentration inequalities that for specific matrices a single random vector is sufficient for accurate spectral estimation, informing our spectral visualisation method. We showcase our package practical utility on a series of examples based on realistic modern neural networks such as the VGG-$16$ and Preactivated ResNets on the CIFAR-$10$/$100$ datasets. We further detail $3$ specific potential use cases enabled by our software: research in stochastic second order optimisation for deep learning, learning rate scheduling using known optimality formulae for convex surfaces and empirical verification of deep learning theory based on comparing empirical and theoretically implied spectra.", "one-sentence_summary": "This package allows the easy computation and visualisation of curvature information for deep neural networks.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "granziol|deep_curvature_suite", "pdf": "/pdf/bd064814083e15af85a08d89abc0b7174024d8b2.pdf", "supplementary_material": "/attachment/ab11d8d035b3858dfff1c165d43dd5c6f92814db.zip", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=epykIrTh_f", "_bibtex": "@misc{\ngranziol2021deep,\ntitle={Deep Curvature Suite},\nauthor={Diego Granziol and Xingchen Wan and Timur Garipov},\nyear={2021},\nurl={https://openreview.net/forum?id=86t2GlfzFo}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq . ***Please remember to file the Code-of-Ethics report. Once you submitted the review, a link to the report will be visible in the bottom right corner of your review.***", "required": true, "markdown": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}, "forum": "86t2GlfzFo", "replyto": "86t2GlfzFo", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"], "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper819/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1607428800000, "duedate": 1606752000000, "multiReply": false, "readers": ["everyone"], "tcdate": 1602538069544, "tmdate": 1606915793837, "super": "ICLR.cc/2021/Conference/-/Official_Review", "signatures": ["OpenReview.net"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Paper819/Reviewers", "OpenReview.net/Support"], "id": "ICLR.cc/2021/Conference/Paper819/-/Official_Review"}}}, {"id": "i6G27-nNSCx", "original": null, "number": 1, "cdate": 1603889468622, "ddate": null, "tcdate": 1603889468622, "tmdate": 1605023936221, "tddate": null, "forum": "86t2GlfzFo", "replyto": "86t2GlfzFo", "invitation": "ICLR.cc/2021/Conference/Paper819/-/Official_Review", "content": {"title": "Unclear contribution; supplementary material not anonymized", "review": "I think this paper needs to be desk-rejected since the supplementary material reveals the authors' identities in multiple places, e.g. the Readme file and the example notebook. Various .py files have an author attribute set.\n\nThis issue aside, both the package and the paper appear rushed to me and **not ready for publication**.\n\nPackage:\n* Most importantly, I could not find any tests whatsoever. Of course tests do not guarantee anything, especially if implemented poorly, but I hope that nobody would trust a completely untested third-party codebase for their own research. A thorough(!) test suite would be a strict requirement from my view to even consider accepting a code library paper at a top-tier conference.\n* There is no setup.py file to install the package and dependencies. I tried importing some of the modules from the root directory but got errors because of missing dependencies (e.g. backpack is not listed in the requirements.txt).\n* The package is split into multiples modules with generic names such as 'core'. I would strongly suggest to put them in a joint namespace.\n* What's the reasoning for including implementations of standard architectures that are available e.g. through torchvision and high-level training functions? Are those required? In general, I think that for a utility library it is best to assume that users have an established workflow of constructing and training their networks (unless the point of the library is to simplify that workflow, but this does not seem to be the case here).\n\nPaper:\n* I don't think that Section 4 fits into the flow of the paper. I would rather see that space used to go more into depth with the examples. At the moment you assume that the reader already knows why they would want to e.g. estimate the spectral density, but I think it would be worth both motivating the experiments and discussing the results.\n* I think basing the code examples on actual network and data loader objects would make them more accessible. Presumably passing string arguments for model and dataset into your compute_eigenspectrum and train_network functions is limited to the architectures and datasets that you implement? How do users provide their own datasets or networks? Or is this not supported? Section 2 seems to claim otherwise.\n* The font sizes and families around the code listings are extremely inconsistent, especially pages 5 and 6 are visually fairly unappealing.\n* There is some discussion around the relationship to Backpack, but what about PyHessian? That package seems more closely related since it also focuses on computing spectral densities.\n* Comparing first and second order optimisers on a per-epoch basis as in Figure 1 does not seem practically relevant to me, a wall clock time comparison would be of much higher interest to most potential users.\n* I would recommend carefully checking the paper for spelling and language. I'm not a native speaker, but to me it seems like there are quite a few inappropriate capitalisations (\"Training\", \"Testing\"), inconsistent capitalisations (\"eigenvalues\" vs \"Eigenvalues\") and hyphenations (\"eigen-decomposition\").\n* The reference pages are missing (after page 8).", "rating": "3: Clear rejection", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["ICLR.cc/2021/Conference/Paper819/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper819/AnonReviewer2"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Deep Curvature Suite", "authorids": ["~Diego_Granziol1", "~Xingchen_Wan1", "~Timur_Garipov1"], "authors": ["Diego Granziol", "Xingchen Wan", "Timur Garipov"], "keywords": ["Hessian computation", "Deep Learning", "Loss Curvature", "Lanczos"], "abstract": "The curvature of the loss, provides rich information on the geometry underlying neural networks, with applications in second order optimisation and Bayesian deep learning. However, accessing curvature information is still a daunting engineering challenge, inaccessible to most practitioners. We hence provide a software package the \\textbf{Deep Curvature Suite}, which allows easy curvature evaluation for large modern neural networks. Beyond the calculation of a highly accurate moment matched approximation of the Hessian spectrum using Lanczos, our package provides: extensive \\emph{loss surface visualisation}, the calculation of the \\emph{Hessian variance} and \\emph{stochastic second order optimisers}. We further address and disprove many common misconceptions in the literature about the Lanczos algorithm, namely that it learns eigenvalues from the top down. We prove using high dimensional concentration inequalities that for specific matrices a single random vector is sufficient for accurate spectral estimation, informing our spectral visualisation method. We showcase our package practical utility on a series of examples based on realistic modern neural networks such as the VGG-$16$ and Preactivated ResNets on the CIFAR-$10$/$100$ datasets. We further detail $3$ specific potential use cases enabled by our software: research in stochastic second order optimisation for deep learning, learning rate scheduling using known optimality formulae for convex surfaces and empirical verification of deep learning theory based on comparing empirical and theoretically implied spectra.", "one-sentence_summary": "This package allows the easy computation and visualisation of curvature information for deep neural networks.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "granziol|deep_curvature_suite", "pdf": "/pdf/bd064814083e15af85a08d89abc0b7174024d8b2.pdf", "supplementary_material": "/attachment/ab11d8d035b3858dfff1c165d43dd5c6f92814db.zip", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=epykIrTh_f", "_bibtex": "@misc{\ngranziol2021deep,\ntitle={Deep Curvature Suite},\nauthor={Diego Granziol and Xingchen Wan and Timur Garipov},\nyear={2021},\nurl={https://openreview.net/forum?id=86t2GlfzFo}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq . ***Please remember to file the Code-of-Ethics report. Once you submitted the review, a link to the report will be visible in the bottom right corner of your review.***", "required": true, "markdown": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}, "forum": "86t2GlfzFo", "replyto": "86t2GlfzFo", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"], "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper819/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1607428800000, "duedate": 1606752000000, "multiReply": false, "readers": ["everyone"], "tcdate": 1602538069544, "tmdate": 1606915793837, "super": "ICLR.cc/2021/Conference/-/Official_Review", "signatures": ["OpenReview.net"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Paper819/Reviewers", "OpenReview.net/Support"], "id": "ICLR.cc/2021/Conference/Paper819/-/Official_Review"}}}, {"id": "fteq0qfFfOg", "original": null, "number": 2, "cdate": 1603894619303, "ddate": null, "tcdate": 1603894619303, "tmdate": 1605023936153, "tddate": null, "forum": "86t2GlfzFo", "replyto": "86t2GlfzFo", "invitation": "ICLR.cc/2021/Conference/Paper819/-/Official_Review", "content": {"title": "Deep Curvature Suite could potentially stimulate more research", "review": "###\nSummary:\nThis paper proposes a software package to ease and provide a standard way for Hessian-related computation, both for loss analysis and second order optimization. It also provides analysis on why Lanczos algorithm is a better choice to estimate Hessian eigenvalue compared to Power Iterations. Finally, it empirically shows the advantage of using Hessian approximation that goes beyond diagonal approximation for spectrum computation.\n\n###\nReasons for score: \nI lean toward acceptance. Implementing Hessian-related computation is complex and often a bottleneck for research. Easing the implementation of those computations lower the entry barrier for second order optimization/loss analysis research and has the potential to stimulate more works in those areas.\n \n###\n Pros:\n- Address an important implementation problem\n- Scale to medium size network used on CIFAR-10.\n \n###\nCons: \n- Comparisons with related work could be expanded. How does this library related to the other software that use Lanczos algorithm for Hessian computation?\n- How extensive is the library? How easy is to use it with an arbitrary Pytorch model? \n- It is not clear if the library would scale to neural network usually used for larger scale problem such as ImageNet.\n \n###\nQuestions:\n- It is not clear to me how to compute the Hessian of a Neural Network with Batch Norm using minibatch statistics due to the dependency on the other samples of the batch. Could you elaborate on this point?\n", "rating": "7: Good paper, accept", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["ICLR.cc/2021/Conference/Paper819/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper819/AnonReviewer1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Deep Curvature Suite", "authorids": ["~Diego_Granziol1", "~Xingchen_Wan1", "~Timur_Garipov1"], "authors": ["Diego Granziol", "Xingchen Wan", "Timur Garipov"], "keywords": ["Hessian computation", "Deep Learning", "Loss Curvature", "Lanczos"], "abstract": "The curvature of the loss, provides rich information on the geometry underlying neural networks, with applications in second order optimisation and Bayesian deep learning. However, accessing curvature information is still a daunting engineering challenge, inaccessible to most practitioners. We hence provide a software package the \\textbf{Deep Curvature Suite}, which allows easy curvature evaluation for large modern neural networks. Beyond the calculation of a highly accurate moment matched approximation of the Hessian spectrum using Lanczos, our package provides: extensive \\emph{loss surface visualisation}, the calculation of the \\emph{Hessian variance} and \\emph{stochastic second order optimisers}. We further address and disprove many common misconceptions in the literature about the Lanczos algorithm, namely that it learns eigenvalues from the top down. We prove using high dimensional concentration inequalities that for specific matrices a single random vector is sufficient for accurate spectral estimation, informing our spectral visualisation method. We showcase our package practical utility on a series of examples based on realistic modern neural networks such as the VGG-$16$ and Preactivated ResNets on the CIFAR-$10$/$100$ datasets. We further detail $3$ specific potential use cases enabled by our software: research in stochastic second order optimisation for deep learning, learning rate scheduling using known optimality formulae for convex surfaces and empirical verification of deep learning theory based on comparing empirical and theoretically implied spectra.", "one-sentence_summary": "This package allows the easy computation and visualisation of curvature information for deep neural networks.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "granziol|deep_curvature_suite", "pdf": "/pdf/bd064814083e15af85a08d89abc0b7174024d8b2.pdf", "supplementary_material": "/attachment/ab11d8d035b3858dfff1c165d43dd5c6f92814db.zip", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=epykIrTh_f", "_bibtex": "@misc{\ngranziol2021deep,\ntitle={Deep Curvature Suite},\nauthor={Diego Granziol and Xingchen Wan and Timur Garipov},\nyear={2021},\nurl={https://openreview.net/forum?id=86t2GlfzFo}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq . ***Please remember to file the Code-of-Ethics report. Once you submitted the review, a link to the report will be visible in the bottom right corner of your review.***", "required": true, "markdown": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}, "forum": "86t2GlfzFo", "replyto": "86t2GlfzFo", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"], "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper819/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1607428800000, "duedate": 1606752000000, "multiReply": false, "readers": ["everyone"], "tcdate": 1602538069544, "tmdate": 1606915793837, "super": "ICLR.cc/2021/Conference/-/Official_Review", "signatures": ["OpenReview.net"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Paper819/Reviewers", "OpenReview.net/Support"], "id": "ICLR.cc/2021/Conference/Paper819/-/Official_Review"}}}, {"id": "Q4YyW0Lz33Z", "original": null, "number": 4, "cdate": 1604706700420, "ddate": null, "tcdate": 1604706700420, "tmdate": 1605023936019, "tddate": null, "forum": "86t2GlfzFo", "replyto": "86t2GlfzFo", "invitation": "ICLR.cc/2021/Conference/Paper819/-/Official_Review", "content": {"title": "Well-written paper and can be a good contribution to the community.", "review": "Summary:\n- This paper introduces a package for computing the second-order information of neural networks based on the Lanczos algorithm. The authors showcase the usages of the package with 1) visualizing the eigenspectrum of the curvature matrix; 2)visualizing the loss surface along with a specific direction, and 3) comparisons between different optimizers. Also, the authors claimed that they address several misconceptions about the Lanczos algorithm.\n\nOverall:\n\nThis paper is well-written and easy to follow. I believe that the developed package can be a good contribution to the machine learning community, especially for people working on second-order optimization and understanding the training dynamics and generalization performance of deep neural networks. However, I still have the following questions:\n\n-  Lanczos algorithm suffers from numerical instability. How do you deal with this issue? Can you provide more details about this?\n\n- I would suggest the authors move Section 4 to the appendix, considering the main scope of the paper is introducing a new machine learning package. In the meantime, the authors should highlight more on the difference between your package and the existing implementations. For example, you can add a table to summarize the features of all the related packages/implementations. Also, a table for comparing the running memory cost and running time cost will be very helpful.\n\nMinors:\n-  as well as the commonly used `Generalsed` Gauss Newton -> as well as the commonly used `Generalised` Gauss-Newton\n\n- The main interface functions are `organsed` as followed: -> The main interface functions are `organized` as following:\n\n- Krylov subspace K (H, v) = span{v,`H^v`,H2v...} is orthogonalised -> Krylov subspace K (H, v) = span{v,`Hv`,H2v...} is orthogonalised\n\n- the reference is missing in the main pdf.\n\n\nRating:\n- This paper did a good job of introducing the package with detailed examples. Also, this package will definitely ease the effort of researchers in related areas to compute the second-order information of the neural networks. In the meantime, I still have the concerns mentioned above. So, my rating is weak acceptance at the current stage. ", "rating": "6: Marginally above acceptance threshold", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "signatures": ["ICLR.cc/2021/Conference/Paper819/AnonReviewer4"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper819/AnonReviewer4"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Deep Curvature Suite", "authorids": ["~Diego_Granziol1", "~Xingchen_Wan1", "~Timur_Garipov1"], "authors": ["Diego Granziol", "Xingchen Wan", "Timur Garipov"], "keywords": ["Hessian computation", "Deep Learning", "Loss Curvature", "Lanczos"], "abstract": "The curvature of the loss, provides rich information on the geometry underlying neural networks, with applications in second order optimisation and Bayesian deep learning. However, accessing curvature information is still a daunting engineering challenge, inaccessible to most practitioners. We hence provide a software package the \\textbf{Deep Curvature Suite}, which allows easy curvature evaluation for large modern neural networks. Beyond the calculation of a highly accurate moment matched approximation of the Hessian spectrum using Lanczos, our package provides: extensive \\emph{loss surface visualisation}, the calculation of the \\emph{Hessian variance} and \\emph{stochastic second order optimisers}. We further address and disprove many common misconceptions in the literature about the Lanczos algorithm, namely that it learns eigenvalues from the top down. We prove using high dimensional concentration inequalities that for specific matrices a single random vector is sufficient for accurate spectral estimation, informing our spectral visualisation method. We showcase our package practical utility on a series of examples based on realistic modern neural networks such as the VGG-$16$ and Preactivated ResNets on the CIFAR-$10$/$100$ datasets. We further detail $3$ specific potential use cases enabled by our software: research in stochastic second order optimisation for deep learning, learning rate scheduling using known optimality formulae for convex surfaces and empirical verification of deep learning theory based on comparing empirical and theoretically implied spectra.", "one-sentence_summary": "This package allows the easy computation and visualisation of curvature information for deep neural networks.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "granziol|deep_curvature_suite", "pdf": "/pdf/bd064814083e15af85a08d89abc0b7174024d8b2.pdf", "supplementary_material": "/attachment/ab11d8d035b3858dfff1c165d43dd5c6f92814db.zip", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=epykIrTh_f", "_bibtex": "@misc{\ngranziol2021deep,\ntitle={Deep Curvature Suite},\nauthor={Diego Granziol and Xingchen Wan and Timur Garipov},\nyear={2021},\nurl={https://openreview.net/forum?id=86t2GlfzFo}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq . ***Please remember to file the Code-of-Ethics report. Once you submitted the review, a link to the report will be visible in the bottom right corner of your review.***", "required": true, "markdown": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}, "forum": "86t2GlfzFo", "replyto": "86t2GlfzFo", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"], "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper819/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1607428800000, "duedate": 1606752000000, "multiReply": false, "readers": ["everyone"], "tcdate": 1602538069544, "tmdate": 1606915793837, "super": "ICLR.cc/2021/Conference/-/Official_Review", "signatures": ["OpenReview.net"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Paper819/Reviewers", "OpenReview.net/Support"], "id": "ICLR.cc/2021/Conference/Paper819/-/Official_Review"}}}], "count": 6}