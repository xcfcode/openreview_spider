{"notes": [{"id": "H1lQIgrFDS", "original": "SkxK3KlYPH", "number": 2316, "cdate": 1569439818718, "ddate": null, "tcdate": 1569439818718, "tmdate": 1577168247276, "tddate": null, "forum": "H1lQIgrFDS", "replyto": null, "invitation": "ICLR.cc/2020/Conference/-/Blind_Submission", "content": {"authorids": ["2016110299@live.sufe.edu.cn", "guanghe@csail.mit.edu", "yuanyang@tsinghua.edu.cn"], "title": "$\\ell_1$ Adversarial Robustness Certificates: a Randomized Smoothing Approach", "authors": ["Jiaye Teng", "Guang-He Lee", "Yang Yuan"], "pdf": "/pdf/2b704ac5e8c7c9fc3a5c8185989a4783c804c06a.pdf", "TL;DR": "We derive the first tight $\\ell_1$ robustness certificate under isotropic Laplace distributions. ", "abstract": "Robustness is an important property to guarantee the security of machine learning models. It has recently been demonstrated that strong robustness certificates can be obtained on ensemble classifiers generated by input randomization. However, tight robustness certificates are only known for symmetric norms including $\\ell_0$ and $\\ell_2$, while for asymmetric norms like $\\ell_1$, the existing techniques do not apply. By converting the likelihood ratio into a one-dimensional mixed random variable, we derive the first tight $\\ell_1$ robustness certificate under isotropic Laplace distributions. Empirically, the deep networks smoothed by Laplace distributions yield the state-of-the-art certified robustness in $\\ell_1$ norm on CIFAR-10 and ImageNet.  ", "keywords": [], "paperhash": "teng|\\ell_1_adversarial_robustness_certificates_a_randomized_smoothing_approach", "original_pdf": "/attachment/c410ce424e0ea8bebe8147e6d0bd93fab7cf1206.pdf", "_bibtex": "@misc{\nteng2020ell,\ntitle={{\\$}{\\textbackslash}ell{\\_}1{\\$} Adversarial Robustness Certificates: a Randomized Smoothing Approach},\nauthor={Jiaye Teng and Guang-He Lee and Yang Yuan},\nyear={2020},\nurl={https://openreview.net/forum?id=H1lQIgrFDS}\n}"}, "signatures": ["ICLR.cc/2020/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference"], "details": {"replyCount": 13, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"reply": {"readers": {"values-regex": ".*"}, "writers": {"values": ["ICLR.cc/2020/Conference"]}, "signatures": {"values": ["ICLR.cc/2020/Conference"]}, "content": {"spotlight_video": {"value-regex": ".*"}, "full_presentation_video": {"value-regex": ".*"}, "original_pdf": {"required": false, "description": "Upload a PDF file that ends with .pdf", "value-regex": ".*"}, "appendix": {"value-regex": ".*"}, "authorids": {"values-regex": ".*"}, "poster": {"value-regex": ".*"}, "authors": {"values": ["Anonymous"]}, "slides": {"value-regex": ".*"}}}, "final": [], "signatures": ["ICLR.cc/2020/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference"], "noninvitees": [], "tcdate": 1569271260237, "tmdate": 1593459412141, "id": "ICLR.cc/2020/Conference/-/Blind_Submission"}}, "tauthor": "OpenReview.net"}, {"id": "34y-FdHzqx", "original": null, "number": 1, "cdate": 1576798746000, "ddate": null, "tcdate": 1576798746000, "tmdate": 1576800890124, "tddate": null, "forum": "H1lQIgrFDS", "replyto": "H1lQIgrFDS", "invitation": "ICLR.cc/2020/Conference/Paper2316/-/Decision", "content": {"decision": "Reject", "comment": "After reading the author's response, all the reviewers agree that this paper is an incremental work. The presentation need to be polished before publish.", "title": "Paper Decision"}, "signatures": ["ICLR.cc/2020/Conference/Program_Chairs"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Program_Chairs"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["2016110299@live.sufe.edu.cn", "guanghe@csail.mit.edu", "yuanyang@tsinghua.edu.cn"], "title": "$\\ell_1$ Adversarial Robustness Certificates: a Randomized Smoothing Approach", "authors": ["Jiaye Teng", "Guang-He Lee", "Yang Yuan"], "pdf": "/pdf/2b704ac5e8c7c9fc3a5c8185989a4783c804c06a.pdf", "TL;DR": "We derive the first tight $\\ell_1$ robustness certificate under isotropic Laplace distributions. ", "abstract": "Robustness is an important property to guarantee the security of machine learning models. It has recently been demonstrated that strong robustness certificates can be obtained on ensemble classifiers generated by input randomization. However, tight robustness certificates are only known for symmetric norms including $\\ell_0$ and $\\ell_2$, while for asymmetric norms like $\\ell_1$, the existing techniques do not apply. By converting the likelihood ratio into a one-dimensional mixed random variable, we derive the first tight $\\ell_1$ robustness certificate under isotropic Laplace distributions. Empirically, the deep networks smoothed by Laplace distributions yield the state-of-the-art certified robustness in $\\ell_1$ norm on CIFAR-10 and ImageNet.  ", "keywords": [], "paperhash": "teng|\\ell_1_adversarial_robustness_certificates_a_randomized_smoothing_approach", "original_pdf": "/attachment/c410ce424e0ea8bebe8147e6d0bd93fab7cf1206.pdf", "_bibtex": "@misc{\nteng2020ell,\ntitle={{\\$}{\\textbackslash}ell{\\_}1{\\$} Adversarial Robustness Certificates: a Randomized Smoothing Approach},\nauthor={Jiaye Teng and Guang-He Lee and Yang Yuan},\nyear={2020},\nurl={https://openreview.net/forum?id=H1lQIgrFDS}\n}"}, "tags": [], "invitation": {"reply": {"writers": {"description": "How your identity will be displayed.", "values-regex": ["ICLR.cc/2020/Conference/Program_Chairs"]}, "signatures": {"values": ["ICLR.cc/2020/Conference/Program_Chairs"], "description": "How your identity will be displayed."}, "content": {"decision": {"value-radio": ["Accept (Spotlight)", "Accept (Talk)", "Accept (Poster)", "Reject"], "description": "Decision", "required": true, "order": 2}, "title": {"value": "Paper Decision", "required": true, "order": 1}, "comment": {"value-regex": "[\\S\\s]{0,5000}", "description": "", "required": false, "order": 3}}, "forum": "H1lQIgrFDS", "replyto": "H1lQIgrFDS", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}}, "expdate": 1576854540000, "duedate": 1576853940000, "multiReply": false, "readers": ["everyone"], "invitees": ["ICLR.cc/2020/Conference/Program_Chairs"], "tcdate": 1576795712121, "tmdate": 1576800261449, "super": "ICLR.cc/2020/Conference/-/Decision", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper2316/-/Decision"}}}, {"id": "rkgZIzOmqS", "original": null, "number": 3, "cdate": 1572205129284, "ddate": null, "tcdate": 1572205129284, "tmdate": 1574273415822, "tddate": null, "forum": "H1lQIgrFDS", "replyto": "H1lQIgrFDS", "invitation": "ICLR.cc/2020/Conference/Paper2316/-/Official_Review", "content": {"experience_assessment": "I have published in this field for several years.", "rating": "6: Weak Accept", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "title": "Official Blind Review #2", "review": "The paper provides a random smoothing technique for L1 perturbation and proves the tightness results for binary classification case. Overall, there are some new results in this paper -- establishing a new certificate bounds for L1 perturbation model. However, I have several concerns about whether this contribution is significant enough: \n\nRandom smoothing has been studied extensively recently and the proof technique in this paper is not so different from previous papers (Cohen et al, Li et al). Also, there were L0 perturbation bounds proposed by (Leet et al). Therefore, although I agree that a tighter certified bound compared to (Lecuyer et al) is new, the paper seems to be a bit incremental. It will be more interesting to see if the proposed technique/theorem can be used for a wider range of norms. \n\nAlso, it may be more interesting to add some discussions about why L1 perturbation is important for image classification (is it more human-imperceptible?)\n\n=======\n\nI have checked the rebuttal and other reviewers' comments. Although there are interesting components in this paper, I do agree that the paper is incremental given that many random smoothing methods have been proposed recently for L2, L_infty norms. Therefore I think this is a borderline case and will be ok with rejection. ", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory."}, "signatures": ["ICLR.cc/2020/Conference/Paper2316/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper2316/AnonReviewer2"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["2016110299@live.sufe.edu.cn", "guanghe@csail.mit.edu", "yuanyang@tsinghua.edu.cn"], "title": "$\\ell_1$ Adversarial Robustness Certificates: a Randomized Smoothing Approach", "authors": ["Jiaye Teng", "Guang-He Lee", "Yang Yuan"], "pdf": "/pdf/2b704ac5e8c7c9fc3a5c8185989a4783c804c06a.pdf", "TL;DR": "We derive the first tight $\\ell_1$ robustness certificate under isotropic Laplace distributions. ", "abstract": "Robustness is an important property to guarantee the security of machine learning models. It has recently been demonstrated that strong robustness certificates can be obtained on ensemble classifiers generated by input randomization. However, tight robustness certificates are only known for symmetric norms including $\\ell_0$ and $\\ell_2$, while for asymmetric norms like $\\ell_1$, the existing techniques do not apply. By converting the likelihood ratio into a one-dimensional mixed random variable, we derive the first tight $\\ell_1$ robustness certificate under isotropic Laplace distributions. Empirically, the deep networks smoothed by Laplace distributions yield the state-of-the-art certified robustness in $\\ell_1$ norm on CIFAR-10 and ImageNet.  ", "keywords": [], "paperhash": "teng|\\ell_1_adversarial_robustness_certificates_a_randomized_smoothing_approach", "original_pdf": "/attachment/c410ce424e0ea8bebe8147e6d0bd93fab7cf1206.pdf", "_bibtex": "@misc{\nteng2020ell,\ntitle={{\\$}{\\textbackslash}ell{\\_}1{\\$} Adversarial Robustness Certificates: a Randomized Smoothing Approach},\nauthor={Jiaye Teng and Guang-He Lee and Yang Yuan},\nyear={2020},\nurl={https://openreview.net/forum?id=H1lQIgrFDS}\n}"}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "H1lQIgrFDS", "replyto": "H1lQIgrFDS", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper2316/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper2316/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1574941270193, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper2316/Reviewers"], "noninvitees": [], "tcdate": 1570237724567, "tmdate": 1574941270205, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper2316/-/Official_Review"}}}, {"id": "rJgvdv2isB", "original": null, "number": 6, "cdate": 1573795695184, "ddate": null, "tcdate": 1573795695184, "tmdate": 1573795695184, "tddate": null, "forum": "H1lQIgrFDS", "replyto": "SklWazkntr", "invitation": "ICLR.cc/2020/Conference/Paper2316/-/Official_Comment", "content": {"title": "Thank you for your review", "comment": "We thank the reviewer for the insightful comments and questions. Please also see our general response above.\n\nQ1: Thanks for the suggestions. We will revise the abstract in later revision.\n\nQ2: Sorry for the confusion. M is T(x), which is a mixed random variable.\n\nQ3: Fig. 3 shows an example of CDF of a mixed random variable M to better understand T(x). Mixed random variables are neither discrete random variables nor continuous random variables (e.g., the sum of a geometric random variable and a Gaussian random variable).\n\nIn Fig. 3, M=X \\mathbb{I}(X !\\in [0.95,2.95])+Pr(X \\in [0.95, 0.95+2/3])*\\delta(x;a=0.95+2/3) +Pr(X \\in [0.95+2/3, 0.95+4/3])*\\delta(x; a=0.95+4/3)+Pr(X \\in [0.95+4/3, 0.95+2])*\\delta(x; a=2.95). (\\delta(x;a) is a dirac delta function, X ~ Exponential(1)). Similarly, T(x) is a mixed random variable, and follows a similar CDF.\n\nMinor measure-theoretic clarification: by definition, a mixed random variable does not admit a probability density function, although a mixed random variable can still have continuous range. \n\nQ4: Yes, the multi-class setting is developed in Theorem 1. Note that Pa and Pb in Theorem 1 denote the prediction probabilities for the most probable and the second most probable classes, respectively, in a multi-class setting. \n\nQ5: Wang et al. developed a theoretically motivated approach to improve ResNet models. However, such improvement cannot be practically certified: it relies on an attack algorithm (e.g., PGD) to show robustness. In contrast, we can compute a robustness certificate, which *proves* that no adversary exists within the certified region. We have updated our paper and made a clarification. Thank you for your reference!"}, "signatures": ["ICLR.cc/2020/Conference/Paper2316/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper2316/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["2016110299@live.sufe.edu.cn", "guanghe@csail.mit.edu", "yuanyang@tsinghua.edu.cn"], "title": "$\\ell_1$ Adversarial Robustness Certificates: a Randomized Smoothing Approach", "authors": ["Jiaye Teng", "Guang-He Lee", "Yang Yuan"], "pdf": "/pdf/2b704ac5e8c7c9fc3a5c8185989a4783c804c06a.pdf", "TL;DR": "We derive the first tight $\\ell_1$ robustness certificate under isotropic Laplace distributions. ", "abstract": "Robustness is an important property to guarantee the security of machine learning models. It has recently been demonstrated that strong robustness certificates can be obtained on ensemble classifiers generated by input randomization. However, tight robustness certificates are only known for symmetric norms including $\\ell_0$ and $\\ell_2$, while for asymmetric norms like $\\ell_1$, the existing techniques do not apply. By converting the likelihood ratio into a one-dimensional mixed random variable, we derive the first tight $\\ell_1$ robustness certificate under isotropic Laplace distributions. Empirically, the deep networks smoothed by Laplace distributions yield the state-of-the-art certified robustness in $\\ell_1$ norm on CIFAR-10 and ImageNet.  ", "keywords": [], "paperhash": "teng|\\ell_1_adversarial_robustness_certificates_a_randomized_smoothing_approach", "original_pdf": "/attachment/c410ce424e0ea8bebe8147e6d0bd93fab7cf1206.pdf", "_bibtex": "@misc{\nteng2020ell,\ntitle={{\\$}{\\textbackslash}ell{\\_}1{\\$} Adversarial Robustness Certificates: a Randomized Smoothing Approach},\nauthor={Jiaye Teng and Guang-He Lee and Yang Yuan},\nyear={2020},\nurl={https://openreview.net/forum?id=H1lQIgrFDS}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "H1lQIgrFDS", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper2316/Authors", "ICLR.cc/2020/Conference/Paper2316/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper2316/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper2316/Reviewers", "ICLR.cc/2020/Conference/Paper2316/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper2316/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper2316/Authors|ICLR.cc/2020/Conference/Paper2316/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504143168, "tmdate": 1576860548224, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper2316/Authors", "ICLR.cc/2020/Conference/Paper2316/Reviewers", "ICLR.cc/2020/Conference/Paper2316/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper2316/-/Official_Comment"}}}, {"id": "rkgObP2isS", "original": null, "number": 5, "cdate": 1573795583585, "ddate": null, "tcdate": 1573795583585, "tmdate": 1573795583585, "tddate": null, "forum": "H1lQIgrFDS", "replyto": "rJxnt1oTtB", "invitation": "ICLR.cc/2020/Conference/Paper2316/-/Official_Comment", "content": {"title": "Thank you for your review ", "comment": "We thank the reviewer for the insightful comments and questions. Please also see our general response above.\n\nRe \u201cafter noting that the radius can be deduced from the work of Li et al.\u201d: \n\nThis seems unfair for evaluating this work. After the first proof of tight results with Gaussian distribution by Cohen et al. (2019), Levine et al. (2019) and Salman et al. (2019) find simpler ways to derive the certificate by other approaches. These follow-up works do not invalidate Cohen et al. (2019). Similarly, Li et al. did not have the Laplace result before the dissemination of this work, and thus their deduction does not invalidate this work (let alone the fact that we even prove the tightness).\n\nRe \u201ca justification for why would one prefer a Laplacian noise of a Gaussian noise\u201d:\n\nOne justification is that, since Laplace distributions puts more weight on the center than Gaussian distributions, Laplace noises are less prone to (negatively) impacting the prediction of the base classifier f than Gaussian noises. Indeed, taking a ResNet110 model on CIFAR-10 (trained without smoothing), we can obtain 24.8% accuracy by using a Laplace noise (variance = 0.12), while the Gaussian noise with the same variance would yield 23.7% accuracy. Here the accuracy is computed with respect to predictions of the base classifier instead of the labels (to illustrate how the smoothing impacts the predictions). \n\nWe formalize the intuition in terms of the sensitivity of the noise distributions with respect to their hyperparameters (\\lambda and \\sigma), and prove that the Laplace noise is less sensitive than the Gaussian noise in terms of negatively impacting the base classifier f. This implies that it is easier to set the hyperparameter for the Laplace noises than Gaussian noises. For a detailed justification, please see Appendix D in the updated version. \nWe do acknowledge that the two distributions are equally competent since the certifiable range are both [0, \\infty). However, the resulting certificates of the two distributions are quite different in practice. An analogy would be architecture design in deep learning research. While existing architectures already exhibit universal approximation / turing completeness, new architectures with suitable inductive bias still improve the empirical performance quite a lot. Here Laplace noises can be regarded as an infinite mixture of L1 balls, which may be a suitable inductive bias for L1 robustness. Empirically, we indeed found that Laplace noises are much better than Gaussian noises for L1 robustness. \n\nTechnical clarification: the L1 and L2 certificates of the Gaussian noise are exactly the same (there is no \\sqrt{n} scaling). The reason is that given any L1/L2 radius r, we can show that the perturbation [r, 0, 0, \u2026, 0] will be a theoretical worst case for Gaussian noises. As a result, the worst cases in L1 and L2 coincide, so the resulting certificates are exactly the same. One may prove the result by the fact that all the points within an L2 sphere have the same worst case prediction value under Gaussian noise (see Cohen et al.).\n\nQ1-Q4. Sorry for the confusion. M is T(x). We have corrected some figures and rearranged our writing. Thank you for the suggestions.\n\nQ5: Inconsistency between Cohen et. al. and Lecuyer et. al. in Figure 6 with Figure 5 of Cohen et al.\nA: Cohen et. al. shows the result of \\ell_2 norm radius, while ours shows the \\ell_1 norm radius. Lecuyer et al. have two certificates (for \\ell_1 and \\ell_2, respectively). In our paper we use the \\ell_1 version while in Cohen et al. they use \\ell_2 version, so they look different.  \n\n"}, "signatures": ["ICLR.cc/2020/Conference/Paper2316/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper2316/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["2016110299@live.sufe.edu.cn", "guanghe@csail.mit.edu", "yuanyang@tsinghua.edu.cn"], "title": "$\\ell_1$ Adversarial Robustness Certificates: a Randomized Smoothing Approach", "authors": ["Jiaye Teng", "Guang-He Lee", "Yang Yuan"], "pdf": "/pdf/2b704ac5e8c7c9fc3a5c8185989a4783c804c06a.pdf", "TL;DR": "We derive the first tight $\\ell_1$ robustness certificate under isotropic Laplace distributions. ", "abstract": "Robustness is an important property to guarantee the security of machine learning models. It has recently been demonstrated that strong robustness certificates can be obtained on ensemble classifiers generated by input randomization. However, tight robustness certificates are only known for symmetric norms including $\\ell_0$ and $\\ell_2$, while for asymmetric norms like $\\ell_1$, the existing techniques do not apply. By converting the likelihood ratio into a one-dimensional mixed random variable, we derive the first tight $\\ell_1$ robustness certificate under isotropic Laplace distributions. Empirically, the deep networks smoothed by Laplace distributions yield the state-of-the-art certified robustness in $\\ell_1$ norm on CIFAR-10 and ImageNet.  ", "keywords": [], "paperhash": "teng|\\ell_1_adversarial_robustness_certificates_a_randomized_smoothing_approach", "original_pdf": "/attachment/c410ce424e0ea8bebe8147e6d0bd93fab7cf1206.pdf", "_bibtex": "@misc{\nteng2020ell,\ntitle={{\\$}{\\textbackslash}ell{\\_}1{\\$} Adversarial Robustness Certificates: a Randomized Smoothing Approach},\nauthor={Jiaye Teng and Guang-He Lee and Yang Yuan},\nyear={2020},\nurl={https://openreview.net/forum?id=H1lQIgrFDS}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "H1lQIgrFDS", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper2316/Authors", "ICLR.cc/2020/Conference/Paper2316/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper2316/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper2316/Reviewers", "ICLR.cc/2020/Conference/Paper2316/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper2316/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper2316/Authors|ICLR.cc/2020/Conference/Paper2316/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504143168, "tmdate": 1576860548224, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper2316/Authors", "ICLR.cc/2020/Conference/Paper2316/Reviewers", "ICLR.cc/2020/Conference/Paper2316/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper2316/-/Official_Comment"}}}, {"id": "HyxgtI3soS", "original": null, "number": 4, "cdate": 1573795448347, "ddate": null, "tcdate": 1573795448347, "tmdate": 1573795448347, "tddate": null, "forum": "H1lQIgrFDS", "replyto": "rkgZIzOmqS", "invitation": "ICLR.cc/2020/Conference/Paper2316/-/Official_Comment", "content": {"title": "Thank you for your review", "comment": "We thank the reviewer for the insightful comments and questions. Please also see our general response above.\n\nQ: Novelty and significance\nA: One part of our proof indeed uses the same Neyman-Pearson Lemma as (Cohen et al.), but our tightness proof result is new and cannot be derived from the existing approaches. \n\nQ: Importance of L1 perturbation\nA: Our explanation is that L1 distance is easier to interpret than L2 distance since L1 is simply the summation of absolute values without a nonlinear square root. Also, L1 has been widely studied in literature for measuring sparsity (thus connecting to sparse adversarial perturbations). "}, "signatures": ["ICLR.cc/2020/Conference/Paper2316/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper2316/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["2016110299@live.sufe.edu.cn", "guanghe@csail.mit.edu", "yuanyang@tsinghua.edu.cn"], "title": "$\\ell_1$ Adversarial Robustness Certificates: a Randomized Smoothing Approach", "authors": ["Jiaye Teng", "Guang-He Lee", "Yang Yuan"], "pdf": "/pdf/2b704ac5e8c7c9fc3a5c8185989a4783c804c06a.pdf", "TL;DR": "We derive the first tight $\\ell_1$ robustness certificate under isotropic Laplace distributions. ", "abstract": "Robustness is an important property to guarantee the security of machine learning models. It has recently been demonstrated that strong robustness certificates can be obtained on ensemble classifiers generated by input randomization. However, tight robustness certificates are only known for symmetric norms including $\\ell_0$ and $\\ell_2$, while for asymmetric norms like $\\ell_1$, the existing techniques do not apply. By converting the likelihood ratio into a one-dimensional mixed random variable, we derive the first tight $\\ell_1$ robustness certificate under isotropic Laplace distributions. Empirically, the deep networks smoothed by Laplace distributions yield the state-of-the-art certified robustness in $\\ell_1$ norm on CIFAR-10 and ImageNet.  ", "keywords": [], "paperhash": "teng|\\ell_1_adversarial_robustness_certificates_a_randomized_smoothing_approach", "original_pdf": "/attachment/c410ce424e0ea8bebe8147e6d0bd93fab7cf1206.pdf", "_bibtex": "@misc{\nteng2020ell,\ntitle={{\\$}{\\textbackslash}ell{\\_}1{\\$} Adversarial Robustness Certificates: a Randomized Smoothing Approach},\nauthor={Jiaye Teng and Guang-He Lee and Yang Yuan},\nyear={2020},\nurl={https://openreview.net/forum?id=H1lQIgrFDS}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "H1lQIgrFDS", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper2316/Authors", "ICLR.cc/2020/Conference/Paper2316/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper2316/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper2316/Reviewers", "ICLR.cc/2020/Conference/Paper2316/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper2316/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper2316/Authors|ICLR.cc/2020/Conference/Paper2316/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504143168, "tmdate": 1576860548224, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper2316/Authors", "ICLR.cc/2020/Conference/Paper2316/Reviewers", "ICLR.cc/2020/Conference/Paper2316/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper2316/-/Official_Comment"}}}, {"id": "H1xWW82jiH", "original": null, "number": 3, "cdate": 1573795321252, "ddate": null, "tcdate": 1573795321252, "tmdate": 1573795321252, "tddate": null, "forum": "H1lQIgrFDS", "replyto": "H1lQIgrFDS", "invitation": "ICLR.cc/2020/Conference/Paper2316/-/Official_Comment", "content": {"title": "General response", "comment": "We thank the reviewers for the insightful comments and questions. \n\nWe would like to clarify the novelty and significance of this paper. \n\nThis is an initial but important attempt towards tight results for general Lp norm and other distributions that inevitably involve mixed random variable analysis (cf. Gaussian and discrete) and asymmetric norms (cf. L2 and L0). While existing approaches fails in these challenging cases, our approach illustrates that tight results are still viable, and shines light on how these challenging cases can be tackled in general.\n\nThis work should be treated as an (Laplace, L1) analogy to the (Gaussian, L2) case proved by (Cohen et al.), which also improves (Lecuyer et al.) and proves that their result is tight. "}, "signatures": ["ICLR.cc/2020/Conference/Paper2316/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper2316/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["2016110299@live.sufe.edu.cn", "guanghe@csail.mit.edu", "yuanyang@tsinghua.edu.cn"], "title": "$\\ell_1$ Adversarial Robustness Certificates: a Randomized Smoothing Approach", "authors": ["Jiaye Teng", "Guang-He Lee", "Yang Yuan"], "pdf": "/pdf/2b704ac5e8c7c9fc3a5c8185989a4783c804c06a.pdf", "TL;DR": "We derive the first tight $\\ell_1$ robustness certificate under isotropic Laplace distributions. ", "abstract": "Robustness is an important property to guarantee the security of machine learning models. It has recently been demonstrated that strong robustness certificates can be obtained on ensemble classifiers generated by input randomization. However, tight robustness certificates are only known for symmetric norms including $\\ell_0$ and $\\ell_2$, while for asymmetric norms like $\\ell_1$, the existing techniques do not apply. By converting the likelihood ratio into a one-dimensional mixed random variable, we derive the first tight $\\ell_1$ robustness certificate under isotropic Laplace distributions. Empirically, the deep networks smoothed by Laplace distributions yield the state-of-the-art certified robustness in $\\ell_1$ norm on CIFAR-10 and ImageNet.  ", "keywords": [], "paperhash": "teng|\\ell_1_adversarial_robustness_certificates_a_randomized_smoothing_approach", "original_pdf": "/attachment/c410ce424e0ea8bebe8147e6d0bd93fab7cf1206.pdf", "_bibtex": "@misc{\nteng2020ell,\ntitle={{\\$}{\\textbackslash}ell{\\_}1{\\$} Adversarial Robustness Certificates: a Randomized Smoothing Approach},\nauthor={Jiaye Teng and Guang-He Lee and Yang Yuan},\nyear={2020},\nurl={https://openreview.net/forum?id=H1lQIgrFDS}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "H1lQIgrFDS", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper2316/Authors", "ICLR.cc/2020/Conference/Paper2316/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper2316/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper2316/Reviewers", "ICLR.cc/2020/Conference/Paper2316/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper2316/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper2316/Authors|ICLR.cc/2020/Conference/Paper2316/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504143168, "tmdate": 1576860548224, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper2316/Authors", "ICLR.cc/2020/Conference/Paper2316/Reviewers", "ICLR.cc/2020/Conference/Paper2316/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper2316/-/Official_Comment"}}}, {"id": "SklWazkntr", "original": null, "number": 1, "cdate": 1571709625235, "ddate": null, "tcdate": 1571709625235, "tmdate": 1572972354674, "tddate": null, "forum": "H1lQIgrFDS", "replyto": "H1lQIgrFDS", "invitation": "ICLR.cc/2020/Conference/Paper2316/-/Official_Review", "content": {"rating": "3: Weak Reject", "experience_assessment": "I have read many papers in this area.", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #1", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review": "In this paper, the author derived a tight ell_1, which is not the symmetric norm, robustness certificates under isotropic Laplace distributions. Experimentally, the authors showed that the deep networks smoothed \nby Laplace distributions yield the state-of-the-art certified robustness in ell_1 norm on the CIFAR-10 \nand ImageNet. To find the ell_1 certificate, the authors first identified the tight robustness certificate, for attacking the model in one particular direction, say the first direction. To show that any other perturbation directions cannot lead to a worse result, the authors convert the d dimensional likelihood function into a one-dimensional function, and the authors used relaxation for different perturbations and show that the worst-case result is bounded by the previously identified direction.  However, I have the following concerns about this work:\n\n1. Theoretically, the authors only showed the certificate is tight for binary classification. I would suggest\nthe author change their claim in the abstract.\n\n2. What is M on page 3 which is used without definition after definition 1?\n\n3. Can you give a concrete continuous probability distribution that leads to the scenario in Fig.~3?\n\n4. Can you extend the analysis to a multi-class classification scenario?\n\n5. Besides randomized smoothing on the input images, recently Wang et al showed that randomize the deep nets can\nalso improve the deep nets and they gave it a nice theoretical interpretation. Here is the reference: Bao Wang, Binjie Yuan, Zuoqiang Shi, Stanley J. Osher. ResNets Ensemble via the Feynman-Kac Formalism to Improve Natural and Robust Accuracies, arXiv:1811.10745, NeurIPS, 2019\n\nOverall, since this work is a straightforward integration of some existing work, I think this\npaper lack novelty. Please address the above questions in rebuttal."}, "signatures": ["ICLR.cc/2020/Conference/Paper2316/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper2316/AnonReviewer1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["2016110299@live.sufe.edu.cn", "guanghe@csail.mit.edu", "yuanyang@tsinghua.edu.cn"], "title": "$\\ell_1$ Adversarial Robustness Certificates: a Randomized Smoothing Approach", "authors": ["Jiaye Teng", "Guang-He Lee", "Yang Yuan"], "pdf": "/pdf/2b704ac5e8c7c9fc3a5c8185989a4783c804c06a.pdf", "TL;DR": "We derive the first tight $\\ell_1$ robustness certificate under isotropic Laplace distributions. ", "abstract": "Robustness is an important property to guarantee the security of machine learning models. It has recently been demonstrated that strong robustness certificates can be obtained on ensemble classifiers generated by input randomization. However, tight robustness certificates are only known for symmetric norms including $\\ell_0$ and $\\ell_2$, while for asymmetric norms like $\\ell_1$, the existing techniques do not apply. By converting the likelihood ratio into a one-dimensional mixed random variable, we derive the first tight $\\ell_1$ robustness certificate under isotropic Laplace distributions. Empirically, the deep networks smoothed by Laplace distributions yield the state-of-the-art certified robustness in $\\ell_1$ norm on CIFAR-10 and ImageNet.  ", "keywords": [], "paperhash": "teng|\\ell_1_adversarial_robustness_certificates_a_randomized_smoothing_approach", "original_pdf": "/attachment/c410ce424e0ea8bebe8147e6d0bd93fab7cf1206.pdf", "_bibtex": "@misc{\nteng2020ell,\ntitle={{\\$}{\\textbackslash}ell{\\_}1{\\$} Adversarial Robustness Certificates: a Randomized Smoothing Approach},\nauthor={Jiaye Teng and Guang-He Lee and Yang Yuan},\nyear={2020},\nurl={https://openreview.net/forum?id=H1lQIgrFDS}\n}"}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "H1lQIgrFDS", "replyto": "H1lQIgrFDS", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper2316/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper2316/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1574941270193, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper2316/Reviewers"], "noninvitees": [], "tcdate": 1570237724567, "tmdate": 1574941270205, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper2316/-/Official_Review"}}}, {"id": "rJxnt1oTtB", "original": null, "number": 2, "cdate": 1571823491665, "ddate": null, "tcdate": 1571823491665, "tmdate": 1572972354636, "tddate": null, "forum": "H1lQIgrFDS", "replyto": "H1lQIgrFDS", "invitation": "ICLR.cc/2020/Conference/Paper2316/-/Official_Review", "content": {"experience_assessment": "I have published one or two papers in this area.", "rating": "3: Weak Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #3", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "Summary.\n\nThe authors propose a new certified classifier in \\ell_1 norm that is tight. That is to say, upon smoothing a given classifier f with Laplacian noise, a smoothed version of that classifier (probabilistic maximum majority vote) is certified with a radius measured in \\ell_1 norm. The authors show that this bound is tight for binary classifiers. These results are complementary to Cohen et al. results.\n\nMajor comments.\n\n1) The major contribution of this paper is the tightness under the \\ell_1 norm for a binary classifier. I do not find this particularly significant. The question is of what value is such a result other than a mathematical exercise. For instance a good justification that the paper is lacking could be one where authors show that their radius is indeed tighter than all other works. The paper still lacks this (I will elaborate on this later), although, their bounds are indeed tighter than Lecure's et al. Since it is not clear whether or not the new certified smoothed classifier has indeed the largest radius among all other works, then at least a justification for why would one prefer a Laplacian noise of a Gaussian noise. Why is Gaussian smoothing sufficient for this purpose given that we do not know for sure that the radius is larger?  What value/advantages does this add? The authors motivate their work by saying deriving the tightest \\ell_1 is difficult due to the \"asymmetry\"  of the norm. While I do agree on this; however, this is not enough motivation as we we are doing doing abstract maths here.\n\nThe new derived radius is not really comparable to the Gaussian radius with \\ell_2 radius and this is my major concern. By norm equivalence, we have that \\ell_2 \\leq \\ell_1 \\leq \\sqrt{n} \\ell_2 where n is the dimension. That is to say that the radius computed with \\ell_1 is larger than the \\ell_2 in some cases by a square root of dimension. The authors can correct me on this if I'm wrong, but for a fair comparison in worst case sense the radius of Cohen et al. should be scaled by \\sqrt{n}. In such a scenario, it is really difficult to understand when does it make sense to tackle such a smoothing technique as opposed to Gaussian smoothing.\n\nI would not have asked the authors about such a question if the authors derived generic radius under \\ell_p smoothing (which is difficult of course). To this end, I believe since the motivation is not clear nor the results are generic enough, I find the work incremental specifically after noting that the radius can be deduced from the work of Li et al. where the main contribution here is the tightness of the radius for a binary classifier.\n\n\nMoreover, I believe the paper still requires some polishing in terms of writing and presentation.\n\nSome more comments.\n\nI believe the paper can benefit from some rewriting. Here is a list of things the authors can do to improve the paper.\n\n1) Define what M is, page 3 \"and it is easy to see that M is a mixed random variable\". I believe the authors meant T(x).\n2) The figures are hardly readable. For instance, authors can perhaps increase the legend's font size in figures 4. Also the chosen colors are suboptimal (perhaps the line width of the plots) should be increased. \n3) The section below Theorem 3 should be moved up to before Theorem 3 as this discusses the proof of Theorem 2. Once a Theorem is presented, the proof sketch should follow.\n4) Experiments on the undefended classifier has to be in Figures 6  7 and 8.\n5) Lastly, why are comparison between Cohen et. al. and Lecuyer et. al. in Figure 6 inconsistent with Figure 5 of Cohen et al."}, "signatures": ["ICLR.cc/2020/Conference/Paper2316/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper2316/AnonReviewer3"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["2016110299@live.sufe.edu.cn", "guanghe@csail.mit.edu", "yuanyang@tsinghua.edu.cn"], "title": "$\\ell_1$ Adversarial Robustness Certificates: a Randomized Smoothing Approach", "authors": ["Jiaye Teng", "Guang-He Lee", "Yang Yuan"], "pdf": "/pdf/2b704ac5e8c7c9fc3a5c8185989a4783c804c06a.pdf", "TL;DR": "We derive the first tight $\\ell_1$ robustness certificate under isotropic Laplace distributions. ", "abstract": "Robustness is an important property to guarantee the security of machine learning models. It has recently been demonstrated that strong robustness certificates can be obtained on ensemble classifiers generated by input randomization. However, tight robustness certificates are only known for symmetric norms including $\\ell_0$ and $\\ell_2$, while for asymmetric norms like $\\ell_1$, the existing techniques do not apply. By converting the likelihood ratio into a one-dimensional mixed random variable, we derive the first tight $\\ell_1$ robustness certificate under isotropic Laplace distributions. Empirically, the deep networks smoothed by Laplace distributions yield the state-of-the-art certified robustness in $\\ell_1$ norm on CIFAR-10 and ImageNet.  ", "keywords": [], "paperhash": "teng|\\ell_1_adversarial_robustness_certificates_a_randomized_smoothing_approach", "original_pdf": "/attachment/c410ce424e0ea8bebe8147e6d0bd93fab7cf1206.pdf", "_bibtex": "@misc{\nteng2020ell,\ntitle={{\\$}{\\textbackslash}ell{\\_}1{\\$} Adversarial Robustness Certificates: a Randomized Smoothing Approach},\nauthor={Jiaye Teng and Guang-He Lee and Yang Yuan},\nyear={2020},\nurl={https://openreview.net/forum?id=H1lQIgrFDS}\n}"}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "H1lQIgrFDS", "replyto": "H1lQIgrFDS", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper2316/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper2316/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1574941270193, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper2316/Reviewers"], "noninvitees": [], "tcdate": 1570237724567, "tmdate": 1574941270205, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper2316/-/Official_Review"}}}, {"id": "HkeDpYAGYH", "original": null, "number": 2, "cdate": 1571117503353, "ddate": null, "tcdate": 1571117503353, "tmdate": 1571117503353, "tddate": null, "forum": "H1lQIgrFDS", "replyto": "rJgZs-Waur", "invitation": "ICLR.cc/2020/Conference/Paper2316/-/Official_Comment", "content": {"comment": "Dear Anthony, \n\nThank you for the reference! The results in Pinot et al. (2019) are very great. The work addressed adversarial robustness for risk (expectation over data distribution). We will definitely add a discussion paragraph in the next revision. \n\nHowever, the paper (Pinot et al., 2019) is fundamentally different from ours. We work on robustness certificates for any (x_i, y_i) pairs, while Pinot et al. (2019) work on robustness guarantee for risk. Specifically, for every given x_i, we can really compute a radius R, such that for any perturbation \\delta s.t. \\|\\delta\\|_1 < R cannot alter the prediction (i.e., we guarantee g(x_i) = g(x_i + \\delta)). Pinot et al. (2019) gave robustness guarantee for risk (including generalization gap), and they did not provide robustness certificates. \n\nAs a side node, we would like to point out that we also proved the *tightness* of our L1 certificates, including both upper and lower bounds, which is new and non-trivial. Pinot et al. (2019) did not show tightness results. \n\nBest Regards, \nAuthors", "title": "responses to \"A closely related paper\""}, "signatures": ["ICLR.cc/2020/Conference/Paper2316/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper2316/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["2016110299@live.sufe.edu.cn", "guanghe@csail.mit.edu", "yuanyang@tsinghua.edu.cn"], "title": "$\\ell_1$ Adversarial Robustness Certificates: a Randomized Smoothing Approach", "authors": ["Jiaye Teng", "Guang-He Lee", "Yang Yuan"], "pdf": "/pdf/2b704ac5e8c7c9fc3a5c8185989a4783c804c06a.pdf", "TL;DR": "We derive the first tight $\\ell_1$ robustness certificate under isotropic Laplace distributions. ", "abstract": "Robustness is an important property to guarantee the security of machine learning models. It has recently been demonstrated that strong robustness certificates can be obtained on ensemble classifiers generated by input randomization. However, tight robustness certificates are only known for symmetric norms including $\\ell_0$ and $\\ell_2$, while for asymmetric norms like $\\ell_1$, the existing techniques do not apply. By converting the likelihood ratio into a one-dimensional mixed random variable, we derive the first tight $\\ell_1$ robustness certificate under isotropic Laplace distributions. Empirically, the deep networks smoothed by Laplace distributions yield the state-of-the-art certified robustness in $\\ell_1$ norm on CIFAR-10 and ImageNet.  ", "keywords": [], "paperhash": "teng|\\ell_1_adversarial_robustness_certificates_a_randomized_smoothing_approach", "original_pdf": "/attachment/c410ce424e0ea8bebe8147e6d0bd93fab7cf1206.pdf", "_bibtex": "@misc{\nteng2020ell,\ntitle={{\\$}{\\textbackslash}ell{\\_}1{\\$} Adversarial Robustness Certificates: a Randomized Smoothing Approach},\nauthor={Jiaye Teng and Guang-He Lee and Yang Yuan},\nyear={2020},\nurl={https://openreview.net/forum?id=H1lQIgrFDS}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "H1lQIgrFDS", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper2316/Authors", "ICLR.cc/2020/Conference/Paper2316/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper2316/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper2316/Reviewers", "ICLR.cc/2020/Conference/Paper2316/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper2316/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper2316/Authors|ICLR.cc/2020/Conference/Paper2316/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504143168, "tmdate": 1576860548224, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper2316/Authors", "ICLR.cc/2020/Conference/Paper2316/Reviewers", "ICLR.cc/2020/Conference/Paper2316/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper2316/-/Official_Comment"}}}, {"id": "rJgZs-Waur", "original": null, "number": 3, "cdate": 1570734488952, "ddate": null, "tcdate": 1570734488952, "tmdate": 1570735711491, "tddate": null, "forum": "H1lQIgrFDS", "replyto": "H1lQIgrFDS", "invitation": "ICLR.cc/2020/Conference/Paper2316/-/Public_Comment", "content": {"comment": "Great work and I really enjoy reading it.\n\nHowever, previous work has studied the robustness theory of randomization techniques on the general family of exponential distributions. Please check out this paper [1], where the randomized models with the Laplace distributions are also considered.\n\n In my opinion, a discussion/comparison seems due.\n\n[1] Theoretical evidence for adversarial robustness through randomization. NeurIPS 2019\n", "title": "A closely related paper"}, "signatures": ["~Anthony_Wittmer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["~Anthony_Wittmer1", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["2016110299@live.sufe.edu.cn", "guanghe@csail.mit.edu", "yuanyang@tsinghua.edu.cn"], "title": "$\\ell_1$ Adversarial Robustness Certificates: a Randomized Smoothing Approach", "authors": ["Jiaye Teng", "Guang-He Lee", "Yang Yuan"], "pdf": "/pdf/2b704ac5e8c7c9fc3a5c8185989a4783c804c06a.pdf", "TL;DR": "We derive the first tight $\\ell_1$ robustness certificate under isotropic Laplace distributions. ", "abstract": "Robustness is an important property to guarantee the security of machine learning models. It has recently been demonstrated that strong robustness certificates can be obtained on ensemble classifiers generated by input randomization. However, tight robustness certificates are only known for symmetric norms including $\\ell_0$ and $\\ell_2$, while for asymmetric norms like $\\ell_1$, the existing techniques do not apply. By converting the likelihood ratio into a one-dimensional mixed random variable, we derive the first tight $\\ell_1$ robustness certificate under isotropic Laplace distributions. Empirically, the deep networks smoothed by Laplace distributions yield the state-of-the-art certified robustness in $\\ell_1$ norm on CIFAR-10 and ImageNet.  ", "keywords": [], "paperhash": "teng|\\ell_1_adversarial_robustness_certificates_a_randomized_smoothing_approach", "original_pdf": "/attachment/c410ce424e0ea8bebe8147e6d0bd93fab7cf1206.pdf", "_bibtex": "@misc{\nteng2020ell,\ntitle={{\\$}{\\textbackslash}ell{\\_}1{\\$} Adversarial Robustness Certificates: a Randomized Smoothing Approach},\nauthor={Jiaye Teng and Guang-He Lee and Yang Yuan},\nyear={2020},\nurl={https://openreview.net/forum?id=H1lQIgrFDS}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "H1lQIgrFDS", "readers": {"values": ["everyone"], "description": "User groups that will be able to read this comment."}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "~.*"}}, "readers": ["everyone"], "tcdate": 1569504182045, "tmdate": 1576860581547, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["everyone"], "noninvitees": ["ICLR.cc/2020/Conference/Paper2316/Authors", "ICLR.cc/2020/Conference/Paper2316/Reviewers", "ICLR.cc/2020/Conference/Paper2316/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper2316/-/Public_Comment"}}}, {"id": "SJl2_f2QuH", "original": null, "number": 2, "cdate": 1570124403774, "ddate": null, "tcdate": 1570124403774, "tmdate": 1570124403774, "tddate": null, "forum": "H1lQIgrFDS", "replyto": "rJlGE2gQur", "invitation": "ICLR.cc/2020/Conference/Paper2316/-/Public_Comment", "content": {"comment": "Thank you for the responses! \n\nI definitely agree that proving the tightness of the L1 certificates is an important contribution. I am not aware of such a tightness, although I have had the same bound. We are going to update our paper and acknowledge your results for the comprehensiveness.\n\nBest,\nBai\n", "title": "responses"}, "signatures": ["~Bai_Li1"], "readers": ["everyone"], "nonreaders": [], "writers": ["~Bai_Li1", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["2016110299@live.sufe.edu.cn", "guanghe@csail.mit.edu", "yuanyang@tsinghua.edu.cn"], "title": "$\\ell_1$ Adversarial Robustness Certificates: a Randomized Smoothing Approach", "authors": ["Jiaye Teng", "Guang-He Lee", "Yang Yuan"], "pdf": "/pdf/2b704ac5e8c7c9fc3a5c8185989a4783c804c06a.pdf", "TL;DR": "We derive the first tight $\\ell_1$ robustness certificate under isotropic Laplace distributions. ", "abstract": "Robustness is an important property to guarantee the security of machine learning models. It has recently been demonstrated that strong robustness certificates can be obtained on ensemble classifiers generated by input randomization. However, tight robustness certificates are only known for symmetric norms including $\\ell_0$ and $\\ell_2$, while for asymmetric norms like $\\ell_1$, the existing techniques do not apply. By converting the likelihood ratio into a one-dimensional mixed random variable, we derive the first tight $\\ell_1$ robustness certificate under isotropic Laplace distributions. Empirically, the deep networks smoothed by Laplace distributions yield the state-of-the-art certified robustness in $\\ell_1$ norm on CIFAR-10 and ImageNet.  ", "keywords": [], "paperhash": "teng|\\ell_1_adversarial_robustness_certificates_a_randomized_smoothing_approach", "original_pdf": "/attachment/c410ce424e0ea8bebe8147e6d0bd93fab7cf1206.pdf", "_bibtex": "@misc{\nteng2020ell,\ntitle={{\\$}{\\textbackslash}ell{\\_}1{\\$} Adversarial Robustness Certificates: a Randomized Smoothing Approach},\nauthor={Jiaye Teng and Guang-He Lee and Yang Yuan},\nyear={2020},\nurl={https://openreview.net/forum?id=H1lQIgrFDS}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "H1lQIgrFDS", "readers": {"values": ["everyone"], "description": "User groups that will be able to read this comment."}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "~.*"}}, "readers": ["everyone"], "tcdate": 1569504182045, "tmdate": 1576860581547, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["everyone"], "noninvitees": ["ICLR.cc/2020/Conference/Paper2316/Authors", "ICLR.cc/2020/Conference/Paper2316/Reviewers", "ICLR.cc/2020/Conference/Paper2316/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper2316/-/Public_Comment"}}}, {"id": "rJlGE2gQur", "original": null, "number": 1, "cdate": 1570077737551, "ddate": null, "tcdate": 1570077737551, "tmdate": 1570077737551, "tddate": null, "forum": "H1lQIgrFDS", "replyto": "ryxTo1HWOB", "invitation": "ICLR.cc/2020/Conference/Paper2316/-/Official_Comment", "content": {"comment": "Dear Bai, \n\nThank you for the comment! \n\nIn our paper, we have made it clear that the first part in our upper bound theorem is the same as Lecuyer et al. (2019). It is very nice to know that the second part can be derived using your framework based on Renyi divergence. We will definitely acknowledge that it is possible to derive that bound under your framework in the paper through later revision. It is indeed a great addition to our paper to diversify the methods for deriving robustness certificates. Thank you!\n\nHowever, in order to make it clear (for the reviewers), we want to emphasize that this work is the first work to establish the certificate (Eq. (1)), no matter how it can be derived. Moreover, your previous paper does not subsume our results for the following reasons:\n\n1. One of our main contributions is proving the *tightness* of the L1 certificates, including both upper and lower bounds. Similarly, Cohen et al. (2019) use the same algorithm as yours (i.e., Gaussian perturbation), but their results are still very interesting, because they were able to prove that their certificate is tight on L2. In our case, while the L1 bound may be derived in different ways (which is not established in the literature, though), we can further prove that the bound is tight, which is new and non-trivial. \n\n2. In your paper, you were analyzing Gaussian perturbations on L2, but our paper uses Laplace distribution on L1. To use your framework to prove our upper bound results, one needs to rewrite the proof for your theorem 2 on Laplace distribution, and pick alpha->\\infty for Lemma 1. In other words, although your proof framework is handy, our upper bound is not a trivial corollary of your theorem. \n\nBest Regards,\nAuthors", "title": "responses to \"a connection to existing work\""}, "signatures": ["ICLR.cc/2020/Conference/Paper2316/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper2316/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["2016110299@live.sufe.edu.cn", "guanghe@csail.mit.edu", "yuanyang@tsinghua.edu.cn"], "title": "$\\ell_1$ Adversarial Robustness Certificates: a Randomized Smoothing Approach", "authors": ["Jiaye Teng", "Guang-He Lee", "Yang Yuan"], "pdf": "/pdf/2b704ac5e8c7c9fc3a5c8185989a4783c804c06a.pdf", "TL;DR": "We derive the first tight $\\ell_1$ robustness certificate under isotropic Laplace distributions. ", "abstract": "Robustness is an important property to guarantee the security of machine learning models. It has recently been demonstrated that strong robustness certificates can be obtained on ensemble classifiers generated by input randomization. However, tight robustness certificates are only known for symmetric norms including $\\ell_0$ and $\\ell_2$, while for asymmetric norms like $\\ell_1$, the existing techniques do not apply. By converting the likelihood ratio into a one-dimensional mixed random variable, we derive the first tight $\\ell_1$ robustness certificate under isotropic Laplace distributions. Empirically, the deep networks smoothed by Laplace distributions yield the state-of-the-art certified robustness in $\\ell_1$ norm on CIFAR-10 and ImageNet.  ", "keywords": [], "paperhash": "teng|\\ell_1_adversarial_robustness_certificates_a_randomized_smoothing_approach", "original_pdf": "/attachment/c410ce424e0ea8bebe8147e6d0bd93fab7cf1206.pdf", "_bibtex": "@misc{\nteng2020ell,\ntitle={{\\$}{\\textbackslash}ell{\\_}1{\\$} Adversarial Robustness Certificates: a Randomized Smoothing Approach},\nauthor={Jiaye Teng and Guang-He Lee and Yang Yuan},\nyear={2020},\nurl={https://openreview.net/forum?id=H1lQIgrFDS}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "H1lQIgrFDS", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper2316/Authors", "ICLR.cc/2020/Conference/Paper2316/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper2316/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper2316/Reviewers", "ICLR.cc/2020/Conference/Paper2316/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper2316/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper2316/Authors|ICLR.cc/2020/Conference/Paper2316/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504143168, "tmdate": 1576860548224, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper2316/Authors", "ICLR.cc/2020/Conference/Paper2316/Reviewers", "ICLR.cc/2020/Conference/Paper2316/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper2316/-/Official_Comment"}}}, {"id": "ryxTo1HWOB", "original": null, "number": 1, "cdate": 1569963940561, "ddate": null, "tcdate": 1569963940561, "tmdate": 1569964760733, "tddate": null, "forum": "H1lQIgrFDS", "replyto": "H1lQIgrFDS", "invitation": "ICLR.cc/2020/Conference/Paper2316/-/Public_Comment", "content": {"comment": "Thank you for the interesting work. \n\nI would like to point out that in equation (1), while the first part \u03bb/2*log(PA/PB) is equivalent to the bound from Lecuyer et al. (2019), the second part \u2212\u03bb log(1 \u2212 PA + PB) can be derived from Li et al. (2019) in Lemma 1 when alpha->\u221e, noticing the Renyi divergence of Laplacian distributions is 1/(\u03b1\u22121)log(\u03b1/(2\u03b1\u22121)exp((\u03b1\u22121)*R/\u03bb)+(\u03b1\u22121)/(2\u03b1\u22121)exp(\u2212\u03b1*R/\u03bb) which converges to R/\u03bb when alpha->\u221e. It also gives the same tight bound in the binary case where R = \u2212\u03bb log[2(1 \u2212 PA)].\n\nIt would be a great addition to your paper if you can make this connection clear. Thank you!\n\n[1] Mathias Lecuyer, Vaggelis Atlidakis, Roxana Geambasu, Daniel J Hsu, and Suman Jana. Certified\nrobustness to adversarial examples with differential privacy. ieee symposium on security and\nprivacy, 2019.\n\n[2] Bai Li, Changyou Chen, Wenlin Wang, and Lawrence Carin. Second-order adversarial attack and\ncertifiable robustness. arXiv: Learning, 2018.", "title": "a connection to existing work"}, "signatures": ["~Bai_Li1"], "readers": ["everyone"], "nonreaders": [], "writers": ["~Bai_Li1", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["2016110299@live.sufe.edu.cn", "guanghe@csail.mit.edu", "yuanyang@tsinghua.edu.cn"], "title": "$\\ell_1$ Adversarial Robustness Certificates: a Randomized Smoothing Approach", "authors": ["Jiaye Teng", "Guang-He Lee", "Yang Yuan"], "pdf": "/pdf/2b704ac5e8c7c9fc3a5c8185989a4783c804c06a.pdf", "TL;DR": "We derive the first tight $\\ell_1$ robustness certificate under isotropic Laplace distributions. ", "abstract": "Robustness is an important property to guarantee the security of machine learning models. It has recently been demonstrated that strong robustness certificates can be obtained on ensemble classifiers generated by input randomization. However, tight robustness certificates are only known for symmetric norms including $\\ell_0$ and $\\ell_2$, while for asymmetric norms like $\\ell_1$, the existing techniques do not apply. By converting the likelihood ratio into a one-dimensional mixed random variable, we derive the first tight $\\ell_1$ robustness certificate under isotropic Laplace distributions. Empirically, the deep networks smoothed by Laplace distributions yield the state-of-the-art certified robustness in $\\ell_1$ norm on CIFAR-10 and ImageNet.  ", "keywords": [], "paperhash": "teng|\\ell_1_adversarial_robustness_certificates_a_randomized_smoothing_approach", "original_pdf": "/attachment/c410ce424e0ea8bebe8147e6d0bd93fab7cf1206.pdf", "_bibtex": "@misc{\nteng2020ell,\ntitle={{\\$}{\\textbackslash}ell{\\_}1{\\$} Adversarial Robustness Certificates: a Randomized Smoothing Approach},\nauthor={Jiaye Teng and Guang-He Lee and Yang Yuan},\nyear={2020},\nurl={https://openreview.net/forum?id=H1lQIgrFDS}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "H1lQIgrFDS", "readers": {"values": ["everyone"], "description": "User groups that will be able to read this comment."}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "~.*"}}, "readers": ["everyone"], "tcdate": 1569504182045, "tmdate": 1576860581547, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["everyone"], "noninvitees": ["ICLR.cc/2020/Conference/Paper2316/Authors", "ICLR.cc/2020/Conference/Paper2316/Reviewers", "ICLR.cc/2020/Conference/Paper2316/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper2316/-/Public_Comment"}}}], "count": 14}