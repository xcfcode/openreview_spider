{"notes": [{"id": "HJGciiR5Y7", "original": "rJxTYpVtKm", "number": 647, "cdate": 1538087842041, "ddate": null, "tcdate": 1538087842041, "tmdate": 1550886627368, "tddate": null, "forum": "HJGciiR5Y7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Latent Convolutional Models", "abstract": "We present a new latent model of natural images that can be learned on large-scale datasets. The learning process provides a latent embedding for every image in the training dataset, as well as a deep convolutional network that maps the latent space to the image space. After training, the new model provides a strong and universal image prior for a variety of image restoration tasks such as large-hole inpainting, superresolution, and colorization. To model high-resolution natural images, our approach uses latent spaces of very high dimensionality (one to two orders of magnitude higher than previous latent image models). To tackle this high dimensionality, we use latent spaces with a special manifold structure (convolutional manifolds) parameterized by a ConvNet of a certain architecture. In the experiments, we compare the learned latent models with latent models learned by autoencoders, advanced variants of generative adversarial networks, and a strong baseline system using simpler parameterization of the latent space. Our model outperforms the competing approaches over a range of restoration tasks.", "keywords": ["latent models", "convolutional networks", "unsupervised learning", "deep learning", "modeling natural images", "image restoration"], "authorids": ["sathar@cs.stonybrook.edu", "e.burnaev@skoltech.ru", "lempitsky@skoltech.ru"], "authors": ["ShahRukh Athar", "Evgeny Burnaev", "Victor Lempitsky"], "TL;DR": "We present a new deep latent model of natural images that can be trained from unlabeled datasets and can be utilized to solve various image restoration tasks.", "pdf": "/pdf/b3a96f512354259c8f0c22df1d2440aebcf44919.pdf", "paperhash": "athar|latent_convolutional_models", "_bibtex": "@inproceedings{\nathar2018latent,\ntitle={Latent Convolutional Models},\nauthor={ShahRukh Athar and Evgeny Burnaev and Victor Lempitsky},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=HJGciiR5Y7},\n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"replyCount": 8, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Blind_Submission", "rdate": null, "ddate": null, "expdate": null, "duedate": 1538085600000, "tmdate": 1538142958393, "tddate": null, "super": null, "final": null, "reply": {"signatures": {"values": ["ICLR.cc/2019/Conference"]}, "forum": null, "readers": {"values": ["everyone"]}, "replyto": null, "content": {"authorids": {"values-regex": ".*"}, "authors": {"values": ["Anonymous"]}}, "writers": {"values": ["ICLR.cc/2019/Conference"]}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["~"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": null, "taskCompletionCount": null, "transform": null, "cdate": 1538142958393}}, "tauthor": "OpenReview.net"}, {"id": "S1lihjEWgE", "original": null, "number": 1, "cdate": 1544797106546, "ddate": null, "tcdate": 1544797106546, "tmdate": 1545354525410, "tddate": null, "forum": "HJGciiR5Y7", "replyto": "HJGciiR5Y7", "invitation": "ICLR.cc/2019/Conference/-/Paper647/Meta_Review", "content": {"metareview": "The reviewers are in general impressed by the results and like the idea but they also express some uncertainty about how the proposed actually is set up. The authors have made a good attempt to address the reviewers' concerns. ", "confidence": "4: The area chair is confident but not absolutely certain", "recommendation": "Accept (Poster)", "title": "Latent model for images - presents convincing results on image impainting+"}, "signatures": ["ICLR.cc/2019/Conference/Paper647/Area_Chair1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference/Paper647/Area_Chair1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Latent Convolutional Models", "abstract": "We present a new latent model of natural images that can be learned on large-scale datasets. The learning process provides a latent embedding for every image in the training dataset, as well as a deep convolutional network that maps the latent space to the image space. After training, the new model provides a strong and universal image prior for a variety of image restoration tasks such as large-hole inpainting, superresolution, and colorization. To model high-resolution natural images, our approach uses latent spaces of very high dimensionality (one to two orders of magnitude higher than previous latent image models). To tackle this high dimensionality, we use latent spaces with a special manifold structure (convolutional manifolds) parameterized by a ConvNet of a certain architecture. In the experiments, we compare the learned latent models with latent models learned by autoencoders, advanced variants of generative adversarial networks, and a strong baseline system using simpler parameterization of the latent space. Our model outperforms the competing approaches over a range of restoration tasks.", "keywords": ["latent models", "convolutional networks", "unsupervised learning", "deep learning", "modeling natural images", "image restoration"], "authorids": ["sathar@cs.stonybrook.edu", "e.burnaev@skoltech.ru", "lempitsky@skoltech.ru"], "authors": ["ShahRukh Athar", "Evgeny Burnaev", "Victor Lempitsky"], "TL;DR": "We present a new deep latent model of natural images that can be trained from unlabeled datasets and can be utilized to solve various image restoration tasks.", "pdf": "/pdf/b3a96f512354259c8f0c22df1d2440aebcf44919.pdf", "paperhash": "athar|latent_convolutional_models", "_bibtex": "@inproceedings{\nathar2018latent,\ntitle={Latent Convolutional Models},\nauthor={ShahRukh Athar and Evgeny Burnaev and Victor Lempitsky},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=HJGciiR5Y7},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper647/Meta_Review", "rdate": null, "ddate": null, "expdate": null, "duedate": 1541548800000, "tmdate": 1545353140820, "tddate": null, "super": null, "final": null, "reply": {"forum": "HJGciiR5Y7", "replyto": "HJGciiR5Y7", "readers": {"description": "Select all user groups that should be able to read this comment. Selecting 'All Users' will allow paper authors, reviewers, area chairs, and program chairs to view this comment.", "values": ["everyone"]}, "signatures": {"description": "How your identity will be displayed with the above content.", "values-regex": "ICLR.cc/2019/Conference/Paper647/Area_Chair[0-9]+"}, "writers": {"description": "Users that may modify this record.", "values-regex": "ICLR.cc/2019/Conference/Paper647/Area_Chair[0-9]+"}, "content": {"title": {"order": 1, "value-regex": ".{1,500}", "description": "Brief summary of your review.", "required": true}, "metareview": {"order": 2, "value-regex": "[\\S\\s]{1,5000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "required": true}, "recommendation": {"order": 3, "value-dropdown": ["Accept (Oral)", "Accept (Poster)", "Reject"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The area chair is absolutely certain", "4: The area chair is confident but not absolutely certain", "3: The area chair is somewhat confident", "2: The area chair is not sure", "1: The area chair's evaluation is an educated guess"], "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper647/Area_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": false, "taskCompletionCount": null, "transform": null, "cdate": 1545353140820}}}, {"id": "r1xLI0153X", "original": null, "number": 1, "cdate": 1541172814303, "ddate": null, "tcdate": 1541172814303, "tmdate": 1542993413493, "tddate": null, "forum": "HJGciiR5Y7", "replyto": "HJGciiR5Y7", "invitation": "ICLR.cc/2019/Conference/-/Paper647/Official_Review", "content": {"title": "[Review] Latent Convolutional Models", "review": "[Summary]\n- This work proposes a new complex latent space described by convolutional manifold, and this manifold can map the image in a more robust manner (when some part of the image are to be restored).\n\n[Pros]\n- The results show that the latent variable mapped to the image well represents the image, and it will be helpful for the image restoration problem.\n- it seems novel to adapt the idea of DIP for defining complex latent space.\n\n[Cons]\n- The main concern is that there is no guarantee that the defined latent space is continuous. \nIt means that it is difficult to judge whether the interpolated point (phi_in, s_in) between two points: (phi_1, s_1) and (\\phi_2, s_2), will be matched to the image distribution. \nEquation 2 in the paper seems that it just fit the generator parameter theta to map the phi_i and x_i and memorize the mapping between the training images and the given latent convolutional variables. \nIf the proposed algorithm just memorizes the training image and map them into given the latent convolution, the result cannot justify the proposal that the author proposes a new latent space.\n\n[Summary]\n- This work proposes an interesting idea of defining complex latent space, but It is doubtful that this work just memorized the mapping between the training images and the latent convolutional parameters.\n- I want to see the (latent space) interpolation test for the proposed latent convolutional space. If the author provides a profound explanation of the problem, I would consider changing the rating.\n\n--------------------------\nSee the additional comment for the changed rating\n", "rating": "7: Good paper, accept", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["ICLR.cc/2019/Conference/Paper647/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": true, "forumContent": {"title": "Latent Convolutional Models", "abstract": "We present a new latent model of natural images that can be learned on large-scale datasets. The learning process provides a latent embedding for every image in the training dataset, as well as a deep convolutional network that maps the latent space to the image space. After training, the new model provides a strong and universal image prior for a variety of image restoration tasks such as large-hole inpainting, superresolution, and colorization. To model high-resolution natural images, our approach uses latent spaces of very high dimensionality (one to two orders of magnitude higher than previous latent image models). To tackle this high dimensionality, we use latent spaces with a special manifold structure (convolutional manifolds) parameterized by a ConvNet of a certain architecture. In the experiments, we compare the learned latent models with latent models learned by autoencoders, advanced variants of generative adversarial networks, and a strong baseline system using simpler parameterization of the latent space. Our model outperforms the competing approaches over a range of restoration tasks.", "keywords": ["latent models", "convolutional networks", "unsupervised learning", "deep learning", "modeling natural images", "image restoration"], "authorids": ["sathar@cs.stonybrook.edu", "e.burnaev@skoltech.ru", "lempitsky@skoltech.ru"], "authors": ["ShahRukh Athar", "Evgeny Burnaev", "Victor Lempitsky"], "TL;DR": "We present a new deep latent model of natural images that can be trained from unlabeled datasets and can be utilized to solve various image restoration tasks.", "pdf": "/pdf/b3a96f512354259c8f0c22df1d2440aebcf44919.pdf", "paperhash": "athar|latent_convolutional_models", "_bibtex": "@inproceedings{\nathar2018latent,\ntitle={Latent Convolutional Models},\nauthor={ShahRukh Athar and Evgeny Burnaev and Victor Lempitsky},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=HJGciiR5Y7},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper647/Official_Review", "cdate": 1542234411927, "expdate": 1552335264000, "duedate": 1541196000000, "reply": {"forum": "HJGciiR5Y7", "replyto": "HJGciiR5Y7", "readers": {"description": "The users who will be allowed to read the reply content.", "values": ["everyone"]}, "nonreaders": {"values": []}, "signatures": {"description": "How your identity will be displayed with the above content.", "values-regex": "ICLR.cc/2019/Conference/Paper647/AnonReviewer[0-9]+"}, "writers": {"description": "Users that may modify this record.", "values": ["ICLR.cc/2019/Conference"]}, "content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "required": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}}, "multiReply": false, "tcdate": 1552335771556, "tmdate": 1552335771556, "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "invitees": ["ICLR.cc/2019/Conference/Paper647/Reviewers"], "noninvitees": [], "signatures": ["ICLR.cc/2019/Conference"]}}}, {"id": "B1xopr2HCQ", "original": null, "number": 7, "cdate": 1542993346634, "ddate": null, "tcdate": 1542993346634, "tmdate": 1542993363334, "tddate": null, "forum": "HJGciiR5Y7", "replyto": "S1x8opbLaX", "invitation": "ICLR.cc/2019/Conference/-/Paper647/Official_Comment", "content": {"title": "Response to the Author comment", "comment": "I agree the comment from the author mostly for my concerns.\n\n(1) From the interpolated images, a point in the latent space seems to be matched to corresponding image in the image distribution, which means that it does not simply memorizes the images.\n\n(2) By seeing the figure 8, I think this work can be tested in image generation task, either. In final version, I strongly want to see the Pure Image generation result. \n\nBased on the comment, I changed my previous rating.\n"}, "signatures": ["ICLR.cc/2019/Conference/Paper647/AnonReviewer3"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper647/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper647/AnonReviewer3", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Latent Convolutional Models", "abstract": "We present a new latent model of natural images that can be learned on large-scale datasets. The learning process provides a latent embedding for every image in the training dataset, as well as a deep convolutional network that maps the latent space to the image space. After training, the new model provides a strong and universal image prior for a variety of image restoration tasks such as large-hole inpainting, superresolution, and colorization. To model high-resolution natural images, our approach uses latent spaces of very high dimensionality (one to two orders of magnitude higher than previous latent image models). To tackle this high dimensionality, we use latent spaces with a special manifold structure (convolutional manifolds) parameterized by a ConvNet of a certain architecture. In the experiments, we compare the learned latent models with latent models learned by autoencoders, advanced variants of generative adversarial networks, and a strong baseline system using simpler parameterization of the latent space. Our model outperforms the competing approaches over a range of restoration tasks.", "keywords": ["latent models", "convolutional networks", "unsupervised learning", "deep learning", "modeling natural images", "image restoration"], "authorids": ["sathar@cs.stonybrook.edu", "e.burnaev@skoltech.ru", "lempitsky@skoltech.ru"], "authors": ["ShahRukh Athar", "Evgeny Burnaev", "Victor Lempitsky"], "TL;DR": "We present a new deep latent model of natural images that can be trained from unlabeled datasets and can be utilized to solve various image restoration tasks.", "pdf": "/pdf/b3a96f512354259c8f0c22df1d2440aebcf44919.pdf", "paperhash": "athar|latent_convolutional_models", "_bibtex": "@inproceedings{\nathar2018latent,\ntitle={Latent Convolutional Models},\nauthor={ShahRukh Athar and Evgeny Burnaev and Victor Lempitsky},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=HJGciiR5Y7},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper647/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621621246, "tddate": null, "super": null, "final": null, "reply": {"forum": "HJGciiR5Y7", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper647/Authors", "ICLR.cc/2019/Conference/Paper647/Reviewers", "ICLR.cc/2019/Conference/Paper647/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper647/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper647/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper647/Authors|ICLR.cc/2019/Conference/Paper647/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper647/Reviewers", "ICLR.cc/2019/Conference/Paper647/Authors", "ICLR.cc/2019/Conference/Paper647/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621621246}}}, {"id": "S1x8opbLaX", "original": null, "number": 3, "cdate": 1541967261909, "ddate": null, "tcdate": 1541967261909, "tmdate": 1541967261909, "tddate": null, "forum": "HJGciiR5Y7", "replyto": "r1xLI0153X", "invitation": "ICLR.cc/2019/Conference/-/Paper647/Official_Comment", "content": {"title": "Response to R3", "comment": "Thank you for the careful review. Fortunately, your main concern though very grave is due to a very simple misunderstanding. We hope that once the misunderstanding is resolved, the rating may be reconsidered.\n\n\"Equation 2 in the paper seems that it just fit the generator parameter theta to map the phi_i and x_i and memorize the mapping between the training images and the given latent convolutional variables. \nIf the proposed algorithm just memorizes the training image and map them into given the latent convolution, the result cannot justify the proposal that the author proposes a new latent space.\"\n\nWe want to stress that all evaluations and qualitative examples are produced on the _hold-out_ test sets that were not in any way used to train the parameters theta of the generator network. So, we can very confidently say that the reason why the approach works is not memorization of the training set within theta. \n\n\"I want to see the (latent space) interpolation test for the proposed latent convolutional space.\"\n\nWe have added latent space interpolations to the appendix G (Figure 12) in the end of the paper. These interpolations were again done on a _hold-out_ set of images. The examples were ``cherry-picked'' for distinctiveness. In more details, in our (biased) view, LCM were always at least as good as other methods, but in some cases, e.g. for pairs of aligned perfectly frontal faces all interpolations look more or less the same, so we picked cases with clear difference between methods. Thank you for suggesting this comparison, it nicely illustrates the effect of the convolutional manifold constraint. If possible, please use zoom-in/large screen to view these results.\n\n\"..the interpolated point (phi_in, s_in) between two points: (phi_1, s_1) and (\\phi_2, s_2)..\"\n\nActually, the s vector is always fixed to some random noise value. I.e. it is not instance specific and is not modified by learning (one can add optimization over s, but in practice this does not change much).\n"}, "signatures": ["ICLR.cc/2019/Conference/Paper647/Authors"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper647/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper647/Authors", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Latent Convolutional Models", "abstract": "We present a new latent model of natural images that can be learned on large-scale datasets. The learning process provides a latent embedding for every image in the training dataset, as well as a deep convolutional network that maps the latent space to the image space. After training, the new model provides a strong and universal image prior for a variety of image restoration tasks such as large-hole inpainting, superresolution, and colorization. To model high-resolution natural images, our approach uses latent spaces of very high dimensionality (one to two orders of magnitude higher than previous latent image models). To tackle this high dimensionality, we use latent spaces with a special manifold structure (convolutional manifolds) parameterized by a ConvNet of a certain architecture. In the experiments, we compare the learned latent models with latent models learned by autoencoders, advanced variants of generative adversarial networks, and a strong baseline system using simpler parameterization of the latent space. Our model outperforms the competing approaches over a range of restoration tasks.", "keywords": ["latent models", "convolutional networks", "unsupervised learning", "deep learning", "modeling natural images", "image restoration"], "authorids": ["sathar@cs.stonybrook.edu", "e.burnaev@skoltech.ru", "lempitsky@skoltech.ru"], "authors": ["ShahRukh Athar", "Evgeny Burnaev", "Victor Lempitsky"], "TL;DR": "We present a new deep latent model of natural images that can be trained from unlabeled datasets and can be utilized to solve various image restoration tasks.", "pdf": "/pdf/b3a96f512354259c8f0c22df1d2440aebcf44919.pdf", "paperhash": "athar|latent_convolutional_models", "_bibtex": "@inproceedings{\nathar2018latent,\ntitle={Latent Convolutional Models},\nauthor={ShahRukh Athar and Evgeny Burnaev and Victor Lempitsky},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=HJGciiR5Y7},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper647/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621621246, "tddate": null, "super": null, "final": null, "reply": {"forum": "HJGciiR5Y7", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper647/Authors", "ICLR.cc/2019/Conference/Paper647/Reviewers", "ICLR.cc/2019/Conference/Paper647/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper647/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper647/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper647/Authors|ICLR.cc/2019/Conference/Paper647/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper647/Reviewers", "ICLR.cc/2019/Conference/Paper647/Authors", "ICLR.cc/2019/Conference/Paper647/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621621246}}}, {"id": "BJeIwpbITQ", "original": null, "number": 2, "cdate": 1541967197986, "ddate": null, "tcdate": 1541967197986, "tmdate": 1541967197986, "tddate": null, "forum": "HJGciiR5Y7", "replyto": "B1et32fpnX", "invitation": "ICLR.cc/2019/Conference/-/Paper647/Official_Comment", "content": {"title": "Response to R1", "comment": "Thank you very much for the review.\nWe would like to point out that there are no encoder network in our approach (although one can possibly discuss ways to add it). Also, note that our contribution is not that we only increase the resolution of the latent space, but that we suggest a specific regularization of the latent space (the convolutional manifold) that significantly improves the generalizability of the resulting latent model.\n\n\"Are test images included in the training the convolutional networks?\"\nAll results (qualitative, quantitative, user study) are performed on hold-out sets, that were not used to train the parameters of the decoder (i.e. theta). The only exception is the progressive GAN baseline, for which there is a mix of training and test sets (since for the comparison we just reuse author-provided models trained on complete sets). This gives an advantage to the pGAN baseline (admittedly not a very big one, since GANs struggle to fit the training sets). To reiterate, all results of OUR method (LCM) are computed strictly on the hold-out test sets.\n\nTo train our model we use the Laplacian-L1 along with an MSE term with a weight of 1.0. We noticed that the MSE term speeds up convergence without affecting the results by much. The optimization is carried out using stochastic gradient descent with a learning rate of 1.0. We note that the code for the paper and the experiments will be released for reproducibility.\n"}, "signatures": ["ICLR.cc/2019/Conference/Paper647/Authors"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper647/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper647/Authors", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Latent Convolutional Models", "abstract": "We present a new latent model of natural images that can be learned on large-scale datasets. The learning process provides a latent embedding for every image in the training dataset, as well as a deep convolutional network that maps the latent space to the image space. After training, the new model provides a strong and universal image prior for a variety of image restoration tasks such as large-hole inpainting, superresolution, and colorization. To model high-resolution natural images, our approach uses latent spaces of very high dimensionality (one to two orders of magnitude higher than previous latent image models). To tackle this high dimensionality, we use latent spaces with a special manifold structure (convolutional manifolds) parameterized by a ConvNet of a certain architecture. In the experiments, we compare the learned latent models with latent models learned by autoencoders, advanced variants of generative adversarial networks, and a strong baseline system using simpler parameterization of the latent space. Our model outperforms the competing approaches over a range of restoration tasks.", "keywords": ["latent models", "convolutional networks", "unsupervised learning", "deep learning", "modeling natural images", "image restoration"], "authorids": ["sathar@cs.stonybrook.edu", "e.burnaev@skoltech.ru", "lempitsky@skoltech.ru"], "authors": ["ShahRukh Athar", "Evgeny Burnaev", "Victor Lempitsky"], "TL;DR": "We present a new deep latent model of natural images that can be trained from unlabeled datasets and can be utilized to solve various image restoration tasks.", "pdf": "/pdf/b3a96f512354259c8f0c22df1d2440aebcf44919.pdf", "paperhash": "athar|latent_convolutional_models", "_bibtex": "@inproceedings{\nathar2018latent,\ntitle={Latent Convolutional Models},\nauthor={ShahRukh Athar and Evgeny Burnaev and Victor Lempitsky},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=HJGciiR5Y7},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper647/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621621246, "tddate": null, "super": null, "final": null, "reply": {"forum": "HJGciiR5Y7", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper647/Authors", "ICLR.cc/2019/Conference/Paper647/Reviewers", "ICLR.cc/2019/Conference/Paper647/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper647/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper647/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper647/Authors|ICLR.cc/2019/Conference/Paper647/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper647/Reviewers", "ICLR.cc/2019/Conference/Paper647/Authors", "ICLR.cc/2019/Conference/Paper647/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621621246}}}, {"id": "Skls46b8TQ", "original": null, "number": 1, "cdate": 1541967155472, "ddate": null, "tcdate": 1541967155472, "tmdate": 1541967155472, "tddate": null, "forum": "HJGciiR5Y7", "replyto": "r1gXKJZ6nX", "invitation": "ICLR.cc/2019/Conference/-/Paper647/Official_Comment", "content": {"title": "Response to R2", "comment": "Thank you for the careful review. Here are the responses.\n\n\"Did you try other standard restoration tasks, such as image denoising or deblurring? If not, do you think they would work equally well?\"\nWe have tried denoising (with synthetic noise), where the relative performance is similar. We have not tried deblurring, although we expect the relative performance. \n\n\"- A limitation (at least as presented) is that the corruption process has to be known analytically (as a likelihood objective) and must be differentiable for gradient-based inference.\"\nWhile technically we do assume that the corruption process is known, it is still possible to apply our approach with simplified (inaccurate) likelihood function. To show that we have added appendix H (Figure 13), which shows how restoration from heavy JPEG artifacts can be done using simple quadratic likelihood functional. The second limitation (need for optimization at test time) is indeed important. We can partially remedy it by adding encoder that would take a corrupted image and output a good starting point in a latent space. We have added discussion/acknowledgement of these limitations to the end of the conclusion section.\n\n\"- How dependent is the restoration result with respect to the initialization? For example, when starting gradient descent with the degraded image vs. a random image.\"\nOur approach cannot start with the degraded image, since we do not know the corresponding latent space initialization. So we always start with a random latent vector. Generally, we found that initializing the latent networks using the same parameters as when the training started worked the best (so we always use the same random vector). Different starting points lead to results with very slightly worse visual quality (the perceptual loss increases by about 0.0006), which are still better than that of competing methods.  Note, that we experimented with different initializations for all the models and chose the one that worked the best for each (to give baselines a fair treatment).\n\n\"Roughly, how many iterations and runtime is needed for inference?\"\nFor a batch of 50 images, it takes about 1000-2000 iterations with takes between 6-12 minutes. Tasks like super-resolution can be done in about 1000 iterations or so and inpainting can take up to 1500-2000 iterations.\n\n\"- Did you try different optimizers, such as L-BFGS?\"\nYes, we have tried L-BFGS for inference. We had to use a lower learning rate and were able to produce results similar to that of SGD. Generally, L-BFGS did not offer any significant advantages over SGD. "}, "signatures": ["ICLR.cc/2019/Conference/Paper647/Authors"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper647/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper647/Authors", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Latent Convolutional Models", "abstract": "We present a new latent model of natural images that can be learned on large-scale datasets. The learning process provides a latent embedding for every image in the training dataset, as well as a deep convolutional network that maps the latent space to the image space. After training, the new model provides a strong and universal image prior for a variety of image restoration tasks such as large-hole inpainting, superresolution, and colorization. To model high-resolution natural images, our approach uses latent spaces of very high dimensionality (one to two orders of magnitude higher than previous latent image models). To tackle this high dimensionality, we use latent spaces with a special manifold structure (convolutional manifolds) parameterized by a ConvNet of a certain architecture. In the experiments, we compare the learned latent models with latent models learned by autoencoders, advanced variants of generative adversarial networks, and a strong baseline system using simpler parameterization of the latent space. Our model outperforms the competing approaches over a range of restoration tasks.", "keywords": ["latent models", "convolutional networks", "unsupervised learning", "deep learning", "modeling natural images", "image restoration"], "authorids": ["sathar@cs.stonybrook.edu", "e.burnaev@skoltech.ru", "lempitsky@skoltech.ru"], "authors": ["ShahRukh Athar", "Evgeny Burnaev", "Victor Lempitsky"], "TL;DR": "We present a new deep latent model of natural images that can be trained from unlabeled datasets and can be utilized to solve various image restoration tasks.", "pdf": "/pdf/b3a96f512354259c8f0c22df1d2440aebcf44919.pdf", "paperhash": "athar|latent_convolutional_models", "_bibtex": "@inproceedings{\nathar2018latent,\ntitle={Latent Convolutional Models},\nauthor={ShahRukh Athar and Evgeny Burnaev and Victor Lempitsky},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=HJGciiR5Y7},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper647/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621621246, "tddate": null, "super": null, "final": null, "reply": {"forum": "HJGciiR5Y7", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper647/Authors", "ICLR.cc/2019/Conference/Paper647/Reviewers", "ICLR.cc/2019/Conference/Paper647/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper647/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper647/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper647/Authors|ICLR.cc/2019/Conference/Paper647/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper647/Reviewers", "ICLR.cc/2019/Conference/Paper647/Authors", "ICLR.cc/2019/Conference/Paper647/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621621246}}}, {"id": "B1et32fpnX", "original": null, "number": 3, "cdate": 1541381297164, "ddate": null, "tcdate": 1541381297164, "tmdate": 1541533810254, "tddate": null, "forum": "HJGciiR5Y7", "replyto": "HJGciiR5Y7", "invitation": "ICLR.cc/2019/Conference/-/Paper647/Official_Review", "content": {"title": "Latent Convolutional Models", "review": "This paper proposes to increase the latent space dimensionality  of images, by stacking the latent representation vectors as a tensor. Then convolutional decoder and encoder networks are used to map the original data to latent space and vice versa. The learned latent representations can then be used in a universal framework for multiple tasks such as image inpainting, superresolution and colorization.\n\nThe idea of increasing the dimensionality of the latent space, although not sophisticated, seems to be performing very good. Indeed in some of qualitative experiments, the results are surprising. The authors should clarify that how is the training procedure performed in more details. Are test images included in the training the convolutional networks?", "rating": "6: Marginally above acceptance threshold", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "signatures": ["ICLR.cc/2019/Conference/Paper647/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Latent Convolutional Models", "abstract": "We present a new latent model of natural images that can be learned on large-scale datasets. The learning process provides a latent embedding for every image in the training dataset, as well as a deep convolutional network that maps the latent space to the image space. After training, the new model provides a strong and universal image prior for a variety of image restoration tasks such as large-hole inpainting, superresolution, and colorization. To model high-resolution natural images, our approach uses latent spaces of very high dimensionality (one to two orders of magnitude higher than previous latent image models). To tackle this high dimensionality, we use latent spaces with a special manifold structure (convolutional manifolds) parameterized by a ConvNet of a certain architecture. In the experiments, we compare the learned latent models with latent models learned by autoencoders, advanced variants of generative adversarial networks, and a strong baseline system using simpler parameterization of the latent space. Our model outperforms the competing approaches over a range of restoration tasks.", "keywords": ["latent models", "convolutional networks", "unsupervised learning", "deep learning", "modeling natural images", "image restoration"], "authorids": ["sathar@cs.stonybrook.edu", "e.burnaev@skoltech.ru", "lempitsky@skoltech.ru"], "authors": ["ShahRukh Athar", "Evgeny Burnaev", "Victor Lempitsky"], "TL;DR": "We present a new deep latent model of natural images that can be trained from unlabeled datasets and can be utilized to solve various image restoration tasks.", "pdf": "/pdf/b3a96f512354259c8f0c22df1d2440aebcf44919.pdf", "paperhash": "athar|latent_convolutional_models", "_bibtex": "@inproceedings{\nathar2018latent,\ntitle={Latent Convolutional Models},\nauthor={ShahRukh Athar and Evgeny Burnaev and Victor Lempitsky},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=HJGciiR5Y7},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper647/Official_Review", "cdate": 1542234411927, "expdate": 1552335264000, "duedate": 1541196000000, "reply": {"forum": "HJGciiR5Y7", "replyto": "HJGciiR5Y7", "readers": {"description": "The users who will be allowed to read the reply content.", "values": ["everyone"]}, "nonreaders": {"values": []}, "signatures": {"description": "How your identity will be displayed with the above content.", "values-regex": "ICLR.cc/2019/Conference/Paper647/AnonReviewer[0-9]+"}, "writers": {"description": "Users that may modify this record.", "values": ["ICLR.cc/2019/Conference"]}, "content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "required": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}}, "multiReply": false, "tcdate": 1552335771556, "tmdate": 1552335771556, "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "invitees": ["ICLR.cc/2019/Conference/Paper647/Reviewers"], "noninvitees": [], "signatures": ["ICLR.cc/2019/Conference"]}}}, {"id": "r1gXKJZ6nX", "original": null, "number": 2, "cdate": 1541373818795, "ddate": null, "tcdate": 1541373818795, "tmdate": 1541533810051, "tddate": null, "forum": "HJGciiR5Y7", "replyto": "HJGciiR5Y7", "invitation": "ICLR.cc/2019/Conference/-/Paper647/Official_Review", "content": {"title": "universal image prior with compelling results, but more limited than specialized restoration nets", "review": "# Summary\nThe paper proposes to embed natural images in a latent convolutional space of high dimensionality to obtain a universal image prior. Concretely, each image is embedded as a custom parameter vector of a CNN, which turns random noise into the input of a universal generator network to restore the image in pixel space.\nInference for image restoration is performed by minimizing the energy of a likelihood objective while constraining the latent representation of the restored image to be part of the learned latent space. Experiments for inpainting, super-resolution, and colorization are performed to evaluate the proposed method.\n\n# Positive\nAs mentioned in the paper, I agree that the idea of learning a universal image prior is appealing, since it can be applied to (m)any image restoration tasks without adjustment.\nI am not very familiar with the related work, but if I understood correctly, the paper seems to combine deep latent modeling (GLO, Bojanowski et al., 2018) and deep image priors (Ulyanov et al., 2018). The experiments show good results which qualitatively appear better than those of related methods. A user study also shows that people mostly prefer the results of the proposed method.\nDid you try other standard restoration tasks, such as image denoising or deblurring? If not, do you think they would work equally well?\n\n# Limitations\nWhile I agree that a universal image prior is valuable, the paper should (briefly) mention what the disadvantages of the proposed approach are:\n- A limitation (at least as presented) is that the corruption process has to be known analytically (as a likelihood objective) and must be differentiable for gradient-based inference.\n- Furthermore, the disadvantage of the universal prior as presented in the paper is that restoring an image requires optimization (e.g. gradient descent). In contrast, corruption-specific neural nets typically just need a forward pass to restore the image and are thus easier and faster to use.\n\n# Restoration inference\n- How dependent is the restoration result with respect to the initialization? For example, when starting gradient descent with the degraded image vs. a random image.\n- Roughly, how many iterations and runtime is needed for inference?\n- Did you try different optimizers, such as L-BFGS?", "rating": "7: Good paper, accept", "confidence": "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper"}, "signatures": ["ICLR.cc/2019/Conference/Paper647/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Latent Convolutional Models", "abstract": "We present a new latent model of natural images that can be learned on large-scale datasets. The learning process provides a latent embedding for every image in the training dataset, as well as a deep convolutional network that maps the latent space to the image space. After training, the new model provides a strong and universal image prior for a variety of image restoration tasks such as large-hole inpainting, superresolution, and colorization. To model high-resolution natural images, our approach uses latent spaces of very high dimensionality (one to two orders of magnitude higher than previous latent image models). To tackle this high dimensionality, we use latent spaces with a special manifold structure (convolutional manifolds) parameterized by a ConvNet of a certain architecture. In the experiments, we compare the learned latent models with latent models learned by autoencoders, advanced variants of generative adversarial networks, and a strong baseline system using simpler parameterization of the latent space. Our model outperforms the competing approaches over a range of restoration tasks.", "keywords": ["latent models", "convolutional networks", "unsupervised learning", "deep learning", "modeling natural images", "image restoration"], "authorids": ["sathar@cs.stonybrook.edu", "e.burnaev@skoltech.ru", "lempitsky@skoltech.ru"], "authors": ["ShahRukh Athar", "Evgeny Burnaev", "Victor Lempitsky"], "TL;DR": "We present a new deep latent model of natural images that can be trained from unlabeled datasets and can be utilized to solve various image restoration tasks.", "pdf": "/pdf/b3a96f512354259c8f0c22df1d2440aebcf44919.pdf", "paperhash": "athar|latent_convolutional_models", "_bibtex": "@inproceedings{\nathar2018latent,\ntitle={Latent Convolutional Models},\nauthor={ShahRukh Athar and Evgeny Burnaev and Victor Lempitsky},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=HJGciiR5Y7},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper647/Official_Review", "cdate": 1542234411927, "expdate": 1552335264000, "duedate": 1541196000000, "reply": {"forum": "HJGciiR5Y7", "replyto": "HJGciiR5Y7", "readers": {"description": "The users who will be allowed to read the reply content.", "values": ["everyone"]}, "nonreaders": {"values": []}, "signatures": {"description": "How your identity will be displayed with the above content.", "values-regex": "ICLR.cc/2019/Conference/Paper647/AnonReviewer[0-9]+"}, "writers": {"description": "Users that may modify this record.", "values": ["ICLR.cc/2019/Conference"]}, "content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "required": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}}, "multiReply": false, "tcdate": 1552335771556, "tmdate": 1552335771556, "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "invitees": ["ICLR.cc/2019/Conference/Paper647/Reviewers"], "noninvitees": [], "signatures": ["ICLR.cc/2019/Conference"]}}}], "count": 9}