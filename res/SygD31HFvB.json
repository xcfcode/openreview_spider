{"notes": [{"id": "SygD31HFvB", "original": "BJgEjbkYvr", "number": 1954, "cdate": 1569439662594, "ddate": null, "tcdate": 1569439662594, "tmdate": 1577168213773, "tddate": null, "forum": "SygD31HFvB", "replyto": null, "invitation": "ICLR.cc/2020/Conference/-/Blind_Submission", "content": {"title": "A Novel Analysis Framework of Lower Complexity Bounds for Finite-Sum Optimization", "authors": ["Guangzeng Xie", "Luo Luo", "Zhihua Zhang"], "authorids": ["smsxgz@pku.edu.cn", "rickyluoluo@gmail.com", "zhzhang@math.pku.edu.cn"], "keywords": ["convex optimization", "lower bound complexity", "proximal incremental first-order oracle"], "abstract": "This paper studies the lower bound complexity for the optimization problem whose objective function is the average of $n$ individual smooth convex functions. We consider the algorithm which gets access to gradient and proximal oracle for each individual component.\nFor the strongly-convex case, we prove such an algorithm can not reach an $\\eps$-suboptimal point in fewer than $\\Omega((n+\\sqrt{\\kappa n})\\log(1/\\eps))$ iterations, where $\\kappa$ is the condition number of the objective function. This lower bound is tighter than previous results and perfectly matches the upper bound of the existing proximal incremental first-order oracle algorithm Point-SAGA.\nWe develop a novel construction to show the above result, which partitions the tridiagonal matrix of classical examples into $n$ groups to make the problem difficult enough to stochastic algorithms. \nThis construction is friendly to the analysis of proximal oracle and also could  be used in general convex and average smooth cases naturally.", "pdf": "/pdf/746a8f488b060a784482d5ebf415fc66f692a2d3.pdf", "paperhash": "xie|a_novel_analysis_framework_of_lower_complexity_bounds_for_finitesum_optimization", "original_pdf": "/attachment/ee6336c636607010673966a630bfdb27e767b74e.pdf", "_bibtex": "@misc{\nxie2020a,\ntitle={A Novel Analysis Framework of Lower Complexity Bounds for Finite-Sum Optimization},\nauthor={Guangzeng Xie and Luo Luo and Zhihua Zhang},\nyear={2020},\nurl={https://openreview.net/forum?id=SygD31HFvB}\n}"}, "signatures": ["ICLR.cc/2020/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference"], "details": {"replyCount": 10, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"reply": {"readers": {"values-regex": ".*"}, "writers": {"values": ["ICLR.cc/2020/Conference"]}, "signatures": {"values": ["ICLR.cc/2020/Conference"]}, "content": {"spotlight_video": {"value-regex": ".*"}, "full_presentation_video": {"value-regex": ".*"}, "original_pdf": {"required": false, "description": "Upload a PDF file that ends with .pdf", "value-regex": ".*"}, "appendix": {"value-regex": ".*"}, "authorids": {"values-regex": ".*"}, "poster": {"value-regex": ".*"}, "authors": {"values": ["Anonymous"]}, "slides": {"value-regex": ".*"}}}, "final": [], "signatures": ["ICLR.cc/2020/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference"], "noninvitees": [], "tcdate": 1569271260237, "tmdate": 1593459412141, "id": "ICLR.cc/2020/Conference/-/Blind_Submission"}}, "tauthor": "OpenReview.net"}, {"id": "FFwV3wZenW", "original": null, "number": 1, "cdate": 1576798736753, "ddate": null, "tcdate": 1576798736753, "tmdate": 1576800899599, "tddate": null, "forum": "SygD31HFvB", "replyto": "SygD31HFvB", "invitation": "ICLR.cc/2020/Conference/Paper1954/-/Decision", "content": {"decision": "Reject", "comment": "The paper considers a lower bound complexity for the convex problems. The reviewers worry about whether the scope of this paper fit in ICLR, the initialization issues, and the novelty and some other problems.", "title": "Paper Decision"}, "signatures": ["ICLR.cc/2020/Conference/Program_Chairs"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Program_Chairs"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "A Novel Analysis Framework of Lower Complexity Bounds for Finite-Sum Optimization", "authors": ["Guangzeng Xie", "Luo Luo", "Zhihua Zhang"], "authorids": ["smsxgz@pku.edu.cn", "rickyluoluo@gmail.com", "zhzhang@math.pku.edu.cn"], "keywords": ["convex optimization", "lower bound complexity", "proximal incremental first-order oracle"], "abstract": "This paper studies the lower bound complexity for the optimization problem whose objective function is the average of $n$ individual smooth convex functions. We consider the algorithm which gets access to gradient and proximal oracle for each individual component.\nFor the strongly-convex case, we prove such an algorithm can not reach an $\\eps$-suboptimal point in fewer than $\\Omega((n+\\sqrt{\\kappa n})\\log(1/\\eps))$ iterations, where $\\kappa$ is the condition number of the objective function. This lower bound is tighter than previous results and perfectly matches the upper bound of the existing proximal incremental first-order oracle algorithm Point-SAGA.\nWe develop a novel construction to show the above result, which partitions the tridiagonal matrix of classical examples into $n$ groups to make the problem difficult enough to stochastic algorithms. \nThis construction is friendly to the analysis of proximal oracle and also could  be used in general convex and average smooth cases naturally.", "pdf": "/pdf/746a8f488b060a784482d5ebf415fc66f692a2d3.pdf", "paperhash": "xie|a_novel_analysis_framework_of_lower_complexity_bounds_for_finitesum_optimization", "original_pdf": "/attachment/ee6336c636607010673966a630bfdb27e767b74e.pdf", "_bibtex": "@misc{\nxie2020a,\ntitle={A Novel Analysis Framework of Lower Complexity Bounds for Finite-Sum Optimization},\nauthor={Guangzeng Xie and Luo Luo and Zhihua Zhang},\nyear={2020},\nurl={https://openreview.net/forum?id=SygD31HFvB}\n}"}, "tags": [], "invitation": {"reply": {"writers": {"description": "How your identity will be displayed.", "values-regex": ["ICLR.cc/2020/Conference/Program_Chairs"]}, "signatures": {"values": ["ICLR.cc/2020/Conference/Program_Chairs"], "description": "How your identity will be displayed."}, "content": {"decision": {"value-radio": ["Accept (Spotlight)", "Accept (Talk)", "Accept (Poster)", "Reject"], "description": "Decision", "required": true, "order": 2}, "title": {"value": "Paper Decision", "required": true, "order": 1}, "comment": {"value-regex": "[\\S\\s]{0,5000}", "description": "", "required": false, "order": 3}}, "forum": "SygD31HFvB", "replyto": "SygD31HFvB", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}}, "expdate": 1576854540000, "duedate": 1576853940000, "multiReply": false, "readers": ["everyone"], "invitees": ["ICLR.cc/2020/Conference/Program_Chairs"], "tcdate": 1576795708951, "tmdate": 1576800257513, "super": "ICLR.cc/2020/Conference/-/Decision", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper1954/-/Decision"}}}, {"id": "r1xmsSQhiS", "original": null, "number": 3, "cdate": 1573823898993, "ddate": null, "tcdate": 1573823898993, "tmdate": 1573827014637, "tddate": null, "forum": "SygD31HFvB", "replyto": "S1xPXyAiYH", "invitation": "ICLR.cc/2020/Conference/Paper1954/-/Official_Comment", "content": {"title": "Thanks for your comments!", "comment": "Thanks for the reviewer's insightful and helpful comments. \n\n1.  We have appended a new lower bound in the case of $\\kappa = \\mathcal{O}(n)$, which matches the upper bound of IFO algorithm (Hannah et al., 2018)  (see Table 1, Theorem 3.1 and Section 4.1 in our latest version of the paper). Please note that the our lower bound analysis includes PIFO algorithms, while previous results (Hannah et al., 2018) only consider IFO one in this case. \n\n2. We must emphasize that the constructions in our proof are novel and different from previous work, which makes our results  stronger. We provide the detailed comparison of our technique  with existing proofs in Appendix B of our latest version.\n\nBriefly speaking\na) The analysis in (Lan and Zhou, 2017; Zhou and Gu, 2019) employed an aggregation framework while this paper proposed a new decomposition framework. The aggregation one is only valid for analyzing IFO algorithms, while our decomposition framework can be easily extended to show the lower bound of PIFO algorithms. \n\nb) The analysis in (Woodworth and Srebro, 2016; Fang et al., 2018) considers a very complicated approach to dealing with the proximal operator (completely different from how to deal with gradient operator). In contrast, our construction holds ''only one'' property (Lemma 2.6) both for proximal and gradient operator, which makes the proof more concise. We also use our technique to prove the tight lower bound of PIFO algorithm when $\\kappa = \\mathcal{O}(n)$, which is a new result.\n\n3. It is worth noting that the proposed analysis framework is general and NOT limited to convex optimization, which also can be used to study NON-CONVEX problems. And we have provided the results and proofs about nonconvex optimization in Appendix J. "}, "signatures": ["ICLR.cc/2020/Conference/Paper1954/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1954/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "A Novel Analysis Framework of Lower Complexity Bounds for Finite-Sum Optimization", "authors": ["Guangzeng Xie", "Luo Luo", "Zhihua Zhang"], "authorids": ["smsxgz@pku.edu.cn", "rickyluoluo@gmail.com", "zhzhang@math.pku.edu.cn"], "keywords": ["convex optimization", "lower bound complexity", "proximal incremental first-order oracle"], "abstract": "This paper studies the lower bound complexity for the optimization problem whose objective function is the average of $n$ individual smooth convex functions. We consider the algorithm which gets access to gradient and proximal oracle for each individual component.\nFor the strongly-convex case, we prove such an algorithm can not reach an $\\eps$-suboptimal point in fewer than $\\Omega((n+\\sqrt{\\kappa n})\\log(1/\\eps))$ iterations, where $\\kappa$ is the condition number of the objective function. This lower bound is tighter than previous results and perfectly matches the upper bound of the existing proximal incremental first-order oracle algorithm Point-SAGA.\nWe develop a novel construction to show the above result, which partitions the tridiagonal matrix of classical examples into $n$ groups to make the problem difficult enough to stochastic algorithms. \nThis construction is friendly to the analysis of proximal oracle and also could  be used in general convex and average smooth cases naturally.", "pdf": "/pdf/746a8f488b060a784482d5ebf415fc66f692a2d3.pdf", "paperhash": "xie|a_novel_analysis_framework_of_lower_complexity_bounds_for_finitesum_optimization", "original_pdf": "/attachment/ee6336c636607010673966a630bfdb27e767b74e.pdf", "_bibtex": "@misc{\nxie2020a,\ntitle={A Novel Analysis Framework of Lower Complexity Bounds for Finite-Sum Optimization},\nauthor={Guangzeng Xie and Luo Luo and Zhihua Zhang},\nyear={2020},\nurl={https://openreview.net/forum?id=SygD31HFvB}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "SygD31HFvB", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper1954/Authors", "ICLR.cc/2020/Conference/Paper1954/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper1954/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper1954/Reviewers", "ICLR.cc/2020/Conference/Paper1954/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper1954/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper1954/Authors|ICLR.cc/2020/Conference/Paper1954/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504148449, "tmdate": 1576860561608, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper1954/Authors", "ICLR.cc/2020/Conference/Paper1954/Reviewers", "ICLR.cc/2020/Conference/Paper1954/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper1954/-/Official_Comment"}}}, {"id": "HklQaUm2jS", "original": null, "number": 4, "cdate": 1573824186681, "ddate": null, "tcdate": 1573824186681, "tmdate": 1573826977486, "tddate": null, "forum": "SygD31HFvB", "replyto": "H1ezmonaYS", "invitation": "ICLR.cc/2020/Conference/Paper1954/-/Official_Comment", "content": {"title": "Thanks for your comments!", "comment": "Thanks for the reviewer's insightful and helpful comments. \n\n1. We have appended a new lower bound in the case of $\\kappa = \\mathcal{O}(n)$, which matches the upper bound of IFO algorithm (Hannah et al., 2018)  (see Table 1, Theorem 3.1 and Section 4.1 in our latest version of the paper). Please note that the our lower bound analysis includes PIFO algorithms, while previous results (Hannah et al., 2018) only consider IFO one in this case. \n\n2. It is interesting to use our framework to analyze the lower bound of algorithms with adaptive sampling. This extension looks not easy and we would like to study it in future work. \n\n3. The main reason of using the construction Eq.5/6 is the decomposition $r({\\bf x})=\\sum_{i=1}^n r_i({\\bf x})$ (omit the constants) is friendly to the analysis of PIFO algorithms. Concretely, our construction holds ''only one'' property (Lemma 2.6) both for proximal and gradient operator, while the construction of (Lan and Zhou, 2017; Zhou and Gu, 2019) only holds this property for IFO, which leads their construction is invalid to analyze PIFO algorithms.  \n\n4. We have included a comparison with other constructions in Appendix B. \n\nBriefly speaking\na) The analysis in (Lan and Zhou, 2017; Zhou and Gu, 2019) employed an aggregation framework while this paper proposed a new decomposition framework.\nAs we stated in Reply 2, the construction in (Lan and Zhou, 2017; Zhou and Gu, 2019) is only valid for analyzing IFO algorithms, while our decomposition framework can be easily extended to show the lower bound of PIFO algorithms. \n\nb) The analysis in (Woodworth and Srebro, 2016; Fang et al., 2018) considers a very complicated approach to dealing with the proximal operator (completely different from how to deal with gradient operator). In contrast, our construction holds ''only one'' property (Lemma 2.6) both for proximal and gradient operator, which makes the proof more concise. We also use our technique to prove the tight lower bound of PIFO algorithm when $\\kappa = \\mathcal{O}(n)$, which is a new result. \n\n5. The construction $f$ of (Lan and Zhou, 2017; Zhou and Gu, 2019) is from ${\\mathbb R}^{mn}$ to ${\\mathbb R}$ while our $r$ is from ${\\mathbb R}^{m}$ to ${\\mathbb R}$ (please see the detailed definitions of $r$ and $f$ in Appendix B), which provides an intuitive understanding why our construction requires a smaller dimension.\n\n"}, "signatures": ["ICLR.cc/2020/Conference/Paper1954/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1954/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "A Novel Analysis Framework of Lower Complexity Bounds for Finite-Sum Optimization", "authors": ["Guangzeng Xie", "Luo Luo", "Zhihua Zhang"], "authorids": ["smsxgz@pku.edu.cn", "rickyluoluo@gmail.com", "zhzhang@math.pku.edu.cn"], "keywords": ["convex optimization", "lower bound complexity", "proximal incremental first-order oracle"], "abstract": "This paper studies the lower bound complexity for the optimization problem whose objective function is the average of $n$ individual smooth convex functions. We consider the algorithm which gets access to gradient and proximal oracle for each individual component.\nFor the strongly-convex case, we prove such an algorithm can not reach an $\\eps$-suboptimal point in fewer than $\\Omega((n+\\sqrt{\\kappa n})\\log(1/\\eps))$ iterations, where $\\kappa$ is the condition number of the objective function. This lower bound is tighter than previous results and perfectly matches the upper bound of the existing proximal incremental first-order oracle algorithm Point-SAGA.\nWe develop a novel construction to show the above result, which partitions the tridiagonal matrix of classical examples into $n$ groups to make the problem difficult enough to stochastic algorithms. \nThis construction is friendly to the analysis of proximal oracle and also could  be used in general convex and average smooth cases naturally.", "pdf": "/pdf/746a8f488b060a784482d5ebf415fc66f692a2d3.pdf", "paperhash": "xie|a_novel_analysis_framework_of_lower_complexity_bounds_for_finitesum_optimization", "original_pdf": "/attachment/ee6336c636607010673966a630bfdb27e767b74e.pdf", "_bibtex": "@misc{\nxie2020a,\ntitle={A Novel Analysis Framework of Lower Complexity Bounds for Finite-Sum Optimization},\nauthor={Guangzeng Xie and Luo Luo and Zhihua Zhang},\nyear={2020},\nurl={https://openreview.net/forum?id=SygD31HFvB}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "SygD31HFvB", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper1954/Authors", "ICLR.cc/2020/Conference/Paper1954/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper1954/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper1954/Reviewers", "ICLR.cc/2020/Conference/Paper1954/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper1954/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper1954/Authors|ICLR.cc/2020/Conference/Paper1954/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504148449, "tmdate": 1576860561608, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper1954/Authors", "ICLR.cc/2020/Conference/Paper1954/Reviewers", "ICLR.cc/2020/Conference/Paper1954/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper1954/-/Official_Comment"}}}, {"id": "S1lhVSXhiB", "original": null, "number": 2, "cdate": 1573823795943, "ddate": null, "tcdate": 1573823795943, "tmdate": 1573826952809, "tddate": null, "forum": "SygD31HFvB", "replyto": "rJxQHktG5r", "invitation": "ICLR.cc/2020/Conference/Paper1954/-/Official_Comment", "content": {"title": "Thanks for your comments!", "comment": "Thanks for the reviewer's insightful and helpful comments. \n\n1.  We have appended a new lower bound in the case of $\\kappa = \\mathcal{O}(n)$, which matches the upper bound of IFO algorithm (Hannah et al., 2018)  (see Table 1, Theorem 3.1 and Section 4.1 in our latest version of the paper). Please note that the our lower bound analysis includes PIFO algorithms, while previous results (Hannah et al., 2018) only consider IFO one in this case. \n\n2. Our framework is valid for any initial point. As we stated at the bottom of Page 3, we can take $\\{{\\hat f}_i({\\bf x}) = f_i({\\bf x} + {\\bf x}_0)\\}_{i=1}^n$ into consideration if the initial point ${\\bf x}_0\\neq 0$. Then analyzing ${\\hat f}_i({\\bf x}) $ is similar to analyzing $f_i({\\bf x})$ with ${\\bf x}_0=0$.\n\n3. It is interesting to use our framework to analyze the lower bound of algorithms with adaptive sampling. This extension looks not easy and we would like to study it in future work."}, "signatures": ["ICLR.cc/2020/Conference/Paper1954/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1954/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "A Novel Analysis Framework of Lower Complexity Bounds for Finite-Sum Optimization", "authors": ["Guangzeng Xie", "Luo Luo", "Zhihua Zhang"], "authorids": ["smsxgz@pku.edu.cn", "rickyluoluo@gmail.com", "zhzhang@math.pku.edu.cn"], "keywords": ["convex optimization", "lower bound complexity", "proximal incremental first-order oracle"], "abstract": "This paper studies the lower bound complexity for the optimization problem whose objective function is the average of $n$ individual smooth convex functions. We consider the algorithm which gets access to gradient and proximal oracle for each individual component.\nFor the strongly-convex case, we prove such an algorithm can not reach an $\\eps$-suboptimal point in fewer than $\\Omega((n+\\sqrt{\\kappa n})\\log(1/\\eps))$ iterations, where $\\kappa$ is the condition number of the objective function. This lower bound is tighter than previous results and perfectly matches the upper bound of the existing proximal incremental first-order oracle algorithm Point-SAGA.\nWe develop a novel construction to show the above result, which partitions the tridiagonal matrix of classical examples into $n$ groups to make the problem difficult enough to stochastic algorithms. \nThis construction is friendly to the analysis of proximal oracle and also could  be used in general convex and average smooth cases naturally.", "pdf": "/pdf/746a8f488b060a784482d5ebf415fc66f692a2d3.pdf", "paperhash": "xie|a_novel_analysis_framework_of_lower_complexity_bounds_for_finitesum_optimization", "original_pdf": "/attachment/ee6336c636607010673966a630bfdb27e767b74e.pdf", "_bibtex": "@misc{\nxie2020a,\ntitle={A Novel Analysis Framework of Lower Complexity Bounds for Finite-Sum Optimization},\nauthor={Guangzeng Xie and Luo Luo and Zhihua Zhang},\nyear={2020},\nurl={https://openreview.net/forum?id=SygD31HFvB}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "SygD31HFvB", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper1954/Authors", "ICLR.cc/2020/Conference/Paper1954/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper1954/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper1954/Reviewers", "ICLR.cc/2020/Conference/Paper1954/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper1954/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper1954/Authors|ICLR.cc/2020/Conference/Paper1954/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504148449, "tmdate": 1576860561608, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper1954/Authors", "ICLR.cc/2020/Conference/Paper1954/Reviewers", "ICLR.cc/2020/Conference/Paper1954/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper1954/-/Official_Comment"}}}, {"id": "rJetIwmnsH", "original": null, "number": 5, "cdate": 1573824336674, "ddate": null, "tcdate": 1573824336674, "tmdate": 1573824354036, "tddate": null, "forum": "SygD31HFvB", "replyto": "SygD31HFvB", "invitation": "ICLR.cc/2020/Conference/Paper1954/-/Official_Comment", "content": {"title": "General Comments on Latest Revision", "comment": "We would like to thanks all official reviewers and Sebastian U Stich for their insightful and helpful comments. \nWe have appended a new lower bound in the case of $\\kappa = \\mathcal{O}(n)$ for strongly-convex optimization, which matches the upper bound of IFO algorithm (Hannah et al., 2018)  (see Table 1, Theorem 3.1 and Section 4.1 in our latest version of the paper). \nWe also have included a comparison with other constructions in Appendix B. "}, "signatures": ["ICLR.cc/2020/Conference/Paper1954/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1954/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "A Novel Analysis Framework of Lower Complexity Bounds for Finite-Sum Optimization", "authors": ["Guangzeng Xie", "Luo Luo", "Zhihua Zhang"], "authorids": ["smsxgz@pku.edu.cn", "rickyluoluo@gmail.com", "zhzhang@math.pku.edu.cn"], "keywords": ["convex optimization", "lower bound complexity", "proximal incremental first-order oracle"], "abstract": "This paper studies the lower bound complexity for the optimization problem whose objective function is the average of $n$ individual smooth convex functions. We consider the algorithm which gets access to gradient and proximal oracle for each individual component.\nFor the strongly-convex case, we prove such an algorithm can not reach an $\\eps$-suboptimal point in fewer than $\\Omega((n+\\sqrt{\\kappa n})\\log(1/\\eps))$ iterations, where $\\kappa$ is the condition number of the objective function. This lower bound is tighter than previous results and perfectly matches the upper bound of the existing proximal incremental first-order oracle algorithm Point-SAGA.\nWe develop a novel construction to show the above result, which partitions the tridiagonal matrix of classical examples into $n$ groups to make the problem difficult enough to stochastic algorithms. \nThis construction is friendly to the analysis of proximal oracle and also could  be used in general convex and average smooth cases naturally.", "pdf": "/pdf/746a8f488b060a784482d5ebf415fc66f692a2d3.pdf", "paperhash": "xie|a_novel_analysis_framework_of_lower_complexity_bounds_for_finitesum_optimization", "original_pdf": "/attachment/ee6336c636607010673966a630bfdb27e767b74e.pdf", "_bibtex": "@misc{\nxie2020a,\ntitle={A Novel Analysis Framework of Lower Complexity Bounds for Finite-Sum Optimization},\nauthor={Guangzeng Xie and Luo Luo and Zhihua Zhang},\nyear={2020},\nurl={https://openreview.net/forum?id=SygD31HFvB}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "SygD31HFvB", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper1954/Authors", "ICLR.cc/2020/Conference/Paper1954/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper1954/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper1954/Reviewers", "ICLR.cc/2020/Conference/Paper1954/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper1954/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper1954/Authors|ICLR.cc/2020/Conference/Paper1954/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504148449, "tmdate": 1576860561608, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper1954/Authors", "ICLR.cc/2020/Conference/Paper1954/Reviewers", "ICLR.cc/2020/Conference/Paper1954/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper1954/-/Official_Comment"}}}, {"id": "S1xPXyAiYH", "original": null, "number": 1, "cdate": 1571704607066, "ddate": null, "tcdate": 1571704607066, "tmdate": 1572972402100, "tddate": null, "forum": "SygD31HFvB", "replyto": "SygD31HFvB", "invitation": "ICLR.cc/2020/Conference/Paper1954/-/Official_Review", "content": {"experience_assessment": "I have read many papers in this area.", "rating": "3: Weak Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "N/A", "title": "Official Blind Review #1", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "The authors prove lower bounds on the number of queries required for optimizing sums of convex functions.  They consider more powerful queries than the usual queries that provide function evaluation/gradient pairs for chosen summands.  As was done in [1] (which is cited in the submission), in this work algorithms can also get the answer to a\n\"prox query\" solving a regularized optimization problem for the chosen summand at the chosen point.  For different classes of functions obtained through smoothness and (strong) convexity constraints, the lower bounds are on\nthe number of queries needed by an algorithm to guarantee to approximate the minimum.\n\nThe main result is for the case that the summands are mu-strongly convex and L-smooth.  Bounds for this case are often\ngiven in terms of kappa = L/mu.  An upper bound of O( (n + sqrt(kappa n) ) log(1/eps)) is known, and\n[1] had proved a lower bound of Omega( n + sqrt(kappa n)  log(1/eps)), which matches the second term of the upper bound, but leaves a log-factor gap for the first.  This paper proves an Omega( (n + sqrt(kappa n) ) log(1/eps))  lower bound, but for a restricted class of algorithms that fix a probability distribution over the summands ahead of time, and randomize by repeatedly sampling independently at random from this fixed distribution.  The iterates of the algorithm are also constrained to be in the span of the answers to previous queries.  Thus, this new result is incomparable in strength with the result in [1].  Also, the authors of this paper mention early in the paper that kappa is often large relative to n.\nBut even if kappa is on the same order as n, the second term of the upper bound dominates the first, and is matched by the lower bound in [1].\n\nThe authors point to some new techniques in their analysis.  I can see some new elements, but my knowledge of the previous work in this area is not deep enough to evaluate technical novelty very well.\n\nI have some question about the extent to which this work is in scope for ICLR.  An argument could go that since stochastic gradient methods are so important to deep learning, study of the foundations and limitations of those methods is in scope.\nBut a lower bound for the convex case seems to be stretching this a little far.  \n\nThis seems like a somewhat incremental contribution that would be of interest to a smallish subset of ICLR attendees.\n\n[1] Blake Woodworth and Nathan Srebro. Tight complexity bounds for\noptimizing composite objectives. In NIPS, 2016."}, "signatures": ["ICLR.cc/2020/Conference/Paper1954/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1954/AnonReviewer1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "A Novel Analysis Framework of Lower Complexity Bounds for Finite-Sum Optimization", "authors": ["Guangzeng Xie", "Luo Luo", "Zhihua Zhang"], "authorids": ["smsxgz@pku.edu.cn", "rickyluoluo@gmail.com", "zhzhang@math.pku.edu.cn"], "keywords": ["convex optimization", "lower bound complexity", "proximal incremental first-order oracle"], "abstract": "This paper studies the lower bound complexity for the optimization problem whose objective function is the average of $n$ individual smooth convex functions. We consider the algorithm which gets access to gradient and proximal oracle for each individual component.\nFor the strongly-convex case, we prove such an algorithm can not reach an $\\eps$-suboptimal point in fewer than $\\Omega((n+\\sqrt{\\kappa n})\\log(1/\\eps))$ iterations, where $\\kappa$ is the condition number of the objective function. This lower bound is tighter than previous results and perfectly matches the upper bound of the existing proximal incremental first-order oracle algorithm Point-SAGA.\nWe develop a novel construction to show the above result, which partitions the tridiagonal matrix of classical examples into $n$ groups to make the problem difficult enough to stochastic algorithms. \nThis construction is friendly to the analysis of proximal oracle and also could  be used in general convex and average smooth cases naturally.", "pdf": "/pdf/746a8f488b060a784482d5ebf415fc66f692a2d3.pdf", "paperhash": "xie|a_novel_analysis_framework_of_lower_complexity_bounds_for_finitesum_optimization", "original_pdf": "/attachment/ee6336c636607010673966a630bfdb27e767b74e.pdf", "_bibtex": "@misc{\nxie2020a,\ntitle={A Novel Analysis Framework of Lower Complexity Bounds for Finite-Sum Optimization},\nauthor={Guangzeng Xie and Luo Luo and Zhihua Zhang},\nyear={2020},\nurl={https://openreview.net/forum?id=SygD31HFvB}\n}"}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "SygD31HFvB", "replyto": "SygD31HFvB", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper1954/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper1954/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1575017085837, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper1954/Reviewers"], "noninvitees": [], "tcdate": 1570237729882, "tmdate": 1575017085850, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper1954/-/Official_Review"}}}, {"id": "H1ezmonaYS", "original": null, "number": 2, "cdate": 1571830553702, "ddate": null, "tcdate": 1571830553702, "tmdate": 1572972402055, "tddate": null, "forum": "SygD31HFvB", "replyto": "SygD31HFvB", "invitation": "ICLR.cc/2020/Conference/Paper1954/-/Official_Review", "content": {"experience_assessment": "I have read many papers in this area.", "rating": "8: Accept", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "N/A", "title": "Official Blind Review #3", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "** Summary\nThe paper derives a novel lower bound on the complexity of optimizing finite-sum convex functions (under different assumptions) using algorithms that have access to point-wise evaluation of the function, its gradient, and proximal information. \n\n** Overall evaluation\nFinite-sum convex functions are very common in machine learning problems and how the optimization complexity scales with their properties (e.g., condition number) and the number of components (e.g., number of samples in typical ML problems) is a very important question. This paper addresses the question from a lower bound point of view, showing that there is no proximal incremental first-order algorithm that can optimize such functions at an accuracy level of epsilon in less than a term which depends linearly with number of components n and sqrt(k) (k being the condition number). The paper fills an existing gap in the literature and it achieves two very interesting results:\n1- The lower bound now matches an existing upper bound for Point-SAGA, showing that no better algorithm can exist (at least in a worst-case sense). \n2- This result also illustrate that proximal algorithms are not necessarily more powerful than first-order methods that only access the gradient of the function. This is also very interesting, as it was still an open question whether proximal information could possibly give an advantage.\n\nThe paper is also well written, although some elements could be improved:\n1- Def 2.4: the authors consider algorithms where the sampling distribution cannot adapt through iterations. Although this is standard, I am wondering whether adaptivity may buy anything in the performance or whether the lower bound applies to adaptive algorithms as well.\n2- Although similar constructions to create worst-case functions were used before in deriving complexity lower bounds, it would be useful to have an intuition about the specific choice made in eg Eq.5/6 and how this enables the refined analysis presented in the paper.\n3- More in general, I encourage the authors to illustrate how their techniques compare and differ from previous lower bound proofs.\n4- In all theorems, the analysis is done by linking the dimension d to all other parameters of the problem. As pointed out by the authors, the requirements on the dimensionality in the theorems of this paper are milder than previous results. It would be helpful to illustrate how the lower bound would behave when the dimensionality changes and provide an intuition about the specific choice in the theorems"}, "signatures": ["ICLR.cc/2020/Conference/Paper1954/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1954/AnonReviewer3"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "A Novel Analysis Framework of Lower Complexity Bounds for Finite-Sum Optimization", "authors": ["Guangzeng Xie", "Luo Luo", "Zhihua Zhang"], "authorids": ["smsxgz@pku.edu.cn", "rickyluoluo@gmail.com", "zhzhang@math.pku.edu.cn"], "keywords": ["convex optimization", "lower bound complexity", "proximal incremental first-order oracle"], "abstract": "This paper studies the lower bound complexity for the optimization problem whose objective function is the average of $n$ individual smooth convex functions. We consider the algorithm which gets access to gradient and proximal oracle for each individual component.\nFor the strongly-convex case, we prove such an algorithm can not reach an $\\eps$-suboptimal point in fewer than $\\Omega((n+\\sqrt{\\kappa n})\\log(1/\\eps))$ iterations, where $\\kappa$ is the condition number of the objective function. This lower bound is tighter than previous results and perfectly matches the upper bound of the existing proximal incremental first-order oracle algorithm Point-SAGA.\nWe develop a novel construction to show the above result, which partitions the tridiagonal matrix of classical examples into $n$ groups to make the problem difficult enough to stochastic algorithms. \nThis construction is friendly to the analysis of proximal oracle and also could  be used in general convex and average smooth cases naturally.", "pdf": "/pdf/746a8f488b060a784482d5ebf415fc66f692a2d3.pdf", "paperhash": "xie|a_novel_analysis_framework_of_lower_complexity_bounds_for_finitesum_optimization", "original_pdf": "/attachment/ee6336c636607010673966a630bfdb27e767b74e.pdf", "_bibtex": "@misc{\nxie2020a,\ntitle={A Novel Analysis Framework of Lower Complexity Bounds for Finite-Sum Optimization},\nauthor={Guangzeng Xie and Luo Luo and Zhihua Zhang},\nyear={2020},\nurl={https://openreview.net/forum?id=SygD31HFvB}\n}"}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "SygD31HFvB", "replyto": "SygD31HFvB", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper1954/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper1954/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1575017085837, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper1954/Reviewers"], "noninvitees": [], "tcdate": 1570237729882, "tmdate": 1575017085850, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper1954/-/Official_Review"}}}, {"id": "rJxQHktG5r", "original": null, "number": 3, "cdate": 1572142907025, "ddate": null, "tcdate": 1572142907025, "tmdate": 1572972402009, "tddate": null, "forum": "SygD31HFvB", "replyto": "SygD31HFvB", "invitation": "ICLR.cc/2020/Conference/Paper1954/-/Official_Review", "content": {"experience_assessment": "I have read many papers in this area.", "rating": "6: Weak Accept", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I did not assess the experiments.", "title": "Official Blind Review #2", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "This paper proves a better complexity lower bound for stochastic PIFO optimizers on the problem of finite-sum minimization. The paper assumes that the objective function is the sum of n individual loss functions. It further assumes that (1) the optimizer initializes at a fixed point, and (2) at each iteration, it randomly and independently selects one loss function to update the parameter vector. \n\nTo prove the desired lower bound, the paper constructed a group of special loss functions, such that each individual loss depends on only 2 coordinates of the parameter vector (except for the regularization term). By this construction, if the parameter vector is initialized at 0, then the number of non-zero coordinates of it will grow slowly enough so that the parameter vector will stay in some low-dimensional subspace unless a large number of iterations is performed. Using this construction, the authors prove the lower bound for 4 different configurations of optimization problems.\n\nOverall, I think the results are very interesting. Similar ideas (the diagonal matrix used in this paper) have been widely adopted in proving complexity lower bound. The novelty of this paper appears to be that the diagonal matrix is partitioned into n groups to define the individual loss functions. Despite the tight lower bound, the assumption (1) and (2) above seems to be restrictive, but they are necessary for the analysis of this paper. If we allow the optimizer to initialize at a random point, or if the optimizer can adaptively choose the loss function at each iteration based on the parameter trajectory, then the analysis framework no longer applies. This is probably the main limitation of this work.\n"}, "signatures": ["ICLR.cc/2020/Conference/Paper1954/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1954/AnonReviewer2"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "A Novel Analysis Framework of Lower Complexity Bounds for Finite-Sum Optimization", "authors": ["Guangzeng Xie", "Luo Luo", "Zhihua Zhang"], "authorids": ["smsxgz@pku.edu.cn", "rickyluoluo@gmail.com", "zhzhang@math.pku.edu.cn"], "keywords": ["convex optimization", "lower bound complexity", "proximal incremental first-order oracle"], "abstract": "This paper studies the lower bound complexity for the optimization problem whose objective function is the average of $n$ individual smooth convex functions. We consider the algorithm which gets access to gradient and proximal oracle for each individual component.\nFor the strongly-convex case, we prove such an algorithm can not reach an $\\eps$-suboptimal point in fewer than $\\Omega((n+\\sqrt{\\kappa n})\\log(1/\\eps))$ iterations, where $\\kappa$ is the condition number of the objective function. This lower bound is tighter than previous results and perfectly matches the upper bound of the existing proximal incremental first-order oracle algorithm Point-SAGA.\nWe develop a novel construction to show the above result, which partitions the tridiagonal matrix of classical examples into $n$ groups to make the problem difficult enough to stochastic algorithms. \nThis construction is friendly to the analysis of proximal oracle and also could  be used in general convex and average smooth cases naturally.", "pdf": "/pdf/746a8f488b060a784482d5ebf415fc66f692a2d3.pdf", "paperhash": "xie|a_novel_analysis_framework_of_lower_complexity_bounds_for_finitesum_optimization", "original_pdf": "/attachment/ee6336c636607010673966a630bfdb27e767b74e.pdf", "_bibtex": "@misc{\nxie2020a,\ntitle={A Novel Analysis Framework of Lower Complexity Bounds for Finite-Sum Optimization},\nauthor={Guangzeng Xie and Luo Luo and Zhihua Zhang},\nyear={2020},\nurl={https://openreview.net/forum?id=SygD31HFvB}\n}"}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "SygD31HFvB", "replyto": "SygD31HFvB", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper1954/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper1954/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1575017085837, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper1954/Reviewers"], "noninvitees": [], "tcdate": 1570237729882, "tmdate": 1575017085850, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper1954/-/Official_Review"}}}, {"id": "BkxbWS7wtr", "original": null, "number": 1, "cdate": 1571398904543, "ddate": null, "tcdate": 1571398904543, "tmdate": 1571398904543, "tddate": null, "forum": "SygD31HFvB", "replyto": "SyxXlwcXYB", "invitation": "ICLR.cc/2020/Conference/Paper1954/-/Official_Comment", "content": {"comment": "1. Many thanks for your reviewing.\n2. The algorithms in Theorem 2 of (Hannah et al., 2018) use IFO while algorithms in our results use PIFO. PIFO provides more information than IFO and it would be potentially more powerful than IFO in first order optimization algorithms. Moreover, we develop a novel analysis framework to deal with PIFO algorithms and our framework is much simpler and more straightforward than the approach in  (Woodworth and Srebro, 2016) .\n3. Indeed, (Hannah et al., 2018) obtained a slightly better result for IFO algorithms. However, a subtle adjustment like the approach in (Hannah et al., 2018) also can improve our result to match the upper bound in (Hannah et al., 2018) as well. And we will update the modified results as soon as possible.\n", "title": "Thanks for reviewing!"}, "signatures": ["ICLR.cc/2020/Conference/Paper1954/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1954/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "A Novel Analysis Framework of Lower Complexity Bounds for Finite-Sum Optimization", "authors": ["Guangzeng Xie", "Luo Luo", "Zhihua Zhang"], "authorids": ["smsxgz@pku.edu.cn", "rickyluoluo@gmail.com", "zhzhang@math.pku.edu.cn"], "keywords": ["convex optimization", "lower bound complexity", "proximal incremental first-order oracle"], "abstract": "This paper studies the lower bound complexity for the optimization problem whose objective function is the average of $n$ individual smooth convex functions. We consider the algorithm which gets access to gradient and proximal oracle for each individual component.\nFor the strongly-convex case, we prove such an algorithm can not reach an $\\eps$-suboptimal point in fewer than $\\Omega((n+\\sqrt{\\kappa n})\\log(1/\\eps))$ iterations, where $\\kappa$ is the condition number of the objective function. This lower bound is tighter than previous results and perfectly matches the upper bound of the existing proximal incremental first-order oracle algorithm Point-SAGA.\nWe develop a novel construction to show the above result, which partitions the tridiagonal matrix of classical examples into $n$ groups to make the problem difficult enough to stochastic algorithms. \nThis construction is friendly to the analysis of proximal oracle and also could  be used in general convex and average smooth cases naturally.", "pdf": "/pdf/746a8f488b060a784482d5ebf415fc66f692a2d3.pdf", "paperhash": "xie|a_novel_analysis_framework_of_lower_complexity_bounds_for_finitesum_optimization", "original_pdf": "/attachment/ee6336c636607010673966a630bfdb27e767b74e.pdf", "_bibtex": "@misc{\nxie2020a,\ntitle={A Novel Analysis Framework of Lower Complexity Bounds for Finite-Sum Optimization},\nauthor={Guangzeng Xie and Luo Luo and Zhihua Zhang},\nyear={2020},\nurl={https://openreview.net/forum?id=SygD31HFvB}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "SygD31HFvB", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper1954/Authors", "ICLR.cc/2020/Conference/Paper1954/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper1954/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper1954/Reviewers", "ICLR.cc/2020/Conference/Paper1954/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper1954/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper1954/Authors|ICLR.cc/2020/Conference/Paper1954/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504148449, "tmdate": 1576860561608, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper1954/Authors", "ICLR.cc/2020/Conference/Paper1954/Reviewers", "ICLR.cc/2020/Conference/Paper1954/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper1954/-/Official_Comment"}}}, {"id": "SyxXlwcXYB", "original": null, "number": 1, "cdate": 1571165930665, "ddate": null, "tcdate": 1571165930665, "tmdate": 1571165930665, "tddate": null, "forum": "SygD31HFvB", "replyto": "SygD31HFvB", "invitation": "ICLR.cc/2020/Conference/Paper1954/-/Public_Comment", "content": {"comment": "Interesting paper!\nHow do your results (and assumptions) compare to e.g. the lower bounds in https://arxiv.org/abs/1805.07786?\nThanks for clarification,", "title": "Lower bounds by Hannah et al."}, "signatures": ["~Sebastian_U_Stich1"], "readers": ["everyone"], "nonreaders": [], "writers": ["~Sebastian_U_Stich1", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "A Novel Analysis Framework of Lower Complexity Bounds for Finite-Sum Optimization", "authors": ["Guangzeng Xie", "Luo Luo", "Zhihua Zhang"], "authorids": ["smsxgz@pku.edu.cn", "rickyluoluo@gmail.com", "zhzhang@math.pku.edu.cn"], "keywords": ["convex optimization", "lower bound complexity", "proximal incremental first-order oracle"], "abstract": "This paper studies the lower bound complexity for the optimization problem whose objective function is the average of $n$ individual smooth convex functions. We consider the algorithm which gets access to gradient and proximal oracle for each individual component.\nFor the strongly-convex case, we prove such an algorithm can not reach an $\\eps$-suboptimal point in fewer than $\\Omega((n+\\sqrt{\\kappa n})\\log(1/\\eps))$ iterations, where $\\kappa$ is the condition number of the objective function. This lower bound is tighter than previous results and perfectly matches the upper bound of the existing proximal incremental first-order oracle algorithm Point-SAGA.\nWe develop a novel construction to show the above result, which partitions the tridiagonal matrix of classical examples into $n$ groups to make the problem difficult enough to stochastic algorithms. \nThis construction is friendly to the analysis of proximal oracle and also could  be used in general convex and average smooth cases naturally.", "pdf": "/pdf/746a8f488b060a784482d5ebf415fc66f692a2d3.pdf", "paperhash": "xie|a_novel_analysis_framework_of_lower_complexity_bounds_for_finitesum_optimization", "original_pdf": "/attachment/ee6336c636607010673966a630bfdb27e767b74e.pdf", "_bibtex": "@misc{\nxie2020a,\ntitle={A Novel Analysis Framework of Lower Complexity Bounds for Finite-Sum Optimization},\nauthor={Guangzeng Xie and Luo Luo and Zhihua Zhang},\nyear={2020},\nurl={https://openreview.net/forum?id=SygD31HFvB}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "SygD31HFvB", "readers": {"values": ["everyone"], "description": "User groups that will be able to read this comment."}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "~.*"}}, "readers": ["everyone"], "tcdate": 1569504187200, "tmdate": 1576860594688, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["everyone"], "noninvitees": ["ICLR.cc/2020/Conference/Paper1954/Authors", "ICLR.cc/2020/Conference/Paper1954/Reviewers", "ICLR.cc/2020/Conference/Paper1954/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper1954/-/Public_Comment"}}}], "count": 11}