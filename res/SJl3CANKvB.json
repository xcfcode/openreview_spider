{"notes": [{"id": "SJl3CANKvB", "original": "r1gLSc9ODS", "number": 1446, "cdate": 1569439444236, "ddate": null, "tcdate": 1569439444236, "tmdate": 1577168228413, "tddate": null, "forum": "SJl3CANKvB", "replyto": null, "invitation": "ICLR.cc/2020/Conference/-/Blind_Submission", "content": {"authorids": ["qi-qi@uiowa.edu", "yanyan.tju@gmail.com", "wuzu@bc.edu", "fanghuaxue@gmail.com", "tianbao-yang@uiowa.edu"], "title": "A SIMPLE AND EFFECTIVE FRAMEWORK FOR PAIRWISE DEEP METRIC LEARNING", "authors": ["Qi Qi", "Yan Yan", "Zixuan Wu", "Xiaoyu Wang", "Tianbao Yang"], "pdf": "/pdf/d2abec51a93fc2cc295f9dc6d9b8add607826195.pdf", "TL;DR": "We provide a general and flexible framework based on distributionally robust optimization for deep metric learning which is robust to imbalanced data pair.", "abstract": "Deep metric learning (DML) has received much attention in deep learning due to its wide applications in computer vision. Previous studies have focused on designing complicated losses and hard example mining methods, which are mostly heuristic and lack of theoretical understanding. In this paper, we cast DML as a simple pairwise binary classification problem that classifies a pair of examples as similar or dissimilar. It identifies the most critical issue in this problem---imbalanced data pairs. To tackle this issue, we propose a simple and effective framework to sample pairs in a batch of data for updating the model. The key to this framework is to define a robust loss for all pairs over a mini-batch of data, which is formulated by distributionally robust optimization. The flexibility in constructing the  {\\it uncertainty decision set} of the dual variable allows us to recover state-of-the-art complicated losses and also to induce novel variants.  Empirical studies on several benchmark data sets demonstrate that our simple and effective method outperforms the state-of-the-art results.", "keywords": ["Deep Metric Learning", "Distributionally Robust Optimization"], "paperhash": "qi|a_simple_and_effective_framework_for_pairwise_deep_metric_learning", "original_pdf": "/attachment/8de17f5f9c75240e116f32d1b9aafc3618e12a7b.pdf", "_bibtex": "@misc{\nqi2020a,\ntitle={A {\\{}SIMPLE{\\}} {\\{}AND{\\}} {\\{}EFFECTIVE{\\}} {\\{}FRAMEWORK{\\}} {\\{}FOR{\\}} {\\{}PAIRWISE{\\}} {\\{}DEEP{\\}} {\\{}METRIC{\\}} {\\{}LEARNING{\\}}},\nauthor={Qi Qi and Yan Yan and Zixuan Wu and Xiaoyu Wang and Tianbao Yang},\nyear={2020},\nurl={https://openreview.net/forum?id=SJl3CANKvB}\n}"}, "signatures": ["ICLR.cc/2020/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference"], "details": {"replyCount": 7, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"reply": {"readers": {"values-regex": ".*"}, "writers": {"values": ["ICLR.cc/2020/Conference"]}, "signatures": {"values": ["ICLR.cc/2020/Conference"]}, "content": {"spotlight_video": {"value-regex": ".*"}, "full_presentation_video": {"value-regex": ".*"}, "original_pdf": {"required": false, "description": "Upload a PDF file that ends with .pdf", "value-regex": ".*"}, "appendix": {"value-regex": ".*"}, "authorids": {"values-regex": ".*"}, "poster": {"value-regex": ".*"}, "authors": {"values": ["Anonymous"]}, "slides": {"value-regex": ".*"}}}, "final": [], "signatures": ["ICLR.cc/2020/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference"], "noninvitees": [], "tcdate": 1569271260237, "tmdate": 1593459412141, "id": "ICLR.cc/2020/Conference/-/Blind_Submission"}}, "tauthor": "OpenReview.net"}, {"id": "E8WAc3bqm8", "original": null, "number": 1, "cdate": 1576798723499, "ddate": null, "tcdate": 1576798723499, "tmdate": 1576800913034, "tddate": null, "forum": "SJl3CANKvB", "replyto": "SJl3CANKvB", "invitation": "ICLR.cc/2020/Conference/Paper1446/-/Decision", "content": {"decision": "Reject", "comment": "The reviewers agree that this is a reasonable paper but somewhat derivative. The authors discussed the contribution further in the rebuttal, but even in light of their comments, I consider the significance of this work too low for acceptance.", "title": "Paper Decision"}, "signatures": ["ICLR.cc/2020/Conference/Program_Chairs"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Program_Chairs"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["qi-qi@uiowa.edu", "yanyan.tju@gmail.com", "wuzu@bc.edu", "fanghuaxue@gmail.com", "tianbao-yang@uiowa.edu"], "title": "A SIMPLE AND EFFECTIVE FRAMEWORK FOR PAIRWISE DEEP METRIC LEARNING", "authors": ["Qi Qi", "Yan Yan", "Zixuan Wu", "Xiaoyu Wang", "Tianbao Yang"], "pdf": "/pdf/d2abec51a93fc2cc295f9dc6d9b8add607826195.pdf", "TL;DR": "We provide a general and flexible framework based on distributionally robust optimization for deep metric learning which is robust to imbalanced data pair.", "abstract": "Deep metric learning (DML) has received much attention in deep learning due to its wide applications in computer vision. Previous studies have focused on designing complicated losses and hard example mining methods, which are mostly heuristic and lack of theoretical understanding. In this paper, we cast DML as a simple pairwise binary classification problem that classifies a pair of examples as similar or dissimilar. It identifies the most critical issue in this problem---imbalanced data pairs. To tackle this issue, we propose a simple and effective framework to sample pairs in a batch of data for updating the model. The key to this framework is to define a robust loss for all pairs over a mini-batch of data, which is formulated by distributionally robust optimization. The flexibility in constructing the  {\\it uncertainty decision set} of the dual variable allows us to recover state-of-the-art complicated losses and also to induce novel variants.  Empirical studies on several benchmark data sets demonstrate that our simple and effective method outperforms the state-of-the-art results.", "keywords": ["Deep Metric Learning", "Distributionally Robust Optimization"], "paperhash": "qi|a_simple_and_effective_framework_for_pairwise_deep_metric_learning", "original_pdf": "/attachment/8de17f5f9c75240e116f32d1b9aafc3618e12a7b.pdf", "_bibtex": "@misc{\nqi2020a,\ntitle={A {\\{}SIMPLE{\\}} {\\{}AND{\\}} {\\{}EFFECTIVE{\\}} {\\{}FRAMEWORK{\\}} {\\{}FOR{\\}} {\\{}PAIRWISE{\\}} {\\{}DEEP{\\}} {\\{}METRIC{\\}} {\\{}LEARNING{\\}}},\nauthor={Qi Qi and Yan Yan and Zixuan Wu and Xiaoyu Wang and Tianbao Yang},\nyear={2020},\nurl={https://openreview.net/forum?id=SJl3CANKvB}\n}"}, "tags": [], "invitation": {"reply": {"writers": {"description": "How your identity will be displayed.", "values-regex": ["ICLR.cc/2020/Conference/Program_Chairs"]}, "signatures": {"values": ["ICLR.cc/2020/Conference/Program_Chairs"], "description": "How your identity will be displayed."}, "content": {"decision": {"value-radio": ["Accept (Spotlight)", "Accept (Talk)", "Accept (Poster)", "Reject"], "description": "Decision", "required": true, "order": 2}, "title": {"value": "Paper Decision", "required": true, "order": 1}, "comment": {"value-regex": "[\\S\\s]{0,5000}", "description": "", "required": false, "order": 3}}, "forum": "SJl3CANKvB", "replyto": "SJl3CANKvB", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}}, "expdate": 1576854540000, "duedate": 1576853940000, "multiReply": false, "readers": ["everyone"], "invitees": ["ICLR.cc/2020/Conference/Program_Chairs"], "tcdate": 1576795712935, "tmdate": 1576800262431, "super": "ICLR.cc/2020/Conference/-/Decision", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper1446/-/Decision"}}}, {"id": "BJgxWlzsoS", "original": null, "number": 1, "cdate": 1573752824248, "ddate": null, "tcdate": 1573752824248, "tmdate": 1573792628863, "tddate": null, "forum": "SJl3CANKvB", "replyto": "HJgZmWvTtr", "invitation": "ICLR.cc/2020/Conference/Paper1446/-/Official_Comment", "content": {"title": "Difference from traditional DRO framework  and our contributions to DML", "comment": "We would emphasize that our framework is not a straightforward application of DRO. Instead, by addressing the critical issues in DML, our framework is an effective and general approach to DML. We summarize two significant contributions of our paper.\n\nFirst, our framework is more general, flexible and practical than traditional DRO. While traditional DRO usually restricts the dual variable to be on a simplex, our framework is built upon the minibatch and its uncertainty set for the dual variable is not necessarily restricted to such probability simplex. Please note that this is very important for us 1) to make the proposed approach practical for big data than traditional DRO defined on the whole data set; 2) to recover the approaches based on MS loss and LS loss by choosing different regularizations on the dual variables. It is notable that such recovery hinges on special grouping of the dual variables, which is not possible under traditional DRO framework; 3) to design more powerful variants such as DRO-TopK-PN, which is less sensitive to the positive to negative ratio (shown in Figure 1). \n\nSecond, our framework introduces significant contributions to DML by 1) connecting loss development and sampling strategy design together, 2) justifying the existing loss functions in DML (e.g., MS and LS loss) from our general framework, and 3) providing insights to design new variants.\nIn literature, as mentioned in our paper, many studies of DML either focus on developing increasingly complicated minibatch losses which rarely provide deep insights for why it is effective, or designing sampling strategies in terms of pairs. Consequently, developing loss functions and designing sampling strategies are two independent research directions, and may not benefit from each other. However, in our framework, we unify these two lines of work into a general framework to jointly take advantage of sampling and loss development. Specifically, the sampling weights according to the variable p is updated based on the relative magnitude of pairwise losses within a mini-batch at each iteration. Then the constructed robust loss is able to promote performance, which has been extensively demonstrated in our experiments. \n"}, "signatures": ["ICLR.cc/2020/Conference/Paper1446/Authors"], "readers": ["ICLR.cc/2020/Conference/Paper1446/Authors", "ICLR.cc/2020/Conference/Paper1446/Reviewers", "ICLR.cc/2020/Conference/Paper1446/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs", "everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1446/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["qi-qi@uiowa.edu", "yanyan.tju@gmail.com", "wuzu@bc.edu", "fanghuaxue@gmail.com", "tianbao-yang@uiowa.edu"], "title": "A SIMPLE AND EFFECTIVE FRAMEWORK FOR PAIRWISE DEEP METRIC LEARNING", "authors": ["Qi Qi", "Yan Yan", "Zixuan Wu", "Xiaoyu Wang", "Tianbao Yang"], "pdf": "/pdf/d2abec51a93fc2cc295f9dc6d9b8add607826195.pdf", "TL;DR": "We provide a general and flexible framework based on distributionally robust optimization for deep metric learning which is robust to imbalanced data pair.", "abstract": "Deep metric learning (DML) has received much attention in deep learning due to its wide applications in computer vision. Previous studies have focused on designing complicated losses and hard example mining methods, which are mostly heuristic and lack of theoretical understanding. In this paper, we cast DML as a simple pairwise binary classification problem that classifies a pair of examples as similar or dissimilar. It identifies the most critical issue in this problem---imbalanced data pairs. To tackle this issue, we propose a simple and effective framework to sample pairs in a batch of data for updating the model. The key to this framework is to define a robust loss for all pairs over a mini-batch of data, which is formulated by distributionally robust optimization. The flexibility in constructing the  {\\it uncertainty decision set} of the dual variable allows us to recover state-of-the-art complicated losses and also to induce novel variants.  Empirical studies on several benchmark data sets demonstrate that our simple and effective method outperforms the state-of-the-art results.", "keywords": ["Deep Metric Learning", "Distributionally Robust Optimization"], "paperhash": "qi|a_simple_and_effective_framework_for_pairwise_deep_metric_learning", "original_pdf": "/attachment/8de17f5f9c75240e116f32d1b9aafc3618e12a7b.pdf", "_bibtex": "@misc{\nqi2020a,\ntitle={A {\\{}SIMPLE{\\}} {\\{}AND{\\}} {\\{}EFFECTIVE{\\}} {\\{}FRAMEWORK{\\}} {\\{}FOR{\\}} {\\{}PAIRWISE{\\}} {\\{}DEEP{\\}} {\\{}METRIC{\\}} {\\{}LEARNING{\\}}},\nauthor={Qi Qi and Yan Yan and Zixuan Wu and Xiaoyu Wang and Tianbao Yang},\nyear={2020},\nurl={https://openreview.net/forum?id=SJl3CANKvB}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "SJl3CANKvB", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper1446/Authors", "ICLR.cc/2020/Conference/Paper1446/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper1446/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper1446/Reviewers", "ICLR.cc/2020/Conference/Paper1446/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper1446/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper1446/Authors|ICLR.cc/2020/Conference/Paper1446/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504155892, "tmdate": 1576860555886, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper1446/Authors", "ICLR.cc/2020/Conference/Paper1446/Reviewers", "ICLR.cc/2020/Conference/Paper1446/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper1446/-/Official_Comment"}}}, {"id": "ryguiHzojH", "original": null, "number": 5, "cdate": 1573754271598, "ddate": null, "tcdate": 1573754271598, "tmdate": 1573792598119, "tddate": null, "forum": "SJl3CANKvB", "replyto": "H1lyrJVHtB", "invitation": "ICLR.cc/2020/Conference/Paper1446/-/Official_Comment", "content": {"title": "Difference from traditional DRO", "comment": "Thanks for your comments! For differences between our framework and traditional DRO method, please also check response to Reviewer 3. We want to emphasize that the modifications (i.e., defining over a mini-bath for the robust loss, and more general and flexible regularization of the dual variables) are subtle but very important for achieving better empirical results than complicated losses and bringing more theoretical insights for complicated losses.  "}, "signatures": ["ICLR.cc/2020/Conference/Paper1446/Authors"], "readers": ["ICLR.cc/2020/Conference/Paper1446/Authors", "ICLR.cc/2020/Conference/Paper1446/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper1446/Reviewers", "ICLR.cc/2020/Conference/Paper1446/Area_Chairs", "everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1446/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["qi-qi@uiowa.edu", "yanyan.tju@gmail.com", "wuzu@bc.edu", "fanghuaxue@gmail.com", "tianbao-yang@uiowa.edu"], "title": "A SIMPLE AND EFFECTIVE FRAMEWORK FOR PAIRWISE DEEP METRIC LEARNING", "authors": ["Qi Qi", "Yan Yan", "Zixuan Wu", "Xiaoyu Wang", "Tianbao Yang"], "pdf": "/pdf/d2abec51a93fc2cc295f9dc6d9b8add607826195.pdf", "TL;DR": "We provide a general and flexible framework based on distributionally robust optimization for deep metric learning which is robust to imbalanced data pair.", "abstract": "Deep metric learning (DML) has received much attention in deep learning due to its wide applications in computer vision. Previous studies have focused on designing complicated losses and hard example mining methods, which are mostly heuristic and lack of theoretical understanding. In this paper, we cast DML as a simple pairwise binary classification problem that classifies a pair of examples as similar or dissimilar. It identifies the most critical issue in this problem---imbalanced data pairs. To tackle this issue, we propose a simple and effective framework to sample pairs in a batch of data for updating the model. The key to this framework is to define a robust loss for all pairs over a mini-batch of data, which is formulated by distributionally robust optimization. The flexibility in constructing the  {\\it uncertainty decision set} of the dual variable allows us to recover state-of-the-art complicated losses and also to induce novel variants.  Empirical studies on several benchmark data sets demonstrate that our simple and effective method outperforms the state-of-the-art results.", "keywords": ["Deep Metric Learning", "Distributionally Robust Optimization"], "paperhash": "qi|a_simple_and_effective_framework_for_pairwise_deep_metric_learning", "original_pdf": "/attachment/8de17f5f9c75240e116f32d1b9aafc3618e12a7b.pdf", "_bibtex": "@misc{\nqi2020a,\ntitle={A {\\{}SIMPLE{\\}} {\\{}AND{\\}} {\\{}EFFECTIVE{\\}} {\\{}FRAMEWORK{\\}} {\\{}FOR{\\}} {\\{}PAIRWISE{\\}} {\\{}DEEP{\\}} {\\{}METRIC{\\}} {\\{}LEARNING{\\}}},\nauthor={Qi Qi and Yan Yan and Zixuan Wu and Xiaoyu Wang and Tianbao Yang},\nyear={2020},\nurl={https://openreview.net/forum?id=SJl3CANKvB}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "SJl3CANKvB", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper1446/Authors", "ICLR.cc/2020/Conference/Paper1446/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper1446/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper1446/Reviewers", "ICLR.cc/2020/Conference/Paper1446/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper1446/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper1446/Authors|ICLR.cc/2020/Conference/Paper1446/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504155892, "tmdate": 1576860555886, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper1446/Authors", "ICLR.cc/2020/Conference/Paper1446/Reviewers", "ICLR.cc/2020/Conference/Paper1446/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper1446/-/Official_Comment"}}}, {"id": "rJxRWXGsjB", "original": null, "number": 2, "cdate": 1573753606394, "ddate": null, "tcdate": 1573753606394, "tmdate": 1573753934614, "tddate": null, "forum": "SJl3CANKvB", "replyto": "HJgZmWvTtr", "invitation": "ICLR.cc/2020/Conference/Paper1446/-/Official_Comment", "content": {"title": "Significant improvement over MS loss", "comment": "We believe that our experimental improvement over MS loss is significant. \nPlease note that (from Table 1 and 3), compared with the best baselines, MS improved 2.1% (over Margin), -1.1% (over ABE), 2.4% (over ABE) on Cub-200-2011, Cars-196 and In-Shop in Recall@1, respectively. On the other hand, our best DRO variant always achieves the best performance, improving 2.4% (over MS) on Cub-200-2011, 1.2% (over ABE), 2.5% (over MS) on Cars-196,  1.6% over MS on In-Shop. Among these variants of our framework, DRO-KL_M improves 2.0% (over MS), 2.5% (over MS), and 1.1% (over  MS) on Cub-200-2011, Cars-196 and In-Shop, respectively.  \n\nIn our ablation study, we show that DRO-KL-G could recover the performance of MS and LS by changing the hyper parameter \\gamma (Table 2 and 4). Furthermore, tuning \\gamma helps DRO-KL-G outperform MS in Recall@1 by 1.4%, 1.8% and 6% on Cub-200-2011, Cars-196 and In-Shop, respectively.\n"}, "signatures": ["ICLR.cc/2020/Conference/Paper1446/Authors"], "readers": ["everyone", "ICLR.cc/2020/Conference/Paper1446/Authors", "ICLR.cc/2020/Conference/Paper1446/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper1446/Reviewers", "ICLR.cc/2020/Conference/Paper1446/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1446/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["qi-qi@uiowa.edu", "yanyan.tju@gmail.com", "wuzu@bc.edu", "fanghuaxue@gmail.com", "tianbao-yang@uiowa.edu"], "title": "A SIMPLE AND EFFECTIVE FRAMEWORK FOR PAIRWISE DEEP METRIC LEARNING", "authors": ["Qi Qi", "Yan Yan", "Zixuan Wu", "Xiaoyu Wang", "Tianbao Yang"], "pdf": "/pdf/d2abec51a93fc2cc295f9dc6d9b8add607826195.pdf", "TL;DR": "We provide a general and flexible framework based on distributionally robust optimization for deep metric learning which is robust to imbalanced data pair.", "abstract": "Deep metric learning (DML) has received much attention in deep learning due to its wide applications in computer vision. Previous studies have focused on designing complicated losses and hard example mining methods, which are mostly heuristic and lack of theoretical understanding. In this paper, we cast DML as a simple pairwise binary classification problem that classifies a pair of examples as similar or dissimilar. It identifies the most critical issue in this problem---imbalanced data pairs. To tackle this issue, we propose a simple and effective framework to sample pairs in a batch of data for updating the model. The key to this framework is to define a robust loss for all pairs over a mini-batch of data, which is formulated by distributionally robust optimization. The flexibility in constructing the  {\\it uncertainty decision set} of the dual variable allows us to recover state-of-the-art complicated losses and also to induce novel variants.  Empirical studies on several benchmark data sets demonstrate that our simple and effective method outperforms the state-of-the-art results.", "keywords": ["Deep Metric Learning", "Distributionally Robust Optimization"], "paperhash": "qi|a_simple_and_effective_framework_for_pairwise_deep_metric_learning", "original_pdf": "/attachment/8de17f5f9c75240e116f32d1b9aafc3618e12a7b.pdf", "_bibtex": "@misc{\nqi2020a,\ntitle={A {\\{}SIMPLE{\\}} {\\{}AND{\\}} {\\{}EFFECTIVE{\\}} {\\{}FRAMEWORK{\\}} {\\{}FOR{\\}} {\\{}PAIRWISE{\\}} {\\{}DEEP{\\}} {\\{}METRIC{\\}} {\\{}LEARNING{\\}}},\nauthor={Qi Qi and Yan Yan and Zixuan Wu and Xiaoyu Wang and Tianbao Yang},\nyear={2020},\nurl={https://openreview.net/forum?id=SJl3CANKvB}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "SJl3CANKvB", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper1446/Authors", "ICLR.cc/2020/Conference/Paper1446/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper1446/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper1446/Reviewers", "ICLR.cc/2020/Conference/Paper1446/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper1446/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper1446/Authors|ICLR.cc/2020/Conference/Paper1446/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504155892, "tmdate": 1576860555886, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper1446/Authors", "ICLR.cc/2020/Conference/Paper1446/Reviewers", "ICLR.cc/2020/Conference/Paper1446/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper1446/-/Official_Comment"}}}, {"id": "H1lyrJVHtB", "original": null, "number": 1, "cdate": 1571270455145, "ddate": null, "tcdate": 1571270455145, "tmdate": 1572972467988, "tddate": null, "forum": "SJl3CANKvB", "replyto": "SJl3CANKvB", "invitation": "ICLR.cc/2020/Conference/Paper1446/-/Official_Review", "content": {"rating": "6: Weak Accept", "experience_assessment": "I do not know much about this area.", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #2", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review": "This paper proposes a framework for deep metric learning. Using ideas from distributionally robust optimization, the loss (in each batch) is the worst case weighted average of all pairwise classification losses, taken over an uncertainty set of possible weights. The framework is shown to be general and encompass various previous approaches. Based on it, the authors propose several new algorithms, which are shown to outperform the SOTA on image retrieval data sets in terms of recall.\n\nThe main contribution of the paper is a unification of previous deep metric learning algorithms, which would be helpful to the community and could inspire new approaches. I found the empirical observation that the proposed algorithms are able to reduce the computation time by nearly half to be compelling. However, apart from DRO-TopK-PN, the proposed algorithms appear to be minor modifications of existing algorithms. \n\nQuestions about the experimental protocol:\n1. Are the results from one run, or averaged over several? Standard errors of the evaluation metrics would be very helpful to judge the improvements made by the algorithms, especially as the algorithms are stochastic due to batching. \n2. The proposed algorithms seem to be similar to those of Fan et al. (2017) and Namkoong and Duchi (2017). Is there a particular reason why they weren\u2019t included in the experiments? "}, "signatures": ["ICLR.cc/2020/Conference/Paper1446/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1446/AnonReviewer2"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["qi-qi@uiowa.edu", "yanyan.tju@gmail.com", "wuzu@bc.edu", "fanghuaxue@gmail.com", "tianbao-yang@uiowa.edu"], "title": "A SIMPLE AND EFFECTIVE FRAMEWORK FOR PAIRWISE DEEP METRIC LEARNING", "authors": ["Qi Qi", "Yan Yan", "Zixuan Wu", "Xiaoyu Wang", "Tianbao Yang"], "pdf": "/pdf/d2abec51a93fc2cc295f9dc6d9b8add607826195.pdf", "TL;DR": "We provide a general and flexible framework based on distributionally robust optimization for deep metric learning which is robust to imbalanced data pair.", "abstract": "Deep metric learning (DML) has received much attention in deep learning due to its wide applications in computer vision. Previous studies have focused on designing complicated losses and hard example mining methods, which are mostly heuristic and lack of theoretical understanding. In this paper, we cast DML as a simple pairwise binary classification problem that classifies a pair of examples as similar or dissimilar. It identifies the most critical issue in this problem---imbalanced data pairs. To tackle this issue, we propose a simple and effective framework to sample pairs in a batch of data for updating the model. The key to this framework is to define a robust loss for all pairs over a mini-batch of data, which is formulated by distributionally robust optimization. The flexibility in constructing the  {\\it uncertainty decision set} of the dual variable allows us to recover state-of-the-art complicated losses and also to induce novel variants.  Empirical studies on several benchmark data sets demonstrate that our simple and effective method outperforms the state-of-the-art results.", "keywords": ["Deep Metric Learning", "Distributionally Robust Optimization"], "paperhash": "qi|a_simple_and_effective_framework_for_pairwise_deep_metric_learning", "original_pdf": "/attachment/8de17f5f9c75240e116f32d1b9aafc3618e12a7b.pdf", "_bibtex": "@misc{\nqi2020a,\ntitle={A {\\{}SIMPLE{\\}} {\\{}AND{\\}} {\\{}EFFECTIVE{\\}} {\\{}FRAMEWORK{\\}} {\\{}FOR{\\}} {\\{}PAIRWISE{\\}} {\\{}DEEP{\\}} {\\{}METRIC{\\}} {\\{}LEARNING{\\}}},\nauthor={Qi Qi and Yan Yan and Zixuan Wu and Xiaoyu Wang and Tianbao Yang},\nyear={2020},\nurl={https://openreview.net/forum?id=SJl3CANKvB}\n}"}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "SJl3CANKvB", "replyto": "SJl3CANKvB", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper1446/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper1446/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1576379314454, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper1446/Reviewers"], "noninvitees": [], "tcdate": 1570237737274, "tmdate": 1576379314469, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper1446/-/Official_Review"}}}, {"id": "SyevOXVstr", "original": null, "number": 2, "cdate": 1571664751435, "ddate": null, "tcdate": 1571664751435, "tmdate": 1572972467954, "tddate": null, "forum": "SJl3CANKvB", "replyto": "SJl3CANKvB", "invitation": "ICLR.cc/2020/Conference/Paper1446/-/Official_Review", "content": {"rating": "6: Weak Accept", "experience_assessment": "I have read many papers in this area.", "review_assessment:_checking_correctness_of_derivations_and_theory": "I did not assess the derivations or theory.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #1", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review": "The authors address the (increasingly popular) problem of learning a metric from a given multi-dimensional data set. They consider the deep metric learning setup, where target distances are defined as the euclidean distances in an artificial feature space (created by a deep neural network). Main focus of the paper is to cases where the data set is affected by a substantial imbalance between the amount of examples that are similar to each other and the total number of examples.\n\nI would tend to accept the paper because handling the imbalance problem in metric learning is important and both the theoretical analysis and the experiments show that the proposed method may have some impact.\n\nThe idea of reducing the problem to a binary classification between similar and dissimilar examples may look too simple but i) is a common approach in deep metric learning, ii) helps to handle the implicit imbalance problem and iii) suggests possible generalisations to other network-based problems (for example, where similarity is naturally defined by the existence of absence of a link). Showing that many complicated losses are equivalent to DRO may also help the general understanding of the metric learning task.\n\nMy main concerns are about the net contribution of the paper. Tackling the imbalance problem is important but it is not clear whether the full metric learning setup is really needed. The authors could have stated more precisely in what sense the metric learning unbalanced problem they consider is different from usual unbalanced binary classification. Otherwise, as DRO is well known, it is hard to identify the real novelty of their method.\n\nQuestions: \n- how does the specific metric learning setup make the considered DRO different from usual unbalanced classification? \n- how the network architecture affects the performance? For example, would the size of the embedding space change the recall/imbalance plot? \n- Is the choice of euclidean distances standard in deep metric learning? Would a choice of more general distances be incorporated in the proposed method?\n \n"}, "signatures": ["ICLR.cc/2020/Conference/Paper1446/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1446/AnonReviewer1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["qi-qi@uiowa.edu", "yanyan.tju@gmail.com", "wuzu@bc.edu", "fanghuaxue@gmail.com", "tianbao-yang@uiowa.edu"], "title": "A SIMPLE AND EFFECTIVE FRAMEWORK FOR PAIRWISE DEEP METRIC LEARNING", "authors": ["Qi Qi", "Yan Yan", "Zixuan Wu", "Xiaoyu Wang", "Tianbao Yang"], "pdf": "/pdf/d2abec51a93fc2cc295f9dc6d9b8add607826195.pdf", "TL;DR": "We provide a general and flexible framework based on distributionally robust optimization for deep metric learning which is robust to imbalanced data pair.", "abstract": "Deep metric learning (DML) has received much attention in deep learning due to its wide applications in computer vision. Previous studies have focused on designing complicated losses and hard example mining methods, which are mostly heuristic and lack of theoretical understanding. In this paper, we cast DML as a simple pairwise binary classification problem that classifies a pair of examples as similar or dissimilar. It identifies the most critical issue in this problem---imbalanced data pairs. To tackle this issue, we propose a simple and effective framework to sample pairs in a batch of data for updating the model. The key to this framework is to define a robust loss for all pairs over a mini-batch of data, which is formulated by distributionally robust optimization. The flexibility in constructing the  {\\it uncertainty decision set} of the dual variable allows us to recover state-of-the-art complicated losses and also to induce novel variants.  Empirical studies on several benchmark data sets demonstrate that our simple and effective method outperforms the state-of-the-art results.", "keywords": ["Deep Metric Learning", "Distributionally Robust Optimization"], "paperhash": "qi|a_simple_and_effective_framework_for_pairwise_deep_metric_learning", "original_pdf": "/attachment/8de17f5f9c75240e116f32d1b9aafc3618e12a7b.pdf", "_bibtex": "@misc{\nqi2020a,\ntitle={A {\\{}SIMPLE{\\}} {\\{}AND{\\}} {\\{}EFFECTIVE{\\}} {\\{}FRAMEWORK{\\}} {\\{}FOR{\\}} {\\{}PAIRWISE{\\}} {\\{}DEEP{\\}} {\\{}METRIC{\\}} {\\{}LEARNING{\\}}},\nauthor={Qi Qi and Yan Yan and Zixuan Wu and Xiaoyu Wang and Tianbao Yang},\nyear={2020},\nurl={https://openreview.net/forum?id=SJl3CANKvB}\n}"}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "SJl3CANKvB", "replyto": "SJl3CANKvB", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper1446/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper1446/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1576379314454, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper1446/Reviewers"], "noninvitees": [], "tcdate": 1570237737274, "tmdate": 1576379314469, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper1446/-/Official_Review"}}}, {"id": "HJgZmWvTtr", "original": null, "number": 3, "cdate": 1571807513465, "ddate": null, "tcdate": 1571807513465, "tmdate": 1572972467918, "tddate": null, "forum": "SJl3CANKvB", "replyto": "SJl3CANKvB", "invitation": "ICLR.cc/2020/Conference/Paper1446/-/Official_Review", "content": {"experience_assessment": "I have read many papers in this area.", "rating": "3: Weak Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #3", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "This paper casts deep metric learning (DML) as a pairwise binary classification problem such that pairs of examples need to be classified as similar or dissimilar. The authors propose an objective function that computes a weighted sum over the pairwise losses in a mini-batch. The weight vector is selected to maximize the objective from a decision set encoding constraints. This formulation is called the distributionally robust optimization (DRO) framework.\n\nThe authors argue that the DRO framework is theoretically justified by showing how certain decision sets result in existing machine learning loss functions. This portion of the paper seemed hand-wavy. It is not clear what is the purpose of including the theorem from Namkoon & Duchi. It would be more clear in my view to just make the short point that a certain decision set recovers the DRO with f-divergence as would be expected. The claims with regard to learning theory are over-stated in the paper.\n\nThe authors proposed three variants of the general framework. They include a top-K formulation, a variance-regularized version, and a top-K version using a balance between positive and negative examples. The DRO framework and the variants are the main contributions in terms of methodology in this paper. It is also shown that the framework generalizes more complicated recently proposed losses.\n\nThe experiments demonstrate the DRO framework consistently outperforms state of the art deep metric learning methods on benchmark datasets by small margins. There is also a computational speed advantage that is shown.\nOverall, this paper shows that the ideas from distributionally robust optimization work well in deep metric learning. In particular, the paper shows that by combining the DRO framework with simple loss functions, performance comparable with complicated loss functions can be obtained. This aspect, along with the generality are the main strong suits. That being said, I do not see this paper to be that significant of a contribution. The main idea in the paper seems like a rather direct application of the DRO modeling framework and it does not provide too significant of improvement over the MS loss.  The paper was not written super clearly and was too long. Reviewers were instructed to apply a higher standard to papers in excess of 8 pages and this paper would have been presented more effectively if it was shorter. For these reasons, I recommended a weak reject."}, "signatures": ["ICLR.cc/2020/Conference/Paper1446/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1446/AnonReviewer3"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["qi-qi@uiowa.edu", "yanyan.tju@gmail.com", "wuzu@bc.edu", "fanghuaxue@gmail.com", "tianbao-yang@uiowa.edu"], "title": "A SIMPLE AND EFFECTIVE FRAMEWORK FOR PAIRWISE DEEP METRIC LEARNING", "authors": ["Qi Qi", "Yan Yan", "Zixuan Wu", "Xiaoyu Wang", "Tianbao Yang"], "pdf": "/pdf/d2abec51a93fc2cc295f9dc6d9b8add607826195.pdf", "TL;DR": "We provide a general and flexible framework based on distributionally robust optimization for deep metric learning which is robust to imbalanced data pair.", "abstract": "Deep metric learning (DML) has received much attention in deep learning due to its wide applications in computer vision. Previous studies have focused on designing complicated losses and hard example mining methods, which are mostly heuristic and lack of theoretical understanding. In this paper, we cast DML as a simple pairwise binary classification problem that classifies a pair of examples as similar or dissimilar. It identifies the most critical issue in this problem---imbalanced data pairs. To tackle this issue, we propose a simple and effective framework to sample pairs in a batch of data for updating the model. The key to this framework is to define a robust loss for all pairs over a mini-batch of data, which is formulated by distributionally robust optimization. The flexibility in constructing the  {\\it uncertainty decision set} of the dual variable allows us to recover state-of-the-art complicated losses and also to induce novel variants.  Empirical studies on several benchmark data sets demonstrate that our simple and effective method outperforms the state-of-the-art results.", "keywords": ["Deep Metric Learning", "Distributionally Robust Optimization"], "paperhash": "qi|a_simple_and_effective_framework_for_pairwise_deep_metric_learning", "original_pdf": "/attachment/8de17f5f9c75240e116f32d1b9aafc3618e12a7b.pdf", "_bibtex": "@misc{\nqi2020a,\ntitle={A {\\{}SIMPLE{\\}} {\\{}AND{\\}} {\\{}EFFECTIVE{\\}} {\\{}FRAMEWORK{\\}} {\\{}FOR{\\}} {\\{}PAIRWISE{\\}} {\\{}DEEP{\\}} {\\{}METRIC{\\}} {\\{}LEARNING{\\}}},\nauthor={Qi Qi and Yan Yan and Zixuan Wu and Xiaoyu Wang and Tianbao Yang},\nyear={2020},\nurl={https://openreview.net/forum?id=SJl3CANKvB}\n}"}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "SJl3CANKvB", "replyto": "SJl3CANKvB", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper1446/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper1446/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1576379314454, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper1446/Reviewers"], "noninvitees": [], "tcdate": 1570237737274, "tmdate": 1576379314469, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper1446/-/Official_Review"}}}], "count": 8}