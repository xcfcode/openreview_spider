{"notes": [{"id": "pAq1h9sQhqd", "original": "lzao_xBcvG", "number": 131, "cdate": 1601308023325, "ddate": null, "tcdate": 1601308023325, "tmdate": 1614985657907, "tddate": null, "forum": "pAq1h9sQhqd", "replyto": null, "invitation": "ICLR.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Stochastic Canonical Correlation Analysis: A Riemannian Approach", "authorids": ["~Zihang_Meng1", "~Rudrasis_Chakraborty1", "~Vikas_Singh1"], "authors": ["Zihang Meng", "Rudrasis Chakraborty", "Vikas Singh"], "keywords": ["CCA", "streaming", "differential geometry", "DeepCCA", "fairness"], "abstract": " We present an efficient stochastic algorithm (RSG+) for canonical correlation analysis (CCA) derived via a differential geometric perspective of the underlying optimization task. We show that exploiting the Riemannian structure of the problem reveals natural strategies for modified forms of manifold stochastic gradient descent schemes that have been variously used in the literature for numerical optimization on manifolds. Our developments complement existing methods for this problem which either require $O(d^3)$ time complexity per iteration with $O(\\frac{1}{\\sqrt{t}})$ convergence rate (where $d$ is the dimensionality) or only extract the top $1$ component with $O(\\frac{1}{t})$ convergence rate. In contrast, our algorithm achieves $O(d^2k)$ runtime complexity per iteration for extracting top $k$ canonical components with $O(\\frac{1}{t})$ convergence rate. We present our theoretical analysis as well as experiments describing the empirical behavior of our algorithm, including a potential application of this idea for training fair models where the label of protected attribute is missing or otherwise unavailable.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "meng|stochastic_canonical_correlation_analysis_a_riemannian_approach", "one-sentence_summary": "We present an efficient stochastic algorithm (RSG+) for canonical correlation analysis (CCA) derived via a differential geometric perspective of the underlying optimization task.", "pdf": "/pdf/46a100d101a05682223099f9d44b113c0cb49950.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=Hss_j4P5GW", "_bibtex": "@misc{\nmeng2021stochastic,\ntitle={Stochastic Canonical Correlation Analysis: A Riemannian Approach},\nauthor={Zihang Meng and Rudrasis Chakraborty and Vikas Singh},\nyear={2021},\nurl={https://openreview.net/forum?id=pAq1h9sQhqd}\n}"}, "signatures": ["ICLR.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference"], "details": {"replyCount": 15, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"reply": {"readers": {"values-regex": ".*"}, "writers": {"values": ["ICLR.cc/2021/Conference"]}, "signatures": {"values": ["ICLR.cc/2021/Conference"]}, "content": {"authors": {"values": ["Anonymous"]}, "authorids": {"values-regex": ".*"}, "reviewed_version_(pdf)": {"required": false, "description": "Upload a PDF file that ends with .pdf", "value-regex": ".*"}}}, "signatures": ["ICLR.cc/2021/Conference"], "readers": ["everyone"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["~", "OpenReview.net/Support"], "tcdate": 1601308008205, "tmdate": 1614984599368, "id": "ICLR.cc/2021/Conference/-/Blind_Submission"}}, "tauthor": "OpenReview.net"}, {"id": "y70QzafjlV", "original": null, "number": 1, "cdate": 1610040504350, "ddate": null, "tcdate": 1610040504350, "tmdate": 1610474111489, "tddate": null, "forum": "pAq1h9sQhqd", "replyto": "pAq1h9sQhqd", "invitation": "ICLR.cc/2021/Conference/Paper131/-/Decision", "content": {"title": "Final Decision", "decision": "Reject", "comment": "This paper gives a new algorithm for the CCA problem. The main idea of the new algorithm is to reformulate the matrices in the CCA problem as a product of three matrices: one orthonormal matrix, one rotation and one upper-diagonal matrix. The algorithm then performs remannian gradient descent to these components. The per-iteration complexity of the algorithm is O(d^2k) while the (local) convergence rate is O(1/t). Overall the reformulation is interesting and the algorithm seems effective in practice. On the other hand the convergence rate proof relies on local strong convexity and it's not clear why the algorithm converges globally (or even what is the radius of convergence locally)."}, "signatures": ["ICLR.cc/2021/Conference/Program_Chairs"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference/Program_Chairs"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Stochastic Canonical Correlation Analysis: A Riemannian Approach", "authorids": ["~Zihang_Meng1", "~Rudrasis_Chakraborty1", "~Vikas_Singh1"], "authors": ["Zihang Meng", "Rudrasis Chakraborty", "Vikas Singh"], "keywords": ["CCA", "streaming", "differential geometry", "DeepCCA", "fairness"], "abstract": " We present an efficient stochastic algorithm (RSG+) for canonical correlation analysis (CCA) derived via a differential geometric perspective of the underlying optimization task. We show that exploiting the Riemannian structure of the problem reveals natural strategies for modified forms of manifold stochastic gradient descent schemes that have been variously used in the literature for numerical optimization on manifolds. Our developments complement existing methods for this problem which either require $O(d^3)$ time complexity per iteration with $O(\\frac{1}{\\sqrt{t}})$ convergence rate (where $d$ is the dimensionality) or only extract the top $1$ component with $O(\\frac{1}{t})$ convergence rate. In contrast, our algorithm achieves $O(d^2k)$ runtime complexity per iteration for extracting top $k$ canonical components with $O(\\frac{1}{t})$ convergence rate. We present our theoretical analysis as well as experiments describing the empirical behavior of our algorithm, including a potential application of this idea for training fair models where the label of protected attribute is missing or otherwise unavailable.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "meng|stochastic_canonical_correlation_analysis_a_riemannian_approach", "one-sentence_summary": "We present an efficient stochastic algorithm (RSG+) for canonical correlation analysis (CCA) derived via a differential geometric perspective of the underlying optimization task.", "pdf": "/pdf/46a100d101a05682223099f9d44b113c0cb49950.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=Hss_j4P5GW", "_bibtex": "@misc{\nmeng2021stochastic,\ntitle={Stochastic Canonical Correlation Analysis: A Riemannian Approach},\nauthor={Zihang Meng and Rudrasis Chakraborty and Vikas Singh},\nyear={2021},\nurl={https://openreview.net/forum?id=pAq1h9sQhqd}\n}"}, "tags": [], "invitation": {"reply": {"forum": "pAq1h9sQhqd", "replyto": "pAq1h9sQhqd", "readers": {"values": ["everyone"]}, "writers": {"values": ["ICLR.cc/2021/Conference/Program_Chairs"]}, "signatures": {"values": ["ICLR.cc/2021/Conference/Program_Chairs"]}, "content": {"title": {"value": "Final Decision"}, "decision": {"value-radio": ["Accept (Oral)", "Accept (Spotlight)", "Accept (Poster)", "Reject"]}, "comment": {"value-regex": "[\\S\\s]{0,50000}", "markdown": true}}}, "multiReply": false, "signatures": ["ICLR.cc/2021/Conference"], "readers": ["everyone"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Program_Chairs"], "tcdate": 1610040504337, "tmdate": 1610474111474, "id": "ICLR.cc/2021/Conference/Paper131/-/Decision"}}}, {"id": "0_9Ym4E4Hx6", "original": null, "number": 11, "cdate": 1605675942607, "ddate": null, "tcdate": 1605675942607, "tmdate": 1605676298578, "tddate": null, "forum": "pAq1h9sQhqd", "replyto": "1mDMWe9VUve", "invitation": "ICLR.cc/2021/Conference/Paper131/-/Official_Comment", "content": {"title": "Clarification of two points", "comment": "1. by `\"asymptotically converge\": does it mean when the number of samples goes to infinity?\n\nAns: Here \u201casymptotic\u201d is with respect to the number of steps of the Riemannian gradient  descent procedure (Bonnabel, 2013 at https://arxiv.org/pdf/1111.5280.pdf), see (4) and Theorem 1. This analysis style has also been used in (http://proceedings.mlr.press/v97/kasai19a/kasai19a.pdf; ICML 19, see Theorem. 4.4 and Corollary 4.5)\n(https://www.di.ens.fr/~fbach/colt_2018_tripurareni_flammarion_bach_jordan.pdf; JMLR 18, see Theorem 1) and others. \nIn our case, as the number of steps goes to infinity, $\\widetilde{U}$ converges to the principal directions, and hence $C(\\widetilde{X}_k)$ converges to $C(X_k)$. Note that as the number of samples is fixed, the number of steps corresponds to the number of iterations over the dataset. In our setup, we used one pass over the dataset as the setting is stochastic. \n\n\n2. By \"ensuring\" the diagonal of S to be nonzero, what exactly does it mean?. A constraint such as $S_{ii} \\neq 0$ may not be nontrivial. How is this enforced without affecting the convergence proof? By optimizing over the log, you also need some non-negativity constraint on $S_ii$, I suppose---otherwise log is not defined. In addition, your algorithm descriptions in the main text and in the supplemental material seem not to reflect this point. The reviewer feels that this explanation seems not to be very convincing.\n\nAns: Observe that, without loss of generality we can assume diagonal of $S$, i.e., $S_{ii} > 0$ as if for any $j$, $S_{jj} <0$, we can flip the sign of the $j^{th}$ column of $Q$, where, $Q$ is an orthogonal matrix. Moreover, sign flip does not affect the converge analysis. \nHence, $S \\in \\mathbf{R}^{k\\times k}$ can be modeled as the manifold $\\mathbf{R}^{k(k-1)/2)}\\times \\mathbf{R}_+^k$ ($\\mathbf{R}_+$ is the space of positive reals). Now, parameterizing $\\mathbf{R}_+$ can be accomplished using Riemannian log map (which is the natural logarithm in this case) (see Cheng et al., AISTATS 2011).  Observe that the log space is unrestricted, as $x > 0 \\implies log(x) \\in \\mathbf{R}$, thus the optimization on the log space is unconstrained.\nFurther, Proposition 3 is used while optimizing for $S$, hence the convergence analysis remains valid. \n"}, "signatures": ["ICLR.cc/2021/Conference/Paper131/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper131/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Stochastic Canonical Correlation Analysis: A Riemannian Approach", "authorids": ["~Zihang_Meng1", "~Rudrasis_Chakraborty1", "~Vikas_Singh1"], "authors": ["Zihang Meng", "Rudrasis Chakraborty", "Vikas Singh"], "keywords": ["CCA", "streaming", "differential geometry", "DeepCCA", "fairness"], "abstract": " We present an efficient stochastic algorithm (RSG+) for canonical correlation analysis (CCA) derived via a differential geometric perspective of the underlying optimization task. We show that exploiting the Riemannian structure of the problem reveals natural strategies for modified forms of manifold stochastic gradient descent schemes that have been variously used in the literature for numerical optimization on manifolds. Our developments complement existing methods for this problem which either require $O(d^3)$ time complexity per iteration with $O(\\frac{1}{\\sqrt{t}})$ convergence rate (where $d$ is the dimensionality) or only extract the top $1$ component with $O(\\frac{1}{t})$ convergence rate. In contrast, our algorithm achieves $O(d^2k)$ runtime complexity per iteration for extracting top $k$ canonical components with $O(\\frac{1}{t})$ convergence rate. We present our theoretical analysis as well as experiments describing the empirical behavior of our algorithm, including a potential application of this idea for training fair models where the label of protected attribute is missing or otherwise unavailable.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "meng|stochastic_canonical_correlation_analysis_a_riemannian_approach", "one-sentence_summary": "We present an efficient stochastic algorithm (RSG+) for canonical correlation analysis (CCA) derived via a differential geometric perspective of the underlying optimization task.", "pdf": "/pdf/46a100d101a05682223099f9d44b113c0cb49950.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=Hss_j4P5GW", "_bibtex": "@misc{\nmeng2021stochastic,\ntitle={Stochastic Canonical Correlation Analysis: A Riemannian Approach},\nauthor={Zihang Meng and Rudrasis Chakraborty and Vikas Singh},\nyear={2021},\nurl={https://openreview.net/forum?id=pAq1h9sQhqd}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "pAq1h9sQhqd", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper131/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper131/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper131/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper131/Authors|ICLR.cc/2021/Conference/Paper131/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper131/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923874275, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper131/-/Official_Comment"}}}, {"id": "1mDMWe9VUve", "original": null, "number": 10, "cdate": 1605660317529, "ddate": null, "tcdate": 1605660317529, "tmdate": 1605660317529, "tddate": null, "forum": "pAq1h9sQhqd", "replyto": "r9GK317rkDD", "invitation": "ICLR.cc/2021/Conference/Paper131/-/Official_Comment", "content": {"title": "Some clarification regarding item 8 and item 9", "comment": "There are some points that the authors may be able to quickly clarify:\n\n1) by `\"asymptotically converge\": does it mean when the number of samples goes to infinity?\n\n2) by \"ensuring\" the diagonal of S to be nonzero, what exactly does it mean?. A constraint such as S_ii \\neq 0 may not be nontrivial in practice (and nonconvex in fact). How is this enforced without affecting the convergence proof? By optimizing over the log, you also need some nonnegativity constraint on S_ii, I suppose---otherwise log is not defined. The reviewer is wondering are you using the log-barrier approach? Not that log barrier works for convex sets, but S_ii\\neq 0 is not convex. Even if the set is convex, the barrier parameter affects the approximation accuracy a lot. It is unclear how this approach affects the overall analysis since this information was not disclosed before.  In addition, your algorithm descriptions in the main text and in the supplemental material seem not to reflect this point.  The reviewer feels that this explanation seems not to be very convincing."}, "signatures": ["ICLR.cc/2021/Conference/Paper131/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper131/AnonReviewer1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Stochastic Canonical Correlation Analysis: A Riemannian Approach", "authorids": ["~Zihang_Meng1", "~Rudrasis_Chakraborty1", "~Vikas_Singh1"], "authors": ["Zihang Meng", "Rudrasis Chakraborty", "Vikas Singh"], "keywords": ["CCA", "streaming", "differential geometry", "DeepCCA", "fairness"], "abstract": " We present an efficient stochastic algorithm (RSG+) for canonical correlation analysis (CCA) derived via a differential geometric perspective of the underlying optimization task. We show that exploiting the Riemannian structure of the problem reveals natural strategies for modified forms of manifold stochastic gradient descent schemes that have been variously used in the literature for numerical optimization on manifolds. Our developments complement existing methods for this problem which either require $O(d^3)$ time complexity per iteration with $O(\\frac{1}{\\sqrt{t}})$ convergence rate (where $d$ is the dimensionality) or only extract the top $1$ component with $O(\\frac{1}{t})$ convergence rate. In contrast, our algorithm achieves $O(d^2k)$ runtime complexity per iteration for extracting top $k$ canonical components with $O(\\frac{1}{t})$ convergence rate. We present our theoretical analysis as well as experiments describing the empirical behavior of our algorithm, including a potential application of this idea for training fair models where the label of protected attribute is missing or otherwise unavailable.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "meng|stochastic_canonical_correlation_analysis_a_riemannian_approach", "one-sentence_summary": "We present an efficient stochastic algorithm (RSG+) for canonical correlation analysis (CCA) derived via a differential geometric perspective of the underlying optimization task.", "pdf": "/pdf/46a100d101a05682223099f9d44b113c0cb49950.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=Hss_j4P5GW", "_bibtex": "@misc{\nmeng2021stochastic,\ntitle={Stochastic Canonical Correlation Analysis: A Riemannian Approach},\nauthor={Zihang Meng and Rudrasis Chakraborty and Vikas Singh},\nyear={2021},\nurl={https://openreview.net/forum?id=pAq1h9sQhqd}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "pAq1h9sQhqd", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper131/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper131/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper131/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper131/Authors|ICLR.cc/2021/Conference/Paper131/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper131/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923874275, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper131/-/Official_Comment"}}}, {"id": "r9GK317rkDD", "original": null, "number": 8, "cdate": 1605481730824, "ddate": null, "tcdate": 1605481730824, "tmdate": 1605484545259, "tddate": null, "forum": "pAq1h9sQhqd", "replyto": "9cxwZ5Ouedz", "invitation": "ICLR.cc/2021/Conference/Paper131/-/Official_Comment", "content": {"title": "Clarifications for Reviewer 1", "comment": "1) Clarity\nAns: The reviewer\u2019s suggestions have helped us slow down the presentation and provide more details in many places throughout the paper with major reorganization. Several steps and concepts which we assumed that a reader will already be familiar with, are now more explicitly described. \n\nReadability\n\n2.1) give the exact definitions in the appendix\nAns: We significantly expanded the appendix describing the material to introduce the reader to every manifold we have used. We also provided additional references for the interested reader. \n\n2.2) page 3 not clear\nAns: Pages 3-4 have been significantly expanded as a response to this comment. \n\n2.3) why structural constraint is good\nAns: In this revised version, we devoted effort and space into describing most aspects of this adjustment and its ramifications regarding the feasibility set and computational efficiency. \n\n2.4) Theorem 1 says E goes to zero when Eq 3b is satisfied. \nAns: The additional discussion related to the initialization followed by the RGD scheme (which is used specifically to maintain feasibility) on pages 2, 3, and 4, we believe will clarify these doubts. \n\n2.5) If Eq 3b is not satisfied, U, V may not be desired solutions. \nAns: We can clarify this doubt. Equation (3b) can be easily satisfied by choosing $\\widetilde{U}$ as the principal vectors, $S_u$ to be the top-k eigenvalues of $X^TX$ and $Q_u$ to be any special orthogonal matrix. This ensures that the initialization is feasible. Notice that the solution space of (3) is a subset of the solution space of (2) under the distributional assumption, so any feasible solution to (3) satisfies (2). \n\n2.6) claims were not clear\nAns: Based on the reviewer\u2019s suggestion, we rewrote and restructured most parts of page 3 including the part preceding and following the \u201cIntuition\u201d subsection, together with other improvements on pages 2 and 4/5. \n\u2028\u2028\n 3) Equivalence of (1), (3). \nAns: We added a sub-section specifically to describe the feasible solution set for (3). We also devoted significantly more text to describe the conditions under which our proposed CC estimator as a solution for (3) is consistent. \n\n4) Thm. presented in abrupt way.\u2028\nAns: Based on these suggestions, we removed Proposition 1 and used Proposition 2 (Proposition 1 in the revised pdf) as a bridge between CC estimator and Theorem 1. We added significantly more text and explanation so that a reader will follow the reasoning much more easily. \n\n5) Prop 5. how is this used\nAns: We have added text after Prop 5 to clarify this point. \n\u2028\n 6) algorithm isn't in main text.\nAns: We included more details of the algorithm in the text and more explanation of each of the main parts of the algorithm which will simplify understanding. \n\n7) major reorganization.\u2028\nAns: This concern is now addressed in this revision. As per reviewer\u2019s suggestion, we much improved the level of detail/explanation provided for each step and expanded the proof of Thm. 1 with additional description and annotation. \n\n8) Thm. 1: sub-Gaussian data; how far from I_k\nAns: For data that severely violates the assumption, our algorithm can be applied but evaluation will be empirical. But the consistency proof may not hold or will need to be reworked or additional assumptions or algorithmic adjustments will be needed on a case-by-case basis based on the distribution at hand to make the current steps go through. While removing such assumptions is desirable, such an assumption is not uncommon for such analyses for CCA as well as many other generic models. For example, Vershynin et al. (The Mathematics of Data, 2017) notes \u201cSub-gaussian distributions form a sufficiently wide class of distributions. Many results in probability and data science are proved nowadays for sub-gaussian random variables\u2026\u201d. \nThm. 1 states that if the data is sub-Gaussian, our proposed CC estimator (soln. of (3)) is consistent, i.e., asymptotically converges to the soln. of (2).\nObserve that, $C(X_k) = I_k$ using the ``whitening constraint\u2019\u2019 as X_k is the projection of X on U, thus  $C(\\tilde{X}_k) \\rightarrow I_k$ implies $C(\\tilde{X}_k) \\rightarrow C(X_k)$. We clarify this in the proof of Theorem 1. Observe that, with $\\widetilde{U}$ as the top-k principal directions, $S_u$ as inverse of the square root of top-k eigenvalues of $X^TX$ and $Q_u$ as any SO matrix, we can satisfy $C(\\tilde{X}_k)  = I_k$. But in practice, because of streaming PCA,  $C(\\tilde{X}_k)  \\rightarrow I_k$ asymptotically. Moreover, as $C(\\tilde{X}_k)$ converges to $I_k$, the error between $F$ (objective function (1)) and $\\widetilde{F}$ (objective function (3)) converges to $0$. \n\n9) Even if the upper triangular structure is preserved, S can be rank deficient\nAns: We ensure the full rank of the upper triangular matrix by ensuring that the diagonal to be non-zero. During optimization, we ensure the non-zero diagonal entries by optimizing over the log of the diagonal entries. We have added additional text which describe these details.   "}, "signatures": ["ICLR.cc/2021/Conference/Paper131/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper131/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Stochastic Canonical Correlation Analysis: A Riemannian Approach", "authorids": ["~Zihang_Meng1", "~Rudrasis_Chakraborty1", "~Vikas_Singh1"], "authors": ["Zihang Meng", "Rudrasis Chakraborty", "Vikas Singh"], "keywords": ["CCA", "streaming", "differential geometry", "DeepCCA", "fairness"], "abstract": " We present an efficient stochastic algorithm (RSG+) for canonical correlation analysis (CCA) derived via a differential geometric perspective of the underlying optimization task. We show that exploiting the Riemannian structure of the problem reveals natural strategies for modified forms of manifold stochastic gradient descent schemes that have been variously used in the literature for numerical optimization on manifolds. Our developments complement existing methods for this problem which either require $O(d^3)$ time complexity per iteration with $O(\\frac{1}{\\sqrt{t}})$ convergence rate (where $d$ is the dimensionality) or only extract the top $1$ component with $O(\\frac{1}{t})$ convergence rate. In contrast, our algorithm achieves $O(d^2k)$ runtime complexity per iteration for extracting top $k$ canonical components with $O(\\frac{1}{t})$ convergence rate. We present our theoretical analysis as well as experiments describing the empirical behavior of our algorithm, including a potential application of this idea for training fair models where the label of protected attribute is missing or otherwise unavailable.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "meng|stochastic_canonical_correlation_analysis_a_riemannian_approach", "one-sentence_summary": "We present an efficient stochastic algorithm (RSG+) for canonical correlation analysis (CCA) derived via a differential geometric perspective of the underlying optimization task.", "pdf": "/pdf/46a100d101a05682223099f9d44b113c0cb49950.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=Hss_j4P5GW", "_bibtex": "@misc{\nmeng2021stochastic,\ntitle={Stochastic Canonical Correlation Analysis: A Riemannian Approach},\nauthor={Zihang Meng and Rudrasis Chakraborty and Vikas Singh},\nyear={2021},\nurl={https://openreview.net/forum?id=pAq1h9sQhqd}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "pAq1h9sQhqd", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper131/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper131/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper131/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper131/Authors|ICLR.cc/2021/Conference/Paper131/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper131/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923874275, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper131/-/Official_Comment"}}}, {"id": "3TB5BjWMuR_", "original": null, "number": 9, "cdate": 1605481862414, "ddate": null, "tcdate": 1605481862414, "tmdate": 1605481862414, "tddate": null, "forum": "pAq1h9sQhqd", "replyto": "qyrddLnfRvx", "invitation": "ICLR.cc/2021/Conference/Paper131/-/Official_Comment", "content": {"title": "Comparison with Yger+2012", "comment": "As per the reviewer's suggestion, we have added a comparison with Yager, 2012 in Table 1."}, "signatures": ["ICLR.cc/2021/Conference/Paper131/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper131/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Stochastic Canonical Correlation Analysis: A Riemannian Approach", "authorids": ["~Zihang_Meng1", "~Rudrasis_Chakraborty1", "~Vikas_Singh1"], "authors": ["Zihang Meng", "Rudrasis Chakraborty", "Vikas Singh"], "keywords": ["CCA", "streaming", "differential geometry", "DeepCCA", "fairness"], "abstract": " We present an efficient stochastic algorithm (RSG+) for canonical correlation analysis (CCA) derived via a differential geometric perspective of the underlying optimization task. We show that exploiting the Riemannian structure of the problem reveals natural strategies for modified forms of manifold stochastic gradient descent schemes that have been variously used in the literature for numerical optimization on manifolds. Our developments complement existing methods for this problem which either require $O(d^3)$ time complexity per iteration with $O(\\frac{1}{\\sqrt{t}})$ convergence rate (where $d$ is the dimensionality) or only extract the top $1$ component with $O(\\frac{1}{t})$ convergence rate. In contrast, our algorithm achieves $O(d^2k)$ runtime complexity per iteration for extracting top $k$ canonical components with $O(\\frac{1}{t})$ convergence rate. We present our theoretical analysis as well as experiments describing the empirical behavior of our algorithm, including a potential application of this idea for training fair models where the label of protected attribute is missing or otherwise unavailable.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "meng|stochastic_canonical_correlation_analysis_a_riemannian_approach", "one-sentence_summary": "We present an efficient stochastic algorithm (RSG+) for canonical correlation analysis (CCA) derived via a differential geometric perspective of the underlying optimization task.", "pdf": "/pdf/46a100d101a05682223099f9d44b113c0cb49950.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=Hss_j4P5GW", "_bibtex": "@misc{\nmeng2021stochastic,\ntitle={Stochastic Canonical Correlation Analysis: A Riemannian Approach},\nauthor={Zihang Meng and Rudrasis Chakraborty and Vikas Singh},\nyear={2021},\nurl={https://openreview.net/forum?id=pAq1h9sQhqd}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "pAq1h9sQhqd", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper131/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper131/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper131/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper131/Authors|ICLR.cc/2021/Conference/Paper131/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper131/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923874275, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper131/-/Official_Comment"}}}, {"id": "9cxwZ5Ouedz", "original": null, "number": 7, "cdate": 1605296300835, "ddate": null, "tcdate": 1605296300835, "tmdate": 1605296300835, "tddate": null, "forum": "pAq1h9sQhqd", "replyto": "igA9vszSRsJ", "invitation": "ICLR.cc/2021/Conference/Paper131/-/Official_Comment", "content": {"title": "Comments on the authors repsonse", "comment": "Comment: \u00a0\u00a01. *paper is packed*\n\nThe reviewer understands page limitation may give challenges for preparing the manuscript. But the clarity bar shouldn\u2019t be lowered because authors have a lot of materials to present. \n\n2. *Improve readability: contributions, formulations, etc*\u2028\n\nThe reviewer has taken a look at page 3 again per the authors\u2019 request. This page is particular hard to follow. First, the reviewer does not think SO, Gr, and St are clearly defined. If the authors are using some conventionally used notations from somewhere else, one standard way is to cite the origin. A better way is perhaps to give the exact definitions in the appendix. Saying SO is a manifold of \u201cspecial matrices\u201d does not help clarify what is the mathematical definition---and the argument that this is \u201cstandard\u201d in certain community may not help neither. Without definitions of these manifolds, the reviewer could only guess what the authors meant to write here.\n\nBesides notation discrepancy, page 3 also have many comments that does not lead to clear understanding.\n\nFor example. In Remark 1\n\nit seems that U, V are constrained in equation (2) rather than \"arbitrary\" matrices.  The decomposition adds more structural constraints on to U, V, but the remark did not explain why this structural constraint is a good constraint. Is it without loss of generality, or it is a compromise for computational efficiency? It may be helpful to clarify these points.\n\nThis is perhaps related to Theorem 1. Theorem 1 only says that E goes to zero when Eq 3b is satisfied. But Theorem 1 does not say when Eq. 3b can be satisfied. If the reviewer understands correctly, the manifold parameterization for U and V may make Eq 3b infeasible, since the search space has been shrunk. This was not quite articulated in the paper. More importantly, if Eq 3b is not satisfied, then the computed U, V may not be desired solutions. How to deal with this situation?\n\nFor the paragraph `` Intuition behind the decomposition''\n\nThe last couple of sentences may be the most useful. But this claim was not clearly seen at this stage.  \n\n\u2028\u2028\u00a03. *Equivalence of (1) and (3) was not clearly shown.*\u2028\u2028\u00a0\n\nThe expression change is indeed minor. But how large is the change in essence? The reviewer\u2019s concern is that this decomposition may have changed the problem to an extent that is not easy to quantify. The question is how much the problem has been changed?Is the approximation good? \u2028\u2028\u00a0\n\n4. *Theorems presented in a bit abrupt way.*\u2028\u2028\u00a0\n\nSome suggestions: Perhaps an equivalence lemma could appear after eq 3. This may be part of Theorem 1 or modified version of Theorem 1. Proposition 1 may be a bridge, and may not need to appear in the main text. Proposition 2 may be more clearly explained how it is used to compute Eq 3, rather than just stating it here without too much explanation. The same applies to Prop 5. How is this used in *this* submission? This is perhaps more important than simply stating this proposition.\n\n\u2028\u00a05. *Even the algorithm does not appear in the main text.*\u2028\u2028\u00a0\n\nThe reviewer does not think readers could follow the \u201cfull\u201d pseudocode to reproduce the algorithm. Indeed, detailed explanations do not add too much value. But vague description may not either.\u2028\u2028\u00a0\n\n6. *Color code is confusing.*\u2028\u2028\u00a0\n\nThis may be just the reviewer\u2019s personal opinion. The authors may keep it. It does not affect the score that the reviewer gives.\u2028\u2028\u00a0\n\n7. *Main Contribution*\u2028\u2028\u00a0\n\nUnfortunately, the reviewer still feels the paper hard to follow. Some major re-organization may help improve the clarification level.\u2028\u2028 The proof of Theorem 1 may be enhanced to justify the reformulation.\n\n\u00a08. *Unclear why the reformulation in (3) is a good approximation for CCA.*\u2028\u2028\u00a0\n\nThe reviewer has checked the proof of Theorem 1. Two major concerns. First, again, this proof is only for sub-Gaussian data, but CCA is a generic tool that can be applied as a deterministic method. Second, C(\\tilde{X}_k) \\rightarrow I_k is unjustified. Can it be I_k? how far is it from I_k? Assuming it approaches I_k is not \u201cconsistency proof\u201d. \u2028\u2028\u00a0\n\n9. *\u201cSO(n)\u201d: what is \u00a0\u201cspecial\u201d here?*\u2028\u2028\u00a0\n\nSee the reviewer\u2019s comment under Q2\u2028\u2028\u00a0\n\n10. *Why is there a Q in the middle?*\u2028\u2028\u00a0\n\nThe above explanation makes sense. The Q matrix is automatically full rank. The unclear part is how the upper triangular structure is preserved in the optimization? In addition, even if the upper triangular structure is preserved, S can still be rank deficient. So overall A=QS may still be rank deficient. How is this addressed? \u2028\u2028\u00a0\n\n11. *How high-level description connects CCA with PCA using this reformulation*\u2028\u2028\u00a0\n\nsee comments on Theorem 1\n"}, "signatures": ["ICLR.cc/2021/Conference/Paper131/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper131/AnonReviewer1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Stochastic Canonical Correlation Analysis: A Riemannian Approach", "authorids": ["~Zihang_Meng1", "~Rudrasis_Chakraborty1", "~Vikas_Singh1"], "authors": ["Zihang Meng", "Rudrasis Chakraborty", "Vikas Singh"], "keywords": ["CCA", "streaming", "differential geometry", "DeepCCA", "fairness"], "abstract": " We present an efficient stochastic algorithm (RSG+) for canonical correlation analysis (CCA) derived via a differential geometric perspective of the underlying optimization task. We show that exploiting the Riemannian structure of the problem reveals natural strategies for modified forms of manifold stochastic gradient descent schemes that have been variously used in the literature for numerical optimization on manifolds. Our developments complement existing methods for this problem which either require $O(d^3)$ time complexity per iteration with $O(\\frac{1}{\\sqrt{t}})$ convergence rate (where $d$ is the dimensionality) or only extract the top $1$ component with $O(\\frac{1}{t})$ convergence rate. In contrast, our algorithm achieves $O(d^2k)$ runtime complexity per iteration for extracting top $k$ canonical components with $O(\\frac{1}{t})$ convergence rate. We present our theoretical analysis as well as experiments describing the empirical behavior of our algorithm, including a potential application of this idea for training fair models where the label of protected attribute is missing or otherwise unavailable.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "meng|stochastic_canonical_correlation_analysis_a_riemannian_approach", "one-sentence_summary": "We present an efficient stochastic algorithm (RSG+) for canonical correlation analysis (CCA) derived via a differential geometric perspective of the underlying optimization task.", "pdf": "/pdf/46a100d101a05682223099f9d44b113c0cb49950.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=Hss_j4P5GW", "_bibtex": "@misc{\nmeng2021stochastic,\ntitle={Stochastic Canonical Correlation Analysis: A Riemannian Approach},\nauthor={Zihang Meng and Rudrasis Chakraborty and Vikas Singh},\nyear={2021},\nurl={https://openreview.net/forum?id=pAq1h9sQhqd}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "pAq1h9sQhqd", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper131/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper131/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper131/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper131/Authors|ICLR.cc/2021/Conference/Paper131/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper131/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923874275, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper131/-/Official_Comment"}}}, {"id": "qyrddLnfRvx", "original": null, "number": 6, "cdate": 1605292666199, "ddate": null, "tcdate": 1605292666199, "tmdate": 1605292666199, "tddate": null, "forum": "pAq1h9sQhqd", "replyto": "wfYblg_7hRr", "invitation": "ICLR.cc/2021/Conference/Paper131/-/Official_Comment", "content": {"title": "Experimental clarification+addtional comparison", "comment": "1. Claim that their proposed method captures more correlation than MSG, two of the three datasets in which their method is superior (MNIST and CIFAR) are not realistic settings (i.e., correlation between left/right half of images).\n\nAns: We chose these datasets mainly because they are commonly used test-beds in other papers which study the CCA model (such as Ge et al. 2016 and Andrew et al. 2013). At a minimum,  they help in evaluating whether a model works satisfactorily in settings where one would certainly expect sufficient correlation. The use of CCA for the fairness experiment was designed to leverage the model\u2019s ability to work in a high dimensional setting, which will otherwise present a key bottleneck. Other use cases which could benefit from a CCA type objective during the training process, appear to be feasible.   \n\n2. Is it possible to make a (numerical) comparison with Yger+2012, which reformulates CCA as an optimization on the generalized Stiefel manifold?\n\nAns: We thank the reviewer for the suggestion. Yes, we will shortly update the paper with these experiments. \n"}, "signatures": ["ICLR.cc/2021/Conference/Paper131/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper131/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Stochastic Canonical Correlation Analysis: A Riemannian Approach", "authorids": ["~Zihang_Meng1", "~Rudrasis_Chakraborty1", "~Vikas_Singh1"], "authors": ["Zihang Meng", "Rudrasis Chakraborty", "Vikas Singh"], "keywords": ["CCA", "streaming", "differential geometry", "DeepCCA", "fairness"], "abstract": " We present an efficient stochastic algorithm (RSG+) for canonical correlation analysis (CCA) derived via a differential geometric perspective of the underlying optimization task. We show that exploiting the Riemannian structure of the problem reveals natural strategies for modified forms of manifold stochastic gradient descent schemes that have been variously used in the literature for numerical optimization on manifolds. Our developments complement existing methods for this problem which either require $O(d^3)$ time complexity per iteration with $O(\\frac{1}{\\sqrt{t}})$ convergence rate (where $d$ is the dimensionality) or only extract the top $1$ component with $O(\\frac{1}{t})$ convergence rate. In contrast, our algorithm achieves $O(d^2k)$ runtime complexity per iteration for extracting top $k$ canonical components with $O(\\frac{1}{t})$ convergence rate. We present our theoretical analysis as well as experiments describing the empirical behavior of our algorithm, including a potential application of this idea for training fair models where the label of protected attribute is missing or otherwise unavailable.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "meng|stochastic_canonical_correlation_analysis_a_riemannian_approach", "one-sentence_summary": "We present an efficient stochastic algorithm (RSG+) for canonical correlation analysis (CCA) derived via a differential geometric perspective of the underlying optimization task.", "pdf": "/pdf/46a100d101a05682223099f9d44b113c0cb49950.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=Hss_j4P5GW", "_bibtex": "@misc{\nmeng2021stochastic,\ntitle={Stochastic Canonical Correlation Analysis: A Riemannian Approach},\nauthor={Zihang Meng and Rudrasis Chakraborty and Vikas Singh},\nyear={2021},\nurl={https://openreview.net/forum?id=pAq1h9sQhqd}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "pAq1h9sQhqd", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper131/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper131/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper131/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper131/Authors|ICLR.cc/2021/Conference/Paper131/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper131/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923874275, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper131/-/Official_Comment"}}}, {"id": "igA9vszSRsJ", "original": null, "number": 5, "cdate": 1605288883381, "ddate": null, "tcdate": 1605288883381, "tmdate": 1605288883381, "tddate": null, "forum": "pAq1h9sQhqd", "replyto": "01DOtEv948y", "invitation": "ICLR.cc/2021/Conference/Paper131/-/Official_Comment", "content": {"title": "Paper will be updated shortly", "comment": "Dear Reviewer 1, \n\nIf these clarifications are useful, please let us know and we will update the paper. We also appreciate any other suggestions. \n\nThanks again for your time. "}, "signatures": ["ICLR.cc/2021/Conference/Paper131/Authors"], "readers": ["everyone", "ICLR.cc/2021/Conference/Paper131/Reviewers"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper131/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Stochastic Canonical Correlation Analysis: A Riemannian Approach", "authorids": ["~Zihang_Meng1", "~Rudrasis_Chakraborty1", "~Vikas_Singh1"], "authors": ["Zihang Meng", "Rudrasis Chakraborty", "Vikas Singh"], "keywords": ["CCA", "streaming", "differential geometry", "DeepCCA", "fairness"], "abstract": " We present an efficient stochastic algorithm (RSG+) for canonical correlation analysis (CCA) derived via a differential geometric perspective of the underlying optimization task. We show that exploiting the Riemannian structure of the problem reveals natural strategies for modified forms of manifold stochastic gradient descent schemes that have been variously used in the literature for numerical optimization on manifolds. Our developments complement existing methods for this problem which either require $O(d^3)$ time complexity per iteration with $O(\\frac{1}{\\sqrt{t}})$ convergence rate (where $d$ is the dimensionality) or only extract the top $1$ component with $O(\\frac{1}{t})$ convergence rate. In contrast, our algorithm achieves $O(d^2k)$ runtime complexity per iteration for extracting top $k$ canonical components with $O(\\frac{1}{t})$ convergence rate. We present our theoretical analysis as well as experiments describing the empirical behavior of our algorithm, including a potential application of this idea for training fair models where the label of protected attribute is missing or otherwise unavailable.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "meng|stochastic_canonical_correlation_analysis_a_riemannian_approach", "one-sentence_summary": "We present an efficient stochastic algorithm (RSG+) for canonical correlation analysis (CCA) derived via a differential geometric perspective of the underlying optimization task.", "pdf": "/pdf/46a100d101a05682223099f9d44b113c0cb49950.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=Hss_j4P5GW", "_bibtex": "@misc{\nmeng2021stochastic,\ntitle={Stochastic Canonical Correlation Analysis: A Riemannian Approach},\nauthor={Zihang Meng and Rudrasis Chakraborty and Vikas Singh},\nyear={2021},\nurl={https://openreview.net/forum?id=pAq1h9sQhqd}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "pAq1h9sQhqd", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper131/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper131/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper131/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper131/Authors|ICLR.cc/2021/Conference/Paper131/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper131/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923874275, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper131/-/Official_Comment"}}}, {"id": "01DOtEv948y", "original": null, "number": 4, "cdate": 1605288510546, "ddate": null, "tcdate": 1605288510546, "tmdate": 1605288510546, "tddate": null, "forum": "pAq1h9sQhqd", "replyto": "yMX_CbHRtO7", "invitation": "ICLR.cc/2021/Conference/Paper131/-/Official_Comment", "content": {"title": "Clarifications for Reviewer 1", "comment": "  1. *Paper is packed*\n\n  We hope that the reviewer agrees that most papers that draw upon a few different areas to derive the algorithm or to analyze its properties may appear to be packed. Indeed, some of the concepts can only be reviewed briefly given the page limits. This is not necessarily due to sloppy presentation. \n\n  2. *Improve readability: contributions, formulations, etc*\n\n  We request the reviewer to briefly look at page 3 again, if possible. Putting the analysis components aside temporarily, we are happy to clarify anything specific on page 3 regarding the contribution/formulation that is unclear. \n\n  Page 3 describes what the overall model is (shown in 2), what a minor adjustment to it yields (in 3a--3b) and also provides an intuition about why this may potentially help. The subsequent sections actualize this intuition and show that this is reasonable by describing the analysis and the mechanics of the numerical scheme.\n\n  3. *Equivalence of (1) and (3) was not clearly shown.*\n\n  We should note that (1) and (2) are both standard for CCA. So we can focus on (3). The reviewer can check that the adjustment from (2) -- (3) is actually minor: everything from (2) stays the same in (3) except that we further tease out the structure in $U$ as $U = \\tilde{U}A$ where $A = QS$, similarly for $V$. Q10 below will help easily clarify this doubt completely.\n\n  4. *Theorems presented in a bit abrupt way.*\n\n  We will much appreciate any guidance on a segue to Theorem 1 that will help address this concern. \n\n  5. *Even the algorithm does not appear in the main text.*\n\n  Alg. 1 in the main paper is indeed the full pseudocode. The appendix simply writes out the low-level details of the gradient calculations, needed only if someone wants to cross-reference with our code. We thought that an explicit description of these calculations (tedious but not difficult) will only add marginal value and impact readability. \n\n  6. *Color code is confusing.*\n\n  The colors were used to easily reference the description in Section 2.2 with the algorithm blocks in Algorithm 1. We are happy to modify it.\n\n  7. *Main Contribution*\n\n  We hope that the clarifications here and the other reviews will help resolve this concern fully. \n\n  8. *Unclear why the reformulation in (3) is a good approximation for CCA.*\n\n  We can clarify this doubt in two parts. \n  First notice that (3) rewrites the standard CCA in (2) using the additional structure on U and V (see Q10 below). Now, the second part deals with whether this is a sensible approximation. This is where we can check Theorem 1: we show that under some assumptions, solution of (3) is a consistent estimator of the CC directions. For the non-Gaussian distribution, one can resort to a case by case analysis but will involve additional assumptions as well as  adjustments to the algorithm making a concise presentation of the ideas difficult.\n\n  9. *\u201cSO(n)\u201d: what is  \u201cspecial\u201d here?*\n\n  $SO(n)$ is the group of $n\\times n$ orthogonal matrices with determinant 1. Referring to it as the special orthogonal group is common practice (https://mathworld.wolfram.com/SpecialOrthogonalGroup.html).  \n\n  10. *Why is there a Q in the middle?*\n\n  Here $\\tilde{U}$ is the matrix of principal vectors and $U$ is the canonical  directions (similarly for $V$). \n  A key observation is that $U$ lies in the column span of $\\tilde{U}$, i.e., $U = \\tilde{U}A$ where we have a full rank matrix $A$. But optimization on the space of full rank matrices is more challenging since we need to satisfy the rank constraint. So, we may decompose $A=QS$ where $Q$ is orthogonal and $S$ is an upper triangular matrix. Substituting $QS$ by $A$, we get $U = \\tilde{U} QS$. We hope this addresses the doubt regarding (3a)-(3b). \n\n  This adjustment makes the optimization convenient. Constraints for orthogonal and upper triangular matrices can be implicitly preserved throughout the Riemannian gradient descent optimization without any explicit regularization.\n\n  11. *How high-level description connects CCA with PCA using this reformulation*\n\n  The key premise (see Reviews 2, 4) is that by treating the PCA and maximizing canonical correlation objective separately, we can achieve potential benefits. The PCA part enforces the whitening constraint. The CC directions lie in the principal subspaces, hence with an efficient scheme to compute principal directions we need to find the appropriate coefficients, which is enabled by (3).\n\n  12. *Hard to see how the complexity of algorithm is calculated.*\n\n  Our algorithm involves structured matrices of size $d\\times k$ and $k\\times k$, so any matrix operation should not exceed a cost of $O(\\max(d^2k, k^3))$, since in general $d \\gg k$, which directly gives $O(d^2k)$. Specifically, as mentioned in the paper, the most expensive calculation is SVD of matrices of size $d\\times k$, which is $O(d^2k)$ (Cline and Dhilon, Handbook of Linear Algebra, 2006). All other calculations are dominated by this term."}, "signatures": ["ICLR.cc/2021/Conference/Paper131/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper131/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Stochastic Canonical Correlation Analysis: A Riemannian Approach", "authorids": ["~Zihang_Meng1", "~Rudrasis_Chakraborty1", "~Vikas_Singh1"], "authors": ["Zihang Meng", "Rudrasis Chakraborty", "Vikas Singh"], "keywords": ["CCA", "streaming", "differential geometry", "DeepCCA", "fairness"], "abstract": " We present an efficient stochastic algorithm (RSG+) for canonical correlation analysis (CCA) derived via a differential geometric perspective of the underlying optimization task. We show that exploiting the Riemannian structure of the problem reveals natural strategies for modified forms of manifold stochastic gradient descent schemes that have been variously used in the literature for numerical optimization on manifolds. Our developments complement existing methods for this problem which either require $O(d^3)$ time complexity per iteration with $O(\\frac{1}{\\sqrt{t}})$ convergence rate (where $d$ is the dimensionality) or only extract the top $1$ component with $O(\\frac{1}{t})$ convergence rate. In contrast, our algorithm achieves $O(d^2k)$ runtime complexity per iteration for extracting top $k$ canonical components with $O(\\frac{1}{t})$ convergence rate. We present our theoretical analysis as well as experiments describing the empirical behavior of our algorithm, including a potential application of this idea for training fair models where the label of protected attribute is missing or otherwise unavailable.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "meng|stochastic_canonical_correlation_analysis_a_riemannian_approach", "one-sentence_summary": "We present an efficient stochastic algorithm (RSG+) for canonical correlation analysis (CCA) derived via a differential geometric perspective of the underlying optimization task.", "pdf": "/pdf/46a100d101a05682223099f9d44b113c0cb49950.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=Hss_j4P5GW", "_bibtex": "@misc{\nmeng2021stochastic,\ntitle={Stochastic Canonical Correlation Analysis: A Riemannian Approach},\nauthor={Zihang Meng and Rudrasis Chakraborty and Vikas Singh},\nyear={2021},\nurl={https://openreview.net/forum?id=pAq1h9sQhqd}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "pAq1h9sQhqd", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper131/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper131/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper131/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper131/Authors|ICLR.cc/2021/Conference/Paper131/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper131/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923874275, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper131/-/Official_Comment"}}}, {"id": "0zW7Tn_sbP", "original": null, "number": 2, "cdate": 1605158411050, "ddate": null, "tcdate": 1605158411050, "tmdate": 1605285854420, "tddate": null, "forum": "pAq1h9sQhqd", "replyto": "D_YudmtLrJr", "invitation": "ICLR.cc/2021/Conference/Paper131/-/Official_Comment", "content": {"title": "Gaussian assumption", "comment": "We thank the reviewer for the review and appreciating our work. We clarify the main questions below, \n\nQ: The theoretical results are obtained under a strong assumption that X and Y both have Gaussian distribution.\n\nAns: \nWe answer in two parts, \n(1) Our setting closely followed the formulation described in a well known result on probabilistic CCA (A probabilistic interpretation of canonical correlation analysis,(Bach and Jordan, 2005 Tech report). Our convergence theorem (Theorem 1) holds under identical assumptions on $X$ and $Y$ as described in probabilistic CCA. The reviewer will likely agree that this assumption is common, even in the batch setting of CCA, to derive convergence or consistency guarantees in the finite sample regime. If we inspect the analysis described in Appendix A.2 that accompanies the result in Prop 2, we see that the steps will carry through as long as $\\Delta$ is bounded. On a case by case basis, depending on the distributional assumption, some other assumptions will need to be imposed to ensure that this condition holds so that the analysis leads to the desired guarantees. \n\n(2) The key computational advantages that the algorithm offers, as noted by the reviewer, emerge from breaking down the CCA objective into PCA (which satisfies the whitening constraint) and the module which maximizes correlation. This modification leads to the computational complexity benefits. On the other hand, the consistency of our estimator to compute canonical directions requires consistency of the PC estimator as well. It is for this reason that the Gaussian assumption seemed sensible.\n\n\nQ: Most propositions are from other papers.\n\nAns: The main theorem (Theorem 1) is original to this paper while we do utilize or restate results from other articles, as needed, at various places in the analysis. \n"}, "signatures": ["ICLR.cc/2021/Conference/Paper131/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper131/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Stochastic Canonical Correlation Analysis: A Riemannian Approach", "authorids": ["~Zihang_Meng1", "~Rudrasis_Chakraborty1", "~Vikas_Singh1"], "authors": ["Zihang Meng", "Rudrasis Chakraborty", "Vikas Singh"], "keywords": ["CCA", "streaming", "differential geometry", "DeepCCA", "fairness"], "abstract": " We present an efficient stochastic algorithm (RSG+) for canonical correlation analysis (CCA) derived via a differential geometric perspective of the underlying optimization task. We show that exploiting the Riemannian structure of the problem reveals natural strategies for modified forms of manifold stochastic gradient descent schemes that have been variously used in the literature for numerical optimization on manifolds. Our developments complement existing methods for this problem which either require $O(d^3)$ time complexity per iteration with $O(\\frac{1}{\\sqrt{t}})$ convergence rate (where $d$ is the dimensionality) or only extract the top $1$ component with $O(\\frac{1}{t})$ convergence rate. In contrast, our algorithm achieves $O(d^2k)$ runtime complexity per iteration for extracting top $k$ canonical components with $O(\\frac{1}{t})$ convergence rate. We present our theoretical analysis as well as experiments describing the empirical behavior of our algorithm, including a potential application of this idea for training fair models where the label of protected attribute is missing or otherwise unavailable.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "meng|stochastic_canonical_correlation_analysis_a_riemannian_approach", "one-sentence_summary": "We present an efficient stochastic algorithm (RSG+) for canonical correlation analysis (CCA) derived via a differential geometric perspective of the underlying optimization task.", "pdf": "/pdf/46a100d101a05682223099f9d44b113c0cb49950.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=Hss_j4P5GW", "_bibtex": "@misc{\nmeng2021stochastic,\ntitle={Stochastic Canonical Correlation Analysis: A Riemannian Approach},\nauthor={Zihang Meng and Rudrasis Chakraborty and Vikas Singh},\nyear={2021},\nurl={https://openreview.net/forum?id=pAq1h9sQhqd}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "pAq1h9sQhqd", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper131/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper131/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper131/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper131/Authors|ICLR.cc/2021/Conference/Paper131/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper131/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923874275, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper131/-/Official_Comment"}}}, {"id": "p3VPG-r0j1B", "original": null, "number": 3, "cdate": 1605158596255, "ddate": null, "tcdate": 1605158596255, "tmdate": 1605158596255, "tddate": null, "forum": "pAq1h9sQhqd", "replyto": "bUrYiJNWEff", "invitation": "ICLR.cc/2021/Conference/Paper131/-/Official_Comment", "content": {"title": "Appreciate for the positive comments", "comment": "We thank the reviewer for appreciating our work. We are happy to answer any additional questions or address any outstanding concerns. Yes, we included (Andrew, 2013) in our deepCCA experiments shown in Table 1."}, "signatures": ["ICLR.cc/2021/Conference/Paper131/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper131/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Stochastic Canonical Correlation Analysis: A Riemannian Approach", "authorids": ["~Zihang_Meng1", "~Rudrasis_Chakraborty1", "~Vikas_Singh1"], "authors": ["Zihang Meng", "Rudrasis Chakraborty", "Vikas Singh"], "keywords": ["CCA", "streaming", "differential geometry", "DeepCCA", "fairness"], "abstract": " We present an efficient stochastic algorithm (RSG+) for canonical correlation analysis (CCA) derived via a differential geometric perspective of the underlying optimization task. We show that exploiting the Riemannian structure of the problem reveals natural strategies for modified forms of manifold stochastic gradient descent schemes that have been variously used in the literature for numerical optimization on manifolds. Our developments complement existing methods for this problem which either require $O(d^3)$ time complexity per iteration with $O(\\frac{1}{\\sqrt{t}})$ convergence rate (where $d$ is the dimensionality) or only extract the top $1$ component with $O(\\frac{1}{t})$ convergence rate. In contrast, our algorithm achieves $O(d^2k)$ runtime complexity per iteration for extracting top $k$ canonical components with $O(\\frac{1}{t})$ convergence rate. We present our theoretical analysis as well as experiments describing the empirical behavior of our algorithm, including a potential application of this idea for training fair models where the label of protected attribute is missing or otherwise unavailable.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "meng|stochastic_canonical_correlation_analysis_a_riemannian_approach", "one-sentence_summary": "We present an efficient stochastic algorithm (RSG+) for canonical correlation analysis (CCA) derived via a differential geometric perspective of the underlying optimization task.", "pdf": "/pdf/46a100d101a05682223099f9d44b113c0cb49950.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=Hss_j4P5GW", "_bibtex": "@misc{\nmeng2021stochastic,\ntitle={Stochastic Canonical Correlation Analysis: A Riemannian Approach},\nauthor={Zihang Meng and Rudrasis Chakraborty and Vikas Singh},\nyear={2021},\nurl={https://openreview.net/forum?id=pAq1h9sQhqd}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "pAq1h9sQhqd", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper131/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper131/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper131/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper131/Authors|ICLR.cc/2021/Conference/Paper131/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper131/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923874275, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper131/-/Official_Comment"}}}, {"id": "bUrYiJNWEff", "original": null, "number": 1, "cdate": 1603720459584, "ddate": null, "tcdate": 1603720459584, "tmdate": 1605024757061, "tddate": null, "forum": "pAq1h9sQhqd", "replyto": "pAq1h9sQhqd", "invitation": "ICLR.cc/2021/Conference/Paper131/-/Official_Review", "content": {"title": "A successful approach to streaming CCA", "review": "The paper presents an approach to find canonical directions in a streaming fashion, i.e. without direct calculation of covariance matrices (which becomes hard when the number of examples is large). This solution to that task is not obvious, because the objective function of CCA, together with whitening constraints, does not allow simple additive decomposition.\n\nFirst, the optimization task is reformulated as a task over certain Riemannian manifolds, and a natural initialization is suggested. It is shown that under a certain assumption, this initialization is already a solution of good quality. Then, a natural minimization algorithm is presented, which is based on stochastic gradient descent on a Riemannian manifold. The key aspect of the algorithm is a combination of 2 types of gradient, the gradient for top-k principal vectors and standard gradient.\n\nThe experimental part shows that the algorithm successfully solves CCA in a streaming fashion. Also, it can be effectively combined with deep feature learning (Andrew, 2013) to find common features for multi-view representation learning tasks. Experiments look convincing.", "rating": "7: Good paper, accept", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "signatures": ["ICLR.cc/2021/Conference/Paper131/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper131/AnonReviewer2"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Stochastic Canonical Correlation Analysis: A Riemannian Approach", "authorids": ["~Zihang_Meng1", "~Rudrasis_Chakraborty1", "~Vikas_Singh1"], "authors": ["Zihang Meng", "Rudrasis Chakraborty", "Vikas Singh"], "keywords": ["CCA", "streaming", "differential geometry", "DeepCCA", "fairness"], "abstract": " We present an efficient stochastic algorithm (RSG+) for canonical correlation analysis (CCA) derived via a differential geometric perspective of the underlying optimization task. We show that exploiting the Riemannian structure of the problem reveals natural strategies for modified forms of manifold stochastic gradient descent schemes that have been variously used in the literature for numerical optimization on manifolds. Our developments complement existing methods for this problem which either require $O(d^3)$ time complexity per iteration with $O(\\frac{1}{\\sqrt{t}})$ convergence rate (where $d$ is the dimensionality) or only extract the top $1$ component with $O(\\frac{1}{t})$ convergence rate. In contrast, our algorithm achieves $O(d^2k)$ runtime complexity per iteration for extracting top $k$ canonical components with $O(\\frac{1}{t})$ convergence rate. We present our theoretical analysis as well as experiments describing the empirical behavior of our algorithm, including a potential application of this idea for training fair models where the label of protected attribute is missing or otherwise unavailable.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "meng|stochastic_canonical_correlation_analysis_a_riemannian_approach", "one-sentence_summary": "We present an efficient stochastic algorithm (RSG+) for canonical correlation analysis (CCA) derived via a differential geometric perspective of the underlying optimization task.", "pdf": "/pdf/46a100d101a05682223099f9d44b113c0cb49950.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=Hss_j4P5GW", "_bibtex": "@misc{\nmeng2021stochastic,\ntitle={Stochastic Canonical Correlation Analysis: A Riemannian Approach},\nauthor={Zihang Meng and Rudrasis Chakraborty and Vikas Singh},\nyear={2021},\nurl={https://openreview.net/forum?id=pAq1h9sQhqd}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq . ***Please remember to file the Code-of-Ethics report. Once you submitted the review, a link to the report will be visible in the bottom right corner of your review.***", "required": true, "markdown": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}, "forum": "pAq1h9sQhqd", "replyto": "pAq1h9sQhqd", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"], "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper131/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1607428800000, "duedate": 1606752000000, "multiReply": false, "readers": ["everyone"], "tcdate": 1602538149720, "tmdate": 1606915801325, "super": "ICLR.cc/2021/Conference/-/Official_Review", "signatures": ["OpenReview.net"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Paper131/Reviewers", "OpenReview.net/Support"], "id": "ICLR.cc/2021/Conference/Paper131/-/Official_Review"}}}, {"id": "wfYblg_7hRr", "original": null, "number": 2, "cdate": 1603862790498, "ddate": null, "tcdate": 1603862790498, "tmdate": 1605024756996, "tddate": null, "forum": "pAq1h9sQhqd", "replyto": "pAq1h9sQhqd", "invitation": "ICLR.cc/2021/Conference/Paper131/-/Official_Review", "content": {"title": "Official Blind Review #3", "review": "This paper aims to reduce the computational complexity of canonical correlation analysis.By decomposing the CCA projection matrices into a product of several structured matrices, a stochastic gradient-based optimization on a Riemannian manifold is provided reducing the computational complexity from $d^3$ to $d^2k$.\n\n\nStrength:\nCCA is a classic and still important method, especially in combination with deep neural networks (e.g., multi-view learnings). \nThe proposed method enables the applications of CCA to high-dimensional vectors with small memory.\nThis makes it easier to use CCA as an objective function of deep neural networks, which is trained on GPUs.\nExperiments show the benefits of their proposed method, in particular, the computational speed is 5-10 times faster than the existing method (MSG).\n\nWeakness:\nAlthough the authors claim that their proposed method captures more correlation than MSG, two of the three datasets in which their method is superior (MNIST and CIFAR) are not realistic setting (i.e., correlation between left/right half of images).\n\nQuestion:\nIs it possible to make a (numerical) comparison with Yger+2012, which reformulates CCA as an optimization on the generalized Stiefel manifold?", "rating": "6: Marginally above acceptance threshold", "confidence": "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper"}, "signatures": ["ICLR.cc/2021/Conference/Paper131/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper131/AnonReviewer3"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Stochastic Canonical Correlation Analysis: A Riemannian Approach", "authorids": ["~Zihang_Meng1", "~Rudrasis_Chakraborty1", "~Vikas_Singh1"], "authors": ["Zihang Meng", "Rudrasis Chakraborty", "Vikas Singh"], "keywords": ["CCA", "streaming", "differential geometry", "DeepCCA", "fairness"], "abstract": " We present an efficient stochastic algorithm (RSG+) for canonical correlation analysis (CCA) derived via a differential geometric perspective of the underlying optimization task. We show that exploiting the Riemannian structure of the problem reveals natural strategies for modified forms of manifold stochastic gradient descent schemes that have been variously used in the literature for numerical optimization on manifolds. Our developments complement existing methods for this problem which either require $O(d^3)$ time complexity per iteration with $O(\\frac{1}{\\sqrt{t}})$ convergence rate (where $d$ is the dimensionality) or only extract the top $1$ component with $O(\\frac{1}{t})$ convergence rate. In contrast, our algorithm achieves $O(d^2k)$ runtime complexity per iteration for extracting top $k$ canonical components with $O(\\frac{1}{t})$ convergence rate. We present our theoretical analysis as well as experiments describing the empirical behavior of our algorithm, including a potential application of this idea for training fair models where the label of protected attribute is missing or otherwise unavailable.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "meng|stochastic_canonical_correlation_analysis_a_riemannian_approach", "one-sentence_summary": "We present an efficient stochastic algorithm (RSG+) for canonical correlation analysis (CCA) derived via a differential geometric perspective of the underlying optimization task.", "pdf": "/pdf/46a100d101a05682223099f9d44b113c0cb49950.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=Hss_j4P5GW", "_bibtex": "@misc{\nmeng2021stochastic,\ntitle={Stochastic Canonical Correlation Analysis: A Riemannian Approach},\nauthor={Zihang Meng and Rudrasis Chakraborty and Vikas Singh},\nyear={2021},\nurl={https://openreview.net/forum?id=pAq1h9sQhqd}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq . ***Please remember to file the Code-of-Ethics report. Once you submitted the review, a link to the report will be visible in the bottom right corner of your review.***", "required": true, "markdown": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}, "forum": "pAq1h9sQhqd", "replyto": "pAq1h9sQhqd", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"], "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper131/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1607428800000, "duedate": 1606752000000, "multiReply": false, "readers": ["everyone"], "tcdate": 1602538149720, "tmdate": 1606915801325, "super": "ICLR.cc/2021/Conference/-/Official_Review", "signatures": ["OpenReview.net"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Paper131/Reviewers", "OpenReview.net/Support"], "id": "ICLR.cc/2021/Conference/Paper131/-/Official_Review"}}}, {"id": "yMX_CbHRtO7", "original": null, "number": 3, "cdate": 1603925939514, "ddate": null, "tcdate": 1603925939514, "tmdate": 1605024756935, "tddate": null, "forum": "pAq1h9sQhqd", "replyto": "pAq1h9sQhqd", "invitation": "ICLR.cc/2021/Conference/Paper131/-/Official_Review", "content": {"title": "The major concern is clarity", "review": "main contribution\n\nThis work offers a stochastic CCA algorithm based on Riemannian optimization approach\n\nStrength\n\n- The paper offers a theory-backed algorithm for CCA under the assumption that the two views are sub-Gaussian. The complexity-accuracy tradeoff of the algorithm seems to be appealing according to the experiments.\n\nWeakness\n\nOverall, the biggest concern is readability. The paper is very packed and many treatments seem to be unbalanced. Important details are missing, and proofs seem to be hastily. The paper may need some re-packaging and re-organization before its core technical contents could be easily followed.\n\n- readability. The biggest concern of the work is that it is very hard to read. This creates a lot of barriers in understanding key aspects of the paper, e.g., contributions, formulations, novelty of the proof, just to name a few. The key formulation and the definitions of the manifolds were not clearly defined. The equivalence of (1) and (3) was not clearly shown. The theorems were presented in a bit abrupt way. Even the algorithm does not appear in the maintext but the appendix (which is also hard to read). The color code is used in a way that is a bit confusing (does ICLR allow writing in different colors?).\n\n- Clarify about the contribution. It is hard to clearly see how much is the contribution. The proofs seem to be short and most of the proofs are presented using \u201cpropositions\u201d cited from existing papers. If the authors think the contributions lie in reformulating the CCA problem as a PCA problem, then the reformulating part is perhaps the contribution. But from the current writing it is hard to follow how the reformulation comes through and how the reformulation enables using these existing propositions to prove convergence of the proposed algorithm.\n\n- It is unclear why the reformulation in (3) is a good approximation for CCA. Some attempts for justifying this were offered in Theorem 1, but it was based on the assumption X and Y are sub-Gaussian, which is at best a special case, even if the proof is correct (which, due to the current organization of the paper, is hard to read and fully understand).\n\n- \u201cSO(n): group/manifold of nxn special orthogonal matrices.\u201d what is the definition of \u201cspecial\u201d here? are they the commonly understood orthogonal matrices?\n\n- The paper has this upper triangular structure of the S matrices but this point seems to have no detailed explanation. If one understands U = \\tilde{U}S as the QR decomposition, then indeed S is upper triangular, but why is there a Q in the middle? Why is this Q useful?\n\n- the \u201chigh-level\u201d description of the algorithm says the idea is to connect CCA with PCA using this reformulation, but this point was not clearly explained.\n\n- Complexity. From the current writing, it is very hard to see how the complexity of the algorithm is calculated. The gradients needed are tabulated in the supplementary materials, but it is very hard for a reader to directly see why the algorithm saves computational complexity.\n\n- It is also unclear how the convergence and convergence rate analyses come together. These parts may need to be elaborated.\n", "rating": "4: Ok but not good enough - rejection", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["ICLR.cc/2021/Conference/Paper131/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper131/AnonReviewer1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Stochastic Canonical Correlation Analysis: A Riemannian Approach", "authorids": ["~Zihang_Meng1", "~Rudrasis_Chakraborty1", "~Vikas_Singh1"], "authors": ["Zihang Meng", "Rudrasis Chakraborty", "Vikas Singh"], "keywords": ["CCA", "streaming", "differential geometry", "DeepCCA", "fairness"], "abstract": " We present an efficient stochastic algorithm (RSG+) for canonical correlation analysis (CCA) derived via a differential geometric perspective of the underlying optimization task. We show that exploiting the Riemannian structure of the problem reveals natural strategies for modified forms of manifold stochastic gradient descent schemes that have been variously used in the literature for numerical optimization on manifolds. Our developments complement existing methods for this problem which either require $O(d^3)$ time complexity per iteration with $O(\\frac{1}{\\sqrt{t}})$ convergence rate (where $d$ is the dimensionality) or only extract the top $1$ component with $O(\\frac{1}{t})$ convergence rate. In contrast, our algorithm achieves $O(d^2k)$ runtime complexity per iteration for extracting top $k$ canonical components with $O(\\frac{1}{t})$ convergence rate. We present our theoretical analysis as well as experiments describing the empirical behavior of our algorithm, including a potential application of this idea for training fair models where the label of protected attribute is missing or otherwise unavailable.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "meng|stochastic_canonical_correlation_analysis_a_riemannian_approach", "one-sentence_summary": "We present an efficient stochastic algorithm (RSG+) for canonical correlation analysis (CCA) derived via a differential geometric perspective of the underlying optimization task.", "pdf": "/pdf/46a100d101a05682223099f9d44b113c0cb49950.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=Hss_j4P5GW", "_bibtex": "@misc{\nmeng2021stochastic,\ntitle={Stochastic Canonical Correlation Analysis: A Riemannian Approach},\nauthor={Zihang Meng and Rudrasis Chakraborty and Vikas Singh},\nyear={2021},\nurl={https://openreview.net/forum?id=pAq1h9sQhqd}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq . ***Please remember to file the Code-of-Ethics report. Once you submitted the review, a link to the report will be visible in the bottom right corner of your review.***", "required": true, "markdown": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}, "forum": "pAq1h9sQhqd", "replyto": "pAq1h9sQhqd", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"], "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper131/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1607428800000, "duedate": 1606752000000, "multiReply": false, "readers": ["everyone"], "tcdate": 1602538149720, "tmdate": 1606915801325, "super": "ICLR.cc/2021/Conference/-/Official_Review", "signatures": ["OpenReview.net"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Paper131/Reviewers", "OpenReview.net/Support"], "id": "ICLR.cc/2021/Conference/Paper131/-/Official_Review"}}}, {"id": "D_YudmtLrJr", "original": null, "number": 4, "cdate": 1604274189480, "ddate": null, "tcdate": 1604274189480, "tmdate": 1605024756875, "tddate": null, "forum": "pAq1h9sQhqd", "replyto": "pAq1h9sQhqd", "invitation": "ICLR.cc/2021/Conference/Paper131/-/Official_Review", "content": {"title": "A stochastic linear CCA method for high dimensional data", "review": "1. Paper summary:\n\nThis paper proposes a method for solving linear CCA on high dimensional data. Linear CCA has a closed form solution. The solution requires a whitening step that costs O(d^3). This makes it not applicable to data in high dimensional spaces, e.g. representations learnt by deep networks. \n\nTo resolve the issue, the authors propose a reformulation of linear CCA which decomposes the transformation matrix U (V) into a product of three matrices. Those three matrices have the following properties:\n\n- Their initial values can be obtained by efficient streaming PCA on original view matrix X (Y). Streaming PCA costs O(d^2 * k) only where k is the top k eigenvectors.\n\n- They allow for Riemannian stochastic gradient descent which ensures their updated values lie on the same manifold.\n\n2. Strong points of the paper:\n\nThe new linear CCA formulation justifies the rationale of batch CCA training.\n\nUnder Gaussian distribution assumption:\n- The absolute difference between correlation found by original linear CCA and stochastic one is bounded.\n- The convergence of the training process is proven.\n\nThe experiments are performed on different aspects:\n- Recovering groundtruth transformations on MNIST, CIFAR and Mediamill data sets.\n- Learning deep features on MNIST data set.\n- Improving fairness in deep learning by adding CCA term to the loss function.\n\n3. Weak points of the paper:\n\nThe theoretical results are obtained under a strong assumption that X and Y both have Gaussian distribution.\n\nMost propositions are from other papers.", "rating": "6: Marginally above acceptance threshold", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["ICLR.cc/2021/Conference/Paper131/AnonReviewer4"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper131/AnonReviewer4"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Stochastic Canonical Correlation Analysis: A Riemannian Approach", "authorids": ["~Zihang_Meng1", "~Rudrasis_Chakraborty1", "~Vikas_Singh1"], "authors": ["Zihang Meng", "Rudrasis Chakraborty", "Vikas Singh"], "keywords": ["CCA", "streaming", "differential geometry", "DeepCCA", "fairness"], "abstract": " We present an efficient stochastic algorithm (RSG+) for canonical correlation analysis (CCA) derived via a differential geometric perspective of the underlying optimization task. We show that exploiting the Riemannian structure of the problem reveals natural strategies for modified forms of manifold stochastic gradient descent schemes that have been variously used in the literature for numerical optimization on manifolds. Our developments complement existing methods for this problem which either require $O(d^3)$ time complexity per iteration with $O(\\frac{1}{\\sqrt{t}})$ convergence rate (where $d$ is the dimensionality) or only extract the top $1$ component with $O(\\frac{1}{t})$ convergence rate. In contrast, our algorithm achieves $O(d^2k)$ runtime complexity per iteration for extracting top $k$ canonical components with $O(\\frac{1}{t})$ convergence rate. We present our theoretical analysis as well as experiments describing the empirical behavior of our algorithm, including a potential application of this idea for training fair models where the label of protected attribute is missing or otherwise unavailable.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "meng|stochastic_canonical_correlation_analysis_a_riemannian_approach", "one-sentence_summary": "We present an efficient stochastic algorithm (RSG+) for canonical correlation analysis (CCA) derived via a differential geometric perspective of the underlying optimization task.", "pdf": "/pdf/46a100d101a05682223099f9d44b113c0cb49950.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=Hss_j4P5GW", "_bibtex": "@misc{\nmeng2021stochastic,\ntitle={Stochastic Canonical Correlation Analysis: A Riemannian Approach},\nauthor={Zihang Meng and Rudrasis Chakraborty and Vikas Singh},\nyear={2021},\nurl={https://openreview.net/forum?id=pAq1h9sQhqd}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq . ***Please remember to file the Code-of-Ethics report. Once you submitted the review, a link to the report will be visible in the bottom right corner of your review.***", "required": true, "markdown": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}, "forum": "pAq1h9sQhqd", "replyto": "pAq1h9sQhqd", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"], "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper131/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1607428800000, "duedate": 1606752000000, "multiReply": false, "readers": ["everyone"], "tcdate": 1602538149720, "tmdate": 1606915801325, "super": "ICLR.cc/2021/Conference/-/Official_Review", "signatures": ["OpenReview.net"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Paper131/Reviewers", "OpenReview.net/Support"], "id": "ICLR.cc/2021/Conference/Paper131/-/Official_Review"}}}], "count": 16}