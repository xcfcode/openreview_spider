{"notes": [{"tddate": null, "ddate": null, "cdate": null, "tmdate": 1486396616140, "tcdate": 1486396616140, "number": 1, "id": "rJl0nfIde", "invitation": "ICLR.cc/2017/conference/-/paper493/acceptance", "forum": "BJFG8Yqxl", "replyto": "BJFG8Yqxl", "signatures": ["ICLR.cc/2017/pcs"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/pcs"], "content": {"decision": "Reject", "title": "ICLR committee final decision", "comment": "This paper proposes to use a group sparsity penalty to train an autoencoder on question answering. The idea to leverage hierarchies of categories in labels is an appealing one. However the paper has problems:\n - it is not clear. In particular, some of the equations do not make sense. This has been pointed by reviewers and not corrected.\n - the choice of the particular group sparsity penalty is not well justified or empirically validated with ablation experiments: experiments lack key comparisons and simply compare to unrelated baselines.\n In its current form, the paper cannot be recommended for acceptance."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"TL;DR": "", "title": "Group Sparse CNNs for Question Sentence Classification with Answer Sets", "abstract": "Classifying question sentences into their corresponding categories is an important task with wide applications, for example in many websites' FAQ sections. \nHowever, traditional question classification techniques do not fully utilize the well-prepared answer data which has great potential for improving question sentence representations which could lead to better classification performance. In order to encode answer information into question representation, we first introduce novel group sparse autoencoders which could utilize the group information in the answer set to refine question representation. We then propose a new group sparse convolutional neural network which could naturally learn the question representation with respect to their corresponding answers by implanting the group sparse autoencoders into the traditional convolutional neural network. The proposed model show significant improvements over strong baselines on four datasets.  ", "pdf": "/pdf/b2be6aeb38cfc5a9b7f5edb69bcb453b6ff4e0cc.pdf", "paperhash": "ma|group_sparse_cnns_for_question_sentence_classification_with_answer_sets", "keywords": [], "conflicts": ["oregonstate.edu", "us.ibm.com"], "authors": ["Mingbo Ma", "Liang Huang", "Bing Xiang", "Bowen Zhou"], "authorids": ["mam@oregonstate.edu", "liang.huang@oregonstate.edu", "bingxia@us.ibm.com", "zhou@us.ibm.com"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1486396617110, "id": "ICLR.cc/2017/conference/-/paper493/acceptance", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/pcs"], "noninvitees": ["ICLR.cc/2017/pcs"], "reply": {"forum": "BJFG8Yqxl", "replyto": "BJFG8Yqxl", "writers": {"values-regex": "ICLR.cc/2017/pcs"}, "signatures": {"values-regex": "ICLR.cc/2017/pcs", "description": "Your displayed identity associated with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your decision.", "value": "ICLR committee final decision"}, "comment": {"required": true, "order": 2, "description": "Decision comments.", "value-regex": "[\\S\\s]{1,5000}"}, "decision": {"required": true, "order": 3, "value-radio": ["Accept (Oral)", "Accept (Poster)", "Reject", "Invite to Workshop Track"]}}}, "nonreaders": [], "cdate": 1486396617110}}}, {"tddate": null, "tmdate": 1482599853467, "tcdate": 1482599853467, "number": 3, "id": "SkBh6XnEe", "invitation": "ICLR.cc/2017/conference/-/paper493/official/review", "forum": "BJFG8Yqxl", "replyto": "BJFG8Yqxl", "signatures": ["ICLR.cc/2017/conference/paper493/AnonReviewer2"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/conference/paper493/AnonReviewer2"], "content": {"title": "Clarity is low, experiments are not convincing.", "rating": "4: Ok but not good enough - rejection", "review": "The paper proposes the group sparse autoencoder that enforces sparsity of the hidden representation group-wise, where the group is formed based on labels (i.e., supervision). The p-th group hidden representation is used for reconstruction with group sparsity penalty, allowing learning more discriminative, class-specific patterns in the dataset. The paper also propose to combine both group-level and individual level sparsity as in Equation (9). \n\nClarity of the paper is a bit low. \n- Do you use only p-th group's activation for reconstruction? If it is true, then for Equation (9) do you use all individual hidden representation for reconstruction or still using the subset of representation corresponding to that class only? \n- In Equation (7), RHS misses the summation over p, and wondering it is a simple typo.\n- Is the algorithm end-to-end trainable? It seems to me that the group sparse CNN is no more than the GSA whose input data is the feature extracted from sequential CNNs (or any other pretrained CNNs).\n\nOther comments are as follows:\n- Furthermore the group sparse autoencoder is (semi-) supervised method since it uses label information to form a group, whereas the standard sparse autoencoder is fully unsupervised. That being said, it is not surprising that group sparse autoencoder learns more class-specific pattern whereas sparse autoencoder doesn't. I think the fair comparison should be to autoencoders that combines classification for their objective function.\n- Although authors claim that GSA learns more group-relevant features, Figure 3 (b) is not convincing enough to support this claim. For example, the first row contains many filters that doesn't look like 1 (e.g., very last column looks like 3).\n- Other than visual inspection, do you observe improvement in classification using proposed algorithm on MNIST experiments?\n- The comparison to the baseline model is missing. I believe the baseline model shouldn't be the sequential CNN, but the sequential CNN + sparse autoencoder. In addition, more control experiment is required that compares between the Equation (7)-(9), with different values of \\alpha and \\beta.\n\nMissing reference:\nShang et al., Discriminative Training of Structured Dictionaries via Block Orthogonal Matching Pursuit, SDM 2016 - they consider block orthgonal matching pursuit for dictionary learning whose blocks (i.e., projection matrices) are constructed based on the class labels for discirminative training.", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"TL;DR": "", "title": "Group Sparse CNNs for Question Sentence Classification with Answer Sets", "abstract": "Classifying question sentences into their corresponding categories is an important task with wide applications, for example in many websites' FAQ sections. \nHowever, traditional question classification techniques do not fully utilize the well-prepared answer data which has great potential for improving question sentence representations which could lead to better classification performance. In order to encode answer information into question representation, we first introduce novel group sparse autoencoders which could utilize the group information in the answer set to refine question representation. We then propose a new group sparse convolutional neural network which could naturally learn the question representation with respect to their corresponding answers by implanting the group sparse autoencoders into the traditional convolutional neural network. The proposed model show significant improvements over strong baselines on four datasets.  ", "pdf": "/pdf/b2be6aeb38cfc5a9b7f5edb69bcb453b6ff4e0cc.pdf", "paperhash": "ma|group_sparse_cnns_for_question_sentence_classification_with_answer_sets", "keywords": [], "conflicts": ["oregonstate.edu", "us.ibm.com"], "authors": ["Mingbo Ma", "Liang Huang", "Bing Xiang", "Bowen Zhou"], "authorids": ["mam@oregonstate.edu", "liang.huang@oregonstate.edu", "bingxia@us.ibm.com", "zhou@us.ibm.com"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1481932799000, "tmdate": 1482599854114, "id": "ICLR.cc/2017/conference/-/paper493/official/review", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/conference/paper493/reviewers"], "noninvitees": ["ICLR.cc/2017/conference/paper493/AnonReviewer1", "ICLR.cc/2017/conference/paper493/AnonReviewer3", "ICLR.cc/2017/conference/paper493/AnonReviewer2"], "reply": {"forum": "BJFG8Yqxl", "replyto": "BJFG8Yqxl", "writers": {"values-regex": "ICLR.cc/2017/conference/paper493/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/conference/paper493/AnonReviewer[0-9]+"}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "value-regex": "[\\S\\s]{1,20000}"}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1489708799000, "cdate": 1482599854114}}}, {"tddate": null, "tmdate": 1482087338289, "tcdate": 1482087338289, "number": 2, "id": "ByGhiIVVl", "invitation": "ICLR.cc/2017/conference/-/paper493/official/review", "forum": "BJFG8Yqxl", "replyto": "BJFG8Yqxl", "signatures": ["ICLR.cc/2017/conference/paper493/AnonReviewer3"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/conference/paper493/AnonReviewer3"], "content": {"title": "", "rating": "5: Marginally below acceptance threshold", "review": "This paper proposed the group sparse auto-encoder for feature extraction. The author then stack the group sparse auto-encoders on top of CNNs to extract better question sentence representation for QA tasks. \n\nPros: \n- group-sparse auto-encoder seems new to me.\n- extensive experiments on QA tasks. \n\nCons:\n- The idea is somewhat incremental.\n- Writing need to be improved. \n- Lack of ablation studies to show the effectiveness of the proposed approach. \n\nMoreover, I am not convinced by the author's answer regarding the baseline. A separate training stages of CNN+SGL for comparison is fine. The purpose is to validate and analyze why the proposed SGA is preferred rather than group lasso, e.g. joint training could improve, or the proposed group-sparse regularization outperforms l_21 norm, etc. However, we can't see it from the current experiments. ", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"TL;DR": "", "title": "Group Sparse CNNs for Question Sentence Classification with Answer Sets", "abstract": "Classifying question sentences into their corresponding categories is an important task with wide applications, for example in many websites' FAQ sections. \nHowever, traditional question classification techniques do not fully utilize the well-prepared answer data which has great potential for improving question sentence representations which could lead to better classification performance. In order to encode answer information into question representation, we first introduce novel group sparse autoencoders which could utilize the group information in the answer set to refine question representation. We then propose a new group sparse convolutional neural network which could naturally learn the question representation with respect to their corresponding answers by implanting the group sparse autoencoders into the traditional convolutional neural network. The proposed model show significant improvements over strong baselines on four datasets.  ", "pdf": "/pdf/b2be6aeb38cfc5a9b7f5edb69bcb453b6ff4e0cc.pdf", "paperhash": "ma|group_sparse_cnns_for_question_sentence_classification_with_answer_sets", "keywords": [], "conflicts": ["oregonstate.edu", "us.ibm.com"], "authors": ["Mingbo Ma", "Liang Huang", "Bing Xiang", "Bowen Zhou"], "authorids": ["mam@oregonstate.edu", "liang.huang@oregonstate.edu", "bingxia@us.ibm.com", "zhou@us.ibm.com"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1481932799000, "tmdate": 1482599854114, "id": "ICLR.cc/2017/conference/-/paper493/official/review", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/conference/paper493/reviewers"], "noninvitees": ["ICLR.cc/2017/conference/paper493/AnonReviewer1", "ICLR.cc/2017/conference/paper493/AnonReviewer3", "ICLR.cc/2017/conference/paper493/AnonReviewer2"], "reply": {"forum": "BJFG8Yqxl", "replyto": "BJFG8Yqxl", "writers": {"values-regex": "ICLR.cc/2017/conference/paper493/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/conference/paper493/AnonReviewer[0-9]+"}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "value-regex": "[\\S\\s]{1,20000}"}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1489708799000, "cdate": 1482599854114}}}, {"tddate": null, "tmdate": 1481849020259, "tcdate": 1481849020255, "number": 1, "id": "S1VTu2e4x", "invitation": "ICLR.cc/2017/conference/-/paper493/official/review", "forum": "BJFG8Yqxl", "replyto": "BJFG8Yqxl", "signatures": ["ICLR.cc/2017/conference/paper493/AnonReviewer1"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/conference/paper493/AnonReviewer1"], "content": {"title": "", "rating": "6: Marginally above acceptance threshold", "review": "This paper propose to classify questions by leveraging corresponding answers. The proposed method uses group sparse autoencoders to model question groups.\n\nThe proposed method offers improved accuracy over baselines. But the baseline used is a little stale. Would be interesting to see how it compares to more recent CNN and RNN based methods. It would also be interesting to see the contribution of each components. For example, how much GSA contributed to the improvement.", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"TL;DR": "", "title": "Group Sparse CNNs for Question Sentence Classification with Answer Sets", "abstract": "Classifying question sentences into their corresponding categories is an important task with wide applications, for example in many websites' FAQ sections. \nHowever, traditional question classification techniques do not fully utilize the well-prepared answer data which has great potential for improving question sentence representations which could lead to better classification performance. In order to encode answer information into question representation, we first introduce novel group sparse autoencoders which could utilize the group information in the answer set to refine question representation. We then propose a new group sparse convolutional neural network which could naturally learn the question representation with respect to their corresponding answers by implanting the group sparse autoencoders into the traditional convolutional neural network. The proposed model show significant improvements over strong baselines on four datasets.  ", "pdf": "/pdf/b2be6aeb38cfc5a9b7f5edb69bcb453b6ff4e0cc.pdf", "paperhash": "ma|group_sparse_cnns_for_question_sentence_classification_with_answer_sets", "keywords": [], "conflicts": ["oregonstate.edu", "us.ibm.com"], "authors": ["Mingbo Ma", "Liang Huang", "Bing Xiang", "Bowen Zhou"], "authorids": ["mam@oregonstate.edu", "liang.huang@oregonstate.edu", "bingxia@us.ibm.com", "zhou@us.ibm.com"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1481932799000, "tmdate": 1482599854114, "id": "ICLR.cc/2017/conference/-/paper493/official/review", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/conference/paper493/reviewers"], "noninvitees": ["ICLR.cc/2017/conference/paper493/AnonReviewer1", "ICLR.cc/2017/conference/paper493/AnonReviewer3", "ICLR.cc/2017/conference/paper493/AnonReviewer2"], "reply": {"forum": "BJFG8Yqxl", "replyto": "BJFG8Yqxl", "writers": {"values-regex": "ICLR.cc/2017/conference/paper493/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/conference/paper493/AnonReviewer[0-9]+"}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "value-regex": "[\\S\\s]{1,20000}"}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1489708799000, "cdate": 1482599854114}}}, {"tddate": null, "tmdate": 1481650481158, "tcdate": 1481650481150, "number": 1, "id": "ryYV-hp7l", "invitation": "ICLR.cc/2017/conference/-/paper493/public/comment", "forum": "BJFG8Yqxl", "replyto": "H1AOBRgQg", "signatures": ["~Mingbo_Ma1"], "readers": ["everyone"], "writers": ["~Mingbo_Ma1"], "content": {"title": "Re:Why not compare against a standard sparse auto-encoder?", "comment": "Dear Reviewer #3:\n\nThanks for your comments. \n\nWe agree with your comments on ablation studies. We will include the comparison experiments between group sparse-based method and standard sparse-based method in the future revision.\n\nAbout the second comments, we only want to argue that SGA can not be trained jointly with CNN together. For SGL, we need to get the sentence representation before we apply the sparse coding model. Then the CNN (for sentence representation) and sparse coding model (for dictionary learning) are trained separately. The motivation of our proposed GSCNN is to combine these two models into one framework."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"TL;DR": "", "title": "Group Sparse CNNs for Question Sentence Classification with Answer Sets", "abstract": "Classifying question sentences into their corresponding categories is an important task with wide applications, for example in many websites' FAQ sections. \nHowever, traditional question classification techniques do not fully utilize the well-prepared answer data which has great potential for improving question sentence representations which could lead to better classification performance. In order to encode answer information into question representation, we first introduce novel group sparse autoencoders which could utilize the group information in the answer set to refine question representation. We then propose a new group sparse convolutional neural network which could naturally learn the question representation with respect to their corresponding answers by implanting the group sparse autoencoders into the traditional convolutional neural network. The proposed model show significant improvements over strong baselines on four datasets.  ", "pdf": "/pdf/b2be6aeb38cfc5a9b7f5edb69bcb453b6ff4e0cc.pdf", "paperhash": "ma|group_sparse_cnns_for_question_sentence_classification_with_answer_sets", "keywords": [], "conflicts": ["oregonstate.edu", "us.ibm.com"], "authors": ["Mingbo Ma", "Liang Huang", "Bing Xiang", "Bowen Zhou"], "authorids": ["mam@oregonstate.edu", "liang.huang@oregonstate.edu", "bingxia@us.ibm.com", "zhou@us.ibm.com"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287554354, "id": "ICLR.cc/2017/conference/-/paper493/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "BJFG8Yqxl", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper493/reviewers", "ICLR.cc/2017/conference/paper493/areachairs"], "cdate": 1485287554354}}}, {"tddate": null, "tmdate": 1480807797772, "tcdate": 1480807797766, "number": 1, "id": "H1AOBRgQg", "invitation": "ICLR.cc/2017/conference/-/paper493/pre-review/question", "forum": "BJFG8Yqxl", "replyto": "BJFG8Yqxl", "signatures": ["ICLR.cc/2017/conference/paper493/AnonReviewer3"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/conference/paper493/AnonReviewer3"], "content": {"title": "Why not compare against a standard sparse auto-encoder?", "question": "It seems to me that there is a lack of ablation studies to show the group sparse auto-encoder works better than standard sparse auto-encoder. In terms of comparison, you can simply place a standard sparse auto-encoder layer on top of the CNNs following your configuration in Sec. 4. \n\nTable 3 does not explain too much yet. At least a KNN+SGA and SVM+SGA can be applied. Also the author's claim on SGL cannot be applied on CNNs should be justified. To me energy based learning allows stacking a sparse coding network on top. Or we can substitute the l2 weight decay with ell_1,2 or ell_2,1 norm in order to induce group sparsity. "}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"TL;DR": "", "title": "Group Sparse CNNs for Question Sentence Classification with Answer Sets", "abstract": "Classifying question sentences into their corresponding categories is an important task with wide applications, for example in many websites' FAQ sections. \nHowever, traditional question classification techniques do not fully utilize the well-prepared answer data which has great potential for improving question sentence representations which could lead to better classification performance. In order to encode answer information into question representation, we first introduce novel group sparse autoencoders which could utilize the group information in the answer set to refine question representation. We then propose a new group sparse convolutional neural network which could naturally learn the question representation with respect to their corresponding answers by implanting the group sparse autoencoders into the traditional convolutional neural network. The proposed model show significant improvements over strong baselines on four datasets.  ", "pdf": "/pdf/b2be6aeb38cfc5a9b7f5edb69bcb453b6ff4e0cc.pdf", "paperhash": "ma|group_sparse_cnns_for_question_sentence_classification_with_answer_sets", "keywords": [], "conflicts": ["oregonstate.edu", "us.ibm.com"], "authors": ["Mingbo Ma", "Liang Huang", "Bing Xiang", "Bowen Zhou"], "authorids": ["mam@oregonstate.edu", "liang.huang@oregonstate.edu", "bingxia@us.ibm.com", "zhou@us.ibm.com"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1480741199000, "tmdate": 1480959250945, "id": "ICLR.cc/2017/conference/-/paper493/pre-review/question", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/conference/paper493/reviewers"], "noninvitees": ["ICLR.cc/2017/conference/paper493/AnonReviewer3"], "reply": {"forum": "BJFG8Yqxl", "replyto": "BJFG8Yqxl", "writers": {"values-regex": "ICLR.cc/2017/conference/paper493/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/conference/paper493/AnonReviewer[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your question.", "value-regex": ".{1,500}"}, "question": {"order": 2, "description": "Your question", "value-regex": "[\\S\\s]{1,5000}"}}}, "nonreaders": [], "expdate": 1488517199000, "cdate": 1480959250945}}}, {"tddate": null, "replyto": null, "ddate": null, "tmdate": 1479658650843, "tcdate": 1478297105361, "number": 493, "id": "BJFG8Yqxl", "invitation": "ICLR.cc/2017/conference/-/submission", "forum": "BJFG8Yqxl", "signatures": ["~Mingbo_Ma1"], "readers": ["everyone"], "content": {"TL;DR": "", "title": "Group Sparse CNNs for Question Sentence Classification with Answer Sets", "abstract": "Classifying question sentences into their corresponding categories is an important task with wide applications, for example in many websites' FAQ sections. \nHowever, traditional question classification techniques do not fully utilize the well-prepared answer data which has great potential for improving question sentence representations which could lead to better classification performance. In order to encode answer information into question representation, we first introduce novel group sparse autoencoders which could utilize the group information in the answer set to refine question representation. We then propose a new group sparse convolutional neural network which could naturally learn the question representation with respect to their corresponding answers by implanting the group sparse autoencoders into the traditional convolutional neural network. The proposed model show significant improvements over strong baselines on four datasets.  ", "pdf": "/pdf/b2be6aeb38cfc5a9b7f5edb69bcb453b6ff4e0cc.pdf", "paperhash": "ma|group_sparse_cnns_for_question_sentence_classification_with_answer_sets", "keywords": [], "conflicts": ["oregonstate.edu", "us.ibm.com"], "authors": ["Mingbo Ma", "Liang Huang", "Bing Xiang", "Bowen Zhou"], "authorids": ["mam@oregonstate.edu", "liang.huang@oregonstate.edu", "bingxia@us.ibm.com", "zhou@us.ibm.com"]}, "writers": [], "nonreaders": [], "details": {"replyCount": 6, "writable": false, "overwriting": [], "revisions": false, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1475686800000, "tmdate": 1478287705855, "id": "ICLR.cc/2017/conference/-/submission", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/pcs"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": null, "replyto": null, "writers": {"values-regex": "~.*"}, "signatures": {"values-regex": "~.*", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"pdf": {"required": true, "order": 5, "description": "Either upload a PDF file or provide a direct link to your PDF on ArXiv (link must begin with http(s) and end with .pdf)", "value-regex": "upload|(http|https):\\/\\/.+\\.pdf"}, "title": {"required": true, "order": 1, "description": "Title of paper.", "value-regex": ".{1,250}"}, "abstract": {"required": true, "order": 4, "description": "Abstract of paper.", "value-regex": "[\\S\\s]{1,5000}"}, "authors": {"required": true, "order": 2, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of author names, as they appear in the paper."}, "conflicts": {"required": true, "order": 100, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of email domains of people who would have a conflict of interest in reviewing this paper, (e.g., cs.umass.edu;google.com, etc.)."}, "keywords": {"order": 6, "description": "Comma separated list of keywords.", "values-dropdown": ["Theory", "Computer vision", "Speech", "Natural language processing", "Deep learning", "Unsupervised Learning", "Supervised Learning", "Semi-Supervised Learning", "Reinforcement Learning", "Transfer Learning", "Multi-modal learning", "Applications", "Optimization", "Structured prediction", "Games"]}, "TL;DR": {"required": false, "order": 3, "description": "\"Too Long; Didn't Read\": a short sentence describing your paper", "value-regex": "[^\\n]{0,250}"}, "authorids": {"required": true, "order": 3, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of author email addresses, in the same order as above."}}}, "nonreaders": [], "noninvitees": [], "expdate": 1483462800000, "cdate": 1478287705855}}}], "count": 7}