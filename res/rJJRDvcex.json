{"notes": [{"tddate": null, "ddate": null, "cdate": null, "tmdate": 1486396563050, "tcdate": 1486396563050, "number": 1, "id": "Hkj5nMU_e", "invitation": "ICLR.cc/2017/conference/-/paper401/acceptance", "forum": "rJJRDvcex", "replyto": "rJJRDvcex", "signatures": ["ICLR.cc/2017/pcs"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/pcs"], "content": {"decision": "Reject", "title": "ICLR committee final decision", "comment": "This paper proposes a hybrid architecture that combines traditional CNN layers with separable RNN layers that quickly increase the receptive field of intermediate features. The paper demonstrates experiments on CIfar-10 and semantic segmentation, both by fine-tuning pretrained CNN models and by training them from scratch, showing numerical improvements. \n \n The reviewers agreed that this paper presents a sound modification of standard CNN architectures in a clear, well-presented manner. They also highlighted the clear improvement of the manuscipt between the first draft and subsequent revisions. \n However, they also agreed that the novelty of the approach is limited compared to recent works (e.g. Bell'16), despite acknowledging the multiple technical differences between the approaches. Another source of concern is the lack of large-scale experiments on imagenet, which would potentially elucidate the role of the proposed interleaved lrnn modules in the performance boost and demonstrate its usefulness to other tasks. \n \n Based on these remarks, the AC recommends rejection of the current manuscript, and encourages the authors to resubmit the work once the large-scale experiments are completed."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Layer Recurrent Neural Networks", "abstract": "In this paper, we propose a Layer-RNN (L-RNN) module that is able to learn contextual information adaptively using within-layer recurrence. Our contributions are three-fold: \n(i) we propose a hybrid neural network architecture that interleaves traditional convolutional layers with L-RNN module for learning long- range dependencies at multiple levels; \n(ii) we show that a L-RNN module can be seamlessly inserted into any convolutional layer of a pre-trained CNN, and the entire network then fine-tuned, leading to a boost in performance; \n(iii) we report experiments on the CIFAR-10 classification task, showing that a network with interleaved convolutional layers and L-RNN modules, achieves comparable results (5.39% top1 error) using only 15 layers and fewer parameters to ResNet-164 (5.46%); and on the PASCAL VOC2012 semantic segmentation task, we show that the performance of a pre-trained FCN network can be boosted by 5% (mean IOU) by simply inserting Layer-RNNs.", "pdf": "/pdf/ee86e273bd4e6d2047a43e5556a9052cab91564f.pdf", "TL;DR": "We propose a Layer-RNN (L-RNN) network that is able to learn contextual information adaptively using within-layer recurrence. We further propose to insert L-RNN to pre-trained CNNs seamlessly.", "paperhash": "xie|layer_recurrent_neural_networks", "keywords": ["Deep learning", "Computer vision"], "conflicts": ["robots.ox.ac.uk", "eng.ox.ac.uk"], "authors": ["Weidi Xie", "Alison Noble", "Andrew Zisserman"], "authorids": ["weidi.xie@eng.ox.ac.uk", "alison.noble@eng.ox.ac.uk", "az@robots.ox.ac.uk"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1486396563540, "id": "ICLR.cc/2017/conference/-/paper401/acceptance", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/pcs"], "noninvitees": ["ICLR.cc/2017/pcs"], "reply": {"forum": "rJJRDvcex", "replyto": "rJJRDvcex", "writers": {"values-regex": "ICLR.cc/2017/pcs"}, "signatures": {"values-regex": "ICLR.cc/2017/pcs", "description": "Your displayed identity associated with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your decision.", "value": "ICLR committee final decision"}, "comment": {"required": true, "order": 2, "description": "Decision comments.", "value-regex": "[\\S\\s]{1,5000}"}, "decision": {"required": true, "order": 3, "value-radio": ["Accept (Oral)", "Accept (Poster)", "Reject", "Invite to Workshop Track"]}}}, "nonreaders": [], "cdate": 1486396563540}}}, {"tddate": null, "tmdate": 1484930051884, "tcdate": 1484930051884, "number": 10, "id": "ryhbhn1De", "invitation": "ICLR.cc/2017/conference/-/paper401/public/comment", "forum": "rJJRDvcex", "replyto": "H1QHIh4me", "signatures": ["(anonymous)"], "readers": ["everyone"], "writers": ["(anonymous)"], "content": {"title": "Accept", "comment": "The authors addressed all of my comments and rigorously revised their manuscript. I suggest to accept the manuscript!"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Layer Recurrent Neural Networks", "abstract": "In this paper, we propose a Layer-RNN (L-RNN) module that is able to learn contextual information adaptively using within-layer recurrence. Our contributions are three-fold: \n(i) we propose a hybrid neural network architecture that interleaves traditional convolutional layers with L-RNN module for learning long- range dependencies at multiple levels; \n(ii) we show that a L-RNN module can be seamlessly inserted into any convolutional layer of a pre-trained CNN, and the entire network then fine-tuned, leading to a boost in performance; \n(iii) we report experiments on the CIFAR-10 classification task, showing that a network with interleaved convolutional layers and L-RNN modules, achieves comparable results (5.39% top1 error) using only 15 layers and fewer parameters to ResNet-164 (5.46%); and on the PASCAL VOC2012 semantic segmentation task, we show that the performance of a pre-trained FCN network can be boosted by 5% (mean IOU) by simply inserting Layer-RNNs.", "pdf": "/pdf/ee86e273bd4e6d2047a43e5556a9052cab91564f.pdf", "TL;DR": "We propose a Layer-RNN (L-RNN) network that is able to learn contextual information adaptively using within-layer recurrence. We further propose to insert L-RNN to pre-trained CNNs seamlessly.", "paperhash": "xie|layer_recurrent_neural_networks", "keywords": ["Deep learning", "Computer vision"], "conflicts": ["robots.ox.ac.uk", "eng.ox.ac.uk"], "authors": ["Weidi Xie", "Alison Noble", "Andrew Zisserman"], "authorids": ["weidi.xie@eng.ox.ac.uk", "alison.noble@eng.ox.ac.uk", "az@robots.ox.ac.uk"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287591853, "id": "ICLR.cc/2017/conference/-/paper401/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "rJJRDvcex", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper401/reviewers", "ICLR.cc/2017/conference/paper401/areachairs"], "cdate": 1485287591853}}}, {"tddate": null, "tmdate": 1484929979633, "tcdate": 1481061946639, "number": 1, "id": "H1QHIh4me", "invitation": "ICLR.cc/2017/conference/-/paper401/public/review", "forum": "rJJRDvcex", "replyto": "rJJRDvcex", "signatures": ["(anonymous)"], "readers": ["everyone"], "writers": ["(anonymous)"], "content": {"title": "Additional evaluations required for being accepted", "rating": "7: Good paper, accept", "review": "The authors propose the use of a vertical and horizontal one-dimensional RNN (denoted as L-RNN module) to capture long-range dependencies and summarize convolutional feature maps. L-RNN modules are an alternative to deeper or wider networks, 2D RNNs, dilated (Atrous) convolutional layers, and a simple flatten or global pooling layer when applied to the last convolutional layer for classification. L-RNN modules are faster than 2D RNNs, since rows and columns can be processed in parallel, are easy to implemented, and can be inserted in existing convolutional networks. The authors demonstrate improvements for classification and semantic segmentation.\n\nHowever, further evaluations are required that show for which use cases L-RNNs are superior to alternatives for summarizing convolutional feature maps:\n\n1. I suggest to use a fixed CNN with as certain number of layers, and summarize the last feature map by a) a flatten layer, b) global average pooling, c) a 2D RNN, d) and dilated convolutional layers for segmentation. The authors should report both the run-time and number of parameters for these variants in addition to prediction performances. For segmentation, the number of dilated convolutional layers should be chosen such that the number of parameters is similar to a single L-RNN module.\n\n2. The authors compare classification performances only on 32x32 CIFAR-10 images. For higher resolution images, the benefit of L-RNN modules to capture long-range dependencies might be more pronounced. I therefore suggest evaluating classification performances on one additional dataset with higher resolution images, e.g. ImageNet or the CUB bird dataset.\n\nAdditionally, I have the following minor comments:\n\n3. The authors use vanilla RNNs. It might be worth investigating LSTMs or GRUs instead.\n\n4. For classification, the authors summarize hidden states of the final vertical recurrent layer by global max pooling. Is this different from more common global average pooling or concatenating the final forward and backward recurrent states?\n\n5. Table 3 is hard to understand since it mingles datasets (Pascal P and COCO C) and methods (CRF post-processing). I suggest, e.g., using an additional column with CRF \u2018yes\u2019 or \u2018no\u2019. I further suggest listing the number of parameters and runtime if possible.\n\n6. Section 3 does not clearly describe in which order batch-normalization is applied in residual blocks. Figure 2 suggest that the newer BN-ReLU-Conv order described in He et al. (2016) is used. This should be mentioned in the text.\n\nFinally, the text needs to be revised to reach publication level quality. Specifically, I have the following comments:\n\n7. Equation (1) is the update of a vanilla RNN, which should be stated more clearly. I suggest to first describe (bidirectional) RNNs, to reference GRUs and LSTMs, and then describe how they are applied here to images. Figure 1 should also be referenced in the text.\n\n8. In section 2.2, I suggest to describe Bell at al. more clearly. Why are they using eight instead of four RNNs? \n\n9. Section 4 starts with a verbose description about transfer learning, which can be compressed into a single reference or skipped entirely.\n\n10. Equation (6) seems to be missing an index i.\n\n11.In particular section 5 and 6 contain a lot of clutter and slang, which should be avoided:\n11.1 page 8: \u2018As can be seen\u2019, \u2018we turn to that case next\u2019\n11.2 page 9: \u2018to the very high value\u2019, \u2018as noted earlier\u2019,  \u2018less context to contribute here\u2019\n11.3 page 10: \u2018In fact\u2019, \u2018far deeper\u2019, \u2018a simple matter of\u2019, \u2018there is much left to investigate.\n\n\n\n\n", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Layer Recurrent Neural Networks", "abstract": "In this paper, we propose a Layer-RNN (L-RNN) module that is able to learn contextual information adaptively using within-layer recurrence. Our contributions are three-fold: \n(i) we propose a hybrid neural network architecture that interleaves traditional convolutional layers with L-RNN module for learning long- range dependencies at multiple levels; \n(ii) we show that a L-RNN module can be seamlessly inserted into any convolutional layer of a pre-trained CNN, and the entire network then fine-tuned, leading to a boost in performance; \n(iii) we report experiments on the CIFAR-10 classification task, showing that a network with interleaved convolutional layers and L-RNN modules, achieves comparable results (5.39% top1 error) using only 15 layers and fewer parameters to ResNet-164 (5.46%); and on the PASCAL VOC2012 semantic segmentation task, we show that the performance of a pre-trained FCN network can be boosted by 5% (mean IOU) by simply inserting Layer-RNNs.", "pdf": "/pdf/ee86e273bd4e6d2047a43e5556a9052cab91564f.pdf", "TL;DR": "We propose a Layer-RNN (L-RNN) network that is able to learn contextual information adaptively using within-layer recurrence. We further propose to insert L-RNN to pre-trained CNNs seamlessly.", "paperhash": "xie|layer_recurrent_neural_networks", "keywords": ["Deep learning", "Computer vision"], "conflicts": ["robots.ox.ac.uk", "eng.ox.ac.uk"], "authors": ["Weidi Xie", "Alison Noble", "Andrew Zisserman"], "authorids": ["weidi.xie@eng.ox.ac.uk", "alison.noble@eng.ox.ac.uk", "az@robots.ox.ac.uk"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1482512926120, "id": "ICLR.cc/2017/conference/-/paper401/public/review", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "rJJRDvcex", "replyto": "rJJRDvcex", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)"}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "value-regex": "[\\S\\s]{1,20000}"}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "noninvitees": ["weidi.xie@eng.ox.ac.uk", "alison.noble@eng.ox.ac.uk", "az@robots.ox.ac.uk", "ICLR.cc/2017/conference/paper401/reviewers", "ICLR.cc/2017/conference/paper401/areachairs", "(anonymous)"], "cdate": 1482512926120}}}, {"tddate": null, "tmdate": 1484787928757, "tcdate": 1484787020297, "number": 7, "id": "rJVIptp8x", "invitation": "ICLR.cc/2017/conference/-/paper401/public/comment", "forum": "rJJRDvcex", "replyto": "S1b82bmHe", "signatures": ["~Weidi_Xie1"], "readers": ["everyone"], "writers": ["~Weidi_Xie1"], "content": {"title": "Response to Specific Comments", "comment": "We have posted a common clarification for all the reviewers. Here we will focus on the specific questions not covered in that common response.\n\nSpecific comments:\n \n* Section 2.2 \u201cwe introduction more nonlinearities (through the convolutional layers and ...\u201d. Convolutional layers are linear operators.\n\n-- In our new version, we have fixed the ambiguities between convolution and convolution + ReLU.\nConvolution is linear operator, convolution + ReLU introduce nonlinearity.\n \n* Section 2.2, why exactly RNN cannot have pooling operators ? I do not see what would impede it.\n\n-- What we mean here is, low-level CNNs modules can provide non-linearities between layers, while the spatial RNNs proposed in ReNets (Visin et al. 2015) can not.\nWe have reworded this sentence to make it more clear.\n \n* Figure 2b and 2c not present? Please fix figure or references to it.\n \n-- We have fixed this issue in the new version.\nThere are only two modules in the paper, namely CNN module and L-RNN module.\nFigure 2a refers to the CNN module, Figure 2b refers to the L-RNN module.\n \n* Maybe add a short description of GRU in the appendix, for completeness?\n \n-- We have already added the description of GRU in version 2 of the paper.\n  \n* Section 5.2.1, last sentence; \u201cwe certainly have a strong baseline\u201d; the Pascal VOC12 for competition 6 reports 85.4 mIoU as best known results. So no, 64.4 is not \u201ccertainly strong\u201d. Please tune down the statement.\n \n-- We have tuned down the statement.\n \n* The results ignore any mention of increased memory usage or computation cost. This is not a small detail. Please add a discussion on the topic.\n \n-- We have added comparisons of time consumption in the CIFAR classification experiments in Table 2.\nComparing with the CNNs, the 1D RNNs processing tend to save time in the im2col operation.\nDue to the sequential nature of RNNs, the memory usage at every step is similar to the usage of 1x1 convolutions.\n \n* Section 6 \u201cadding multi-scale spatial\u201d -> \u201cadding spatial\u201d (there is nothing inherently \u201cmulti\u201d in the RNN)\n\n-- See the experiments on Network E, it is designed by interleaving CNN modules and L-RNN modules, where the network is equipped with the capability to learn multi-scale contextual information.\nAlso, in the semantic segmentation experiments, the L-RNN modules are added at multiple-scales, for instance, in Figure 4, the L-RNN Module 1 is added on the feature maps of spatial size of 12 x 12 pixels, L-RNN Module 2 is added on the feature maps of spatial size of 24 x 24 pixels, L-RNN Module 3 is added on the feature maps of spatial size of 48 x 48 pixels."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Layer Recurrent Neural Networks", "abstract": "In this paper, we propose a Layer-RNN (L-RNN) module that is able to learn contextual information adaptively using within-layer recurrence. Our contributions are three-fold: \n(i) we propose a hybrid neural network architecture that interleaves traditional convolutional layers with L-RNN module for learning long- range dependencies at multiple levels; \n(ii) we show that a L-RNN module can be seamlessly inserted into any convolutional layer of a pre-trained CNN, and the entire network then fine-tuned, leading to a boost in performance; \n(iii) we report experiments on the CIFAR-10 classification task, showing that a network with interleaved convolutional layers and L-RNN modules, achieves comparable results (5.39% top1 error) using only 15 layers and fewer parameters to ResNet-164 (5.46%); and on the PASCAL VOC2012 semantic segmentation task, we show that the performance of a pre-trained FCN network can be boosted by 5% (mean IOU) by simply inserting Layer-RNNs.", "pdf": "/pdf/ee86e273bd4e6d2047a43e5556a9052cab91564f.pdf", "TL;DR": "We propose a Layer-RNN (L-RNN) network that is able to learn contextual information adaptively using within-layer recurrence. We further propose to insert L-RNN to pre-trained CNNs seamlessly.", "paperhash": "xie|layer_recurrent_neural_networks", "keywords": ["Deep learning", "Computer vision"], "conflicts": ["robots.ox.ac.uk", "eng.ox.ac.uk"], "authors": ["Weidi Xie", "Alison Noble", "Andrew Zisserman"], "authorids": ["weidi.xie@eng.ox.ac.uk", "alison.noble@eng.ox.ac.uk", "az@robots.ox.ac.uk"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287591853, "id": "ICLR.cc/2017/conference/-/paper401/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "rJJRDvcex", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper401/reviewers", "ICLR.cc/2017/conference/paper401/areachairs"], "cdate": 1485287591853}}}, {"tddate": null, "tmdate": 1484787827140, "tcdate": 1484786889371, "number": 6, "id": "Sy-A3KT8e", "invitation": "ICLR.cc/2017/conference/-/paper401/public/comment", "forum": "rJJRDvcex", "replyto": "rJJRDvcex", "signatures": ["~Weidi_Xie1"], "readers": ["everyone"], "writers": ["~Weidi_Xie1"], "content": {"title": "Response to All Reviewers on Common Points", "comment": "Thank you very much for all the comments and suggestions.\nSome of the comments were already addressed in version 2 of the paper.\nVersion 3 addresses most of the remaining points. \n\nWe summarize the main changes here:\n \nVersion 3:\n1. Added additional architectures for CIFAR-10 classification, including\n-- Network E, F, where CNN modules and LRNN modules are interleaved at multiple levels. Network F outperforms the ResNet-164.\n2. Reformulated Figure 4 (Architectures for CIFAR experiments) as Table 1,\n3. Extended discussions on the experimental results.\n\nVersion 2: \n1. L-RNN modules with vanilla RNNs trained with Layer Normalization (Ba et al. 2016)\n2. Baseline-CNN added containing only convolutional layers.\n\nThe following are the response to all reviewers on the common points:\n\n---- All the reviewers comment on the very good paper by Bell et al. We address those points here.\n\nReviewer 1:\n* Idea somewhat incremental (e.g. can be seen as derivative from Bell 2016).\n \nReviewer 2:\n* Regarding novelty, the idea of combining a recurrent layer with a CNN, something practically very similar was proposed in Bell et al (2016). There are a few technical differences (e.g. cascading versus applying in parallel the recurrent layers), but in my understanding these are minor changes. The idea of initializing the recurrent network with the CNN is reasonable but is at the level of improving one wrong choice in the original work of Bell, rather than really proposing something novel.\n \nReviewer 3:\n* Contributions relative to, e.g. Bell et al., are minor.\n\nResponse:\nIn our paper, the proposed L-RNN module aims to be general; it can be inserted at any stage in the architectures for capturing contextual information at multiple levels.\n\nTo be clear on the differences:\n\n1. Interleaving CNN with L-RNN modules:\nIn Bell et al., the spatial RNNs are applied on top of CNN features (VGG-net) to learn contextual information at the final stage. A similar idea was also proposed in ReSeg (Visin et al. 2016).\nOur paper goes further than Bell et al. or Visin et al. by interleaving the CNN and LRNN modules at multiple levels of the network.\nIn consequence, the network is capable of learning representations from both local and larger context at every layer, alleviating the limitations of a fixed kernel size.\n \n2. How L-RNNs are inserted and initialized:\nUnder the scenario when the amount of data is limited, e.g. detection in Bell et al, semantic segmentation in our case.\nIn Bell et al., the authors take pre-trained CNN networks (VGG-16 up to conv5), and then train spatial RNNs on top of the pre-computed features.\nIn contrast, we show that a L-RNN can be directly inserted and trained within existing convolutional layers. This means that we increase the representational power of the pre-trained model directly. All layers in the pre-trained networks can therefore be adapted efficiently.\n\nIn our case, we re-purpose several layers in the pre-trained network as L-RNN modules at multiple levels, e.g. after pool3, pool4, and the final fully connected layers. As a result, we get a performance boost of 5% (mean IOU).\n \n3. Choice of RNNs.\nIn Bell et al., to avoid computational cost, the authors choose to use ReLU-based vanilla RNN (rather than GRU or LSTM).\nIn our paper, we validate this choice by showing that vanilla RNN with Layer Normalization (Ba et al. 2016) achieves similar performance to GRU.\n \n4. Separable Convolutions:\nIn Bell et al., 4 bidirectional spatial RNNs are applied to learn the global context. While in our paper, we propose to use 2, each bidirectional spatial RNNs is learning to approximate 1D convolutions, this idea comes from separable convolution.\n\n---- Comments on CIFAR classification experiments.\n \nReviewer 2:\n* Furthermore, as noted in my early question, Wide Residual Networks (Sergey Zagoruyko, Nikos Komodakis, BMVC16) report  better results on CIFAR-10 (4% error), while not using any recurrent layers (rather using instead a wide, VGG-type, ResNet variant). \nSo, the authors answer: \"Wide Residual Networks use the depth of the network to spread the receptive field across the entire image (DenseNet (Huang et al., 2016) similarly uses depth). Thus there is no need for recurrence within layers to capture contextual information. In contrast, we show that a shallow CNN, where the receptive field would be limited, can capture contextual information within the whole image if a L-RNN is used.\"\n \n* So, we agree that WRN do not need recurrence - and can still do better.\nThe point of my question has practically been whether using a recurrent layer is really necessary; I can understand the answer as being \"yes, if you want to keep your network shallow\".  I do not necessarily see why one would want to keep one's network shallow.\n \nReviewer 3:\n* One additional issue with the CIFAR experiments is that I expect to see a direct comparison of models A-F with and without L-RNN. It is hard to understand from the presented results if L-RNN actually adds much. In sum, I have a hard time taking away any valuable information from the CIFAR experiments.\n \nResponse:\nHere is a short summary of the discussion part of the CIFAR experiments (now included in  the updated paper).\n\nThe L-RNN module is a general computational module; it is not our intention to replace the deep networks (e.g. residual variants). \n\n1. Why only use shallow networks?\nIt is well known that deep networks can generally achieve better results than shallow ones. Thus, in our experiments, we use relatively shallow networks to avoid the possibility that the performance gain is due to network depth. Our experiments confirm that increasing the network depth by only adding low-level CNN modules below a L-RNN improves the results (Table 2, Network A to D)\n\n2. Interleaving L-RNN with CNN modules.\nWe show a comparison between a Baseline-CNN and Network-E in Table 2. Baseline-CNN is composed of 7 convolutional layers with 1.56M parameters, it achieves 8.48% top1 error. While the Network-E interleaved with CNN and L-RNN modules contains 0.97M parameters, achieving 5.96% top1 error. The difference between them is the added LRNN modules.\nMoreover, by adding more layers, Network F(5.39% top1 error) achieves comparable performance to ResNet-164 (5.46%). \n\n---- Questions related to ImageNet.\n\nReviewer 2:\n* Regarding the evaluation, experiments on CIFAR are interesting, but only as proof of concept.\n* Probably an evaluation on imageNet would bring some more insight about the merit of this layer.\n \nReviewer 3:\n* Classification experiments are not convincing.\n* I am generally skeptical of the utility of classification experiments on CIFAR-10 when presented in isolation (e.g., no results on ImageNet too). The issue is that CIFAR-10 is not interesting as a task unto itself *and* methods that work well on CIFAR-10 do not necessarily generalize to other tasks. ImageNet has been useful because, thus far, it produces features that generalize well to other tasks. Showing good results on ImageNet is much more likely to demonstrate a model that learns generalizable features. However, that is not even necessarily true, and ideally I would like to see that that a model that does well on ImageNet in fact transfers its benefit to at least one other tasks (e.g., detection).\n \nResponse:\nFurther experiments on ImageNet are definitely on the top list of our future work.\n\n---- Comments on Training Details.\n \nReviewer 1:\n* Section 5.2.1 (and appendix A), how is the learning rate increased and decreased? Manually ? This is an important detail that should be made explicit. Is the learning rate schedule the same in all experiments of each table? If there is a human in the loop, what is the variance in results between \u201ctwo human schedulers\u201d?\n \nReviewer 2:\n* Appendix A: this is very mysterious. Did you try other learning rate schedules? (e.g. polynomial)\n \nResponse:\nThe important message here is that restarting the learning rate several times can help the networks to escape saddle points or local minima.\nWe only experiment with the stepwise decay (no polynomial), and change the learning rate every 40, 60 or 80 epochs, we did not find much difference on this detail.\nWe only provide the intuitive explanation because it is not the main focus of this paper, it is just a training trick. If the readers are interested in this, we found two other related papers in this ICLR submission.\n\nhttps://openreview.net/forum?id=Skq89Scxx\nhttps://openreview.net/forum?id=BJYwwY9ll"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Layer Recurrent Neural Networks", "abstract": "In this paper, we propose a Layer-RNN (L-RNN) module that is able to learn contextual information adaptively using within-layer recurrence. Our contributions are three-fold: \n(i) we propose a hybrid neural network architecture that interleaves traditional convolutional layers with L-RNN module for learning long- range dependencies at multiple levels; \n(ii) we show that a L-RNN module can be seamlessly inserted into any convolutional layer of a pre-trained CNN, and the entire network then fine-tuned, leading to a boost in performance; \n(iii) we report experiments on the CIFAR-10 classification task, showing that a network with interleaved convolutional layers and L-RNN modules, achieves comparable results (5.39% top1 error) using only 15 layers and fewer parameters to ResNet-164 (5.46%); and on the PASCAL VOC2012 semantic segmentation task, we show that the performance of a pre-trained FCN network can be boosted by 5% (mean IOU) by simply inserting Layer-RNNs.", "pdf": "/pdf/ee86e273bd4e6d2047a43e5556a9052cab91564f.pdf", "TL;DR": "We propose a Layer-RNN (L-RNN) network that is able to learn contextual information adaptively using within-layer recurrence. We further propose to insert L-RNN to pre-trained CNNs seamlessly.", "paperhash": "xie|layer_recurrent_neural_networks", "keywords": ["Deep learning", "Computer vision"], "conflicts": ["robots.ox.ac.uk", "eng.ox.ac.uk"], "authors": ["Weidi Xie", "Alison Noble", "Andrew Zisserman"], "authorids": ["weidi.xie@eng.ox.ac.uk", "alison.noble@eng.ox.ac.uk", "az@robots.ox.ac.uk"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287591853, "id": "ICLR.cc/2017/conference/-/paper401/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "rJJRDvcex", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper401/reviewers", "ICLR.cc/2017/conference/paper401/areachairs"], "cdate": 1485287591853}}}, {"tddate": null, "tmdate": 1484787351601, "tcdate": 1484787351601, "number": 9, "id": "SJgo0F68x", "invitation": "ICLR.cc/2017/conference/-/paper401/public/comment", "forum": "rJJRDvcex", "replyto": "B13xt9b4x", "signatures": ["~Weidi_Xie1"], "readers": ["everyone"], "writers": ["~Weidi_Xie1"], "content": {"title": "Response", "comment": "Thank you very much for your comments, we have updated the paper and posted a common clarification.\n\nThe clarification and updated paper should solve the questions mentioned here.\n"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Layer Recurrent Neural Networks", "abstract": "In this paper, we propose a Layer-RNN (L-RNN) module that is able to learn contextual information adaptively using within-layer recurrence. Our contributions are three-fold: \n(i) we propose a hybrid neural network architecture that interleaves traditional convolutional layers with L-RNN module for learning long- range dependencies at multiple levels; \n(ii) we show that a L-RNN module can be seamlessly inserted into any convolutional layer of a pre-trained CNN, and the entire network then fine-tuned, leading to a boost in performance; \n(iii) we report experiments on the CIFAR-10 classification task, showing that a network with interleaved convolutional layers and L-RNN modules, achieves comparable results (5.39% top1 error) using only 15 layers and fewer parameters to ResNet-164 (5.46%); and on the PASCAL VOC2012 semantic segmentation task, we show that the performance of a pre-trained FCN network can be boosted by 5% (mean IOU) by simply inserting Layer-RNNs.", "pdf": "/pdf/ee86e273bd4e6d2047a43e5556a9052cab91564f.pdf", "TL;DR": "We propose a Layer-RNN (L-RNN) network that is able to learn contextual information adaptively using within-layer recurrence. We further propose to insert L-RNN to pre-trained CNNs seamlessly.", "paperhash": "xie|layer_recurrent_neural_networks", "keywords": ["Deep learning", "Computer vision"], "conflicts": ["robots.ox.ac.uk", "eng.ox.ac.uk"], "authors": ["Weidi Xie", "Alison Noble", "Andrew Zisserman"], "authorids": ["weidi.xie@eng.ox.ac.uk", "alison.noble@eng.ox.ac.uk", "az@robots.ox.ac.uk"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287591853, "id": "ICLR.cc/2017/conference/-/paper401/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "rJJRDvcex", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper401/reviewers", "ICLR.cc/2017/conference/paper401/areachairs"], "cdate": 1485287591853}}}, {"tddate": null, "tmdate": 1484787158001, "tcdate": 1484787158001, "number": 8, "id": "rkCC6FaUg", "invitation": "ICLR.cc/2017/conference/-/paper401/public/comment", "forum": "rJJRDvcex", "replyto": "ryeRthbEl", "signatures": ["~Weidi_Xie1"], "readers": ["everyone"], "writers": ["~Weidi_Xie1"], "content": {"title": "Response to Specific Comments", "comment": "We have posted a common clarification for all the reviewers. Here we will focus on the specific questions not covered in that common response.\n \n** Regarding semantic segmentation, one of my questions has been:\n\"Is the boost you are obtaining due to something special to the recurrent layer, or is simply because one is adding extra parameters on top of a pre-trained network? (I admit I may have missed some details of your experimental evaluation)\"\nThe answer was:\n\"...For PASCAL segmentation, we add the L-RNN into a pre-trained network (this adds recurrence parameters), and again show that this boosts performance - more so than adding the same number of parameters as extra CNN layers - as it is able to model long-range dependences\"\nI could not find one such experiment in the paper ('more so than adding the same number of parameters as extra CNN layers'); I understand that you have 2048 x 2048 connections for the recurrence, it would be interesting to see what you get by spreading them over (non-recurrent) residual layers.\nClearly, this is not going to be my criterion for rejection/acceptance, since one can easily make it fail - but I was mostly asking for some sanity check\n\nResponse: \nWe have added discussion for this in the paper.\n1. As shown in the Table 3, the FCN-8s with 4096 channels(no L-RNN) in the fully connected layer has a similar number of parameters to the FCN-8s with 2048 channels(LRNN added). The comparison of performance is 64.4% vs. 69.1% on the validation set. Clearly, the performance gain is from the recurrence, not from the increased number of parameters.\n\n2. As shown in the CIFAR-10 classification experiments, Network-E (0.97M parameters) achieves much better performance than the Baseline-CNN (1.56M parameters).\n \n** Another thing that is not clear to me is where the boost comes from in Table 2; the authors mention that \"when inserting the L-RNN after pool 3 and pool4 in FCN-8s, the L-RNN is able to learn contextual information over a much larger range than the receptive field of pure local convolutions. \"\nThis is potentially true, but I do not see why this was not also the case for FCN-32s (this is more a property of the recurrence rather than the 8/32 factor, right?)\n \nResponse: \nWhat we mean here is that even without inserting L-RNN, the receptive field for the fully connected layer in FCN-32s is already over 200 pixels. Given such a big receptive field already, inserting L-RNN modules to these fully connected layers does not help much (less context can be contributed here).\nTherefore, we add L-RNN modules to the low-level features (pool3 and pool4) in FCN-8s, hoping to capture bigger contextual information in the low-level layers, and we do see performance improvements (64.1 to 69.1 mean IOU).\n \nWe have added discussion on this in the updated paper."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Layer Recurrent Neural Networks", "abstract": "In this paper, we propose a Layer-RNN (L-RNN) module that is able to learn contextual information adaptively using within-layer recurrence. Our contributions are three-fold: \n(i) we propose a hybrid neural network architecture that interleaves traditional convolutional layers with L-RNN module for learning long- range dependencies at multiple levels; \n(ii) we show that a L-RNN module can be seamlessly inserted into any convolutional layer of a pre-trained CNN, and the entire network then fine-tuned, leading to a boost in performance; \n(iii) we report experiments on the CIFAR-10 classification task, showing that a network with interleaved convolutional layers and L-RNN modules, achieves comparable results (5.39% top1 error) using only 15 layers and fewer parameters to ResNet-164 (5.46%); and on the PASCAL VOC2012 semantic segmentation task, we show that the performance of a pre-trained FCN network can be boosted by 5% (mean IOU) by simply inserting Layer-RNNs.", "pdf": "/pdf/ee86e273bd4e6d2047a43e5556a9052cab91564f.pdf", "TL;DR": "We propose a Layer-RNN (L-RNN) network that is able to learn contextual information adaptively using within-layer recurrence. We further propose to insert L-RNN to pre-trained CNNs seamlessly.", "paperhash": "xie|layer_recurrent_neural_networks", "keywords": ["Deep learning", "Computer vision"], "conflicts": ["robots.ox.ac.uk", "eng.ox.ac.uk"], "authors": ["Weidi Xie", "Alison Noble", "Andrew Zisserman"], "authorids": ["weidi.xie@eng.ox.ac.uk", "alison.noble@eng.ox.ac.uk", "az@robots.ox.ac.uk"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287591853, "id": "ICLR.cc/2017/conference/-/paper401/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "rJJRDvcex", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper401/reviewers", "ICLR.cc/2017/conference/paper401/areachairs"], "cdate": 1485287591853}}}, {"tddate": null, "replyto": null, "ddate": null, "tmdate": 1484786425454, "tcdate": 1478289350770, "number": 401, "id": "rJJRDvcex", "invitation": "ICLR.cc/2017/conference/-/submission", "forum": "rJJRDvcex", "signatures": ["~Weidi_Xie1"], "readers": ["everyone"], "content": {"title": "Layer Recurrent Neural Networks", "abstract": "In this paper, we propose a Layer-RNN (L-RNN) module that is able to learn contextual information adaptively using within-layer recurrence. Our contributions are three-fold: \n(i) we propose a hybrid neural network architecture that interleaves traditional convolutional layers with L-RNN module for learning long- range dependencies at multiple levels; \n(ii) we show that a L-RNN module can be seamlessly inserted into any convolutional layer of a pre-trained CNN, and the entire network then fine-tuned, leading to a boost in performance; \n(iii) we report experiments on the CIFAR-10 classification task, showing that a network with interleaved convolutional layers and L-RNN modules, achieves comparable results (5.39% top1 error) using only 15 layers and fewer parameters to ResNet-164 (5.46%); and on the PASCAL VOC2012 semantic segmentation task, we show that the performance of a pre-trained FCN network can be boosted by 5% (mean IOU) by simply inserting Layer-RNNs.", "pdf": "/pdf/ee86e273bd4e6d2047a43e5556a9052cab91564f.pdf", "TL;DR": "We propose a Layer-RNN (L-RNN) network that is able to learn contextual information adaptively using within-layer recurrence. We further propose to insert L-RNN to pre-trained CNNs seamlessly.", "paperhash": "xie|layer_recurrent_neural_networks", "keywords": ["Deep learning", "Computer vision"], "conflicts": ["robots.ox.ac.uk", "eng.ox.ac.uk"], "authors": ["Weidi Xie", "Alison Noble", "Andrew Zisserman"], "authorids": ["weidi.xie@eng.ox.ac.uk", "alison.noble@eng.ox.ac.uk", "az@robots.ox.ac.uk"]}, "writers": [], "nonreaders": [], "details": {"replyCount": 15, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1475686800000, "tmdate": 1478287705855, "id": "ICLR.cc/2017/conference/-/submission", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/pcs"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": null, "replyto": null, "writers": {"values-regex": "~.*"}, "signatures": {"values-regex": "~.*", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"pdf": {"required": true, "order": 5, "description": "Either upload a PDF file or provide a direct link to your PDF on ArXiv (link must begin with http(s) and end with .pdf)", "value-regex": "upload|(http|https):\\/\\/.+\\.pdf"}, "title": {"required": true, "order": 1, "description": "Title of paper.", "value-regex": ".{1,250}"}, "abstract": {"required": true, "order": 4, "description": "Abstract of paper.", "value-regex": "[\\S\\s]{1,5000}"}, "authors": {"required": true, "order": 2, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of author names, as they appear in the paper."}, "conflicts": {"required": true, "order": 100, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of email domains of people who would have a conflict of interest in reviewing this paper, (e.g., cs.umass.edu;google.com, etc.)."}, "keywords": {"order": 6, "description": "Comma separated list of keywords.", "values-dropdown": ["Theory", "Computer vision", "Speech", "Natural language processing", "Deep learning", "Unsupervised Learning", "Supervised Learning", "Semi-Supervised Learning", "Reinforcement Learning", "Transfer Learning", "Multi-modal learning", "Applications", "Optimization", "Structured prediction", "Games"]}, "TL;DR": {"required": false, "order": 3, "description": "\"Too Long; Didn't Read\": a short sentence describing your paper", "value-regex": "[^\\n]{0,250}"}, "authorids": {"required": true, "order": 3, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of author email addresses, in the same order as above."}}}, "nonreaders": [], "noninvitees": [], "expdate": 1483462800000, "cdate": 1478287705855}}}, {"tddate": null, "tmdate": 1483050056842, "tcdate": 1483050056842, "number": 3, "id": "S1b82bmHe", "invitation": "ICLR.cc/2017/conference/-/paper401/official/review", "forum": "rJJRDvcex", "replyto": "rJJRDvcex", "signatures": ["ICLR.cc/2017/conference/paper401/AnonReviewer1"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/conference/paper401/AnonReviewer1"], "content": {"title": "Interesting approach to large field of view networks", "rating": "7: Good paper, accept", "review": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.\n\n\nPaper summary: this work proposes to use RNNs inside a convolutional network architecture as a complementary mechanism to propagate spatial information across the image. Promising results on classification and semantic labeling are reported.\n\n\nReview summary:\nThe text is clear, the idea well describe, the experiments seem well constructed and do not overclaim. Overall it is not a earth shattering paper, but a good piece of incremental science.\n\n\nPros:\n* Clear description\n* Well built experiments\n* Simple yet effective idea\n* No overclaiming\n* Detailed comparison with related work architectures\n\n\nCons:\n* Idea somewhat incremental (e.g. can be seen as derivative from Bell 2016)\n* Results are good, but do not improve over state of the art\n\n\nQuality: the ideas are sound, experiments well built and analysed.\n\n\nClarity: easy to read, and mostly clear (but some relevant details left out, see comments below)\n\n\nOriginality: minor, this is a different combination of ideas well known.\n\n\nSignificance: seems like a good step forward in our quest to learn good practices to build neural networks for task X (here semantic labelling and classification).\n\n\nSpecific comments:\n* Section 2.2 \u201cwe introduction more nonlinearities (through the convolutional layers and ...\u201d. Convolutional layers are linear operators.\n* Section 2.2, why exactly RNN cannot have pooling operators ? I do not see what would impede it.\n* Section 3 \u201cinto the computational block\u201d, which block ? Seems like a typo, please rephrase.\n* Figure 2b and 2c not present ? Please fix figure or references to it.\n* Maybe add a short description of GRU in the appendix, for completeness ?\n* Section 5.1, last sentence. Not sure what is meant. The convolutions + relu and pooling in ResNet do provide non-linearities \u201cbetween layers\u201d too. Please clarify\n* Section 5.2.1 (and appendix A), how is the learning rate increased and decreased ? Manually ? This is an important detail that should be made explicit. Is the learning rate schedule the same in all experiments of each table ? If there is a human in the loop, what is the variance in results between \u201ctwo human schedulers\u201d ?\n* Section 5.2.1, last sentence; \u201cwe certainly have  a strong baseline\u201d; the Pascal VOC12 for competition 6 reports 85.4 mIoU as best known results. So no, 64.4 is not \u201ccertainly strong\u201d. Please tune down the statement.\n* Section 5.2.3 Modules -> modules\n* The results ignore any mention of increased memory usage or computation cost. This is not a small detail. Please add a discussion on the topic.\n* Section 6 \u201cadding multi-scale spatial\u201d -> \u201cadding spatial\u201d (there is nothing inherently \u201cmulti\u201d in the RNN)\n* Section 6 Furthermoe -> Furthermore\n* Appendix C, redundant with Figure 5 ?", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Layer Recurrent Neural Networks", "abstract": "In this paper, we propose a Layer-RNN (L-RNN) module that is able to learn contextual information adaptively using within-layer recurrence. Our contributions are three-fold: \n(i) we propose a hybrid neural network architecture that interleaves traditional convolutional layers with L-RNN module for learning long- range dependencies at multiple levels; \n(ii) we show that a L-RNN module can be seamlessly inserted into any convolutional layer of a pre-trained CNN, and the entire network then fine-tuned, leading to a boost in performance; \n(iii) we report experiments on the CIFAR-10 classification task, showing that a network with interleaved convolutional layers and L-RNN modules, achieves comparable results (5.39% top1 error) using only 15 layers and fewer parameters to ResNet-164 (5.46%); and on the PASCAL VOC2012 semantic segmentation task, we show that the performance of a pre-trained FCN network can be boosted by 5% (mean IOU) by simply inserting Layer-RNNs.", "pdf": "/pdf/ee86e273bd4e6d2047a43e5556a9052cab91564f.pdf", "TL;DR": "We propose a Layer-RNN (L-RNN) network that is able to learn contextual information adaptively using within-layer recurrence. We further propose to insert L-RNN to pre-trained CNNs seamlessly.", "paperhash": "xie|layer_recurrent_neural_networks", "keywords": ["Deep learning", "Computer vision"], "conflicts": ["robots.ox.ac.uk", "eng.ox.ac.uk"], "authors": ["Weidi Xie", "Alison Noble", "Andrew Zisserman"], "authorids": ["weidi.xie@eng.ox.ac.uk", "alison.noble@eng.ox.ac.uk", "az@robots.ox.ac.uk"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1481932799000, "tmdate": 1483050057467, "id": "ICLR.cc/2017/conference/-/paper401/official/review", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/conference/paper401/reviewers"], "noninvitees": ["ICLR.cc/2017/conference/paper401/AnonReviewer3", "ICLR.cc/2017/conference/paper401/AnonReviewer2", "ICLR.cc/2017/conference/paper401/AnonReviewer1"], "reply": {"forum": "rJJRDvcex", "replyto": "rJJRDvcex", "writers": {"values-regex": "ICLR.cc/2017/conference/paper401/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/conference/paper401/AnonReviewer[0-9]+"}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "value-regex": "[\\S\\s]{1,20000}"}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1489708799000, "cdate": 1483050057467}}}, {"tddate": null, "tmdate": 1481914824305, "tcdate": 1481914824305, "number": 2, "id": "ryeRthbEl", "invitation": "ICLR.cc/2017/conference/-/paper401/official/review", "forum": "rJJRDvcex", "replyto": "rJJRDvcex", "signatures": ["ICLR.cc/2017/conference/paper401/AnonReviewer2"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/conference/paper401/AnonReviewer2"], "content": {"title": "", "rating": "6: Marginally above acceptance threshold", "review": "The paper proposes a method of integrating recurrent layers within larger, potentially pre-trained, convolutional networks. The objective is to combine the feature extraction abilities of CNNs with the ability of RNNs to gather global context information.\nThe authors validate their idea on two tasks, image classification (on CIFAR-10) and semantic segmentation (on PASCAL VOC12).\n\nOn the positive side, the paper is clear and well-written (apart from some occasional typos), the proposed idea is simple and could be adopted by other works, and can be deployed as a beneficial perturbation of existing systems, which is practically important if one wants to increase the performance of a system without retraining it from scratch. The evaluation is also systematic, providing a clear ablation study. \n\nOn the negative side, the novelty of the work is relatively limited, while the validation is lacking a bit. \nRegarding novelty, the idea of combining a recurrent layer with a CNN, something practically very similar was proposed in Bell et al (2016). There are a few technical differences (e.g. cascading versus applying in parallel the recurrent layers), but in my understanding these are minor changes. The idea of initializing the recurrent network with the CNN is reasonable but is at the level of improving one wrong choice in the original work of Bell, rather than really proposing something novel. \nThis contribution (\" we use RNNs within layers\") is repeatedly mentioned in the paper (including intro &  conclusion), but in my understanding was part of Bell et al, modulo minor changes. \n\nRegarding the evaluation, experiments on CIFAR are interesting, but only as proof of concept. \n\nFurthermore, as noted in my early question, Wide Residual Networks (Sergey Zagoruyko, Nikos Komodakis, BMVC16)\nreport  better results on CIFAR-10 (4% error), while not using any recurrent layers (rather using instead a wide, VGG-type, ResNet variant). So. \nThe authors answer: \"Wide Residual Networks use the depth of the network to spread the receptive field across the entire image (DenseNet (Huang et al., 2016) similarly uses depth). Thus there is no need for recurrence within layers to capture contextual information. In contrast, we show that a shallow CNN, where the receptive field would be limited, can capture contextual information within the whole image if a L-RNN is used.\"\n\nSo, we agree that WRN do not need recurrence - and can still do better. \nThe point of my question has practically been whether using a recurrent layer is really necessary; I can understand the answer as being \"yes, if you want to keep your network shallow\".  I do not necessarily see why one would want to keep one's network shallow.\n\nProbably an evaluation on imagenet would bring some more insight about the merit of this layer. \n\n\nRegarding semantic segmentation, one of my questions has been:\n\"Is the boost you are obtaining due to something special to the recurrent layer, or is simply because one is adding extra parameters on top of a pre-trained network? (I admit I may have missed some details of your experimental evaluation)\"\nThe answer was:\n\"...For PASCAL segmentation, we add the L-RNN into a pre-trained network (this adds recurrence parameters), and again show that this boosts performance - more so than adding the same number of parameters as extra CNN layers - as it is able to model long-range dependences\"\nI could not find one such experiment in the paper ('more so than adding the same number of parameters as extra CNN layers'); I understand that you have 2048 x 2048 connections for the recurrence, it would be interesting to see what you get by spreading them over (non-recurrent) residual layers.\nClearly, this is not going to be my criterion for rejection/acceptance, since one can easily make it fail - but I was mostly asking for some sanity check \n\nFurthermore, it is a bit misleading to put in Table 3 FCN-8s and FCN8s-LRNN, since this gives the impression that the LRNN gives a  boost by 10%. In practice the \"FCN8s\" prefix of \"FCN8s-LRNN\" is that of the authors, and not of Long et al (as indicated in Table 2, 8s original is quite worse than 8s here). \n\nAnother thing that is not clear to me is where the boost comes from in Table 2; the authors mention that \"when inserting the L-RNN after pool 3 and pool4 in FCN-8s, the L-RNN is able to learn contextual information over a much larger range than the receptive field of pure local convolutions. \"\nThis is potentially true, but I do not see why this was not also the case for FCN-32s (this is more a property of the recurrence rather than the 8/32 factor, right?)\n\nA few additional points: \nIt seems like Fig 2b and Fig2c never made it into the pdf. \n\nFigure 4 is unstructured and throws some 30 boxes to the reader - I would be surprised if anyone is able to get some information out of this (why not have a table?) \n\nAppendix A: this is very mysterious. Did you try other learning rate schedules? (e.g. polynomial)\nWhat is the performance if you apply a standard training schedule? (e.g. step). \nAppendix C: \"maps .. is\" -> \"maps ... are\"\n\n\n", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Layer Recurrent Neural Networks", "abstract": "In this paper, we propose a Layer-RNN (L-RNN) module that is able to learn contextual information adaptively using within-layer recurrence. Our contributions are three-fold: \n(i) we propose a hybrid neural network architecture that interleaves traditional convolutional layers with L-RNN module for learning long- range dependencies at multiple levels; \n(ii) we show that a L-RNN module can be seamlessly inserted into any convolutional layer of a pre-trained CNN, and the entire network then fine-tuned, leading to a boost in performance; \n(iii) we report experiments on the CIFAR-10 classification task, showing that a network with interleaved convolutional layers and L-RNN modules, achieves comparable results (5.39% top1 error) using only 15 layers and fewer parameters to ResNet-164 (5.46%); and on the PASCAL VOC2012 semantic segmentation task, we show that the performance of a pre-trained FCN network can be boosted by 5% (mean IOU) by simply inserting Layer-RNNs.", "pdf": "/pdf/ee86e273bd4e6d2047a43e5556a9052cab91564f.pdf", "TL;DR": "We propose a Layer-RNN (L-RNN) network that is able to learn contextual information adaptively using within-layer recurrence. We further propose to insert L-RNN to pre-trained CNNs seamlessly.", "paperhash": "xie|layer_recurrent_neural_networks", "keywords": ["Deep learning", "Computer vision"], "conflicts": ["robots.ox.ac.uk", "eng.ox.ac.uk"], "authors": ["Weidi Xie", "Alison Noble", "Andrew Zisserman"], "authorids": ["weidi.xie@eng.ox.ac.uk", "alison.noble@eng.ox.ac.uk", "az@robots.ox.ac.uk"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1481932799000, "tmdate": 1483050057467, "id": "ICLR.cc/2017/conference/-/paper401/official/review", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/conference/paper401/reviewers"], "noninvitees": ["ICLR.cc/2017/conference/paper401/AnonReviewer3", "ICLR.cc/2017/conference/paper401/AnonReviewer2", "ICLR.cc/2017/conference/paper401/AnonReviewer1"], "reply": {"forum": "rJJRDvcex", "replyto": "rJJRDvcex", "writers": {"values-regex": "ICLR.cc/2017/conference/paper401/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/conference/paper401/AnonReviewer[0-9]+"}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "value-regex": "[\\S\\s]{1,20000}"}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1489708799000, "cdate": 1483050057467}}}, {"tddate": null, "tmdate": 1481906420372, "tcdate": 1481906420372, "number": 1, "id": "B13xt9b4x", "invitation": "ICLR.cc/2017/conference/-/paper401/official/review", "forum": "rJJRDvcex", "replyto": "rJJRDvcex", "signatures": ["ICLR.cc/2017/conference/paper401/AnonReviewer3"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/conference/paper401/AnonReviewer3"], "content": {"title": "", "rating": "5: Marginally below acceptance threshold", "review": "This paper proposes a cascade of paired (left/right, up/down) 1D RNNs as a module in CNNs in order to quickly add global context information to features without the need for stacking many convolutional layers. Experimental results are presented on image classification and semantic segmentation tasks.\n\nPros:\n- The paper is very clear and easy to read.\n- Enough details are given that the paper can likely be reproduced with or without source code.\n- Using 1D RNNs inside CNNs is a topic that deserves more experimental exploration than what exists in the literature.\n\nCons (elaborated on below):\n(1) Contributions relative to, e.g. Bell et al., are minor.\n(2) Disappointed in the actual use of the proposed L-RNN module versus how it's sold in the intro.\n(3) Classification experiments are not convincing.\n\n(1,2): The introduction states w.r.t. Bell et al. \"more substantial differences are two fold: first, we treat the L-RNN module as a general block, that can be inserted into any layer of a modern architecture, such as into a residual module. Second, we show (section 4) that the\nL-RNN can be formulated to be inserted into a pre-trained FCN (by initializing with zero recurrence\nmatrices), and that the entire network can then be fine-tuned end-to-end.\"\n\nI felt positive about these contributions after reading the intro, but then much less so after reading the experimental sections. Based on the first contribution (\"general block that can be inserted into any layer\"), I strongly expected to see the L-RNN block integrated throughout the CNN starting from near the input. However, the architectures for classification and segmentation only place the module towards the very end of the network. While not exactly the same as Bell et al. (there are many technical details that differ), it is close. The paper does not compare to the design from Bell et al. Is there any advantage to the proposed design? Or is it a variation that performs similarly? What happens if L-RNN is integrated earlier in the network, as suggested by the introduction?\n\nThe second difference is a bit more solid, but still does not rise to a 'substantive difference' in my view. Note that Bell et al. also integrate 1D RNNs into an ImageNet pretrained VGG-16 model. I do, however, think that the method of integration proposed in this paper (zero initialization) may be more elegant and does not require two-stage training by first freezing the lower layers and then later unfreezing them.\n\n(3) I am generally skeptical of the utility of classification experiments on CIFAR-10 when presented in isolation (e.g., no results on ImageNet too). The issue is that CIFAR-10 is not interesting as a task unto itself *and* methods that work well on CIFAR-10 do not necessarily generalize to other tasks. ImageNet has been useful because, thus far, it produces features that generalize well to other tasks. Showing good results on ImageNet is much more likely to demonstrate a model that learns generalizable features. However, that is not even necessarily true, and ideally I would like to see that that a model that does well on ImageNet in fact transfers its benefit to at least one other ask (e.g., detection).\n\nOne additional issue with the CIFAR experiments is that I expect to see a direct comparison of models A-F with and without L-RNN. It is hard to understand from the presented results if L-RNN actually adds much. In sum, I have a hard time taking away any valuable information from the CIFAR experiments.\n\nMinor suggestion:\n- Figure 4 is hard to read. The pixelated rounded corners on the yellow boxes are distracting.", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Layer Recurrent Neural Networks", "abstract": "In this paper, we propose a Layer-RNN (L-RNN) module that is able to learn contextual information adaptively using within-layer recurrence. Our contributions are three-fold: \n(i) we propose a hybrid neural network architecture that interleaves traditional convolutional layers with L-RNN module for learning long- range dependencies at multiple levels; \n(ii) we show that a L-RNN module can be seamlessly inserted into any convolutional layer of a pre-trained CNN, and the entire network then fine-tuned, leading to a boost in performance; \n(iii) we report experiments on the CIFAR-10 classification task, showing that a network with interleaved convolutional layers and L-RNN modules, achieves comparable results (5.39% top1 error) using only 15 layers and fewer parameters to ResNet-164 (5.46%); and on the PASCAL VOC2012 semantic segmentation task, we show that the performance of a pre-trained FCN network can be boosted by 5% (mean IOU) by simply inserting Layer-RNNs.", "pdf": "/pdf/ee86e273bd4e6d2047a43e5556a9052cab91564f.pdf", "TL;DR": "We propose a Layer-RNN (L-RNN) network that is able to learn contextual information adaptively using within-layer recurrence. We further propose to insert L-RNN to pre-trained CNNs seamlessly.", "paperhash": "xie|layer_recurrent_neural_networks", "keywords": ["Deep learning", "Computer vision"], "conflicts": ["robots.ox.ac.uk", "eng.ox.ac.uk"], "authors": ["Weidi Xie", "Alison Noble", "Andrew Zisserman"], "authorids": ["weidi.xie@eng.ox.ac.uk", "alison.noble@eng.ox.ac.uk", "az@robots.ox.ac.uk"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1481932799000, "tmdate": 1483050057467, "id": "ICLR.cc/2017/conference/-/paper401/official/review", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/conference/paper401/reviewers"], "noninvitees": ["ICLR.cc/2017/conference/paper401/AnonReviewer3", "ICLR.cc/2017/conference/paper401/AnonReviewer2", "ICLR.cc/2017/conference/paper401/AnonReviewer1"], "reply": {"forum": "rJJRDvcex", "replyto": "rJJRDvcex", "writers": {"values-regex": "ICLR.cc/2017/conference/paper401/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/conference/paper401/AnonReviewer[0-9]+"}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "value-regex": "[\\S\\s]{1,20000}"}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1489708799000, "cdate": 1483050057467}}}, {"tddate": null, "tmdate": 1481853009780, "tcdate": 1481852964580, "number": 5, "id": "B12QOTe4g", "invitation": "ICLR.cc/2017/conference/-/paper401/public/comment", "forum": "rJJRDvcex", "replyto": "Hkz_xck7x", "signatures": ["~Weidi_Xie1"], "readers": ["everyone"], "writers": ["~Weidi_Xie1"], "content": {"title": "regarding recurrent layer", "comment": "Thank you very much for your comments. \n\nWe are glad that the reviewers recognize the two principal contributions of the paper: (i) that L-RNN modules can be interleaved with CNN modules to increase the receptive field without a significant increase in parameters, and trained end-to-end from scratch (and we demonstrate this for classification); and (ii) that L-RNNs can be inserted into a pre-trained CNN and then trained to improve performance (and we demonstrate this for a FCN (VGG-type) for segmentation).\n\n1. Wide Residual Networks (Sergey Zagoruyko, Nikos Komodakis, BMVC16)\nreport  better results on CIFAR-10 (4% error), while not using any recurrent layers (rather using instead a wide, VGG-type, ResNet variant) - can you comment?\n\nWide Residual Networks use the depth of the network to spread the receptive field across the entire image (DenseNet (Huang et al., 2016) similarly uses depth). Thus there is no need for recurrence within layers to capture contextual information. In contrast, we show that a shallow CNN, where the receptive field would be limited, can capture contextual information within the whole image if a L-RNN is used.\n\n2 . Is the boost you are obtaining due to something special to the recurrent layer, or is simply because one is adding extra parameters on top of a pre-trained network? (I admit I may have missed some details of your experimental evaluation)\n\nThere are two cases: (i)  For CIFAR-10 classification, we are not using any pre-trained networks, we train the whole network end-to-end with L-RNN built on top of CNNs - so the boost is only because of the L-RNN, and the something special is global context. (ii) For PASCAL segmentation, we add the L-RNN into a pre-trained network (this adds recurrence parameters), and again show that this boosts performance - more so than adding the same number of parameters as extra CNN layers - as it is able to model long-range dependences.\n\n3. The results on PASCAL look really promising - but it would also be good to know what is the boost one can expect to get for semantic segmentation when using a strong baseline, such as Deeplab V2 (https://arxiv.org/abs/1606.00915) where the performance is reaching 80% on VOC.\nIt would also be interesting to compare the recurrent processing layer's complementarity to the Atrous SPP context aggregation proposed there. \n\nYes, we agree that is an investigation we should do. In this paper, we chose to insert L-RNNs directly into a pre-trained VGG-type network, aiming to provide an initial insight on how the learnt contextual information can improve the baseline VGG-type network. Then, our future work, will be to insert these modules into other state-of-the-art networks, including the ResNets variants.\n\n4. Finally, regarding the recurrent part, this seems to me similar to the network of Bell 2016; if the difference consists in cascading the L-R/T-D flows, rather than doing them in parallel, could you comment on whether this is better or worse performance-wise?\n(I understand that these are now being used as Residual Layers, which was not the case before).\n\nOur motivation is similar to the work by Bell 2016, to model contextual features with Recurrent Neural Networks in a flexible way. However, several distinguishing points are worth noting.\n-- To model the contextual information reaching whole image level, cascading the L-R/ T-D flows should be enough. Comparing with doing them in parallel, ours use fewer parameters.\n-- We treat the L-RNN module as a general block, that can be inserted into any layer of modern architectures, such as a residual module.\n-- Instead of using the identity recurrence matrix, we train them.\n-- We treat CNNs as a special case of Spatial Recurrent Neural Networks. Our observation is that standard RNNs compute responses based on two terms, a local term and a recurrence term. CNNs can be formalized as exactly the RNNs without the recurrence term. CNNs were designed with fixed receptive fields at each spatial position within a layer, while the added recurrence is able to model contextual information. Since CNNs have already proved to work very well on various tasks, we can always keep the CNN weights unchanged, and treat them as the local term in RNNs, then insert the recurrence term directly and train this. This formulation and method of training were not apparent in Bell et al.\n"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Layer Recurrent Neural Networks", "abstract": "In this paper, we propose a Layer-RNN (L-RNN) module that is able to learn contextual information adaptively using within-layer recurrence. Our contributions are three-fold: \n(i) we propose a hybrid neural network architecture that interleaves traditional convolutional layers with L-RNN module for learning long- range dependencies at multiple levels; \n(ii) we show that a L-RNN module can be seamlessly inserted into any convolutional layer of a pre-trained CNN, and the entire network then fine-tuned, leading to a boost in performance; \n(iii) we report experiments on the CIFAR-10 classification task, showing that a network with interleaved convolutional layers and L-RNN modules, achieves comparable results (5.39% top1 error) using only 15 layers and fewer parameters to ResNet-164 (5.46%); and on the PASCAL VOC2012 semantic segmentation task, we show that the performance of a pre-trained FCN network can be boosted by 5% (mean IOU) by simply inserting Layer-RNNs.", "pdf": "/pdf/ee86e273bd4e6d2047a43e5556a9052cab91564f.pdf", "TL;DR": "We propose a Layer-RNN (L-RNN) network that is able to learn contextual information adaptively using within-layer recurrence. We further propose to insert L-RNN to pre-trained CNNs seamlessly.", "paperhash": "xie|layer_recurrent_neural_networks", "keywords": ["Deep learning", "Computer vision"], "conflicts": ["robots.ox.ac.uk", "eng.ox.ac.uk"], "authors": ["Weidi Xie", "Alison Noble", "Andrew Zisserman"], "authorids": ["weidi.xie@eng.ox.ac.uk", "alison.noble@eng.ox.ac.uk", "az@robots.ox.ac.uk"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287591853, "id": "ICLR.cc/2017/conference/-/paper401/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "rJJRDvcex", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper401/reviewers", "ICLR.cc/2017/conference/paper401/areachairs"], "cdate": 1485287591853}}}, {"tddate": null, "tmdate": 1480725905494, "tcdate": 1480724585838, "number": 1, "id": "Hkz_xck7x", "invitation": "ICLR.cc/2017/conference/-/paper401/pre-review/question", "forum": "rJJRDvcex", "replyto": "rJJRDvcex", "signatures": ["ICLR.cc/2017/conference/paper401/AnonReviewer2"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/conference/paper401/AnonReviewer2"], "content": {"title": "regarding recurrent layer", "question": "One general question relates to the necessity of the recurrent processing. \n\nWide Residual Networks (Sergey Zagoruyko, Nikos Komodakis, BMVC16)\nreport  better results on CIFAR-10 (4% error), while not using any recurrent layers (rather using instead a wide, VGG-type, ResNet variant) - can you comment?\nIs the boost you are obtaining due to something special to the recurrent layer, or is simply because one is adding extra parameters on top of a pre-trained network? (I admit I may have missed some details of your experimental evaluation)\n\nThe results on PASCAL look really promising - but it would also be good to know what is the boost one can expect to get for semantic segmentation when using a strong baseline, such as Deeplab V2 (https://arxiv.org/abs/1606.00915) where the performance is reaching 80% on VOC.\nIt would also be interesting to compare the recurrent processing layer's complementarity to the Atrous SPP context aggregation proposed there. \n\nFinally, regarding the recurrent part, this seems to me similar to the network of Bell 2016; if the difference consists in cascading the L-R/T-D flows, rather than doing them in parallel, could you comment on whether this is better or worse performance-wise?\n(I understand that these are now being used as Residual Layers, which was not the case before).\n\nThank you."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Layer Recurrent Neural Networks", "abstract": "In this paper, we propose a Layer-RNN (L-RNN) module that is able to learn contextual information adaptively using within-layer recurrence. Our contributions are three-fold: \n(i) we propose a hybrid neural network architecture that interleaves traditional convolutional layers with L-RNN module for learning long- range dependencies at multiple levels; \n(ii) we show that a L-RNN module can be seamlessly inserted into any convolutional layer of a pre-trained CNN, and the entire network then fine-tuned, leading to a boost in performance; \n(iii) we report experiments on the CIFAR-10 classification task, showing that a network with interleaved convolutional layers and L-RNN modules, achieves comparable results (5.39% top1 error) using only 15 layers and fewer parameters to ResNet-164 (5.46%); and on the PASCAL VOC2012 semantic segmentation task, we show that the performance of a pre-trained FCN network can be boosted by 5% (mean IOU) by simply inserting Layer-RNNs.", "pdf": "/pdf/ee86e273bd4e6d2047a43e5556a9052cab91564f.pdf", "TL;DR": "We propose a Layer-RNN (L-RNN) network that is able to learn contextual information adaptively using within-layer recurrence. We further propose to insert L-RNN to pre-trained CNNs seamlessly.", "paperhash": "xie|layer_recurrent_neural_networks", "keywords": ["Deep learning", "Computer vision"], "conflicts": ["robots.ox.ac.uk", "eng.ox.ac.uk"], "authors": ["Weidi Xie", "Alison Noble", "Andrew Zisserman"], "authorids": ["weidi.xie@eng.ox.ac.uk", "alison.noble@eng.ox.ac.uk", "az@robots.ox.ac.uk"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1480741199000, "tmdate": 1480959302370, "id": "ICLR.cc/2017/conference/-/paper401/pre-review/question", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/conference/paper401/reviewers"], "noninvitees": ["ICLR.cc/2017/conference/paper401/AnonReviewer2"], "reply": {"forum": "rJJRDvcex", "replyto": "rJJRDvcex", "writers": {"values-regex": "ICLR.cc/2017/conference/paper401/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/conference/paper401/AnonReviewer[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your question.", "value-regex": ".{1,500}"}, "question": {"order": 2, "description": "Your question", "value-regex": "[\\S\\s]{1,5000}"}}}, "nonreaders": [], "expdate": 1488517199000, "cdate": 1480959302370}}}, {"tddate": null, "tmdate": 1479888356852, "tcdate": 1479888356847, "number": 4, "id": "H1aJApzMx", "invitation": "ICLR.cc/2017/conference/-/paper401/public/comment", "forum": "rJJRDvcex", "replyto": "HySyOhyMx", "signatures": ["(anonymous)"], "readers": ["everyone"], "writers": ["(anonymous)"], "content": {"title": "Re: Addditional evaluation needed", "comment": "1. I suggest, if possible, to compare both the runtime and the number of parameters, and to add these numbers to table 2 and 3.\n2. Together with a Batch-normalization layer, you might be able to use gates in the recurrent layers. You should at least describe in the manuscript which kind of recurrent layers were used.\n5. Most state-of-the art classification networks such as ResNet use global average pooling. A quick comparison would be useful."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Layer Recurrent Neural Networks", "abstract": "In this paper, we propose a Layer-RNN (L-RNN) module that is able to learn contextual information adaptively using within-layer recurrence. Our contributions are three-fold: \n(i) we propose a hybrid neural network architecture that interleaves traditional convolutional layers with L-RNN module for learning long- range dependencies at multiple levels; \n(ii) we show that a L-RNN module can be seamlessly inserted into any convolutional layer of a pre-trained CNN, and the entire network then fine-tuned, leading to a boost in performance; \n(iii) we report experiments on the CIFAR-10 classification task, showing that a network with interleaved convolutional layers and L-RNN modules, achieves comparable results (5.39% top1 error) using only 15 layers and fewer parameters to ResNet-164 (5.46%); and on the PASCAL VOC2012 semantic segmentation task, we show that the performance of a pre-trained FCN network can be boosted by 5% (mean IOU) by simply inserting Layer-RNNs.", "pdf": "/pdf/ee86e273bd4e6d2047a43e5556a9052cab91564f.pdf", "TL;DR": "We propose a Layer-RNN (L-RNN) network that is able to learn contextual information adaptively using within-layer recurrence. We further propose to insert L-RNN to pre-trained CNNs seamlessly.", "paperhash": "xie|layer_recurrent_neural_networks", "keywords": ["Deep learning", "Computer vision"], "conflicts": ["robots.ox.ac.uk", "eng.ox.ac.uk"], "authors": ["Weidi Xie", "Alison Noble", "Andrew Zisserman"], "authorids": ["weidi.xie@eng.ox.ac.uk", "alison.noble@eng.ox.ac.uk", "az@robots.ox.ac.uk"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287591853, "id": "ICLR.cc/2017/conference/-/paper401/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "rJJRDvcex", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper401/reviewers", "ICLR.cc/2017/conference/paper401/areachairs"], "cdate": 1485287591853}}}, {"tddate": null, "tmdate": 1479686109522, "tcdate": 1479686109516, "number": 3, "id": "HySyOhyMx", "invitation": "ICLR.cc/2017/conference/-/paper401/public/comment", "forum": "rJJRDvcex", "replyto": "HyfWOLkfl", "signatures": ["~Weidi_Xie1"], "readers": ["everyone"], "writers": ["~Weidi_Xie1"], "content": {"title": "Re: Addditional evaluation needed", "comment": "Thank you very much for your attention.\n\nTo answer your questions:\n\n1. Comparing both the performance and run-time of a single L-RNN layer compared with global average pooling\n\nWe will do this experiment and add it in a later version.\n\n2. GRU vs LSTMs\n\nFor the CIFAR-10 classification task we applied GRU not LSTMs - this is because ReLUs are not suited to LSTMs, and we wish to use ReLUs in the RNN to match the statistics of the low-level CNNs. \n\nFor the semantic segmentation task,  we did not use GRU or LSTMs - this is because we wish\nto exploit pre-trained networks (as we've already witnessed how well the vanilla FCNs can perform) and thus wanted to insert an RNN into a pre-trained CNN seamlessly. This required a ReLU based vanilla RNN without any gates.  \n\n3. Comparing a ResNet block with two recurrent layers as proposed with two dilated convolutional layers, which have recently been shown powerful for segmentation?\n\nWe are working on this.\n\n4. Evaluating L-RNN on other data sets than CIFAR-10, in particular using images of a higher resolution? The performance gain via L-RNN should be more pronounced for images larger than 32x32 at the cost of a higher runtime.\n\nYes, we agree. We intend to apply the proposed hybrid architectures to ImageNet.\n\n5. In your classification architectures, is it right that you are performing global max-pooling after the L-RNN layer? Did you try global average pooling or using the last hidden states of the recurrent layers?\n\nYes, we apply global max pooling. The reason being a hypothesis that decisions are made based on the most salient features. We will compare to average pooling now, and update it.\n\nThank you for your suggestions on the texts, and the equation."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Layer Recurrent Neural Networks", "abstract": "In this paper, we propose a Layer-RNN (L-RNN) module that is able to learn contextual information adaptively using within-layer recurrence. Our contributions are three-fold: \n(i) we propose a hybrid neural network architecture that interleaves traditional convolutional layers with L-RNN module for learning long- range dependencies at multiple levels; \n(ii) we show that a L-RNN module can be seamlessly inserted into any convolutional layer of a pre-trained CNN, and the entire network then fine-tuned, leading to a boost in performance; \n(iii) we report experiments on the CIFAR-10 classification task, showing that a network with interleaved convolutional layers and L-RNN modules, achieves comparable results (5.39% top1 error) using only 15 layers and fewer parameters to ResNet-164 (5.46%); and on the PASCAL VOC2012 semantic segmentation task, we show that the performance of a pre-trained FCN network can be boosted by 5% (mean IOU) by simply inserting Layer-RNNs.", "pdf": "/pdf/ee86e273bd4e6d2047a43e5556a9052cab91564f.pdf", "TL;DR": "We propose a Layer-RNN (L-RNN) network that is able to learn contextual information adaptively using within-layer recurrence. We further propose to insert L-RNN to pre-trained CNNs seamlessly.", "paperhash": "xie|layer_recurrent_neural_networks", "keywords": ["Deep learning", "Computer vision"], "conflicts": ["robots.ox.ac.uk", "eng.ox.ac.uk"], "authors": ["Weidi Xie", "Alison Noble", "Andrew Zisserman"], "authorids": ["weidi.xie@eng.ox.ac.uk", "alison.noble@eng.ox.ac.uk", "az@robots.ox.ac.uk"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287591853, "id": "ICLR.cc/2017/conference/-/paper401/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "rJJRDvcex", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper401/reviewers", "ICLR.cc/2017/conference/paper401/areachairs"], "cdate": 1485287591853}}}, {"tddate": null, "tmdate": 1479661561983, "tcdate": 1479661561978, "number": 1, "id": "HyfWOLkfl", "invitation": "ICLR.cc/2017/conference/-/paper401/public/comment", "forum": "rJJRDvcex", "replyto": "rJJRDvcex", "signatures": ["(anonymous)"], "readers": ["everyone"], "writers": ["(anonymous)"], "content": {"title": "Addditional evaluation needed", "comment": "Hey,\n\nI like the described approach to capture dependencies in images! \n\nCan you let me know if you did the following experiments:\n* comparing both the performance and run-time of a single L-RNN layer compared with global average pooling\n* comparing GRUs vs. LSTMs\n* comparing a ResNet block with two recurrent layers as proposed with two dilated convolutional layers, which have recently been shown powerful for segmentation?\n* evaluating L-RNN on other data sets than CIFAR-10, in particular using images of a higher resolution? The performance gain via L-RNN should be more pronounced for images larger than 32x32 at the cost of a higher runtime.\n\nIn your classification architectures, is it right that you are performing global max-pooling after the L-RNN layer? Did you try global average pooling or using the last hidden states of the recurrent layers?\n\nI think the index i is missing in equation 6: (W * X^L)_i. I also suggest to polish the text by removing clutter (e.g. \u2018as it is well known\u2019, \u2018where there are copious annotations\u2019, \u2018what is very clear\u2019, \u2018as practitioners know\u2019, \u2018it is worth noting\u2019, \u2018as expected\u2019) and avoiding slang (e.g. can\u2019t).\n\nBest,"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Layer Recurrent Neural Networks", "abstract": "In this paper, we propose a Layer-RNN (L-RNN) module that is able to learn contextual information adaptively using within-layer recurrence. Our contributions are three-fold: \n(i) we propose a hybrid neural network architecture that interleaves traditional convolutional layers with L-RNN module for learning long- range dependencies at multiple levels; \n(ii) we show that a L-RNN module can be seamlessly inserted into any convolutional layer of a pre-trained CNN, and the entire network then fine-tuned, leading to a boost in performance; \n(iii) we report experiments on the CIFAR-10 classification task, showing that a network with interleaved convolutional layers and L-RNN modules, achieves comparable results (5.39% top1 error) using only 15 layers and fewer parameters to ResNet-164 (5.46%); and on the PASCAL VOC2012 semantic segmentation task, we show that the performance of a pre-trained FCN network can be boosted by 5% (mean IOU) by simply inserting Layer-RNNs.", "pdf": "/pdf/ee86e273bd4e6d2047a43e5556a9052cab91564f.pdf", "TL;DR": "We propose a Layer-RNN (L-RNN) network that is able to learn contextual information adaptively using within-layer recurrence. We further propose to insert L-RNN to pre-trained CNNs seamlessly.", "paperhash": "xie|layer_recurrent_neural_networks", "keywords": ["Deep learning", "Computer vision"], "conflicts": ["robots.ox.ac.uk", "eng.ox.ac.uk"], "authors": ["Weidi Xie", "Alison Noble", "Andrew Zisserman"], "authorids": ["weidi.xie@eng.ox.ac.uk", "alison.noble@eng.ox.ac.uk", "az@robots.ox.ac.uk"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287591853, "id": "ICLR.cc/2017/conference/-/paper401/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "rJJRDvcex", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper401/reviewers", "ICLR.cc/2017/conference/paper401/areachairs"], "cdate": 1485287591853}}}], "count": 16}