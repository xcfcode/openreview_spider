{"notes": [{"tddate": null, "replyto": null, "ddate": null, "tmdate": 1528124433381, "tcdate": 1518465418585, "number": 241, "cdate": 1518465418585, "id": "rkX9Z_kwf", "invitation": "ICLR.cc/2018/Workshop/-/Submission", "forum": "rkX9Z_kwf", "signatures": ["~Raghav_Goyal1"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Workshop"], "content": {"title": "Evaluating visual \"common sense\" using fine-grained classification and captioning tasks", "abstract": "We introduce the Something-something V2 dataset, which contains captions of finely-varying human-object interactions. We also discuss various baseline models, and show that neural networks show surprisingly strong performance on many of the very hard, detailed discrimination tasks associated with this dataset.", "paperhash": "goyal|evaluating_visual_common_sense_using_finegrained_classification_and_captioning_tasks", "_bibtex": "@misc{\n  goyal2018evaluating,\n  title={Evaluating visual \"common sense\" using fine-grained classification and captioning tasks},\n  author={Raghav Goyal and Farzaneh Mahdisoltani and Guillaume Berger and Waseem Gharbieh and Ingo Bax and Roland Memisevic},\n  year={2018},\n  url={https://openreview.net/forum?id=rkX9Z_kwf}\n}", "authorids": ["raghav.goyal@twentybn.com", "farzaneh.mahdisoltani@twentybn.com", "guillaume.berger@twentybn.com", "waseem.gharbieh@twentybn.com", "ingo.bax@twentybn.com", "roland.memisevic@twentybn.com"], "authors": ["Raghav Goyal", "Farzaneh Mahdisoltani", "Guillaume Berger", "Waseem Gharbieh", "Ingo Bax", "Roland Memisevic"], "keywords": ["video dataset", "fine-grained understanding", "common sense", "video captioning"], "pdf": "/pdf/672ccfb1dbd05a82d45446bc4caa4a19859e6171.pdf"}, "nonreaders": [], "details": {"replyCount": 4, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1518472800000, "tmdate": 1518474081690, "id": "ICLR.cc/2018/Workshop/-/Submission", "writers": ["ICLR.cc/2018/Workshop"], "signatures": ["ICLR.cc/2018/Workshop"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": null, "replyto": null, "writers": {"values": ["ICLR.cc/2018/Workshop"]}, "signatures": {"values-regex": "~.*|ICLR.cc/2018/Workshop", "description": "Your authorized identity to be associated with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"pdf": {"required": true, "order": 9, "value-regex": "upload", "description": "Upload a PDF file that ends with .pdf"}, "title": {"required": true, "order": 1, "description": "Title of paper.", "value-regex": ".{1,250}"}, "abstract": {"required": true, "order": 8, "description": "Abstract of paper.", "value-regex": "[\\S\\s]{1,5000}"}, "authors": {"required": true, "order": 2, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of author names. Please provide real names; identities will be anonymized."}, "keywords": {"order": 6, "values-regex": "(^$)|[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of keywords."}, "TL;DR": {"required": false, "order": 7, "description": "\"Too Long; Didn't Read\": a short sentence describing your paper", "value-regex": "[^\\n]{0,500}"}, "authorids": {"required": true, "order": 3, "values-regex": "([a-z0-9_\\-\\.]{2,}@[a-z0-9_\\-\\.]{2,}\\.[a-z]{2,},){0,}([a-z0-9_\\-\\.]{2,}@[a-z0-9_\\-\\.]{2,}\\.[a-z]{2,})", "description": "Comma separated list of author email addresses, lowercased, in the same order as above. For authors with existing OpenReview accounts, please make sure that the provided email address(es) match those listed in the author's profile. Please provide real emails; identities will be anonymized."}}}, "nonreaders": [], "noninvitees": [], "expdate": 1526248800000, "cdate": 1518474081690}}}, {"tddate": null, "ddate": null, "original": null, "tmdate": 1521582917849, "tcdate": 1520383072529, "number": 1, "cdate": 1520383072529, "id": "Hy_wEn3uf", "invitation": "ICLR.cc/2018/Workshop/-/Paper241/Official_Review", "forum": "rkX9Z_kwf", "replyto": "rkX9Z_kwf", "signatures": ["ICLR.cc/2018/Workshop/Paper241/AnonReviewer2"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Workshop/Paper241/AnonReviewer2"], "content": {"title": "Further discussions would have made the paper stronger", "rating": "6: Marginally above acceptance threshold", "review": " \n==========================================\nSummary\n==========================================\n \nThe paper proposes a new metric to measure the discriminative properties of a classification model beyond its top-k accuracy.\nThis metric is obtained by grouping annotated classes by different criteria, e.g. \"pretending\", \"prepositions, \"final state\", etc., and reporting the mean score over groups.\n\nIn addition, an new version of the Something-Something dataset (Goyal et al,ICCV'17) is released including the group-level annotations.\n\n\n----------------\nNovelty\n----------------\n\nThis paper proposes a new metric and a Something-Something dataset (Goyal et al,ICCV'17)\n\n----------------\nClarity\n----------------\n\nThe paper is clear and its content is easy to follow.\n\n----------------\nSignificance\n----------------\n\nBeyond the proposed metric, the additionl group-related labels could be useful in other work that explores the internal properties of trained models or towards model interpretation.\n\n----------------\nQuality\n----------------\n\nObservations made through the presentated experiments are barely discussed which hinders the significance of the work. Beyond some presented results, it is hard to asses why the proposed metric indeed encondes discriminative properties of the model.\n\nIn addition, is not clear to me the purpose of the captioning problem mentioned in the paper since there is no experiment or result reported related to that problem.\n\n==========================================\nPROs:\n- Clear and easy to follow.\n- Potential to foster model interpretation research.\n\n\nCONS:\n- Findings/observations made through are barely discussed.\n- No provided evidence that the proposed metric achieves its goal of measuring discriminative properties of a model\n==========================================\n", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Evaluating visual \"common sense\" using fine-grained classification and captioning tasks", "abstract": "We introduce the Something-something V2 dataset, which contains captions of finely-varying human-object interactions. We also discuss various baseline models, and show that neural networks show surprisingly strong performance on many of the very hard, detailed discrimination tasks associated with this dataset.", "paperhash": "goyal|evaluating_visual_common_sense_using_finegrained_classification_and_captioning_tasks", "_bibtex": "@misc{\n  goyal2018evaluating,\n  title={Evaluating visual \"common sense\" using fine-grained classification and captioning tasks},\n  author={Raghav Goyal and Farzaneh Mahdisoltani and Guillaume Berger and Waseem Gharbieh and Ingo Bax and Roland Memisevic},\n  year={2018},\n  url={https://openreview.net/forum?id=rkX9Z_kwf}\n}", "authorids": ["raghav.goyal@twentybn.com", "farzaneh.mahdisoltani@twentybn.com", "guillaume.berger@twentybn.com", "waseem.gharbieh@twentybn.com", "ingo.bax@twentybn.com", "roland.memisevic@twentybn.com"], "authors": ["Raghav Goyal", "Farzaneh Mahdisoltani", "Guillaume Berger", "Waseem Gharbieh", "Ingo Bax", "Roland Memisevic"], "keywords": ["video dataset", "fine-grained understanding", "common sense", "video captioning"], "pdf": "/pdf/672ccfb1dbd05a82d45446bc4caa4a19859e6171.pdf"}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1520657999000, "tmdate": 1521582917620, "id": "ICLR.cc/2018/Workshop/-/Paper241/Official_Review", "writers": ["ICLR.cc/2018/Workshop"], "signatures": ["ICLR.cc/2018/Workshop"], "readers": ["everyone"], "invitees": ["ICLR.cc/2018/Workshop/Paper241/Reviewers"], "noninvitees": ["ICLR.cc/2018/Workshop/Paper241/AnonReviewer2", "ICLR.cc/2018/Workshop/Paper241/AnonReviewer3", "ICLR.cc/2018/Workshop/Paper241/AnonReviewer1"], "reply": {"forum": "rkX9Z_kwf", "replyto": "rkX9Z_kwf", "writers": {"values-regex": "ICLR.cc/2018/Workshop/Paper241/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2018/Workshop/Paper241/AnonReviewer[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"required": true, "order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"required": true, "order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "value-regex": "[\\S\\s]{1,200000}"}, "rating": {"required": true, "order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"required": true, "order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1528433999000, "cdate": 1521582917620}}}, {"tddate": null, "ddate": null, "original": null, "tmdate": 1521582626402, "tcdate": 1520828519632, "number": 2, "cdate": 1520828519632, "id": "rJeugYQFM", "invitation": "ICLR.cc/2018/Workshop/-/Paper241/Official_Review", "forum": "rkX9Z_kwf", "replyto": "rkX9Z_kwf", "signatures": ["ICLR.cc/2018/Workshop/Paper241/AnonReviewer3"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Workshop/Paper241/AnonReviewer3"], "content": {"title": "Review", "rating": "5: Marginally below acceptance threshold", "review": "The authors present a brief study on the evaluation of visual \"common sense\" in video. They propose an updated dataset ('something-something' Goyal et.al. 2017), the use of 'contrastive groups' for more robust learning, and a baseline method that incorporates this.\n\nThe paper is somewhat difficult to parse -- particularly with regard to what the central thesis being proposed.\n\nFor example, it's not at all clear what the addition of object categories.\nInitially, the authors state:\n \"The first version of this dataset, that was introduced by (Goyal et al., 2017), is generated by asking crowd\n  workers to act out template-based labels, such as \u201cDropping something into something\u201d and to fill in the\n  \"something\" placeholders with the object used to generate the video.\"\nIt's not clear what 'object used to generate the video' means, and how it is different from having object categories.\n\nThe use of contrastive groups seems like a reasonable means to clean data/evaluation to be robust to a variety of unrelated factors for the purposes considered. And the common-sense measure itself is a prior-adjusted classification score that further helps robustnes of results.\n\nThe saliency visualisations seem to indicate reasonable things; although the T-SNE plots are again hard to understand (especially Fig.2) without a proper explanation.\n\nThe captioning part is presented in too brief a form to make sense of it -- and no evaluation or references to any number of prior papers on action-recognition in videos using natural language.\n\nI understand space is at a premium, but to cram as much as possible into a 3-page paper only makes it difficult to understand and evaluate.\n\nOverall, I feel this paper does not quite pass muster for this venue.", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Evaluating visual \"common sense\" using fine-grained classification and captioning tasks", "abstract": "We introduce the Something-something V2 dataset, which contains captions of finely-varying human-object interactions. We also discuss various baseline models, and show that neural networks show surprisingly strong performance on many of the very hard, detailed discrimination tasks associated with this dataset.", "paperhash": "goyal|evaluating_visual_common_sense_using_finegrained_classification_and_captioning_tasks", "_bibtex": "@misc{\n  goyal2018evaluating,\n  title={Evaluating visual \"common sense\" using fine-grained classification and captioning tasks},\n  author={Raghav Goyal and Farzaneh Mahdisoltani and Guillaume Berger and Waseem Gharbieh and Ingo Bax and Roland Memisevic},\n  year={2018},\n  url={https://openreview.net/forum?id=rkX9Z_kwf}\n}", "authorids": ["raghav.goyal@twentybn.com", "farzaneh.mahdisoltani@twentybn.com", "guillaume.berger@twentybn.com", "waseem.gharbieh@twentybn.com", "ingo.bax@twentybn.com", "roland.memisevic@twentybn.com"], "authors": ["Raghav Goyal", "Farzaneh Mahdisoltani", "Guillaume Berger", "Waseem Gharbieh", "Ingo Bax", "Roland Memisevic"], "keywords": ["video dataset", "fine-grained understanding", "common sense", "video captioning"], "pdf": "/pdf/672ccfb1dbd05a82d45446bc4caa4a19859e6171.pdf"}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1520657999000, "tmdate": 1521582917620, "id": "ICLR.cc/2018/Workshop/-/Paper241/Official_Review", "writers": ["ICLR.cc/2018/Workshop"], "signatures": ["ICLR.cc/2018/Workshop"], "readers": ["everyone"], "invitees": ["ICLR.cc/2018/Workshop/Paper241/Reviewers"], "noninvitees": ["ICLR.cc/2018/Workshop/Paper241/AnonReviewer2", "ICLR.cc/2018/Workshop/Paper241/AnonReviewer3", "ICLR.cc/2018/Workshop/Paper241/AnonReviewer1"], "reply": {"forum": "rkX9Z_kwf", "replyto": "rkX9Z_kwf", "writers": {"values-regex": "ICLR.cc/2018/Workshop/Paper241/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2018/Workshop/Paper241/AnonReviewer[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"required": true, "order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"required": true, "order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "value-regex": "[\\S\\s]{1,200000}"}, "rating": {"required": true, "order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"required": true, "order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1528433999000, "cdate": 1521582917620}}}, {"tddate": null, "ddate": null, "original": null, "tmdate": 1521582601175, "tcdate": 1520968038349, "number": 3, "cdate": 1520968038349, "id": "HyADbortz", "invitation": "ICLR.cc/2018/Workshop/-/Paper241/Official_Review", "forum": "rkX9Z_kwf", "replyto": "rkX9Z_kwf", "signatures": ["ICLR.cc/2018/Workshop/Paper241/AnonReviewer1"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Workshop/Paper241/AnonReviewer1"], "content": {"title": "Paper with useful contributions but unclear in a number of important aspects", "rating": "6: Marginally above acceptance threshold", "review": "The paper presents the something-something v2 dataset; a dataset containing a large number of videos collected by requesting crowd workers to act out actions like \"Dropping *something* into *something*\". This is the second version of such dataset, in which the number of videos is doubled and introduces object categories. Apart from this dataset, the authors propose three simple baseline methods on this dataset and other relatively smaller contributions (visualization, caption prediction and a new evaluation method).\n\n-Positive points\nExtending an existing dataset is definitely a contribution to the community. The dataset is twice larger and easier for object/action separation. The inclusion of three basic baselines is very useful for researchers to test their ideas incrementally, specially when one of the baselines is better in terms of accuracy than the best current results (in dataset v1, which is not directly comparable). The paper's language is good. \n\n- Negative points\nThe main negative point is the clarity of the paper. I think the authors have tried to explain too many things in a short paper, resulting in some basic ideas not being properly explained. For example:\n-- Explaining the metric construction properly is *essential* for a dataset paper. However, the authors are not making it completely clear. In the computation of mA1, mA2 and the common score, is the classifier retrained so that the output only considers the classes in the contrastive group? Is the classifier left as is but only the scores within the group are taken into account? Anything else?\nThe metric must be perfectly unambiguous.\n-- In Figure 1, what is visualized? The examples are predicted as \"opening something\". What are then the other annotations (Putting something into something, etc)? The ground truth? Activations related to those particular outputs?\n\nSince the qualitative results related to the captioning and visualizations are so small compared to the size of the dataset (and therefore could be arbitrarily cherrypicked), I would prefer to remove some of the space related to them and make the rest of the paper more verbose and clear.\n\nSummary:\nI believe the paper is a step forward from the first version of the dataset. The step is relatively small, but worth being presented in a workshop. However, my rating is relatively low given the lack of clarity in essential aspects like the evaluation metric.", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Evaluating visual \"common sense\" using fine-grained classification and captioning tasks", "abstract": "We introduce the Something-something V2 dataset, which contains captions of finely-varying human-object interactions. We also discuss various baseline models, and show that neural networks show surprisingly strong performance on many of the very hard, detailed discrimination tasks associated with this dataset.", "paperhash": "goyal|evaluating_visual_common_sense_using_finegrained_classification_and_captioning_tasks", "_bibtex": "@misc{\n  goyal2018evaluating,\n  title={Evaluating visual \"common sense\" using fine-grained classification and captioning tasks},\n  author={Raghav Goyal and Farzaneh Mahdisoltani and Guillaume Berger and Waseem Gharbieh and Ingo Bax and Roland Memisevic},\n  year={2018},\n  url={https://openreview.net/forum?id=rkX9Z_kwf}\n}", "authorids": ["raghav.goyal@twentybn.com", "farzaneh.mahdisoltani@twentybn.com", "guillaume.berger@twentybn.com", "waseem.gharbieh@twentybn.com", "ingo.bax@twentybn.com", "roland.memisevic@twentybn.com"], "authors": ["Raghav Goyal", "Farzaneh Mahdisoltani", "Guillaume Berger", "Waseem Gharbieh", "Ingo Bax", "Roland Memisevic"], "keywords": ["video dataset", "fine-grained understanding", "common sense", "video captioning"], "pdf": "/pdf/672ccfb1dbd05a82d45446bc4caa4a19859e6171.pdf"}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1520657999000, "tmdate": 1521582917620, "id": "ICLR.cc/2018/Workshop/-/Paper241/Official_Review", "writers": ["ICLR.cc/2018/Workshop"], "signatures": ["ICLR.cc/2018/Workshop"], "readers": ["everyone"], "invitees": ["ICLR.cc/2018/Workshop/Paper241/Reviewers"], "noninvitees": ["ICLR.cc/2018/Workshop/Paper241/AnonReviewer2", "ICLR.cc/2018/Workshop/Paper241/AnonReviewer3", "ICLR.cc/2018/Workshop/Paper241/AnonReviewer1"], "reply": {"forum": "rkX9Z_kwf", "replyto": "rkX9Z_kwf", "writers": {"values-regex": "ICLR.cc/2018/Workshop/Paper241/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2018/Workshop/Paper241/AnonReviewer[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"required": true, "order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"required": true, "order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "value-regex": "[\\S\\s]{1,200000}"}, "rating": {"required": true, "order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"required": true, "order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1528433999000, "cdate": 1521582917620}}}, {"tddate": null, "ddate": null, "original": null, "tmdate": 1521573575879, "tcdate": 1521573575879, "number": 139, "cdate": 1521573575539, "id": "S1lA0RCtz", "invitation": "ICLR.cc/2018/Workshop/-/Acceptance_Decision", "forum": "rkX9Z_kwf", "replyto": "rkX9Z_kwf", "signatures": ["ICLR.cc/2018/Workshop/Program_Chairs"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Workshop/Program_Chairs"], "content": {"decision": "Accept", "title": "ICLR 2018 Workshop Acceptance Decision", "comment": "Congratulations, your paper was accepted to the ICLR workshop."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Evaluating visual \"common sense\" using fine-grained classification and captioning tasks", "abstract": "We introduce the Something-something V2 dataset, which contains captions of finely-varying human-object interactions. We also discuss various baseline models, and show that neural networks show surprisingly strong performance on many of the very hard, detailed discrimination tasks associated with this dataset.", "paperhash": "goyal|evaluating_visual_common_sense_using_finegrained_classification_and_captioning_tasks", "_bibtex": "@misc{\n  goyal2018evaluating,\n  title={Evaluating visual \"common sense\" using fine-grained classification and captioning tasks},\n  author={Raghav Goyal and Farzaneh Mahdisoltani and Guillaume Berger and Waseem Gharbieh and Ingo Bax and Roland Memisevic},\n  year={2018},\n  url={https://openreview.net/forum?id=rkX9Z_kwf}\n}", "authorids": ["raghav.goyal@twentybn.com", "farzaneh.mahdisoltani@twentybn.com", "guillaume.berger@twentybn.com", "waseem.gharbieh@twentybn.com", "ingo.bax@twentybn.com", "roland.memisevic@twentybn.com"], "authors": ["Raghav Goyal", "Farzaneh Mahdisoltani", "Guillaume Berger", "Waseem Gharbieh", "Ingo Bax", "Roland Memisevic"], "keywords": ["video dataset", "fine-grained understanding", "common sense", "video captioning"], "pdf": "/pdf/672ccfb1dbd05a82d45446bc4caa4a19859e6171.pdf"}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "tmdate": 1518629844880, "id": "ICLR.cc/2018/Workshop/-/Acceptance_Decision", "writers": ["ICLR.cc/2018/Workshop"], "signatures": ["ICLR.cc/2018/Workshop"], "readers": ["everyone"], "invitees": ["ICLR.cc/2018/Workshop/Program_Chairs"], "reply": {"forum": null, "replyto": null, "invitation": "ICLR.cc/2018/Workshop/-/Submission", "writers": {"values": ["ICLR.cc/2018/Workshop/Program_Chairs"]}, "signatures": {"description": "How your identity will be displayed with the above content.", "values": ["ICLR.cc/2018/Workshop/Program_Chairs"]}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["ICLR.cc/2018/Workshop/Program_Chairs", "everyone"]}, "content": {"title": {"required": true, "order": 1, "value": "ICLR 2018 Workshop Acceptance Decision"}, "comment": {"required": false, "order": 3, "description": "(optional) Comment on this decision.", "value-regex": "[\\S\\s]{0,5000}"}, "decision": {"required": true, "order": 2, "value-dropdown": ["Accept", "Reject"]}}}, "nonreaders": [], "noninvitees": [], "cdate": 1518629844880}}}], "count": 5}