{"notes": [{"id": "S1gvPPMVv4", "original": "HygUDPGNvE", "number": 9, "cdate": 1552324446566, "ddate": null, "tcdate": 1552324446566, "tmdate": 1562082109176, "tddate": null, "forum": "S1gvPPMVv4", "replyto": null, "invitation": "ICLR.cc/2019/Workshop/LLD/-/Blind_Submission", "content": {"title": "Domain Adaptation with Asymmetrically-Relaxed Distribution Alignment", "authors": ["Yifan Wu", "Ezra Winston", "Divyansh Kaushik", "Zachary Lipton"], "authorids": ["yw4@andrew.cmu.edu", "ewinston@cs.cmu.edu", "dkaushik@cs.cmu.edu", "zlipton@cmu.edu"], "keywords": ["domain adaptation", "distribution alignment", "adversarial training", "theory"], "TL;DR": "Instead of strict distribution alignments in traditional deep domain adaptation objectives, which fails when target label distribution shifts, we propose to optimize a relaxed objective with new analysis, new algorithms, and experimental validation.", "abstract": "Domain adaptation addresses the common problem when the target distribution generating our test data drifts from the source (training) distribution. While absent assumptions, domain adaptation is impossible, strict conditions, e.g. covariate or label shift, enable principled algorithms. Recently-proposed domain-adversarial approaches consist of aligning source and target encodings, often motivating this approach as minimizing two (of three) terms in a theoretical bound on target error. Unfortunately, this minimization can cause arbitrary increases in the third term, e.g. they can break down under shifting label distributions. We propose asymmetrically-relaxed distribution alignment, a new approach that overcomes some limitations of standard domain-adversarial algorithms. Moreover, we characterize precise assumptions under which our algorithm is theoretically principled and demonstrate empirical benefits on both synthetic and real datasets.", "pdf": "/pdf/89ce113031cbc6cc5dbfb501e84ede8be4fcb185.pdf", "paperhash": "wu|domain_adaptation_with_asymmetricallyrelaxed_distribution_alignment"}, "signatures": ["ICLR.cc/2019/Workshop/LLD"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Workshop/LLD"], "details": {"replyCount": 3, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"id": "ICLR.cc/2019/Workshop/LLD/-/Blind_Submission", "cdate": 1548689671889, "reply": {"forum": null, "replyto": null, "readers": {"values-regex": ".*"}, "writers": {"values": ["ICLR.cc/2019/Workshop/LLD"]}, "signatures": {"values": ["ICLR.cc/2019/Workshop/LLD"]}, "content": {"authors": {"values-regex": ".*"}, "authorids": {"values-regex": ".*"}}}, "tcdate": 1548689671889, "tmdate": 1557933709646, "readers": ["everyone"], "writers": ["ICLR.cc/2019/Workshop/LLD"], "invitees": ["~"], "signatures": ["ICLR.cc/2019/Workshop/LLD"], "details": {"writable": true}}}, "tauthor": "ICLR.cc/2019/Workshop/LLD"}, {"id": "rJgdks9vFV", "original": null, "number": 1, "cdate": 1554651872225, "ddate": null, "tcdate": 1554651872225, "tmdate": 1555512020421, "tddate": null, "forum": "S1gvPPMVv4", "replyto": "S1gvPPMVv4", "invitation": "ICLR.cc/2019/Workshop/LLD/-/Paper9/Official_Review", "content": {"title": "Attached paper is good but short version needs rework", "review": "This paper identifies a limit of the theoretical framework of Ben-David et al. (2010), regarding an upper bound of the target error in the domain adaptation setting, which is the sum of 3 terms. Authors show that Domain adversarial approach from Ganin et al. (2016) focuses on minimizing 2 of these 3 terms but leaving out the third term leads to a lower bound on the target error, which increases when the difference between source and target distributions augment. The paper then suggests to used relaxed metrics to prevent this effect : giving several examples of such metrics, the authors propose new theoretical bounds on the target error.\n\nThe attached paper (12 pages, excluding proofs) is very clear and interesting. The framework and the theorems are stated clearly and, despite the technicality of the theorems, the key ideas seem easy to follow. The short (workshop) paper, however, is not as pleasant to read: the authors clearly lacked space, which especially shows in the last section, where no comment or explanations of the experiment are provided. Depending on the LLD organizers, this may be a problem. I suggest that the authors drop a few more results and propositions, for example concentrating on the \u03b2-f-divergences and the experiments on MNIST-USPS, which seem to be convincing enough.\n\nSeveral points could also be detailed:\n1. Why are WDANN variants absent from the final experiments?\n2. The new upper bound on target error involves several terms, provided by assumptions on the source and target domains; is there a practical advantage of this formulation? How do these smaller bounds vary when the source and target distributions shift? This seems to be a central point in advocating the relevance of the proposed approach, which could benefit the longer paper.\n3. The connected assumption 3.2 is intriguing. Does it appear in related works? Did you find datasets from which it is absent, or which provide a bad \u03b4\u2083 bound?", "rating": "4: Top 50% of accepted papers, clear accept", "confidence": "2: The reviewer is fairly confident that the evaluation is correct"}, "signatures": ["ICLR.cc/2019/Workshop/LLD/Paper9/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Workshop/LLD/Paper9/AnonReviewer1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Domain Adaptation with Asymmetrically-Relaxed Distribution Alignment", "authors": ["Yifan Wu", "Ezra Winston", "Divyansh Kaushik", "Zachary Lipton"], "authorids": ["yw4@andrew.cmu.edu", "ewinston@cs.cmu.edu", "dkaushik@cs.cmu.edu", "zlipton@cmu.edu"], "keywords": ["domain adaptation", "distribution alignment", "adversarial training", "theory"], "TL;DR": "Instead of strict distribution alignments in traditional deep domain adaptation objectives, which fails when target label distribution shifts, we propose to optimize a relaxed objective with new analysis, new algorithms, and experimental validation.", "abstract": "Domain adaptation addresses the common problem when the target distribution generating our test data drifts from the source (training) distribution. While absent assumptions, domain adaptation is impossible, strict conditions, e.g. covariate or label shift, enable principled algorithms. Recently-proposed domain-adversarial approaches consist of aligning source and target encodings, often motivating this approach as minimizing two (of three) terms in a theoretical bound on target error. Unfortunately, this minimization can cause arbitrary increases in the third term, e.g. they can break down under shifting label distributions. We propose asymmetrically-relaxed distribution alignment, a new approach that overcomes some limitations of standard domain-adversarial algorithms. Moreover, we characterize precise assumptions under which our algorithm is theoretically principled and demonstrate empirical benefits on both synthetic and real datasets.", "pdf": "/pdf/89ce113031cbc6cc5dbfb501e84ede8be4fcb185.pdf", "paperhash": "wu|domain_adaptation_with_asymmetricallyrelaxed_distribution_alignment"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Workshop/LLD/-/Paper9/Official_Review", "cdate": 1553713420843, "expdate": 1555718400000, "duedate": 1554681600000, "reply": {"forum": "S1gvPPMVv4", "replyto": "S1gvPPMVv4", "writers": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2019/Workshop/LLD/Paper9/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2019/Workshop/LLD/Paper9/AnonReviewer[0-9]+"}, "readers": {"values": ["everyone"], "description": "The users who will be allowed to read the above content."}, "content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "required": true}, "rating": {"order": 3, "value-dropdown": ["5: Top 15% of accepted papers, strong accept", "4: Top 50% of accepted papers, clear accept", "3: Marginally above acceptance threshold", "2: Marginally below acceptance threshold", "1: Strong rejection"], "required": true}, "confidence": {"order": 4, "value-radio": ["3: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "2: The reviewer is fairly confident that the evaluation is correct", "1: The reviewer's evaluation is an educated guess"], "required": true}}}, "tcdate": 1553713420843, "tmdate": 1555511818666, "readers": ["everyone"], "writers": ["ICLR.cc/2019/Workshop/LLD"], "invitees": ["ICLR.cc/2019/Workshop/LLD/Paper9/Reviewers"], "signatures": ["ICLR.cc/2019/Workshop/LLD"]}}}, {"id": "rJl0jWWnYV", "original": null, "number": 2, "cdate": 1554940325647, "ddate": null, "tcdate": 1554940325647, "tmdate": 1555511878225, "tddate": null, "forum": "S1gvPPMVv4", "replyto": "S1gvPPMVv4", "invitation": "ICLR.cc/2019/Workshop/LLD/-/Paper9/Official_Review", "content": {"title": "Interesting method", "review": "The paper proposes an asymmetrically-relaxed distribution alignment approach, to do unsupervised domain adaptation. For this, they propose 3 different \"relaxed\" distances. \n\nPros: \n- The paper is well written and, although dense, quite clear.\n- The proposed models are a good alternative to the original DANN\n- The long version of the paper could be submitted to a journal.\n\nCons:\n- The paper is very dense. \n- Experiments section is very short and explanation of results is minimal. We do not know what are the different acronyms because they are not defined. They are only defined in the long version of the paper, that was attached. \n- Conclusions are lacking.\n", "rating": "3: Marginally above acceptance threshold", "confidence": "2: The reviewer is fairly confident that the evaluation is correct"}, "signatures": ["ICLR.cc/2019/Workshop/LLD/Paper9/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Workshop/LLD/Paper9/AnonReviewer2"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Domain Adaptation with Asymmetrically-Relaxed Distribution Alignment", "authors": ["Yifan Wu", "Ezra Winston", "Divyansh Kaushik", "Zachary Lipton"], "authorids": ["yw4@andrew.cmu.edu", "ewinston@cs.cmu.edu", "dkaushik@cs.cmu.edu", "zlipton@cmu.edu"], "keywords": ["domain adaptation", "distribution alignment", "adversarial training", "theory"], "TL;DR": "Instead of strict distribution alignments in traditional deep domain adaptation objectives, which fails when target label distribution shifts, we propose to optimize a relaxed objective with new analysis, new algorithms, and experimental validation.", "abstract": "Domain adaptation addresses the common problem when the target distribution generating our test data drifts from the source (training) distribution. While absent assumptions, domain adaptation is impossible, strict conditions, e.g. covariate or label shift, enable principled algorithms. Recently-proposed domain-adversarial approaches consist of aligning source and target encodings, often motivating this approach as minimizing two (of three) terms in a theoretical bound on target error. Unfortunately, this minimization can cause arbitrary increases in the third term, e.g. they can break down under shifting label distributions. We propose asymmetrically-relaxed distribution alignment, a new approach that overcomes some limitations of standard domain-adversarial algorithms. Moreover, we characterize precise assumptions under which our algorithm is theoretically principled and demonstrate empirical benefits on both synthetic and real datasets.", "pdf": "/pdf/89ce113031cbc6cc5dbfb501e84ede8be4fcb185.pdf", "paperhash": "wu|domain_adaptation_with_asymmetricallyrelaxed_distribution_alignment"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Workshop/LLD/-/Paper9/Official_Review", "cdate": 1553713420843, "expdate": 1555718400000, "duedate": 1554681600000, "reply": {"forum": "S1gvPPMVv4", "replyto": "S1gvPPMVv4", "writers": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2019/Workshop/LLD/Paper9/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2019/Workshop/LLD/Paper9/AnonReviewer[0-9]+"}, "readers": {"values": ["everyone"], "description": "The users who will be allowed to read the above content."}, "content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "required": true}, "rating": {"order": 3, "value-dropdown": ["5: Top 15% of accepted papers, strong accept", "4: Top 50% of accepted papers, clear accept", "3: Marginally above acceptance threshold", "2: Marginally below acceptance threshold", "1: Strong rejection"], "required": true}, "confidence": {"order": 4, "value-radio": ["3: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "2: The reviewer is fairly confident that the evaluation is correct", "1: The reviewer's evaluation is an educated guess"], "required": true}}}, "tcdate": 1553713420843, "tmdate": 1555511818666, "readers": ["everyone"], "writers": ["ICLR.cc/2019/Workshop/LLD"], "invitees": ["ICLR.cc/2019/Workshop/LLD/Paper9/Reviewers"], "signatures": ["ICLR.cc/2019/Workshop/LLD"]}}}, {"id": "SyxGwnhfcE", "original": null, "number": 1, "cdate": 1555381337614, "ddate": null, "tcdate": 1555381337614, "tmdate": 1555510977865, "tddate": null, "forum": "S1gvPPMVv4", "replyto": "S1gvPPMVv4", "invitation": "ICLR.cc/2019/Workshop/LLD/-/Paper9/Decision", "content": {"title": "Acceptance Decision", "decision": "Accept"}, "signatures": ["ICLR.cc/2019/Workshop/LLD/Program_Chairs"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Workshop/LLD/Program_Chairs"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Domain Adaptation with Asymmetrically-Relaxed Distribution Alignment", "authors": ["Yifan Wu", "Ezra Winston", "Divyansh Kaushik", "Zachary Lipton"], "authorids": ["yw4@andrew.cmu.edu", "ewinston@cs.cmu.edu", "dkaushik@cs.cmu.edu", "zlipton@cmu.edu"], "keywords": ["domain adaptation", "distribution alignment", "adversarial training", "theory"], "TL;DR": "Instead of strict distribution alignments in traditional deep domain adaptation objectives, which fails when target label distribution shifts, we propose to optimize a relaxed objective with new analysis, new algorithms, and experimental validation.", "abstract": "Domain adaptation addresses the common problem when the target distribution generating our test data drifts from the source (training) distribution. While absent assumptions, domain adaptation is impossible, strict conditions, e.g. covariate or label shift, enable principled algorithms. Recently-proposed domain-adversarial approaches consist of aligning source and target encodings, often motivating this approach as minimizing two (of three) terms in a theoretical bound on target error. Unfortunately, this minimization can cause arbitrary increases in the third term, e.g. they can break down under shifting label distributions. We propose asymmetrically-relaxed distribution alignment, a new approach that overcomes some limitations of standard domain-adversarial algorithms. Moreover, we characterize precise assumptions under which our algorithm is theoretically principled and demonstrate empirical benefits on both synthetic and real datasets.", "pdf": "/pdf/89ce113031cbc6cc5dbfb501e84ede8be4fcb185.pdf", "paperhash": "wu|domain_adaptation_with_asymmetricallyrelaxed_distribution_alignment"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Workshop/LLD/-/Paper9/Decision", "cdate": 1554736069837, "reply": {"forum": "S1gvPPMVv4", "replyto": "S1gvPPMVv4", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-regex": ["ICLR.cc/2019/Workshop/LLD/Program_Chairs"], "description": "How your identity will be displayed."}, "signatures": {"values": ["ICLR.cc/2019/Workshop/LLD/Program_Chairs"], "description": "How your identity will be displayed."}, "content": {"title": {"order": 1, "required": true, "value": "Acceptance Decision"}, "decision": {"order": 2, "required": true, "value-radio": ["Accept", "Reject"], "description": "Acceptance decision"}, "comment": {"order": 3, "required": false, "value-regex": "[\\S\\s]{0,5000}", "description": ""}}}, "tcdate": 1554736069837, "tmdate": 1555510968907, "readers": ["everyone"], "writers": ["ICLR.cc/2019/Workshop/LLD"], "invitees": ["ICLR.cc/2019/Workshop/LLD/Program_Chairs"], "signatures": ["ICLR.cc/2019/Workshop/LLD"]}}}], "count": 4}