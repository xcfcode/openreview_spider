{"notes": [{"id": "S1eVe2AqKX", "original": "SJlL4lA5tm", "number": 1069, "cdate": 1538087916468, "ddate": null, "tcdate": 1538087916468, "tmdate": 1545355417364, "tddate": null, "forum": "S1eVe2AqKX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "PCNN: Environment Adaptive Model Without Finetuning", "abstract": "Convolutional Neural Networks (CNNs) have achieved tremendous success for many computer vision tasks, which shows a promising perspective of deploying CNNs on mobile platforms. An obstacle to this promising perspective is the tension between intensive resource consumption of CNNs and limited resource budget on mobile platforms. Existing works generally utilize a simpler architecture with lower accuracy for a higher energy-efficiency, \\textit{i.e.}, trading accuracy for resource consumption. An emerging opportunity to both increasing accuracy and decreasing resource consumption is \\textbf{class skew}, \\textit{i.e.}, the strong temporal and spatial locality of the appearance of classes. However, it is challenging to efficiently utilize the class skew due to both the frequent switches and the huge number of class skews. Existing works use transfer learning to adapt the model towards the class skew during runtime, which consumes resource intensively. In this paper, we propose \\textbf{probability layer}, an \\textit{easily-implemented and highly flexible add-on module} to adapt the model efficiently during runtime \\textit{without any fine-tuning} and achieving an \\textit{equivalent or better} performance than transfer learning. Further, both \\textit{increasing accuracy} and \\textit{decreasing resource consumption} can be achieved during runtime through the combination of probability layer and pruning methods.", "keywords": ["Class skew", "Runtime adaption"], "authorids": ["boyuan@cs.ucsb.edu", "kun@cs.ucsb.edu", "shuyang1995@ucsb.edu", "yufeiding@cs.ucsb.edu"], "authors": ["Boyuan Feng", "Kun Wan", "Shu Yang", "Yufei Ding"], "pdf": "/pdf/0433eaef5167e45b9043bdbdd544454d1fba6239.pdf", "paperhash": "feng|pcnn_environment_adaptive_model_without_finetuning", "_bibtex": "@misc{\nfeng2019pcnn,\ntitle={{PCNN}: Environment Adaptive Model Without Finetuning},\nauthor={Boyuan Feng and Kun Wan and Shu Yang and Yufei Ding},\nyear={2019},\nurl={https://openreview.net/forum?id=S1eVe2AqKX},\n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"replyCount": 8, "writable": false, "overwriting": [], "revisions": false, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Blind_Submission", "rdate": null, "ddate": null, "expdate": null, "duedate": 1538085600000, "tmdate": 1538142958393, "tddate": null, "super": null, "final": null, "reply": {"signatures": {"values": ["ICLR.cc/2019/Conference"]}, "forum": null, "readers": {"values": ["everyone"]}, "replyto": null, "content": {"authorids": {"values-regex": ".*"}, "authors": {"values": ["Anonymous"]}}, "writers": {"values": ["ICLR.cc/2019/Conference"]}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["~"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": null, "taskCompletionCount": null, "transform": null, "cdate": 1538142958393}}, "tauthor": "OpenReview.net"}, {"id": "rkx6RZ_iyV", "original": null, "number": 1, "cdate": 1544417748718, "ddate": null, "tcdate": 1544417748718, "tmdate": 1545354497539, "tddate": null, "forum": "S1eVe2AqKX", "replyto": "S1eVe2AqKX", "invitation": "ICLR.cc/2019/Conference/-/Paper1069/Meta_Review", "content": {"metareview": "All reviewers rate the paper as below threshold. While the authors responded to an earlier request for clarification, there is no rebuttal to the actual reviews. Thus, there is no basis by which the paper can be accepted.", "confidence": "5: The area chair is absolutely certain", "recommendation": "Reject", "title": "metareview: no rebuttal"}, "signatures": ["ICLR.cc/2019/Conference/Paper1069/Area_Chair1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference/Paper1069/Area_Chair1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "PCNN: Environment Adaptive Model Without Finetuning", "abstract": "Convolutional Neural Networks (CNNs) have achieved tremendous success for many computer vision tasks, which shows a promising perspective of deploying CNNs on mobile platforms. An obstacle to this promising perspective is the tension between intensive resource consumption of CNNs and limited resource budget on mobile platforms. Existing works generally utilize a simpler architecture with lower accuracy for a higher energy-efficiency, \\textit{i.e.}, trading accuracy for resource consumption. An emerging opportunity to both increasing accuracy and decreasing resource consumption is \\textbf{class skew}, \\textit{i.e.}, the strong temporal and spatial locality of the appearance of classes. However, it is challenging to efficiently utilize the class skew due to both the frequent switches and the huge number of class skews. Existing works use transfer learning to adapt the model towards the class skew during runtime, which consumes resource intensively. In this paper, we propose \\textbf{probability layer}, an \\textit{easily-implemented and highly flexible add-on module} to adapt the model efficiently during runtime \\textit{without any fine-tuning} and achieving an \\textit{equivalent or better} performance than transfer learning. Further, both \\textit{increasing accuracy} and \\textit{decreasing resource consumption} can be achieved during runtime through the combination of probability layer and pruning methods.", "keywords": ["Class skew", "Runtime adaption"], "authorids": ["boyuan@cs.ucsb.edu", "kun@cs.ucsb.edu", "shuyang1995@ucsb.edu", "yufeiding@cs.ucsb.edu"], "authors": ["Boyuan Feng", "Kun Wan", "Shu Yang", "Yufei Ding"], "pdf": "/pdf/0433eaef5167e45b9043bdbdd544454d1fba6239.pdf", "paperhash": "feng|pcnn_environment_adaptive_model_without_finetuning", "_bibtex": "@misc{\nfeng2019pcnn,\ntitle={{PCNN}: Environment Adaptive Model Without Finetuning},\nauthor={Boyuan Feng and Kun Wan and Shu Yang and Yufei Ding},\nyear={2019},\nurl={https://openreview.net/forum?id=S1eVe2AqKX},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper1069/Meta_Review", "rdate": null, "ddate": null, "expdate": null, "duedate": 1541548800000, "tmdate": 1545352979047, "tddate": null, "super": null, "final": null, "reply": {"forum": "S1eVe2AqKX", "replyto": "S1eVe2AqKX", "readers": {"description": "Select all user groups that should be able to read this comment. Selecting 'All Users' will allow paper authors, reviewers, area chairs, and program chairs to view this comment.", "values": ["everyone"]}, "signatures": {"description": "How your identity will be displayed with the above content.", "values-regex": "ICLR.cc/2019/Conference/Paper1069/Area_Chair[0-9]+"}, "writers": {"description": "Users that may modify this record.", "values-regex": "ICLR.cc/2019/Conference/Paper1069/Area_Chair[0-9]+"}, "content": {"title": {"order": 1, "value-regex": ".{1,500}", "description": "Brief summary of your review.", "required": true}, "metareview": {"order": 2, "value-regex": "[\\S\\s]{1,5000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "required": true}, "recommendation": {"order": 3, "value-dropdown": ["Accept (Oral)", "Accept (Poster)", "Reject"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The area chair is absolutely certain", "4: The area chair is confident but not absolutely certain", "3: The area chair is somewhat confident", "2: The area chair is not sure", "1: The area chair's evaluation is an educated guess"], "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper1069/Area_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": false, "taskCompletionCount": null, "transform": null, "cdate": 1545352979047}}}, {"id": "HylkPTJ0hX", "original": null, "number": 3, "cdate": 1541434711345, "ddate": null, "tcdate": 1541434711345, "tmdate": 1541533450036, "tddate": null, "forum": "S1eVe2AqKX", "replyto": "S1eVe2AqKX", "invitation": "ICLR.cc/2019/Conference/-/Paper1069/Official_Review", "content": {"title": "Simple Idea, Good Results But Novelty? Detailed Analysis?", "review": "The paper proposes a simple idea to calibrate probabilities outputted by a CNN model to adapt easily to environments where class distributions change with space and time (and are often skewed). The paper shows that such a simple approach is sufficient to get good accuracies without requiring any costly retraining or transfer learning. Thereby proving to give benefits in terms of resource consumption and at the same time giving better results than the state of the art.\n\nHowever, \nA] The proposed calibration doesn't take any CNN specific details into consideration, rather it is a general calibration method which was also proposed in Saerens et. al, 2002 (cited in the paper). It is unclear why the paper specifically talks about CNN.\nB] The proposed Class Skew Detector is a simple method. Change-point detection is a well-studied area. The paper lacks a literature review in this area and a reasoning of why the proposed approach is preferred. Also, an independent analysis of how the class skew detector behaves in the face of rapidly changing class skews versus slow changing class skews is warranted here. Particularly, given that the paper proposes to use this approaches in mobile which may work in both rapid and slow changing class skews.\nC] The Class Skew Detector is dependent on the base model. Thus, it is also likely that the empirical distribution estimated is biased and yet the final accuracies reported are much higher than the base model accuracies. There is something interesting happening here. An analysis of the robustness of the proposed approach in the face of noisy class skew detection could potentially make this paper a stronger work.\nD] The analysis in the paper has largely focused on pre-trained models. However, another analysis that could have been useful here is, varying the quality of the classifier (e.g. classifier trained on skewed training data vs. balanced training data) and measuring how the quality of the classifier correlates with the final performance. Maybe even attempt to answer the question \"which classifiers are likely to work with this approach?\" In fact, this analysis can be either done in a general context of any classifier or just CNN's and identifying whether certain properties of CNN help in getting better performance.\n\nThe paper lacks novelty and at the same time, it is not quite compensating that with a detailed analysis of the work. The problem is interesting and I like the work because the approach is simple and the results look good. I think with a stronger focus on more detailed analysis, this can be a good submission to an applied conference like MobiCom etc.\n\nBy the way, the paper is riddled with several spelling errors - \n\"filed\" -> \"field\", page 1, second paragraph, last line\n\"complimentary\" -> \"complementary\", page 2, section 2, paragraph 1, last line\n\"epoches\" -> \"epochs\", page 2, section 2, transfer learning, second paragraph, second last line\n\"CNNs does not use\" -> \"CNNs do not use\", page 3, section 3, intuition, first paragraph, first line\n\"formular\" -> \"formula\", page 4, above equation 4\nEquation 4 has a typo in the denominator, P_t(i) should be P_t(j), same with Equation 5\n\"obstained\" -> \"obtained\", page 7, second paragraph, first line\n\"adaptation\" is almost everywhere spelled as \"adaption\"", "rating": "4: Ok but not good enough - rejection", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["ICLR.cc/2019/Conference/Paper1069/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "PCNN: Environment Adaptive Model Without Finetuning", "abstract": "Convolutional Neural Networks (CNNs) have achieved tremendous success for many computer vision tasks, which shows a promising perspective of deploying CNNs on mobile platforms. An obstacle to this promising perspective is the tension between intensive resource consumption of CNNs and limited resource budget on mobile platforms. Existing works generally utilize a simpler architecture with lower accuracy for a higher energy-efficiency, \\textit{i.e.}, trading accuracy for resource consumption. An emerging opportunity to both increasing accuracy and decreasing resource consumption is \\textbf{class skew}, \\textit{i.e.}, the strong temporal and spatial locality of the appearance of classes. However, it is challenging to efficiently utilize the class skew due to both the frequent switches and the huge number of class skews. Existing works use transfer learning to adapt the model towards the class skew during runtime, which consumes resource intensively. In this paper, we propose \\textbf{probability layer}, an \\textit{easily-implemented and highly flexible add-on module} to adapt the model efficiently during runtime \\textit{without any fine-tuning} and achieving an \\textit{equivalent or better} performance than transfer learning. Further, both \\textit{increasing accuracy} and \\textit{decreasing resource consumption} can be achieved during runtime through the combination of probability layer and pruning methods.", "keywords": ["Class skew", "Runtime adaption"], "authorids": ["boyuan@cs.ucsb.edu", "kun@cs.ucsb.edu", "shuyang1995@ucsb.edu", "yufeiding@cs.ucsb.edu"], "authors": ["Boyuan Feng", "Kun Wan", "Shu Yang", "Yufei Ding"], "pdf": "/pdf/0433eaef5167e45b9043bdbdd544454d1fba6239.pdf", "paperhash": "feng|pcnn_environment_adaptive_model_without_finetuning", "_bibtex": "@misc{\nfeng2019pcnn,\ntitle={{PCNN}: Environment Adaptive Model Without Finetuning},\nauthor={Boyuan Feng and Kun Wan and Shu Yang and Yufei Ding},\nyear={2019},\nurl={https://openreview.net/forum?id=S1eVe2AqKX},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper1069/Official_Review", "cdate": 1542234313095, "expdate": 1552335264000, "duedate": 1541196000000, "reply": {"forum": "S1eVe2AqKX", "replyto": "S1eVe2AqKX", "readers": {"description": "The users who will be allowed to read the reply content.", "values": ["everyone"]}, "nonreaders": {"values": []}, "signatures": {"description": "How your identity will be displayed with the above content.", "values-regex": "ICLR.cc/2019/Conference/Paper1069/AnonReviewer[0-9]+"}, "writers": {"description": "Users that may modify this record.", "values": ["ICLR.cc/2019/Conference"]}, "content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "required": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}}, "multiReply": false, "tcdate": 1552335865963, "tmdate": 1552335865963, "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "invitees": ["ICLR.cc/2019/Conference/Paper1069/Reviewers"], "noninvitees": [], "signatures": ["ICLR.cc/2019/Conference"]}}}, {"id": "S1glW4P5hX", "original": null, "number": 2, "cdate": 1541202935961, "ddate": null, "tcdate": 1541202935961, "tmdate": 1541533449790, "tddate": null, "forum": "S1eVe2AqKX", "replyto": "S1eVe2AqKX", "invitation": "ICLR.cc/2019/Conference/-/Paper1069/Official_Review", "content": {"title": "No technical contribution, Heuristic solution", "review": "This paper proposed a way to detect a skew in the distribution of classes in a stream of images and reweight the class priors accordingly, to estimate the final posterior probabilities of present classes. This probability re-calibration is referred to as the probability layer. A simple algorithm is proposed to detect the class distribution skew. The proposed benefit of this method is that they do not require fine-tuning any network parameters using newly skewed data. \n\nOverall the method is quite simple and heuristic. The technical contribution - i) updating class priors online ii) detecting class skews, is marginal. \n\nThe evaluation is performed on a contrived setting of skewed imagenet images. I would have liked to see some evaluation on video stream data where the skews are more natural. \n\nIn real scenarios, the class specific appearances P_{X|Y}(x|i) as well as class distributions P_Y(i) change online. The method seems incapable to handle such problems.  In these situations, there is no simple fix, and one needs to resort to transfer.\n ", "rating": "3: Clear rejection", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["ICLR.cc/2019/Conference/Paper1069/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "PCNN: Environment Adaptive Model Without Finetuning", "abstract": "Convolutional Neural Networks (CNNs) have achieved tremendous success for many computer vision tasks, which shows a promising perspective of deploying CNNs on mobile platforms. An obstacle to this promising perspective is the tension between intensive resource consumption of CNNs and limited resource budget on mobile platforms. Existing works generally utilize a simpler architecture with lower accuracy for a higher energy-efficiency, \\textit{i.e.}, trading accuracy for resource consumption. An emerging opportunity to both increasing accuracy and decreasing resource consumption is \\textbf{class skew}, \\textit{i.e.}, the strong temporal and spatial locality of the appearance of classes. However, it is challenging to efficiently utilize the class skew due to both the frequent switches and the huge number of class skews. Existing works use transfer learning to adapt the model towards the class skew during runtime, which consumes resource intensively. In this paper, we propose \\textbf{probability layer}, an \\textit{easily-implemented and highly flexible add-on module} to adapt the model efficiently during runtime \\textit{without any fine-tuning} and achieving an \\textit{equivalent or better} performance than transfer learning. Further, both \\textit{increasing accuracy} and \\textit{decreasing resource consumption} can be achieved during runtime through the combination of probability layer and pruning methods.", "keywords": ["Class skew", "Runtime adaption"], "authorids": ["boyuan@cs.ucsb.edu", "kun@cs.ucsb.edu", "shuyang1995@ucsb.edu", "yufeiding@cs.ucsb.edu"], "authors": ["Boyuan Feng", "Kun Wan", "Shu Yang", "Yufei Ding"], "pdf": "/pdf/0433eaef5167e45b9043bdbdd544454d1fba6239.pdf", "paperhash": "feng|pcnn_environment_adaptive_model_without_finetuning", "_bibtex": "@misc{\nfeng2019pcnn,\ntitle={{PCNN}: Environment Adaptive Model Without Finetuning},\nauthor={Boyuan Feng and Kun Wan and Shu Yang and Yufei Ding},\nyear={2019},\nurl={https://openreview.net/forum?id=S1eVe2AqKX},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper1069/Official_Review", "cdate": 1542234313095, "expdate": 1552335264000, "duedate": 1541196000000, "reply": {"forum": "S1eVe2AqKX", "replyto": "S1eVe2AqKX", "readers": {"description": "The users who will be allowed to read the reply content.", "values": ["everyone"]}, "nonreaders": {"values": []}, "signatures": {"description": "How your identity will be displayed with the above content.", "values-regex": "ICLR.cc/2019/Conference/Paper1069/AnonReviewer[0-9]+"}, "writers": {"description": "Users that may modify this record.", "values": ["ICLR.cc/2019/Conference"]}, "content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "required": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}}, "multiReply": false, "tcdate": 1552335865963, "tmdate": 1552335865963, "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "invitees": ["ICLR.cc/2019/Conference/Paper1069/Reviewers"], "noninvitees": [], "signatures": ["ICLR.cc/2019/Conference"]}}}, {"id": "SkgZr2nwh7", "original": null, "number": 1, "cdate": 1541028920596, "ddate": null, "tcdate": 1541028920596, "tmdate": 1541533449574, "tddate": null, "forum": "S1eVe2AqKX", "replyto": "S1eVe2AqKX", "invitation": "ICLR.cc/2019/Conference/-/Paper1069/Official_Review", "content": {"title": "Review", "review": "The idea proposed in this paper is to improve classification accuracy by making use of the context.\nE.g. on the north pole we will see polar bears but no penguins, on Antartica we have no polar bears but many penguins.\nHence, if we apply our imagenet-like classifier in the wild, we can improve accuracy by taking into account changes in the prior distribution.\n\nThe paper proposes a way to rescale the probabilities to do exactly this and reports improved results on modified versions of \n CIFAR 10 and imagenet with artificial class skew. To achieve this, an additional trick is introduced where the re-scaling is only used when the model is not very certain of its prediction. And additional motivation for this work is that less compute resources are needed if the problem is simplified by utilizing class skew. \n\nThe core idea of the paper is interesting. However, I am not able to understand what exactly is done and I am 100% confident I cannot re-implement it. The authors already improved upon this in our interactions prior to the review deadline. \nAn additional issue is that the paper does not have a good baseline. \nI would not like to dismiss the approach based on its simplicity. An elegant solution is always preferred. However, all the tasks are quite artificial and this limits the \"impact\" of this work. If an \"natural\" application/evaluation where this approach would be possible, it would strengthen the paper greatly. \n\nFor the reasons above I recommend rejection of the manuscript in the current state but I am confident that many of these issues can be resolved easily and if this is done I will update the review.\n\nMissing information\n----------------------------\n- The original manuscript had a lot of information missing, but much of it has since been provided by the authors.\n- In the static class skew experiment, were two passes over the data needed? Or was the Pt(i) pre-set? Would it also be possible to give details about LR, optimizer, LR schedule, batch size, .... for the transfer learning experiments. This would enhance reproducibility. \n- For the imagenet experiments how was Pt(i) set in the if I assume correctly, static setting.\n\nPossible additional baselines:\n-----------------------------------------\n\nWe could make a simpler rescaling by changing the prior distribution and assuming everything else remains constant.\nWhile this is a simplifying assumption, it is very easy to implement and should take only a couple of minutes to run. \nP(i|x)=1/P(X)*P(X|i)*P(i)\nPt(i|x)=P(i|x)*Pt(i)/P(i)\n\nOne could also introduce another baseline where only the most probably classes are considered. Since this approach is clearly sub-optimal since it guarantees some mis-predictions it should serve as a lower bound on the performance that is to be expected. \n", "rating": "4: Ok but not good enough - rejection", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["ICLR.cc/2019/Conference/Paper1069/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "PCNN: Environment Adaptive Model Without Finetuning", "abstract": "Convolutional Neural Networks (CNNs) have achieved tremendous success for many computer vision tasks, which shows a promising perspective of deploying CNNs on mobile platforms. An obstacle to this promising perspective is the tension between intensive resource consumption of CNNs and limited resource budget on mobile platforms. Existing works generally utilize a simpler architecture with lower accuracy for a higher energy-efficiency, \\textit{i.e.}, trading accuracy for resource consumption. An emerging opportunity to both increasing accuracy and decreasing resource consumption is \\textbf{class skew}, \\textit{i.e.}, the strong temporal and spatial locality of the appearance of classes. However, it is challenging to efficiently utilize the class skew due to both the frequent switches and the huge number of class skews. Existing works use transfer learning to adapt the model towards the class skew during runtime, which consumes resource intensively. In this paper, we propose \\textbf{probability layer}, an \\textit{easily-implemented and highly flexible add-on module} to adapt the model efficiently during runtime \\textit{without any fine-tuning} and achieving an \\textit{equivalent or better} performance than transfer learning. Further, both \\textit{increasing accuracy} and \\textit{decreasing resource consumption} can be achieved during runtime through the combination of probability layer and pruning methods.", "keywords": ["Class skew", "Runtime adaption"], "authorids": ["boyuan@cs.ucsb.edu", "kun@cs.ucsb.edu", "shuyang1995@ucsb.edu", "yufeiding@cs.ucsb.edu"], "authors": ["Boyuan Feng", "Kun Wan", "Shu Yang", "Yufei Ding"], "pdf": "/pdf/0433eaef5167e45b9043bdbdd544454d1fba6239.pdf", "paperhash": "feng|pcnn_environment_adaptive_model_without_finetuning", "_bibtex": "@misc{\nfeng2019pcnn,\ntitle={{PCNN}: Environment Adaptive Model Without Finetuning},\nauthor={Boyuan Feng and Kun Wan and Shu Yang and Yufei Ding},\nyear={2019},\nurl={https://openreview.net/forum?id=S1eVe2AqKX},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper1069/Official_Review", "cdate": 1542234313095, "expdate": 1552335264000, "duedate": 1541196000000, "reply": {"forum": "S1eVe2AqKX", "replyto": "S1eVe2AqKX", "readers": {"description": "The users who will be allowed to read the reply content.", "values": ["everyone"]}, "nonreaders": {"values": []}, "signatures": {"description": "How your identity will be displayed with the above content.", "values-regex": "ICLR.cc/2019/Conference/Paper1069/AnonReviewer[0-9]+"}, "writers": {"description": "Users that may modify this record.", "values": ["ICLR.cc/2019/Conference"]}, "content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "required": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}}, "multiReply": false, "tcdate": 1552335865963, "tmdate": 1552335865963, "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "invitees": ["ICLR.cc/2019/Conference/Paper1069/Reviewers"], "noninvitees": [], "signatures": ["ICLR.cc/2019/Conference"]}}}, {"id": "HJl1rrQdnX", "original": null, "number": 5, "cdate": 1541055799201, "ddate": null, "tcdate": 1541055799201, "tmdate": 1541055799201, "tddate": null, "forum": "S1eVe2AqKX", "replyto": "r1eLxATDhm", "invitation": "ICLR.cc/2019/Conference/-/Paper1069/Official_Comment", "content": {"title": "Clarification on section 4.", "comment": "Dear reviewer:\n\nThanks for your comment!  (This clarification could be better read in pdf version (https://drive.google.com/file/d/17wFjCrhnNjcoIeV5v537gvcw9bH3KekX/view?usp=sharing) due to latex equations.)\n\n\nWe estimate $P_t(i)$ with the \\textit{empirical class distribution} [1] in a short time window (every $\\omega_{min}$). In algorithm 1, $y_t$ indicates the prediction result for the $t$-th input frame classified by the model $h(\\cdot)$. $S_j$ indicates the empirical distribution in the $j$-th time window (the utilization of time window will be justified in \\textbf{Assumption} paragraph) and $\\oplus$ indicates the concatenation of two distributions. $S_j \\leftarrow S_j \\oplus [y_t]$ means that every new prediction result $y_t$ will be incorporated into the \\textit{empirical class distribution} $S_j$ composed by all $\\omega_{min}$ predictions, which will be computed as following:\n\\begin{equation}\n  S_j(i) = \\frac{1}{\\omega_{min}} \\sum_{t=1}^{\\omega_{min}}\\mathbbm{1}_{y_t \\leq i}    \n\\end{equation}\n. The $P_t(i)$ can be derived from empirical class distribution $S_j(i)$ by \n\\begin{equation}\n    P_t(i) = S_j(i) - S_j(i-1)\n\\end{equation}\n\n\nThe if statement of $|| S_{j-1}, S_j|| \\leq \\pi_r$ is proposed for detecting the switch of class skew, as detailed in the following.\n\n\n\\paragraph{Assumption.}As described in the first paragraph of section 4, the only assumption we hold is that the class skew in a scenario remains unchanged. Formally, let assume the existence of a partition (scenario for a class skew) $\\pi: N^+ \\rightarrow N^+$ over the input stream, where $\\pi(t)$ refers to the class skew that $t$-th image belongs to. Here, each partition maintains a distribution $T_{\\pi(t)}$ and the image $(x_t, y_t)$ is drawn randomly (\\textit{i.i.d.}) from distribution $T_{\\pi(t)}$. Here, the overall series is composed by a sequence of abruptly-changing partitions and the distribution within each partition remains same. This is a very weak but realistic assumption, since we do not have any other assumptions on how long a stationary distribution exists. Thus our proposed algorithm needs to not only detect the underlying distribution $T_{\\pi(t)}$ ($P_t(i)$ is the probability of each class $i$ in the distribution $T_{\\pi(t)}$), but also recognize the start time and end time for each partition $\\pi(t)$ (class skew) in an untrimmed streams of data.\n\n\\paragraph{Proposed approach.}As described in the second paragraph of section 4, we propose a windowed class skew detector to approximate the underlying distribution, as well as the start time and end time for each partition $\\pi(t)$ (class skew). Here, the empirical distribution $S_j$ in each window $j$ can be obtained to estimate the $P_t(i)$. Furher, the start time and end time of each partition $\\pi(t)$ (class skew) can be decided when there is a dramatic change in empirical class distributions $S_{j-1}$ and $S_{j}$ from adjacent windows $j-1$ and $j$. A dramatic change is decided when\n\\begin{equation}\n  \\underset{i}{\\text{sup}} | S_{j}(i) - S_{j-1}(i) | \\geq \\frac{\\pi_r}{\\omega_{min}}\n\\end{equation}\n, where $\\omega_{min} = 30$ and $\\pi_r = 2$ in our evaluations.\n\n\\paragraph{Edge case when class skew switches.}Our proposed probability layer can handle the edge case, \\textit{i.e.}, a small turbulence to class skew has happened. For example, $10$ people stays in a lab and a stranger suddenly visits. This edge case is handled by the weak class skew (p<1) in our evaluation section.\n\nWe apologize for not providing enough detail for the Algorithm 1. We will revise it in our final version.\n\n\\begin{wrapfigure}{R}{0.35\\textwidth}\n    \\begin{minipage}{0.35\\textwidth}\n      \\begin{algorithm}[H]\n        \\caption{CSD algorithm}\n        \\begin{algorithmic}\n            \\Function{CSD}{$ $} \\label{alg: WEG}\n                \\For{$t$ in $1, ..., w_{min}$}\n                    \\State $y_t \\leftarrow h(t)$\n                    \\State $S_j \\leftarrow S_j \\oplus [y_t]$\n                \\EndFor\n                \\If{$|| S_{j-1}, S_j|| \\leq \\pi_r$}\n                    \\State $S_j \\leftarrow S_{j-1} \\oplus S_j$\n                \\EndIf\n                \\State \\Return $S_j$\n            \\EndFunction\n        \\end{algorithmic}\n         \\label{alg: algorithm}\n      \\end{algorithm}\n    \\end{minipage}\n\\end{wrapfigure}\n\n[1]  J. Shao.Mathematical Statistics. Springer Texts in Statistics. Springer, 2003.\n"}, "signatures": ["ICLR.cc/2019/Conference/Paper1069/Authors"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper1069/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper1069/Authors", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "PCNN: Environment Adaptive Model Without Finetuning", "abstract": "Convolutional Neural Networks (CNNs) have achieved tremendous success for many computer vision tasks, which shows a promising perspective of deploying CNNs on mobile platforms. An obstacle to this promising perspective is the tension between intensive resource consumption of CNNs and limited resource budget on mobile platforms. Existing works generally utilize a simpler architecture with lower accuracy for a higher energy-efficiency, \\textit{i.e.}, trading accuracy for resource consumption. An emerging opportunity to both increasing accuracy and decreasing resource consumption is \\textbf{class skew}, \\textit{i.e.}, the strong temporal and spatial locality of the appearance of classes. However, it is challenging to efficiently utilize the class skew due to both the frequent switches and the huge number of class skews. Existing works use transfer learning to adapt the model towards the class skew during runtime, which consumes resource intensively. In this paper, we propose \\textbf{probability layer}, an \\textit{easily-implemented and highly flexible add-on module} to adapt the model efficiently during runtime \\textit{without any fine-tuning} and achieving an \\textit{equivalent or better} performance than transfer learning. Further, both \\textit{increasing accuracy} and \\textit{decreasing resource consumption} can be achieved during runtime through the combination of probability layer and pruning methods.", "keywords": ["Class skew", "Runtime adaption"], "authorids": ["boyuan@cs.ucsb.edu", "kun@cs.ucsb.edu", "shuyang1995@ucsb.edu", "yufeiding@cs.ucsb.edu"], "authors": ["Boyuan Feng", "Kun Wan", "Shu Yang", "Yufei Ding"], "pdf": "/pdf/0433eaef5167e45b9043bdbdd544454d1fba6239.pdf", "paperhash": "feng|pcnn_environment_adaptive_model_without_finetuning", "_bibtex": "@misc{\nfeng2019pcnn,\ntitle={{PCNN}: Environment Adaptive Model Without Finetuning},\nauthor={Boyuan Feng and Kun Wan and Shu Yang and Yufei Ding},\nyear={2019},\nurl={https://openreview.net/forum?id=S1eVe2AqKX},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper1069/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621625333, "tddate": null, "super": null, "final": null, "reply": {"forum": "S1eVe2AqKX", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper1069/Authors", "ICLR.cc/2019/Conference/Paper1069/Reviewers", "ICLR.cc/2019/Conference/Paper1069/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper1069/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper1069/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper1069/Authors|ICLR.cc/2019/Conference/Paper1069/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper1069/Reviewers", "ICLR.cc/2019/Conference/Paper1069/Authors", "ICLR.cc/2019/Conference/Paper1069/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621625333}}}, {"id": "r1eLxATDhm", "original": null, "number": 4, "cdate": 1541033453640, "ddate": null, "tcdate": 1541033453640, "tmdate": 1541033453640, "tddate": null, "forum": "S1eVe2AqKX", "replyto": "Syen8Xawn7", "invitation": "ICLR.cc/2019/Conference/-/Paper1069/Official_Comment", "content": {"title": "Thanks for this response", "comment": "Thanks for this response, \n\nCan you also expand on section 4. The notation used in algorithm 1 is not detailed. \nWhat is of particular interest is how Pt(i) is computed."}, "signatures": ["ICLR.cc/2019/Conference/Paper1069/AnonReviewer3"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper1069/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper1069/AnonReviewer3", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "PCNN: Environment Adaptive Model Without Finetuning", "abstract": "Convolutional Neural Networks (CNNs) have achieved tremendous success for many computer vision tasks, which shows a promising perspective of deploying CNNs on mobile platforms. An obstacle to this promising perspective is the tension between intensive resource consumption of CNNs and limited resource budget on mobile platforms. Existing works generally utilize a simpler architecture with lower accuracy for a higher energy-efficiency, \\textit{i.e.}, trading accuracy for resource consumption. An emerging opportunity to both increasing accuracy and decreasing resource consumption is \\textbf{class skew}, \\textit{i.e.}, the strong temporal and spatial locality of the appearance of classes. However, it is challenging to efficiently utilize the class skew due to both the frequent switches and the huge number of class skews. Existing works use transfer learning to adapt the model towards the class skew during runtime, which consumes resource intensively. In this paper, we propose \\textbf{probability layer}, an \\textit{easily-implemented and highly flexible add-on module} to adapt the model efficiently during runtime \\textit{without any fine-tuning} and achieving an \\textit{equivalent or better} performance than transfer learning. Further, both \\textit{increasing accuracy} and \\textit{decreasing resource consumption} can be achieved during runtime through the combination of probability layer and pruning methods.", "keywords": ["Class skew", "Runtime adaption"], "authorids": ["boyuan@cs.ucsb.edu", "kun@cs.ucsb.edu", "shuyang1995@ucsb.edu", "yufeiding@cs.ucsb.edu"], "authors": ["Boyuan Feng", "Kun Wan", "Shu Yang", "Yufei Ding"], "pdf": "/pdf/0433eaef5167e45b9043bdbdd544454d1fba6239.pdf", "paperhash": "feng|pcnn_environment_adaptive_model_without_finetuning", "_bibtex": "@misc{\nfeng2019pcnn,\ntitle={{PCNN}: Environment Adaptive Model Without Finetuning},\nauthor={Boyuan Feng and Kun Wan and Shu Yang and Yufei Ding},\nyear={2019},\nurl={https://openreview.net/forum?id=S1eVe2AqKX},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper1069/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621625333, "tddate": null, "super": null, "final": null, "reply": {"forum": "S1eVe2AqKX", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper1069/Authors", "ICLR.cc/2019/Conference/Paper1069/Reviewers", "ICLR.cc/2019/Conference/Paper1069/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper1069/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper1069/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper1069/Authors|ICLR.cc/2019/Conference/Paper1069/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper1069/Reviewers", "ICLR.cc/2019/Conference/Paper1069/Authors", "ICLR.cc/2019/Conference/Paper1069/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621625333}}}, {"id": "Syen8Xawn7", "original": null, "number": 3, "cdate": 1541030740022, "ddate": null, "tcdate": 1541030740022, "tmdate": 1541031110969, "tddate": null, "forum": "S1eVe2AqKX", "replyto": "SkgDx7nD3X", "invitation": "ICLR.cc/2019/Conference/-/Paper1069/Official_Comment", "content": {"title": "Clarification on the transition from euqation 3 to equation 4", "comment": "Dear reviewer,\n\nThanks for your comment! There is a small typo in equation 4, which has no influence over other parts in our paper. (This clarification could be better read in pdf version (https://drive.google.com/file/d/1M1t0CjZWmcolfELb-kkqKVWtcqR9A6mg/view?usp=sharing) due to latex equations.)\n\nInstead of \n\\begin{equation*}\n    P_t(i|X) = \\frac{\\frac{P_t(i)}{P(i)} \\cdot P(i|X)}{\\sum_{j=1}^n \\frac{P_t(i)}{P(j)} \\cdot P(j|X)}\n\\end{equation*},\nit should be \n\\begin{align*}\n     P_t(i|X)  = \\frac{\\frac{P_t(i)}{P(i)} \\cdot P(i|X)}{\\sum_{j=1}^n \\frac{P_t(j)}{P(j)} \\cdot P(j|X)}\n\\end{align*}.\nNote the single $i$ in the denominator has been replaced by $j$.\n\nThe following is the detailed proof on the transition from equation 3 to equation 4.\n\nIn equation 3, we have $P_t(i|X) = \\frac{P_t(i)}{P(i)} \\cdot \\frac{P(X)}{P_t(X)} \\cdot P(i|X)$. We also have $\\sum_{i=1}^n P_t(i|X) = 1$, based on the property of probability. Together, we can find that \n\\begin{align*}\n    1 & = \\sum_{i=1}^n P_t(i|X) \\\\\n      & = \\sum_{i=1}^n\\frac{P_t(i)}{P(i)} \\cdot \\frac{P(X)}{P_t(X)} \\cdot P(i|X) \\\\\n      & = \\frac{P(X)}{P_t(X)} \\cdot \\sum_{i=1}^n \\frac{P_t(i)}{P(i)} \\cdot P(i|X)\n\\end{align*}\nThe second equality holds by using equation 3. The third equality holds since $\\frac{P(X)}{P_t(X)}$ does not change over $i$.\n\nThus, we can have\n\\begin{align*}\n    \\frac{P(X)}{P_t(X)} & = \\frac{1}{\\sum_{i=1}^n \\frac{P_t(i)}{P(i)} \\cdot P(i|X)}   \\\\ \n                        & = \\frac{1}{\\sum_{j=1}^n \\frac{P_t(j)}{P(j)} \\cdot P(j|X)}\n\\end{align*}\nThe second equality holds since every $i$ has been replaced with $j$. We conduct this replacement to avoid confusement with $i$ used in equation 3 and equation 4.\n\nUse this equation to replace $\\frac{P(X)}{P_t(X)}$ in equation 3, we can get\n\\begin{align*}\n    P_t(i|X) & =  \\frac{P_t(i)}{P(i)} \\cdot P(i|X) \\cdot \\frac{P(X)}{P_t(X)} \\\\\n             & = \\frac{P_t(i)}{P(i)} \\cdot P(i|X) \\cdot \\frac{1}{\\sum_{j=1}^n \\frac{P_t(j)}{P(j)} \\cdot P(j|X)} \\\\\n             & = \\frac{\\frac{P_t(i)}{P(i)} \\cdot P(i|X)}{\\sum_{j=1}^n \\frac{P_t(j)}{P(j)} \\cdot P(j|X)}\n\\end{align*}\n"}, "signatures": ["ICLR.cc/2019/Conference/Paper1069/Authors"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper1069/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper1069/Authors", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "PCNN: Environment Adaptive Model Without Finetuning", "abstract": "Convolutional Neural Networks (CNNs) have achieved tremendous success for many computer vision tasks, which shows a promising perspective of deploying CNNs on mobile platforms. An obstacle to this promising perspective is the tension between intensive resource consumption of CNNs and limited resource budget on mobile platforms. Existing works generally utilize a simpler architecture with lower accuracy for a higher energy-efficiency, \\textit{i.e.}, trading accuracy for resource consumption. An emerging opportunity to both increasing accuracy and decreasing resource consumption is \\textbf{class skew}, \\textit{i.e.}, the strong temporal and spatial locality of the appearance of classes. However, it is challenging to efficiently utilize the class skew due to both the frequent switches and the huge number of class skews. Existing works use transfer learning to adapt the model towards the class skew during runtime, which consumes resource intensively. In this paper, we propose \\textbf{probability layer}, an \\textit{easily-implemented and highly flexible add-on module} to adapt the model efficiently during runtime \\textit{without any fine-tuning} and achieving an \\textit{equivalent or better} performance than transfer learning. Further, both \\textit{increasing accuracy} and \\textit{decreasing resource consumption} can be achieved during runtime through the combination of probability layer and pruning methods.", "keywords": ["Class skew", "Runtime adaption"], "authorids": ["boyuan@cs.ucsb.edu", "kun@cs.ucsb.edu", "shuyang1995@ucsb.edu", "yufeiding@cs.ucsb.edu"], "authors": ["Boyuan Feng", "Kun Wan", "Shu Yang", "Yufei Ding"], "pdf": "/pdf/0433eaef5167e45b9043bdbdd544454d1fba6239.pdf", "paperhash": "feng|pcnn_environment_adaptive_model_without_finetuning", "_bibtex": "@misc{\nfeng2019pcnn,\ntitle={{PCNN}: Environment Adaptive Model Without Finetuning},\nauthor={Boyuan Feng and Kun Wan and Shu Yang and Yufei Ding},\nyear={2019},\nurl={https://openreview.net/forum?id=S1eVe2AqKX},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper1069/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621625333, "tddate": null, "super": null, "final": null, "reply": {"forum": "S1eVe2AqKX", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper1069/Authors", "ICLR.cc/2019/Conference/Paper1069/Reviewers", "ICLR.cc/2019/Conference/Paper1069/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper1069/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper1069/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper1069/Authors|ICLR.cc/2019/Conference/Paper1069/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper1069/Reviewers", "ICLR.cc/2019/Conference/Paper1069/Authors", "ICLR.cc/2019/Conference/Paper1069/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621625333}}}, {"id": "SkgDx7nD3X", "original": null, "number": 1, "cdate": 1541026542777, "ddate": null, "tcdate": 1541026542777, "tmdate": 1541026542777, "tddate": null, "forum": "S1eVe2AqKX", "replyto": "S1eVe2AqKX", "invitation": "ICLR.cc/2019/Conference/-/Paper1069/Official_Comment", "content": {"title": "Request for clarification", "comment": "Dear Authors,\n\nCould you please clarify the transition from equation 3 to equation 4. I do not understand how this step is made.\n\nIt would be helpful if you could clarify this before I submit the official review.\n\n"}, "signatures": ["ICLR.cc/2019/Conference/Paper1069/AnonReviewer3"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper1069/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper1069/AnonReviewer3", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "PCNN: Environment Adaptive Model Without Finetuning", "abstract": "Convolutional Neural Networks (CNNs) have achieved tremendous success for many computer vision tasks, which shows a promising perspective of deploying CNNs on mobile platforms. An obstacle to this promising perspective is the tension between intensive resource consumption of CNNs and limited resource budget on mobile platforms. Existing works generally utilize a simpler architecture with lower accuracy for a higher energy-efficiency, \\textit{i.e.}, trading accuracy for resource consumption. An emerging opportunity to both increasing accuracy and decreasing resource consumption is \\textbf{class skew}, \\textit{i.e.}, the strong temporal and spatial locality of the appearance of classes. However, it is challenging to efficiently utilize the class skew due to both the frequent switches and the huge number of class skews. Existing works use transfer learning to adapt the model towards the class skew during runtime, which consumes resource intensively. In this paper, we propose \\textbf{probability layer}, an \\textit{easily-implemented and highly flexible add-on module} to adapt the model efficiently during runtime \\textit{without any fine-tuning} and achieving an \\textit{equivalent or better} performance than transfer learning. Further, both \\textit{increasing accuracy} and \\textit{decreasing resource consumption} can be achieved during runtime through the combination of probability layer and pruning methods.", "keywords": ["Class skew", "Runtime adaption"], "authorids": ["boyuan@cs.ucsb.edu", "kun@cs.ucsb.edu", "shuyang1995@ucsb.edu", "yufeiding@cs.ucsb.edu"], "authors": ["Boyuan Feng", "Kun Wan", "Shu Yang", "Yufei Ding"], "pdf": "/pdf/0433eaef5167e45b9043bdbdd544454d1fba6239.pdf", "paperhash": "feng|pcnn_environment_adaptive_model_without_finetuning", "_bibtex": "@misc{\nfeng2019pcnn,\ntitle={{PCNN}: Environment Adaptive Model Without Finetuning},\nauthor={Boyuan Feng and Kun Wan and Shu Yang and Yufei Ding},\nyear={2019},\nurl={https://openreview.net/forum?id=S1eVe2AqKX},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper1069/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621625333, "tddate": null, "super": null, "final": null, "reply": {"forum": "S1eVe2AqKX", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper1069/Authors", "ICLR.cc/2019/Conference/Paper1069/Reviewers", "ICLR.cc/2019/Conference/Paper1069/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper1069/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper1069/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper1069/Authors|ICLR.cc/2019/Conference/Paper1069/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper1069/Reviewers", "ICLR.cc/2019/Conference/Paper1069/Authors", "ICLR.cc/2019/Conference/Paper1069/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621625333}}}], "count": 9}