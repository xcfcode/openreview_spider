{"notes": [{"tddate": null, "replyto": null, "ddate": null, "tmdate": 1528124446352, "tcdate": 1518469150357, "number": 266, "cdate": 1518469150357, "id": "SJUXltkvM", "invitation": "ICLR.cc/2018/Workshop/-/Submission", "forum": "SJUXltkvM", "signatures": ["~Fei_Wang1"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Workshop"], "content": {"title": "From Gameplay to Symbolic Reasoning", "abstract": "Despite the recent successes of deep neural networks in various fields such as image and speech recognition, natural language processing, and reinforcement learning, we still face big challenges bringing the power of numeric optimization to\nsymbolic reasoning. Researchers have proposed different avenues such as neural machine translation for proof synthesis, vectorization of symbols and expressions for representing symbolic patterns, and coupling of neural back-ends for dimensionality reduction with symbolic front-ends for decision making. However, these initial explorations are still only point solutions, and bear other shortcomings such as lack of correctness guarantees. In this paper, we present our approach of casting symbolic reasoning as games, and directly harnessing the power of deep reinforcement learning in the style of Alpha(Go) Zero on symbolic problems. Using the Boolean Satisfiability (SAT) problem as showcase, we demonstrate the feasibility of our method, and the advantages of modularity, efficiency, and correctness guarantees.", "paperhash": "wang|from_gameplay_to_symbolic_reasoning", "_bibtex": "@misc{\n  wang2018from,\n  title={From Gameplay to Symbolic Reasoning},\n  author={Fei Wang and Tiark Rompf},\n  year={2018},\n  url={https://openreview.net/forum?id=SJUXltkvM}\n}", "authorids": ["wang603@purdue.edu", "tiark@purdue.edu"], "authors": ["Fei Wang", "Tiark Rompf"], "keywords": ["deep reinforcement learning", "Alpha(Go) Zero", "symbolic reasoning", "gameplay", "SAT"], "pdf": "/pdf/1c3daa71ca777ae507bb211d2efabcd8de06e200.pdf"}, "nonreaders": [], "details": {"replyCount": 4, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1518472800000, "tmdate": 1518474081690, "id": "ICLR.cc/2018/Workshop/-/Submission", "writers": ["ICLR.cc/2018/Workshop"], "signatures": ["ICLR.cc/2018/Workshop"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": null, "replyto": null, "writers": {"values": ["ICLR.cc/2018/Workshop"]}, "signatures": {"values-regex": "~.*|ICLR.cc/2018/Workshop", "description": "Your authorized identity to be associated with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"pdf": {"required": true, "order": 9, "value-regex": "upload", "description": "Upload a PDF file that ends with .pdf"}, "title": {"required": true, "order": 1, "description": "Title of paper.", "value-regex": ".{1,250}"}, "abstract": {"required": true, "order": 8, "description": "Abstract of paper.", "value-regex": "[\\S\\s]{1,5000}"}, "authors": {"required": true, "order": 2, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of author names. Please provide real names; identities will be anonymized."}, "keywords": {"order": 6, "values-regex": "(^$)|[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of keywords."}, "TL;DR": {"required": false, "order": 7, "description": "\"Too Long; Didn't Read\": a short sentence describing your paper", "value-regex": "[^\\n]{0,500}"}, "authorids": {"required": true, "order": 3, "values-regex": "([a-z0-9_\\-\\.]{2,}@[a-z0-9_\\-\\.]{2,}\\.[a-z]{2,},){0,}([a-z0-9_\\-\\.]{2,}@[a-z0-9_\\-\\.]{2,}\\.[a-z]{2,})", "description": "Comma separated list of author email addresses, lowercased, in the same order as above. For authors with existing OpenReview accounts, please make sure that the provided email address(es) match those listed in the author's profile. Please provide real emails; identities will be anonymized."}}}, "nonreaders": [], "noninvitees": [], "expdate": 1526248800000, "cdate": 1518474081690}}}, {"tddate": null, "ddate": null, "original": null, "tmdate": 1521582989859, "tcdate": 1519566732857, "number": 1, "cdate": 1519566732857, "id": "ryS5JHlOM", "invitation": "ICLR.cc/2018/Workshop/-/Paper266/Official_Review", "forum": "SJUXltkvM", "replyto": "SJUXltkvM", "signatures": ["ICLR.cc/2018/Workshop/Paper266/AnonReviewer3"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Workshop/Paper266/AnonReviewer3"], "content": {"title": "Writing the rule-book of real-life \"games\" is the hard part!", "rating": "6: Marginally above acceptance threshold", "review": "This extended abstract proposes to approach symbolic problems with neural networks by formalizing problems as a games, and then using deep RL methods to teach a network to play the game. The idea is illustrated through the Boolean Satisfiability problem, where an AlphaGo-like system is shown to outperform deep Q learning and a heuristic method in terms of generalization to the test set.\n\nThe proposal is interesting, but I find it problematic for the following reason. To formulate a problem as a game, you must be able to formalize it well enough that you can exhasutively define the set of rules. However, the history of GOFAI suggests that, in most interesting real-life domains, experts are unable to craft such rules by hand, which is the main reason why the field eventually shifted to learning-based systems, such as neural networks. How would your approach scale up to, say, handling natural language--arguably a symbolic domain, but one where, despite centuries of trying, no linguist has ever come up with an exhaustive \"rulebook\". I would really like the authors to discuss this point.\n\nI assume most ICLR attenders will not be familiar with symbolic approaches to SAT. So, it would be good to describe how the problem is formulated in more details. Also, please give us a sense of how good MiniSAT is, with respect to other symbolic solvers: how impressive is it that AlphaGo outperforms it?\n\nFinally, it would be good to have (in an Appendix) more details on the deep RL systems and how they were trained.\n", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "From Gameplay to Symbolic Reasoning", "abstract": "Despite the recent successes of deep neural networks in various fields such as image and speech recognition, natural language processing, and reinforcement learning, we still face big challenges bringing the power of numeric optimization to\nsymbolic reasoning. Researchers have proposed different avenues such as neural machine translation for proof synthesis, vectorization of symbols and expressions for representing symbolic patterns, and coupling of neural back-ends for dimensionality reduction with symbolic front-ends for decision making. However, these initial explorations are still only point solutions, and bear other shortcomings such as lack of correctness guarantees. In this paper, we present our approach of casting symbolic reasoning as games, and directly harnessing the power of deep reinforcement learning in the style of Alpha(Go) Zero on symbolic problems. Using the Boolean Satisfiability (SAT) problem as showcase, we demonstrate the feasibility of our method, and the advantages of modularity, efficiency, and correctness guarantees.", "paperhash": "wang|from_gameplay_to_symbolic_reasoning", "_bibtex": "@misc{\n  wang2018from,\n  title={From Gameplay to Symbolic Reasoning},\n  author={Fei Wang and Tiark Rompf},\n  year={2018},\n  url={https://openreview.net/forum?id=SJUXltkvM}\n}", "authorids": ["wang603@purdue.edu", "tiark@purdue.edu"], "authors": ["Fei Wang", "Tiark Rompf"], "keywords": ["deep reinforcement learning", "Alpha(Go) Zero", "symbolic reasoning", "gameplay", "SAT"], "pdf": "/pdf/1c3daa71ca777ae507bb211d2efabcd8de06e200.pdf"}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1520657999000, "tmdate": 1521582989642, "id": "ICLR.cc/2018/Workshop/-/Paper266/Official_Review", "writers": ["ICLR.cc/2018/Workshop"], "signatures": ["ICLR.cc/2018/Workshop"], "readers": ["everyone"], "invitees": ["ICLR.cc/2018/Workshop/Paper266/Reviewers"], "noninvitees": ["ICLR.cc/2018/Workshop/Paper266/AnonReviewer3", "ICLR.cc/2018/Workshop/Paper266/AnonReviewer1", "ICLR.cc/2018/Workshop/Paper266/AnonReviewer2"], "reply": {"forum": "SJUXltkvM", "replyto": "SJUXltkvM", "writers": {"values-regex": "ICLR.cc/2018/Workshop/Paper266/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2018/Workshop/Paper266/AnonReviewer[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"required": true, "order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"required": true, "order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "value-regex": "[\\S\\s]{1,200000}"}, "rating": {"required": true, "order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"required": true, "order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1528433999000, "cdate": 1521582989642}}}, {"tddate": null, "ddate": null, "original": null, "tmdate": 1521582698818, "tcdate": 1520710222768, "number": 2, "cdate": 1520710222768, "id": "B1PLMnWtz", "invitation": "ICLR.cc/2018/Workshop/-/Paper266/Official_Review", "forum": "SJUXltkvM", "replyto": "SJUXltkvM", "signatures": ["ICLR.cc/2018/Workshop/Paper266/AnonReviewer1"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Workshop/Paper266/AnonReviewer1"], "content": {"title": "Nice ideas, but still preliminary in doing any kind of symbolic reasoning ", "rating": "7: Good paper, accept", "review": "The authors focus on the problem of learning symbolic reasoning from examples by deep neural networks. This sort of problem has been discussed for a way, and has received significant attention lately, as noted by the authors. The paper is thus quite relevant. It is well written and quite clear, packing quite a bit of material in a short space. \n\nThe solution presented by the authors is to learn to prove things by understanding the act of proving as a game where one tries to find policies that take one to a proof. In this analogy, to learn to prove is to learn a game, and the authors try recent algorithms focused on game learning to the setting of symbolic reasoning. This is an interesting approach and I think it is a promising path that deserves some attention.\n\nHowever, the paper has its weaknesses. For one thing, the experiments are interesting but very small; the authors acknowledge this and it is perhaps natural to have small experiments in preliminary work. But the problem is more serious: it seems to me that by learning SAT solving, the authors are just learning heuristics for SAT solvers. Now, it is not clear that heuristic learning means really \"symbolic reasoning learning\". Perhaps I missed something in this regard, but the text seems clear in its explanation.\n\nAlso, given that SAT solving is now highly advanced, getting to learn and test with SAT problems of some hundred variables seems frustratingly little to advance the cause of symbolic reasoning. And on top of that, it seems to me that the kind of reasoning that is learned here is always approximate reasoning (the authors say that reasoning is \"guaranteed to be correct\", but how can this be guaranteed...?), not exact reasoning. So the correct comparison here is with large approximate SAT solvers; in that case, do the learned policies win? This is something I urge the authors to try.\n\nOverall, I find the work relevant, well written, and with some original contributions. So it is worth publishing, but it is really very preliminary and may not work well in more testing. Significant work is still to be done here. \n\nFinally, there are some problems in the references with capitalization (atari, go).\n\n", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "From Gameplay to Symbolic Reasoning", "abstract": "Despite the recent successes of deep neural networks in various fields such as image and speech recognition, natural language processing, and reinforcement learning, we still face big challenges bringing the power of numeric optimization to\nsymbolic reasoning. Researchers have proposed different avenues such as neural machine translation for proof synthesis, vectorization of symbols and expressions for representing symbolic patterns, and coupling of neural back-ends for dimensionality reduction with symbolic front-ends for decision making. However, these initial explorations are still only point solutions, and bear other shortcomings such as lack of correctness guarantees. In this paper, we present our approach of casting symbolic reasoning as games, and directly harnessing the power of deep reinforcement learning in the style of Alpha(Go) Zero on symbolic problems. Using the Boolean Satisfiability (SAT) problem as showcase, we demonstrate the feasibility of our method, and the advantages of modularity, efficiency, and correctness guarantees.", "paperhash": "wang|from_gameplay_to_symbolic_reasoning", "_bibtex": "@misc{\n  wang2018from,\n  title={From Gameplay to Symbolic Reasoning},\n  author={Fei Wang and Tiark Rompf},\n  year={2018},\n  url={https://openreview.net/forum?id=SJUXltkvM}\n}", "authorids": ["wang603@purdue.edu", "tiark@purdue.edu"], "authors": ["Fei Wang", "Tiark Rompf"], "keywords": ["deep reinforcement learning", "Alpha(Go) Zero", "symbolic reasoning", "gameplay", "SAT"], "pdf": "/pdf/1c3daa71ca777ae507bb211d2efabcd8de06e200.pdf"}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1520657999000, "tmdate": 1521582989642, "id": "ICLR.cc/2018/Workshop/-/Paper266/Official_Review", "writers": ["ICLR.cc/2018/Workshop"], "signatures": ["ICLR.cc/2018/Workshop"], "readers": ["everyone"], "invitees": ["ICLR.cc/2018/Workshop/Paper266/Reviewers"], "noninvitees": ["ICLR.cc/2018/Workshop/Paper266/AnonReviewer3", "ICLR.cc/2018/Workshop/Paper266/AnonReviewer1", "ICLR.cc/2018/Workshop/Paper266/AnonReviewer2"], "reply": {"forum": "SJUXltkvM", "replyto": "SJUXltkvM", "writers": {"values-regex": "ICLR.cc/2018/Workshop/Paper266/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2018/Workshop/Paper266/AnonReviewer[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"required": true, "order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"required": true, "order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "value-regex": "[\\S\\s]{1,200000}"}, "rating": {"required": true, "order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"required": true, "order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1528433999000, "cdate": 1521582989642}}}, {"tddate": null, "ddate": null, "original": null, "tmdate": 1521582680754, "tcdate": 1520729395212, "number": 3, "cdate": 1520729395212, "id": "SkoNTgMtz", "invitation": "ICLR.cc/2018/Workshop/-/Paper266/Official_Review", "forum": "SJUXltkvM", "replyto": "SJUXltkvM", "signatures": ["ICLR.cc/2018/Workshop/Paper266/AnonReviewer2"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Workshop/Paper266/AnonReviewer2"], "content": {"title": "Interesting approach but too vague/little", "rating": "4: Ok but not good enough - rejection", "review": "The paper uses a way to cast SAT solving as a Conflict Driven Clause Learning game, and presents results deep models trained on these games. The input features consist of encoding the SAT problems in Conjunctive Normal Form as sparse adjacency matrices. The training algorithms are either DQN or Alpha(Go)Zero-like. They compare results to a MiniSAT baseline, on a train and test set taken from SATLIB. The results are: DQN overfits and has worse error than baseline on test. AlphaZero has twice better (i.e. less) average branching decisions than baseline on train and test.\n\nThe approach is interesting, but the paper is too vague and includes too little results so that one can conclude that the promising positive results are not due to MCTS, or to the baseline being weak. A short description of the model(s) and a description of the differences between train and test time (if any) would help.\n\nConjuctive -> Conjunctive", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "From Gameplay to Symbolic Reasoning", "abstract": "Despite the recent successes of deep neural networks in various fields such as image and speech recognition, natural language processing, and reinforcement learning, we still face big challenges bringing the power of numeric optimization to\nsymbolic reasoning. Researchers have proposed different avenues such as neural machine translation for proof synthesis, vectorization of symbols and expressions for representing symbolic patterns, and coupling of neural back-ends for dimensionality reduction with symbolic front-ends for decision making. However, these initial explorations are still only point solutions, and bear other shortcomings such as lack of correctness guarantees. In this paper, we present our approach of casting symbolic reasoning as games, and directly harnessing the power of deep reinforcement learning in the style of Alpha(Go) Zero on symbolic problems. Using the Boolean Satisfiability (SAT) problem as showcase, we demonstrate the feasibility of our method, and the advantages of modularity, efficiency, and correctness guarantees.", "paperhash": "wang|from_gameplay_to_symbolic_reasoning", "_bibtex": "@misc{\n  wang2018from,\n  title={From Gameplay to Symbolic Reasoning},\n  author={Fei Wang and Tiark Rompf},\n  year={2018},\n  url={https://openreview.net/forum?id=SJUXltkvM}\n}", "authorids": ["wang603@purdue.edu", "tiark@purdue.edu"], "authors": ["Fei Wang", "Tiark Rompf"], "keywords": ["deep reinforcement learning", "Alpha(Go) Zero", "symbolic reasoning", "gameplay", "SAT"], "pdf": "/pdf/1c3daa71ca777ae507bb211d2efabcd8de06e200.pdf"}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1520657999000, "tmdate": 1521582989642, "id": "ICLR.cc/2018/Workshop/-/Paper266/Official_Review", "writers": ["ICLR.cc/2018/Workshop"], "signatures": ["ICLR.cc/2018/Workshop"], "readers": ["everyone"], "invitees": ["ICLR.cc/2018/Workshop/Paper266/Reviewers"], "noninvitees": ["ICLR.cc/2018/Workshop/Paper266/AnonReviewer3", "ICLR.cc/2018/Workshop/Paper266/AnonReviewer1", "ICLR.cc/2018/Workshop/Paper266/AnonReviewer2"], "reply": {"forum": "SJUXltkvM", "replyto": "SJUXltkvM", "writers": {"values-regex": "ICLR.cc/2018/Workshop/Paper266/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2018/Workshop/Paper266/AnonReviewer[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"required": true, "order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"required": true, "order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "value-regex": "[\\S\\s]{1,200000}"}, "rating": {"required": true, "order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"required": true, "order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1528433999000, "cdate": 1521582989642}}}, {"tddate": null, "ddate": null, "original": null, "tmdate": 1521573576102, "tcdate": 1521573576102, "number": 140, "cdate": 1521573575759, "id": "rygARCRKM", "invitation": "ICLR.cc/2018/Workshop/-/Acceptance_Decision", "forum": "SJUXltkvM", "replyto": "SJUXltkvM", "signatures": ["ICLR.cc/2018/Workshop/Program_Chairs"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Workshop/Program_Chairs"], "content": {"decision": "Reject", "title": "ICLR 2018 Workshop Acceptance Decision", "comment": "Based on the reviews, this paper has not been accepted for presentation at the ICLR workshop. The results were too small scale and quite preliminary, even for the workshop. However, the conversation and updates can continue to appear here on OpenReview, and we look further for improvements!"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "From Gameplay to Symbolic Reasoning", "abstract": "Despite the recent successes of deep neural networks in various fields such as image and speech recognition, natural language processing, and reinforcement learning, we still face big challenges bringing the power of numeric optimization to\nsymbolic reasoning. Researchers have proposed different avenues such as neural machine translation for proof synthesis, vectorization of symbols and expressions for representing symbolic patterns, and coupling of neural back-ends for dimensionality reduction with symbolic front-ends for decision making. However, these initial explorations are still only point solutions, and bear other shortcomings such as lack of correctness guarantees. In this paper, we present our approach of casting symbolic reasoning as games, and directly harnessing the power of deep reinforcement learning in the style of Alpha(Go) Zero on symbolic problems. Using the Boolean Satisfiability (SAT) problem as showcase, we demonstrate the feasibility of our method, and the advantages of modularity, efficiency, and correctness guarantees.", "paperhash": "wang|from_gameplay_to_symbolic_reasoning", "_bibtex": "@misc{\n  wang2018from,\n  title={From Gameplay to Symbolic Reasoning},\n  author={Fei Wang and Tiark Rompf},\n  year={2018},\n  url={https://openreview.net/forum?id=SJUXltkvM}\n}", "authorids": ["wang603@purdue.edu", "tiark@purdue.edu"], "authors": ["Fei Wang", "Tiark Rompf"], "keywords": ["deep reinforcement learning", "Alpha(Go) Zero", "symbolic reasoning", "gameplay", "SAT"], "pdf": "/pdf/1c3daa71ca777ae507bb211d2efabcd8de06e200.pdf"}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "tmdate": 1518629844880, "id": "ICLR.cc/2018/Workshop/-/Acceptance_Decision", "writers": ["ICLR.cc/2018/Workshop"], "signatures": ["ICLR.cc/2018/Workshop"], "readers": ["everyone"], "invitees": ["ICLR.cc/2018/Workshop/Program_Chairs"], "reply": {"forum": null, "replyto": null, "invitation": "ICLR.cc/2018/Workshop/-/Submission", "writers": {"values": ["ICLR.cc/2018/Workshop/Program_Chairs"]}, "signatures": {"description": "How your identity will be displayed with the above content.", "values": ["ICLR.cc/2018/Workshop/Program_Chairs"]}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["ICLR.cc/2018/Workshop/Program_Chairs", "everyone"]}, "content": {"title": {"required": true, "order": 1, "value": "ICLR 2018 Workshop Acceptance Decision"}, "comment": {"required": false, "order": 3, "description": "(optional) Comment on this decision.", "value-regex": "[\\S\\s]{0,5000}"}, "decision": {"required": true, "order": 2, "value-dropdown": ["Accept", "Reject"]}}}, "nonreaders": [], "noninvitees": [], "cdate": 1518629844880}}}], "count": 5}