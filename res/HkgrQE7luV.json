{"notes": [{"id": "HkgrQE7luV", "original": "B1lrG_SdPV", "number": 17, "cdate": 1553114140612, "ddate": null, "tcdate": 1553114140612, "tmdate": 1562082107658, "tddate": null, "forum": "HkgrQE7luV", "replyto": null, "invitation": "ICLR.cc/2019/Workshop/LLD/-/Blind_Submission", "content": {"title": "Online Semi-Supervised Learning with Bandit Feedback", "authors": ["Mikhail Yurochkin", "Sohini Upadhyay", "Djallel Bouneffouf", "Mayank Agarwal", "Yasaman Khazaeni"], "authorids": ["mikhail.yurochkin@ibm.com", "sohini.upadhyay@ibm.com", "djallel_info@yahoo.fr", "mayank.agarwal@ibm.com", "yasaman.khazaeni@us.ibm.com"], "keywords": ["online learning", "graph convolutional networks", "contextual bandits"], "TL;DR": "Synthesis of GCN and LINUCB algorithms for online learning with missing feedbacks", "abstract": "We formulate a new problem at the intersection of semi-supervised learning and contextual bandits, motivated by several applications including clinical trials and dialog systems. We demonstrate how contextual bandit and graph convolutional networks can be adjusted to the new problem formulation. We then take the best of both approaches to develop multi-GCN embedded contextual bandit. Our algorithms are verified on several real world datasets.", "pdf": "/pdf/545ccd6e6ba488db445972f47ec1c0ad269cabb4.pdf", "paperhash": "yurochkin|online_semisupervised_learning_with_bandit_feedback"}, "signatures": ["ICLR.cc/2019/Workshop/LLD"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Workshop/LLD"], "details": {"replyCount": 3, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"id": "ICLR.cc/2019/Workshop/LLD/-/Blind_Submission", "cdate": 1548689671889, "reply": {"forum": null, "replyto": null, "readers": {"values-regex": ".*"}, "writers": {"values": ["ICLR.cc/2019/Workshop/LLD"]}, "signatures": {"values": ["ICLR.cc/2019/Workshop/LLD"]}, "content": {"authors": {"values-regex": ".*"}, "authorids": {"values-regex": ".*"}}}, "tcdate": 1548689671889, "tmdate": 1557933709646, "readers": ["everyone"], "writers": ["ICLR.cc/2019/Workshop/LLD"], "invitees": ["~"], "signatures": ["ICLR.cc/2019/Workshop/LLD"], "details": {"writable": true}}}, "tauthor": "OpenReview.net"}, {"id": "BkgInDxwtV", "original": null, "number": 1, "cdate": 1554610094300, "ddate": null, "tcdate": 1554610094300, "tmdate": 1555512021329, "tddate": null, "forum": "HkgrQE7luV", "replyto": "HkgrQE7luV", "invitation": "ICLR.cc/2019/Workshop/LLD/-/Paper17/Official_Review", "content": {"title": "Interesting setting but insufficient positioning in the literature", "review": "This paper introduces the \"Online Partially Rewarded\" setting, which appears to be interesting both from a practical and a theoretical point of view. They then propose two approaches based on GCN, which maintain a similarity graph between observations to help predictions. As Rewarded Online GCN only cannot deal with missclassified observations, the authors propose to combine a multi-armed bandit approach with multiple GCN embedding.\n\nThe resulting algorithm maintains k different embeddings for the whole dataset, which are recomputed at each iteration (new observation t). This seems to be costly: would it be possible to update only a few last observations? As noted by the authors, this prevents them to apply their algorithm to bigger datasets. A discussion on the performance would still be a plus. \n\nThe detail of the algorithm shows that the proposed algorithm does not account for delayed environment response. This seems to be an important limitation, not implied by the OPR setting: at iteration t, the algorithm has to predict y_t and then observes response h_t. If h_t is missing, the corresponding context is set forever, and a late h_t will just be ignored. Recent works in the bandit community propose frameworks which seem to be more general (see e.g. Bandits with Delayed Anonymous Feedback by Pike-Burke et al. or Online Learning under Delayed Feedback by Joulani et al.).\n\nExperiments are conducted on real datasets but with a simulated OPR setting, which is a slight limitation. However, only the two proposed methods and a standard algorithm (LINUCB) of the literature are compared. The results are very encouraging, especially, as noted by the authors, when a natural graph structure is present in the data; but the LINUCB baseline is not adapted to the OPR setting and thus the experiments do not provide enough evidence to back the proposed approach. Here again, I would suggest comparisons with more recent works, such as Variational Thompson Sampling for Relational Recurrent Bandits by Lamprier et al.", "rating": "2: Marginally below acceptance threshold", "confidence": "2: The reviewer is fairly confident that the evaluation is correct"}, "signatures": ["ICLR.cc/2019/Workshop/LLD/Paper17/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Workshop/LLD/Paper17/AnonReviewer2"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Online Semi-Supervised Learning with Bandit Feedback", "authors": ["Mikhail Yurochkin", "Sohini Upadhyay", "Djallel Bouneffouf", "Mayank Agarwal", "Yasaman Khazaeni"], "authorids": ["mikhail.yurochkin@ibm.com", "sohini.upadhyay@ibm.com", "djallel_info@yahoo.fr", "mayank.agarwal@ibm.com", "yasaman.khazaeni@us.ibm.com"], "keywords": ["online learning", "graph convolutional networks", "contextual bandits"], "TL;DR": "Synthesis of GCN and LINUCB algorithms for online learning with missing feedbacks", "abstract": "We formulate a new problem at the intersection of semi-supervised learning and contextual bandits, motivated by several applications including clinical trials and dialog systems. We demonstrate how contextual bandit and graph convolutional networks can be adjusted to the new problem formulation. We then take the best of both approaches to develop multi-GCN embedded contextual bandit. Our algorithms are verified on several real world datasets.", "pdf": "/pdf/545ccd6e6ba488db445972f47ec1c0ad269cabb4.pdf", "paperhash": "yurochkin|online_semisupervised_learning_with_bandit_feedback"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Workshop/LLD/-/Paper17/Official_Review", "cdate": 1553713419552, "expdate": 1555718400000, "duedate": 1554681600000, "reply": {"forum": "HkgrQE7luV", "replyto": "HkgrQE7luV", "writers": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2019/Workshop/LLD/Paper17/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2019/Workshop/LLD/Paper17/AnonReviewer[0-9]+"}, "readers": {"values": ["everyone"], "description": "The users who will be allowed to read the above content."}, "content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "required": true}, "rating": {"order": 3, "value-dropdown": ["5: Top 15% of accepted papers, strong accept", "4: Top 50% of accepted papers, clear accept", "3: Marginally above acceptance threshold", "2: Marginally below acceptance threshold", "1: Strong rejection"], "required": true}, "confidence": {"order": 4, "value-radio": ["3: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "2: The reviewer is fairly confident that the evaluation is correct", "1: The reviewer's evaluation is an educated guess"], "required": true}}}, "tcdate": 1553713419552, "tmdate": 1555511817314, "readers": ["everyone"], "writers": ["ICLR.cc/2019/Workshop/LLD"], "invitees": ["ICLR.cc/2019/Workshop/LLD/Paper17/Reviewers"], "signatures": ["ICLR.cc/2019/Workshop/LLD"]}}}, {"id": "HyeXCw_jF4", "original": null, "number": 2, "cdate": 1554905034903, "ddate": null, "tcdate": 1554905034903, "tmdate": 1555511879072, "tddate": null, "forum": "HkgrQE7luV", "replyto": "HkgrQE7luV", "invitation": "ICLR.cc/2019/Workshop/LLD/-/Paper17/Official_Review", "content": {"title": "Review for paper: Online Semi-Supervised Learning with Bandit Feedback", "review": "The paper considers a multi-armed bandit problem in which on some iterations, the reward from the environment might be\ncompletely missing. To the rescue, a modified LinUCB-type algorithm is then proposed. Experimental results seam sound.\nThe authors show that their proposal outpowers a blind LinUCB algorithm. The t-SNE plots (Figs 1 and 2) also show that\nthe embeddings learned by the proposed model are more compactly clustered w.r.t the true labels.\n\nThe paper is well-written and the movitated problems are well described.\n\nThe paper considers a multi-armed bandit problem in which on some iterations, the reward from the environment might be\ncompletely missing. To the rescue, a modified LinUCB-type algorithm is then proposed. Experimental results seam sound.\nThe authors show that their proposal outpowers a blind LinUCB algorithm. The t-SNE plots (Figs 1 and 2) also show that\nthe embeddings learned by the proposed model are more compactly clustered w.r.t the true labels.\n\nThe paper is well-written and the movitated problems are well described.\n", "rating": "3: Marginally above acceptance threshold", "confidence": "2: The reviewer is fairly confident that the evaluation is correct"}, "signatures": ["ICLR.cc/2019/Workshop/LLD/Paper17/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Workshop/LLD/Paper17/AnonReviewer1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Online Semi-Supervised Learning with Bandit Feedback", "authors": ["Mikhail Yurochkin", "Sohini Upadhyay", "Djallel Bouneffouf", "Mayank Agarwal", "Yasaman Khazaeni"], "authorids": ["mikhail.yurochkin@ibm.com", "sohini.upadhyay@ibm.com", "djallel_info@yahoo.fr", "mayank.agarwal@ibm.com", "yasaman.khazaeni@us.ibm.com"], "keywords": ["online learning", "graph convolutional networks", "contextual bandits"], "TL;DR": "Synthesis of GCN and LINUCB algorithms for online learning with missing feedbacks", "abstract": "We formulate a new problem at the intersection of semi-supervised learning and contextual bandits, motivated by several applications including clinical trials and dialog systems. We demonstrate how contextual bandit and graph convolutional networks can be adjusted to the new problem formulation. We then take the best of both approaches to develop multi-GCN embedded contextual bandit. Our algorithms are verified on several real world datasets.", "pdf": "/pdf/545ccd6e6ba488db445972f47ec1c0ad269cabb4.pdf", "paperhash": "yurochkin|online_semisupervised_learning_with_bandit_feedback"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Workshop/LLD/-/Paper17/Official_Review", "cdate": 1553713419552, "expdate": 1555718400000, "duedate": 1554681600000, "reply": {"forum": "HkgrQE7luV", "replyto": "HkgrQE7luV", "writers": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2019/Workshop/LLD/Paper17/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2019/Workshop/LLD/Paper17/AnonReviewer[0-9]+"}, "readers": {"values": ["everyone"], "description": "The users who will be allowed to read the above content."}, "content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "required": true}, "rating": {"order": 3, "value-dropdown": ["5: Top 15% of accepted papers, strong accept", "4: Top 50% of accepted papers, clear accept", "3: Marginally above acceptance threshold", "2: Marginally below acceptance threshold", "1: Strong rejection"], "required": true}, "confidence": {"order": 4, "value-radio": ["3: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "2: The reviewer is fairly confident that the evaluation is correct", "1: The reviewer's evaluation is an educated guess"], "required": true}}}, "tcdate": 1553713419552, "tmdate": 1555511817314, "readers": ["everyone"], "writers": ["ICLR.cc/2019/Workshop/LLD"], "invitees": ["ICLR.cc/2019/Workshop/LLD/Paper17/Reviewers"], "signatures": ["ICLR.cc/2019/Workshop/LLD"]}}}, {"id": "SkghYohf9N", "original": null, "number": 1, "cdate": 1555381124153, "ddate": null, "tcdate": 1555381124153, "tmdate": 1555510978978, "tddate": null, "forum": "HkgrQE7luV", "replyto": "HkgrQE7luV", "invitation": "ICLR.cc/2019/Workshop/LLD/-/Paper17/Decision", "content": {"title": "Acceptance Decision", "decision": "Accept"}, "signatures": ["ICLR.cc/2019/Workshop/LLD/Program_Chairs"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Workshop/LLD/Program_Chairs"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Online Semi-Supervised Learning with Bandit Feedback", "authors": ["Mikhail Yurochkin", "Sohini Upadhyay", "Djallel Bouneffouf", "Mayank Agarwal", "Yasaman Khazaeni"], "authorids": ["mikhail.yurochkin@ibm.com", "sohini.upadhyay@ibm.com", "djallel_info@yahoo.fr", "mayank.agarwal@ibm.com", "yasaman.khazaeni@us.ibm.com"], "keywords": ["online learning", "graph convolutional networks", "contextual bandits"], "TL;DR": "Synthesis of GCN and LINUCB algorithms for online learning with missing feedbacks", "abstract": "We formulate a new problem at the intersection of semi-supervised learning and contextual bandits, motivated by several applications including clinical trials and dialog systems. We demonstrate how contextual bandit and graph convolutional networks can be adjusted to the new problem formulation. We then take the best of both approaches to develop multi-GCN embedded contextual bandit. Our algorithms are verified on several real world datasets.", "pdf": "/pdf/545ccd6e6ba488db445972f47ec1c0ad269cabb4.pdf", "paperhash": "yurochkin|online_semisupervised_learning_with_bandit_feedback"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Workshop/LLD/-/Paper17/Decision", "cdate": 1554736068495, "reply": {"forum": "HkgrQE7luV", "replyto": "HkgrQE7luV", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-regex": ["ICLR.cc/2019/Workshop/LLD/Program_Chairs"], "description": "How your identity will be displayed."}, "signatures": {"values": ["ICLR.cc/2019/Workshop/LLD/Program_Chairs"], "description": "How your identity will be displayed."}, "content": {"title": {"order": 1, "required": true, "value": "Acceptance Decision"}, "decision": {"order": 2, "required": true, "value-radio": ["Accept", "Reject"], "description": "Acceptance decision"}, "comment": {"order": 3, "required": false, "value-regex": "[\\S\\s]{0,5000}", "description": ""}}}, "tcdate": 1554736068495, "tmdate": 1555510970195, "readers": ["everyone"], "writers": ["ICLR.cc/2019/Workshop/LLD"], "invitees": ["ICLR.cc/2019/Workshop/LLD/Program_Chairs"], "signatures": ["ICLR.cc/2019/Workshop/LLD"]}}}], "count": 4}