{"notes": [{"tddate": null, "replyto": null, "ddate": null, "tmdate": 1528124427332, "tcdate": 1518447404336, "number": 131, "cdate": 1518447404336, "id": "SkNEsmJwf", "invitation": "ICLR.cc/2018/Workshop/-/Submission", "forum": "SkNEsmJwf", "signatures": ["~Chong_Yu2"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Workshop"], "content": {"title": "3D-Scene-GAN: Three-dimensional Scene Reconstruction with Generative Adversarial Networks", "abstract": "Three-dimensional (3D) Reconstruction is a vital and challenging research topic in advanced computer graphics and computer vision due to the intrinsic complexity and computation cost. Existing methods often produce holes, distortions and obscure parts in the reconstructed 3D models which are not adequate for real usage. The focus of this paper is to achieve high quality 3D reconstruction performance of complicated scene by adopting Generative Adversarial Network (GAN). We propose a novel workflow, namely 3D-Scene-GAN, which can iteratively improve any raw 3D reconstructed models consisting of meshes and textures. 3D-Scene-GAN is a weakly semi-supervised model. It only takes real-time 2D observation images as the supervision, and doesn\u2019t rely on prior knowledge of shape models or any referenced observations. Finally, through the qualitative and quantitative experiments, 3D-Scene-GAN shows compelling advantages over the state-of-the-art methods: balanced rank estimation (BRE) scores are improved by 30%-100% on ICL-NUIM dataset, and 36%-190% on SUN3D dataset. And the mean distance error (MDR) also outperforms other state-of-the-art methods on benchmarks.", "paperhash": "yu|3dscenegan_threedimensional_scene_reconstruction_with_generative_adversarial_networks", "keywords": ["3D Reconstruction", "Generative Adversarial Network", "semi-supervised model"], "_bibtex": "@misc{\n  yu20183d-scene-gan:,\n  title={3D-Scene-GAN: Three-dimensional Scene Reconstruction with Generative Adversarial Networks},\n  author={Chong Yu and Young Wang},\n  year={2018},\n  url={https://openreview.net/forum?id=SkNEsmJwf}\n}", "authorids": ["chong.yu@intel.com", "young.wang@intel.com"], "authors": ["Chong Yu", "Young Wang"], "TL;DR": " We propose a novel workflow, namely 3D-Scene-GAN, which can iteratively improve any raw 3D reconstructed models consisting of meshes and textures with GAN framework.", "pdf": "/pdf/d14dbf42583cedde6dd8376d7c8b0a60808d7b5e.pdf"}, "nonreaders": [], "details": {"replyCount": 5, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1518472800000, "tmdate": 1518474081690, "id": "ICLR.cc/2018/Workshop/-/Submission", "writers": ["ICLR.cc/2018/Workshop"], "signatures": ["ICLR.cc/2018/Workshop"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": null, "replyto": null, "writers": {"values": ["ICLR.cc/2018/Workshop"]}, "signatures": {"values-regex": "~.*|ICLR.cc/2018/Workshop", "description": "Your authorized identity to be associated with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"pdf": {"required": true, "order": 9, "value-regex": "upload", "description": "Upload a PDF file that ends with .pdf"}, "title": {"required": true, "order": 1, "description": "Title of paper.", "value-regex": ".{1,250}"}, "abstract": {"required": true, "order": 8, "description": "Abstract of paper.", "value-regex": "[\\S\\s]{1,5000}"}, "authors": {"required": true, "order": 2, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of author names. Please provide real names; identities will be anonymized."}, "keywords": {"order": 6, "values-regex": "(^$)|[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of keywords."}, "TL;DR": {"required": false, "order": 7, "description": "\"Too Long; Didn't Read\": a short sentence describing your paper", "value-regex": "[^\\n]{0,500}"}, "authorids": {"required": true, "order": 3, "values-regex": "([a-z0-9_\\-\\.]{2,}@[a-z0-9_\\-\\.]{2,}\\.[a-z]{2,},){0,}([a-z0-9_\\-\\.]{2,}@[a-z0-9_\\-\\.]{2,}\\.[a-z]{2,})", "description": "Comma separated list of author email addresses, lowercased, in the same order as above. For authors with existing OpenReview accounts, please make sure that the provided email address(es) match those listed in the author's profile. Please provide real emails; identities will be anonymized."}}}, "nonreaders": [], "noninvitees": [], "expdate": 1526248800000, "cdate": 1518474081690}}}, {"tddate": null, "ddate": null, "original": null, "tmdate": 1521582812263, "tcdate": 1520617321645, "number": 1, "cdate": 1520617321645, "id": "ByMOwBlKM", "invitation": "ICLR.cc/2018/Workshop/-/Paper131/Official_Review", "forum": "SkNEsmJwf", "replyto": "SkNEsmJwf", "signatures": ["ICLR.cc/2018/Workshop/Paper131/AnonReviewer2"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Workshop/Paper131/AnonReviewer2"], "content": {"title": "Interesting idea but the description of the method lacks of clarity and details. ", "rating": "5: Marginally below acceptance threshold", "review": "The idea of using GAN method to 3D scene reconstruction is novel and interesting. The proposed method performs well especially for the BRE Metric presented in Table 1.\n\nMajor concerns:  \nHowever, the method is presented as a 3D reconstruction technique, but it is not clear how the method can deal with a complete scene reconstruction from scratch. Indeed, an initial reconstruction (during the inference and the training) seems to be necessary and this aspect should be more discussed. \nThe method should be presented in more details:  \n\u2022\tHow are the points of view chosen during the learning process? Is it possible to use multi-view images as input for the discriminator?\n\u2022\tAre the real images segmented before being fed to the discriminator? Indeed, with the background it seems trivial to classify real/fake images.\n\u2022\tThe details concerning the generator are missing. In particular, how the rendering is achieved with respect to the generator error? \n\u2022\tThe method needs to compute the camera pose from the 2D image and the 3D model. However, the initialization robustness to the estimated pose is not discussed? \n\nMinor concerns:  \nThe writing of the paper can be improved: \n\u2022\tTo long sentences, for example, \u201cIf this person observes the reconstructed 3D scene at exactly the same positions and viewpoints as in the real 3D scene, and all the observed 2D scene image pairs in reconstructed and real 3D scene are exactly the same.\u201d \n\u2022\tMissing word, for example, \u201cUnlike many state-of-the-art methods can only generate voxelized objects or some simple isolated objects such as chair, car, plane, etc., 3D-Scene-GAN can be applied to generate very complicated 3D reconstructed scene, and still obtains decent result.\u201d\n\u2022\tFigure 2 and 3: the text size is too small.\n\u2022\tIt could be more adequate to remove Figure 1 and to replace it with Figure 4 by adding 2D images of the real scene which are clearly missing and by presenting different viewpoints.  \n", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "3D-Scene-GAN: Three-dimensional Scene Reconstruction with Generative Adversarial Networks", "abstract": "Three-dimensional (3D) Reconstruction is a vital and challenging research topic in advanced computer graphics and computer vision due to the intrinsic complexity and computation cost. Existing methods often produce holes, distortions and obscure parts in the reconstructed 3D models which are not adequate for real usage. The focus of this paper is to achieve high quality 3D reconstruction performance of complicated scene by adopting Generative Adversarial Network (GAN). We propose a novel workflow, namely 3D-Scene-GAN, which can iteratively improve any raw 3D reconstructed models consisting of meshes and textures. 3D-Scene-GAN is a weakly semi-supervised model. It only takes real-time 2D observation images as the supervision, and doesn\u2019t rely on prior knowledge of shape models or any referenced observations. Finally, through the qualitative and quantitative experiments, 3D-Scene-GAN shows compelling advantages over the state-of-the-art methods: balanced rank estimation (BRE) scores are improved by 30%-100% on ICL-NUIM dataset, and 36%-190% on SUN3D dataset. And the mean distance error (MDR) also outperforms other state-of-the-art methods on benchmarks.", "paperhash": "yu|3dscenegan_threedimensional_scene_reconstruction_with_generative_adversarial_networks", "keywords": ["3D Reconstruction", "Generative Adversarial Network", "semi-supervised model"], "_bibtex": "@misc{\n  yu20183d-scene-gan:,\n  title={3D-Scene-GAN: Three-dimensional Scene Reconstruction with Generative Adversarial Networks},\n  author={Chong Yu and Young Wang},\n  year={2018},\n  url={https://openreview.net/forum?id=SkNEsmJwf}\n}", "authorids": ["chong.yu@intel.com", "young.wang@intel.com"], "authors": ["Chong Yu", "Young Wang"], "TL;DR": " We propose a novel workflow, namely 3D-Scene-GAN, which can iteratively improve any raw 3D reconstructed models consisting of meshes and textures with GAN framework.", "pdf": "/pdf/d14dbf42583cedde6dd8376d7c8b0a60808d7b5e.pdf"}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1520657999000, "tmdate": 1521582812050, "id": "ICLR.cc/2018/Workshop/-/Paper131/Official_Review", "writers": ["ICLR.cc/2018/Workshop"], "signatures": ["ICLR.cc/2018/Workshop"], "readers": ["everyone"], "invitees": ["ICLR.cc/2018/Workshop/Paper131/Reviewers"], "noninvitees": ["ICLR.cc/2018/Workshop/Paper131/AnonReviewer2", "ICLR.cc/2018/Workshop/Paper131/AnonReviewer4"], "reply": {"forum": "SkNEsmJwf", "replyto": "SkNEsmJwf", "writers": {"values-regex": "ICLR.cc/2018/Workshop/Paper131/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2018/Workshop/Paper131/AnonReviewer[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"required": true, "order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"required": true, "order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "value-regex": "[\\S\\s]{1,200000}"}, "rating": {"required": true, "order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"required": true, "order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1528433999000, "cdate": 1521582812050}}}, {"tddate": null, "ddate": null, "original": null, "tmdate": 1521582583493, "tcdate": 1521284357799, "number": 2, "cdate": 1521284357799, "id": "S1abrOqKf", "invitation": "ICLR.cc/2018/Workshop/-/Paper131/Official_Review", "forum": "SkNEsmJwf", "replyto": "SkNEsmJwf", "signatures": ["ICLR.cc/2018/Workshop/Paper131/AnonReviewer4"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Workshop/Paper131/AnonReviewer4"], "content": {"title": "Far from reproducible, would benefit from another edit", "rating": "5: Marginally below acceptance threshold", "review": "GANs are currently popular for synthesizing structured objects, the vast majority of attention has been on 2D images. This paper looks at a natural extension to 3D scenes, which is likely to be a promising area.\n\nIt isn't possible to reproduce the proposed method from the paper, and the linked github site doesn't fill in that detail. Figure 1 isn't actually created by the method? Even in this ideal case, the rendered 2D images would be easy to distinguish from the photos, so what constraints are preventing the classifier from rapidly \"over-fitting\"?\n\nThe quality of the paper could be improved. Figure 2 is too small to read. The text is quite hard to follow -- I think the description of the principle only makes sense because I already know what a GAN is. This text could be tightened up and more precise experimental detail given.\n\nMinor: This part: \"However, batch normalization makes the discriminative model to map from a batch of inputs to a batch of outputs. 3D-Scene-GAN wants to keep the mapping relation from single input to single output. We replace batch normalization by layer normalization for generative and discriminative networks to avoid the correlations introduced between input samples.\" -- is hard to follow, and the methods mentioned are not cited.", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "3D-Scene-GAN: Three-dimensional Scene Reconstruction with Generative Adversarial Networks", "abstract": "Three-dimensional (3D) Reconstruction is a vital and challenging research topic in advanced computer graphics and computer vision due to the intrinsic complexity and computation cost. Existing methods often produce holes, distortions and obscure parts in the reconstructed 3D models which are not adequate for real usage. The focus of this paper is to achieve high quality 3D reconstruction performance of complicated scene by adopting Generative Adversarial Network (GAN). We propose a novel workflow, namely 3D-Scene-GAN, which can iteratively improve any raw 3D reconstructed models consisting of meshes and textures. 3D-Scene-GAN is a weakly semi-supervised model. It only takes real-time 2D observation images as the supervision, and doesn\u2019t rely on prior knowledge of shape models or any referenced observations. Finally, through the qualitative and quantitative experiments, 3D-Scene-GAN shows compelling advantages over the state-of-the-art methods: balanced rank estimation (BRE) scores are improved by 30%-100% on ICL-NUIM dataset, and 36%-190% on SUN3D dataset. And the mean distance error (MDR) also outperforms other state-of-the-art methods on benchmarks.", "paperhash": "yu|3dscenegan_threedimensional_scene_reconstruction_with_generative_adversarial_networks", "keywords": ["3D Reconstruction", "Generative Adversarial Network", "semi-supervised model"], "_bibtex": "@misc{\n  yu20183d-scene-gan:,\n  title={3D-Scene-GAN: Three-dimensional Scene Reconstruction with Generative Adversarial Networks},\n  author={Chong Yu and Young Wang},\n  year={2018},\n  url={https://openreview.net/forum?id=SkNEsmJwf}\n}", "authorids": ["chong.yu@intel.com", "young.wang@intel.com"], "authors": ["Chong Yu", "Young Wang"], "TL;DR": " We propose a novel workflow, namely 3D-Scene-GAN, which can iteratively improve any raw 3D reconstructed models consisting of meshes and textures with GAN framework.", "pdf": "/pdf/d14dbf42583cedde6dd8376d7c8b0a60808d7b5e.pdf"}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1520657999000, "tmdate": 1521582812050, "id": "ICLR.cc/2018/Workshop/-/Paper131/Official_Review", "writers": ["ICLR.cc/2018/Workshop"], "signatures": ["ICLR.cc/2018/Workshop"], "readers": ["everyone"], "invitees": ["ICLR.cc/2018/Workshop/Paper131/Reviewers"], "noninvitees": ["ICLR.cc/2018/Workshop/Paper131/AnonReviewer2", "ICLR.cc/2018/Workshop/Paper131/AnonReviewer4"], "reply": {"forum": "SkNEsmJwf", "replyto": "SkNEsmJwf", "writers": {"values-regex": "ICLR.cc/2018/Workshop/Paper131/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2018/Workshop/Paper131/AnonReviewer[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"required": true, "order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"required": true, "order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "value-regex": "[\\S\\s]{1,200000}"}, "rating": {"required": true, "order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"required": true, "order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1528433999000, "cdate": 1521582812050}}}, {"tddate": null, "ddate": null, "original": null, "tmdate": 1521573584933, "tcdate": 1521573584933, "number": 179, "cdate": 1521573584587, "id": "r1FRAACKM", "invitation": "ICLR.cc/2018/Workshop/-/Acceptance_Decision", "forum": "SkNEsmJwf", "replyto": "SkNEsmJwf", "signatures": ["ICLR.cc/2018/Workshop/Program_Chairs"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Workshop/Program_Chairs"], "content": {"decision": "Accept", "title": "ICLR 2018 Workshop Acceptance Decision", "comment": "Congratulations, your paper was accepted to the ICLR workshop."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "3D-Scene-GAN: Three-dimensional Scene Reconstruction with Generative Adversarial Networks", "abstract": "Three-dimensional (3D) Reconstruction is a vital and challenging research topic in advanced computer graphics and computer vision due to the intrinsic complexity and computation cost. Existing methods often produce holes, distortions and obscure parts in the reconstructed 3D models which are not adequate for real usage. The focus of this paper is to achieve high quality 3D reconstruction performance of complicated scene by adopting Generative Adversarial Network (GAN). We propose a novel workflow, namely 3D-Scene-GAN, which can iteratively improve any raw 3D reconstructed models consisting of meshes and textures. 3D-Scene-GAN is a weakly semi-supervised model. It only takes real-time 2D observation images as the supervision, and doesn\u2019t rely on prior knowledge of shape models or any referenced observations. Finally, through the qualitative and quantitative experiments, 3D-Scene-GAN shows compelling advantages over the state-of-the-art methods: balanced rank estimation (BRE) scores are improved by 30%-100% on ICL-NUIM dataset, and 36%-190% on SUN3D dataset. And the mean distance error (MDR) also outperforms other state-of-the-art methods on benchmarks.", "paperhash": "yu|3dscenegan_threedimensional_scene_reconstruction_with_generative_adversarial_networks", "keywords": ["3D Reconstruction", "Generative Adversarial Network", "semi-supervised model"], "_bibtex": "@misc{\n  yu20183d-scene-gan:,\n  title={3D-Scene-GAN: Three-dimensional Scene Reconstruction with Generative Adversarial Networks},\n  author={Chong Yu and Young Wang},\n  year={2018},\n  url={https://openreview.net/forum?id=SkNEsmJwf}\n}", "authorids": ["chong.yu@intel.com", "young.wang@intel.com"], "authors": ["Chong Yu", "Young Wang"], "TL;DR": " We propose a novel workflow, namely 3D-Scene-GAN, which can iteratively improve any raw 3D reconstructed models consisting of meshes and textures with GAN framework.", "pdf": "/pdf/d14dbf42583cedde6dd8376d7c8b0a60808d7b5e.pdf"}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "tmdate": 1518629844880, "id": "ICLR.cc/2018/Workshop/-/Acceptance_Decision", "writers": ["ICLR.cc/2018/Workshop"], "signatures": ["ICLR.cc/2018/Workshop"], "readers": ["everyone"], "invitees": ["ICLR.cc/2018/Workshop/Program_Chairs"], "reply": {"forum": null, "replyto": null, "invitation": "ICLR.cc/2018/Workshop/-/Submission", "writers": {"values": ["ICLR.cc/2018/Workshop/Program_Chairs"]}, "signatures": {"description": "How your identity will be displayed with the above content.", "values": ["ICLR.cc/2018/Workshop/Program_Chairs"]}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["ICLR.cc/2018/Workshop/Program_Chairs", "everyone"]}, "content": {"title": {"required": true, "order": 1, "value": "ICLR 2018 Workshop Acceptance Decision"}, "comment": {"required": false, "order": 3, "description": "(optional) Comment on this decision.", "value-regex": "[\\S\\s]{0,5000}"}, "decision": {"required": true, "order": 2, "value-dropdown": ["Accept", "Reject"]}}}, "nonreaders": [], "noninvitees": [], "cdate": 1518629844880}}}, {"tddate": null, "ddate": null, "tmdate": 1518947871079, "tcdate": 1518947871079, "number": 2, "cdate": 1518947871079, "id": "SJwmR6LDM", "invitation": "ICLR.cc/2018/Workshop/-/Paper131/Public_Comment", "forum": "SkNEsmJwf", "replyto": "SJmUMjSwf", "signatures": ["~Chong_Yu2"], "readers": ["everyone"], "writers": ["~Chong_Yu2"], "content": {"title": "Submitted the fixed length version to ICLR2018 Program Chairs", "comment": "Thanks for ICLR2018 Program Chairs. We submitted the fixed length version to iclr2018.programchairs@gmail.com on February 17th, 2018."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "3D-Scene-GAN: Three-dimensional Scene Reconstruction with Generative Adversarial Networks", "abstract": "Three-dimensional (3D) Reconstruction is a vital and challenging research topic in advanced computer graphics and computer vision due to the intrinsic complexity and computation cost. Existing methods often produce holes, distortions and obscure parts in the reconstructed 3D models which are not adequate for real usage. The focus of this paper is to achieve high quality 3D reconstruction performance of complicated scene by adopting Generative Adversarial Network (GAN). We propose a novel workflow, namely 3D-Scene-GAN, which can iteratively improve any raw 3D reconstructed models consisting of meshes and textures. 3D-Scene-GAN is a weakly semi-supervised model. It only takes real-time 2D observation images as the supervision, and doesn\u2019t rely on prior knowledge of shape models or any referenced observations. Finally, through the qualitative and quantitative experiments, 3D-Scene-GAN shows compelling advantages over the state-of-the-art methods: balanced rank estimation (BRE) scores are improved by 30%-100% on ICL-NUIM dataset, and 36%-190% on SUN3D dataset. And the mean distance error (MDR) also outperforms other state-of-the-art methods on benchmarks.", "paperhash": "yu|3dscenegan_threedimensional_scene_reconstruction_with_generative_adversarial_networks", "keywords": ["3D Reconstruction", "Generative Adversarial Network", "semi-supervised model"], "_bibtex": "@misc{\n  yu20183d-scene-gan:,\n  title={3D-Scene-GAN: Three-dimensional Scene Reconstruction with Generative Adversarial Networks},\n  author={Chong Yu and Young Wang},\n  year={2018},\n  url={https://openreview.net/forum?id=SkNEsmJwf}\n}", "authorids": ["chong.yu@intel.com", "young.wang@intel.com"], "authors": ["Chong Yu", "Young Wang"], "TL;DR": " We propose a novel workflow, namely 3D-Scene-GAN, which can iteratively improve any raw 3D reconstructed models consisting of meshes and textures with GAN framework.", "pdf": "/pdf/d14dbf42583cedde6dd8376d7c8b0a60808d7b5e.pdf"}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "tmdate": 1518712626186, "id": "ICLR.cc/2018/Workshop/-/Paper131/Public_Comment", "writers": ["ICLR.cc/2018/Workshop"], "signatures": ["ICLR.cc/2018/Workshop"], "readers": ["everyone"], "invitees": ["~"], "noninvitees": ["ICLR.cc/2018/Workshop/Paper131/Reviewers"], "reply": {"replyto": null, "forum": "SkNEsmJwf", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone"]}, "content": {"title": {"required": true, "order": 0, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"required": true, "order": 1, "description": "Your comment or reply (max 5000 characters).", "value-regex": "[\\S\\s]{1,5000}"}}}, "nonreaders": [], "cdate": 1518712626186}}}, {"tddate": null, "ddate": null, "tmdate": 1518871307556, "tcdate": 1518871115432, "number": 1, "cdate": 1518871115432, "id": "SJmUMjSwf", "invitation": "ICLR.cc/2018/Workshop/-/Paper131/Public_Comment", "forum": "SkNEsmJwf", "replyto": "SkNEsmJwf", "signatures": ["~Oriol_Vinyals1"], "readers": ["everyone"], "writers": ["~Oriol_Vinyals1"], "content": {"title": "Please Fix Length", "comment": "Your paper violates by a few lines the 3 page limit (see https://iclr.cc/Conferences/2018/CallForWorkshops). Please send us a fixed version of your PDF at iclr2018.programchairs@gmail.com by the end of Monday, February 19th, or else we will reject your paper.\n\nThanks,\nICLR2018 Program Chairs"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "3D-Scene-GAN: Three-dimensional Scene Reconstruction with Generative Adversarial Networks", "abstract": "Three-dimensional (3D) Reconstruction is a vital and challenging research topic in advanced computer graphics and computer vision due to the intrinsic complexity and computation cost. Existing methods often produce holes, distortions and obscure parts in the reconstructed 3D models which are not adequate for real usage. The focus of this paper is to achieve high quality 3D reconstruction performance of complicated scene by adopting Generative Adversarial Network (GAN). We propose a novel workflow, namely 3D-Scene-GAN, which can iteratively improve any raw 3D reconstructed models consisting of meshes and textures. 3D-Scene-GAN is a weakly semi-supervised model. It only takes real-time 2D observation images as the supervision, and doesn\u2019t rely on prior knowledge of shape models or any referenced observations. Finally, through the qualitative and quantitative experiments, 3D-Scene-GAN shows compelling advantages over the state-of-the-art methods: balanced rank estimation (BRE) scores are improved by 30%-100% on ICL-NUIM dataset, and 36%-190% on SUN3D dataset. And the mean distance error (MDR) also outperforms other state-of-the-art methods on benchmarks.", "paperhash": "yu|3dscenegan_threedimensional_scene_reconstruction_with_generative_adversarial_networks", "keywords": ["3D Reconstruction", "Generative Adversarial Network", "semi-supervised model"], "_bibtex": "@misc{\n  yu20183d-scene-gan:,\n  title={3D-Scene-GAN: Three-dimensional Scene Reconstruction with Generative Adversarial Networks},\n  author={Chong Yu and Young Wang},\n  year={2018},\n  url={https://openreview.net/forum?id=SkNEsmJwf}\n}", "authorids": ["chong.yu@intel.com", "young.wang@intel.com"], "authors": ["Chong Yu", "Young Wang"], "TL;DR": " We propose a novel workflow, namely 3D-Scene-GAN, which can iteratively improve any raw 3D reconstructed models consisting of meshes and textures with GAN framework.", "pdf": "/pdf/d14dbf42583cedde6dd8376d7c8b0a60808d7b5e.pdf"}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "tmdate": 1518712626186, "id": "ICLR.cc/2018/Workshop/-/Paper131/Public_Comment", "writers": ["ICLR.cc/2018/Workshop"], "signatures": ["ICLR.cc/2018/Workshop"], "readers": ["everyone"], "invitees": ["~"], "noninvitees": ["ICLR.cc/2018/Workshop/Paper131/Reviewers"], "reply": {"replyto": null, "forum": "SkNEsmJwf", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone"]}, "content": {"title": {"required": true, "order": 0, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"required": true, "order": 1, "description": "Your comment or reply (max 5000 characters).", "value-regex": "[\\S\\s]{1,5000}"}}}, "nonreaders": [], "cdate": 1518712626186}}}], "count": 6}