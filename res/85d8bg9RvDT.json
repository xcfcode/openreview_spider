{"notes": [{"id": "85d8bg9RvDT", "original": "Okn1ADaQXLV", "number": 1423, "cdate": 1601308158555, "ddate": null, "tcdate": 1601308158555, "tmdate": 1614985632686, "tddate": null, "forum": "85d8bg9RvDT", "replyto": null, "invitation": "ICLR.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Deep Retrieval: An End-to-End Structure Model for Large-Scale Recommendations", "authorids": ["~Weihao_Gao1", "xiangjun.fan@bytedance.com", "jiankai.sun@bytedance.com", "jiakai@bytedance.com", "xiaowenzhi@bytedance.com", "~Chong_Wang8", "~Xiaobing_Liu1"], "authors": ["Weihao Gao", "Xiangjun Fan", "Jiankai Sun", "Kai Jia", "Wenzhi Xiao", "Chong Wang", "Xiaobing Liu"], "keywords": ["Large-scale recommendation system", "End-to-end training"], "abstract": "One of the core problems in large-scale recommendations is to retrieve top relevant candidates accurately and efficiently, preferably in sub-linear time. Previous approaches are mostly based on a two-step procedure: first learn an inner-product model and then use maximum inner product search (MIPS) algorithms to search top candidates, leading to potential loss of retrieval accuracy. In this paper, we present Deep Retrieval (DR), an end-to-end learnable structure model for large-scale recommendations. DR encodes all candidates into a discrete latent space. Those latent codes for the candidates are model parameters and to be learnt together with other neural network parameters to maximize the same objective function. With the model learnt, a beam search over the latent codes is performed to retrieve the top candidates. Empirically, we showed that DR, with sub-linear computational complexity, can achieve almost the same accuracy as the brute-force baseline.", "one-sentence_summary": "We proposed Deep Retrieval, a novel end-to-end learnable structure model which can accurately and efficiently retrieve top relevant candidates in large-scale recommendation system.", "pdf": "/pdf/a6e0db55154994db5cb1dcdff5875c9025cd658c.pdf", "supplementary_material": "/attachment/55736f81424c35929e923459e9d127fe1e9bb045.zip", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "gao|deep_retrieval_an_endtoend_structure_model_for_largescale_recommendations", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=Hmb1B1IO9", "_bibtex": "@misc{\ngao2021deep,\ntitle={Deep Retrieval: An End-to-End Structure Model for Large-Scale Recommendations},\nauthor={Weihao Gao and Xiangjun Fan and Jiankai Sun and Kai Jia and Wenzhi Xiao and Chong Wang and Xiaobing Liu},\nyear={2021},\nurl={https://openreview.net/forum?id=85d8bg9RvDT}\n}"}, "signatures": ["ICLR.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference"], "details": {"replyCount": 5, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"reply": {"readers": {"values-regex": ".*"}, "writers": {"values": ["ICLR.cc/2021/Conference"]}, "signatures": {"values": ["ICLR.cc/2021/Conference"]}, "content": {"authors": {"values": ["Anonymous"]}, "authorids": {"values-regex": ".*"}, "reviewed_version_(pdf)": {"required": false, "description": "Upload a PDF file that ends with .pdf", "value-regex": ".*"}}}, "signatures": ["ICLR.cc/2021/Conference"], "readers": ["everyone"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["~", "OpenReview.net/Support"], "tcdate": 1601308008205, "tmdate": 1614984599368, "id": "ICLR.cc/2021/Conference/-/Blind_Submission"}}, "tauthor": "OpenReview.net"}, {"id": "237JgSQe_6a", "original": null, "number": 1, "cdate": 1610040528134, "ddate": null, "tcdate": 1610040528134, "tmdate": 1610474137387, "tddate": null, "forum": "85d8bg9RvDT", "replyto": "85d8bg9RvDT", "invitation": "ICLR.cc/2021/Conference/Paper1423/-/Decision", "content": {"title": "Final Decision", "decision": "Reject", "comment": "The introduced method is novel and interesting. However, as pointed in the reviews the` paper misses several important references. The authors should extend their discussion on related work by methods from both recommender systems and extreme classification. Besides the papers listed by the reviewers, the introduced method seems also to be related to LTLS (https://arxiv.org/abs/1611.01964) and W-LTST (http://papers.neurips.cc/paper/7953-efficient-loss-based-decoding-on-graphs-for-extreme-classification.pdf), as well as to probabilistic classifier chains (https://icml.cc/Conferences/2010/papers/589.pdf) used for multi-label classification (recommendation can be reduced to multi-label classification under 0/1 loss by coding each item using a binary code of a fixed length). Nevertheless, the introduced method seems to be novel, nicely reusing and fitting together existing ideas. \n\nUnfortunately, the authors did not submit any rebuttal. Therefore, the paper cannot be accepted to ICLR. We encourage the authors to work further and extend the paper by an exhaustive discussion about related work, a wider experimental study, a more detailed description of all the steps of the method. \n\n"}, "signatures": ["ICLR.cc/2021/Conference/Program_Chairs"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference/Program_Chairs"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Deep Retrieval: An End-to-End Structure Model for Large-Scale Recommendations", "authorids": ["~Weihao_Gao1", "xiangjun.fan@bytedance.com", "jiankai.sun@bytedance.com", "jiakai@bytedance.com", "xiaowenzhi@bytedance.com", "~Chong_Wang8", "~Xiaobing_Liu1"], "authors": ["Weihao Gao", "Xiangjun Fan", "Jiankai Sun", "Kai Jia", "Wenzhi Xiao", "Chong Wang", "Xiaobing Liu"], "keywords": ["Large-scale recommendation system", "End-to-end training"], "abstract": "One of the core problems in large-scale recommendations is to retrieve top relevant candidates accurately and efficiently, preferably in sub-linear time. Previous approaches are mostly based on a two-step procedure: first learn an inner-product model and then use maximum inner product search (MIPS) algorithms to search top candidates, leading to potential loss of retrieval accuracy. In this paper, we present Deep Retrieval (DR), an end-to-end learnable structure model for large-scale recommendations. DR encodes all candidates into a discrete latent space. Those latent codes for the candidates are model parameters and to be learnt together with other neural network parameters to maximize the same objective function. With the model learnt, a beam search over the latent codes is performed to retrieve the top candidates. Empirically, we showed that DR, with sub-linear computational complexity, can achieve almost the same accuracy as the brute-force baseline.", "one-sentence_summary": "We proposed Deep Retrieval, a novel end-to-end learnable structure model which can accurately and efficiently retrieve top relevant candidates in large-scale recommendation system.", "pdf": "/pdf/a6e0db55154994db5cb1dcdff5875c9025cd658c.pdf", "supplementary_material": "/attachment/55736f81424c35929e923459e9d127fe1e9bb045.zip", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "gao|deep_retrieval_an_endtoend_structure_model_for_largescale_recommendations", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=Hmb1B1IO9", "_bibtex": "@misc{\ngao2021deep,\ntitle={Deep Retrieval: An End-to-End Structure Model for Large-Scale Recommendations},\nauthor={Weihao Gao and Xiangjun Fan and Jiankai Sun and Kai Jia and Wenzhi Xiao and Chong Wang and Xiaobing Liu},\nyear={2021},\nurl={https://openreview.net/forum?id=85d8bg9RvDT}\n}"}, "tags": [], "invitation": {"reply": {"forum": "85d8bg9RvDT", "replyto": "85d8bg9RvDT", "readers": {"values": ["everyone"]}, "writers": {"values": ["ICLR.cc/2021/Conference/Program_Chairs"]}, "signatures": {"values": ["ICLR.cc/2021/Conference/Program_Chairs"]}, "content": {"title": {"value": "Final Decision"}, "decision": {"value-radio": ["Accept (Oral)", "Accept (Spotlight)", "Accept (Poster)", "Reject"]}, "comment": {"value-regex": "[\\S\\s]{0,50000}", "markdown": true}}}, "multiReply": false, "signatures": ["ICLR.cc/2021/Conference"], "readers": ["everyone"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Program_Chairs"], "tcdate": 1610040528121, "tmdate": 1610474137371, "id": "ICLR.cc/2021/Conference/Paper1423/-/Decision"}}}, {"id": "km7j-UZkjHj", "original": null, "number": 2, "cdate": 1603887714297, "ddate": null, "tcdate": 1603887714297, "tmdate": 1605024449000, "tddate": null, "forum": "85d8bg9RvDT", "replyto": "85d8bg9RvDT", "invitation": "ICLR.cc/2021/Conference/Paper1423/-/Official_Review", "content": {"title": "Interesting algorithm, but sub-par experimentation protocol", "review": "##########################################################################\nSummary: \n\nThis paper presents an end-to-end deep retrieval method for recommendation. The model encodes all candidates into a discrete latent space, and learns the latent space parameters alongside the other neural network parameters. Recommendation is performed through beam search. The paper compares the method on two public dataset against several methods (DNN, CF, TDM) and concludes that it can achieve the same result as a brute-force solution in sub-linear time.\n\n##########################################################################\nReasons for score:\u00a0\n\nThe paper presents an interesting end-to-end deep retrieval approach.\u00a0 However, the paper suffers from several key limitations:\n\nFirst, it makes a very strong assumption (that vector-based approaches have fundamental limitations).\u00a0 Because this assertion is very strong, it should be backed by a more thorough analysis than what is done on the paper (more details below).\n\nSecond, it fails to take into account several key state-of-the-art methods (such as VAE).\u00a0 The method proposed in the paper might perform significantly worse than this SOTA based on their reported results.\n\nFinally, it brings confusion between two problems:\u00a0the one of choosing an algorithm (vector-based versus deep end-to-end) and the one of choosing a brute-force vs approximate nearest-neighbor.\u00a0 Yet it is well-known that approximate nearest neighbor search is often almost as good as brute-force nearest neighbor, as can be seen here:\u00a0http://ann-benchmarks.com/\n\nThe method presented in the paper is interesting, though.\u00a0 I believe this work could be published, but with significantly more research work.\n\n##########################################################################\nPros:\n\n- Novelty: this paper present a method that, as far as I know, is novel.\n\n- Comparison to tree-based methods: the paper presents an interesting comparison with tree-based approaches\u00a0\n\n##########################################################################\nCons:\u00a0\n\n- Lack of validation: first and foremost, the work presented in this paper lacks validation experiments.\u00a0 For a paper presenting a new algorithm and making a strong claim regarding vector-based methods, we would expect at least 4-5 datasets as is commonly done in the literature, e.g. with MSD, Netflix, Medium, Amazon, Yahoo datasets.\u00a0 We would also expect more metrics, and in particular, the right recall values as is commonly done in the field.\u00a0 In particular, other papers use recall@20 and recall@50 (as can be seen in paperswithcode.com) instead of recall@10.\n\n- Missing state-of-the-art: the paper misses on significant portions of state of the art regarding the evaluation.\u00a0 Several key methods should be included in the evaluation, such as VAEs [1], EASE [2], RACT [3], SLIM [4] and CML [5].\u00a0 While these methods are not end-to-end, the paper should compare its performance against these methods to conclude whether end-to-end deep retrieval yields better (or even similar) performance compared to them.\u00a0 It turns out that some of these methods perform well on recall@20 and maybe better than the method presented in this paper.\u00a0 Note that some of these methods are also sub-linear in the number of items, such as CML.\n\n- The paper is also missing a reference on solving the vector-based limitations, with\u00a0Off-Policy Learning in Two-Stage Recommender Systems [6].\n\n- The paper claims to address \"large-scale\" recommender systems (at several places in the paper) but does not address this aspect.\u00a0 There exist a significant body of literature on the topic of recommender systems operating at the scale of billions of users and items now, e.g. [7], [8].\u00a0 Working at the scale of MovieLens and AmazonBooks is not large-scale.\u00a0 In addition, a complexity analysis of the method would be very welcome.\n\n- Lack of clarity: The clarity of the paper could be greatly improved by putting the description of the algorithm in a single place.\u00a0 At the moment, it is spread between Section 1 and Section 2.1.\u00a0 In particular, Section 1 introduces D and K but does not explain what they are. Some aspects of the algorithms are described in a single line (a GRU is used to project the behavior sequence, but nothing is explained about it).\u00a0\u00a0\n\n- Lack of code: the paper does not provide the code, which does not help for reproducibility and sharing with the community.\u00a0 Providing code is paramount when proposing a new algorithm.\n\n[1]\u00a0Daeryong Kim and Bongwon Suh. 2019. Enhancing VAEs for Collaborative Filtering: Flexible Priors Gating Mechanisms. In Proceedings ofthe 13th ACM Conference on Recommender Systems (RecSys \u201919). Association for Computing Machinery, New York, NY, USA, 403\u2013407. https://doi.org/10.1145/3298689.3347015\n\n[2]\u00a0Harald Steck. 2019. Embarrassingly Shallow Autoencoders for Sparse Data. In The World Wide Web Conference (WWW \u201919). Association forComputing Machinery, New York, NY, USA, 3251\u20133257. https://doi.org/10.1145/3308558.3313710\n\n[3]\u00a0Sam Lobel, Chunyuan Li, Jianfeng Gao, and Lawrence Carin. 2020. RaCT: Toward Amortized Ranking-Critical Training For Collaborative Filtering. InEighth International Conference on Learning Representations (ICLR). https://www.microsoft.com/en-us/research/publication/ract-toward-amortizedranking-critical-training-for-collaborative-filtering/\n\n[4]\u00a0Xia Ning and George Karypis. 2011. SLIM: Sparse Linear Methods for Top-N Recommender Systems. In Proceedings of the 2011 IEEE 11th InternationalConference on Data Mining (ICDM \u201911). IEEE Computer Society, USA, 497\u2013506. https://doi.org/10.1109/ICDM.2011.134\n\n[5]\u00a0Cheng-Kang Hsieh, Longqi Yang, Yin Cui, Tsung-Yi Lin, Serge Belongie, and Deborah Estrin. 2017. Collaborative Metric Learning. In Proceedings ofthe 26th International Conference on World Wide Web (WWW \u201917). International World Wide Web Conferences Steering Committee, Republic andCanton of Geneva, CHE, 193\u2013201. https://doi.org/10.1145/3038912.3052639\n\n[6]\u00a0Jiaqi Ma, Zhe Zhao, Xinyang Yi, Ji Yang, Minmin Chen, Jiaxi Tang, Lichan Hong,\u00a0and Ed H. Chi. 2020. Off-Policy Learning in Two-Stage Recommender Systems.\u00a0In Proceedings of The Web Conference 2020 (WWW \u201920). Association for Computing\u00a0Machinery, New York, NY, USA, 463\u2013473. https://doi.org/10.1145/3366423.\u00a03380130\n\n[7]\u00a0Chantat Eksombatchai, Pranav Jindal, Jerry Zitao Liu, Yuchen Liu, Rahul Sharma,\u00a0Charles Sugnet, Mark Ulrich, and Jure Leskovec. 2018. Pixie: A System for\u00a0Recommending 3+ Billion Items to 200+Million Users in Real-Time. In Proceedings\u00a0of the 2018 World Wide Web Conference (WWW \u201918). International World Wide\u00a0Web Conferences Steering Committee, Republic and Canton of Geneva, CHE,\u00a01775\u20131784. https://doi.org/10.1145/3178876.3186183\n\n[8] JizheWang, Pipei Huang, Huan Zhao, Zhibo Zhang, Binqiang Zhao, and Dik Lun Lee. 2018. Billion-scale Commodity Embedding for E-commerce Recommendation in Alibaba. In Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining (KDD \u201918). ACM, New York, NY, USA, 839\u2013848. https://doi.org/10.1145/3219819.3219869\u00a0\n\n#########################################################################\nSome typos:\u00a0\n\n\"grow\" on page 1\n\n\"from the all successors\" on page 4\n\nupper-case are missing in the references (e.g. ALSH)\n", "rating": "3: Clear rejection", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}, "signatures": ["ICLR.cc/2021/Conference/Paper1423/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1423/AnonReviewer3"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Deep Retrieval: An End-to-End Structure Model for Large-Scale Recommendations", "authorids": ["~Weihao_Gao1", "xiangjun.fan@bytedance.com", "jiankai.sun@bytedance.com", "jiakai@bytedance.com", "xiaowenzhi@bytedance.com", "~Chong_Wang8", "~Xiaobing_Liu1"], "authors": ["Weihao Gao", "Xiangjun Fan", "Jiankai Sun", "Kai Jia", "Wenzhi Xiao", "Chong Wang", "Xiaobing Liu"], "keywords": ["Large-scale recommendation system", "End-to-end training"], "abstract": "One of the core problems in large-scale recommendations is to retrieve top relevant candidates accurately and efficiently, preferably in sub-linear time. Previous approaches are mostly based on a two-step procedure: first learn an inner-product model and then use maximum inner product search (MIPS) algorithms to search top candidates, leading to potential loss of retrieval accuracy. In this paper, we present Deep Retrieval (DR), an end-to-end learnable structure model for large-scale recommendations. DR encodes all candidates into a discrete latent space. Those latent codes for the candidates are model parameters and to be learnt together with other neural network parameters to maximize the same objective function. With the model learnt, a beam search over the latent codes is performed to retrieve the top candidates. Empirically, we showed that DR, with sub-linear computational complexity, can achieve almost the same accuracy as the brute-force baseline.", "one-sentence_summary": "We proposed Deep Retrieval, a novel end-to-end learnable structure model which can accurately and efficiently retrieve top relevant candidates in large-scale recommendation system.", "pdf": "/pdf/a6e0db55154994db5cb1dcdff5875c9025cd658c.pdf", "supplementary_material": "/attachment/55736f81424c35929e923459e9d127fe1e9bb045.zip", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "gao|deep_retrieval_an_endtoend_structure_model_for_largescale_recommendations", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=Hmb1B1IO9", "_bibtex": "@misc{\ngao2021deep,\ntitle={Deep Retrieval: An End-to-End Structure Model for Large-Scale Recommendations},\nauthor={Weihao Gao and Xiangjun Fan and Jiankai Sun and Kai Jia and Wenzhi Xiao and Chong Wang and Xiaobing Liu},\nyear={2021},\nurl={https://openreview.net/forum?id=85d8bg9RvDT}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq . ***Please remember to file the Code-of-Ethics report. Once you submitted the review, a link to the report will be visible in the bottom right corner of your review.***", "required": true, "markdown": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}, "forum": "85d8bg9RvDT", "replyto": "85d8bg9RvDT", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"], "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper1423/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1607428800000, "duedate": 1606752000000, "multiReply": false, "readers": ["everyone"], "tcdate": 1602538118990, "tmdate": 1606915807967, "super": "ICLR.cc/2021/Conference/-/Official_Review", "signatures": ["OpenReview.net"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Paper1423/Reviewers", "OpenReview.net/Support"], "id": "ICLR.cc/2021/Conference/Paper1423/-/Official_Review"}}}, {"id": "6AGcmYEdEMq", "original": null, "number": 3, "cdate": 1603920286460, "ddate": null, "tcdate": 1603920286460, "tmdate": 1605024448928, "tddate": null, "forum": "85d8bg9RvDT", "replyto": "85d8bg9RvDT", "invitation": "ICLR.cc/2021/Conference/Paper1423/-/Official_Review", "content": {"title": "Review", "review": "In this paper, the authors proposed Deep Retrieval, which encodes all items in a discrete latent space for end-to-end retrieval. The proposed method is claimed to perform\u00a0on par with the brute-force method, under sub-linear computational complexity.\n\n1. The authors mainly claim that the objective of learning\u00a0vector representation and good inner-product search are not well aligned, and the dependence on inner-products of user/item embeddings may not be sufficient to capture their interactions. This is an ongoing research discussion on this domain. I'd recommend the authors to refer to a recent paper, proposing the opposite direction from this submission:\nNeural Collaborative Filtering vs. Matrix Factorization Revisited (RecSys 2020)\u00a0https://arxiv.org/abs/2005.09683\n\n2. According to Figure 1, a user embedding is given as an input, and the proposed model outputs probability distribution over all possible item codes, which in turn interpreted as items. That being said, it seems the user embedding is highly important in this model. A user can be modeled in a various ways, e.g., as a sequence of items consumed, or using some meta-data. If the user embeddings are not representative enough, the proposed model may not work, and on the other hand, if the user embedding is strong, it will estimate the probs more precisely. We would like to see more discussion on this.\n\n3. In the experiment, there are multiple points that can be addressed.\u00a0(a) Related to the point #2, the quality of embeddings is not controlled. Thus, comparing DR against brute-force proves that the proposed method is effective on MIPS, but not on the end-to-end retrieval. Ideally, we'd like to see experiments with multiple SOTA embeddings to see if applying DR to those embeddings still improves end-to-end retrieval performance. See examples below.\u00a0(b) The baselines used in the experiment are not representing the current SOTA. Item-based CF is quite an old method, and YouTube DNN is not fully reproducible due to the discrepancy on input features (which are not publicly available outside of YouTube). We recommend comparing against / using embeddings of LLORMA (JMLR'16), EASE^R (WWW'19), and RecVAE (WSDM'20).\u00a0(c) Evaluation metrics are somewhat arbitrary. The authors used only one k for P@k, R@k, and F1@k, arbitrarily chosen for each dataset. This may look like a cherry-picking, so we recommend to report scores with multiple k, e.g., {1, 5, 10, 50, 100}. Taking a metric like MAP or NDCG is another option.\n\n4. The main contribution of this paper seems faster retrieval on MIPS. Overall, the paper is well-written. We recommend adding more intuitive description why the proposed mathematical form guarantees / leads to the optimal / better alignment to the retrieval structure. That is, how/why the use of greedy search leads to the optimal selection of item codes.", "rating": "5: Marginally below acceptance threshold", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "signatures": ["ICLR.cc/2021/Conference/Paper1423/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1423/AnonReviewer2"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Deep Retrieval: An End-to-End Structure Model for Large-Scale Recommendations", "authorids": ["~Weihao_Gao1", "xiangjun.fan@bytedance.com", "jiankai.sun@bytedance.com", "jiakai@bytedance.com", "xiaowenzhi@bytedance.com", "~Chong_Wang8", "~Xiaobing_Liu1"], "authors": ["Weihao Gao", "Xiangjun Fan", "Jiankai Sun", "Kai Jia", "Wenzhi Xiao", "Chong Wang", "Xiaobing Liu"], "keywords": ["Large-scale recommendation system", "End-to-end training"], "abstract": "One of the core problems in large-scale recommendations is to retrieve top relevant candidates accurately and efficiently, preferably in sub-linear time. Previous approaches are mostly based on a two-step procedure: first learn an inner-product model and then use maximum inner product search (MIPS) algorithms to search top candidates, leading to potential loss of retrieval accuracy. In this paper, we present Deep Retrieval (DR), an end-to-end learnable structure model for large-scale recommendations. DR encodes all candidates into a discrete latent space. Those latent codes for the candidates are model parameters and to be learnt together with other neural network parameters to maximize the same objective function. With the model learnt, a beam search over the latent codes is performed to retrieve the top candidates. Empirically, we showed that DR, with sub-linear computational complexity, can achieve almost the same accuracy as the brute-force baseline.", "one-sentence_summary": "We proposed Deep Retrieval, a novel end-to-end learnable structure model which can accurately and efficiently retrieve top relevant candidates in large-scale recommendation system.", "pdf": "/pdf/a6e0db55154994db5cb1dcdff5875c9025cd658c.pdf", "supplementary_material": "/attachment/55736f81424c35929e923459e9d127fe1e9bb045.zip", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "gao|deep_retrieval_an_endtoend_structure_model_for_largescale_recommendations", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=Hmb1B1IO9", "_bibtex": "@misc{\ngao2021deep,\ntitle={Deep Retrieval: An End-to-End Structure Model for Large-Scale Recommendations},\nauthor={Weihao Gao and Xiangjun Fan and Jiankai Sun and Kai Jia and Wenzhi Xiao and Chong Wang and Xiaobing Liu},\nyear={2021},\nurl={https://openreview.net/forum?id=85d8bg9RvDT}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq . ***Please remember to file the Code-of-Ethics report. Once you submitted the review, a link to the report will be visible in the bottom right corner of your review.***", "required": true, "markdown": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}, "forum": "85d8bg9RvDT", "replyto": "85d8bg9RvDT", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"], "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper1423/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1607428800000, "duedate": 1606752000000, "multiReply": false, "readers": ["everyone"], "tcdate": 1602538118990, "tmdate": 1606915807967, "super": "ICLR.cc/2021/Conference/-/Official_Review", "signatures": ["OpenReview.net"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Paper1423/Reviewers", "OpenReview.net/Support"], "id": "ICLR.cc/2021/Conference/Paper1423/-/Official_Review"}}}, {"id": "MiMY80LxWL1", "original": null, "number": 4, "cdate": 1604068140732, "ddate": null, "tcdate": 1604068140732, "tmdate": 1605024448860, "tddate": null, "forum": "85d8bg9RvDT", "replyto": "85d8bg9RvDT", "invitation": "ICLR.cc/2021/Conference/Paper1423/-/Official_Review", "content": {"title": "Algorithmic approach for top-k retrieval", "review": "The paper presents a method for \"end-to-end\" learning for retrieving top-k items in recommendation system setup. This is achieved by learning the hidden representations of the items and under neural network as a single objective function optimized using the expectation maximization framework. It is claimed that the proposed method achives better results than state-of-the-art tree-based models and those approaches which learn these components separately.\n\nSome of the concerns regarding the paper are as follows :\n- The paper lacks a motivation for using the proposed scheme. It says that for tree-based models, the number of parameters is proportional to the number of clusters and hence it is a problem. This is not clear why this is such a problem. Successful application of tree-structure for large-scale problem has been demonstrated in [1,2]. Also, it is not clear how the proposed method addresses data scarcity, which according to the paper happens only in tree-based methods, and not in the proposed method as there are no leaves. \n\n- It is not clear how the proposed structure model (of using K \\times D matrix) is different from the Chen etal 2018. The differences and similarities compared to this work should be clearly specified. Also, what seems to be missing is why such an architecture of using stacked multi-layer perceptrons should lead to better performance especially in positive data-scarcity situations where most of the users 'like' or 'buy' only few items.\n\n- The experimental comparison looks unclear and incomplete. The comparison should also be done with the approach proposed in Zhou etal 2020 ICML paper. At the end of Page 6 it is said that the results of JTM were only available for Amazon Books. How do you make sure that same training and test split (as in JTM) is used as the description says that test and validation set is done randomly. Also, it would also be good to see the code and be able to reproduce the results.\n\n- References of some key papers are based on arxiv versions, such as Chen etal 2018 and Zhou etal. 2020, where both the papers have been accepted in ICML conference of respective years. \n\n[1] Extreme Classification in Log Memory using Count-Min Sketch: A Case Study of Amazon Search with 50M Products, NeurIPS 2019\n\n[2] AttentionXML: Label Tree-based Attention-Aware Deep Model for High-Performance Extreme Multi-Label Text Classification, NeurIPS 2019", "rating": "4: Ok but not good enough - rejection", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "signatures": ["ICLR.cc/2021/Conference/Paper1423/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1423/AnonReviewer1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Deep Retrieval: An End-to-End Structure Model for Large-Scale Recommendations", "authorids": ["~Weihao_Gao1", "xiangjun.fan@bytedance.com", "jiankai.sun@bytedance.com", "jiakai@bytedance.com", "xiaowenzhi@bytedance.com", "~Chong_Wang8", "~Xiaobing_Liu1"], "authors": ["Weihao Gao", "Xiangjun Fan", "Jiankai Sun", "Kai Jia", "Wenzhi Xiao", "Chong Wang", "Xiaobing Liu"], "keywords": ["Large-scale recommendation system", "End-to-end training"], "abstract": "One of the core problems in large-scale recommendations is to retrieve top relevant candidates accurately and efficiently, preferably in sub-linear time. Previous approaches are mostly based on a two-step procedure: first learn an inner-product model and then use maximum inner product search (MIPS) algorithms to search top candidates, leading to potential loss of retrieval accuracy. In this paper, we present Deep Retrieval (DR), an end-to-end learnable structure model for large-scale recommendations. DR encodes all candidates into a discrete latent space. Those latent codes for the candidates are model parameters and to be learnt together with other neural network parameters to maximize the same objective function. With the model learnt, a beam search over the latent codes is performed to retrieve the top candidates. Empirically, we showed that DR, with sub-linear computational complexity, can achieve almost the same accuracy as the brute-force baseline.", "one-sentence_summary": "We proposed Deep Retrieval, a novel end-to-end learnable structure model which can accurately and efficiently retrieve top relevant candidates in large-scale recommendation system.", "pdf": "/pdf/a6e0db55154994db5cb1dcdff5875c9025cd658c.pdf", "supplementary_material": "/attachment/55736f81424c35929e923459e9d127fe1e9bb045.zip", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "gao|deep_retrieval_an_endtoend_structure_model_for_largescale_recommendations", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=Hmb1B1IO9", "_bibtex": "@misc{\ngao2021deep,\ntitle={Deep Retrieval: An End-to-End Structure Model for Large-Scale Recommendations},\nauthor={Weihao Gao and Xiangjun Fan and Jiankai Sun and Kai Jia and Wenzhi Xiao and Chong Wang and Xiaobing Liu},\nyear={2021},\nurl={https://openreview.net/forum?id=85d8bg9RvDT}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq . ***Please remember to file the Code-of-Ethics report. Once you submitted the review, a link to the report will be visible in the bottom right corner of your review.***", "required": true, "markdown": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}, "forum": "85d8bg9RvDT", "replyto": "85d8bg9RvDT", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"], "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper1423/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1607428800000, "duedate": 1606752000000, "multiReply": false, "readers": ["everyone"], "tcdate": 1602538118990, "tmdate": 1606915807967, "super": "ICLR.cc/2021/Conference/-/Official_Review", "signatures": ["OpenReview.net"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Paper1423/Reviewers", "OpenReview.net/Support"], "id": "ICLR.cc/2021/Conference/Paper1423/-/Official_Review"}}}, {"id": "Y9SPZBTcrDA", "original": null, "number": 1, "cdate": 1603781070215, "ddate": null, "tcdate": 1603781070215, "tmdate": 1605024448792, "tddate": null, "forum": "85d8bg9RvDT", "replyto": "85d8bg9RvDT", "invitation": "ICLR.cc/2021/Conference/Paper1423/-/Official_Review", "content": {"title": "Novel attempt without clear motivation and convincing experiments", "review": "The paper seeks to propose an end-to-end learnable retrieval model for recommendation, to replace existing two-step based approaches (learn embeddings first, then do MIPS search).\n\nThe underlying model structure is motivated by KD-code (Chen et al. 2018), where each item is encoded as a D-dimensional discrete vector (with a cardinality K in each dim). Then a conditional, probabilistic framework is proposed to learn the model with a multi-path extension for further improvement. After training, Beam Search is adopted to retrieve top candidates.\n\nThe paper is technically sound, and it's new to adopt a KD-code like model for retrieval. However, I have some concerns in motivation, methods, and experiments.\n\n- The significant feature of the DR model (from the claim in the abstract) to encode all candidates in a discrete latent space. However, there are some previous attempts in this direction that are not discussed. For example VQ-VAE[1] also learns a discrete space. Another more related example is HashRec[2], which (end-to-end) learns binary codes for users and items for efficient hash table retrieval. It's not clear of the connections and why the proposed discrete structure is more suitable.\n\n- The experiments didn't show the superiority of the proposed method. As a retrieval method, the most common comparison method (e.g. https://github.com/erikbern/ann-benchmarks) is the plot of performance-retrieval time, which is absent in this paper. The paper didn't compare the efficiency against the baselines like TDM, JTM, or ANN-based models, which makes the experiments less convincing as the better performance may due to the longer retrieval time.\n\n- It's not clear to me what retrieval/MIPS search methods are adopted for Item-CF, Youtube DNN.\n\n- What's the performance of purely using softmax?\n\n- It seems only DR uses RNNs for sequential behavior modeling, while the baselines didn't. This'd be a unfair comparison, and sequential methods should be included if DR uses RNN and sequential actions for training.\n\n- I didn't understand the motivation of using the multi-path extension. As you already encode each item in D different clusters, this should be enough to express different aspects with a larger D. Why a multi-path variant is needed for making the model more expressive?\n\n- The Beam Search may not guarantee sub-linear time complexity due to the new hyper-parameter B. It's possible that a very large B is needed for retrieving enough candidates.\n\nIn summary, it's not clear to me why the proposed discrete structure is more suitable for the task given we have Tree-based and binary code based approaches (that are also end-to-end learnable). And the experiments didn't show the superiority of the proposed method due to the lack of important comparisons (retrieval time, against HashRec, etc.).\n\n[1]Neural Discrete Representation Learning, NIPS'17\n[2]Candidate Generation with Binary Codes for Large-scale Top-N Recommendation, CIKM'19", "rating": "4: Ok but not good enough - rejection", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["ICLR.cc/2021/Conference/Paper1423/AnonReviewer4"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1423/AnonReviewer4"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Deep Retrieval: An End-to-End Structure Model for Large-Scale Recommendations", "authorids": ["~Weihao_Gao1", "xiangjun.fan@bytedance.com", "jiankai.sun@bytedance.com", "jiakai@bytedance.com", "xiaowenzhi@bytedance.com", "~Chong_Wang8", "~Xiaobing_Liu1"], "authors": ["Weihao Gao", "Xiangjun Fan", "Jiankai Sun", "Kai Jia", "Wenzhi Xiao", "Chong Wang", "Xiaobing Liu"], "keywords": ["Large-scale recommendation system", "End-to-end training"], "abstract": "One of the core problems in large-scale recommendations is to retrieve top relevant candidates accurately and efficiently, preferably in sub-linear time. Previous approaches are mostly based on a two-step procedure: first learn an inner-product model and then use maximum inner product search (MIPS) algorithms to search top candidates, leading to potential loss of retrieval accuracy. In this paper, we present Deep Retrieval (DR), an end-to-end learnable structure model for large-scale recommendations. DR encodes all candidates into a discrete latent space. Those latent codes for the candidates are model parameters and to be learnt together with other neural network parameters to maximize the same objective function. With the model learnt, a beam search over the latent codes is performed to retrieve the top candidates. Empirically, we showed that DR, with sub-linear computational complexity, can achieve almost the same accuracy as the brute-force baseline.", "one-sentence_summary": "We proposed Deep Retrieval, a novel end-to-end learnable structure model which can accurately and efficiently retrieve top relevant candidates in large-scale recommendation system.", "pdf": "/pdf/a6e0db55154994db5cb1dcdff5875c9025cd658c.pdf", "supplementary_material": "/attachment/55736f81424c35929e923459e9d127fe1e9bb045.zip", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "gao|deep_retrieval_an_endtoend_structure_model_for_largescale_recommendations", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=Hmb1B1IO9", "_bibtex": "@misc{\ngao2021deep,\ntitle={Deep Retrieval: An End-to-End Structure Model for Large-Scale Recommendations},\nauthor={Weihao Gao and Xiangjun Fan and Jiankai Sun and Kai Jia and Wenzhi Xiao and Chong Wang and Xiaobing Liu},\nyear={2021},\nurl={https://openreview.net/forum?id=85d8bg9RvDT}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq . ***Please remember to file the Code-of-Ethics report. Once you submitted the review, a link to the report will be visible in the bottom right corner of your review.***", "required": true, "markdown": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}, "forum": "85d8bg9RvDT", "replyto": "85d8bg9RvDT", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"], "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper1423/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1607428800000, "duedate": 1606752000000, "multiReply": false, "readers": ["everyone"], "tcdate": 1602538118990, "tmdate": 1606915807967, "super": "ICLR.cc/2021/Conference/-/Official_Review", "signatures": ["OpenReview.net"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Paper1423/Reviewers", "OpenReview.net/Support"], "id": "ICLR.cc/2021/Conference/Paper1423/-/Official_Review"}}}], "count": 6}