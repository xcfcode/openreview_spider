{"notes": [{"id": "ZwZ3sc0qad", "original": "wm9u-f5RvLmS", "number": 2115, "cdate": 1601308233004, "ddate": null, "tcdate": 1601308233004, "tmdate": 1614985679920, "tddate": null, "forum": "ZwZ3sc0qad", "replyto": null, "invitation": "ICLR.cc/2021/Conference/-/Blind_Submission", "content": {"title": "On Alignment in Deep Linear Neural Networks", "authorids": ["~Adityanarayanan_Radhakrishnan1", "~Eshaan_Nichani1", "dibernst@mit.edu", "~Caroline_Uhler1"], "authors": ["Adityanarayanan Radhakrishnan", "Eshaan Nichani", "Daniel Bernstein", "Caroline Uhler"], "keywords": ["Alignment", "Linear Neural Networks", "Implicit Regularization"], "abstract": "    We study the properties of alignment, a form of implicit regularization, in linear neural networks under gradient descent.  We define alignment for fully connected networks with multidimensional outputs and show that it is a natural extension of alignment in networks with 1-dimensional outputs as defined by Ji and Telgarsky, 2018.  While in fully connected networks, there always exists a global minimum corresponding to an aligned solution, we analyze alignment as it relates to the training process.  Namely, we characterize when alignment is an invariant of training under gradient descent by providing necessary and sufficient conditions for this invariant to hold. In such settings, the dynamics of gradient descent simplify, thereby allowing us to provide an explicit learning rate under which the network converges linearly to a global minimum.  We then analyze networks with layer constraints such as convolutional networks. In this setting, we prove that gradient descent is equivalent to projected gradient descent, and that alignment is impossible with sufficiently large datasets.  \n", "one-sentence_summary": "We study the properties of alignment, a form of implicit regularization, in linear neural networks under gradient descent.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "radhakrishnan|on_alignment_in_deep_linear_neural_networks", "supplementary_material": "/attachment/e9983d1443f60f776ae650f15dda401556b95bfa.zip", "pdf": "/pdf/1d640d09b4b14153e9215e013fb0bda05974459d.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=sjIbfp_jrc", "_bibtex": "@misc{\nradhakrishnan2021on,\ntitle={On Alignment in Deep Linear Neural Networks},\nauthor={Adityanarayanan Radhakrishnan and Eshaan Nichani and Daniel Bernstein and Caroline Uhler},\nyear={2021},\nurl={https://openreview.net/forum?id=ZwZ3sc0qad}\n}"}, "signatures": ["ICLR.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference"], "details": {"replyCount": 10, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"reply": {"readers": {"values-regex": ".*"}, "writers": {"values": ["ICLR.cc/2021/Conference"]}, "signatures": {"values": ["ICLR.cc/2021/Conference"]}, "content": {"authors": {"values": ["Anonymous"]}, "authorids": {"values-regex": ".*"}, "reviewed_version_(pdf)": {"required": false, "description": "Upload a PDF file that ends with .pdf", "value-regex": ".*"}}}, "signatures": ["ICLR.cc/2021/Conference"], "readers": ["everyone"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["~", "OpenReview.net/Support"], "tcdate": 1601308008205, "tmdate": 1614984599368, "id": "ICLR.cc/2021/Conference/-/Blind_Submission"}}, "tauthor": "OpenReview.net"}, {"id": "Ogtx83cWJX0", "original": null, "number": 1, "cdate": 1610040474340, "ddate": null, "tcdate": 1610040474340, "tmdate": 1610474078688, "tddate": null, "forum": "ZwZ3sc0qad", "replyto": "ZwZ3sc0qad", "invitation": "ICLR.cc/2021/Conference/Paper2115/-/Decision", "content": {"title": "Final Decision", "decision": "Reject", "comment": "The consensus view was that the reviewers were not convinced that the analysis done in the paper was sufficient motivated."}, "signatures": ["ICLR.cc/2021/Conference/Program_Chairs"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference/Program_Chairs"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "On Alignment in Deep Linear Neural Networks", "authorids": ["~Adityanarayanan_Radhakrishnan1", "~Eshaan_Nichani1", "dibernst@mit.edu", "~Caroline_Uhler1"], "authors": ["Adityanarayanan Radhakrishnan", "Eshaan Nichani", "Daniel Bernstein", "Caroline Uhler"], "keywords": ["Alignment", "Linear Neural Networks", "Implicit Regularization"], "abstract": "    We study the properties of alignment, a form of implicit regularization, in linear neural networks under gradient descent.  We define alignment for fully connected networks with multidimensional outputs and show that it is a natural extension of alignment in networks with 1-dimensional outputs as defined by Ji and Telgarsky, 2018.  While in fully connected networks, there always exists a global minimum corresponding to an aligned solution, we analyze alignment as it relates to the training process.  Namely, we characterize when alignment is an invariant of training under gradient descent by providing necessary and sufficient conditions for this invariant to hold. In such settings, the dynamics of gradient descent simplify, thereby allowing us to provide an explicit learning rate under which the network converges linearly to a global minimum.  We then analyze networks with layer constraints such as convolutional networks. In this setting, we prove that gradient descent is equivalent to projected gradient descent, and that alignment is impossible with sufficiently large datasets.  \n", "one-sentence_summary": "We study the properties of alignment, a form of implicit regularization, in linear neural networks under gradient descent.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "radhakrishnan|on_alignment_in_deep_linear_neural_networks", "supplementary_material": "/attachment/e9983d1443f60f776ae650f15dda401556b95bfa.zip", "pdf": "/pdf/1d640d09b4b14153e9215e013fb0bda05974459d.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=sjIbfp_jrc", "_bibtex": "@misc{\nradhakrishnan2021on,\ntitle={On Alignment in Deep Linear Neural Networks},\nauthor={Adityanarayanan Radhakrishnan and Eshaan Nichani and Daniel Bernstein and Caroline Uhler},\nyear={2021},\nurl={https://openreview.net/forum?id=ZwZ3sc0qad}\n}"}, "tags": [], "invitation": {"reply": {"forum": "ZwZ3sc0qad", "replyto": "ZwZ3sc0qad", "readers": {"values": ["everyone"]}, "writers": {"values": ["ICLR.cc/2021/Conference/Program_Chairs"]}, "signatures": {"values": ["ICLR.cc/2021/Conference/Program_Chairs"]}, "content": {"title": {"value": "Final Decision"}, "decision": {"value-radio": ["Accept (Oral)", "Accept (Spotlight)", "Accept (Poster)", "Reject"]}, "comment": {"value-regex": "[\\S\\s]{0,50000}", "markdown": true}}}, "multiReply": false, "signatures": ["ICLR.cc/2021/Conference"], "readers": ["everyone"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Program_Chairs"], "tcdate": 1610040474326, "tmdate": 1610474078672, "id": "ICLR.cc/2021/Conference/Paper2115/-/Decision"}}}, {"id": "F1l4iKT7Cyv", "original": null, "number": 2, "cdate": 1603976533989, "ddate": null, "tcdate": 1603976533989, "tmdate": 1606771498880, "tddate": null, "forum": "ZwZ3sc0qad", "replyto": "ZwZ3sc0qad", "invitation": "ICLR.cc/2021/Conference/Paper2115/-/Official_Review", "content": {"title": "Alignment notion too stringent, limited application.", "review": "This article extends the notion of alignment [Ji and Telgarsky, 2018] to linear neural networks with multiple output nodes, which requires the consecutive layers (i+1, i) to have the same (right, left) singular spaces. The authors identify necessary and sufficient conditions under which, alignment is an invariant of the gradient descent iterates (Definition 3), which in particular means that the gradient descent iterates only update the singular values of the layers, and not their singular vectors. The authors studied alignment for several shallow and deep linear architectures, and specify learning rates for which gradient descent enjoys exponential convergence.\n\nHere are my main comments, mostly about the significance of the results.\nAlignment (Definition 2), itself, is a very restrictive assumption: it requires the left and right singular spaces of all consecutive layers to be aligned, i.e. V_{i+1} = U_{i}. In fact, the authors show in Theorem 3 that alignment cannot occur, for a large class of interesting architectures, including convolutional neural networks. Therefore, studying this notion is not well-motivated to begin with.\nAlignment being an invariant of training (Definition 3), is a far more stringent assumption, particularly because it requires the singular spaces of all hidden layers to remain fixed during the training. As it is shown in Theorem 1, this property holds if and only if the input and the output have the same right singular space. On the other hand, when this condition can be satisfied, e.g. for instances that are given in section 4.2, it is not clear if the analysis provides any additional insights/improvements over the previous works.\n\nSome additional comments:\nDefinition 3 requires interpolation under the linear model, i.e., the data is clean (no noise), and the relationship between the output and the input is completely characterized by a linear map, which makes the result less interesting from a practical view. While this setting is well-studied in the literature, this work does not provide comparisons against the previous works.\nMatrix Sensing in section 4.2: how can matrix sensing be an instance of a deep linear network with a multi-dimensional output? Both the labels y_i and the network predictions Tr(M_i^T W_d...W_1) are scalers, and hence 1-dimensional. \n\nTo sum up, the paper studies an extension of alignment [Ji and Telgarsky, 2018] to linear networks with multi-dimensional output. This notion is too stringent -- as the authors confirm in the paper -- and cannot be satisfied unless in some special cases. On the other hand, when the condition can be satisfied, it is not clear if the results provide any insights/improvements over the previous work. For these reasons, I vote for rejecting this submission.\n\n\n========================\nFinal Recommendation\n\nI have read the rebuttal and decided to keep my score. I think this study needs to be further motivated.\nI also want to clarify a minor issue in authors rebuttal. In contributions, you say: \"We demonstrate that alignment is an invariant for fully connected networks with multidimensional outputs only in special problem classes including autoencoding, matrix factorization and matrix sensing. This is in contrast to networks with 1-dimensional outputs, where there exists an initialization...\". My point is that the matrix sensing problem that you study here has 1-dimensional output.\n", "rating": "4: Ok but not good enough - rejection", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["ICLR.cc/2021/Conference/Paper2115/AnonReviewer4"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2115/AnonReviewer4"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "On Alignment in Deep Linear Neural Networks", "authorids": ["~Adityanarayanan_Radhakrishnan1", "~Eshaan_Nichani1", "dibernst@mit.edu", "~Caroline_Uhler1"], "authors": ["Adityanarayanan Radhakrishnan", "Eshaan Nichani", "Daniel Bernstein", "Caroline Uhler"], "keywords": ["Alignment", "Linear Neural Networks", "Implicit Regularization"], "abstract": "    We study the properties of alignment, a form of implicit regularization, in linear neural networks under gradient descent.  We define alignment for fully connected networks with multidimensional outputs and show that it is a natural extension of alignment in networks with 1-dimensional outputs as defined by Ji and Telgarsky, 2018.  While in fully connected networks, there always exists a global minimum corresponding to an aligned solution, we analyze alignment as it relates to the training process.  Namely, we characterize when alignment is an invariant of training under gradient descent by providing necessary and sufficient conditions for this invariant to hold. In such settings, the dynamics of gradient descent simplify, thereby allowing us to provide an explicit learning rate under which the network converges linearly to a global minimum.  We then analyze networks with layer constraints such as convolutional networks. In this setting, we prove that gradient descent is equivalent to projected gradient descent, and that alignment is impossible with sufficiently large datasets.  \n", "one-sentence_summary": "We study the properties of alignment, a form of implicit regularization, in linear neural networks under gradient descent.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "radhakrishnan|on_alignment_in_deep_linear_neural_networks", "supplementary_material": "/attachment/e9983d1443f60f776ae650f15dda401556b95bfa.zip", "pdf": "/pdf/1d640d09b4b14153e9215e013fb0bda05974459d.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=sjIbfp_jrc", "_bibtex": "@misc{\nradhakrishnan2021on,\ntitle={On Alignment in Deep Linear Neural Networks},\nauthor={Adityanarayanan Radhakrishnan and Eshaan Nichani and Daniel Bernstein and Caroline Uhler},\nyear={2021},\nurl={https://openreview.net/forum?id=ZwZ3sc0qad}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq . ***Please remember to file the Code-of-Ethics report. Once you submitted the review, a link to the report will be visible in the bottom right corner of your review.***", "required": true, "markdown": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}, "forum": "ZwZ3sc0qad", "replyto": "ZwZ3sc0qad", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"], "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper2115/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1607428800000, "duedate": 1606752000000, "multiReply": false, "readers": ["everyone"], "tcdate": 1602538103737, "tmdate": 1606915793192, "super": "ICLR.cc/2021/Conference/-/Official_Review", "signatures": ["OpenReview.net"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Paper2115/Reviewers", "OpenReview.net/Support"], "id": "ICLR.cc/2021/Conference/Paper2115/-/Official_Review"}}}, {"id": "OuzriliJJpU", "original": null, "number": 10, "cdate": 1606061308362, "ddate": null, "tcdate": 1606061308362, "tmdate": 1606061408738, "tddate": null, "forum": "ZwZ3sc0qad", "replyto": "pA-VZrtXdZ", "invitation": "ICLR.cc/2021/Conference/Paper2115/-/Official_Comment", "content": {"title": "The notion of alignment is too strong", "comment": "Thanks for the response. I am sorry that I did not notice the supplementary file; indeed a general version of Theorem 1 is provided in Appendix D. \n\nHowever, I still think the notion of alignment is too strong; therefore even though Theorem 1 gives a sufficient and necessary characterization of alignment, its importance is still unclear to me. As I mentioned above, for the matrix factorization and inversion examples, to initialize the network so that Theorem 1 can be applied, we already need to know an unsorted, signed singular value decomposition of the matrix, which is enough to solve the problem. I do not see why such an initialization is reasonable. For example, for linear margin maximization with linear networks, only a very mild condition on the initialization is needed, and specifically the solution is not encoded in the initialization.\n\n"}, "signatures": ["ICLR.cc/2021/Conference/Paper2115/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2115/AnonReviewer1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "On Alignment in Deep Linear Neural Networks", "authorids": ["~Adityanarayanan_Radhakrishnan1", "~Eshaan_Nichani1", "dibernst@mit.edu", "~Caroline_Uhler1"], "authors": ["Adityanarayanan Radhakrishnan", "Eshaan Nichani", "Daniel Bernstein", "Caroline Uhler"], "keywords": ["Alignment", "Linear Neural Networks", "Implicit Regularization"], "abstract": "    We study the properties of alignment, a form of implicit regularization, in linear neural networks under gradient descent.  We define alignment for fully connected networks with multidimensional outputs and show that it is a natural extension of alignment in networks with 1-dimensional outputs as defined by Ji and Telgarsky, 2018.  While in fully connected networks, there always exists a global minimum corresponding to an aligned solution, we analyze alignment as it relates to the training process.  Namely, we characterize when alignment is an invariant of training under gradient descent by providing necessary and sufficient conditions for this invariant to hold. In such settings, the dynamics of gradient descent simplify, thereby allowing us to provide an explicit learning rate under which the network converges linearly to a global minimum.  We then analyze networks with layer constraints such as convolutional networks. In this setting, we prove that gradient descent is equivalent to projected gradient descent, and that alignment is impossible with sufficiently large datasets.  \n", "one-sentence_summary": "We study the properties of alignment, a form of implicit regularization, in linear neural networks under gradient descent.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "radhakrishnan|on_alignment_in_deep_linear_neural_networks", "supplementary_material": "/attachment/e9983d1443f60f776ae650f15dda401556b95bfa.zip", "pdf": "/pdf/1d640d09b4b14153e9215e013fb0bda05974459d.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=sjIbfp_jrc", "_bibtex": "@misc{\nradhakrishnan2021on,\ntitle={On Alignment in Deep Linear Neural Networks},\nauthor={Adityanarayanan Radhakrishnan and Eshaan Nichani and Daniel Bernstein and Caroline Uhler},\nyear={2021},\nurl={https://openreview.net/forum?id=ZwZ3sc0qad}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "ZwZ3sc0qad", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper2115/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper2115/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper2115/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper2115/Authors|ICLR.cc/2021/Conference/Paper2115/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2115/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923852105, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper2115/-/Official_Comment"}}}, {"id": "pA-VZrtXdZ", "original": null, "number": 9, "cdate": 1605801884510, "ddate": null, "tcdate": 1605801884510, "tmdate": 1605801884510, "tddate": null, "forum": "ZwZ3sc0qad", "replyto": "EVZePnIautM", "invitation": "ICLR.cc/2021/Conference/Paper2115/-/Official_Comment", "content": {"title": "Response to Reviewer 1", "comment": "We thank the reviewer for their feedback, and address their concerns below:\n\nWe would first like to clarify that the appendices were indeed provided in the initial submission, and can be viewed if you click the zip download next to the supplementary material (which was presented as an option in the Author FAQ (https://iclr.cc/Conferences/2021/AuthorGuide).\n\n* \u201cTo get a practical algorithm, we need to find such a good initialization, which seems nontrivial\u201d\n    * We would like to emphasize that the purpose of studying gradient descent in linear neural networks is not to devise a practical algorithm for training such networks, but rather to provide intuition on non-convex optimization more generally.\n    * As mentioned in our related work, our definition of invariance of alignment is the same as used in various prior works, e.g. Gidel et. al. (2019), Saxe et. al. (2018), Saxe et. al. (2014), and also the following submission to ICLR 2021 (https://openreview.net/forum?id=D9pSaTGUemb), where this is referred to as \u201cSpectral Initialization\u201d. In particular, our invariance of alignment definition corresponds to the assumption used in Theorem 3 from Gidel et. al. (2019) to study discrete training dynamics and prove linear convergence of gradient descent in a two layer linear network. In our paper, we first establish necessary and sufficient conditions on training data under which this assumption holds (Theorem 1) and then extend the convergence result from Gidel et. al. (2019) to networks of arbitrary depth (Proposition 2). \n    * Since the purpose of analyzing the training dynamics of linear neural networks is to gain intuition around how gradient descent can converge to a global minimum in non-convex settings, our work shows that when initialized to be aligned, deep linear neural networks converge linearly to a global minimum. We feel that our analysis of these assumptions from prior work provide an important positive result relevant to the study of linear neural networks. In addition, we believe it is equally important to understand the limitations of assumptions used in prior works and we therefore argue that our negative results are also of high relevance.\n* \u201cTheorem 1 requires the input dimension to be the same as the output dimension\u201d\n    * Before the statement of Theorem 1 we clearly state \u201cTo simplify notation, we consider the case when the layers are square matrices, i.e. $k_i = k_j$ for all $0 \\le i, j \\le d$. The general result for non-square matrices is provided in Appendix D.\u201d"}, "signatures": ["ICLR.cc/2021/Conference/Paper2115/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2115/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "On Alignment in Deep Linear Neural Networks", "authorids": ["~Adityanarayanan_Radhakrishnan1", "~Eshaan_Nichani1", "dibernst@mit.edu", "~Caroline_Uhler1"], "authors": ["Adityanarayanan Radhakrishnan", "Eshaan Nichani", "Daniel Bernstein", "Caroline Uhler"], "keywords": ["Alignment", "Linear Neural Networks", "Implicit Regularization"], "abstract": "    We study the properties of alignment, a form of implicit regularization, in linear neural networks under gradient descent.  We define alignment for fully connected networks with multidimensional outputs and show that it is a natural extension of alignment in networks with 1-dimensional outputs as defined by Ji and Telgarsky, 2018.  While in fully connected networks, there always exists a global minimum corresponding to an aligned solution, we analyze alignment as it relates to the training process.  Namely, we characterize when alignment is an invariant of training under gradient descent by providing necessary and sufficient conditions for this invariant to hold. In such settings, the dynamics of gradient descent simplify, thereby allowing us to provide an explicit learning rate under which the network converges linearly to a global minimum.  We then analyze networks with layer constraints such as convolutional networks. In this setting, we prove that gradient descent is equivalent to projected gradient descent, and that alignment is impossible with sufficiently large datasets.  \n", "one-sentence_summary": "We study the properties of alignment, a form of implicit regularization, in linear neural networks under gradient descent.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "radhakrishnan|on_alignment_in_deep_linear_neural_networks", "supplementary_material": "/attachment/e9983d1443f60f776ae650f15dda401556b95bfa.zip", "pdf": "/pdf/1d640d09b4b14153e9215e013fb0bda05974459d.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=sjIbfp_jrc", "_bibtex": "@misc{\nradhakrishnan2021on,\ntitle={On Alignment in Deep Linear Neural Networks},\nauthor={Adityanarayanan Radhakrishnan and Eshaan Nichani and Daniel Bernstein and Caroline Uhler},\nyear={2021},\nurl={https://openreview.net/forum?id=ZwZ3sc0qad}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "ZwZ3sc0qad", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper2115/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper2115/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper2115/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper2115/Authors|ICLR.cc/2021/Conference/Paper2115/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2115/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923852105, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper2115/-/Official_Comment"}}}, {"id": "Ru9bOwQRFl5", "original": null, "number": 8, "cdate": 1605801721110, "ddate": null, "tcdate": 1605801721110, "tmdate": 1605801721110, "tddate": null, "forum": "ZwZ3sc0qad", "replyto": "F1l4iKT7Cyv", "invitation": "ICLR.cc/2021/Conference/Paper2115/-/Official_Comment", "content": {"title": "Response to Reviewer 4", "comment": "We thank the reviewer for their feedback, and address their concerns below:\n* \u201cTherefore, studying this notion is not well-motivated to begin with.\u201d\n    * As mentioned in our related work, our definition of invariance of alignment is the same as used in various prior works, e.g. Gidel et. al. (2019), Saxe et. al. (2018), Saxe et. al. (2014), and also the following submission to ICLR 2021 (https://openreview.net/forum?id=D9pSaTGUemb), where this is referred to as \u201cSpectral Initialization\u201d. In particular, our invariance of alignment definition corresponds to the assumption used in Theorem 3 from Gidel et. al. (2019) to study discrete training dynamics and prove linear convergence of gradient descent in a two layer linear network. In our paper, we first establish necessary and sufficient conditions on training data under which this assumption holds (Theorem 1) and then extend the convergence result from Gidel et. al. (2019) to networks of arbitrary depth (Proposition 2). \n    * Since the purpose of analyzing the training dynamics of linear neural networks is to gain intuition around how gradient descent can converge to a global minimum in non-convex settings, our work shows that when initialized to be aligned, deep linear neural networks converge linearly to a global minimum. We feel that our analysis of these assumptions from prior work provide an important positive result relevant to the study of linear neural networks. In addition, we believe it is equally important to understand the limitations of assumptions used in prior works and we therefore argue that our negative results are also of high relevance.\n* \u201c...the relationship between the output and the input is completely characterized by a linear map, which makes the result less interesting from a practical view. While this setting is well-studied in the literature, this work does not provide comparisons against the previous works\u201d\n    * All of the works we discuss extensively in our related work section (Ji & Telgarsky (2018), Gidel et al. (2019), Saxe et al. (2014, 2019), Arora et al. (2018), Du et al. (2018)) rely on the assumption that the output is a linear function of the input.\n    * In fact, virtually all previous work on linear neural networks assumes that a linear network can perfectly interpolate the data. This is because we are interested in the dynamics of gradient descent in the overparameterized regime, where there are infinitely many solutions which perfectly fit the data and we would like to understand which of these solutions is learned by the network.\n* \u201c Matrix Sensing in section 4.2: how can matrix sensing be an instance of a deep linear network with a multi-dimensional output?\u201d\n    * As written, the matrix sensing case involves parameters that are all multi-dimensional $W_1, W_2, \\ldots W_d$.  \n"}, "signatures": ["ICLR.cc/2021/Conference/Paper2115/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2115/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "On Alignment in Deep Linear Neural Networks", "authorids": ["~Adityanarayanan_Radhakrishnan1", "~Eshaan_Nichani1", "dibernst@mit.edu", "~Caroline_Uhler1"], "authors": ["Adityanarayanan Radhakrishnan", "Eshaan Nichani", "Daniel Bernstein", "Caroline Uhler"], "keywords": ["Alignment", "Linear Neural Networks", "Implicit Regularization"], "abstract": "    We study the properties of alignment, a form of implicit regularization, in linear neural networks under gradient descent.  We define alignment for fully connected networks with multidimensional outputs and show that it is a natural extension of alignment in networks with 1-dimensional outputs as defined by Ji and Telgarsky, 2018.  While in fully connected networks, there always exists a global minimum corresponding to an aligned solution, we analyze alignment as it relates to the training process.  Namely, we characterize when alignment is an invariant of training under gradient descent by providing necessary and sufficient conditions for this invariant to hold. In such settings, the dynamics of gradient descent simplify, thereby allowing us to provide an explicit learning rate under which the network converges linearly to a global minimum.  We then analyze networks with layer constraints such as convolutional networks. In this setting, we prove that gradient descent is equivalent to projected gradient descent, and that alignment is impossible with sufficiently large datasets.  \n", "one-sentence_summary": "We study the properties of alignment, a form of implicit regularization, in linear neural networks under gradient descent.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "radhakrishnan|on_alignment_in_deep_linear_neural_networks", "supplementary_material": "/attachment/e9983d1443f60f776ae650f15dda401556b95bfa.zip", "pdf": "/pdf/1d640d09b4b14153e9215e013fb0bda05974459d.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=sjIbfp_jrc", "_bibtex": "@misc{\nradhakrishnan2021on,\ntitle={On Alignment in Deep Linear Neural Networks},\nauthor={Adityanarayanan Radhakrishnan and Eshaan Nichani and Daniel Bernstein and Caroline Uhler},\nyear={2021},\nurl={https://openreview.net/forum?id=ZwZ3sc0qad}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "ZwZ3sc0qad", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper2115/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper2115/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper2115/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper2115/Authors|ICLR.cc/2021/Conference/Paper2115/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2115/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923852105, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper2115/-/Official_Comment"}}}, {"id": "hQWtRtt9FqF", "original": null, "number": 7, "cdate": 1605801577725, "ddate": null, "tcdate": 1605801577725, "tmdate": 1605801577725, "tddate": null, "forum": "ZwZ3sc0qad", "replyto": "gMwfR00_963", "invitation": "ICLR.cc/2021/Conference/Paper2115/-/Official_Comment", "content": {"title": "Response to Reviewer 2", "comment": "We thank the reviewer for their feedback, and their positive comments. We address their concerns:\n* \u201cHowever, the constraints on the datasets X and Y in Theorem 1 are pretty stringent. It might be interesting to present a study on how realistic these conditions are in practice.\u201d\n    * In Section 4.2, we discuss common problems for which the data condition is satisfied, including autoencoding, matrix factorization/inversion, matrix sensing, and networks with 1d outputs.\n    * Furthermore, we note that these constraints on the data are implicit in various prior works e.g. Gidel et. al. (2019), Saxe et. al. (2018), Saxe et. al. (2014).\n"}, "signatures": ["ICLR.cc/2021/Conference/Paper2115/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2115/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "On Alignment in Deep Linear Neural Networks", "authorids": ["~Adityanarayanan_Radhakrishnan1", "~Eshaan_Nichani1", "dibernst@mit.edu", "~Caroline_Uhler1"], "authors": ["Adityanarayanan Radhakrishnan", "Eshaan Nichani", "Daniel Bernstein", "Caroline Uhler"], "keywords": ["Alignment", "Linear Neural Networks", "Implicit Regularization"], "abstract": "    We study the properties of alignment, a form of implicit regularization, in linear neural networks under gradient descent.  We define alignment for fully connected networks with multidimensional outputs and show that it is a natural extension of alignment in networks with 1-dimensional outputs as defined by Ji and Telgarsky, 2018.  While in fully connected networks, there always exists a global minimum corresponding to an aligned solution, we analyze alignment as it relates to the training process.  Namely, we characterize when alignment is an invariant of training under gradient descent by providing necessary and sufficient conditions for this invariant to hold. In such settings, the dynamics of gradient descent simplify, thereby allowing us to provide an explicit learning rate under which the network converges linearly to a global minimum.  We then analyze networks with layer constraints such as convolutional networks. In this setting, we prove that gradient descent is equivalent to projected gradient descent, and that alignment is impossible with sufficiently large datasets.  \n", "one-sentence_summary": "We study the properties of alignment, a form of implicit regularization, in linear neural networks under gradient descent.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "radhakrishnan|on_alignment_in_deep_linear_neural_networks", "supplementary_material": "/attachment/e9983d1443f60f776ae650f15dda401556b95bfa.zip", "pdf": "/pdf/1d640d09b4b14153e9215e013fb0bda05974459d.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=sjIbfp_jrc", "_bibtex": "@misc{\nradhakrishnan2021on,\ntitle={On Alignment in Deep Linear Neural Networks},\nauthor={Adityanarayanan Radhakrishnan and Eshaan Nichani and Daniel Bernstein and Caroline Uhler},\nyear={2021},\nurl={https://openreview.net/forum?id=ZwZ3sc0qad}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "ZwZ3sc0qad", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper2115/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper2115/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper2115/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper2115/Authors|ICLR.cc/2021/Conference/Paper2115/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2115/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923852105, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper2115/-/Official_Comment"}}}, {"id": "jAmrmHmHZXz", "original": null, "number": 6, "cdate": 1605801516589, "ddate": null, "tcdate": 1605801516589, "tmdate": 1605801516589, "tddate": null, "forum": "ZwZ3sc0qad", "replyto": "uT18Q9yla7", "invitation": "ICLR.cc/2021/Conference/Paper2115/-/Official_Comment", "content": {"title": "Response to Reviewer 3", "comment": "We thank the reviewer for their feedback, and address their concerns below:\n\n* \u201cThis definition is significantly different and a much stronger condition compared to similar properties in prior work\u201d\n    * As mentioned in our related work, our definition of invariance of alignment is the same as used in various prior works, e.g. Gidel et. al. (2019), Saxe et. al. (2018), Saxe et. al. (2014), and also the following submission to ICLR 2021 (https://openreview.net/forum?id=D9pSaTGUemb), where this is referred to as \u201cSpectral Initialization\u201d. In particular, our invariance of alignment definition corresponds to the assumption used in Theorem 3 from Gidel et. al. (2019) to study discrete training dynamics and prove linear convergence of gradient descent in a two layer linear network. In our paper, we first establish necessary and sufficient conditions on training data under which this assumption holds (Theorem 1) and then extend the convergence result from Gidel et. al. (2019) to networks of arbitrary depth (Proposition 2). \n    * Since the purpose of analyzing the training dynamics of linear neural networks is to gain intuition around how gradient descent can converge to a global minimum in non-convex settings, our work shows that when initialized to be aligned, deep linear neural networks converge linearly to a global minimum. We feel that our analysis of these assumptions from prior work provide an important positive result relevant to the study of linear neural networks. In addition, we believe it is equally important to understand the limitations of assumptions used in prior works and we therefore argue that our negative results are also of high relevance.\n* \u201cIn practice, this condition almost always never holds without requiring circular computations.\u201d\n    * We would like to emphasize that the purpose of studying gradient descent in linear neural networks is not to devise a practical algorithm for training such networks, but rather to provide intuition on non-convex optimization more generally.\n* \u201cmany existing results show convergence of gradient descent under often much less restrictive conditions, e.g., with just balancedness at initialization\u201d\n    * We would like to emphasize that balancedness is a restrictive condition, as it assumes that the singular values between layers are equal. Our definitions do not assume anything about the singular values of each layer."}, "signatures": ["ICLR.cc/2021/Conference/Paper2115/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2115/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "On Alignment in Deep Linear Neural Networks", "authorids": ["~Adityanarayanan_Radhakrishnan1", "~Eshaan_Nichani1", "dibernst@mit.edu", "~Caroline_Uhler1"], "authors": ["Adityanarayanan Radhakrishnan", "Eshaan Nichani", "Daniel Bernstein", "Caroline Uhler"], "keywords": ["Alignment", "Linear Neural Networks", "Implicit Regularization"], "abstract": "    We study the properties of alignment, a form of implicit regularization, in linear neural networks under gradient descent.  We define alignment for fully connected networks with multidimensional outputs and show that it is a natural extension of alignment in networks with 1-dimensional outputs as defined by Ji and Telgarsky, 2018.  While in fully connected networks, there always exists a global minimum corresponding to an aligned solution, we analyze alignment as it relates to the training process.  Namely, we characterize when alignment is an invariant of training under gradient descent by providing necessary and sufficient conditions for this invariant to hold. In such settings, the dynamics of gradient descent simplify, thereby allowing us to provide an explicit learning rate under which the network converges linearly to a global minimum.  We then analyze networks with layer constraints such as convolutional networks. In this setting, we prove that gradient descent is equivalent to projected gradient descent, and that alignment is impossible with sufficiently large datasets.  \n", "one-sentence_summary": "We study the properties of alignment, a form of implicit regularization, in linear neural networks under gradient descent.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "radhakrishnan|on_alignment_in_deep_linear_neural_networks", "supplementary_material": "/attachment/e9983d1443f60f776ae650f15dda401556b95bfa.zip", "pdf": "/pdf/1d640d09b4b14153e9215e013fb0bda05974459d.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=sjIbfp_jrc", "_bibtex": "@misc{\nradhakrishnan2021on,\ntitle={On Alignment in Deep Linear Neural Networks},\nauthor={Adityanarayanan Radhakrishnan and Eshaan Nichani and Daniel Bernstein and Caroline Uhler},\nyear={2021},\nurl={https://openreview.net/forum?id=ZwZ3sc0qad}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "ZwZ3sc0qad", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper2115/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper2115/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper2115/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper2115/Authors|ICLR.cc/2021/Conference/Paper2115/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2115/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923852105, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper2115/-/Official_Comment"}}}, {"id": "EVZePnIautM", "original": null, "number": 1, "cdate": 1603658646466, "ddate": null, "tcdate": 1603658646466, "tmdate": 1605024285854, "tddate": null, "forum": "ZwZ3sc0qad", "replyto": "ZwZ3sc0qad", "invitation": "ICLR.cc/2021/Conference/Paper2115/-/Official_Review", "content": {"title": "A characterization of alignment in deep linear networks", "review": "This paper considers deep linear networks trained by gradient descent with the squared loss, and characterizes when alignment happens, meaning that for any pair of adjacent weight matrices W_{i+1} and W_i, the (unsorted, signed) right singular vectors of W_{i+1} are identical to the (unsorted, signed) left singular vectors of W_i. This paper further gives a few examples where the conditions of alignment hold, and proves a convergence rate for aligned networks. For networks with constrained layer structure, such as convolutional networks, this paper shows that aligned networks in general cannot achieve zero training error with the squared loss. Finally, empirical support of the theory is provided.\n\nI think this paper provides a nice necessary and sufficient condition for alignment in deep linear networks, which simplifies the training dynamic and let us prove a linear convergence rate. On the other hand, when the layer structure is constrained, it is shown that aligned networks in general cannot achieve zero training error, which is interesting. \n\nHowever, there are some weaknesses that should be noticed:\n1. As given by Definition 3, if alignment is an invariant of training, it only means that there exists a good initialization. To get a practical algorithm, we need to find such a good initialization, which seems nontrivial. For example, matrix factorization and inversion are mentioned as an example which satisfies the conditions of Theorem 1, but according to the proof of Theorem 1, to factorize or inverse a matrix M, we need to initialize the first and last weight matrices using an unsorted, signed singular value decomposition of M, which does not make sense. \n2. Theorem 1 requires the input dimension to be the same as the output dimension, and it only uses square layers, which I think means that each hidden width is also equal to the input dimension. This setting is pretty restrictive; for example, autoencoding is mentioned as an example of Theorem 1, but if the hidden widths are equal to the input dimension, then there seems to be no point to do such an encoding. On the other hand, Corollary 1 doesn't seem to need the hidden widths to be identical, which is inconsistent.\n\nAdditionally, the appendices should be provided. ", "rating": "4: Ok but not good enough - rejection", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["ICLR.cc/2021/Conference/Paper2115/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2115/AnonReviewer1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "On Alignment in Deep Linear Neural Networks", "authorids": ["~Adityanarayanan_Radhakrishnan1", "~Eshaan_Nichani1", "dibernst@mit.edu", "~Caroline_Uhler1"], "authors": ["Adityanarayanan Radhakrishnan", "Eshaan Nichani", "Daniel Bernstein", "Caroline Uhler"], "keywords": ["Alignment", "Linear Neural Networks", "Implicit Regularization"], "abstract": "    We study the properties of alignment, a form of implicit regularization, in linear neural networks under gradient descent.  We define alignment for fully connected networks with multidimensional outputs and show that it is a natural extension of alignment in networks with 1-dimensional outputs as defined by Ji and Telgarsky, 2018.  While in fully connected networks, there always exists a global minimum corresponding to an aligned solution, we analyze alignment as it relates to the training process.  Namely, we characterize when alignment is an invariant of training under gradient descent by providing necessary and sufficient conditions for this invariant to hold. In such settings, the dynamics of gradient descent simplify, thereby allowing us to provide an explicit learning rate under which the network converges linearly to a global minimum.  We then analyze networks with layer constraints such as convolutional networks. In this setting, we prove that gradient descent is equivalent to projected gradient descent, and that alignment is impossible with sufficiently large datasets.  \n", "one-sentence_summary": "We study the properties of alignment, a form of implicit regularization, in linear neural networks under gradient descent.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "radhakrishnan|on_alignment_in_deep_linear_neural_networks", "supplementary_material": "/attachment/e9983d1443f60f776ae650f15dda401556b95bfa.zip", "pdf": "/pdf/1d640d09b4b14153e9215e013fb0bda05974459d.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=sjIbfp_jrc", "_bibtex": "@misc{\nradhakrishnan2021on,\ntitle={On Alignment in Deep Linear Neural Networks},\nauthor={Adityanarayanan Radhakrishnan and Eshaan Nichani and Daniel Bernstein and Caroline Uhler},\nyear={2021},\nurl={https://openreview.net/forum?id=ZwZ3sc0qad}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq . ***Please remember to file the Code-of-Ethics report. Once you submitted the review, a link to the report will be visible in the bottom right corner of your review.***", "required": true, "markdown": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}, "forum": "ZwZ3sc0qad", "replyto": "ZwZ3sc0qad", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"], "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper2115/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1607428800000, "duedate": 1606752000000, "multiReply": false, "readers": ["everyone"], "tcdate": 1602538103737, "tmdate": 1606915793192, "super": "ICLR.cc/2021/Conference/-/Official_Review", "signatures": ["OpenReview.net"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Paper2115/Reviewers", "OpenReview.net/Support"], "id": "ICLR.cc/2021/Conference/Paper2115/-/Official_Review"}}}, {"id": "gMwfR00_963", "original": null, "number": 3, "cdate": 1604101413670, "ddate": null, "tcdate": 1604101413670, "tmdate": 1605024285737, "tddate": null, "forum": "ZwZ3sc0qad", "replyto": "ZwZ3sc0qad", "invitation": "ICLR.cc/2021/Conference/Paper2115/-/Official_Review", "content": {"title": "The paper studies the concept of alignment in deep neural networks in the context of linear networks with multidimensional outputs. ", "review": "The paper presents an extension of the idea of alignment in linear neural networks, that can help in providing convergence analysis of such networks. Such a notion was previously studied for networks with a single output. The current paper extends it to networks with multi-dimensional outputs. The paper offers multiple interesting results: a) conditions on the datasets where alignment can remain invariant b) lack of alignment or invariance for networks with constrained layers \n\nThe paper is very clearly written and is offers a coherent explanation of the ideas presented. The presented theoretical results are interesting. However, the constraints on the datasets X and Y in Theorem 1 are pretty stringent. It might be interesting to present a study on how realistic these conditions are in practice.  \n\n", "rating": "7: Good paper, accept", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "signatures": ["ICLR.cc/2021/Conference/Paper2115/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2115/AnonReviewer2"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "On Alignment in Deep Linear Neural Networks", "authorids": ["~Adityanarayanan_Radhakrishnan1", "~Eshaan_Nichani1", "dibernst@mit.edu", "~Caroline_Uhler1"], "authors": ["Adityanarayanan Radhakrishnan", "Eshaan Nichani", "Daniel Bernstein", "Caroline Uhler"], "keywords": ["Alignment", "Linear Neural Networks", "Implicit Regularization"], "abstract": "    We study the properties of alignment, a form of implicit regularization, in linear neural networks under gradient descent.  We define alignment for fully connected networks with multidimensional outputs and show that it is a natural extension of alignment in networks with 1-dimensional outputs as defined by Ji and Telgarsky, 2018.  While in fully connected networks, there always exists a global minimum corresponding to an aligned solution, we analyze alignment as it relates to the training process.  Namely, we characterize when alignment is an invariant of training under gradient descent by providing necessary and sufficient conditions for this invariant to hold. In such settings, the dynamics of gradient descent simplify, thereby allowing us to provide an explicit learning rate under which the network converges linearly to a global minimum.  We then analyze networks with layer constraints such as convolutional networks. In this setting, we prove that gradient descent is equivalent to projected gradient descent, and that alignment is impossible with sufficiently large datasets.  \n", "one-sentence_summary": "We study the properties of alignment, a form of implicit regularization, in linear neural networks under gradient descent.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "radhakrishnan|on_alignment_in_deep_linear_neural_networks", "supplementary_material": "/attachment/e9983d1443f60f776ae650f15dda401556b95bfa.zip", "pdf": "/pdf/1d640d09b4b14153e9215e013fb0bda05974459d.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=sjIbfp_jrc", "_bibtex": "@misc{\nradhakrishnan2021on,\ntitle={On Alignment in Deep Linear Neural Networks},\nauthor={Adityanarayanan Radhakrishnan and Eshaan Nichani and Daniel Bernstein and Caroline Uhler},\nyear={2021},\nurl={https://openreview.net/forum?id=ZwZ3sc0qad}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq . ***Please remember to file the Code-of-Ethics report. Once you submitted the review, a link to the report will be visible in the bottom right corner of your review.***", "required": true, "markdown": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}, "forum": "ZwZ3sc0qad", "replyto": "ZwZ3sc0qad", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"], "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper2115/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1607428800000, "duedate": 1606752000000, "multiReply": false, "readers": ["everyone"], "tcdate": 1602538103737, "tmdate": 1606915793192, "super": "ICLR.cc/2021/Conference/-/Official_Review", "signatures": ["OpenReview.net"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Paper2115/Reviewers", "OpenReview.net/Support"], "id": "ICLR.cc/2021/Conference/Paper2115/-/Official_Review"}}}, {"id": "uT18Q9yla7", "original": null, "number": 4, "cdate": 1604182076143, "ddate": null, "tcdate": 1604182076143, "tmdate": 1605024285670, "tddate": null, "forum": "ZwZ3sc0qad", "replyto": "ZwZ3sc0qad", "invitation": "ICLR.cc/2021/Conference/Paper2115/-/Official_Review", "content": {"title": "Insufficient motivation for the studying the strong definition of \"alignment invariance\"", "review": "The paper introduces the property of *alignment invariance* of gradient descent for linear networks. Under this definition (Definition 3) the left singular vectors of the linear transform in layer i is aligned with right singular vectors of i+1, and further the definition requires that the singular vectors remain constant throughout the training process (only the singular values are updated along gradient updates). The main theorem derives the necessary and sufficient conditions under which such a notion of alignment invariance is possible. The paper further shows that when such a condition holds, the trajectories of gradient descent are simplified for analysis of convergence speed. \n\nMy main concern with the paper is that the definition of alignment invariance in Def 3 is very restrictive and the motivation for considering such strong conditions is not sufficiently justified.\n1. This definition is significantly different and a much stronger condition compared to similar  properties in prior work: (a) \u201calignment\u201d in Ji & Telgarsky 2018 (for 1D output) refers to condition where only the final converged solution has aligned singular vectors, but at initialization and throughout training the alignment and invariance need not (and does not) hold, and (b) the balancedness in Arora et al. 2018 and Du et al. 2018 (for gradient flow) are conditions on W_i^TW_i^T-W_{i+1}W_{i+1} being small throughout training. This requires that the singular values be nearly aligned but they need not be constant through the training process. This is a significant difference as for any dataset, the balancedness W_i^TW_i^T-W_{i+1}W_{i+1} can be shown to always be an invariant through gradient flow but that is not true for singular vectors. \n\n2. In practice, this condition almost always never holds without requiring circular computations. For example, in order to initialize an autoencoder to satisfy Def 3, one needs to do know the spectral decomposition of data matrix X, which is in fact the primary computation performed by linear autoencoders! Also, No examples are provided where predictors obtained through such restrictive flows lead to useful models. \n\n3. It is ok to consider restrictive assumptions if such assumptions provide significant new insights and results that are atleast somewhat relevant in practice. However the main use case for this Def 3 in the paper is that these conditions make the analysis of convergence speed of gradient descent simpler. But for linear networks, even though the underlying problem is non-convex, many existing results show convergence of gradient descent under often much less restrictive conditions, e.g., with just balancedness at initialization in Arora et al. 2019a. More specifically, the paper shows Def 3 leads to simplified dynamics, but it is not demonstrated how one can use the simplified dynamics to derive new results/insights that were not previously known. Finally, in terms of pure analysis, although the paper extends for deeper networks, the key proof ideas are similar to those of Gidel et al. 2019. \n\n", "rating": "4: Ok but not good enough - rejection", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}, "signatures": ["ICLR.cc/2021/Conference/Paper2115/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2115/AnonReviewer3"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "On Alignment in Deep Linear Neural Networks", "authorids": ["~Adityanarayanan_Radhakrishnan1", "~Eshaan_Nichani1", "dibernst@mit.edu", "~Caroline_Uhler1"], "authors": ["Adityanarayanan Radhakrishnan", "Eshaan Nichani", "Daniel Bernstein", "Caroline Uhler"], "keywords": ["Alignment", "Linear Neural Networks", "Implicit Regularization"], "abstract": "    We study the properties of alignment, a form of implicit regularization, in linear neural networks under gradient descent.  We define alignment for fully connected networks with multidimensional outputs and show that it is a natural extension of alignment in networks with 1-dimensional outputs as defined by Ji and Telgarsky, 2018.  While in fully connected networks, there always exists a global minimum corresponding to an aligned solution, we analyze alignment as it relates to the training process.  Namely, we characterize when alignment is an invariant of training under gradient descent by providing necessary and sufficient conditions for this invariant to hold. In such settings, the dynamics of gradient descent simplify, thereby allowing us to provide an explicit learning rate under which the network converges linearly to a global minimum.  We then analyze networks with layer constraints such as convolutional networks. In this setting, we prove that gradient descent is equivalent to projected gradient descent, and that alignment is impossible with sufficiently large datasets.  \n", "one-sentence_summary": "We study the properties of alignment, a form of implicit regularization, in linear neural networks under gradient descent.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "radhakrishnan|on_alignment_in_deep_linear_neural_networks", "supplementary_material": "/attachment/e9983d1443f60f776ae650f15dda401556b95bfa.zip", "pdf": "/pdf/1d640d09b4b14153e9215e013fb0bda05974459d.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=sjIbfp_jrc", "_bibtex": "@misc{\nradhakrishnan2021on,\ntitle={On Alignment in Deep Linear Neural Networks},\nauthor={Adityanarayanan Radhakrishnan and Eshaan Nichani and Daniel Bernstein and Caroline Uhler},\nyear={2021},\nurl={https://openreview.net/forum?id=ZwZ3sc0qad}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq . ***Please remember to file the Code-of-Ethics report. Once you submitted the review, a link to the report will be visible in the bottom right corner of your review.***", "required": true, "markdown": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}, "forum": "ZwZ3sc0qad", "replyto": "ZwZ3sc0qad", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"], "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper2115/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1607428800000, "duedate": 1606752000000, "multiReply": false, "readers": ["everyone"], "tcdate": 1602538103737, "tmdate": 1606915793192, "super": "ICLR.cc/2021/Conference/-/Official_Review", "signatures": ["OpenReview.net"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Paper2115/Reviewers", "OpenReview.net/Support"], "id": "ICLR.cc/2021/Conference/Paper2115/-/Official_Review"}}}], "count": 11}