{"notes": [{"ddate": null, "legacy_migration": true, "tmdate": 1392611340000, "tcdate": 1392611340000, "number": 4, "id": "Ftelj_S85VjH4", "invitation": "ICLR.cc/2014/-/submission/conference/review", "forum": "srkxraD5zAMCX", "replyto": "srkxraD5zAMCX", "signatures": ["Balazs Kegl"], "readers": ["everyone"], "writers": ["anonymous"], "content": {"title": "", "review": "'To my opinion, an important contribution is the use of boosting in an auto-associative setting to select a subset of pixels that is used to select the neighborhoods, however, this appears in the paper only as a speedup trick. From an image processing viewpoint, what are these most predictive pixels picked up by Adaboost? This actually a very neat representation learning trick I have not seen elsewhere.'\r\n\r\nThe selected pixels (and channels) are in Figure 2. \r\n\r\nWe have experimented for a while with autoassociative boosting about six years ago to replace autoassociative neural nets, it worked nicely for the first layer but stacking never improved the error, so we dropped the line of research."}, "nonreaders": [], "details": {"replyCount": 0, "overwriting": [], "revisions": false, "forumContent": {"title": "Correlation-based construction of neighborhood and edge features", "decision": "submitted, no decision", "abstract": "Motivated by an abstract notion of low-level edge detector filters, we propose a simple method of unsupervised feature construction based on pairwise statistics of features. In the first step, we construct neighborhoods of features by regrouping features that correlate. Then we use these subsets as filters to produce new neighborhood features. Next, we connect neighborhood features that correlate, and construct edge features by subtracting the correlated neighborhood features of each other. To validate the usefulness of the constructed features, we ran AdaBoost.MH on four multi-class classification problems. Our most significant result is a test error of 0.94% on MNIST with an algorithm which is essentially free of any image-specific priors. On CIFAR-10 our method is suboptimal compared to today's best deep learning techniques, nevertheless, we show that the proposed method outperforms not only boosting on the raw pixels, but also boosting on Haar filters.", "pdf": "https://arxiv.org/abs/1312.7335", "paperhash": "k\u00e9gl|correlationbased_construction_of_neighborhood_and_edge_features", "authors": ["Bal\u00e1zs K\u00e9gl"], "authorids": ["balazs.kegl@gmail.com"], "keywords": [], "conflicts": []}, "tags": [], "invitation": {}}}, {"ddate": null, "legacy_migration": true, "tmdate": 1392611280000, "tcdate": 1392611280000, "number": 1, "id": "DDNVMlw3s76Jb", "invitation": "ICLR.cc/2014/-/submission/conference/reply", "forum": "srkxraD5zAMCX", "replyto": "_voA_q1WJavfX", "signatures": ["Balazs Kegl"], "readers": ["everyone"], "writers": ["anonymous"], "content": {"title": "", "reply": "'Why not run something like a linear SVM on top of the constructed features?'\r\n\r\nYes, this could be done, although note that after 400K iterations (of 4-leaf trees), boosting is using all features several times, so SVM would be just another way to combine all the features. I chose boosting because we have a good 'in-house' implementation, because on raw pixels on MNIST it outperforms SVMs (1.25% vs 1.4%), and in general, our implementation of AdaBoost.MH is on par with SVMs (see my other submission to ICLR)."}, "nonreaders": [], "details": {"replyCount": 0, "overwriting": [], "revisions": false, "forumContent": {"title": "Correlation-based construction of neighborhood and edge features", "decision": "submitted, no decision", "abstract": "Motivated by an abstract notion of low-level edge detector filters, we propose a simple method of unsupervised feature construction based on pairwise statistics of features. In the first step, we construct neighborhoods of features by regrouping features that correlate. Then we use these subsets as filters to produce new neighborhood features. Next, we connect neighborhood features that correlate, and construct edge features by subtracting the correlated neighborhood features of each other. To validate the usefulness of the constructed features, we ran AdaBoost.MH on four multi-class classification problems. Our most significant result is a test error of 0.94% on MNIST with an algorithm which is essentially free of any image-specific priors. On CIFAR-10 our method is suboptimal compared to today's best deep learning techniques, nevertheless, we show that the proposed method outperforms not only boosting on the raw pixels, but also boosting on Haar filters.", "pdf": "https://arxiv.org/abs/1312.7335", "paperhash": "k\u00e9gl|correlationbased_construction_of_neighborhood_and_edge_features", "authors": ["Bal\u00e1zs K\u00e9gl"], "authorids": ["balazs.kegl@gmail.com"], "keywords": [], "conflicts": []}, "tags": [], "invitation": {}}}, {"ddate": null, "legacy_migration": true, "tmdate": 1392611220000, "tcdate": 1392611220000, "number": 1, "id": "uurzmOgjnbmX1", "invitation": "ICLR.cc/2014/-/submission/conference/reply", "forum": "srkxraD5zAMCX", "replyto": "IILuhH0xutIc8", "signatures": ["Balazs Kegl"], "readers": ["everyone"], "writers": ["anonymous"], "content": {"title": "", "reply": "'I find the section Constructing the representation hard to follow. It would help to use a much more detailed description. Also, under 1. the term 'features' is used to refer to the learned representations as well as to pixels (second page, after 1.)',\r\n\r\nThis is sort of an intended terminology since 1) all these features (including pixels) are representations of the input, and 2) the procedure can be applied recursively, as in stacked autoencoders. I added the adjective 'raw' in some places where where it is clear that I am talking about pixels. I also added a footnote to make this choice explicit.\r\n\r\n'under 2. the same indexes are used on the two sides of the equal sign'\r\n\r\nCorrected. Thanks for spotting this.\r\n\r\n'and under 3. defining the symbol 'equal with triangle on top' would help.'\r\n\r\nIt was a shorthand for defining (a notation for) elements of the edge set, and I agree that it is confusing. I split the sentence and made the definition of the notation explicit.\r\n\r\n'The result of CIFAR-10 seems encouraging. Is this without image priors (that is, permutation invariant)?'\r\n\r\nYes, that's exactly the point.\r\n\r\n'As is, I find the paper quite hard to read, and it will be important to improve the clarity of the presentation.'\r\n\r\nPlease point out the exact problems and confusing notations/notions, I would be happy to take your concrete suggestions into account.\r\n\r\nI uploaded a new version to arxiv with the suggested corrections."}, "nonreaders": [], "details": {"replyCount": 0, "overwriting": [], "revisions": false, "forumContent": {"title": "Correlation-based construction of neighborhood and edge features", "decision": "submitted, no decision", "abstract": "Motivated by an abstract notion of low-level edge detector filters, we propose a simple method of unsupervised feature construction based on pairwise statistics of features. In the first step, we construct neighborhoods of features by regrouping features that correlate. Then we use these subsets as filters to produce new neighborhood features. Next, we connect neighborhood features that correlate, and construct edge features by subtracting the correlated neighborhood features of each other. To validate the usefulness of the constructed features, we ran AdaBoost.MH on four multi-class classification problems. Our most significant result is a test error of 0.94% on MNIST with an algorithm which is essentially free of any image-specific priors. On CIFAR-10 our method is suboptimal compared to today's best deep learning techniques, nevertheless, we show that the proposed method outperforms not only boosting on the raw pixels, but also boosting on Haar filters.", "pdf": "https://arxiv.org/abs/1312.7335", "paperhash": "k\u00e9gl|correlationbased_construction_of_neighborhood_and_edge_features", "authors": ["Bal\u00e1zs K\u00e9gl"], "authorids": ["balazs.kegl@gmail.com"], "keywords": [], "conflicts": []}, "tags": [], "invitation": {}}}, {"ddate": null, "legacy_migration": true, "tmdate": 1391978580000, "tcdate": 1391978580000, "number": 3, "id": "qQc-FS6LJ1Fix", "invitation": "ICLR.cc/2014/-/submission/conference/review", "forum": "srkxraD5zAMCX", "replyto": "srkxraD5zAMCX", "signatures": ["anonymous reviewer 1142"], "readers": ["everyone"], "writers": ["anonymous"], "content": {"title": "review of Correlation-based construction of neighborhood and edge features", "review": "In its present form, the paper proposes a very neat task-agnostic feature transformation trick that brings Adaboost nearly up to the start of the art on image classification tasks, which is quite a feat. The trick seems so far to bring top performance on tasks where there are known feature correlations (like pixels) but not on others.\r\n\r\nWhile it would be a nice workshop contribution  in its present state, I think it requires some work to be a significant contribution to representation learning: some important aspects of the work are not properly explained, and experiments only use one algorithm (Adaboost.MH with hamming trees) and would need to be try  other algorithms (SVMs, first layer of deep learning).\r\n\r\nThe authors take the traditional local smoothing and edge detection used for image processing, but remove all knowledge that pixels are adjacent. Thus the smoothing can be done on any set of pixels provided they are similar (measured through correlation). The correlation is measured again between smoothed pixels to determine edges. I assume this is original, as in its exhaustive form, one would probably discard the method as computationally not practical (I assume it scales as O(N_example*N_features^2)).\r\nTo my opinion, an important contribution is the use of boosting in an auto-associative setting to select a subset of pixels that is used to select the neighborhoods, however, this appears in the paper only as a speedup trick. From an image processing viewpoint, what are these most predictive pixels picked up by Adaboost? This actually a very neat representation learning trick I have not seen elsewhere."}, "nonreaders": [], "details": {"replyCount": 0, "overwriting": [], "revisions": false, "forumContent": {"title": "Correlation-based construction of neighborhood and edge features", "decision": "submitted, no decision", "abstract": "Motivated by an abstract notion of low-level edge detector filters, we propose a simple method of unsupervised feature construction based on pairwise statistics of features. In the first step, we construct neighborhoods of features by regrouping features that correlate. Then we use these subsets as filters to produce new neighborhood features. Next, we connect neighborhood features that correlate, and construct edge features by subtracting the correlated neighborhood features of each other. To validate the usefulness of the constructed features, we ran AdaBoost.MH on four multi-class classification problems. Our most significant result is a test error of 0.94% on MNIST with an algorithm which is essentially free of any image-specific priors. On CIFAR-10 our method is suboptimal compared to today's best deep learning techniques, nevertheless, we show that the proposed method outperforms not only boosting on the raw pixels, but also boosting on Haar filters.", "pdf": "https://arxiv.org/abs/1312.7335", "paperhash": "k\u00e9gl|correlationbased_construction_of_neighborhood_and_edge_features", "authors": ["Bal\u00e1zs K\u00e9gl"], "authorids": ["balazs.kegl@gmail.com"], "keywords": [], "conflicts": []}, "tags": [], "invitation": {}}}, {"ddate": null, "legacy_migration": true, "tmdate": 1391940420000, "tcdate": 1391940420000, "number": 2, "id": "_voA_q1WJavfX", "invitation": "ICLR.cc/2014/-/submission/conference/review", "forum": "srkxraD5zAMCX", "replyto": "srkxraD5zAMCX", "signatures": ["anonymous reviewer 1cb9"], "readers": ["everyone"], "writers": ["anonymous"], "content": {"title": "review of Correlation-based construction of neighborhood and edge features", "review": "The paper proposes a method for feature construction/augmentation based on grouping features that correlate, in an iterative/recursive fashion. These feature sets are validated using AdaBoost.MH and a few interesting results on MNIST and CIFAR are presented, as well as a few interesting negative results. The authors claim a relatively state of the art results on MNIST (without using image priors). While the CIFAR results are not as competitive with state of the art, they do improve on the boosting state of the art.\r\n\r\nThe method is relatively simple: group features that correlate, then connect neighborhood features that correlate and construct edge features by subtracting the correlated neighborhood features. The authors suggest this was inspired by biology/Haar/Gabor filters, but I am not sure this connection is particularly informative.  A hybrid AdaBoost.MH with decision stumps (for picking the features to augment) with AdaBoost.MH + Hamming trees was run.\r\n\r\nOn MNIST this gives a 0.94% test error, which sounds like state-of-the-art(-ish). Interestingly, on CIFAR-10 this kind of approach beats boosting approaches on top of Harr filter features (though is not very close to state of the art!). For smaller and lower-dimensional datasets, the gains are relatively small -- the authors hypothesize that this is because the dimensionality is too low basically.\r\n\r\nWhy not run something like a linear SVM on top of the constructed features? I think it would be an interesting result too. Or even just a second-degree polynomial expansion of the feature-set found by the decision stump phase? Would make the results in this paper stronger, in my opinion: right now, it\u2019s unclear if the extra gain is because of the clever selection of which features to combine or simply because features were combined at all."}, "nonreaders": [], "details": {"replyCount": 0, "overwriting": [], "revisions": false, "forumContent": {"title": "Correlation-based construction of neighborhood and edge features", "decision": "submitted, no decision", "abstract": "Motivated by an abstract notion of low-level edge detector filters, we propose a simple method of unsupervised feature construction based on pairwise statistics of features. In the first step, we construct neighborhoods of features by regrouping features that correlate. Then we use these subsets as filters to produce new neighborhood features. Next, we connect neighborhood features that correlate, and construct edge features by subtracting the correlated neighborhood features of each other. To validate the usefulness of the constructed features, we ran AdaBoost.MH on four multi-class classification problems. Our most significant result is a test error of 0.94% on MNIST with an algorithm which is essentially free of any image-specific priors. On CIFAR-10 our method is suboptimal compared to today's best deep learning techniques, nevertheless, we show that the proposed method outperforms not only boosting on the raw pixels, but also boosting on Haar filters.", "pdf": "https://arxiv.org/abs/1312.7335", "paperhash": "k\u00e9gl|correlationbased_construction_of_neighborhood_and_edge_features", "authors": ["Bal\u00e1zs K\u00e9gl"], "authorids": ["balazs.kegl@gmail.com"], "keywords": [], "conflicts": []}, "tags": [], "invitation": {}}}, {"ddate": null, "legacy_migration": true, "tmdate": 1391482500000, "tcdate": 1391482500000, "number": 1, "id": "IILuhH0xutIc8", "invitation": "ICLR.cc/2014/-/submission/conference/review", "forum": "srkxraD5zAMCX", "replyto": "srkxraD5zAMCX", "signatures": ["anonymous reviewer d9df"], "readers": ["everyone"], "writers": ["anonymous"], "content": {"title": "review of Correlation-based construction of neighborhood and edge features", "review": "The paper proposes a new method for constructing features by hand. Features are constructed as follows: First, one averages the input dimensions that are strongly correlated (for images these will be nearby pixels). Then one attaches to the result the differences between subsets of pairs of these features which are still highly correlated.\r\n\r\nThe beginning of the introduction is just a copy of the abstract. \r\n\r\nI find the section Constructing the representation hard to follow. It would help to use a much more detailed description. Also, under 1. the term 'features' is used to refer to the learned representations as well as to pixels (second page, after 1.), under 2. the same indexes are used on the two sides of the equal sign, and under 3. defining the symbol 'equal with triangle on top' would help.\r\n\r\nThe construction of the features reminded me of locally binary patterns LBP (unless I am missing something), so it feels like it would be good to compare to these.\r\n\r\nWhile 94 errors on MNIST seems decent, the method contains a huge number of hyperparameters (first level correlation threshold, second level correlation threshold, several boosting parameters, size and choice of random matrix to estimate correlations etc. etc. etc.).\r\n\r\nThe result of CIFAR-10 seems encouraging. Is this without image priors (that is, permutation invariant)?\r\n\r\nAs is, I find the paper quite hard to read, and it will be important to improve the clarity of the presentation."}, "nonreaders": [], "details": {"replyCount": 0, "overwriting": [], "revisions": false, "forumContent": {"title": "Correlation-based construction of neighborhood and edge features", "decision": "submitted, no decision", "abstract": "Motivated by an abstract notion of low-level edge detector filters, we propose a simple method of unsupervised feature construction based on pairwise statistics of features. In the first step, we construct neighborhoods of features by regrouping features that correlate. Then we use these subsets as filters to produce new neighborhood features. Next, we connect neighborhood features that correlate, and construct edge features by subtracting the correlated neighborhood features of each other. To validate the usefulness of the constructed features, we ran AdaBoost.MH on four multi-class classification problems. Our most significant result is a test error of 0.94% on MNIST with an algorithm which is essentially free of any image-specific priors. On CIFAR-10 our method is suboptimal compared to today's best deep learning techniques, nevertheless, we show that the proposed method outperforms not only boosting on the raw pixels, but also boosting on Haar filters.", "pdf": "https://arxiv.org/abs/1312.7335", "paperhash": "k\u00e9gl|correlationbased_construction_of_neighborhood_and_edge_features", "authors": ["Bal\u00e1zs K\u00e9gl"], "authorids": ["balazs.kegl@gmail.com"], "keywords": [], "conflicts": []}, "tags": [], "invitation": {}}}, {"replyto": null, "ddate": null, "legacy_migration": true, "tmdate": 1388551380000, "tcdate": 1388551380000, "number": 63, "id": "srkxraD5zAMCX", "invitation": "ICLR.cc/2014/conference/-/submission", "forum": "srkxraD5zAMCX", "signatures": ["balazs.kegl@gmail.com"], "readers": ["everyone"], "content": {"title": "Correlation-based construction of neighborhood and edge features", "decision": "submitted, no decision", "abstract": "Motivated by an abstract notion of low-level edge detector filters, we propose a simple method of unsupervised feature construction based on pairwise statistics of features. In the first step, we construct neighborhoods of features by regrouping features that correlate. Then we use these subsets as filters to produce new neighborhood features. Next, we connect neighborhood features that correlate, and construct edge features by subtracting the correlated neighborhood features of each other. To validate the usefulness of the constructed features, we ran AdaBoost.MH on four multi-class classification problems. Our most significant result is a test error of 0.94% on MNIST with an algorithm which is essentially free of any image-specific priors. On CIFAR-10 our method is suboptimal compared to today's best deep learning techniques, nevertheless, we show that the proposed method outperforms not only boosting on the raw pixels, but also boosting on Haar filters.", "pdf": "https://arxiv.org/abs/1312.7335", "paperhash": "k\u00e9gl|correlationbased_construction_of_neighborhood_and_edge_features", "authors": ["Bal\u00e1zs K\u00e9gl"], "authorids": ["balazs.kegl@gmail.com"], "keywords": [], "conflicts": []}, "writers": [], "details": {"replyCount": 6, "writable": false, "overwriting": [], "revisions": false, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1369422751717, "tmdate": 1496674357195, "id": "ICLR.cc/2014/conference/-/submission", "writers": ["ICLR.cc/2014"], "signatures": ["OpenReview.net"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": null, "replyto": null, "writers": {"values-regex": "~.*"}, "signatures": {"values-regex": "~.*", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"pdf": {"required": true, "order": 5, "description": "Either upload a PDF file or provide a direct link to your PDF on ArXiv (link must begin with http(s) and end with .pdf)", "value-regex": "upload|(http|https):\\/\\/.+\\.pdf"}, "title": {"required": true, "order": 1, "description": "Title of paper.", "value-regex": ".{1,250}"}, "abstract": {"required": true, "order": 4, "description": "Abstract of paper.", "value-regex": "[\\S\\s]{1,5000}"}, "authors": {"required": true, "order": 2, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of author names, as they appear in the paper."}, "conflicts": {"required": true, "order": 100, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of email domains of people who would have a conflict of interest in reviewing this paper, (e.g., cs.umass.edu;google.com, etc.)."}, "keywords": {"order": 6, "description": "Comma separated list of keywords.", "values-dropdown": []}, "authorids": {"required": true, "order": 3, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of author email addresses, in the same order as above."}}}, "nonreaders": [], "noninvitees": [], "expdate": 1377198751717, "cdate": 1496674357195}}}], "count": 7}