{"notes": [{"id": "BJx-ZeSKDB", "original": "SkxhlkgKPS", "number": 2124, "cdate": 1569439736571, "ddate": null, "tcdate": 1569439736571, "tmdate": 1578602605084, "tddate": null, "forum": "BJx-ZeSKDB", "replyto": null, "invitation": "ICLR.cc/2020/Conference/-/Blind_Submission", "content": {"authorids": ["zli14@wpi.edu", "jrwhitehill@wpi.edu"], "title": "Compositional Embeddings: Joint Perception and Comparison of Class Label Sets", "authors": ["Zeqian Li", "Jacob Whitehill"], "pdf": "/pdf/a333627776f0de437c16e52965a359a273a9b83f.pdf", "TL;DR": "We explored how a novel method of compositional set embeddings can both perceive and represent not just a single class but an entire set of classes that is associated with the input data.", "abstract": "We explore the idea of compositional set embeddings that can be used to infer not\njust a single class, but the set of classes associated with the input data (e.g., image,\nvideo, audio signal). This can be useful, for example, in multi-object detection in\nimages, or multi-speaker diarization (one-shot learning) in audio. In particular, we\ndevise and implement two novel models consisting of (1) an embedding function\nf trained jointly with a \u201ccomposite\u201d function g that computes set union opera-\ntions between the classes encoded in two embedding vectors; and (2) embedding\nf trained jointly with a \u201cquery\u201d function h that computes whether the classes en-\ncoded in one embedding subsume the classes encoded in another embedding. In\ncontrast to prior work, these models must both perceive the classes associated\nwith the input examples, and also encode the relationships between different class\nlabel sets. In experiments conducted on simulated data, OmniGlot, and COCO\ndatasets, the proposed composite embedding models outperform baselines based\non traditional embedding approaches.", "code": "https://drive.google.com/open?id=1zjsK9DP3CUqwcVSNwDPshIxOV5hQwFxt", "keywords": ["Embedding", "One-shot Learning", "Compositional Representation"], "paperhash": "li|compositional_embeddings_joint_perception_and_comparison_of_class_label_sets", "original_pdf": "/attachment/a5e01dada21b04be59e3475000c1c3d9859364d1.pdf", "_bibtex": "@misc{\nli2020compositional,\ntitle={Compositional Embeddings: Joint Perception and Comparison of Class Label Sets},\nauthor={Zeqian Li and Jacob Whitehill},\nyear={2020},\nurl={https://openreview.net/forum?id=BJx-ZeSKDB}\n}"}, "signatures": ["ICLR.cc/2020/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference"], "details": {"replyCount": 8, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"reply": {"readers": {"values-regex": ".*"}, "writers": {"values": ["ICLR.cc/2020/Conference"]}, "signatures": {"values": ["ICLR.cc/2020/Conference"]}, "content": {"spotlight_video": {"value-regex": ".*"}, "full_presentation_video": {"value-regex": ".*"}, "original_pdf": {"required": false, "description": "Upload a PDF file that ends with .pdf", "value-regex": ".*"}, "appendix": {"value-regex": ".*"}, "authorids": {"values-regex": ".*"}, "poster": {"value-regex": ".*"}, "authors": {"values": ["Anonymous"]}, "slides": {"value-regex": ".*"}}}, "final": [], "signatures": ["ICLR.cc/2020/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference"], "noninvitees": [], "tcdate": 1569271260237, "tmdate": 1593459412141, "id": "ICLR.cc/2020/Conference/-/Blind_Submission"}}, "tauthor": "OpenReview.net"}, {"id": "Eq55j-Xan0", "original": null, "number": 1, "cdate": 1576798741180, "ddate": null, "tcdate": 1576798741180, "tmdate": 1576800895044, "tddate": null, "forum": "BJx-ZeSKDB", "replyto": "BJx-ZeSKDB", "invitation": "ICLR.cc/2020/Conference/Paper2124/-/Decision", "content": {"decision": "Reject", "comment": "The authors propose a new type of compositional embedding (with two proposed variants) for performing tasks that involve set relationships between examples (say, images) containing sets of classes (say, objects).  The setting is new and the reviewers are mostly in agreement (after discussion and revision) that the approach is interesting and the results encouraging.  There is some concern, however, that the task setup may be too contrived, and that in any real task there could be a more obvious baseline that would do better.  For example, one task setup requires that examples be represented via embeddings, and no reference can be made to the original inputs; this is justified in a setting where space is a constraint, but the combination of this setting with the specific set query tasks considered seems quite rare.  The paper may be an example of a hammer in search of a nail.  The ideas are interesting and the paper is written well, and so the authors can hopefully refine the proposed class of problems toward more practical settings.", "title": "Paper Decision"}, "signatures": ["ICLR.cc/2020/Conference/Program_Chairs"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Program_Chairs"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["zli14@wpi.edu", "jrwhitehill@wpi.edu"], "title": "Compositional Embeddings: Joint Perception and Comparison of Class Label Sets", "authors": ["Zeqian Li", "Jacob Whitehill"], "pdf": "/pdf/a333627776f0de437c16e52965a359a273a9b83f.pdf", "TL;DR": "We explored how a novel method of compositional set embeddings can both perceive and represent not just a single class but an entire set of classes that is associated with the input data.", "abstract": "We explore the idea of compositional set embeddings that can be used to infer not\njust a single class, but the set of classes associated with the input data (e.g., image,\nvideo, audio signal). This can be useful, for example, in multi-object detection in\nimages, or multi-speaker diarization (one-shot learning) in audio. In particular, we\ndevise and implement two novel models consisting of (1) an embedding function\nf trained jointly with a \u201ccomposite\u201d function g that computes set union opera-\ntions between the classes encoded in two embedding vectors; and (2) embedding\nf trained jointly with a \u201cquery\u201d function h that computes whether the classes en-\ncoded in one embedding subsume the classes encoded in another embedding. In\ncontrast to prior work, these models must both perceive the classes associated\nwith the input examples, and also encode the relationships between different class\nlabel sets. In experiments conducted on simulated data, OmniGlot, and COCO\ndatasets, the proposed composite embedding models outperform baselines based\non traditional embedding approaches.", "code": "https://drive.google.com/open?id=1zjsK9DP3CUqwcVSNwDPshIxOV5hQwFxt", "keywords": ["Embedding", "One-shot Learning", "Compositional Representation"], "paperhash": "li|compositional_embeddings_joint_perception_and_comparison_of_class_label_sets", "original_pdf": "/attachment/a5e01dada21b04be59e3475000c1c3d9859364d1.pdf", "_bibtex": "@misc{\nli2020compositional,\ntitle={Compositional Embeddings: Joint Perception and Comparison of Class Label Sets},\nauthor={Zeqian Li and Jacob Whitehill},\nyear={2020},\nurl={https://openreview.net/forum?id=BJx-ZeSKDB}\n}"}, "tags": [], "invitation": {"reply": {"writers": {"description": "How your identity will be displayed.", "values-regex": ["ICLR.cc/2020/Conference/Program_Chairs"]}, "signatures": {"values": ["ICLR.cc/2020/Conference/Program_Chairs"], "description": "How your identity will be displayed."}, "content": {"decision": {"value-radio": ["Accept (Spotlight)", "Accept (Talk)", "Accept (Poster)", "Reject"], "description": "Decision", "required": true, "order": 2}, "title": {"value": "Paper Decision", "required": true, "order": 1}, "comment": {"value-regex": "[\\S\\s]{0,5000}", "description": "", "required": false, "order": 3}}, "forum": "BJx-ZeSKDB", "replyto": "BJx-ZeSKDB", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}}, "expdate": 1576854540000, "duedate": 1576853940000, "multiReply": false, "readers": ["everyone"], "invitees": ["ICLR.cc/2020/Conference/Program_Chairs"], "tcdate": 1576795713573, "tmdate": 1576800263217, "super": "ICLR.cc/2020/Conference/-/Decision", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper2124/-/Decision"}}}, {"id": "Hkx7Kvvk5S", "original": null, "number": 3, "cdate": 1571940218771, "ddate": null, "tcdate": 1571940218771, "tmdate": 1574474444551, "tddate": null, "forum": "BJx-ZeSKDB", "replyto": "BJx-ZeSKDB", "invitation": "ICLR.cc/2020/Conference/Paper2124/-/Official_Review", "content": {"experience_assessment": "I have read many papers in this area.", "rating": "6: Weak Accept", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "title": "Official Blind Review #2", "review": "This paper describes a way to train functions that are able to represent the union of classes as well as to query if the classes in an image subsume the classes in another image. This is done throughly jointly training embedding functions, a set union function and a query function. The paper reads well.\n\nWhile the approach is reasonable, the experiments seem to be quite incomplete and no explanation is given why a trivial solution cannot be used instead of the learnt functions.\n\nThe paper argues for learning a set union function however much of the evaluation focuses on quite small sets of 2 or 3 items. On the evaluation that utilises larger sets, e.g. COCO, there isn't any analysis of how performance of the technique scales with the size of the set since that would be one of the defining characteristics of a set union function. The COCO experiment is also lacking in detail, for example, how many items are there in the positive and negative sets and how the test set is balanced. Finally, it seems that f, g and h could be trivial non-learnt functions. For example, f could be a function that maps an image to a binary representation of its classes (this could be a typical ResNet image classifier), g could be a function that does a binary OR of its two arguments and h could be a function that uses a binary AND and equality test on its two arguments. In this case, g and h don't need to be learnt at all. This may not be possible in the COCO experiment where the individual labels are not known but it seems quite unrealistic to have a dataset where only pairwise subset relationships are known.\n\nIt also seems that the f is always different between that used with g and that used with h, is this the case? SimRef also doesn't do data augmentation but there's no explanation why it is done for the proposed method and not for this baseline. The MF baseline in experiment 1 seems to be a straw man especially since the baselines in experiment 2 are much stronger.\n\n================================================================================\nUpdate after rebuttal:\n\nThanks for answering my questions and performing the additional experiments with a ResNet baseline and performing an additional analysis based on the number of subclasses in figure 5. I think these provide a substantially better analysis of the algorithm so I've increased my score correspondingly. For the final paper, I think it would be good to add TradEmb/ResNet to figure 5 as well to understand how those methods scale worse/better with the number of subclasses.", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory."}, "signatures": ["ICLR.cc/2020/Conference/Paper2124/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper2124/AnonReviewer2"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["zli14@wpi.edu", "jrwhitehill@wpi.edu"], "title": "Compositional Embeddings: Joint Perception and Comparison of Class Label Sets", "authors": ["Zeqian Li", "Jacob Whitehill"], "pdf": "/pdf/a333627776f0de437c16e52965a359a273a9b83f.pdf", "TL;DR": "We explored how a novel method of compositional set embeddings can both perceive and represent not just a single class but an entire set of classes that is associated with the input data.", "abstract": "We explore the idea of compositional set embeddings that can be used to infer not\njust a single class, but the set of classes associated with the input data (e.g., image,\nvideo, audio signal). This can be useful, for example, in multi-object detection in\nimages, or multi-speaker diarization (one-shot learning) in audio. In particular, we\ndevise and implement two novel models consisting of (1) an embedding function\nf trained jointly with a \u201ccomposite\u201d function g that computes set union opera-\ntions between the classes encoded in two embedding vectors; and (2) embedding\nf trained jointly with a \u201cquery\u201d function h that computes whether the classes en-\ncoded in one embedding subsume the classes encoded in another embedding. In\ncontrast to prior work, these models must both perceive the classes associated\nwith the input examples, and also encode the relationships between different class\nlabel sets. In experiments conducted on simulated data, OmniGlot, and COCO\ndatasets, the proposed composite embedding models outperform baselines based\non traditional embedding approaches.", "code": "https://drive.google.com/open?id=1zjsK9DP3CUqwcVSNwDPshIxOV5hQwFxt", "keywords": ["Embedding", "One-shot Learning", "Compositional Representation"], "paperhash": "li|compositional_embeddings_joint_perception_and_comparison_of_class_label_sets", "original_pdf": "/attachment/a5e01dada21b04be59e3475000c1c3d9859364d1.pdf", "_bibtex": "@misc{\nli2020compositional,\ntitle={Compositional Embeddings: Joint Perception and Comparison of Class Label Sets},\nauthor={Zeqian Li and Jacob Whitehill},\nyear={2020},\nurl={https://openreview.net/forum?id=BJx-ZeSKDB}\n}"}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "BJx-ZeSKDB", "replyto": "BJx-ZeSKDB", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper2124/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper2124/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1575798100269, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper2124/Reviewers"], "noninvitees": [], "tcdate": 1570237727363, "tmdate": 1575798100285, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper2124/-/Official_Review"}}}, {"id": "HJg9EJB2oB", "original": null, "number": 4, "cdate": 1573830449940, "ddate": null, "tcdate": 1573830449940, "tmdate": 1573830449940, "tddate": null, "forum": "BJx-ZeSKDB", "replyto": "BJx-ZeSKDB", "invitation": "ICLR.cc/2020/Conference/Paper2124/-/Official_Comment", "content": {"title": "Reviewers, any comments on the author response?", "comment": "Dear Reviewers, thanks for your thoughtful input on this submission!  The authors have now responded to your comments.  Please be sure to go through their replies and revisions.  If you have additional feedback or questions, it would be great to know.  The authors still have one more day to respond/revise further.  Thanks!\n"}, "signatures": ["ICLR.cc/2020/Conference/Paper2124/Area_Chair1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper2124/Area_Chair1", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["zli14@wpi.edu", "jrwhitehill@wpi.edu"], "title": "Compositional Embeddings: Joint Perception and Comparison of Class Label Sets", "authors": ["Zeqian Li", "Jacob Whitehill"], "pdf": "/pdf/a333627776f0de437c16e52965a359a273a9b83f.pdf", "TL;DR": "We explored how a novel method of compositional set embeddings can both perceive and represent not just a single class but an entire set of classes that is associated with the input data.", "abstract": "We explore the idea of compositional set embeddings that can be used to infer not\njust a single class, but the set of classes associated with the input data (e.g., image,\nvideo, audio signal). This can be useful, for example, in multi-object detection in\nimages, or multi-speaker diarization (one-shot learning) in audio. In particular, we\ndevise and implement two novel models consisting of (1) an embedding function\nf trained jointly with a \u201ccomposite\u201d function g that computes set union opera-\ntions between the classes encoded in two embedding vectors; and (2) embedding\nf trained jointly with a \u201cquery\u201d function h that computes whether the classes en-\ncoded in one embedding subsume the classes encoded in another embedding. In\ncontrast to prior work, these models must both perceive the classes associated\nwith the input examples, and also encode the relationships between different class\nlabel sets. In experiments conducted on simulated data, OmniGlot, and COCO\ndatasets, the proposed composite embedding models outperform baselines based\non traditional embedding approaches.", "code": "https://drive.google.com/open?id=1zjsK9DP3CUqwcVSNwDPshIxOV5hQwFxt", "keywords": ["Embedding", "One-shot Learning", "Compositional Representation"], "paperhash": "li|compositional_embeddings_joint_perception_and_comparison_of_class_label_sets", "original_pdf": "/attachment/a5e01dada21b04be59e3475000c1c3d9859364d1.pdf", "_bibtex": "@misc{\nli2020compositional,\ntitle={Compositional Embeddings: Joint Perception and Comparison of Class Label Sets},\nauthor={Zeqian Li and Jacob Whitehill},\nyear={2020},\nurl={https://openreview.net/forum?id=BJx-ZeSKDB}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "BJx-ZeSKDB", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper2124/Authors", "ICLR.cc/2020/Conference/Paper2124/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper2124/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper2124/Reviewers", "ICLR.cc/2020/Conference/Paper2124/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper2124/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper2124/Authors|ICLR.cc/2020/Conference/Paper2124/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504145975, "tmdate": 1576860538413, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper2124/Authors", "ICLR.cc/2020/Conference/Paper2124/Reviewers", "ICLR.cc/2020/Conference/Paper2124/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper2124/-/Official_Comment"}}}, {"id": "HylvuIEnjB", "original": null, "number": 3, "cdate": 1573828206672, "ddate": null, "tcdate": 1573828206672, "tmdate": 1573828206672, "tddate": null, "forum": "BJx-ZeSKDB", "replyto": "B1lxwbMTtS", "invitation": "ICLR.cc/2020/Conference/Paper2124/-/Official_Comment", "content": {"title": "More experiments have been conducted to answer the reviewer's concern", "comment": "\u201chow was the exact neural architecture for f in section 3.2 chosen? It seems contrived. Is it possible to do some ablation studies?\u201d -- In our updated paper we compare models with different numbers of layers (g_Lin, g_Lin+FC, g_DNN). We also add some more details about training in the appendix."}, "signatures": ["ICLR.cc/2020/Conference/Paper2124/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper2124/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["zli14@wpi.edu", "jrwhitehill@wpi.edu"], "title": "Compositional Embeddings: Joint Perception and Comparison of Class Label Sets", "authors": ["Zeqian Li", "Jacob Whitehill"], "pdf": "/pdf/a333627776f0de437c16e52965a359a273a9b83f.pdf", "TL;DR": "We explored how a novel method of compositional set embeddings can both perceive and represent not just a single class but an entire set of classes that is associated with the input data.", "abstract": "We explore the idea of compositional set embeddings that can be used to infer not\njust a single class, but the set of classes associated with the input data (e.g., image,\nvideo, audio signal). This can be useful, for example, in multi-object detection in\nimages, or multi-speaker diarization (one-shot learning) in audio. In particular, we\ndevise and implement two novel models consisting of (1) an embedding function\nf trained jointly with a \u201ccomposite\u201d function g that computes set union opera-\ntions between the classes encoded in two embedding vectors; and (2) embedding\nf trained jointly with a \u201cquery\u201d function h that computes whether the classes en-\ncoded in one embedding subsume the classes encoded in another embedding. In\ncontrast to prior work, these models must both perceive the classes associated\nwith the input examples, and also encode the relationships between different class\nlabel sets. In experiments conducted on simulated data, OmniGlot, and COCO\ndatasets, the proposed composite embedding models outperform baselines based\non traditional embedding approaches.", "code": "https://drive.google.com/open?id=1zjsK9DP3CUqwcVSNwDPshIxOV5hQwFxt", "keywords": ["Embedding", "One-shot Learning", "Compositional Representation"], "paperhash": "li|compositional_embeddings_joint_perception_and_comparison_of_class_label_sets", "original_pdf": "/attachment/a5e01dada21b04be59e3475000c1c3d9859364d1.pdf", "_bibtex": "@misc{\nli2020compositional,\ntitle={Compositional Embeddings: Joint Perception and Comparison of Class Label Sets},\nauthor={Zeqian Li and Jacob Whitehill},\nyear={2020},\nurl={https://openreview.net/forum?id=BJx-ZeSKDB}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "BJx-ZeSKDB", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper2124/Authors", "ICLR.cc/2020/Conference/Paper2124/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper2124/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper2124/Reviewers", "ICLR.cc/2020/Conference/Paper2124/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper2124/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper2124/Authors|ICLR.cc/2020/Conference/Paper2124/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504145975, "tmdate": 1576860538413, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper2124/Authors", "ICLR.cc/2020/Conference/Paper2124/Reviewers", "ICLR.cc/2020/Conference/Paper2124/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper2124/-/Official_Comment"}}}, {"id": "S1lrgINnoH", "original": null, "number": 2, "cdate": 1573828077177, "ddate": null, "tcdate": 1573828077177, "tmdate": 1573828077177, "tddate": null, "forum": "BJx-ZeSKDB", "replyto": "H1edfYN0YS", "invitation": "ICLR.cc/2020/Conference/Paper2124/-/Official_Comment", "content": {"title": "Paper updated with new experiments and clarification", "comment": "\u201cDoes the proposal mean each embedding eventually corresponds to multiple classes/subclasses ie., one can learn something on-trivial about each class from these embeddings that is different from class-specific embedding?\u201d \u2014 Yes, that is the goal. The embedding computed by f can encode an entire *set* of classes, not just 1 class (as with traditional embeddings).\n\n\u201cHow do you avoid the trivial solution problem here i.e., the embeddings are going to be average of the class-specific embeddings\u201d \u2014 Based on the reviewer\u2019s suggestion, we added several more comparisons in Experiments 2, 3, and 4. In particular, we compared our proposed method to (1) \u201cMean\u201d: Simply computing the mean of multiple embeddings from an embedding function f trained just on singletons. (2) \u201cf & g_mean\u201d: Computing the mean of multiple embeddings when the embedding f was trained *with the knowledge* that its outputs would be averaged together. In summary: we found evidence that the proposed method, based on f and a non-linear g, can deliver better performance than either of the two \u201cmean\u201d baselines.\n\n\u201c\u2018... x_a containing objects in another image \u2018 -- this statement is not making sense, is it objects in x_a also present in another image x_b?\u201d -- Yes, that is correct. Objects in x_a are presented in x_b.\n\n\u201cSimpler models (like Symm(a,b,.) i.e., just the first layer of what is being used now) should be evaluated instead to get better understanding of what is going on.\u201d -- Thanks for the suggestion. We have implemented several new variants of g (and of h) in our updated paper. In some cases, a simple g consisting of a single linear layer works best, whereas in other cases a deeper g works better. Please note that we also fixed a bug in the implementation of the bi-linear baseline from our original submission. The result (which is now called the g_Lin method) has been updated in the paper. In experiment 3, we also used a different random seed and the new results are slightly different from the previous version.\n"}, "signatures": ["ICLR.cc/2020/Conference/Paper2124/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper2124/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["zli14@wpi.edu", "jrwhitehill@wpi.edu"], "title": "Compositional Embeddings: Joint Perception and Comparison of Class Label Sets", "authors": ["Zeqian Li", "Jacob Whitehill"], "pdf": "/pdf/a333627776f0de437c16e52965a359a273a9b83f.pdf", "TL;DR": "We explored how a novel method of compositional set embeddings can both perceive and represent not just a single class but an entire set of classes that is associated with the input data.", "abstract": "We explore the idea of compositional set embeddings that can be used to infer not\njust a single class, but the set of classes associated with the input data (e.g., image,\nvideo, audio signal). This can be useful, for example, in multi-object detection in\nimages, or multi-speaker diarization (one-shot learning) in audio. In particular, we\ndevise and implement two novel models consisting of (1) an embedding function\nf trained jointly with a \u201ccomposite\u201d function g that computes set union opera-\ntions between the classes encoded in two embedding vectors; and (2) embedding\nf trained jointly with a \u201cquery\u201d function h that computes whether the classes en-\ncoded in one embedding subsume the classes encoded in another embedding. In\ncontrast to prior work, these models must both perceive the classes associated\nwith the input examples, and also encode the relationships between different class\nlabel sets. In experiments conducted on simulated data, OmniGlot, and COCO\ndatasets, the proposed composite embedding models outperform baselines based\non traditional embedding approaches.", "code": "https://drive.google.com/open?id=1zjsK9DP3CUqwcVSNwDPshIxOV5hQwFxt", "keywords": ["Embedding", "One-shot Learning", "Compositional Representation"], "paperhash": "li|compositional_embeddings_joint_perception_and_comparison_of_class_label_sets", "original_pdf": "/attachment/a5e01dada21b04be59e3475000c1c3d9859364d1.pdf", "_bibtex": "@misc{\nli2020compositional,\ntitle={Compositional Embeddings: Joint Perception and Comparison of Class Label Sets},\nauthor={Zeqian Li and Jacob Whitehill},\nyear={2020},\nurl={https://openreview.net/forum?id=BJx-ZeSKDB}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "BJx-ZeSKDB", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper2124/Authors", "ICLR.cc/2020/Conference/Paper2124/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper2124/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper2124/Reviewers", "ICLR.cc/2020/Conference/Paper2124/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper2124/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper2124/Authors|ICLR.cc/2020/Conference/Paper2124/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504145975, "tmdate": 1576860538413, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper2124/Authors", "ICLR.cc/2020/Conference/Paper2124/Reviewers", "ICLR.cc/2020/Conference/Paper2124/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper2124/-/Official_Comment"}}}, {"id": "ByxlAVN2jB", "original": null, "number": 1, "cdate": 1573827783830, "ddate": null, "tcdate": 1573827783830, "tmdate": 1573827783830, "tddate": null, "forum": "BJx-ZeSKDB", "replyto": "Hkx7Kvvk5S", "invitation": "ICLR.cc/2020/Conference/Paper2124/-/Official_Comment", "content": {"title": "We would like to thank the reviewer for noting some missing points in our experiments. We updated the paper with some new experiments according to the suggestions and made some clarification.", "comment": "\u201cNo explanation is given why a trivial solution cannot be used instead of the learnt functions.\u201d \u2014 First, we want to point out that training a classifier (e.g., ResNet) using standard supervised learning is only possible if the training and testing classes are the same. For our Omnigot and simulation studies (Experiments 2 and 1, respectively), they were different (one-shot learning). This is an important case, e.g., for speaker diarization. Second, based on the reviewer\u2019s suggestion, we did conduct a follow-up analysis on COCO (Experiment 4, in which training and testing classes are indeed the same) -- please see the updated paper. Interestingly, the trained ResNet classifier (followed by a threshold of 0.5 and then a bit-comparison to answer label queries) did not perform very well compared to the proposed f & h method -- see Table 1(b). One possible reason is that ResNet is not optimized to answer queries about image pairs. Instead, it tries to encode each image into an n-bit string (for n classes). While this representation can account for all 2^n possible label sets, it may not be the most effective or efficient representation for the task, especially since some objects are very unlikely to co-occur with others. The proposed f & h embedding method can harness the co-occurrence structure to answer queries more accurately, whereas a ResNet trained to recognize all the individual classes does not harness it. Another reason may be that such a classifier trained on COCO has to overcome strong class imbalance (which is not trivial to fix on COCO), which the compositional embeddings do not (since they were trained inherently with 50%/50% balance).\n\n\u201cAnalysis of how performance of the technique scales with the size of the set\u201d \u2014 We added a study to the appendix on the accuracy of f & h as a function of the label set size.\n\n\u201cf is always different between that used with g and that used with h, is this the case?\u201d \u2014 f is the same architecture but has different parameters in g than h.\n\n\u201cSimRef also doesn't do data augmentation but there's no explanation why\u2026\u201d \u2014 Actually, SimRef uses the same augmentation as the proposed f & g method. Recall that all the methods receive reference examples of the *singleton* classes, which are created using random affine transformations of the original OminGlot data. The reviewer may be referring to the statement, \u201cwithout shifting/scaling/rotation\u201d in our paper. Please note that these transformations were part of the *rendering* function r. Since r is assumed to be hidden (from all the methods), we did not give oracle access of how r works to the SimRef method.\n"}, "signatures": ["ICLR.cc/2020/Conference/Paper2124/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper2124/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["zli14@wpi.edu", "jrwhitehill@wpi.edu"], "title": "Compositional Embeddings: Joint Perception and Comparison of Class Label Sets", "authors": ["Zeqian Li", "Jacob Whitehill"], "pdf": "/pdf/a333627776f0de437c16e52965a359a273a9b83f.pdf", "TL;DR": "We explored how a novel method of compositional set embeddings can both perceive and represent not just a single class but an entire set of classes that is associated with the input data.", "abstract": "We explore the idea of compositional set embeddings that can be used to infer not\njust a single class, but the set of classes associated with the input data (e.g., image,\nvideo, audio signal). This can be useful, for example, in multi-object detection in\nimages, or multi-speaker diarization (one-shot learning) in audio. In particular, we\ndevise and implement two novel models consisting of (1) an embedding function\nf trained jointly with a \u201ccomposite\u201d function g that computes set union opera-\ntions between the classes encoded in two embedding vectors; and (2) embedding\nf trained jointly with a \u201cquery\u201d function h that computes whether the classes en-\ncoded in one embedding subsume the classes encoded in another embedding. In\ncontrast to prior work, these models must both perceive the classes associated\nwith the input examples, and also encode the relationships between different class\nlabel sets. In experiments conducted on simulated data, OmniGlot, and COCO\ndatasets, the proposed composite embedding models outperform baselines based\non traditional embedding approaches.", "code": "https://drive.google.com/open?id=1zjsK9DP3CUqwcVSNwDPshIxOV5hQwFxt", "keywords": ["Embedding", "One-shot Learning", "Compositional Representation"], "paperhash": "li|compositional_embeddings_joint_perception_and_comparison_of_class_label_sets", "original_pdf": "/attachment/a5e01dada21b04be59e3475000c1c3d9859364d1.pdf", "_bibtex": "@misc{\nli2020compositional,\ntitle={Compositional Embeddings: Joint Perception and Comparison of Class Label Sets},\nauthor={Zeqian Li and Jacob Whitehill},\nyear={2020},\nurl={https://openreview.net/forum?id=BJx-ZeSKDB}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "BJx-ZeSKDB", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper2124/Authors", "ICLR.cc/2020/Conference/Paper2124/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper2124/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper2124/Reviewers", "ICLR.cc/2020/Conference/Paper2124/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper2124/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper2124/Authors|ICLR.cc/2020/Conference/Paper2124/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504145975, "tmdate": 1576860538413, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper2124/Authors", "ICLR.cc/2020/Conference/Paper2124/Reviewers", "ICLR.cc/2020/Conference/Paper2124/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper2124/-/Official_Comment"}}}, {"id": "B1lxwbMTtS", "original": null, "number": 1, "cdate": 1571787095719, "ddate": null, "tcdate": 1571787095719, "tmdate": 1572972380042, "tddate": null, "forum": "BJx-ZeSKDB", "replyto": "BJx-ZeSKDB", "invitation": "ICLR.cc/2020/Conference/Paper2124/-/Official_Review", "content": {"experience_assessment": "I have read many papers in this area.", "rating": "6: Weak Accept", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #1", "review_assessment:_checking_correctness_of_derivations_and_theory": "N/A", "review": "Summary:\n=======\nThis paper proposes compositional embeddings i.e. embeddings that can be used to infer multiple classes from the data. In particular, the paper deals with two types of composite functions for embeddings, one that computes union of the different classes represented by each embedding vector, and the other where the class of one of the embeddings is subsumed by the class of the other embedding. The actual composition functions are parameterized by neural networks whose parameters are learned from data. Results on synthetic as well as several real-world datasets highlight the superiority of the learned composite embeddings. \n\n\n\nComments:\n==========\n1) This paper presents a welcome contribution to the saturated literature on embeddings. The whole idea of compositionally and its application to speaker diarization and multi-object detection is novel. \n\n2) The execution of the idea is also excellent and thorough. Further, the paper is very well written and puts itself nicely in context of previous work. I think this should inspire future work on other kinds of composite functions other than the two considered here. \n\n3) The results on both the synthetic and real-world omniglot and COCO datasets are impressive and mostly well executed and show significant improvement over the \"most frequent\" baseline. \n\n\n4) My only concern regarding the paper is w.r.t some arbitrary decisions made in the experiments e.g. how was the exact neural architecture for f in section 3.2 chosen? It seems contrived. Is it possible to do some ablation studies? Also, I think it will be nice to provide some more details regarding the neural network training in Section 3.1.\n"}, "signatures": ["ICLR.cc/2020/Conference/Paper2124/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper2124/AnonReviewer1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["zli14@wpi.edu", "jrwhitehill@wpi.edu"], "title": "Compositional Embeddings: Joint Perception and Comparison of Class Label Sets", "authors": ["Zeqian Li", "Jacob Whitehill"], "pdf": "/pdf/a333627776f0de437c16e52965a359a273a9b83f.pdf", "TL;DR": "We explored how a novel method of compositional set embeddings can both perceive and represent not just a single class but an entire set of classes that is associated with the input data.", "abstract": "We explore the idea of compositional set embeddings that can be used to infer not\njust a single class, but the set of classes associated with the input data (e.g., image,\nvideo, audio signal). This can be useful, for example, in multi-object detection in\nimages, or multi-speaker diarization (one-shot learning) in audio. In particular, we\ndevise and implement two novel models consisting of (1) an embedding function\nf trained jointly with a \u201ccomposite\u201d function g that computes set union opera-\ntions between the classes encoded in two embedding vectors; and (2) embedding\nf trained jointly with a \u201cquery\u201d function h that computes whether the classes en-\ncoded in one embedding subsume the classes encoded in another embedding. In\ncontrast to prior work, these models must both perceive the classes associated\nwith the input examples, and also encode the relationships between different class\nlabel sets. In experiments conducted on simulated data, OmniGlot, and COCO\ndatasets, the proposed composite embedding models outperform baselines based\non traditional embedding approaches.", "code": "https://drive.google.com/open?id=1zjsK9DP3CUqwcVSNwDPshIxOV5hQwFxt", "keywords": ["Embedding", "One-shot Learning", "Compositional Representation"], "paperhash": "li|compositional_embeddings_joint_perception_and_comparison_of_class_label_sets", "original_pdf": "/attachment/a5e01dada21b04be59e3475000c1c3d9859364d1.pdf", "_bibtex": "@misc{\nli2020compositional,\ntitle={Compositional Embeddings: Joint Perception and Comparison of Class Label Sets},\nauthor={Zeqian Li and Jacob Whitehill},\nyear={2020},\nurl={https://openreview.net/forum?id=BJx-ZeSKDB}\n}"}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "BJx-ZeSKDB", "replyto": "BJx-ZeSKDB", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper2124/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper2124/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1575798100269, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper2124/Reviewers"], "noninvitees": [], "tcdate": 1570237727363, "tmdate": 1575798100285, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper2124/-/Official_Review"}}}, {"id": "H1edfYN0YS", "original": null, "number": 2, "cdate": 1571862799583, "ddate": null, "tcdate": 1571862799583, "tmdate": 1572972379998, "tddate": null, "forum": "BJx-ZeSKDB", "replyto": "BJx-ZeSKDB", "invitation": "ICLR.cc/2020/Conference/Paper2124/-/Official_Review", "content": {"experience_assessment": "I have published one or two papers in this area.", "rating": "3: Weak Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #3", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "The authors propose a joint/compositional embedding procedure where a single instance can be mapped/embedded to multiple classes while preserving the class-specific information in the embedded representations. The authors look at class union and class query criteria for the composite embeddings. The proposed approach is evaluated appropriately. There are several issues with the work. \n\nDoes the proposal mean each embedding eventually corresponds to multiple classes/subclasses ie., one can learn something on-trivial about each class from these embeddings that is different from class-specific embedding? How do you avoid the trivial solution problem here i.e., the embeddings are going to be average of the class-specific embeddings --- as we see in the evaluations this is in fact happening (figure 1b)? Also, is this behaviour desired i.e., tending towards mean? \n\nAnd continuing along these lines, a clear choice of baseline for the proposal is to choose mean embeddings i.e., men of independent embeddings? Or is this not appropriate? Why is ML the best baseline? We can use the probability map (the input to final softmax) instead as the embedding as well correct? \n\n\"... x_a containing objects in another image \" -- this statement is not making sense, is it objects in x_a also present in another image x_b?\n\nIt is rather difficult to interpret the usefulness of g(.) when it is a nonlinear model like neural network. Simpler models (like Symm(a,b,.) i.e., just the first layer of what is being used now) should be evaluated instead to get better understanding of what is going on! \n"}, "signatures": ["ICLR.cc/2020/Conference/Paper2124/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper2124/AnonReviewer3"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["zli14@wpi.edu", "jrwhitehill@wpi.edu"], "title": "Compositional Embeddings: Joint Perception and Comparison of Class Label Sets", "authors": ["Zeqian Li", "Jacob Whitehill"], "pdf": "/pdf/a333627776f0de437c16e52965a359a273a9b83f.pdf", "TL;DR": "We explored how a novel method of compositional set embeddings can both perceive and represent not just a single class but an entire set of classes that is associated with the input data.", "abstract": "We explore the idea of compositional set embeddings that can be used to infer not\njust a single class, but the set of classes associated with the input data (e.g., image,\nvideo, audio signal). This can be useful, for example, in multi-object detection in\nimages, or multi-speaker diarization (one-shot learning) in audio. In particular, we\ndevise and implement two novel models consisting of (1) an embedding function\nf trained jointly with a \u201ccomposite\u201d function g that computes set union opera-\ntions between the classes encoded in two embedding vectors; and (2) embedding\nf trained jointly with a \u201cquery\u201d function h that computes whether the classes en-\ncoded in one embedding subsume the classes encoded in another embedding. In\ncontrast to prior work, these models must both perceive the classes associated\nwith the input examples, and also encode the relationships between different class\nlabel sets. In experiments conducted on simulated data, OmniGlot, and COCO\ndatasets, the proposed composite embedding models outperform baselines based\non traditional embedding approaches.", "code": "https://drive.google.com/open?id=1zjsK9DP3CUqwcVSNwDPshIxOV5hQwFxt", "keywords": ["Embedding", "One-shot Learning", "Compositional Representation"], "paperhash": "li|compositional_embeddings_joint_perception_and_comparison_of_class_label_sets", "original_pdf": "/attachment/a5e01dada21b04be59e3475000c1c3d9859364d1.pdf", "_bibtex": "@misc{\nli2020compositional,\ntitle={Compositional Embeddings: Joint Perception and Comparison of Class Label Sets},\nauthor={Zeqian Li and Jacob Whitehill},\nyear={2020},\nurl={https://openreview.net/forum?id=BJx-ZeSKDB}\n}"}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "BJx-ZeSKDB", "replyto": "BJx-ZeSKDB", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper2124/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper2124/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1575798100269, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper2124/Reviewers"], "noninvitees": [], "tcdate": 1570237727363, "tmdate": 1575798100285, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper2124/-/Official_Review"}}}], "count": 9}