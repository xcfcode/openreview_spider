{"notes": [{"id": "wUUKCAmBx6q", "original": "q28d999DF2R", "number": 2586, "cdate": 1601308286304, "ddate": null, "tcdate": 1601308286304, "tmdate": 1614985781133, "tddate": null, "forum": "wUUKCAmBx6q", "replyto": null, "invitation": "ICLR.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Flow Neural Network for Traffic Flow Modelling in IP Networks", "authorids": ["~Xiangle_Cheng1", "y325he@uwaterloo.ca", "longfeifei@huawei.com", "xiaoshihan@huawei.com", "lifenglin@huawei.com"], "authors": ["Xiangle Cheng", "Yuchen He", "Feifei Long", "Shihan Xiao", "Fenglin Li"], "keywords": ["Flow neural network", "contrastive induction learning", "representation learning", "spatio-temporal induction"], "abstract": "This paper presents and investigates a novel and timely application domain for deep learning: sub-second traffic flow modelling in IP networks. Traffic flows are the most fundamental components in an IP based networking system. The accurate modelling of the generative patterns of these flows is crucial for many practical network applications. However, the high nonlinearity and dynamics of both the traffic and network conditions make this task challenging, particularly at the time granularity of sub-second. In this paper, we cast this problem as a representation learning task to model the intricate patterns in data traffic according to the IP network structure and working mechanism. Accordingly, we propose a customized Flow Neural Network, which works in a self-supervised way to extract the domain-specific data correlations. We report the state-of-the-art performances on both synthetic and realistic traffic patterns on multiple practical network applications, which provides a good testament to the strength of our approach.", "one-sentence_summary": "We propose a customised Flow Neural Network for the subsecond traffic flow modelling in IP networks by exploiting the domain-specific data properties according to the IP network structure and working machenism.", "pdf": "/pdf/395453ab2fb1a2fde41b7e1a8b5947aaffe4823f.pdf", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "cheng|flow_neural_network_for_traffic_flow_modelling_in_ip_networks", "supplementary_material": "/attachment/8349da2b0ae3d9a80c00229b5ce31cb11630310e.zip", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=m8VD_hNVNR", "_bibtex": "@misc{\ncheng2021flow,\ntitle={Flow Neural Network for Traffic Flow Modelling in {\\{}IP{\\}} Networks},\nauthor={Xiangle Cheng and Yuchen He and Feifei Long and Shihan Xiao and Fenglin Li},\nyear={2021},\nurl={https://openreview.net/forum?id=wUUKCAmBx6q}\n}"}, "signatures": ["ICLR.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference"], "details": {"replyCount": 6, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"reply": {"readers": {"values-regex": ".*"}, "writers": {"values": ["ICLR.cc/2021/Conference"]}, "signatures": {"values": ["ICLR.cc/2021/Conference"]}, "content": {"authors": {"values": ["Anonymous"]}, "authorids": {"values-regex": ".*"}, "reviewed_version_(pdf)": {"required": false, "description": "Upload a PDF file that ends with .pdf", "value-regex": ".*"}}}, "signatures": ["ICLR.cc/2021/Conference"], "readers": ["everyone"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["~", "OpenReview.net/Support"], "tcdate": 1601308008205, "tmdate": 1614984599368, "id": "ICLR.cc/2021/Conference/-/Blind_Submission"}}, "tauthor": "OpenReview.net"}, {"id": "s400TTStoY", "original": null, "number": 1, "cdate": 1610040348690, "ddate": null, "tcdate": 1610040348690, "tmdate": 1610473937528, "tddate": null, "forum": "wUUKCAmBx6q", "replyto": "wUUKCAmBx6q", "invitation": "ICLR.cc/2021/Conference/Paper2586/-/Decision", "content": {"title": "Final Decision", "decision": "Reject", "comment": "The revised paper is a solid improvement.  However, all reviewers and I find that there are still a number of issues that prevent the paper from being acceptable at the current stage.  For example, some important parts are still unclear, especially the definition of STI effect.  The observation of STI effect requires more theoretical or empirical investigation, in addition to a toy example."}, "signatures": ["ICLR.cc/2021/Conference/Program_Chairs"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference/Program_Chairs"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Flow Neural Network for Traffic Flow Modelling in IP Networks", "authorids": ["~Xiangle_Cheng1", "y325he@uwaterloo.ca", "longfeifei@huawei.com", "xiaoshihan@huawei.com", "lifenglin@huawei.com"], "authors": ["Xiangle Cheng", "Yuchen He", "Feifei Long", "Shihan Xiao", "Fenglin Li"], "keywords": ["Flow neural network", "contrastive induction learning", "representation learning", "spatio-temporal induction"], "abstract": "This paper presents and investigates a novel and timely application domain for deep learning: sub-second traffic flow modelling in IP networks. Traffic flows are the most fundamental components in an IP based networking system. The accurate modelling of the generative patterns of these flows is crucial for many practical network applications. However, the high nonlinearity and dynamics of both the traffic and network conditions make this task challenging, particularly at the time granularity of sub-second. In this paper, we cast this problem as a representation learning task to model the intricate patterns in data traffic according to the IP network structure and working mechanism. Accordingly, we propose a customized Flow Neural Network, which works in a self-supervised way to extract the domain-specific data correlations. We report the state-of-the-art performances on both synthetic and realistic traffic patterns on multiple practical network applications, which provides a good testament to the strength of our approach.", "one-sentence_summary": "We propose a customised Flow Neural Network for the subsecond traffic flow modelling in IP networks by exploiting the domain-specific data properties according to the IP network structure and working machenism.", "pdf": "/pdf/395453ab2fb1a2fde41b7e1a8b5947aaffe4823f.pdf", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "cheng|flow_neural_network_for_traffic_flow_modelling_in_ip_networks", "supplementary_material": "/attachment/8349da2b0ae3d9a80c00229b5ce31cb11630310e.zip", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=m8VD_hNVNR", "_bibtex": "@misc{\ncheng2021flow,\ntitle={Flow Neural Network for Traffic Flow Modelling in {\\{}IP{\\}} Networks},\nauthor={Xiangle Cheng and Yuchen He and Feifei Long and Shihan Xiao and Fenglin Li},\nyear={2021},\nurl={https://openreview.net/forum?id=wUUKCAmBx6q}\n}"}, "tags": [], "invitation": {"reply": {"forum": "wUUKCAmBx6q", "replyto": "wUUKCAmBx6q", "readers": {"values": ["everyone"]}, "writers": {"values": ["ICLR.cc/2021/Conference/Program_Chairs"]}, "signatures": {"values": ["ICLR.cc/2021/Conference/Program_Chairs"]}, "content": {"title": {"value": "Final Decision"}, "decision": {"value-radio": ["Accept (Oral)", "Accept (Spotlight)", "Accept (Poster)", "Reject"]}, "comment": {"value-regex": "[\\S\\s]{0,50000}", "markdown": true}}}, "multiReply": false, "signatures": ["ICLR.cc/2021/Conference"], "readers": ["everyone"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Program_Chairs"], "tcdate": 1610040348673, "tmdate": 1610473937507, "id": "ICLR.cc/2021/Conference/Paper2586/-/Decision"}}}, {"id": "8xJC38u5rOo", "original": null, "number": 4, "cdate": 1603954832276, "ddate": null, "tcdate": 1603954832276, "tmdate": 1606813352691, "tddate": null, "forum": "wUUKCAmBx6q", "replyto": "wUUKCAmBx6q", "invitation": "ICLR.cc/2021/Conference/Paper2586/-/Official_Review", "content": {"title": "The paper cannot be well understood and evaluated", "review": "Summary: \n- The paper claims to discover a universal \u201cspatio-temporal induction (STI) effect\u201d in network traffic flows, and developed a model FlowNN to learn representations of flow-structure data. However, the STI effect was not clearly explained and the problem is not well formulated, making it hard for readers to understand the value of this work.\n\nStrong points: \n- Modeling flow-structure data and internet traffic flows is an interesting problem.\n- The paper motivates the problem well.\n\nWeak points: \n- The writing of this paper is very confusing and unclear. \n- The problem was not clearly formulated or articulated.\n- The descriptions of the model and STI effect are confusing.\n\nRecommendation: \n- I strongly recommend a reject. While the topic is interesting, the paper is hardly understandable in its current form. The contributions cannot be well understood and evaluated. Improving clarity will make it a much stronger submission in the future.\n\nComments & questions:\n- What exactly is the task? It was never clearly stated in the paper. Only mentioning \u201cLearning the representations\u201d or \u201cregression tasks\u201d is unclear and confusing.\n- What is the training and test data split? How does the approach generalize to unseen networks or flows?\n- The definition of STI is unclear. In Definition 1, the paper writes \u201cSpatio-Temporal Induction defines the synchronized map process to produce the future/spatial evolution between neighboring nodes.\u201d This does not define the STI effect. What exactly is the \u201csynchronized map process\u201d? Different network flows process packets at different paces, so how are they synchronized?\n- How can the representation (Fig 3a) scale with the number of nodes in the network? You would need one such 3D matrix for a flow. The paper evaluates with 28 nodes in total (Sec. 4), but the real internet is orders of magnitude larger (billions and millions of flows).\n- The meaning of Fig 4. is unclear. \u201ca spike at a upstream node in Fig. 4a spurts the flow at downstream nodes in certain subsequent time windows.\u201d However, it\u2019s very hard to see that from the figure. It seems like all flows are fluctuating at different time steps.\n- Many claims seem to be wrong or not supported. A few examples:\n  - \u201ca encoding net with shared weights is learnt to extract the common patterns shared in all received inputs.\u201d Share weights imply extracting \u201csimilar\u201d patterns across flows, how can the design extract \u201ccommon\u201d patterns?\n  - \u201cThis reconstructs the evolution patterns of the APP source flows that drive the evolution processes at all nodes along the path.\u201d -> How exactly?\n- The meaning of many sentences are unclear. A few examples:\n  - \u201cthe flow rates be- tween two neighbouring or any pair of nodes in the routing path will become larger interchangeably than the other so that the flux is conserved among nodes.\u201d\n  - \u201cThis not only experimentally confirms the S-shaped spatio-temporal correlation present in the flow-structured data, but also further confines the correlation with the explicit (partial) flow conservation.\u201d\n  - \u201cInduction is operated on \u2026 by the paired induction operator.\u201d\n- Many grammar issues. A few examples:\n  - \u201cData can be organized compact and complete\u201d\n  - \u201cpropagation process as doing in above IP traffic flows\u201d\n  - \u201cWhile any encoder and decoder can be used so long as we can backpropagate through it.\u201d\n\nSuggestions\n- Writing-wise, it will be helpful to simplify the wording and be direct and specific. \n- It\u2019ll be helpful to ask people not familiar with the project to read the paper and get feedback.\n\n==== Updates after the response ====\n\nI appreciate the authors\u2019 effort in updating the manuscript. The new manuscript has significant changes, but still many questions are left unanswered. Thus, I\u2019m keeping my rating and recommendation.", "rating": "2: Strong rejection", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["ICLR.cc/2021/Conference/Paper2586/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2586/AnonReviewer2"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Flow Neural Network for Traffic Flow Modelling in IP Networks", "authorids": ["~Xiangle_Cheng1", "y325he@uwaterloo.ca", "longfeifei@huawei.com", "xiaoshihan@huawei.com", "lifenglin@huawei.com"], "authors": ["Xiangle Cheng", "Yuchen He", "Feifei Long", "Shihan Xiao", "Fenglin Li"], "keywords": ["Flow neural network", "contrastive induction learning", "representation learning", "spatio-temporal induction"], "abstract": "This paper presents and investigates a novel and timely application domain for deep learning: sub-second traffic flow modelling in IP networks. Traffic flows are the most fundamental components in an IP based networking system. The accurate modelling of the generative patterns of these flows is crucial for many practical network applications. However, the high nonlinearity and dynamics of both the traffic and network conditions make this task challenging, particularly at the time granularity of sub-second. In this paper, we cast this problem as a representation learning task to model the intricate patterns in data traffic according to the IP network structure and working mechanism. Accordingly, we propose a customized Flow Neural Network, which works in a self-supervised way to extract the domain-specific data correlations. We report the state-of-the-art performances on both synthetic and realistic traffic patterns on multiple practical network applications, which provides a good testament to the strength of our approach.", "one-sentence_summary": "We propose a customised Flow Neural Network for the subsecond traffic flow modelling in IP networks by exploiting the domain-specific data properties according to the IP network structure and working machenism.", "pdf": "/pdf/395453ab2fb1a2fde41b7e1a8b5947aaffe4823f.pdf", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "cheng|flow_neural_network_for_traffic_flow_modelling_in_ip_networks", "supplementary_material": "/attachment/8349da2b0ae3d9a80c00229b5ce31cb11630310e.zip", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=m8VD_hNVNR", "_bibtex": "@misc{\ncheng2021flow,\ntitle={Flow Neural Network for Traffic Flow Modelling in {\\{}IP{\\}} Networks},\nauthor={Xiangle Cheng and Yuchen He and Feifei Long and Shihan Xiao and Fenglin Li},\nyear={2021},\nurl={https://openreview.net/forum?id=wUUKCAmBx6q}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq . ***Please remember to file the Code-of-Ethics report. Once you submitted the review, a link to the report will be visible in the bottom right corner of your review.***", "required": true, "markdown": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}, "forum": "wUUKCAmBx6q", "replyto": "wUUKCAmBx6q", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"], "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper2586/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1607428800000, "duedate": 1606752000000, "multiReply": false, "readers": ["everyone"], "tcdate": 1602538093013, "tmdate": 1606915757976, "super": "ICLR.cc/2021/Conference/-/Official_Review", "signatures": ["OpenReview.net"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Paper2586/Reviewers", "OpenReview.net/Support"], "id": "ICLR.cc/2021/Conference/Paper2586/-/Official_Review"}}}, {"id": "VQfqYj9gPCc", "original": null, "number": 2, "cdate": 1606304600553, "ddate": null, "tcdate": 1606304600553, "tmdate": 1606304600553, "tddate": null, "forum": "wUUKCAmBx6q", "replyto": "wUUKCAmBx6q", "invitation": "ICLR.cc/2021/Conference/Paper2586/-/Official_Comment", "content": {"title": "revision summary for the provided response letter in supplementary material", "comment": "We appreciate the time and efforts all reviewers and ACs have devoted to the review of this paper. Your comments and suggestions help us a lot to improve the quality of this paper.  Basically, all reviewers posted many shared concerns about the writing and vague problem formulation in our previous submission that make all reviewers hard to understand and evaluate. With the help of the suggestions and questions all reviewers provided, we have reorganized the writing of this paper and added more details to illustrate the IP networking backgrounds, working mechanism, the motivation of our problem and methods, as well as more experiments to justify the novelty, superiority and robustness of our proposal.  Please see the response letter attached in Supplementary Material for more details."}, "signatures": ["ICLR.cc/2021/Conference/Paper2586/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2586/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Flow Neural Network for Traffic Flow Modelling in IP Networks", "authorids": ["~Xiangle_Cheng1", "y325he@uwaterloo.ca", "longfeifei@huawei.com", "xiaoshihan@huawei.com", "lifenglin@huawei.com"], "authors": ["Xiangle Cheng", "Yuchen He", "Feifei Long", "Shihan Xiao", "Fenglin Li"], "keywords": ["Flow neural network", "contrastive induction learning", "representation learning", "spatio-temporal induction"], "abstract": "This paper presents and investigates a novel and timely application domain for deep learning: sub-second traffic flow modelling in IP networks. Traffic flows are the most fundamental components in an IP based networking system. The accurate modelling of the generative patterns of these flows is crucial for many practical network applications. However, the high nonlinearity and dynamics of both the traffic and network conditions make this task challenging, particularly at the time granularity of sub-second. In this paper, we cast this problem as a representation learning task to model the intricate patterns in data traffic according to the IP network structure and working mechanism. Accordingly, we propose a customized Flow Neural Network, which works in a self-supervised way to extract the domain-specific data correlations. We report the state-of-the-art performances on both synthetic and realistic traffic patterns on multiple practical network applications, which provides a good testament to the strength of our approach.", "one-sentence_summary": "We propose a customised Flow Neural Network for the subsecond traffic flow modelling in IP networks by exploiting the domain-specific data properties according to the IP network structure and working machenism.", "pdf": "/pdf/395453ab2fb1a2fde41b7e1a8b5947aaffe4823f.pdf", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "cheng|flow_neural_network_for_traffic_flow_modelling_in_ip_networks", "supplementary_material": "/attachment/8349da2b0ae3d9a80c00229b5ce31cb11630310e.zip", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=m8VD_hNVNR", "_bibtex": "@misc{\ncheng2021flow,\ntitle={Flow Neural Network for Traffic Flow Modelling in {\\{}IP{\\}} Networks},\nauthor={Xiangle Cheng and Yuchen He and Feifei Long and Shihan Xiao and Fenglin Li},\nyear={2021},\nurl={https://openreview.net/forum?id=wUUKCAmBx6q}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "wUUKCAmBx6q", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper2586/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper2586/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper2586/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper2586/Authors|ICLR.cc/2021/Conference/Paper2586/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2586/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923846651, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper2586/-/Official_Comment"}}}, {"id": "4LPO5nWkRng", "original": null, "number": 3, "cdate": 1603918954325, "ddate": null, "tcdate": 1603918954325, "tmdate": 1605132916572, "tddate": null, "forum": "wUUKCAmBx6q", "replyto": "wUUKCAmBx6q", "invitation": "ICLR.cc/2021/Conference/Paper2586/-/Official_Review", "content": {"title": "The paper raises some valid points but falls short in providing consistent analysis and proof for their claims. The experimental setup needs to be improved and include general flow network types and stronger benchmarking.", "review": "Summary: \n\nThe goal of this study is the 1-step prediction of flow rate in flow networks. They first define a \u201cspatial-temporal induction effect (STI)\u201d and claim it to be the universal property of flow networks. Their main contribution is their proposed \u201cflow neural network\u201d which is based on the STI effect and a combination of GCN and GRU architectures.  According to authors, the novelty of their work lies in the fact that they consider the spatiotemporal features of the flow network simultaneously, whereas the previous works only consider them separately. \n\n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% \n\nStrengths of the paper: \n\nThe raised concern over the fact that considering the time series of the node alone does not capture the full complexity of the flow dynamics is valid and an interesting direction to pursue. \n\nTheir proposed model achieves a better validation loss than the benchmarks \n\nThe paper does a decent job in pointing out the flaws of the previous models. \n\n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% \n\nDetailed Review: \n\nMajor concerns: \n\nFor a paper that heavily relies on empirical results (as mentioned throughout the paper), there is a serious lack of various experimentations to prove the followings:\n\n- The claimed universality of spatiotemporal induction (STI) effect, \n\n- Considering the spatial-temporal features separately (i.e., spatial-spatial and temporal-temporal) indeed results in considerably poorer performance in different settings, \n\n- The practical benefit of the proposed architecture tested on different real-world networks from different domains (to comply with the title and the claim in the paper that the proposed method is extensible to other flow networks besides IP networks, as well). \n\nThe authors claim the inefficiency of previous studies (some of which are based on strong mathematical theories) on the same domain (e.g., Harchol-Balter, 2013; Ciucu & Schmitt, 2012; Ciucu et al., 2019) without proof and do not consider these works in their baselines. In fact, many of the selected baseline belong to relatively old studies that are not necessarily SOTA for the flow prediction task right now. There are numerous recent studies on network flow prediction (e.g., traffic flow, crowd flow, etc.) combing the spatial-temporal features of the system through (e.g., these two papers to name a few:  \n\nhttps://www.sciencedirect.com/science/article/pii/S0968090X19301330?casa_token=_HkqrohsGwEAAAAA:_qI_xcFnpiFkXGzqxhXNTfEx4jJA_EoAN673pBimQezdlIFCw_79EWTcB9XIhpSiCGwhJ9W_Pyx9 \n\nhttps://www.aaai.org/ojs/index.php/AAAI/article/view/3892) \n\nI suggest authors develop their related work section further and use more SOTA baselines in their experiments. Also, choose more than one dataset from different domains for validating the proposed model. \n\n%%%%%%%%%%%%% \n\nThe definition of \u201cspatial temporal induction\u201d is rather vague and does not clarify what STI effect means, both theoretically and intuitively. There are no proof on the \u201cuniversality\u201d of this effect for all flow networks and the two properties listed in page 4 are neither proven nor connected to the rest of the paper. What is the significance of STI and why do we care about its two properties (if they indeed hold). \n\n%%%%%%%%%%%%% \n\nThe paper is rather tough to read. There are instances of using abbreviations before they are defined and mathematical notations with variables that are not properly defined (ref. Page 5). \n\n%%%%%%%%%%%%% \n\nHow are the flow timeseries defined as (in-flow? Out-flow?). On the same note, how does the ordering of the subtraction affect figure 4.b (e.g. changing 130-136 to 136-130 while keeping the rest of subtractions the same). \n\n%%%%%%%%%%%%% \n\nThe figures in general are not well connected to the text. Majority of them include details that are not explained in the text (or the caption) and a number of them are hard to interpret. For example, \n\nFigure 1.b: what is the red box for? \n\nFigure 3.a: what is x_ijt in terms of flow rate (I can only attribute it to in-flow and out-flow which does not seem to be used in this study)? And what does X_iit imply? How is the blue curve (called S curve) obtained in the figure? \n\nFigure 3.b: what is to be inferred from this figure? \n\nFigure 4.a and 4.b: Are these based on real data or they are only toy examples? If it is the latter, then it cannot be used to prove the existence of STI effect. If it is the former, what is the data? It is hard to attribute meaning to the graphs without knowing the context of the data. \n\n Moreover, in figure 4.a, shouldn\u2019t the spike in the source node 41 reach to neighboring node 130 with some time delay (the same for other nodes as well)? \n\nFigure 5: Again, what is X_ij?  What is the direct output from \u201cflowing invariant coding\u201d used for? \n\nFigure 6: I find it hard to interpret the caption from the figure. \n\nFigure 8: what is to be inferred from the red boxes? \n\nI suggest authors increase the font and quality of their figures and enrich their captions to convey the intended message with more clarity. \n\n%%%%%%%%%%%%% \n\nThe problem statement and novelty of the study is not clear from the introduction section.  I suggest authors clearly define the problem and point out the novelty of their work in comparison with current studies from the beginning. \n\n%%%%%%%%%%%%% \n\nPlease elaborate on how the flow structured data is a \u201cradically new data type\u201d (ref. Section 1) \n\n%%%%%%%%%%%%% \n\nThe results in figure 7 are called \u201cvalidation\u201d loss. Does that imply these nodes have been included in the training or hyperparameter tuning of the model? If yes, it is more interesting to know how model performs for flow prediction of unseen nodes. \n\n%%%%%%%%%%%%% \n\nIt is interesting to know how the flow prediction task for K-step ahead will be.  \n\n%%%%%%%%%%%%% %%%%%%%%%%%%% \n\nMinor Concerns: \n\nThe paper has to be self-sufficient, so for equation 1 and 2, more explanation is needed instead of referring readers to the previous work.  \n\n%%%%%%%%%%%%% \n\nSome typos and grammatical errors that need to be fixed. Some examples: \n\nSection 1: \u201ctens to tens thousand of nodes\u201d, \u201cparticular deep learning\u201d \n\nFigure 3 caption: repeated \u201cthe\u201d \n\nSection 2: \u201cany pair of nodes in the routing path will become larger interchangeably than the other so that the flux is conserved among nodes\u201d \n\nSection 3: \u201ca encoding\u201d, \u201ca RNN\u201d, \u201cWhile any encoder and decoder can be used so long as we can backpropagate through it.\u201d, \u201cAnalogy to CPC, we define the following induction loss...\u201d \n\nPage 6: the two lines before section 4 do not seem to connect correctly with the previous page. \n\n %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% \n\nQuestions: \n\nPlease answer the questions raised in \u201cdetailed review\u201d above. \n\n \n\n \n\n \n\n ", "rating": "4: Ok but not good enough - rejection", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["ICLR.cc/2021/Conference/Paper2586/AnonReviewer4"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2586/AnonReviewer4"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Flow Neural Network for Traffic Flow Modelling in IP Networks", "authorids": ["~Xiangle_Cheng1", "y325he@uwaterloo.ca", "longfeifei@huawei.com", "xiaoshihan@huawei.com", "lifenglin@huawei.com"], "authors": ["Xiangle Cheng", "Yuchen He", "Feifei Long", "Shihan Xiao", "Fenglin Li"], "keywords": ["Flow neural network", "contrastive induction learning", "representation learning", "spatio-temporal induction"], "abstract": "This paper presents and investigates a novel and timely application domain for deep learning: sub-second traffic flow modelling in IP networks. Traffic flows are the most fundamental components in an IP based networking system. The accurate modelling of the generative patterns of these flows is crucial for many practical network applications. However, the high nonlinearity and dynamics of both the traffic and network conditions make this task challenging, particularly at the time granularity of sub-second. In this paper, we cast this problem as a representation learning task to model the intricate patterns in data traffic according to the IP network structure and working mechanism. Accordingly, we propose a customized Flow Neural Network, which works in a self-supervised way to extract the domain-specific data correlations. We report the state-of-the-art performances on both synthetic and realistic traffic patterns on multiple practical network applications, which provides a good testament to the strength of our approach.", "one-sentence_summary": "We propose a customised Flow Neural Network for the subsecond traffic flow modelling in IP networks by exploiting the domain-specific data properties according to the IP network structure and working machenism.", "pdf": "/pdf/395453ab2fb1a2fde41b7e1a8b5947aaffe4823f.pdf", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "cheng|flow_neural_network_for_traffic_flow_modelling_in_ip_networks", "supplementary_material": "/attachment/8349da2b0ae3d9a80c00229b5ce31cb11630310e.zip", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=m8VD_hNVNR", "_bibtex": "@misc{\ncheng2021flow,\ntitle={Flow Neural Network for Traffic Flow Modelling in {\\{}IP{\\}} Networks},\nauthor={Xiangle Cheng and Yuchen He and Feifei Long and Shihan Xiao and Fenglin Li},\nyear={2021},\nurl={https://openreview.net/forum?id=wUUKCAmBx6q}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq . ***Please remember to file the Code-of-Ethics report. Once you submitted the review, a link to the report will be visible in the bottom right corner of your review.***", "required": true, "markdown": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}, "forum": "wUUKCAmBx6q", "replyto": "wUUKCAmBx6q", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"], "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper2586/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1607428800000, "duedate": 1606752000000, "multiReply": false, "readers": ["everyone"], "tcdate": 1602538093013, "tmdate": 1606915757976, "super": "ICLR.cc/2021/Conference/-/Official_Review", "signatures": ["OpenReview.net"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Paper2586/Reviewers", "OpenReview.net/Support"], "id": "ICLR.cc/2021/Conference/Paper2586/-/Official_Review"}}}, {"id": "ikClxc9IUX", "original": null, "number": 1, "cdate": 1603880539310, "ddate": null, "tcdate": 1603880539310, "tmdate": 1605024176135, "tddate": null, "forum": "wUUKCAmBx6q", "replyto": "wUUKCAmBx6q", "invitation": "ICLR.cc/2021/Conference/Paper2586/-/Official_Review", "content": {"title": "Possibly an interesting approach but difficult to follow due to lack of clarity.", "review": "The work proposes a new way to analyse flow structured data using what they call flow neural networks, which supposedly better exploits correlations between different connected nodes at different time-points. The approach is tested on the public dataset NumFabric with better results than the compared to approaches.\n\nAlthough I believe I get the rough outline of what the authors are proposing, there is simply too many unclear aspects of the work for it to be published at ICLR. Prior work, especially the benchmarked methods, also seems to be mostly tangentially related, e.g. covering general methods for time-series or graph analysis and not specific methods for traffic analysis.\n\nQuality\nA single dataset is used for comparison and it is unclear how relevant the baselines are, as there appears to be a lot of prior work on deep learning for traffic analysis, some of this is cited, but not benchmarked against. See also the additional references [1, 2], and the large number of works citing them. It would be good if the authors could explain why their chosen set of baselines are relevant.\n\nClarity\nThe work is hard to understand. An incomplete list of things follows below.\n\n- Crucially I don't clearly understand the STI effect as explained in definition 1.\n- Why do you specifically mention self-driving Tesla cars, wouldn't this be relevant for other self-driving cars as well?\n- What do you mean by more than 1 million flows, that is, how do you count flows?\n- \"As the advent of many advanced machine learning (particular deep learning), intelligent flow analysis tools are gaining more momentum to proceed\", sentence does not make sense.\n- I do not understand the paragraph starting with \"Additionally, in contrast to the learning analysis of formation-agnostic natural objects, ...\" What is a formation-agnostic natural object? How can a network system enjoy rich domain expertise? How can network traffic experience something? Etc.\n- temproal -> temporal\n- was originated -> originated\n- \"This essentially discriminates\", does not really make sense to me in this context.\n- Sentence starting with \"In the path-constrained propagation process as doing in above IP traffic flows,..\", does not make sense to me.\n- What is APP?\n- It would be good to use the same number of decimal points for the result of each method in Table 1.\n- \"However, all deep learning based solutions achieve several times to tens times better accuracy.\", I do not see this in the figure.\n- Please use consistent naming schemes, see \"uniGRU\" and \"univarGRU\".\n- In summarizing the results (4.1), I think the word improves is a bit unclear when talking about reduction in loss. E.g. the loss is only xx percent of yy would be more clear.\n- \"This is benefited from the STI effect\" -> \"This is benefiting from the STI effect\"\n\nOriginality\nThe proposed work may very well be original and novel. I am just not convinced.\n\nSignificance\nIn its present form, I doubt it will have much influence.\n\n[1] Polson, Nicholas G., and Vadim O. Sokolov. \"Deep learning for short-term traffic flow prediction.\" Transportation Research Part C: Emerging Technologies 79 (2017): 1-17.\n[2] Cui, Zhiyong, et al. \"Traffic graph convolutional recurrent neural network: A deep learning framework for network-scale traffic learning and forecasting.\" IEEE Transactions on Intelligent Transportation Systems (2019).\n", "rating": "3: Clear rejection", "confidence": "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper"}, "signatures": ["ICLR.cc/2021/Conference/Paper2586/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2586/AnonReviewer3"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Flow Neural Network for Traffic Flow Modelling in IP Networks", "authorids": ["~Xiangle_Cheng1", "y325he@uwaterloo.ca", "longfeifei@huawei.com", "xiaoshihan@huawei.com", "lifenglin@huawei.com"], "authors": ["Xiangle Cheng", "Yuchen He", "Feifei Long", "Shihan Xiao", "Fenglin Li"], "keywords": ["Flow neural network", "contrastive induction learning", "representation learning", "spatio-temporal induction"], "abstract": "This paper presents and investigates a novel and timely application domain for deep learning: sub-second traffic flow modelling in IP networks. Traffic flows are the most fundamental components in an IP based networking system. The accurate modelling of the generative patterns of these flows is crucial for many practical network applications. However, the high nonlinearity and dynamics of both the traffic and network conditions make this task challenging, particularly at the time granularity of sub-second. In this paper, we cast this problem as a representation learning task to model the intricate patterns in data traffic according to the IP network structure and working mechanism. Accordingly, we propose a customized Flow Neural Network, which works in a self-supervised way to extract the domain-specific data correlations. We report the state-of-the-art performances on both synthetic and realistic traffic patterns on multiple practical network applications, which provides a good testament to the strength of our approach.", "one-sentence_summary": "We propose a customised Flow Neural Network for the subsecond traffic flow modelling in IP networks by exploiting the domain-specific data properties according to the IP network structure and working machenism.", "pdf": "/pdf/395453ab2fb1a2fde41b7e1a8b5947aaffe4823f.pdf", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "cheng|flow_neural_network_for_traffic_flow_modelling_in_ip_networks", "supplementary_material": "/attachment/8349da2b0ae3d9a80c00229b5ce31cb11630310e.zip", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=m8VD_hNVNR", "_bibtex": "@misc{\ncheng2021flow,\ntitle={Flow Neural Network for Traffic Flow Modelling in {\\{}IP{\\}} Networks},\nauthor={Xiangle Cheng and Yuchen He and Feifei Long and Shihan Xiao and Fenglin Li},\nyear={2021},\nurl={https://openreview.net/forum?id=wUUKCAmBx6q}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq . ***Please remember to file the Code-of-Ethics report. Once you submitted the review, a link to the report will be visible in the bottom right corner of your review.***", "required": true, "markdown": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}, "forum": "wUUKCAmBx6q", "replyto": "wUUKCAmBx6q", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"], "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper2586/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1607428800000, "duedate": 1606752000000, "multiReply": false, "readers": ["everyone"], "tcdate": 1602538093013, "tmdate": 1606915757976, "super": "ICLR.cc/2021/Conference/-/Official_Review", "signatures": ["OpenReview.net"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Paper2586/Reviewers", "OpenReview.net/Support"], "id": "ICLR.cc/2021/Conference/Paper2586/-/Official_Review"}}}, {"id": "l4dt9vS_0oi", "original": null, "number": 2, "cdate": 1603884799112, "ddate": null, "tcdate": 1603884799112, "tmdate": 1605024176073, "tddate": null, "forum": "wUUKCAmBx6q", "replyto": "wUUKCAmBx6q", "invitation": "ICLR.cc/2021/Conference/Paper2586/-/Official_Review", "content": {"title": "This paper proposes a Flow Neural Network (FlowNN) to model the flow-structured data. However, the writing and experiments should be improved.", "review": "In this paper, the authors present a new Flow Neural Network (FlowNN) to model the flow-structured data. The main idea is to employ the unique properties of the network traffic flows, i.e., flowing invariance and variance. \n\nOverall this seems like a nice attempt to model the flow-structured data. However, the paper should be improved in the following aspects.\n\n- Presentation: My first concern is the writing of this paper. \n1) After reading the first two sections, I was really confused about what the problem is. According to the experiment part, this paper seems to study the flow prediction task. What is the difference between this problem and spatio-temporal prediction? I strongly suggest that the authors write a section for introducing the problem statement. \n2) What is flow data? There seems no mathematical formulation of the network flow data (seemingly a tensor). \n3) More related works (e.g., flow-structure data mining, spatio-temporal GCNs, spatio-temporal forecasting) should be included to help the audiences better understand the context.\n\n- Experiments: \n1) The baselines are weak. To the best of my knowledge, in the recent 2 years, there are many papers [1, 2, 3] published at top-tier conferences (e.g., KDD, IJCAI, AAAI) that achieve much better results than the baselines included in this study. Why not comparing FlowNN with them?\n2) The proposed method is only evaluated on a single dataset, which limits its universality. If possible, more datasets should be considered.\n3) How about the robustness and stability of the proposed method? The variance of the performance should be present.\n4) In real-world applications such as traffic forecasting, multi-step ahead forecasting is more practical than 1-step prediction. It would be good to evaluate the effectiveness when predicting more future horizons.\n\n- Minor issues:\n1) The reference of GCN-GRU is wrong. As I know, Yu et al. 2018 combined temporal convolutional networks with GCN, instead of using RNN for capturing temporal dependencies.\n2) what is the meaning of the S-shaped road in Fig. 1?\n\nReference:\n[1] Wu et al., Graph WaveNet for Deep Spatial-Temporal Graph Modeling, IJCAI 2019\n[2] Guo et al., Attention Based Spatial-Temporal Graph Convolutional Networks for Traffic Flow Forecasting, AAAI 2019\n[3] Pan et al., Urban Traffic Prediction from Spatio-Temporal Data Using Deep Meta Learning, KDD 2019\n", "rating": "4: Ok but not good enough - rejection", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "signatures": ["ICLR.cc/2021/Conference/Paper2586/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2586/AnonReviewer1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Flow Neural Network for Traffic Flow Modelling in IP Networks", "authorids": ["~Xiangle_Cheng1", "y325he@uwaterloo.ca", "longfeifei@huawei.com", "xiaoshihan@huawei.com", "lifenglin@huawei.com"], "authors": ["Xiangle Cheng", "Yuchen He", "Feifei Long", "Shihan Xiao", "Fenglin Li"], "keywords": ["Flow neural network", "contrastive induction learning", "representation learning", "spatio-temporal induction"], "abstract": "This paper presents and investigates a novel and timely application domain for deep learning: sub-second traffic flow modelling in IP networks. Traffic flows are the most fundamental components in an IP based networking system. The accurate modelling of the generative patterns of these flows is crucial for many practical network applications. However, the high nonlinearity and dynamics of both the traffic and network conditions make this task challenging, particularly at the time granularity of sub-second. In this paper, we cast this problem as a representation learning task to model the intricate patterns in data traffic according to the IP network structure and working mechanism. Accordingly, we propose a customized Flow Neural Network, which works in a self-supervised way to extract the domain-specific data correlations. We report the state-of-the-art performances on both synthetic and realistic traffic patterns on multiple practical network applications, which provides a good testament to the strength of our approach.", "one-sentence_summary": "We propose a customised Flow Neural Network for the subsecond traffic flow modelling in IP networks by exploiting the domain-specific data properties according to the IP network structure and working machenism.", "pdf": "/pdf/395453ab2fb1a2fde41b7e1a8b5947aaffe4823f.pdf", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "cheng|flow_neural_network_for_traffic_flow_modelling_in_ip_networks", "supplementary_material": "/attachment/8349da2b0ae3d9a80c00229b5ce31cb11630310e.zip", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=m8VD_hNVNR", "_bibtex": "@misc{\ncheng2021flow,\ntitle={Flow Neural Network for Traffic Flow Modelling in {\\{}IP{\\}} Networks},\nauthor={Xiangle Cheng and Yuchen He and Feifei Long and Shihan Xiao and Fenglin Li},\nyear={2021},\nurl={https://openreview.net/forum?id=wUUKCAmBx6q}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq . ***Please remember to file the Code-of-Ethics report. Once you submitted the review, a link to the report will be visible in the bottom right corner of your review.***", "required": true, "markdown": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}, "forum": "wUUKCAmBx6q", "replyto": "wUUKCAmBx6q", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"], "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper2586/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1607428800000, "duedate": 1606752000000, "multiReply": false, "readers": ["everyone"], "tcdate": 1602538093013, "tmdate": 1606915757976, "super": "ICLR.cc/2021/Conference/-/Official_Review", "signatures": ["OpenReview.net"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Paper2586/Reviewers", "OpenReview.net/Support"], "id": "ICLR.cc/2021/Conference/Paper2586/-/Official_Review"}}}], "count": 7}