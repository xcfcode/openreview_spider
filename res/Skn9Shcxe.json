{"notes": [{"tddate": null, "replyto": null, "ddate": null, "tmdate": 1489526473969, "tcdate": 1478309267684, "number": 539, "id": "Skn9Shcxe", "invitation": "ICLR.cc/2017/conference/-/submission", "forum": "Skn9Shcxe", "signatures": ["~Klaus_Greff1"], "readers": ["everyone"], "content": {"TL;DR": "", "title": "Highway and Residual Networks learn Unrolled Iterative Estimation", "abstract": "The past year saw the introduction of new architectures such as Highway networks and Residual networks which, for the first time, enabled the training of feedforward networks with dozens to hundreds of layers using simple gradient descent.\nWhile depth of representation has been posited as a primary reason for their success, there are indications that these architectures defy a popular view of deep learning as a hierarchical computation of increasingly abstract features at each layer.\n\nIn this report, we argue that this view is incomplete and does not adequately explain several recent findings.\nWe propose an alternative viewpoint based on unrolled iterative estimation---a group of successive layers iteratively refine their estimates of the same features instead of computing an entirely new representation.\nWe demonstrate that this viewpoint directly leads to the construction of highway and residual networks. \nFinally we provide preliminary experiments to discuss the similarities and differences between the two architectures.", "pdf": "/pdf/0bbf16911fcc27702f7d59202487194811132f4a.pdf", "paperhash": "greff|highway_and_residual_networks_learn_unrolled_iterative_estimation", "keywords": ["Theory", "Deep learning", "Supervised Learning"], "conflicts": ["idsia.ch", "usi.ch", "supsi.ch"], "authors": ["Klaus Greff", "Rupesh K. Srivastava", "J\u00fcrgen Schmidhuber"], "authorids": ["klaus@idsia.ch", "rupesh@idsia.ch", "juergen@idsia.ch"]}, "writers": [], "nonreaders": [], "details": {"replyCount": 9, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1475686800000, "tmdate": 1478287705855, "id": "ICLR.cc/2017/conference/-/submission", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/pcs"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": null, "replyto": null, "writers": {"values-regex": "~.*"}, "signatures": {"values-regex": "~.*", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"pdf": {"required": true, "order": 5, "description": "Either upload a PDF file or provide a direct link to your PDF on ArXiv (link must begin with http(s) and end with .pdf)", "value-regex": "upload|(http|https):\\/\\/.+\\.pdf"}, "title": {"required": true, "order": 1, "description": "Title of paper.", "value-regex": ".{1,250}"}, "abstract": {"required": true, "order": 4, "description": "Abstract of paper.", "value-regex": "[\\S\\s]{1,5000}"}, "authors": {"required": true, "order": 2, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of author names, as they appear in the paper."}, "conflicts": {"required": true, "order": 100, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of email domains of people who would have a conflict of interest in reviewing this paper, (e.g., cs.umass.edu;google.com, etc.)."}, "keywords": {"order": 6, "description": "Comma separated list of keywords.", "values-dropdown": ["Theory", "Computer vision", "Speech", "Natural language processing", "Deep learning", "Unsupervised Learning", "Supervised Learning", "Semi-Supervised Learning", "Reinforcement Learning", "Transfer Learning", "Multi-modal learning", "Applications", "Optimization", "Structured prediction", "Games"]}, "TL;DR": {"required": false, "order": 3, "description": "\"Too Long; Didn't Read\": a short sentence describing your paper", "value-regex": "[^\\n]{0,250}"}, "authorids": {"required": true, "order": 3, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of author email addresses, in the same order as above."}}}, "nonreaders": [], "noninvitees": [], "expdate": 1483462800000, "cdate": 1478287705855}}}, {"tddate": null, "ddate": null, "cdate": null, "tmdate": 1486396665060, "tcdate": 1486396665060, "number": 1, "id": "Sy--pfU_e", "invitation": "ICLR.cc/2017/conference/-/paper539/acceptance", "forum": "Skn9Shcxe", "replyto": "Skn9Shcxe", "signatures": ["ICLR.cc/2017/pcs"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/pcs"], "content": {"title": "ICLR committee final decision", "comment": "The paper provides interesting new interpretations of highway and residual networks, which should be of great interest to the community.", "decision": "Accept (Poster)"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"TL;DR": "", "title": "Highway and Residual Networks learn Unrolled Iterative Estimation", "abstract": "The past year saw the introduction of new architectures such as Highway networks and Residual networks which, for the first time, enabled the training of feedforward networks with dozens to hundreds of layers using simple gradient descent.\nWhile depth of representation has been posited as a primary reason for their success, there are indications that these architectures defy a popular view of deep learning as a hierarchical computation of increasingly abstract features at each layer.\n\nIn this report, we argue that this view is incomplete and does not adequately explain several recent findings.\nWe propose an alternative viewpoint based on unrolled iterative estimation---a group of successive layers iteratively refine their estimates of the same features instead of computing an entirely new representation.\nWe demonstrate that this viewpoint directly leads to the construction of highway and residual networks. \nFinally we provide preliminary experiments to discuss the similarities and differences between the two architectures.", "pdf": "/pdf/0bbf16911fcc27702f7d59202487194811132f4a.pdf", "paperhash": "greff|highway_and_residual_networks_learn_unrolled_iterative_estimation", "keywords": ["Theory", "Deep learning", "Supervised Learning"], "conflicts": ["idsia.ch", "usi.ch", "supsi.ch"], "authors": ["Klaus Greff", "Rupesh K. Srivastava", "J\u00fcrgen Schmidhuber"], "authorids": ["klaus@idsia.ch", "rupesh@idsia.ch", "juergen@idsia.ch"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1486396665581, "id": "ICLR.cc/2017/conference/-/paper539/acceptance", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/pcs"], "noninvitees": ["ICLR.cc/2017/pcs"], "reply": {"forum": "Skn9Shcxe", "replyto": "Skn9Shcxe", "writers": {"values-regex": "ICLR.cc/2017/pcs"}, "signatures": {"values-regex": "ICLR.cc/2017/pcs", "description": "Your displayed identity associated with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your decision.", "value": "ICLR committee final decision"}, "comment": {"required": true, "order": 2, "description": "Decision comments.", "value-regex": "[\\S\\s]{1,5000}"}, "decision": {"required": true, "order": 3, "value-radio": ["Accept (Oral)", "Accept (Poster)", "Reject", "Invite to Workshop Track"]}}}, "nonreaders": [], "cdate": 1486396665581}}}, {"tddate": null, "tmdate": 1484750055207, "tcdate": 1484750055207, "number": 3, "id": "BkkgTl6Il", "invitation": "ICLR.cc/2017/conference/-/paper539/public/comment", "forum": "Skn9Shcxe", "replyto": "Skn9Shcxe", "signatures": ["~Klaus_Greff1"], "readers": ["everyone"], "writers": ["~Klaus_Greff1"], "content": {"title": "Updated Version", "comment": "We've uploaded an updated version of the paper which addresses reviewers' concerns and makes several improvements. Apologies for the late revision, mainly due to the time-consuming ImageNet experiments. \n\n- To further confirm the iterative estimation, and contrast our view with the findings of Zeiler and Fergus (2014), we did a literature survey and planned on adding some visualizations of ResNet features.  We found a technical report from Brian Chu at Berkeley who applied known visualization techniques to Resnets independently and report exactly the behaviour we were expecting: The features within a stage get refined and sharpened. So now we refer to their paper and (with their kind permission) reproduce one of their visualizations. We have added a discussion of these findings which support our proposed view. \n\n- We've added mean+-std results for the experiments in Section 5.1.\nThese experiments take a long time, so we performed only three runs each, but the results are stable enough for comparison.\n\n- We've elaborated a bit further on the role of batch normalization in Section 5.1. \n\n- improved language and organization\n\nApart from these changes we've also started investigating the unexpected behaviour of stage 4, by creating modified architectures. We've added three blocks to that stage and we've tried adding a fifth stage. We found that both variants improve performance to ca. 6.8% top5 error.\nBut the average estimation error stays high for the first few blocks and only later starts to decrease: [-0.32, -0.31, -0.30, -0.27, -0.17] (compare Figure 3)\nWe are further investigating this and we'll add our findings as soon as they paint a coherent picture.  But as of now, we didn't consider them to be interesting enough to be included in the paper. \n"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"TL;DR": "", "title": "Highway and Residual Networks learn Unrolled Iterative Estimation", "abstract": "The past year saw the introduction of new architectures such as Highway networks and Residual networks which, for the first time, enabled the training of feedforward networks with dozens to hundreds of layers using simple gradient descent.\nWhile depth of representation has been posited as a primary reason for their success, there are indications that these architectures defy a popular view of deep learning as a hierarchical computation of increasingly abstract features at each layer.\n\nIn this report, we argue that this view is incomplete and does not adequately explain several recent findings.\nWe propose an alternative viewpoint based on unrolled iterative estimation---a group of successive layers iteratively refine their estimates of the same features instead of computing an entirely new representation.\nWe demonstrate that this viewpoint directly leads to the construction of highway and residual networks. \nFinally we provide preliminary experiments to discuss the similarities and differences between the two architectures.", "pdf": "/pdf/0bbf16911fcc27702f7d59202487194811132f4a.pdf", "paperhash": "greff|highway_and_residual_networks_learn_unrolled_iterative_estimation", "keywords": ["Theory", "Deep learning", "Supervised Learning"], "conflicts": ["idsia.ch", "usi.ch", "supsi.ch"], "authors": ["Klaus Greff", "Rupesh K. Srivastava", "J\u00fcrgen Schmidhuber"], "authorids": ["klaus@idsia.ch", "rupesh@idsia.ch", "juergen@idsia.ch"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287531069, "id": "ICLR.cc/2017/conference/-/paper539/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "Skn9Shcxe", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper539/reviewers", "ICLR.cc/2017/conference/paper539/areachairs"], "cdate": 1485287531069}}}, {"tddate": null, "tmdate": 1482439953568, "tcdate": 1482433400766, "number": 3, "id": "rJ-YmjtEg", "invitation": "ICLR.cc/2017/conference/-/paper539/official/review", "forum": "Skn9Shcxe", "replyto": "Skn9Shcxe", "signatures": ["ICLR.cc/2017/conference/paper539/AnonReviewer1"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/conference/paper539/AnonReviewer1"], "content": {"title": "An interesting angle on resNets and Highway nets", "rating": "7: Good paper, accept", "review": "Thank you for an interesting angle on highway and residual networks. This paper shows a new angle to how and what kind of representations are learnt at each layer in the aforementioned models. Due to residual information being provided at a periodic number of steps, each of the layers preserve feature identity which prevents lesioning unlike convolutional neural nets.                                 \n                                                                                                                                                                                                          \nPros                                                                                                                                                                                                      \n- the iterative unrolling view was extremely simple and intuitive, which was supported by theoretical results and reasonable assumptions.                                                                 \n- Figure 3 gave a clear visualization for the iterative unrolling view                                                                                                                                    \n                                                                                                                                                                                                          \nCons                                                                                                                                                                                                      \n- Even though, the perspective is interesting few empirical results were shown to support the argument. The major experiments are image classification and language models trained on mutations of character-aware neural language models.                                                                                                                                                                         \n- Figure 4 and 5 could be combined and enlarged to show the effects of batch normalization.   ", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"TL;DR": "", "title": "Highway and Residual Networks learn Unrolled Iterative Estimation", "abstract": "The past year saw the introduction of new architectures such as Highway networks and Residual networks which, for the first time, enabled the training of feedforward networks with dozens to hundreds of layers using simple gradient descent.\nWhile depth of representation has been posited as a primary reason for their success, there are indications that these architectures defy a popular view of deep learning as a hierarchical computation of increasingly abstract features at each layer.\n\nIn this report, we argue that this view is incomplete and does not adequately explain several recent findings.\nWe propose an alternative viewpoint based on unrolled iterative estimation---a group of successive layers iteratively refine their estimates of the same features instead of computing an entirely new representation.\nWe demonstrate that this viewpoint directly leads to the construction of highway and residual networks. \nFinally we provide preliminary experiments to discuss the similarities and differences between the two architectures.", "pdf": "/pdf/0bbf16911fcc27702f7d59202487194811132f4a.pdf", "paperhash": "greff|highway_and_residual_networks_learn_unrolled_iterative_estimation", "keywords": ["Theory", "Deep learning", "Supervised Learning"], "conflicts": ["idsia.ch", "usi.ch", "supsi.ch"], "authors": ["Klaus Greff", "Rupesh K. Srivastava", "J\u00fcrgen Schmidhuber"], "authorids": ["klaus@idsia.ch", "rupesh@idsia.ch", "juergen@idsia.ch"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1481932799000, "tmdate": 1482512548775, "id": "ICLR.cc/2017/conference/-/paper539/official/review", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/conference/paper539/reviewers"], "noninvitees": ["ICLR.cc/2017/conference/paper539/AnonReviewer3", "ICLR.cc/2017/conference/paper539/AnonReviewer2", "ICLR.cc/2017/conference/paper539/AnonReviewer1"], "reply": {"forum": "Skn9Shcxe", "replyto": "Skn9Shcxe", "writers": {"values-regex": "ICLR.cc/2017/conference/paper539/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/conference/paper539/AnonReviewer[0-9]+"}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "value-regex": "[\\S\\s]{1,20000}"}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1489708799000, "cdate": 1482512548775}}}, {"tddate": null, "tmdate": 1481826830915, "tcdate": 1481826830911, "number": 2, "id": "ryPfGPlVe", "invitation": "ICLR.cc/2017/conference/-/paper539/public/comment", "forum": "Skn9Shcxe", "replyto": "HkofLcpml", "signatures": ["~Klaus_Greff1"], "readers": ["everyone"], "writers": ["~Klaus_Greff1"], "content": {"title": "several answers", "comment": "@Question 1:\nWe intended A_i to mean the (unknown) value towards which the feature i is converging. But we agree that this is unclear in the current version. In our experiments we've just used the final feature value (A_i = a_i^L).\n\n@Question 2:\nThe x-axis measures the blocks within the stage. So point k represents is the empirical mean and variance of estimation error for block k, i.e. a^k - A_i as in Eq 1, that is the difference of the block-output with the final representation of that stage.\n"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"TL;DR": "", "title": "Highway and Residual Networks learn Unrolled Iterative Estimation", "abstract": "The past year saw the introduction of new architectures such as Highway networks and Residual networks which, for the first time, enabled the training of feedforward networks with dozens to hundreds of layers using simple gradient descent.\nWhile depth of representation has been posited as a primary reason for their success, there are indications that these architectures defy a popular view of deep learning as a hierarchical computation of increasingly abstract features at each layer.\n\nIn this report, we argue that this view is incomplete and does not adequately explain several recent findings.\nWe propose an alternative viewpoint based on unrolled iterative estimation---a group of successive layers iteratively refine their estimates of the same features instead of computing an entirely new representation.\nWe demonstrate that this viewpoint directly leads to the construction of highway and residual networks. \nFinally we provide preliminary experiments to discuss the similarities and differences between the two architectures.", "pdf": "/pdf/0bbf16911fcc27702f7d59202487194811132f4a.pdf", "paperhash": "greff|highway_and_residual_networks_learn_unrolled_iterative_estimation", "keywords": ["Theory", "Deep learning", "Supervised Learning"], "conflicts": ["idsia.ch", "usi.ch", "supsi.ch"], "authors": ["Klaus Greff", "Rupesh K. Srivastava", "J\u00fcrgen Schmidhuber"], "authorids": ["klaus@idsia.ch", "rupesh@idsia.ch", "juergen@idsia.ch"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287531069, "id": "ICLR.cc/2017/conference/-/paper539/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "Skn9Shcxe", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper539/reviewers", "ICLR.cc/2017/conference/paper539/areachairs"], "cdate": 1485287531069}}}, {"tddate": null, "tmdate": 1481826676922, "tcdate": 1481826676918, "number": 1, "id": "HyTuZPx4e", "invitation": "ICLR.cc/2017/conference/-/paper539/public/comment", "forum": "Skn9Shcxe", "replyto": "BJHkc2JXx", "signatures": ["~Klaus_Greff1"], "readers": ["everyone"], "writers": ["~Klaus_Greff1"], "content": {"title": "Additional Experiments", "comment": "We agree, and we are in the process of running these experiments. But please note that each run takes several days to complete, so it will take a while."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"TL;DR": "", "title": "Highway and Residual Networks learn Unrolled Iterative Estimation", "abstract": "The past year saw the introduction of new architectures such as Highway networks and Residual networks which, for the first time, enabled the training of feedforward networks with dozens to hundreds of layers using simple gradient descent.\nWhile depth of representation has been posited as a primary reason for their success, there are indications that these architectures defy a popular view of deep learning as a hierarchical computation of increasingly abstract features at each layer.\n\nIn this report, we argue that this view is incomplete and does not adequately explain several recent findings.\nWe propose an alternative viewpoint based on unrolled iterative estimation---a group of successive layers iteratively refine their estimates of the same features instead of computing an entirely new representation.\nWe demonstrate that this viewpoint directly leads to the construction of highway and residual networks. \nFinally we provide preliminary experiments to discuss the similarities and differences between the two architectures.", "pdf": "/pdf/0bbf16911fcc27702f7d59202487194811132f4a.pdf", "paperhash": "greff|highway_and_residual_networks_learn_unrolled_iterative_estimation", "keywords": ["Theory", "Deep learning", "Supervised Learning"], "conflicts": ["idsia.ch", "usi.ch", "supsi.ch"], "authors": ["Klaus Greff", "Rupesh K. Srivastava", "J\u00fcrgen Schmidhuber"], "authorids": ["klaus@idsia.ch", "rupesh@idsia.ch", "juergen@idsia.ch"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287531069, "id": "ICLR.cc/2017/conference/-/paper539/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "Skn9Shcxe", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper539/reviewers", "ICLR.cc/2017/conference/paper539/areachairs"], "cdate": 1485287531069}}}, {"tddate": null, "tmdate": 1481819633547, "tcdate": 1481819531327, "number": 2, "id": "BJ79SHeNg", "invitation": "ICLR.cc/2017/conference/-/paper539/official/review", "forum": "Skn9Shcxe", "replyto": "Skn9Shcxe", "signatures": ["ICLR.cc/2017/conference/paper539/AnonReviewer2"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/conference/paper539/AnonReviewer2"], "content": {"title": "An interesting perspective on representations in DNNs", "rating": "8: Top 50% of accepted papers, clear accept", "review": "The paper describes an alternative view on hierarchical feature representations in deep neural networks. The viewpoint of refining representations is well motivated and is in agreement with the success of recent model structures like ResNets.\n\nPros:\n\n- Good motivation for the effectiveness of ResNets and Highway networks\n- Convincing analysis and evaluation\n\nCons:\n\n- The effect of this finding of the interpretation of batch-normalization is only captured briefly but seems to be significant\n- Explanation of findings in (Zeiler & Fergus (2014)) using UIE viewpoint missing\n\nRemarks:\n\n- Missing word in line 223: \"that it *is* valid\"", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"TL;DR": "", "title": "Highway and Residual Networks learn Unrolled Iterative Estimation", "abstract": "The past year saw the introduction of new architectures such as Highway networks and Residual networks which, for the first time, enabled the training of feedforward networks with dozens to hundreds of layers using simple gradient descent.\nWhile depth of representation has been posited as a primary reason for their success, there are indications that these architectures defy a popular view of deep learning as a hierarchical computation of increasingly abstract features at each layer.\n\nIn this report, we argue that this view is incomplete and does not adequately explain several recent findings.\nWe propose an alternative viewpoint based on unrolled iterative estimation---a group of successive layers iteratively refine their estimates of the same features instead of computing an entirely new representation.\nWe demonstrate that this viewpoint directly leads to the construction of highway and residual networks. \nFinally we provide preliminary experiments to discuss the similarities and differences between the two architectures.", "pdf": "/pdf/0bbf16911fcc27702f7d59202487194811132f4a.pdf", "paperhash": "greff|highway_and_residual_networks_learn_unrolled_iterative_estimation", "keywords": ["Theory", "Deep learning", "Supervised Learning"], "conflicts": ["idsia.ch", "usi.ch", "supsi.ch"], "authors": ["Klaus Greff", "Rupesh K. Srivastava", "J\u00fcrgen Schmidhuber"], "authorids": ["klaus@idsia.ch", "rupesh@idsia.ch", "juergen@idsia.ch"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1481932799000, "tmdate": 1482512548775, "id": "ICLR.cc/2017/conference/-/paper539/official/review", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/conference/paper539/reviewers"], "noninvitees": ["ICLR.cc/2017/conference/paper539/AnonReviewer3", "ICLR.cc/2017/conference/paper539/AnonReviewer2", "ICLR.cc/2017/conference/paper539/AnonReviewer1"], "reply": {"forum": "Skn9Shcxe", "replyto": "Skn9Shcxe", "writers": {"values-regex": "ICLR.cc/2017/conference/paper539/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/conference/paper539/AnonReviewer[0-9]+"}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "value-regex": "[\\S\\s]{1,20000}"}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1489708799000, "cdate": 1482512548775}}}, {"tddate": null, "tmdate": 1481817436394, "tcdate": 1481817436388, "number": 1, "id": "SkVvpEeEg", "invitation": "ICLR.cc/2017/conference/-/paper539/official/review", "forum": "Skn9Shcxe", "replyto": "Skn9Shcxe", "signatures": ["ICLR.cc/2017/conference/paper539/AnonReviewer3"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/conference/paper539/AnonReviewer3"], "content": {"title": "A New Perspective of ResNet and Highway Network", "rating": "6: Marginally above acceptance threshold", "review": "This paper provides a new perspective to understanding the ResNet and Highway net. The new perspective assumes that the blocks inside the networks with residual or skip-connection are groups of successive layers with the same hidden size, which performs to iteratively refine their estimates of the same feature instead of generate new representations. Under this perspective, some contradictories with the traditional representation view induced by ResNet and Highway network and other paper can be well explained.\n\nThe pros of the paper are:\n1. A novel perspective to understand the recent progress of neural network is proposed.\n2. The paper provides a quantitatively experimentals to compare ResNet and Highway net, and shows contradict results with several claims from previous work. The authors also give discussions and explanations about the contradictories, which provides a good insight of the disadvantages and advantages between these two kind of networks.\n\nThe main cons of the paper is that the experiments are not sufficient. For example, since the main contribution of the paper is to propose the \u201cunrolled iterative estimation\" and the stage 4 of Figure 3 seems not follow the assumption of \"unrolled iterative estimation\" and the authors says: \"We note that stage four (with three blocks) appears to be underestimating the representation values, indicating a probable weak link in the architecture.\". Thus, it would be much better to do experiments to show that under some condition, the performance of stage 4 can follow the assumption. \n\nMoreover, the paper should provide more experiments to show the evidence of \"unrolled iterative estimation\", not comparing ResNet with Highway Net. The lack of experiments on this point is the main concern from myself.\n\n", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"TL;DR": "", "title": "Highway and Residual Networks learn Unrolled Iterative Estimation", "abstract": "The past year saw the introduction of new architectures such as Highway networks and Residual networks which, for the first time, enabled the training of feedforward networks with dozens to hundreds of layers using simple gradient descent.\nWhile depth of representation has been posited as a primary reason for their success, there are indications that these architectures defy a popular view of deep learning as a hierarchical computation of increasingly abstract features at each layer.\n\nIn this report, we argue that this view is incomplete and does not adequately explain several recent findings.\nWe propose an alternative viewpoint based on unrolled iterative estimation---a group of successive layers iteratively refine their estimates of the same features instead of computing an entirely new representation.\nWe demonstrate that this viewpoint directly leads to the construction of highway and residual networks. \nFinally we provide preliminary experiments to discuss the similarities and differences between the two architectures.", "pdf": "/pdf/0bbf16911fcc27702f7d59202487194811132f4a.pdf", "paperhash": "greff|highway_and_residual_networks_learn_unrolled_iterative_estimation", "keywords": ["Theory", "Deep learning", "Supervised Learning"], "conflicts": ["idsia.ch", "usi.ch", "supsi.ch"], "authors": ["Klaus Greff", "Rupesh K. Srivastava", "J\u00fcrgen Schmidhuber"], "authorids": ["klaus@idsia.ch", "rupesh@idsia.ch", "juergen@idsia.ch"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1481932799000, "tmdate": 1482512548775, "id": "ICLR.cc/2017/conference/-/paper539/official/review", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/conference/paper539/reviewers"], "noninvitees": ["ICLR.cc/2017/conference/paper539/AnonReviewer3", "ICLR.cc/2017/conference/paper539/AnonReviewer2", "ICLR.cc/2017/conference/paper539/AnonReviewer1"], "reply": {"forum": "Skn9Shcxe", "replyto": "Skn9Shcxe", "writers": {"values-regex": "ICLR.cc/2017/conference/paper539/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/conference/paper539/AnonReviewer[0-9]+"}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "value-regex": "[\\S\\s]{1,20000}"}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1489708799000, "cdate": 1482512548775}}}, {"tddate": null, "tmdate": 1481643539424, "tcdate": 1481643539417, "number": 2, "id": "HkofLcpml", "invitation": "ICLR.cc/2017/conference/-/paper539/pre-review/question", "forum": "Skn9Shcxe", "replyto": "Skn9Shcxe", "signatures": ["ICLR.cc/2017/conference/paper539/AnonReviewer3"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/conference/paper539/AnonReviewer3"], "content": {"title": "several questions", "question": "1. What is the definition of A_i in the paper?\n\n2. What is the x-axis of Figure 3?"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"TL;DR": "", "title": "Highway and Residual Networks learn Unrolled Iterative Estimation", "abstract": "The past year saw the introduction of new architectures such as Highway networks and Residual networks which, for the first time, enabled the training of feedforward networks with dozens to hundreds of layers using simple gradient descent.\nWhile depth of representation has been posited as a primary reason for their success, there are indications that these architectures defy a popular view of deep learning as a hierarchical computation of increasingly abstract features at each layer.\n\nIn this report, we argue that this view is incomplete and does not adequately explain several recent findings.\nWe propose an alternative viewpoint based on unrolled iterative estimation---a group of successive layers iteratively refine their estimates of the same features instead of computing an entirely new representation.\nWe demonstrate that this viewpoint directly leads to the construction of highway and residual networks. \nFinally we provide preliminary experiments to discuss the similarities and differences between the two architectures.", "pdf": "/pdf/0bbf16911fcc27702f7d59202487194811132f4a.pdf", "paperhash": "greff|highway_and_residual_networks_learn_unrolled_iterative_estimation", "keywords": ["Theory", "Deep learning", "Supervised Learning"], "conflicts": ["idsia.ch", "usi.ch", "supsi.ch"], "authors": ["Klaus Greff", "Rupesh K. Srivastava", "J\u00fcrgen Schmidhuber"], "authorids": ["klaus@idsia.ch", "rupesh@idsia.ch", "juergen@idsia.ch"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1480741199000, "tmdate": 1481643540046, "id": "ICLR.cc/2017/conference/-/paper539/pre-review/question", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/conference/paper539/reviewers"], "noninvitees": ["ICLR.cc/2017/conference/paper539/AnonReviewer1", "ICLR.cc/2017/conference/paper539/AnonReviewer3"], "reply": {"forum": "Skn9Shcxe", "replyto": "Skn9Shcxe", "writers": {"values-regex": "ICLR.cc/2017/conference/paper539/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/conference/paper539/AnonReviewer[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your question.", "value-regex": ".{1,500}"}, "question": {"order": 2, "description": "Your question", "value-regex": "[\\S\\s]{1,5000}"}}}, "nonreaders": [], "expdate": 1488517199000, "cdate": 1481643540046}}}, {"tddate": null, "tmdate": 1480735196985, "tcdate": 1480735196979, "number": 1, "id": "BJHkc2JXx", "invitation": "ICLR.cc/2017/conference/-/paper539/pre-review/question", "forum": "Skn9Shcxe", "replyto": "Skn9Shcxe", "signatures": ["ICLR.cc/2017/conference/paper539/AnonReviewer1"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/conference/paper539/AnonReviewer1"], "content": {"title": "Batch Normalization", "question": "An interesting view on skip-connection based networks.\n\nI had one comment though, it would be great to have significance test on the experimental results to verify claims made in Section 5.1"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"TL;DR": "", "title": "Highway and Residual Networks learn Unrolled Iterative Estimation", "abstract": "The past year saw the introduction of new architectures such as Highway networks and Residual networks which, for the first time, enabled the training of feedforward networks with dozens to hundreds of layers using simple gradient descent.\nWhile depth of representation has been posited as a primary reason for their success, there are indications that these architectures defy a popular view of deep learning as a hierarchical computation of increasingly abstract features at each layer.\n\nIn this report, we argue that this view is incomplete and does not adequately explain several recent findings.\nWe propose an alternative viewpoint based on unrolled iterative estimation---a group of successive layers iteratively refine their estimates of the same features instead of computing an entirely new representation.\nWe demonstrate that this viewpoint directly leads to the construction of highway and residual networks. \nFinally we provide preliminary experiments to discuss the similarities and differences between the two architectures.", "pdf": "/pdf/0bbf16911fcc27702f7d59202487194811132f4a.pdf", "paperhash": "greff|highway_and_residual_networks_learn_unrolled_iterative_estimation", "keywords": ["Theory", "Deep learning", "Supervised Learning"], "conflicts": ["idsia.ch", "usi.ch", "supsi.ch"], "authors": ["Klaus Greff", "Rupesh K. Srivastava", "J\u00fcrgen Schmidhuber"], "authorids": ["klaus@idsia.ch", "rupesh@idsia.ch", "juergen@idsia.ch"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1480741199000, "tmdate": 1481643540046, "id": "ICLR.cc/2017/conference/-/paper539/pre-review/question", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/conference/paper539/reviewers"], "noninvitees": ["ICLR.cc/2017/conference/paper539/AnonReviewer1", "ICLR.cc/2017/conference/paper539/AnonReviewer3"], "reply": {"forum": "Skn9Shcxe", "replyto": "Skn9Shcxe", "writers": {"values-regex": "ICLR.cc/2017/conference/paper539/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/conference/paper539/AnonReviewer[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your question.", "value-regex": ".{1,500}"}, "question": {"order": 2, "description": "Your question", "value-regex": "[\\S\\s]{1,5000}"}}}, "nonreaders": [], "expdate": 1488517199000, "cdate": 1481643540046}}}], "count": 10}