{"notes": [{"id": "S1l5yrVqPS", "original": null, "number": 8, "cdate": 1569502433715, "ddate": null, "tcdate": 1569502433715, "tmdate": 1569502433715, "tddate": null, "forum": "HkxStoC5F7", "replyto": "HyxBBF9MDB", "invitation": "ICLR.cc/2019/Conference/-/Paper441/Official_Comment", "content": {"title": "To provide a fair comparison we use standard choices for architecture and other parameters across different meta-learning methods.", "comment": "Thank you for your comment!\n\nSummary: \n\nTo provide a fair comparison we use standard choices for architecture and other parameters across different meta-learning methods.\n\nDetailed Response:\n\nFor many works in the meta-learning community (especially for image classification as the main testbed) it is often difficult to disentangle gains due to improved feature extractors or improved meta-learning methodology. Depending on the data modality, stronger or weaker feature extractors may exist. To assess the quality of the meta-learner and not of ever-deeper architectures, many works utilise the same or very similar architecture (4 layer convnet) as a feature extractor, see our discussion on page 8. Note that this protocol for evaluating meta-learning methods is in line with e.g., MAML, Prototypical networks, Matching nets, and others. \n\nBauer et al 2017 (https://arxiv.org/abs/1706.00326, https://openreview.net/forum?id=r1DPFCyA-) and, more recently, Chen et al 2019 (https://openreview.net/forum?id=HkxLXnAcFQ) discuss the role of deeper feature extractors in few-shot learning scenarios. Both works find that results for the same meta-learning methodology vary hugely depending on the feature extractor used; the variability due to feature extractor is often larger than that due to meta-learner. \n\nAs our work proposes a new meta-learner, we -- in line with many other meta-learning works -- chose to compare on the simple standard architecture on which we indeed achieve SotA.  Comparing performance of one algorithm using a ResNet to another using the simpler convnet network is an apples-to-oranges comparison. As you note, the results we report for SNAIL are taken from their ablation study, where they investigate SNAIL performance with this simpler architecture. In this setting, Versa significantly outperforms SNAIL, and this is an important data-point."}, "signatures": ["ICLR.cc/2019/Conference/Paper441/Authors"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper441/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper441/Authors", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Meta-Learning Probabilistic Inference for Prediction", "abstract": "This paper introduces a new framework for data efficient and versatile learning. Specifically:\n1) We develop ML-PIP, a general framework for Meta-Learning approximate Probabilistic Inference for Prediction. ML-PIP extends existing probabilistic interpretations of meta-learning to cover a broad class of methods. \n2) We introduce \\Versa{}, an instance of the framework employing a flexible and versatile amortization network that takes few-shot learning datasets as inputs, with arbitrary numbers of shots, and outputs a distribution over task-specific parameters in a single forward pass. \\Versa{} substitutes optimization at test time with forward passes through inference networks, amortizing the cost of inference and relieving the need for second derivatives during training.\n3) We evaluate \\Versa{} on benchmark datasets where the method sets new state-of-the-art results, and can handle arbitrary number of shots, and for classification, arbitrary numbers of classes at train and test time. The power of the approach is then demonstrated through a challenging few-shot ShapeNet view reconstruction task.", "keywords": ["probabilistic models", "approximate inference", "few-shot learning", "meta-learning"], "authorids": ["jg801@cam.ac.uk", "jfb54@cam.ac.uk", "bauer@tue.mpg.de", "nowozin@google.com", "ret26@cam.ac.uk"], "authors": ["Jonathan Gordon", "John Bronskill", "Matthias Bauer", "Sebastian Nowozin", "Richard Turner"], "TL;DR": "Novel framework for meta-learning that unifies and extends a broad class of existing few-shot learning methods. Achieves strong performance on few-shot learning benchmarks without requiring iterative test-time inference.   ", "pdf": "/pdf/e9d0c9677cdf67034a920a123c97bfbea6e64d5b.pdf", "paperhash": "gordon|metalearning_probabilistic_inference_for_prediction", "_bibtex": "@inproceedings{\ngordon2018metalearning,\ntitle={Meta-Learning Probabilistic Inference for Prediction},\nauthor={Jonathan Gordon and John Bronskill and Matthias Bauer and Sebastian Nowozin and Richard Turner},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=HkxStoC5F7},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper441/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621620899, "tddate": null, "super": null, "final": null, "reply": {"forum": "HkxStoC5F7", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper441/Authors", "ICLR.cc/2019/Conference/Paper441/Reviewers", "ICLR.cc/2019/Conference/Paper441/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper441/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper441/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper441/Authors|ICLR.cc/2019/Conference/Paper441/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper441/Reviewers", "ICLR.cc/2019/Conference/Paper441/Authors", "ICLR.cc/2019/Conference/Paper441/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621620899}}}, {"id": "SylVqUcGvr", "original": null, "number": 4, "cdate": 1569003148477, "ddate": null, "tcdate": 1569003148477, "tmdate": 1569007152804, "tddate": null, "forum": "HkxStoC5F7", "replyto": "HkxStoC5F7", "invitation": "ICLR.cc/2019/Conference/-/Paper441/Public_Comment", "content": {"comment": "In your paper, you report 45.1% and 55.2% accuracies for SNAIL [1] for 1-shot and 5-shot, respectively, yet in their original paper they reported much higher results (55.71 \u00b1 0.99% and 68.88 \u00b1 0.92%). I could not find any explanations for the results you reported. Could you comment on it? Am I missing something? Thank you.\n\n[UPDATE] I noticed the appendix in their paper where they report these results you reported for an architecture equivalent to the one used by other approaches. In any case, I think it's misleading to claim to be the state of the art on a dataset in this way. You could say at most that you are the state of the art on MiniImageNet with the Conv4 architecture.\n\n[1] Nikhil Mishra, Mostafa Rohaninejad, Xi Chen, and Pieter Abbeel.  A simple neural attentive meta-learner. In International Conference on Learning Representations, 2018.\nhttps://openreview.net/forum?id=B1DmUzWAW&noteId=B1DmUzWAW", "title": "Incorrect results for SNAIL?"}, "signatures": ["(anonymous)"], "readers": ["everyone"], "nonreaders": [], "writers": ["(anonymous)", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Meta-Learning Probabilistic Inference for Prediction", "abstract": "This paper introduces a new framework for data efficient and versatile learning. Specifically:\n1) We develop ML-PIP, a general framework for Meta-Learning approximate Probabilistic Inference for Prediction. ML-PIP extends existing probabilistic interpretations of meta-learning to cover a broad class of methods. \n2) We introduce \\Versa{}, an instance of the framework employing a flexible and versatile amortization network that takes few-shot learning datasets as inputs, with arbitrary numbers of shots, and outputs a distribution over task-specific parameters in a single forward pass. \\Versa{} substitutes optimization at test time with forward passes through inference networks, amortizing the cost of inference and relieving the need for second derivatives during training.\n3) We evaluate \\Versa{} on benchmark datasets where the method sets new state-of-the-art results, and can handle arbitrary number of shots, and for classification, arbitrary numbers of classes at train and test time. The power of the approach is then demonstrated through a challenging few-shot ShapeNet view reconstruction task.", "keywords": ["probabilistic models", "approximate inference", "few-shot learning", "meta-learning"], "authorids": ["jg801@cam.ac.uk", "jfb54@cam.ac.uk", "bauer@tue.mpg.de", "nowozin@google.com", "ret26@cam.ac.uk"], "authors": ["Jonathan Gordon", "John Bronskill", "Matthias Bauer", "Sebastian Nowozin", "Richard Turner"], "TL;DR": "Novel framework for meta-learning that unifies and extends a broad class of existing few-shot learning methods. Achieves strong performance on few-shot learning benchmarks without requiring iterative test-time inference.   ", "pdf": "/pdf/e9d0c9677cdf67034a920a123c97bfbea6e64d5b.pdf", "paperhash": "gordon|metalearning_probabilistic_inference_for_prediction", "_bibtex": "@inproceedings{\ngordon2018metalearning,\ntitle={Meta-Learning Probabilistic Inference for Prediction},\nauthor={Jonathan Gordon and John Bronskill and Matthias Bauer and Sebastian Nowozin and Richard Turner},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=HkxStoC5F7},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper441/Public_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1542311839633, "tddate": null, "super": null, "final": null, "reply": {"signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed."}, "nonreaders": {"values": []}, "forum": "HkxStoC5F7", "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper441/Authors", "ICLR.cc/2019/Conference/Paper441/Reviewers", "ICLR.cc/2019/Conference/Paper441/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "replyto": null, "content": {"comment": {"value-regex": "[\\S\\s]{1,5000}", "required": true, "order": 1, "description": "Your comment or reply (max 5000 characters)."}, "title": {"value-regex": ".{1,500}", "required": true, "order": 0, "description": "Brief summary of your comment."}}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["~"], "noninvitees": ["ICLR.cc/2019/Conference/Paper441/Authors", "ICLR.cc/2019/Conference/Paper441/Reviewers", "ICLR.cc/2019/Conference/Paper441/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1542311839633}}}, {"id": "HyxBBF9MDB", "original": null, "number": 5, "cdate": 1569003837241, "ddate": null, "tcdate": 1569003837241, "tmdate": 1569003837241, "tddate": null, "forum": "HkxStoC5F7", "replyto": "SylVqUcGvr", "invitation": "ICLR.cc/2019/Conference/-/Paper441/Public_Comment", "content": {"comment": "The authors claimed state-of-the-art on MiniImageNet dataset excluding many works for different reasons like pre-training parts of the meta-learner (that doesn't have anything to do with the main goal which is learning from few shots in novel tasks of meta-test partition!). Even from the remaining works, although the accuracies are copied from the reported results of other papers in most cases, numbers from SNAIL paper are entered much lower than they have been published. ", "title": "Then how does it report state of the art?"}, "signatures": ["(anonymous)"], "readers": ["everyone"], "nonreaders": [], "writers": ["(anonymous)", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Meta-Learning Probabilistic Inference for Prediction", "abstract": "This paper introduces a new framework for data efficient and versatile learning. Specifically:\n1) We develop ML-PIP, a general framework for Meta-Learning approximate Probabilistic Inference for Prediction. ML-PIP extends existing probabilistic interpretations of meta-learning to cover a broad class of methods. \n2) We introduce \\Versa{}, an instance of the framework employing a flexible and versatile amortization network that takes few-shot learning datasets as inputs, with arbitrary numbers of shots, and outputs a distribution over task-specific parameters in a single forward pass. \\Versa{} substitutes optimization at test time with forward passes through inference networks, amortizing the cost of inference and relieving the need for second derivatives during training.\n3) We evaluate \\Versa{} on benchmark datasets where the method sets new state-of-the-art results, and can handle arbitrary number of shots, and for classification, arbitrary numbers of classes at train and test time. The power of the approach is then demonstrated through a challenging few-shot ShapeNet view reconstruction task.", "keywords": ["probabilistic models", "approximate inference", "few-shot learning", "meta-learning"], "authorids": ["jg801@cam.ac.uk", "jfb54@cam.ac.uk", "bauer@tue.mpg.de", "nowozin@google.com", "ret26@cam.ac.uk"], "authors": ["Jonathan Gordon", "John Bronskill", "Matthias Bauer", "Sebastian Nowozin", "Richard Turner"], "TL;DR": "Novel framework for meta-learning that unifies and extends a broad class of existing few-shot learning methods. Achieves strong performance on few-shot learning benchmarks without requiring iterative test-time inference.   ", "pdf": "/pdf/e9d0c9677cdf67034a920a123c97bfbea6e64d5b.pdf", "paperhash": "gordon|metalearning_probabilistic_inference_for_prediction", "_bibtex": "@inproceedings{\ngordon2018metalearning,\ntitle={Meta-Learning Probabilistic Inference for Prediction},\nauthor={Jonathan Gordon and John Bronskill and Matthias Bauer and Sebastian Nowozin and Richard Turner},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=HkxStoC5F7},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper441/Public_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1542311839633, "tddate": null, "super": null, "final": null, "reply": {"signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed."}, "nonreaders": {"values": []}, "forum": "HkxStoC5F7", "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper441/Authors", "ICLR.cc/2019/Conference/Paper441/Reviewers", "ICLR.cc/2019/Conference/Paper441/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "replyto": null, "content": {"comment": {"value-regex": "[\\S\\s]{1,5000}", "required": true, "order": 1, "description": "Your comment or reply (max 5000 characters)."}, "title": {"value-regex": ".{1,500}", "required": true, "order": 0, "description": "Brief summary of your comment."}}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["~"], "noninvitees": ["ICLR.cc/2019/Conference/Paper441/Authors", "ICLR.cc/2019/Conference/Paper441/Reviewers", "ICLR.cc/2019/Conference/Paper441/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1542311839633}}}, {"id": "HkxStoC5F7", "original": "B1xUcC9qYQ", "number": 441, "cdate": 1538087804846, "ddate": null, "tcdate": 1538087804846, "tmdate": 1550688003840, "tddate": null, "forum": "HkxStoC5F7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Meta-Learning Probabilistic Inference for Prediction", "abstract": "This paper introduces a new framework for data efficient and versatile learning. Specifically:\n1) We develop ML-PIP, a general framework for Meta-Learning approximate Probabilistic Inference for Prediction. ML-PIP extends existing probabilistic interpretations of meta-learning to cover a broad class of methods. \n2) We introduce \\Versa{}, an instance of the framework employing a flexible and versatile amortization network that takes few-shot learning datasets as inputs, with arbitrary numbers of shots, and outputs a distribution over task-specific parameters in a single forward pass. \\Versa{} substitutes optimization at test time with forward passes through inference networks, amortizing the cost of inference and relieving the need for second derivatives during training.\n3) We evaluate \\Versa{} on benchmark datasets where the method sets new state-of-the-art results, and can handle arbitrary number of shots, and for classification, arbitrary numbers of classes at train and test time. The power of the approach is then demonstrated through a challenging few-shot ShapeNet view reconstruction task.", "keywords": ["probabilistic models", "approximate inference", "few-shot learning", "meta-learning"], "authorids": ["jg801@cam.ac.uk", "jfb54@cam.ac.uk", "bauer@tue.mpg.de", "nowozin@google.com", "ret26@cam.ac.uk"], "authors": ["Jonathan Gordon", "John Bronskill", "Matthias Bauer", "Sebastian Nowozin", "Richard Turner"], "TL;DR": "Novel framework for meta-learning that unifies and extends a broad class of existing few-shot learning methods. Achieves strong performance on few-shot learning benchmarks without requiring iterative test-time inference.   ", "pdf": "/pdf/e9d0c9677cdf67034a920a123c97bfbea6e64d5b.pdf", "paperhash": "gordon|metalearning_probabilistic_inference_for_prediction", "_bibtex": "@inproceedings{\ngordon2018metalearning,\ntitle={Meta-Learning Probabilistic Inference for Prediction},\nauthor={Jonathan Gordon and John Bronskill and Matthias Bauer and Sebastian Nowozin and Richard Turner},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=HkxStoC5F7},\n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"replyCount": 17, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Blind_Submission", "rdate": null, "ddate": null, "expdate": null, "duedate": 1538085600000, "tmdate": 1538142958393, "tddate": null, "super": null, "final": null, "reply": {"signatures": {"values": ["ICLR.cc/2019/Conference"]}, "forum": null, "readers": {"values": ["everyone"]}, "replyto": null, "content": {"authorids": {"values-regex": ".*"}, "authors": {"values": ["Anonymous"]}}, "writers": {"values": ["ICLR.cc/2019/Conference"]}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["~"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": null, "taskCompletionCount": null, "transform": null, "cdate": 1538142958393}}, "tauthor": "OpenReview.net"}, {"id": "HJxOG3CxlV", "original": null, "number": 1, "cdate": 1544772624087, "ddate": null, "tcdate": 1544772624087, "tmdate": 1545354522024, "tddate": null, "forum": "HkxStoC5F7", "replyto": "HkxStoC5F7", "invitation": "ICLR.cc/2019/Conference/-/Paper441/Meta_Review", "content": {"metareview": "The paper proposes a decision-theoretic framework for meta-learning. The ideas and analysis are interesting and well-motivated, and the experiments are thorough. The primary concerns of the reviewers have been addressed in new revisions of the paper. The reviewers all agree that the paper should be accepted. Hence, I recommend acceptance.", "confidence": "5: The area chair is absolutely certain", "recommendation": "Accept (Poster)", "title": "meta review"}, "signatures": ["ICLR.cc/2019/Conference/Paper441/Area_Chair1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference/Paper441/Area_Chair1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Meta-Learning Probabilistic Inference for Prediction", "abstract": "This paper introduces a new framework for data efficient and versatile learning. Specifically:\n1) We develop ML-PIP, a general framework for Meta-Learning approximate Probabilistic Inference for Prediction. ML-PIP extends existing probabilistic interpretations of meta-learning to cover a broad class of methods. \n2) We introduce \\Versa{}, an instance of the framework employing a flexible and versatile amortization network that takes few-shot learning datasets as inputs, with arbitrary numbers of shots, and outputs a distribution over task-specific parameters in a single forward pass. \\Versa{} substitutes optimization at test time with forward passes through inference networks, amortizing the cost of inference and relieving the need for second derivatives during training.\n3) We evaluate \\Versa{} on benchmark datasets where the method sets new state-of-the-art results, and can handle arbitrary number of shots, and for classification, arbitrary numbers of classes at train and test time. The power of the approach is then demonstrated through a challenging few-shot ShapeNet view reconstruction task.", "keywords": ["probabilistic models", "approximate inference", "few-shot learning", "meta-learning"], "authorids": ["jg801@cam.ac.uk", "jfb54@cam.ac.uk", "bauer@tue.mpg.de", "nowozin@google.com", "ret26@cam.ac.uk"], "authors": ["Jonathan Gordon", "John Bronskill", "Matthias Bauer", "Sebastian Nowozin", "Richard Turner"], "TL;DR": "Novel framework for meta-learning that unifies and extends a broad class of existing few-shot learning methods. Achieves strong performance on few-shot learning benchmarks without requiring iterative test-time inference.   ", "pdf": "/pdf/e9d0c9677cdf67034a920a123c97bfbea6e64d5b.pdf", "paperhash": "gordon|metalearning_probabilistic_inference_for_prediction", "_bibtex": "@inproceedings{\ngordon2018metalearning,\ntitle={Meta-Learning Probabilistic Inference for Prediction},\nauthor={Jonathan Gordon and John Bronskill and Matthias Bauer and Sebastian Nowozin and Richard Turner},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=HkxStoC5F7},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper441/Meta_Review", "rdate": null, "ddate": null, "expdate": null, "duedate": 1541548800000, "tmdate": 1545353215382, "tddate": null, "super": null, "final": null, "reply": {"forum": "HkxStoC5F7", "replyto": "HkxStoC5F7", "readers": {"description": "Select all user groups that should be able to read this comment. Selecting 'All Users' will allow paper authors, reviewers, area chairs, and program chairs to view this comment.", "values": ["everyone"]}, "signatures": {"description": "How your identity will be displayed with the above content.", "values-regex": "ICLR.cc/2019/Conference/Paper441/Area_Chair[0-9]+"}, "writers": {"description": "Users that may modify this record.", "values-regex": "ICLR.cc/2019/Conference/Paper441/Area_Chair[0-9]+"}, "content": {"title": {"order": 1, "value-regex": ".{1,500}", "description": "Brief summary of your review.", "required": true}, "metareview": {"order": 2, "value-regex": "[\\S\\s]{1,5000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "required": true}, "recommendation": {"order": 3, "value-dropdown": ["Accept (Oral)", "Accept (Poster)", "Reject"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The area chair is absolutely certain", "4: The area chair is confident but not absolutely certain", "3: The area chair is somewhat confident", "2: The area chair is not sure", "1: The area chair's evaluation is an educated guess"], "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper441/Area_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": false, "taskCompletionCount": null, "transform": null, "cdate": 1545353215382}}}, {"id": "H1ghXV0kgN", "original": null, "number": 7, "cdate": 1544705059991, "ddate": null, "tcdate": 1544705059991, "tmdate": 1544705059991, "tddate": null, "forum": "HkxStoC5F7", "replyto": "ByldnORAJV", "invitation": "ICLR.cc/2019/Conference/-/Paper441/Official_Comment", "content": {"title": "Numbers using prototypical networks matched training protocol", "comment": "Thanks for the follow up questions.\n\nThe experiments with 1 task per batch yield the following result on 5-way 5-shot learning with Versa: (66.75 + / - 0.9)%. This is within the error bars of the current numbers in the paper, and above Prototypical networks trained and tested on 5-way (65.77 + / - 0.7)%. Further, this result was achieved quickly in response to this discussion without any tuning of the optimization hyper-parameters (learning rate etc.) to this new setting. Based on past experience with Versa, we are confident that this performance can be further improved. \n\nWe will similarly investigate the performance in the 1-shot setting, and report final numbers for the next iteration of the paper. We would be happy to include the numbers achieved with both Versa training procedures above, as well as the numbers achieved by both training procedures achieved by Proto-nets in Table 3, along with a thorough discussion about the differences induced between the two procedures in the case of Versa and Prototypical networks.\n\nWe do disagree with your statement that the two settings (5-way classification with 4 tasks per batch and 20-way classification) are the same. A 20-way classification task is not equivalent to four 5-way classification tasks, namely in the independence assumptions induced over the predictive distributions by the different normalizing constants. This is consistent with the fact that, in contradiction to what your claims would imply, Versa's performance on the meta-test set is not impacted by reducing the number of tasks per batch, while prototypical networks significantly benefits from higher-way training. \n\nFinally, several members of our team are away (or are about to depart) for the holidays. So, whilst we're very happy to discuss these matters further, we will only be able to do so after the Christmas break. We would be very happy for you to reach out to us directly at this time so that we can continue discussion in a more direct way with a quicker response time. Thank you again for your input, and happy holidays."}, "signatures": ["ICLR.cc/2019/Conference/Paper441/Authors"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper441/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper441/Authors", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Meta-Learning Probabilistic Inference for Prediction", "abstract": "This paper introduces a new framework for data efficient and versatile learning. Specifically:\n1) We develop ML-PIP, a general framework for Meta-Learning approximate Probabilistic Inference for Prediction. ML-PIP extends existing probabilistic interpretations of meta-learning to cover a broad class of methods. \n2) We introduce \\Versa{}, an instance of the framework employing a flexible and versatile amortization network that takes few-shot learning datasets as inputs, with arbitrary numbers of shots, and outputs a distribution over task-specific parameters in a single forward pass. \\Versa{} substitutes optimization at test time with forward passes through inference networks, amortizing the cost of inference and relieving the need for second derivatives during training.\n3) We evaluate \\Versa{} on benchmark datasets where the method sets new state-of-the-art results, and can handle arbitrary number of shots, and for classification, arbitrary numbers of classes at train and test time. The power of the approach is then demonstrated through a challenging few-shot ShapeNet view reconstruction task.", "keywords": ["probabilistic models", "approximate inference", "few-shot learning", "meta-learning"], "authorids": ["jg801@cam.ac.uk", "jfb54@cam.ac.uk", "bauer@tue.mpg.de", "nowozin@google.com", "ret26@cam.ac.uk"], "authors": ["Jonathan Gordon", "John Bronskill", "Matthias Bauer", "Sebastian Nowozin", "Richard Turner"], "TL;DR": "Novel framework for meta-learning that unifies and extends a broad class of existing few-shot learning methods. Achieves strong performance on few-shot learning benchmarks without requiring iterative test-time inference.   ", "pdf": "/pdf/e9d0c9677cdf67034a920a123c97bfbea6e64d5b.pdf", "paperhash": "gordon|metalearning_probabilistic_inference_for_prediction", "_bibtex": "@inproceedings{\ngordon2018metalearning,\ntitle={Meta-Learning Probabilistic Inference for Prediction},\nauthor={Jonathan Gordon and John Bronskill and Matthias Bauer and Sebastian Nowozin and Richard Turner},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=HkxStoC5F7},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper441/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621620899, "tddate": null, "super": null, "final": null, "reply": {"forum": "HkxStoC5F7", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper441/Authors", "ICLR.cc/2019/Conference/Paper441/Reviewers", "ICLR.cc/2019/Conference/Paper441/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper441/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper441/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper441/Authors|ICLR.cc/2019/Conference/Paper441/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper441/Reviewers", "ICLR.cc/2019/Conference/Paper441/Authors", "ICLR.cc/2019/Conference/Paper441/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621620899}}}, {"id": "ByldnORAJV", "original": null, "number": 3, "cdate": 1544640687792, "ddate": null, "tcdate": 1544640687792, "tmdate": 1544640932886, "tddate": null, "forum": "HkxStoC5F7", "replyto": "SygBAooCkE", "invitation": "ICLR.cc/2019/Conference/-/Paper441/Public_Comment", "content": {"comment": "Thank you for your detailed replies.\n\nFirst of all, please, provide the numbers. There are a lot of phrases like \"within error bars\", \"no substantial effect\". Please, be specific. While your model with 1 task per meta-batch might be within the error bars of your current submission, it might no longer be within the error-bars of current SOTA results on some of the benchmarks. \n\nMatching to MAML protocol is understandable, however, the Prototypical Networks are trained using a single episode (=single task per meta-batch) per shared model update. If you insist on your current training protocol, the Prototypical Networks need to be trained using the same number of episodes per single task-specific (in fact shared!) update as you use. You need to truly match Prototypical Networks protocol to the one you and MAML use. Otherwise report your numbers with a single task per meta-batch protocol, whether they are within the error-bars of your current submission or not. \n\nIt certainly makes sense to take into consideration the number of query samples used for a single task-specific model (in fact HEAVILY shared across different tasks). The more query samples you use, the more regularised is the training of the shared feature extractor that both VERSA and Prototypical Nets utilise. You use from 15 * 20 to 15 * 40 samples for miniImageNet while the Prototypical Nets from your table only use 15 * 5. This is the advantage you give yourself by comparing your multitask-per-meta-batch protocol to the single-task-per-meta-batch protocol in Prototypical Networks.\n\nIn addition to that, if we are talking about using truly comparable settings for all models, similarly to MAML and the Prototypical Nets, your feature extractor should consist of 4 convolutional blocks for miniImageNet dataset, not 5, and the number of features better also be similar.  I understand that this might not change the relative positions, however, it should be interesting to see what would be the margin between the results in this case. This would help to evaluate the advantage of using additional network compared to the Prototypical Nets.\n\nAnother approach would be to ignore all those minor differences in the setups and objectives and use acknowledged peer-reviewed best results for all models and try to make your model as good as possible. While it is good to have an additional table that compares the models in the almost exact settings, different models might benefit from different tricks, so these tricks should not be ignored in final assessment of the model. Absence of the best result by the Prototypical Networks together with your claims about setting SOTA is certainly misleading. It is your job to demonstrate the best potential of your model, so there needs to be a comparison to the Prototypical Networks at their best, even if it requires using additional protocol (even though I still consider your protocol to be interpretable within the protocol of the Prototypical Nets, you repeated my explanation with your own words confirming the the difference is only in the objective). The lack of a valid comparison is certainly a drawback.\n\nIf one discovers they can use some valid trick to improve the results of their model, they should not avoid using it. The Prototypical Networks are learning a more complicated task during the training stage than any of the other models in the table while using the same amount of data, and they should not be punished for that. It is not that the size of their model was drastically different (in fact, it is the smallest since they only use the same feature extractor as you and MAML do) or that the quality of their model was increasing linearly with the larger number of the classes used during the training. There is a trade-off, they explored it and used for regularising their model, in the same way other people use different architectures or objectives.", "title": "I'm still not convinced at all. Matter of wordings and formalities."}, "signatures": ["(anonymous)"], "readers": ["everyone"], "nonreaders": [], "writers": ["(anonymous)", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Meta-Learning Probabilistic Inference for Prediction", "abstract": "This paper introduces a new framework for data efficient and versatile learning. Specifically:\n1) We develop ML-PIP, a general framework for Meta-Learning approximate Probabilistic Inference for Prediction. ML-PIP extends existing probabilistic interpretations of meta-learning to cover a broad class of methods. \n2) We introduce \\Versa{}, an instance of the framework employing a flexible and versatile amortization network that takes few-shot learning datasets as inputs, with arbitrary numbers of shots, and outputs a distribution over task-specific parameters in a single forward pass. \\Versa{} substitutes optimization at test time with forward passes through inference networks, amortizing the cost of inference and relieving the need for second derivatives during training.\n3) We evaluate \\Versa{} on benchmark datasets where the method sets new state-of-the-art results, and can handle arbitrary number of shots, and for classification, arbitrary numbers of classes at train and test time. The power of the approach is then demonstrated through a challenging few-shot ShapeNet view reconstruction task.", "keywords": ["probabilistic models", "approximate inference", "few-shot learning", "meta-learning"], "authorids": ["jg801@cam.ac.uk", "jfb54@cam.ac.uk", "bauer@tue.mpg.de", "nowozin@google.com", "ret26@cam.ac.uk"], "authors": ["Jonathan Gordon", "John Bronskill", "Matthias Bauer", "Sebastian Nowozin", "Richard Turner"], "TL;DR": "Novel framework for meta-learning that unifies and extends a broad class of existing few-shot learning methods. Achieves strong performance on few-shot learning benchmarks without requiring iterative test-time inference.   ", "pdf": "/pdf/e9d0c9677cdf67034a920a123c97bfbea6e64d5b.pdf", "paperhash": "gordon|metalearning_probabilistic_inference_for_prediction", "_bibtex": "@inproceedings{\ngordon2018metalearning,\ntitle={Meta-Learning Probabilistic Inference for Prediction},\nauthor={Jonathan Gordon and John Bronskill and Matthias Bauer and Sebastian Nowozin and Richard Turner},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=HkxStoC5F7},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper441/Public_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1542311839633, "tddate": null, "super": null, "final": null, "reply": {"signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed."}, "nonreaders": {"values": []}, "forum": "HkxStoC5F7", "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper441/Authors", "ICLR.cc/2019/Conference/Paper441/Reviewers", "ICLR.cc/2019/Conference/Paper441/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "replyto": null, "content": {"comment": {"value-regex": "[\\S\\s]{1,5000}", "required": true, "order": 1, "description": "Your comment or reply (max 5000 characters)."}, "title": {"value-regex": ".{1,500}", "required": true, "order": 0, "description": "Brief summary of your comment."}}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["~"], "noninvitees": ["ICLR.cc/2019/Conference/Paper441/Authors", "ICLR.cc/2019/Conference/Paper441/Reviewers", "ICLR.cc/2019/Conference/Paper441/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1542311839633}}}, {"id": "SygBAooCkE", "original": null, "number": 6, "cdate": 1544629196603, "ddate": null, "tcdate": 1544629196603, "tmdate": 1544629196603, "tddate": null, "forum": "HkxStoC5F7", "replyto": "B1gDhDl0y4", "invitation": "ICLR.cc/2019/Conference/-/Paper441/Official_Comment", "content": {"title": "Yes, the comparison is fair for the following reasons.", "comment": "Thanks for the follow up question!\n \nExisting comparisons:\n- As is shown in Section 4, prototypical networks is a special case of Versa, allowing for a direct comparison of the two when the training procedure is equivalent.\n- Our training procedure (and that of other methods presented in Table 3) is equivalent to the \"matched training condition\" in prototypical nets (i.e., train and test \"way\" are the same).\n- Experimental protocols (and in particular, makeup of the mini-batches) were found not to have a substantial effect on the performance of Versa. The experimental protocols described in the paper (number of tasks per batch, size of test sets, etc') closely follow that of MAML. See below for more details.\n- For example, we ran Versa with a meta-training batch of 1 (directly equivalent to the prototypical network setup), and found the final accuracy is within error-bars of the result of the submission, and still above the errors bars of prototypical networks trained and tested on 5-way.\n- We therefore consider the comparisons presented to be direct and fair.\n\nComparisons using higher way training\n- We have not investigated the effects of training with a higher way than testing.\n- This changes the objective function due to the normalisation constant in the softmax e.g. this would have a single normaliser for all 20 classes if considered together, versus separate ones for each of the tasks if the classes were split into 4 tasks of 5 classes each.\n- This is the key difference between these two training conditions and is not something Versa currently exploits.\n- We agree that it would be interesting to test whether using this modified objective improved Versa and indeed whether the same idea could lead to improvements in other methods too.\n\nMore details on the training protocol\n- For both Omniglot and miniImageNet, experiments demonstrated that the performance of Versa on the meta-test set is not sensitive to the number of tasks per batch during training.\n- As such, the experimental protocol (number of tasks per batch and the number of query points per batch) for both miniImageNet and Omniglot were chosen to match the MAML protocol.\n- We also ran the experiments with meta-training batch of size 1, which is directly equivalent to the prototypical network setup. \n- The performance in these experiments was very similar to our best results (within error bars), and significantly better than what is reported by prototypical nets for the same setup.\n- In summary the final performance was not found to be particularly sensitive to these choices.\n- Arguably, this is to be expected as this is equivalent to selecting the size of the mini-batch in conventional learning. In particular, our model makes an independence assumption across tasks (given \\theta).\n- As prototypical networks are a special case of Versa (with the amortization network set to identity around the mean encoding), we expect similar findings to hold for this model."}, "signatures": ["ICLR.cc/2019/Conference/Paper441/Authors"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper441/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper441/Authors", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Meta-Learning Probabilistic Inference for Prediction", "abstract": "This paper introduces a new framework for data efficient and versatile learning. Specifically:\n1) We develop ML-PIP, a general framework for Meta-Learning approximate Probabilistic Inference for Prediction. ML-PIP extends existing probabilistic interpretations of meta-learning to cover a broad class of methods. \n2) We introduce \\Versa{}, an instance of the framework employing a flexible and versatile amortization network that takes few-shot learning datasets as inputs, with arbitrary numbers of shots, and outputs a distribution over task-specific parameters in a single forward pass. \\Versa{} substitutes optimization at test time with forward passes through inference networks, amortizing the cost of inference and relieving the need for second derivatives during training.\n3) We evaluate \\Versa{} on benchmark datasets where the method sets new state-of-the-art results, and can handle arbitrary number of shots, and for classification, arbitrary numbers of classes at train and test time. The power of the approach is then demonstrated through a challenging few-shot ShapeNet view reconstruction task.", "keywords": ["probabilistic models", "approximate inference", "few-shot learning", "meta-learning"], "authorids": ["jg801@cam.ac.uk", "jfb54@cam.ac.uk", "bauer@tue.mpg.de", "nowozin@google.com", "ret26@cam.ac.uk"], "authors": ["Jonathan Gordon", "John Bronskill", "Matthias Bauer", "Sebastian Nowozin", "Richard Turner"], "TL;DR": "Novel framework for meta-learning that unifies and extends a broad class of existing few-shot learning methods. Achieves strong performance on few-shot learning benchmarks without requiring iterative test-time inference.   ", "pdf": "/pdf/e9d0c9677cdf67034a920a123c97bfbea6e64d5b.pdf", "paperhash": "gordon|metalearning_probabilistic_inference_for_prediction", "_bibtex": "@inproceedings{\ngordon2018metalearning,\ntitle={Meta-Learning Probabilistic Inference for Prediction},\nauthor={Jonathan Gordon and John Bronskill and Matthias Bauer and Sebastian Nowozin and Richard Turner},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=HkxStoC5F7},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper441/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621620899, "tddate": null, "super": null, "final": null, "reply": {"forum": "HkxStoC5F7", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper441/Authors", "ICLR.cc/2019/Conference/Paper441/Reviewers", "ICLR.cc/2019/Conference/Paper441/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper441/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper441/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper441/Authors|ICLR.cc/2019/Conference/Paper441/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper441/Reviewers", "ICLR.cc/2019/Conference/Paper441/Authors", "ICLR.cc/2019/Conference/Paper441/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621620899}}}, {"id": "B1gDhDl0y4", "original": null, "number": 2, "cdate": 1544583087351, "ddate": null, "tcdate": 1544583087351, "tmdate": 1544583452586, "tddate": null, "forum": "HkxStoC5F7", "replyto": "HyxhLmE6JN", "invitation": "ICLR.cc/2019/Conference/-/Paper441/Public_Comment", "content": {"comment": "In your submission it is stated that during training you used 16 tasks per batch for all four Omniglot setups, 4 tasks per batch for 5-shot 5-way task on miniImageNet and 8 tasks per batch for 1-shot 5-way task on miniImageNet. Technically, if we take a look at the features right before the softmax, due to the context independence assumption between the posteriors of different classes there is no difference between running four parallel 5-way tasks and one 20-way task, as long as you don't update the weights while running these four tasks. So your learning procedure can be viewed as a 20-way classification with masked softmax. From this point of view it seems that the Prototypical Networks try to learn a more complicated 20-way task during the training stage while your model is trained on a \"simplified and masked\" 5-way task while having access to the same 20 classes (in the 5-way 5-shot miniImagenet setup, and it has access to a much larger number of classes and total number of query samples in all the other setups, more query samples that the Prototypical Networks have access to during a single update of the fully shared model). The difference is only in the losses, and it is okay (I guess?) to have different losses (your way of computing losses can be viewed as a particular, masked instance of their way). It seems that if we are talking about truly fair comparison to the results by Prototypical Networks that you mention in your current version of the paper, your model should be trained with a single task per meta-batch, at least so that the number of query samples used for a single model update was comparable (now it is 15 * 5 for Prototypical Networks and 15 * 20 for 5-way 5-shot and 15 * 40 for 5-way 1-shot VERSA models on miniImageNet), otherwise it is also not fair.\n\nFinally, there is a difference between the claims \"within the error bars for all standard benchmarks\" and \"sets new SOTA results by a certain margin over the pervious best\".", "title": "Question regarding your protocol: is your current comparison really fair?"}, "signatures": ["(anonymous)"], "readers": ["everyone"], "nonreaders": [], "writers": ["(anonymous)", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Meta-Learning Probabilistic Inference for Prediction", "abstract": "This paper introduces a new framework for data efficient and versatile learning. Specifically:\n1) We develop ML-PIP, a general framework for Meta-Learning approximate Probabilistic Inference for Prediction. ML-PIP extends existing probabilistic interpretations of meta-learning to cover a broad class of methods. \n2) We introduce \\Versa{}, an instance of the framework employing a flexible and versatile amortization network that takes few-shot learning datasets as inputs, with arbitrary numbers of shots, and outputs a distribution over task-specific parameters in a single forward pass. \\Versa{} substitutes optimization at test time with forward passes through inference networks, amortizing the cost of inference and relieving the need for second derivatives during training.\n3) We evaluate \\Versa{} on benchmark datasets where the method sets new state-of-the-art results, and can handle arbitrary number of shots, and for classification, arbitrary numbers of classes at train and test time. The power of the approach is then demonstrated through a challenging few-shot ShapeNet view reconstruction task.", "keywords": ["probabilistic models", "approximate inference", "few-shot learning", "meta-learning"], "authorids": ["jg801@cam.ac.uk", "jfb54@cam.ac.uk", "bauer@tue.mpg.de", "nowozin@google.com", "ret26@cam.ac.uk"], "authors": ["Jonathan Gordon", "John Bronskill", "Matthias Bauer", "Sebastian Nowozin", "Richard Turner"], "TL;DR": "Novel framework for meta-learning that unifies and extends a broad class of existing few-shot learning methods. Achieves strong performance on few-shot learning benchmarks without requiring iterative test-time inference.   ", "pdf": "/pdf/e9d0c9677cdf67034a920a123c97bfbea6e64d5b.pdf", "paperhash": "gordon|metalearning_probabilistic_inference_for_prediction", "_bibtex": "@inproceedings{\ngordon2018metalearning,\ntitle={Meta-Learning Probabilistic Inference for Prediction},\nauthor={Jonathan Gordon and John Bronskill and Matthias Bauer and Sebastian Nowozin and Richard Turner},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=HkxStoC5F7},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper441/Public_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1542311839633, "tddate": null, "super": null, "final": null, "reply": {"signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed."}, "nonreaders": {"values": []}, "forum": "HkxStoC5F7", "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper441/Authors", "ICLR.cc/2019/Conference/Paper441/Reviewers", "ICLR.cc/2019/Conference/Paper441/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "replyto": null, "content": {"comment": {"value-regex": "[\\S\\s]{1,5000}", "required": true, "order": 1, "description": "Your comment or reply (max 5000 characters)."}, "title": {"value-regex": ".{1,500}", "required": true, "order": 0, "description": "Brief summary of your comment."}}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["~"], "noninvitees": ["ICLR.cc/2019/Conference/Paper441/Authors", "ICLR.cc/2019/Conference/Paper441/Reviewers", "ICLR.cc/2019/Conference/Paper441/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1542311839633}}}, {"id": "HyxhLmE6JN", "original": null, "number": 5, "cdate": 1544532820021, "ddate": null, "tcdate": 1544532820021, "tmdate": 1544532847328, "tddate": null, "forum": "HkxStoC5F7", "replyto": "r1eb9eOnyN", "invitation": "ICLR.cc/2019/Conference/-/Paper441/Official_Comment", "content": {"title": "Prototypical Nets propose several experimental protocols", "comment": "Thank you for your question!\n\nThe prototypical networks paper proposes a number of different experimental protocols. One of these protocols trains on higher \"way\" than what is ultimately used for testing. This is detailed in table 5 in Appendix B of the prototypical networks paper. There you will see that the number you are quoting is achieved by training the system to perform 20 way classification, and then testing it on 5 way classification (final row of the table). This experimental protocol differs from that used by all other methods. When matching experimental protocols are used, i.e., training and testing on 5-way classification, prototypical networks achieve the numbers we quote in our ICLR submission (row 10 of their table). \n\nThe discrepancy between the experimental protocols was pointed out to us by readers of the arxiv version of our paper who suggested reporting numbers from the same experimental protocol. Hence the differing numbers between this submission and the arxiv version. You are correct in pointing out that in the unconstrained setting prototypical networks achieve better performance, but we are of the opinion that a fairer comparison is made when all methods use the same experimental protocol. The note in our submission saying \"The tables include results for only those approaches with comparable training procedures ...\" was intended to clarify this, but we will clarify this more explicitly in the final version if it is accepted. \n\nFinally, note that even the improved prototypical networks number (68.20 \u00b1 0.66%) is within error bars of the Versa number (67.37 \u00b1 0.86%)."}, "signatures": ["ICLR.cc/2019/Conference/Paper441/Authors"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper441/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper441/Authors", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Meta-Learning Probabilistic Inference for Prediction", "abstract": "This paper introduces a new framework for data efficient and versatile learning. Specifically:\n1) We develop ML-PIP, a general framework for Meta-Learning approximate Probabilistic Inference for Prediction. ML-PIP extends existing probabilistic interpretations of meta-learning to cover a broad class of methods. \n2) We introduce \\Versa{}, an instance of the framework employing a flexible and versatile amortization network that takes few-shot learning datasets as inputs, with arbitrary numbers of shots, and outputs a distribution over task-specific parameters in a single forward pass. \\Versa{} substitutes optimization at test time with forward passes through inference networks, amortizing the cost of inference and relieving the need for second derivatives during training.\n3) We evaluate \\Versa{} on benchmark datasets where the method sets new state-of-the-art results, and can handle arbitrary number of shots, and for classification, arbitrary numbers of classes at train and test time. The power of the approach is then demonstrated through a challenging few-shot ShapeNet view reconstruction task.", "keywords": ["probabilistic models", "approximate inference", "few-shot learning", "meta-learning"], "authorids": ["jg801@cam.ac.uk", "jfb54@cam.ac.uk", "bauer@tue.mpg.de", "nowozin@google.com", "ret26@cam.ac.uk"], "authors": ["Jonathan Gordon", "John Bronskill", "Matthias Bauer", "Sebastian Nowozin", "Richard Turner"], "TL;DR": "Novel framework for meta-learning that unifies and extends a broad class of existing few-shot learning methods. Achieves strong performance on few-shot learning benchmarks without requiring iterative test-time inference.   ", "pdf": "/pdf/e9d0c9677cdf67034a920a123c97bfbea6e64d5b.pdf", "paperhash": "gordon|metalearning_probabilistic_inference_for_prediction", "_bibtex": "@inproceedings{\ngordon2018metalearning,\ntitle={Meta-Learning Probabilistic Inference for Prediction},\nauthor={Jonathan Gordon and John Bronskill and Matthias Bauer and Sebastian Nowozin and Richard Turner},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=HkxStoC5F7},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper441/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621620899, "tddate": null, "super": null, "final": null, "reply": {"forum": "HkxStoC5F7", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper441/Authors", "ICLR.cc/2019/Conference/Paper441/Reviewers", "ICLR.cc/2019/Conference/Paper441/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper441/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper441/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper441/Authors|ICLR.cc/2019/Conference/Paper441/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper441/Reviewers", "ICLR.cc/2019/Conference/Paper441/Authors", "ICLR.cc/2019/Conference/Paper441/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621620899}}}, {"id": "r1eb9eOnyN", "original": null, "number": 1, "cdate": 1544482952823, "ddate": null, "tcdate": 1544482952823, "tmdate": 1544482952823, "tddate": null, "forum": "HkxStoC5F7", "replyto": "HkxStoC5F7", "invitation": "ICLR.cc/2019/Conference/-/Paper441/Public_Comment", "content": {"comment": "Could you please comment on why the results of Prototypical Nets mentioned in Table 3 of your submission are different (lower) from those reported by the authors of the model in their paper [1]? Especially this concerns the 5-shot 5-way miniImageNet setup where their result is 68,20 +/- 0.66% which contradicts your claim of getting state-of-the-art results on any of the standard few-shot learning benchmarks. This is especially strange since the arxiv version of your paper includes the correct numbers. Thank you in advance for your answer.\n\n[1] - Snell, Jake, Kevin Swersky, and Richard Zemel. Prototypical networks for few-shot learning. Advances in Neural Information Processing Systems. 2017.", "title": "Incorrect results of Prototypical Nets in Table 3?"}, "signatures": ["(anonymous)"], "readers": ["everyone"], "nonreaders": [], "writers": ["(anonymous)", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Meta-Learning Probabilistic Inference for Prediction", "abstract": "This paper introduces a new framework for data efficient and versatile learning. Specifically:\n1) We develop ML-PIP, a general framework for Meta-Learning approximate Probabilistic Inference for Prediction. ML-PIP extends existing probabilistic interpretations of meta-learning to cover a broad class of methods. \n2) We introduce \\Versa{}, an instance of the framework employing a flexible and versatile amortization network that takes few-shot learning datasets as inputs, with arbitrary numbers of shots, and outputs a distribution over task-specific parameters in a single forward pass. \\Versa{} substitutes optimization at test time with forward passes through inference networks, amortizing the cost of inference and relieving the need for second derivatives during training.\n3) We evaluate \\Versa{} on benchmark datasets where the method sets new state-of-the-art results, and can handle arbitrary number of shots, and for classification, arbitrary numbers of classes at train and test time. The power of the approach is then demonstrated through a challenging few-shot ShapeNet view reconstruction task.", "keywords": ["probabilistic models", "approximate inference", "few-shot learning", "meta-learning"], "authorids": ["jg801@cam.ac.uk", "jfb54@cam.ac.uk", "bauer@tue.mpg.de", "nowozin@google.com", "ret26@cam.ac.uk"], "authors": ["Jonathan Gordon", "John Bronskill", "Matthias Bauer", "Sebastian Nowozin", "Richard Turner"], "TL;DR": "Novel framework for meta-learning that unifies and extends a broad class of existing few-shot learning methods. Achieves strong performance on few-shot learning benchmarks without requiring iterative test-time inference.   ", "pdf": "/pdf/e9d0c9677cdf67034a920a123c97bfbea6e64d5b.pdf", "paperhash": "gordon|metalearning_probabilistic_inference_for_prediction", "_bibtex": "@inproceedings{\ngordon2018metalearning,\ntitle={Meta-Learning Probabilistic Inference for Prediction},\nauthor={Jonathan Gordon and John Bronskill and Matthias Bauer and Sebastian Nowozin and Richard Turner},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=HkxStoC5F7},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper441/Public_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1542311839633, "tddate": null, "super": null, "final": null, "reply": {"signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed."}, "nonreaders": {"values": []}, "forum": "HkxStoC5F7", "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper441/Authors", "ICLR.cc/2019/Conference/Paper441/Reviewers", "ICLR.cc/2019/Conference/Paper441/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "replyto": null, "content": {"comment": {"value-regex": "[\\S\\s]{1,5000}", "required": true, "order": 1, "description": "Your comment or reply (max 5000 characters)."}, "title": {"value-regex": ".{1,500}", "required": true, "order": 0, "description": "Brief summary of your comment."}}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["~"], "noninvitees": ["ICLR.cc/2019/Conference/Paper441/Authors", "ICLR.cc/2019/Conference/Paper441/Reviewers", "ICLR.cc/2019/Conference/Paper441/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1542311839633}}}, {"id": "rJe6s67O6m", "original": null, "number": 1, "cdate": 1542106533464, "ddate": null, "tcdate": 1542106533464, "tmdate": 1542106945917, "tddate": null, "forum": "HkxStoC5F7", "replyto": "HkxStoC5F7", "invitation": "ICLR.cc/2019/Conference/-/Paper441/Official_Comment", "content": {"title": "Thank you for your reviews and comments", "comment": "Dear Reviewers,\n\nMany thanks for your detailed comments and suggestions. We really appreciate the time and effort you have put into reading our paper. Your comments are both insightful and constructive, and we believe have contributed to improving the quality of our paper.\n\nWe have uploaded a revised version of the paper, incorporating your comments and suggestions. Below, we address each of your reviews individually.\n"}, "signatures": ["ICLR.cc/2019/Conference/Paper441/Authors"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper441/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper441/Authors", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Meta-Learning Probabilistic Inference for Prediction", "abstract": "This paper introduces a new framework for data efficient and versatile learning. Specifically:\n1) We develop ML-PIP, a general framework for Meta-Learning approximate Probabilistic Inference for Prediction. ML-PIP extends existing probabilistic interpretations of meta-learning to cover a broad class of methods. \n2) We introduce \\Versa{}, an instance of the framework employing a flexible and versatile amortization network that takes few-shot learning datasets as inputs, with arbitrary numbers of shots, and outputs a distribution over task-specific parameters in a single forward pass. \\Versa{} substitutes optimization at test time with forward passes through inference networks, amortizing the cost of inference and relieving the need for second derivatives during training.\n3) We evaluate \\Versa{} on benchmark datasets where the method sets new state-of-the-art results, and can handle arbitrary number of shots, and for classification, arbitrary numbers of classes at train and test time. The power of the approach is then demonstrated through a challenging few-shot ShapeNet view reconstruction task.", "keywords": ["probabilistic models", "approximate inference", "few-shot learning", "meta-learning"], "authorids": ["jg801@cam.ac.uk", "jfb54@cam.ac.uk", "bauer@tue.mpg.de", "nowozin@google.com", "ret26@cam.ac.uk"], "authors": ["Jonathan Gordon", "John Bronskill", "Matthias Bauer", "Sebastian Nowozin", "Richard Turner"], "TL;DR": "Novel framework for meta-learning that unifies and extends a broad class of existing few-shot learning methods. Achieves strong performance on few-shot learning benchmarks without requiring iterative test-time inference.   ", "pdf": "/pdf/e9d0c9677cdf67034a920a123c97bfbea6e64d5b.pdf", "paperhash": "gordon|metalearning_probabilistic_inference_for_prediction", "_bibtex": "@inproceedings{\ngordon2018metalearning,\ntitle={Meta-Learning Probabilistic Inference for Prediction},\nauthor={Jonathan Gordon and John Bronskill and Matthias Bauer and Sebastian Nowozin and Richard Turner},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=HkxStoC5F7},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper441/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621620899, "tddate": null, "super": null, "final": null, "reply": {"forum": "HkxStoC5F7", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper441/Authors", "ICLR.cc/2019/Conference/Paper441/Reviewers", "ICLR.cc/2019/Conference/Paper441/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper441/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper441/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper441/Authors|ICLR.cc/2019/Conference/Paper441/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper441/Reviewers", "ICLR.cc/2019/Conference/Paper441/Authors", "ICLR.cc/2019/Conference/Paper441/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621620899}}}, {"id": "r1xx7y4dTQ", "original": null, "number": 4, "cdate": 1542106904497, "ddate": null, "tcdate": 1542106904497, "tmdate": 1542106904497, "tddate": null, "forum": "HkxStoC5F7", "replyto": "r1llzOxFhX", "invitation": "ICLR.cc/2019/Conference/-/Paper441/Official_Comment", "content": {"title": "On justification for the context-indepence assumption", "comment": "\u201cThe important aspect of the algorithm is the context independence assumption between posteriors of different classes for learning weights. \u2026 The idea sounds great, but I am skeptical of the justification behind the independence assumption which, as per its justifications sounds contrived and only empirical.\u201d\n\nWe thank the reviewer for imploring us to think more carefully about this point. We share the concern that providing only an empirical justification for the context independent assumption is slightly troubling. We have therefore considered this more carefully, and have found that there is a principled justification of this design choice, which is best understood through the lens of density ratio estimation [i, ii]. \n\nResults from Density Ratio Estimation [i, ii] show that an optimal softmax classifier learns the ratio of the densities\n\n    Softmax(y=k | x) = p(x | y=k) / Sum_j p(x | y=j)\n\nassuming equal a priori probability for each class. Our system follows his optimal form by setting:\n\n            log p(\\tilde{x} | y=c) proportional h_theta ( \\tilde{x})^T w_c\n\nwhere w_c ~ q_phi (w | {x_n ; y_n=c} ) for each class in a given task. Here {(x_n, y_n)} are the few-shot training examples, and $\\tilde{x}$ is the test example. This argument states that under ideal conditions (i.e., we can perfectly estimate p(y=c | x) ), the context-independent assumption is correct, and further motivates our design.\n\nWe have amended the paper to include this argument (see Appendix B). We thank the reviewer for pointing to this important issue, and we hope that this alleviates some of their concerns.\n\n[i] - S. Mohamed. The Density Ratio Trick. The Spectator (Blog). 2018\n[ii] - M. Sugiyama, T. Suzuki, and T. Kanamori. Density ratio estimation in machine learning. 2012\n"}, "signatures": ["ICLR.cc/2019/Conference/Paper441/Authors"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper441/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper441/Authors", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Meta-Learning Probabilistic Inference for Prediction", "abstract": "This paper introduces a new framework for data efficient and versatile learning. Specifically:\n1) We develop ML-PIP, a general framework for Meta-Learning approximate Probabilistic Inference for Prediction. ML-PIP extends existing probabilistic interpretations of meta-learning to cover a broad class of methods. \n2) We introduce \\Versa{}, an instance of the framework employing a flexible and versatile amortization network that takes few-shot learning datasets as inputs, with arbitrary numbers of shots, and outputs a distribution over task-specific parameters in a single forward pass. \\Versa{} substitutes optimization at test time with forward passes through inference networks, amortizing the cost of inference and relieving the need for second derivatives during training.\n3) We evaluate \\Versa{} on benchmark datasets where the method sets new state-of-the-art results, and can handle arbitrary number of shots, and for classification, arbitrary numbers of classes at train and test time. The power of the approach is then demonstrated through a challenging few-shot ShapeNet view reconstruction task.", "keywords": ["probabilistic models", "approximate inference", "few-shot learning", "meta-learning"], "authorids": ["jg801@cam.ac.uk", "jfb54@cam.ac.uk", "bauer@tue.mpg.de", "nowozin@google.com", "ret26@cam.ac.uk"], "authors": ["Jonathan Gordon", "John Bronskill", "Matthias Bauer", "Sebastian Nowozin", "Richard Turner"], "TL;DR": "Novel framework for meta-learning that unifies and extends a broad class of existing few-shot learning methods. Achieves strong performance on few-shot learning benchmarks without requiring iterative test-time inference.   ", "pdf": "/pdf/e9d0c9677cdf67034a920a123c97bfbea6e64d5b.pdf", "paperhash": "gordon|metalearning_probabilistic_inference_for_prediction", "_bibtex": "@inproceedings{\ngordon2018metalearning,\ntitle={Meta-Learning Probabilistic Inference for Prediction},\nauthor={Jonathan Gordon and John Bronskill and Matthias Bauer and Sebastian Nowozin and Richard Turner},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=HkxStoC5F7},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper441/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621620899, "tddate": null, "super": null, "final": null, "reply": {"forum": "HkxStoC5F7", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper441/Authors", "ICLR.cc/2019/Conference/Paper441/Reviewers", "ICLR.cc/2019/Conference/Paper441/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper441/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper441/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper441/Authors|ICLR.cc/2019/Conference/Paper441/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper441/Reviewers", "ICLR.cc/2019/Conference/Paper441/Authors", "ICLR.cc/2019/Conference/Paper441/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621620899}}}, {"id": "Hye5i0QOpQ", "original": null, "number": 3, "cdate": 1542106786043, "ddate": null, "tcdate": 1542106786043, "tmdate": 1542106786043, "tddate": null, "forum": "HkxStoC5F7", "replyto": "Byxh3JK9nQ", "invitation": "ICLR.cc/2019/Conference/-/Paper441/Official_Comment", "content": {"title": "More experiments to main text + timing experiments", "comment": "\u201cIt would have been good if some of the experiments could be moved into the main paper. \u2026 the structure and organization of the paper could be improved by moving some of the methodological details and experimental results in the appendix to the main paper.\u201d\n\nWe agree that a significant portion of interesting content has been relegated to the appendix in our submission. Much of this, of course, has to do with space constraints. However, we have addressed this in the revised version in line with your suggestions by (i) moving the appendix containing the toy-data experimentation to the main body of the paper (see Section 5.1), and (ii) moving some methodological details from the appendix in to the experiments section (see Section 5).\n\n\u201cIt would have been good if there was some validation of the time-performance of the model as one motivation of meta-learning is rapid adaptation to a test-time task. \u201c\n\nWe strongly agree that the issue of performance timing is of great interest, and it is useful and important to validate this experimentally. We were originally hesitant to add any timing results as code released with research papers is often optimized for correctness as opposed to speed. That said, we measured the test time performance of both MAML (as implemented in the authors'  publicly available repository at https://github.com/cbfinn/maml) and Versa in 5-shot 5-way experiments on mini-ImageNet, using the same architectures for both. We found Versa to achieve 5x speed up compared to MAML, while achieving significantly better accuracy (see Table 3). We have amended the paper to include this experimental data (see Section 5.2 for details). We believe this data demonstrates the performance gains achieved by relieving the need for test time optimization procedures.\n"}, "signatures": ["ICLR.cc/2019/Conference/Paper441/Authors"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper441/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper441/Authors", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Meta-Learning Probabilistic Inference for Prediction", "abstract": "This paper introduces a new framework for data efficient and versatile learning. Specifically:\n1) We develop ML-PIP, a general framework for Meta-Learning approximate Probabilistic Inference for Prediction. ML-PIP extends existing probabilistic interpretations of meta-learning to cover a broad class of methods. \n2) We introduce \\Versa{}, an instance of the framework employing a flexible and versatile amortization network that takes few-shot learning datasets as inputs, with arbitrary numbers of shots, and outputs a distribution over task-specific parameters in a single forward pass. \\Versa{} substitutes optimization at test time with forward passes through inference networks, amortizing the cost of inference and relieving the need for second derivatives during training.\n3) We evaluate \\Versa{} on benchmark datasets where the method sets new state-of-the-art results, and can handle arbitrary number of shots, and for classification, arbitrary numbers of classes at train and test time. The power of the approach is then demonstrated through a challenging few-shot ShapeNet view reconstruction task.", "keywords": ["probabilistic models", "approximate inference", "few-shot learning", "meta-learning"], "authorids": ["jg801@cam.ac.uk", "jfb54@cam.ac.uk", "bauer@tue.mpg.de", "nowozin@google.com", "ret26@cam.ac.uk"], "authors": ["Jonathan Gordon", "John Bronskill", "Matthias Bauer", "Sebastian Nowozin", "Richard Turner"], "TL;DR": "Novel framework for meta-learning that unifies and extends a broad class of existing few-shot learning methods. Achieves strong performance on few-shot learning benchmarks without requiring iterative test-time inference.   ", "pdf": "/pdf/e9d0c9677cdf67034a920a123c97bfbea6e64d5b.pdf", "paperhash": "gordon|metalearning_probabilistic_inference_for_prediction", "_bibtex": "@inproceedings{\ngordon2018metalearning,\ntitle={Meta-Learning Probabilistic Inference for Prediction},\nauthor={Jonathan Gordon and John Bronskill and Matthias Bauer and Sebastian Nowozin and Richard Turner},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=HkxStoC5F7},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper441/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621620899, "tddate": null, "super": null, "final": null, "reply": {"forum": "HkxStoC5F7", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper441/Authors", "ICLR.cc/2019/Conference/Paper441/Reviewers", "ICLR.cc/2019/Conference/Paper441/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper441/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper441/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper441/Authors|ICLR.cc/2019/Conference/Paper441/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper441/Reviewers", "ICLR.cc/2019/Conference/Paper441/Authors", "ICLR.cc/2019/Conference/Paper441/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621620899}}}, {"id": "rkxV4A7_am", "original": null, "number": 2, "cdate": 1542106668026, "ddate": null, "tcdate": 1542106668026, "tmdate": 1542106668026, "tddate": null, "forum": "HkxStoC5F7", "replyto": "Syewq7hpoX", "invitation": "ICLR.cc/2019/Conference/-/Paper441/Official_Comment", "content": {"title": "Responding to your review", "comment": "\u201cWhich of the competitors (if any) use the same restricted model setup (inference only on the top-layer weights)?\u201d\n\nTo the best of our knowledge, almost all the competing methods adapt the entire network for new tasks. We have amended the paper to clarify this point (see Section 5.2).\n\n\u201cDo competitors without train/test split also get k_c + 15 points, or only k_c points?\u201d\n\nTo the best of our knowledge, all methods we compare to use train/test splits, with the exception of the VI methods referenced in Table 1. The VI methods used the same number of observations at train time (i.e., the data available to all methods was identical).\n\n\u201cThe main paper does not really state what the model or the likelihood is [in the ShapeNet experiments]. From F.4 in the Appendix, this model does not have the form of your classification models, but psi is input at the bottom of the network. Also, the final layer has sigmoid activation. What likelihood do you use?\u201d\n\nThe terseness of the ShapeNet model details was a result of space constraints. We have amended the paper to include additional explanatory details (see Section 3). You are correct in observing that psi plays a different role from the classification case, namely as an input to the image-generator. The likelihood we used is Gaussian, the sigmoid activation ensures that the mean is between 0 and 1, reflecting the constraints on pixel-intensities. Your observation that using top-layer weights would allow us to perform exact inference is very insightful. We decided to use an architecture that passed the latent parameters underlying each shape instance through multiple non-linearities, but it would be very interesting to compare to the simpler baseline that you suggest. As this is a significant undertaking, we will leave it to future work,\n\n\u201cReal Bayesian inference would just see features h_theta(x) as inputs, not the x's. Why not simply feed features in then? \u2026 Be clear how it depends on theta (I think nothing is lost by feeding in the h_theta(x)).\u201d\n\nThank you for suggesting this cleaner way of presenting our work. We agree with your observations on the input to the inference network. We have amended Fig. 2 accordingly, and have improved the descriptions in Section 3.\n\n\u201cThe marginal likelihood has an Occam's razor argument to prevent overfitting. Why would your criterion prevent overfitting?\u201d\n\nThe mechanism preventing overfitting in our criterion is the meta train / test splits, which explicitly encourages the model to generalize from the training observations to the test data. Methods based on held-out sets, like cross validation, are known to favor models which are more complex than those favoured by Bayesian model comparison [i, ii]. However, as is empirically demonstrated in the experimental section, our proposed criterion consistently outperformed variational objectives.\n\n\u201cIt is quite worrying that the prior p(psi | theta) drops out of the method entirely. Can you comment more on that?\u201d\n\nThis is a subtle point that we view as both a feature and a bug. It is a feature in the sense that a prior is learned implicitly through the sampling procedure (as is shown for example in the simple Gaussian experiment -- see Section 5.1). This can be compared to VI, for example, where the prior enters through a KL regularization term which often favours underfitting. It is a bug if, for example, the user has a priori knowledge about the parameters that they would like to leverage. In this case, it could be possible to use synthetic training data to incorporate such knowledge into the scheme.  However, for the predictive purposes explored in this work, we did not find that the lack of prior posed an issue.\n\n\n[i] - C. E. Rasumessen and Z. Ghahramani. Occam\u2019s razor. 2001.\n[ii] - I. Murray and Z. Ghahramani. A note on the evidence and Bayesian Occam\u2019s razor. 2005.\n"}, "signatures": ["ICLR.cc/2019/Conference/Paper441/Authors"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper441/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper441/Authors", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Meta-Learning Probabilistic Inference for Prediction", "abstract": "This paper introduces a new framework for data efficient and versatile learning. Specifically:\n1) We develop ML-PIP, a general framework for Meta-Learning approximate Probabilistic Inference for Prediction. ML-PIP extends existing probabilistic interpretations of meta-learning to cover a broad class of methods. \n2) We introduce \\Versa{}, an instance of the framework employing a flexible and versatile amortization network that takes few-shot learning datasets as inputs, with arbitrary numbers of shots, and outputs a distribution over task-specific parameters in a single forward pass. \\Versa{} substitutes optimization at test time with forward passes through inference networks, amortizing the cost of inference and relieving the need for second derivatives during training.\n3) We evaluate \\Versa{} on benchmark datasets where the method sets new state-of-the-art results, and can handle arbitrary number of shots, and for classification, arbitrary numbers of classes at train and test time. The power of the approach is then demonstrated through a challenging few-shot ShapeNet view reconstruction task.", "keywords": ["probabilistic models", "approximate inference", "few-shot learning", "meta-learning"], "authorids": ["jg801@cam.ac.uk", "jfb54@cam.ac.uk", "bauer@tue.mpg.de", "nowozin@google.com", "ret26@cam.ac.uk"], "authors": ["Jonathan Gordon", "John Bronskill", "Matthias Bauer", "Sebastian Nowozin", "Richard Turner"], "TL;DR": "Novel framework for meta-learning that unifies and extends a broad class of existing few-shot learning methods. Achieves strong performance on few-shot learning benchmarks without requiring iterative test-time inference.   ", "pdf": "/pdf/e9d0c9677cdf67034a920a123c97bfbea6e64d5b.pdf", "paperhash": "gordon|metalearning_probabilistic_inference_for_prediction", "_bibtex": "@inproceedings{\ngordon2018metalearning,\ntitle={Meta-Learning Probabilistic Inference for Prediction},\nauthor={Jonathan Gordon and John Bronskill and Matthias Bauer and Sebastian Nowozin and Richard Turner},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=HkxStoC5F7},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper441/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621620899, "tddate": null, "super": null, "final": null, "reply": {"forum": "HkxStoC5F7", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper441/Authors", "ICLR.cc/2019/Conference/Paper441/Reviewers", "ICLR.cc/2019/Conference/Paper441/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper441/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper441/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper441/Authors|ICLR.cc/2019/Conference/Paper441/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper441/Reviewers", "ICLR.cc/2019/Conference/Paper441/Authors", "ICLR.cc/2019/Conference/Paper441/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621620899}}}, {"id": "Byxh3JK9nQ", "original": null, "number": 3, "cdate": 1541210035915, "ddate": null, "tcdate": 1541210035915, "tmdate": 1541533993177, "tddate": null, "forum": "HkxStoC5F7", "replyto": "HkxStoC5F7", "invitation": "ICLR.cc/2019/Conference/-/Paper441/Official_Review", "content": {"title": "A novel meta-learning framework", "review": "This paper proposes both a general meta-learning framework with approximate probabilistic inference, and implements an instance of it for few-shot learning. First, they propose Meta-Learning Probabilistic inference for Prediction (ML-PIP) which trains the meta-learner to minimize the KL-divergence between the approximate predictive distribution generated from it and predictive distribution for each class. Then, they use this framework to implement Versatile Amortized Inference, which they call VERSA. VERSA replaces the optimization for test time with efficient posterior inference, by generating distribution over task-specific parameters in a single forward pass. The authors validate VERSA against amortized and non-amortized variational inference which it outperforms. VERSA is also highly versatile as it can be trained with varying number of classes and shots.\n\nPros\n- The proposed general meta-learning framework that aims to learn the meta-learner that approximates the predictive distribution over multiple tasks is quite novel and makes sense.\n- VERSA obtains impressive performance on both benchmark datasets for few-shot learning and is versatile in terms of number of classes and shots.\n- The appendix section has in-depth analysis and additional experimental results which are quite helpful in understanding the paper.\n\nCons\n- The main paper feels quite empty, especially the experimental validation parts with limited number of baselines. It would have been good if some of the experiments could be moved into the main paper. Some experimental results such as Figure 4 on versatility does not add much insight to the main story and could be moved to appendix.\n- It would have been good if there was some validation of the time-performance of the model as one motivation of meta-learning is rapid adaptation to a test-time task. \n\nIn sum, since the proposed meta-learning probabilistic inference framework is novel and effective I vote for accepting the paper. However the structure and organization of the paper could be improved by moving some of the methodological details and experimental results in the appendix to the main paper. \n", "rating": "7: Good paper, accept", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["ICLR.cc/2019/Conference/Paper441/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Meta-Learning Probabilistic Inference for Prediction", "abstract": "This paper introduces a new framework for data efficient and versatile learning. Specifically:\n1) We develop ML-PIP, a general framework for Meta-Learning approximate Probabilistic Inference for Prediction. ML-PIP extends existing probabilistic interpretations of meta-learning to cover a broad class of methods. \n2) We introduce \\Versa{}, an instance of the framework employing a flexible and versatile amortization network that takes few-shot learning datasets as inputs, with arbitrary numbers of shots, and outputs a distribution over task-specific parameters in a single forward pass. \\Versa{} substitutes optimization at test time with forward passes through inference networks, amortizing the cost of inference and relieving the need for second derivatives during training.\n3) We evaluate \\Versa{} on benchmark datasets where the method sets new state-of-the-art results, and can handle arbitrary number of shots, and for classification, arbitrary numbers of classes at train and test time. The power of the approach is then demonstrated through a challenging few-shot ShapeNet view reconstruction task.", "keywords": ["probabilistic models", "approximate inference", "few-shot learning", "meta-learning"], "authorids": ["jg801@cam.ac.uk", "jfb54@cam.ac.uk", "bauer@tue.mpg.de", "nowozin@google.com", "ret26@cam.ac.uk"], "authors": ["Jonathan Gordon", "John Bronskill", "Matthias Bauer", "Sebastian Nowozin", "Richard Turner"], "TL;DR": "Novel framework for meta-learning that unifies and extends a broad class of existing few-shot learning methods. Achieves strong performance on few-shot learning benchmarks without requiring iterative test-time inference.   ", "pdf": "/pdf/e9d0c9677cdf67034a920a123c97bfbea6e64d5b.pdf", "paperhash": "gordon|metalearning_probabilistic_inference_for_prediction", "_bibtex": "@inproceedings{\ngordon2018metalearning,\ntitle={Meta-Learning Probabilistic Inference for Prediction},\nauthor={Jonathan Gordon and John Bronskill and Matthias Bauer and Sebastian Nowozin and Richard Turner},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=HkxStoC5F7},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper441/Official_Review", "cdate": 1542234460896, "expdate": 1552335264000, "duedate": 1541196000000, "reply": {"forum": "HkxStoC5F7", "replyto": "HkxStoC5F7", "readers": {"description": "The users who will be allowed to read the reply content.", "values": ["everyone"]}, "nonreaders": {"values": []}, "signatures": {"description": "How your identity will be displayed with the above content.", "values-regex": "ICLR.cc/2019/Conference/Paper441/AnonReviewer[0-9]+"}, "writers": {"description": "Users that may modify this record.", "values": ["ICLR.cc/2019/Conference"]}, "content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "required": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}}, "multiReply": false, "tcdate": 1552335724870, "tmdate": 1552335724870, "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "invitees": ["ICLR.cc/2019/Conference/Paper441/Reviewers"], "noninvitees": [], "signatures": ["ICLR.cc/2019/Conference"]}}}, {"id": "r1llzOxFhX", "original": null, "number": 2, "cdate": 1541109767830, "ddate": null, "tcdate": 1541109767830, "tmdate": 1541533992973, "tddate": null, "forum": "HkxStoC5F7", "replyto": "HkxStoC5F7", "invitation": "ICLR.cc/2019/Conference/-/Paper441/Official_Review", "content": {"title": "Review for Meta-Learning Probabilistic Inference for Prediction", "review": "This paper presents two different sections:\n1. A generalized framework to describe a range of meta-learning algorithms.\n2. A meta-learning algorithm that allows few shot inference over new tasks without the need for retraining. The important aspect of the algorithm is the context independence assumption between posteriors of different classes for learning weights. This reduces the number of parameters to amortize during meta-training. More importantly, it makes it independent of the number of classes in a task, and effectively doing meta-training across class inference instead of each task. The idea sounds great, but I am skeptical of the justification behind the independence assumption which, as per its justifications sounds contrived and only empirical. \n\nOverall, I feel the paper makes some progress in important aspects of meta-learning.", "rating": "6: Marginally above acceptance threshold", "confidence": "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper"}, "signatures": ["ICLR.cc/2019/Conference/Paper441/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Meta-Learning Probabilistic Inference for Prediction", "abstract": "This paper introduces a new framework for data efficient and versatile learning. Specifically:\n1) We develop ML-PIP, a general framework for Meta-Learning approximate Probabilistic Inference for Prediction. ML-PIP extends existing probabilistic interpretations of meta-learning to cover a broad class of methods. \n2) We introduce \\Versa{}, an instance of the framework employing a flexible and versatile amortization network that takes few-shot learning datasets as inputs, with arbitrary numbers of shots, and outputs a distribution over task-specific parameters in a single forward pass. \\Versa{} substitutes optimization at test time with forward passes through inference networks, amortizing the cost of inference and relieving the need for second derivatives during training.\n3) We evaluate \\Versa{} on benchmark datasets where the method sets new state-of-the-art results, and can handle arbitrary number of shots, and for classification, arbitrary numbers of classes at train and test time. The power of the approach is then demonstrated through a challenging few-shot ShapeNet view reconstruction task.", "keywords": ["probabilistic models", "approximate inference", "few-shot learning", "meta-learning"], "authorids": ["jg801@cam.ac.uk", "jfb54@cam.ac.uk", "bauer@tue.mpg.de", "nowozin@google.com", "ret26@cam.ac.uk"], "authors": ["Jonathan Gordon", "John Bronskill", "Matthias Bauer", "Sebastian Nowozin", "Richard Turner"], "TL;DR": "Novel framework for meta-learning that unifies and extends a broad class of existing few-shot learning methods. Achieves strong performance on few-shot learning benchmarks without requiring iterative test-time inference.   ", "pdf": "/pdf/e9d0c9677cdf67034a920a123c97bfbea6e64d5b.pdf", "paperhash": "gordon|metalearning_probabilistic_inference_for_prediction", "_bibtex": "@inproceedings{\ngordon2018metalearning,\ntitle={Meta-Learning Probabilistic Inference for Prediction},\nauthor={Jonathan Gordon and John Bronskill and Matthias Bauer and Sebastian Nowozin and Richard Turner},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=HkxStoC5F7},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper441/Official_Review", "cdate": 1542234460896, "expdate": 1552335264000, "duedate": 1541196000000, "reply": {"forum": "HkxStoC5F7", "replyto": "HkxStoC5F7", "readers": {"description": "The users who will be allowed to read the reply content.", "values": ["everyone"]}, "nonreaders": {"values": []}, "signatures": {"description": "How your identity will be displayed with the above content.", "values-regex": "ICLR.cc/2019/Conference/Paper441/AnonReviewer[0-9]+"}, "writers": {"description": "Users that may modify this record.", "values": ["ICLR.cc/2019/Conference"]}, "content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "required": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}}, "multiReply": false, "tcdate": 1552335724870, "tmdate": 1552335724870, "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "invitees": ["ICLR.cc/2019/Conference/Paper441/Reviewers"], "noninvitees": [], "signatures": ["ICLR.cc/2019/Conference"]}}}, {"id": "Syewq7hpoX", "original": null, "number": 1, "cdate": 1540371342555, "ddate": null, "tcdate": 1540371342555, "tmdate": 1541533992761, "tddate": null, "forum": "HkxStoC5F7", "replyto": "HkxStoC5F7", "invitation": "ICLR.cc/2019/Conference/-/Paper441/Official_Review", "content": {"title": "Few-shot learning, based on amortized inference network for parameters of logistic regression head models. Uses learning criterion based on predictive distributions on train/test splits. Extensive comparison, achieves state-of-the-art despite simpler setup than many competitors", "review": "Summary:\nThis work tackles few-shot (or meta) learning from a probabilistic inference viewpoint. Compared to previous work, it uses a simpler setup, performing task-specific inference only for single-layer head models, and employs an objective based on predictive distributions on train/test splits for each task (rather than an approximation to log marginal likelihood). Inference is done amortized by a network, whose input is the task training split. The same network is used for parameters of each class (only feeding training points of that class), which allows an arbitrary number of classes per task. At test time, inference just requires forward passes through this network, attractive compared to non-amortized approaches which need optimization or gradients here.\n\nIt provides a clean, decision-theoretic derivation, and clarifies relationships to previous work. The experimental results are encouraging: the method achieves a new best on 5-way, 5-shot miniImageNet, despite the simple setup. In general, explanations in the main text could be more complete (see questions). I'd recommend shortening Section 4, which is pretty obvious.\n\n- Quality: Several interesting differences to prior work. Well-done experiments\n- Clarity: Clean derivation, easy to understand. Some details could be spelled out better\n- Originality: Several important novelties (predictive criterion, simple model setup, amortized inference network). Closely related to \"neural processes\" work, but this happened roughly at the same time\n- Significance: The few-shot learning results are competitive, in particular given they use a simpler model setup than most previous work. I am not an expert on these kind of experiments, but I found the comparisons fair and rather extensive\n\nInteresting about this work:\n- Clean Bayesian decision-theoretic viewpoint. Key question is of course whether\n   an inference network of this simple structure (no correlations, sum combination\n   of datapoints, same network for each class) can deliver a good approximation to\n   the true posterior.\n- Different to previous work, task-specific inference is done only on the weights of\n   single-layer head models (logistic regression models, with shared features).\n   Highly encouraging that this is sufficient for state-of-the-art few-shot classification\n   performance. The authors could be more clear about this point.\n- Simple and efficient amortized inference model, which along with the neural\n   network features, is learned on all data jointly\n- Optimization criterion is based on predictive distributions on train/test splits, not\n   on the log marginal likelihood. Has some odd consequences (question below),\n   but clearly works better for few-shot classification\n\nExperiments:\n- 5.1: Convincing results, in particular given the simplicity of the model setup and\n   the inference network. But some important points are not explained:\n   - Which of the competitors (if any) use the same restricted model setup (inference\n      only on the top-layer weights)? Clearly, MAML does not, right? Please state this\n      explicitly.\n   - For Versa, you use k_c training and 15 test points per task update during\n      training. Do competitors without train/test split also get k_c + 15 points, or\n      only k_c points? The former would be fair, the latter not so much.\n- 5.2: This seems a challenging problem, and both your numbers and reconstructions\n   look better than the competitor. I cannot say more, based on the very brief\n   explanations provided here.\n   The main paper does not really state what the model or the likelihood is. From\n   F.4 in the Appendix, this model does not have the form of your classification\n   models, but psi is input at the bottom of the network. Also, the final layer has\n   sigmoid activation. What likelihood do you use?\n   One observation: If you used the same \"inference on final layer weights\" setup\n   here, and Gaussian likelihood, you could compute the posterior over psi in closed\n   form, no amortization needed. Would this setup apply to your problem?\n\nFurther questions:\n- Confused about the input to the inference network. Real Bayesian inference would\n   just see features h_theta(x) as inputs, not the x's. Why not simply feed features in\n   then?\n   Please do improve the description of the inference network, this is a major\n   novelty of this paper, and even the appendix is only understandable by reading\n   other work as well. Be clear how it depends on theta (I think nothing is lost by\n   feeding in the h_theta(x)).\n- The learning criterion based on predictive distributions on train/test splits seem\n   to work better than ELBO-like criteria, for few-shot classification.\n   But there are some worrying aspects. The marginal likelihood has an Occam's\n   razor argument to prevent overfitting. Why would your criterion prevent overfitting?\n   And it is quite worrying that the prior p(psi | theta) drops out of the method\n   entirely. Can you comment more on that?\n\nSmall:\n- p(psi_t | tilde{x}_t, D_t, theta) should be p(psi_t | D_t, theta). Please avoid a more\n   general notation early on, if you do not do it later on. This is confusing\n", "rating": "8: Top 50% of accepted papers, clear accept", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["ICLR.cc/2019/Conference/Paper441/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Meta-Learning Probabilistic Inference for Prediction", "abstract": "This paper introduces a new framework for data efficient and versatile learning. Specifically:\n1) We develop ML-PIP, a general framework for Meta-Learning approximate Probabilistic Inference for Prediction. ML-PIP extends existing probabilistic interpretations of meta-learning to cover a broad class of methods. \n2) We introduce \\Versa{}, an instance of the framework employing a flexible and versatile amortization network that takes few-shot learning datasets as inputs, with arbitrary numbers of shots, and outputs a distribution over task-specific parameters in a single forward pass. \\Versa{} substitutes optimization at test time with forward passes through inference networks, amortizing the cost of inference and relieving the need for second derivatives during training.\n3) We evaluate \\Versa{} on benchmark datasets where the method sets new state-of-the-art results, and can handle arbitrary number of shots, and for classification, arbitrary numbers of classes at train and test time. The power of the approach is then demonstrated through a challenging few-shot ShapeNet view reconstruction task.", "keywords": ["probabilistic models", "approximate inference", "few-shot learning", "meta-learning"], "authorids": ["jg801@cam.ac.uk", "jfb54@cam.ac.uk", "bauer@tue.mpg.de", "nowozin@google.com", "ret26@cam.ac.uk"], "authors": ["Jonathan Gordon", "John Bronskill", "Matthias Bauer", "Sebastian Nowozin", "Richard Turner"], "TL;DR": "Novel framework for meta-learning that unifies and extends a broad class of existing few-shot learning methods. Achieves strong performance on few-shot learning benchmarks without requiring iterative test-time inference.   ", "pdf": "/pdf/e9d0c9677cdf67034a920a123c97bfbea6e64d5b.pdf", "paperhash": "gordon|metalearning_probabilistic_inference_for_prediction", "_bibtex": "@inproceedings{\ngordon2018metalearning,\ntitle={Meta-Learning Probabilistic Inference for Prediction},\nauthor={Jonathan Gordon and John Bronskill and Matthias Bauer and Sebastian Nowozin and Richard Turner},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=HkxStoC5F7},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper441/Official_Review", "cdate": 1542234460896, "expdate": 1552335264000, "duedate": 1541196000000, "reply": {"forum": "HkxStoC5F7", "replyto": "HkxStoC5F7", "readers": {"description": "The users who will be allowed to read the reply content.", "values": ["everyone"]}, "nonreaders": {"values": []}, "signatures": {"description": "How your identity will be displayed with the above content.", "values-regex": "ICLR.cc/2019/Conference/Paper441/AnonReviewer[0-9]+"}, "writers": {"description": "Users that may modify this record.", "values": ["ICLR.cc/2019/Conference"]}, "content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "required": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}}, "multiReply": false, "tcdate": 1552335724870, "tmdate": 1552335724870, "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "invitees": ["ICLR.cc/2019/Conference/Paper441/Reviewers"], "noninvitees": [], "signatures": ["ICLR.cc/2019/Conference"]}}}], "count": 18}