{"notes": [{"id": "WUTkGqErZ9", "original": "zayILXFH48l", "number": 2034, "cdate": 1601308224027, "ddate": null, "tcdate": 1601308224027, "tmdate": 1614985637351, "tddate": null, "forum": "WUTkGqErZ9", "replyto": null, "invitation": "ICLR.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Convolutional Neural Networks are not invariant to translation, but they can learn to be", "authorids": ["~Valerio_Biscione1", "~Jeffrey_Bowers1"], "authors": ["Valerio Biscione", "Jeffrey Bowers"], "keywords": ["Invariance", "Convolutional Networks", "Translation", "Internal Representations"], "abstract": "When seeing a new object, humans can immediately recognize it across different retinal locations: we say that the internal object representation is invariant to translation. It is commonly believed that Convolutional Neural Networks (CNNs) are architecturally invariant to translation thanks to the convolution and/or pooling operations they are endowed with. In fact, several works have found that these networks systematically fail to recognise new objects on untrained locations. In this work we show how, even though CNNs are not 'architecturally invariant' to translation, they can indeed 'learn' to be invariant to translation. We verified that this can be achieved by pretraining on ImageNet, and we found that it is also possible with much simpler datasets in which the items are fully translated across the input canvas. Significantly, simply training everywhere on the canvas was not enough. We investigated how this pretraining affected the internal network representations, finding that the invariance was almost always acquired, even though it was some times disrupted by further training due to catastrophic forgetting/interference. \n These experiments show how pretraining a network on an environment with the right 'latent' characteristics (a more naturalistic environment) can result in the network learning deep perceptual rules which would dramatically improve subsequent generalization.", "one-sentence_summary": "CNNs are not, as commonly assumed, 'architecturally' invariant to translation, but we investigated the conditions in which they can learn to be invariant to translation.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "biscione|convolutional_neural_networks_are_not_invariant_to_translation_but_they_can_learn_to_be", "pdf": "/pdf/c6064e5c0f7f43c271676e5152f170a8e7d0d899.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=yDCpsCm7rU", "_bibtex": "@misc{\nbiscione2021convolutional,\ntitle={Convolutional Neural Networks are not invariant to translation, but they can learn to be},\nauthor={Valerio Biscione and Jeffrey Bowers},\nyear={2021},\nurl={https://openreview.net/forum?id=WUTkGqErZ9}\n}"}, "signatures": ["ICLR.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference"], "details": {"replyCount": 4, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"reply": {"readers": {"values-regex": ".*"}, "writers": {"values": ["ICLR.cc/2021/Conference"]}, "signatures": {"values": ["ICLR.cc/2021/Conference"]}, "content": {"authors": {"values": ["Anonymous"]}, "authorids": {"values-regex": ".*"}, "reviewed_version_(pdf)": {"required": false, "description": "Upload a PDF file that ends with .pdf", "value-regex": ".*"}}}, "signatures": ["ICLR.cc/2021/Conference"], "readers": ["everyone"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["~", "OpenReview.net/Support"], "tcdate": 1601308008205, "tmdate": 1614984599368, "id": "ICLR.cc/2021/Conference/-/Blind_Submission"}}, "tauthor": "OpenReview.net"}, {"id": "cWkJc9GFGAv", "original": null, "number": 1, "cdate": 1610040524235, "ddate": null, "tcdate": 1610040524235, "tmdate": 1610474133271, "tddate": null, "forum": "WUTkGqErZ9", "replyto": "WUTkGqErZ9", "invitation": "ICLR.cc/2021/Conference/Paper2034/-/Decision", "content": {"title": "Final Decision", "decision": "Reject", "comment": "This paper receives 3 initial rejection ratings. No rebuttal was submitted by the authors. There is no basis for overturning the reviewers' decisions. This paper should be rejected."}, "signatures": ["ICLR.cc/2021/Conference/Program_Chairs"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference/Program_Chairs"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Convolutional Neural Networks are not invariant to translation, but they can learn to be", "authorids": ["~Valerio_Biscione1", "~Jeffrey_Bowers1"], "authors": ["Valerio Biscione", "Jeffrey Bowers"], "keywords": ["Invariance", "Convolutional Networks", "Translation", "Internal Representations"], "abstract": "When seeing a new object, humans can immediately recognize it across different retinal locations: we say that the internal object representation is invariant to translation. It is commonly believed that Convolutional Neural Networks (CNNs) are architecturally invariant to translation thanks to the convolution and/or pooling operations they are endowed with. In fact, several works have found that these networks systematically fail to recognise new objects on untrained locations. In this work we show how, even though CNNs are not 'architecturally invariant' to translation, they can indeed 'learn' to be invariant to translation. We verified that this can be achieved by pretraining on ImageNet, and we found that it is also possible with much simpler datasets in which the items are fully translated across the input canvas. Significantly, simply training everywhere on the canvas was not enough. We investigated how this pretraining affected the internal network representations, finding that the invariance was almost always acquired, even though it was some times disrupted by further training due to catastrophic forgetting/interference. \n These experiments show how pretraining a network on an environment with the right 'latent' characteristics (a more naturalistic environment) can result in the network learning deep perceptual rules which would dramatically improve subsequent generalization.", "one-sentence_summary": "CNNs are not, as commonly assumed, 'architecturally' invariant to translation, but we investigated the conditions in which they can learn to be invariant to translation.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "biscione|convolutional_neural_networks_are_not_invariant_to_translation_but_they_can_learn_to_be", "pdf": "/pdf/c6064e5c0f7f43c271676e5152f170a8e7d0d899.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=yDCpsCm7rU", "_bibtex": "@misc{\nbiscione2021convolutional,\ntitle={Convolutional Neural Networks are not invariant to translation, but they can learn to be},\nauthor={Valerio Biscione and Jeffrey Bowers},\nyear={2021},\nurl={https://openreview.net/forum?id=WUTkGqErZ9}\n}"}, "tags": [], "invitation": {"reply": {"forum": "WUTkGqErZ9", "replyto": "WUTkGqErZ9", "readers": {"values": ["everyone"]}, "writers": {"values": ["ICLR.cc/2021/Conference/Program_Chairs"]}, "signatures": {"values": ["ICLR.cc/2021/Conference/Program_Chairs"]}, "content": {"title": {"value": "Final Decision"}, "decision": {"value-radio": ["Accept (Oral)", "Accept (Spotlight)", "Accept (Poster)", "Reject"]}, "comment": {"value-regex": "[\\S\\s]{0,50000}", "markdown": true}}}, "multiReply": false, "signatures": ["ICLR.cc/2021/Conference"], "readers": ["everyone"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Program_Chairs"], "tcdate": 1610040524221, "tmdate": 1610474133256, "id": "ICLR.cc/2021/Conference/Paper2034/-/Decision"}}}, {"id": "UE_HQ5hvq2C", "original": null, "number": 1, "cdate": 1603972491066, "ddate": null, "tcdate": 1603972491066, "tmdate": 1606739380890, "tddate": null, "forum": "WUTkGqErZ9", "replyto": "WUTkGqErZ9", "invitation": "ICLR.cc/2021/Conference/Paper2034/-/Official_Review", "content": {"title": "Review on Convolutional Neural Networks are not invariant to translation, but they can learn to be", "review": "This paper analysis and studies translation invariance in convolution neural networks. It argues that typically it is claimed that CNNs are translation invariant due to the convolution function, and that actually convolution are equivariant. While pooling is the actual function that gives local invariance (or global when the pooling is across all locations), this is not included in the description of invariance. One neural network, VGG-16, is used for the analysis in different scenarios: 1) pre-trained on Imagenet and fine-tuned to the new dataset on one location 2) trained from scratch using the new dataset in one location 3) trained from scratch using the new datasets in all locations of the canvas and test on the other datasets. The main conclusion in the paper is that CNNs are not invariant to translation by design of the architecture, but that when pre-trained on naturalistic images, they can be. \n\n\nPositive points:\n\n- the research question is important and this kind of analysis to understand CNNs are crucial to better understand network capabilities and being able to predict their behaviour.\n\n----\nCOMMENT AFTER REBUTTAL PERIOD:\nGiven that there was no rebuttal, I keep my initial rating.\n\n- study how using pre-trained networks affect the generalization in some factors, e.g. translation invariance in this paper, is interesting and novel.\n\n- The paper is well written and easy to follow.\n\n\n\nConcerns: \n\n- The main concern is about the experimental set-up and results presented in the paper. Only one network is used for the study, to validate if it is indeed the architectural design the gives translation invariance. It is a weak statement if other CNNs architectures with different configurations (number of layers, amount of local pooling, if global pooling is used, the effect of strides, etc ) analyzed, and the current observations might only apply to VGG-16.\n\n- The results in figure 2 B when comparing the translation invariance across the different datasets, it is mentioned that depending on the dataset that the network is initialized from it brings more or less translation invariance. A deeper analysis on the amount of data used, the similarity between the objects across datasets, and how this effect the final performance would be nice to include. Here talking about invariance is a bit confusing, and it might be that this robustness to position changes is more related the generalization properties to the other datasets due to the resemblance of the objects, and obtained by experience. \n \n- It would have been nice to see the behaviour in another transformation as well, since it would strengthen the claim that the invariance (I would say robustness) to transformations is not due to the architecture, but to previous exposure to naturalistic images, and if it is not, it would bring some light into why it is for translation and not for other transformations.\n\n\n\n \nMinor comments: \n \n* As a side comment, since there is some motivation in the introduction relating to human visual processing, humans have a loss of acuity (recognition performance) with distance to the focal point, and perceive high accuracy in the fovea a low-accuracy in the periphery, which is not captured by typical CNNs. ", "rating": "5: Marginally below acceptance threshold", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}, "signatures": ["ICLR.cc/2021/Conference/Paper2034/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2034/AnonReviewer2"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Convolutional Neural Networks are not invariant to translation, but they can learn to be", "authorids": ["~Valerio_Biscione1", "~Jeffrey_Bowers1"], "authors": ["Valerio Biscione", "Jeffrey Bowers"], "keywords": ["Invariance", "Convolutional Networks", "Translation", "Internal Representations"], "abstract": "When seeing a new object, humans can immediately recognize it across different retinal locations: we say that the internal object representation is invariant to translation. It is commonly believed that Convolutional Neural Networks (CNNs) are architecturally invariant to translation thanks to the convolution and/or pooling operations they are endowed with. In fact, several works have found that these networks systematically fail to recognise new objects on untrained locations. In this work we show how, even though CNNs are not 'architecturally invariant' to translation, they can indeed 'learn' to be invariant to translation. We verified that this can be achieved by pretraining on ImageNet, and we found that it is also possible with much simpler datasets in which the items are fully translated across the input canvas. Significantly, simply training everywhere on the canvas was not enough. We investigated how this pretraining affected the internal network representations, finding that the invariance was almost always acquired, even though it was some times disrupted by further training due to catastrophic forgetting/interference. \n These experiments show how pretraining a network on an environment with the right 'latent' characteristics (a more naturalistic environment) can result in the network learning deep perceptual rules which would dramatically improve subsequent generalization.", "one-sentence_summary": "CNNs are not, as commonly assumed, 'architecturally' invariant to translation, but we investigated the conditions in which they can learn to be invariant to translation.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "biscione|convolutional_neural_networks_are_not_invariant_to_translation_but_they_can_learn_to_be", "pdf": "/pdf/c6064e5c0f7f43c271676e5152f170a8e7d0d899.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=yDCpsCm7rU", "_bibtex": "@misc{\nbiscione2021convolutional,\ntitle={Convolutional Neural Networks are not invariant to translation, but they can learn to be},\nauthor={Valerio Biscione and Jeffrey Bowers},\nyear={2021},\nurl={https://openreview.net/forum?id=WUTkGqErZ9}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq . ***Please remember to file the Code-of-Ethics report. Once you submitted the review, a link to the report will be visible in the bottom right corner of your review.***", "required": true, "markdown": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}, "forum": "WUTkGqErZ9", "replyto": "WUTkGqErZ9", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"], "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper2034/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1607428800000, "duedate": 1606752000000, "multiReply": false, "readers": ["everyone"], "tcdate": 1602538105461, "tmdate": 1606915806914, "super": "ICLR.cc/2021/Conference/-/Official_Review", "signatures": ["OpenReview.net"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Paper2034/Reviewers", "OpenReview.net/Support"], "id": "ICLR.cc/2021/Conference/Paper2034/-/Official_Review"}}}, {"id": "bTn2iBdTLRs", "original": null, "number": 2, "cdate": 1603979778102, "ddate": null, "tcdate": 1603979778102, "tmdate": 1605024303463, "tddate": null, "forum": "WUTkGqErZ9", "replyto": "WUTkGqErZ9", "invitation": "ICLR.cc/2021/Conference/Paper2034/-/Official_Review", "content": {"title": "Interesting experimental setup to evaluate translation invariance, but insights are not significantly new", "review": "This paper addresses the problem of how convolutional neural networks (CNNs) achieve translation invariance, and the authors argue that this invariance es mostly learned from suitable datasets, rather than a result of the architecture. In particular, ImageNet-pretrained networks have learned to be invariant to translation, and fine tuned. The experiments are performed in MNIST-like datasets evaluating classification performance at different locations. The authors conclude that invariance is achieved when the CNN is trained with the different objects being presented at different locations across the canvas, and that the invariance can be forgotten after subsequent training.\n\nPros:\n- The experiments explore several settings and are convincing in clearly showing that translation invariance requires that the network observes the different objects translated across the canvas, in their particular setting (although I have some concerns about the setting).\n- Understanding how neural networks achieve certain properties, such as translation invariance, is very relevant.\n- The paper is well written and can be followed easily. I like particularly the ilustrations of the experiments.\n\n\nCons:\n- The main concern I have is that the insights are relatively incremental. The experimental setting replicates Blything et al 2020 and the main insight of CNNs can learn translation invariance from suitable large and diverse datasets such as ImageNet was already shown in that paper (note that, although available in arxiv in Sept 2020, the authors are aware of the work, since they state that they use Bything et al.'s dataset and replicate their experiments). The results in the submission are not showing significantly novel insights.\n- Results are shown with small datasets (MNIST-like), but not clear how they extrapolate to more complex one. It is also not clear to me that is possible to train a heavy model such as VGG16 with such small resolution datasets, even when they are translated to different locations. It probably results in very significant overfitting.\n- Only evaluated on VGG16. To be more convincing in the general claim, it is necessary to also evaluate other models. \n- The authors only analyze translation invariance of the whole network. It would be more interesting to analyze invariance of the different layers via intermediate representations. Experiment 3 for instance, encourages local translation invariance (within each quadrant), but not across the whole canvas. I would expect that higher layers still behave like Vanilla VGG16 which overfits to the location, while lower layers show higher level of invariance. \n- Fine tuning the whole network (I understand the authors train/fine tune all the layers) in this setting is probably leading to significant overfitting and therefore to catastrophic forgetting. The authors should consider the case where only the classifier is trained (and a variable number of layers in the top), and thus less prone to overfitting and avoid forgetting in lower layers, to further assess the invariance in different layers.\n\nQuestions\nPlease clarify cons.\n\nMinor comments\nSome figures seem to suggest that images have multiple objects in multiple locations. My understanding is that every image has only one object, and the location can change, so those figures may be misleading. Please clarify and modify the figure if necessary.", "rating": "4: Ok but not good enough - rejection", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "signatures": ["ICLR.cc/2021/Conference/Paper2034/AnonReviewer4"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2034/AnonReviewer4"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Convolutional Neural Networks are not invariant to translation, but they can learn to be", "authorids": ["~Valerio_Biscione1", "~Jeffrey_Bowers1"], "authors": ["Valerio Biscione", "Jeffrey Bowers"], "keywords": ["Invariance", "Convolutional Networks", "Translation", "Internal Representations"], "abstract": "When seeing a new object, humans can immediately recognize it across different retinal locations: we say that the internal object representation is invariant to translation. It is commonly believed that Convolutional Neural Networks (CNNs) are architecturally invariant to translation thanks to the convolution and/or pooling operations they are endowed with. In fact, several works have found that these networks systematically fail to recognise new objects on untrained locations. In this work we show how, even though CNNs are not 'architecturally invariant' to translation, they can indeed 'learn' to be invariant to translation. We verified that this can be achieved by pretraining on ImageNet, and we found that it is also possible with much simpler datasets in which the items are fully translated across the input canvas. Significantly, simply training everywhere on the canvas was not enough. We investigated how this pretraining affected the internal network representations, finding that the invariance was almost always acquired, even though it was some times disrupted by further training due to catastrophic forgetting/interference. \n These experiments show how pretraining a network on an environment with the right 'latent' characteristics (a more naturalistic environment) can result in the network learning deep perceptual rules which would dramatically improve subsequent generalization.", "one-sentence_summary": "CNNs are not, as commonly assumed, 'architecturally' invariant to translation, but we investigated the conditions in which they can learn to be invariant to translation.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "biscione|convolutional_neural_networks_are_not_invariant_to_translation_but_they_can_learn_to_be", "pdf": "/pdf/c6064e5c0f7f43c271676e5152f170a8e7d0d899.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=yDCpsCm7rU", "_bibtex": "@misc{\nbiscione2021convolutional,\ntitle={Convolutional Neural Networks are not invariant to translation, but they can learn to be},\nauthor={Valerio Biscione and Jeffrey Bowers},\nyear={2021},\nurl={https://openreview.net/forum?id=WUTkGqErZ9}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq . ***Please remember to file the Code-of-Ethics report. Once you submitted the review, a link to the report will be visible in the bottom right corner of your review.***", "required": true, "markdown": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}, "forum": "WUTkGqErZ9", "replyto": "WUTkGqErZ9", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"], "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper2034/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1607428800000, "duedate": 1606752000000, "multiReply": false, "readers": ["everyone"], "tcdate": 1602538105461, "tmdate": 1606915806914, "super": "ICLR.cc/2021/Conference/-/Official_Review", "signatures": ["OpenReview.net"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Paper2034/Reviewers", "OpenReview.net/Support"], "id": "ICLR.cc/2021/Conference/Paper2034/-/Official_Review"}}}, {"id": "2jXZSPp1_W", "original": null, "number": 3, "cdate": 1604273058119, "ddate": null, "tcdate": 1604273058119, "tmdate": 1605024303406, "tddate": null, "forum": "WUTkGqErZ9", "replyto": "WUTkGqErZ9", "invitation": "ICLR.cc/2021/Conference/Paper2034/-/Official_Review", "content": {"title": "through experiments but lacks novelty", "review": "This paper examines the source of translational invariance in CNNs and points out that the convolution operation is translationally equi-variant and not invariant. Authors thoroughly examine how training and architecture contribute to translational invariance in CNNs. My main concern about this paper is with respect to its novelty. While the experiments are done in a thorough way, the main point of this paper (that translation invariance is formed during training) is mostly known to the community. The equi-variance property of convolution operation is discussed in machine/deep learning textbooks (e.g. [2]) and the importance of image-augmentations like spatial jitter on network object recognition performance has repeatedly been demonstrated. Because of this reason I don\u2019t think this paper would be suitable for publication at ICLR. \n\nOther comments: \n* The contribution of the paper is very unclear from the abstract, even getting past the first two sections I was still left wondering what I should be expecting to see in the rest of the paper. \n* The text needs more proofing reading, more than few typos and misuse of words. E.g. bases \u2014> basis; human vision recognition \u2014> human visual (object) recognition\n* LeCun et al. 1998 is cited as a biological model which is not a good example of a biological neural network. Although CNNs have some commonalities with biological neural networks they have many more differences. [1] might be a better reference to an early biologically inspired neural net\n* It is claimed that \u201cCNNs achieve neither rotation nor scale invariance\u201d. However this is not a binary property. What matters is the degree of invariance that could be measured. \n* section 3: by \"non-pretrained network\u201d do you mean the untrained network?\n* It is unclear from the text under section 3 what \u201cpretraining on the whole canvas\u201d is\n* the 1-location dataset is not described anywhere in the paper and I had to go by a guess as to what this dataset contains. \n* in section 5, the use of the cosine similarity measure instead of the accuracy which was used in the previous 4 experiments is not well motivated. If this is a better measure why not using it in all experiments. \n\n\n[1] Fukushima, K. (1975). Cognitron: A self-organizing multilayered neural network. Biological cybernetics, 20(3-4), 121-136.\n\n[2] Goodfellow, I., Bengio, Y., Courville, A., & Bengio, Y. (2016). Deep learning (Vol. 1, p. 2). Cambridge: MIT press.", "rating": "4: Ok but not good enough - rejection", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["ICLR.cc/2021/Conference/Paper2034/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2034/AnonReviewer3"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Convolutional Neural Networks are not invariant to translation, but they can learn to be", "authorids": ["~Valerio_Biscione1", "~Jeffrey_Bowers1"], "authors": ["Valerio Biscione", "Jeffrey Bowers"], "keywords": ["Invariance", "Convolutional Networks", "Translation", "Internal Representations"], "abstract": "When seeing a new object, humans can immediately recognize it across different retinal locations: we say that the internal object representation is invariant to translation. It is commonly believed that Convolutional Neural Networks (CNNs) are architecturally invariant to translation thanks to the convolution and/or pooling operations they are endowed with. In fact, several works have found that these networks systematically fail to recognise new objects on untrained locations. In this work we show how, even though CNNs are not 'architecturally invariant' to translation, they can indeed 'learn' to be invariant to translation. We verified that this can be achieved by pretraining on ImageNet, and we found that it is also possible with much simpler datasets in which the items are fully translated across the input canvas. Significantly, simply training everywhere on the canvas was not enough. We investigated how this pretraining affected the internal network representations, finding that the invariance was almost always acquired, even though it was some times disrupted by further training due to catastrophic forgetting/interference. \n These experiments show how pretraining a network on an environment with the right 'latent' characteristics (a more naturalistic environment) can result in the network learning deep perceptual rules which would dramatically improve subsequent generalization.", "one-sentence_summary": "CNNs are not, as commonly assumed, 'architecturally' invariant to translation, but we investigated the conditions in which they can learn to be invariant to translation.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "biscione|convolutional_neural_networks_are_not_invariant_to_translation_but_they_can_learn_to_be", "pdf": "/pdf/c6064e5c0f7f43c271676e5152f170a8e7d0d899.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=yDCpsCm7rU", "_bibtex": "@misc{\nbiscione2021convolutional,\ntitle={Convolutional Neural Networks are not invariant to translation, but they can learn to be},\nauthor={Valerio Biscione and Jeffrey Bowers},\nyear={2021},\nurl={https://openreview.net/forum?id=WUTkGqErZ9}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq . ***Please remember to file the Code-of-Ethics report. Once you submitted the review, a link to the report will be visible in the bottom right corner of your review.***", "required": true, "markdown": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}, "forum": "WUTkGqErZ9", "replyto": "WUTkGqErZ9", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"], "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper2034/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1607428800000, "duedate": 1606752000000, "multiReply": false, "readers": ["everyone"], "tcdate": 1602538105461, "tmdate": 1606915806914, "super": "ICLR.cc/2021/Conference/-/Official_Review", "signatures": ["OpenReview.net"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Paper2034/Reviewers", "OpenReview.net/Support"], "id": "ICLR.cc/2021/Conference/Paper2034/-/Official_Review"}}}], "count": 5}