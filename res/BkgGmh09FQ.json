{"notes": [{"id": "BkgGmh09FQ", "original": "BkgDNZC5YQ", "number": 1338, "cdate": 1538087962078, "ddate": null, "tcdate": 1538087962078, "tmdate": 1545355429483, "tddate": null, "forum": "BkgGmh09FQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Understanding Opportunities for Efficiency in Single-image Super Resolution Networks", "abstract": "A successful application of convolutional architectures is to increase the resolution of single low-resolution images -- a image restoration task called super-resolution (SR). Naturally, SR is of value to resource constrained devices like mobile phones, electronic photograph frames and televisions to enhance image quality. However, SR demands perhaps the most extreme amounts of memory and compute operations of any mainstream vision task known today, preventing SR from being deployed to devices that require them. In this paper, we perform a early systematic study of system resource efficiency for SR, within the context of a variety of architectural and low-precision approaches originally developed for discriminative neural networks. We present a rich set of insights, representative SR architectures, and efficiency trade-offs; for example, the prioritization of ways to compress models to reach a specific memory and computation target and techniques to compact SR models so that they are suitable for DSPs and FPGAs. As a result of doing so, we manage to achieve better and comparable performance with previous models in the existing literature, highlighting the practicality of using existing efficiency techniques in SR tasks. Collectively, we believe these results provides the foundation for further research into the little explored area of resource efficiency for SR. ", "keywords": ["Super-Resolution", "Resource-Efficiency"], "authorids": ["rs@roysonlee.com", "nicholas.d.lane@gmail.com", "marko.stankovic996@gmail.com", "bsourav@gmail.com"], "authors": ["Royson Lee", "Nic Lane", "Marko Stankovic", "Sourav Bhattacharya"], "TL;DR": "We build an understanding of resource-efficient techniques on Super-Resolution", "pdf": "/pdf/21f463083d76b7439df2380734c1262cb75f6947.pdf", "paperhash": "lee|understanding_opportunities_for_efficiency_in_singleimage_super_resolution_networks", "_bibtex": "@misc{\nlee2019understanding,\ntitle={Understanding Opportunities for Efficiency in Single-image Super Resolution Networks},\nauthor={Royson Lee and Nic Lane and Marko Stankovic and Sourav Bhattacharya},\nyear={2019},\nurl={https://openreview.net/forum?id=BkgGmh09FQ},\n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"replyCount": 7, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Blind_Submission", "rdate": null, "ddate": null, "expdate": null, "duedate": 1538085600000, "tmdate": 1538142958393, "tddate": null, "super": null, "final": null, "reply": {"signatures": {"values": ["ICLR.cc/2019/Conference"]}, "forum": null, "readers": {"values": ["everyone"]}, "replyto": null, "content": {"authorids": {"values-regex": ".*"}, "authors": {"values": ["Anonymous"]}}, "writers": {"values": ["ICLR.cc/2019/Conference"]}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["~"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": null, "taskCompletionCount": null, "transform": null, "cdate": 1538142958393}}, "tauthor": "OpenReview.net"}, {"id": "ryxbNPPEeV", "original": null, "number": 1, "cdate": 1545004841078, "ddate": null, "tcdate": 1545004841078, "tmdate": 1545354486823, "tddate": null, "forum": "BkgGmh09FQ", "replyto": "BkgGmh09FQ", "invitation": "ICLR.cc/2019/Conference/-/Paper1338/Meta_Review", "content": {"metareview": "This paper targets improving the computation efficiency of super resolution task. Reviewers have a consensus that this paper lacks technical contribution, therefore not recommend acceptance. ", "confidence": "4: The area chair is confident but not absolutely certain", "recommendation": "Reject", "title": "lack technical contributions"}, "signatures": ["ICLR.cc/2019/Conference/Paper1338/Area_Chair1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference/Paper1338/Area_Chair1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Understanding Opportunities for Efficiency in Single-image Super Resolution Networks", "abstract": "A successful application of convolutional architectures is to increase the resolution of single low-resolution images -- a image restoration task called super-resolution (SR). Naturally, SR is of value to resource constrained devices like mobile phones, electronic photograph frames and televisions to enhance image quality. However, SR demands perhaps the most extreme amounts of memory and compute operations of any mainstream vision task known today, preventing SR from being deployed to devices that require them. In this paper, we perform a early systematic study of system resource efficiency for SR, within the context of a variety of architectural and low-precision approaches originally developed for discriminative neural networks. We present a rich set of insights, representative SR architectures, and efficiency trade-offs; for example, the prioritization of ways to compress models to reach a specific memory and computation target and techniques to compact SR models so that they are suitable for DSPs and FPGAs. As a result of doing so, we manage to achieve better and comparable performance with previous models in the existing literature, highlighting the practicality of using existing efficiency techniques in SR tasks. Collectively, we believe these results provides the foundation for further research into the little explored area of resource efficiency for SR. ", "keywords": ["Super-Resolution", "Resource-Efficiency"], "authorids": ["rs@roysonlee.com", "nicholas.d.lane@gmail.com", "marko.stankovic996@gmail.com", "bsourav@gmail.com"], "authors": ["Royson Lee", "Nic Lane", "Marko Stankovic", "Sourav Bhattacharya"], "TL;DR": "We build an understanding of resource-efficient techniques on Super-Resolution", "pdf": "/pdf/21f463083d76b7439df2380734c1262cb75f6947.pdf", "paperhash": "lee|understanding_opportunities_for_efficiency_in_singleimage_super_resolution_networks", "_bibtex": "@misc{\nlee2019understanding,\ntitle={Understanding Opportunities for Efficiency in Single-image Super Resolution Networks},\nauthor={Royson Lee and Nic Lane and Marko Stankovic and Sourav Bhattacharya},\nyear={2019},\nurl={https://openreview.net/forum?id=BkgGmh09FQ},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper1338/Meta_Review", "rdate": null, "ddate": null, "expdate": null, "duedate": 1541548800000, "tmdate": 1545352873925, "tddate": null, "super": null, "final": null, "reply": {"forum": "BkgGmh09FQ", "replyto": "BkgGmh09FQ", "readers": {"description": "Select all user groups that should be able to read this comment. Selecting 'All Users' will allow paper authors, reviewers, area chairs, and program chairs to view this comment.", "values": ["everyone"]}, "signatures": {"description": "How your identity will be displayed with the above content.", "values-regex": "ICLR.cc/2019/Conference/Paper1338/Area_Chair[0-9]+"}, "writers": {"description": "Users that may modify this record.", "values-regex": "ICLR.cc/2019/Conference/Paper1338/Area_Chair[0-9]+"}, "content": {"title": {"order": 1, "value-regex": ".{1,500}", "description": "Brief summary of your review.", "required": true}, "metareview": {"order": 2, "value-regex": "[\\S\\s]{1,5000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "required": true}, "recommendation": {"order": 3, "value-dropdown": ["Accept (Oral)", "Accept (Poster)", "Reject"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The area chair is absolutely certain", "4: The area chair is confident but not absolutely certain", "3: The area chair is somewhat confident", "2: The area chair is not sure", "1: The area chair's evaluation is an educated guess"], "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper1338/Area_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": false, "taskCompletionCount": null, "transform": null, "cdate": 1545352873925}}}, {"id": "BJl1kj0FCQ", "original": null, "number": 3, "cdate": 1543264982785, "ddate": null, "tcdate": 1543264982785, "tmdate": 1543264982785, "tddate": null, "forum": "BkgGmh09FQ", "replyto": "BJliGqDS2Q", "invitation": "ICLR.cc/2019/Conference/-/Paper1338/Official_Comment", "content": {"title": "Revised paper to underline new insights proposed and add more visual comparisons. Techniques are agnostic to any task. Better & comparable results.", "comment": "Thanks for identifying the missing gaps from the paper. We have revised the paper to include more visual comparisons and make our objectives and writing clearer. \n\nThe focus of the paper is to understand the empirical effects of applying and comparing existing techniques that are popular in image discriminative tasks. \n\n> All techniques considered in this paper have been investigated in previous works\n\nAll techniques, apart from group convolutions which were investigated in [A], considered in this paper have not been investigated in super resolution networks. Due to the up-sampling structure of SR models, these efficiency methods may therefore produce potentially stronger side-effects to image distortion.\n\n[A] Ahn, N., Kang, B., & Sohn, K. A. (2018). Fast, Accurate, and, Lightweight Super-Resolution with Cascading Residual Network. arXiv preprint arXiv:1803.08664.\n\n> Thus no new idea is proposed in this work\n\nAlthough we do not propose a new way to perform compression, we show that these techniques differ greatly in trade-offs between efficiency and performance in different vision tasks, such as image classification and super-resolution. We derive a list of novel best practices from our results that can be used to efficiently construct or reduce any SR model.\n\n> Not clear why these improvement is particular suitable for the task for super resolution\n\nLow rank factorization is agnostic and is not specifically designed for any particular task. As long as the reconstruction error is small, the decomposition should follow the performance of the original model. Our results show that these techniques can also be practical and effective in super-resolution and can help existing practitioners construct or reduce their models though a list of recommendations that work better in terms of trade-off between image distortion (PSNR/SSIM) and size/operations. \n\n> these techniques actually can be used to improve a variety of network architectures in both high-level and low-level vision tasks\n\nYes, but the extent of improvement differs in both high-level and low-level vision tasks and the trade-offs when applied to SR are unclear prior to this study. For quantization, we obtain similar trade-offs in performance and efficiency. For convolutional approximations, we show that this is not the case for different vision tasks. For instance, unlike in image classification tasks, the use of low rank tensor decomposition, which we called bottleneck reduction, has better trade-offs than the use of grouped convolutions and/or channel shuffling in super-resolution tasks. Additionally, we also show that as more layers are compressed, the worse the trade-offs, an observation which is unlike previous observations in image classification tasks.\n\n> experimental results are weak\n\nWe managed to achieve better or comparable results with the models in recent existing literature. We are not aware of any model in the literature that is better in all aspects (performance, memory, and compute). To the best of our knowledge, there is always some trade-off made; if the model performs better, it is usually less efficient and vice versa. Additionally, our proposed best practices are complementary to any model in the existing literature.\n\nOnce again, we would like to thank you for the time and valuable comments.\n"}, "signatures": ["ICLR.cc/2019/Conference/Paper1338/Authors"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper1338/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper1338/Authors", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Understanding Opportunities for Efficiency in Single-image Super Resolution Networks", "abstract": "A successful application of convolutional architectures is to increase the resolution of single low-resolution images -- a image restoration task called super-resolution (SR). Naturally, SR is of value to resource constrained devices like mobile phones, electronic photograph frames and televisions to enhance image quality. However, SR demands perhaps the most extreme amounts of memory and compute operations of any mainstream vision task known today, preventing SR from being deployed to devices that require them. In this paper, we perform a early systematic study of system resource efficiency for SR, within the context of a variety of architectural and low-precision approaches originally developed for discriminative neural networks. We present a rich set of insights, representative SR architectures, and efficiency trade-offs; for example, the prioritization of ways to compress models to reach a specific memory and computation target and techniques to compact SR models so that they are suitable for DSPs and FPGAs. As a result of doing so, we manage to achieve better and comparable performance with previous models in the existing literature, highlighting the practicality of using existing efficiency techniques in SR tasks. Collectively, we believe these results provides the foundation for further research into the little explored area of resource efficiency for SR. ", "keywords": ["Super-Resolution", "Resource-Efficiency"], "authorids": ["rs@roysonlee.com", "nicholas.d.lane@gmail.com", "marko.stankovic996@gmail.com", "bsourav@gmail.com"], "authors": ["Royson Lee", "Nic Lane", "Marko Stankovic", "Sourav Bhattacharya"], "TL;DR": "We build an understanding of resource-efficient techniques on Super-Resolution", "pdf": "/pdf/21f463083d76b7439df2380734c1262cb75f6947.pdf", "paperhash": "lee|understanding_opportunities_for_efficiency_in_singleimage_super_resolution_networks", "_bibtex": "@misc{\nlee2019understanding,\ntitle={Understanding Opportunities for Efficiency in Single-image Super Resolution Networks},\nauthor={Royson Lee and Nic Lane and Marko Stankovic and Sourav Bhattacharya},\nyear={2019},\nurl={https://openreview.net/forum?id=BkgGmh09FQ},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper1338/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621609312, "tddate": null, "super": null, "final": null, "reply": {"forum": "BkgGmh09FQ", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper1338/Authors", "ICLR.cc/2019/Conference/Paper1338/Reviewers", "ICLR.cc/2019/Conference/Paper1338/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper1338/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper1338/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper1338/Authors|ICLR.cc/2019/Conference/Paper1338/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper1338/Reviewers", "ICLR.cc/2019/Conference/Paper1338/Authors", "ICLR.cc/2019/Conference/Paper1338/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621609312}}}, {"id": "HklazuAY0X", "original": null, "number": 2, "cdate": 1543264277116, "ddate": null, "tcdate": 1543264277116, "tmdate": 1543264277116, "tddate": null, "forum": "BkgGmh09FQ", "replyto": "HJlpdIWA37", "invitation": "ICLR.cc/2019/Conference/-/Paper1338/Official_Comment", "content": {"title": "both distortion and perceptual SR have their own advantages / revised paper to show our focus in SR literature", "comment": "Thank you for your valuable comments and suggestions. We revised the paper to follow your suggestions and make our points clearer.\n\n> metric that are known to not be well correlated with perceptual quality / these models are the current state-of-the-art in terms of perceptual quality\n\nWe disagree. The recent PIRM 2018 Challenge [A] provided the insight that structured images look perceptually better using models that were trained to reduce image distortion (PSNR/SSIM) and unstructured details were more visually pleasing using models that were trained to improve the perception metrics which you mentioned. Therefore, we believe that both lines of work have their own advantages. Furthermore, images that are better in terms of perceptual quality performed worse than images that are better in terms of distortion quality when used as inputs for image classification [B]. Therefore, we believe that both lines of work have their own advantages. \n\n[A] Blau, Y., Mechrez, R., Timofte, R., Michaeli, T., & Zelnik-Manor, L. (2018). 2018 PIRM Challenge on Perceptual Image Super-resolution. arXiv preprint arXiv:1809.07517.\n\n[B] Jaffe, L., Sundram, S., & Martinez-Nieves, C. (2017). Super-resolution to improve classification accuracy of low-resolution images. Tech. Rep. 19, Stanford University.\n\n>this perceptual line of work needs to be cited\n\nWe are aware of the perceptual track that you mentioned and only focus on the image distortion metrics. Hence, we previously kept the paper short and concise and did not cite the perceptual line of work as we did not use ideas such as the use of perpetual, contextual, adversarial losses etc. Following your advice, we have included a \u2018Related work\u2019 section to cover this and highlight the scope of our work and where it lies in the literature.\n\n> Not obvious to me that the insights obtained in this work would translate to the other case. / would the conclusions drawn on this work transfer to that setting? paper needs to provide a detailed justification on why models using these losses are not considered\n\nAs mentioned, we believe that both lines of work are important. Intuitively, as the models in our experiments are not trained to improve perception metrics and the compressed super-resolution images are less visually pleasing as compared to those produced by RCAN [C], our work would not improve the score based on perceptual tests. Regardless, you made a good suggestion to use perceptual tests and we agree that it would be interesting to perform these techniques on models that are trained to improve the perception metrics or both distortion and perception metrics to look at the trade-offs. Unfortunately, doing so would involve another huge set of systematic large-scale experiments due to the large variability of how these models can be trained, a change that would be significantly different from the original scope of the paper, which focuses on the trade-offs between efficiency and the image distortion metrics.\n\n[C] Zhang, Y., Li, K., Li, K., Wang, L., Zhong, B., & Fu, Y. (2018). Image super-resolution using very deep residual channel attention networks. arXiv preprint arXiv:1807.02758.\n\n> training details\n\nWe used the pretrained x2 scaling model as a starting point to train the x3 and x4 scaling models. This has been previous shown [D] to converge the model faster without affecting performance.\n\n[D] Lim, B., Son, S., Kim, H., Nah, S., & Lee, K. M. (2017, July). Enhanced deep residual networks for single image super-resolution. In The IEEE conference on computer vision and pattern recognition (CVPR) workshops (Vol. 1, No. 2, p. 4).\n\n> distillation techniques\n\nWe speculate that distillation will further reduce the performance as shown in other image restoration tasks such as image enhancement [E]. However, we agree that it will be interesting as a future work to experiment and compare it with the conclusions that are proposed in our paper.\n\n[E]  Hui, Z., Wang, X., Deng, L., Gao, X.:  Perception-preserving convolutional networks for image enhancement on smartphones. In:  European Conference on Computer Vision Workshops (2018)\n\n> try scaling factors larger than x4\n\nWe did not try scaling factors larger than x4. However, as the trade-offs are consistent for x2, x3, and x4 scaling factors, we strongly speculate that the same conclusions hold for high scaling factors. \n\n> simpler methods can achieve quite competitive results (such as simple interpolation methods)\n\nTo the best of our knowledge, we are not aware of any simple interpolation methods that are comparable to the use of neural networks for single image super resolution.\n\n> overall writing could be improved. Citation style is not used properly.\n\nWe carefully proofread and made the appropriate modifications to the paper based on your feedback. Thank you once again for the detailed review.\n"}, "signatures": ["ICLR.cc/2019/Conference/Paper1338/Authors"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper1338/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper1338/Authors", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Understanding Opportunities for Efficiency in Single-image Super Resolution Networks", "abstract": "A successful application of convolutional architectures is to increase the resolution of single low-resolution images -- a image restoration task called super-resolution (SR). Naturally, SR is of value to resource constrained devices like mobile phones, electronic photograph frames and televisions to enhance image quality. However, SR demands perhaps the most extreme amounts of memory and compute operations of any mainstream vision task known today, preventing SR from being deployed to devices that require them. In this paper, we perform a early systematic study of system resource efficiency for SR, within the context of a variety of architectural and low-precision approaches originally developed for discriminative neural networks. We present a rich set of insights, representative SR architectures, and efficiency trade-offs; for example, the prioritization of ways to compress models to reach a specific memory and computation target and techniques to compact SR models so that they are suitable for DSPs and FPGAs. As a result of doing so, we manage to achieve better and comparable performance with previous models in the existing literature, highlighting the practicality of using existing efficiency techniques in SR tasks. Collectively, we believe these results provides the foundation for further research into the little explored area of resource efficiency for SR. ", "keywords": ["Super-Resolution", "Resource-Efficiency"], "authorids": ["rs@roysonlee.com", "nicholas.d.lane@gmail.com", "marko.stankovic996@gmail.com", "bsourav@gmail.com"], "authors": ["Royson Lee", "Nic Lane", "Marko Stankovic", "Sourav Bhattacharya"], "TL;DR": "We build an understanding of resource-efficient techniques on Super-Resolution", "pdf": "/pdf/21f463083d76b7439df2380734c1262cb75f6947.pdf", "paperhash": "lee|understanding_opportunities_for_efficiency_in_singleimage_super_resolution_networks", "_bibtex": "@misc{\nlee2019understanding,\ntitle={Understanding Opportunities for Efficiency in Single-image Super Resolution Networks},\nauthor={Royson Lee and Nic Lane and Marko Stankovic and Sourav Bhattacharya},\nyear={2019},\nurl={https://openreview.net/forum?id=BkgGmh09FQ},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper1338/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621609312, "tddate": null, "super": null, "final": null, "reply": {"forum": "BkgGmh09FQ", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper1338/Authors", "ICLR.cc/2019/Conference/Paper1338/Reviewers", "ICLR.cc/2019/Conference/Paper1338/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper1338/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper1338/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper1338/Authors|ICLR.cc/2019/Conference/Paper1338/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper1338/Reviewers", "ICLR.cc/2019/Conference/Paper1338/Authors", "ICLR.cc/2019/Conference/Paper1338/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621609312}}}, {"id": "H1lUmvRFRX", "original": null, "number": 1, "cdate": 1543264029647, "ddate": null, "tcdate": 1543264029647, "tmdate": 1543264029647, "tddate": null, "forum": "BkgGmh09FQ", "replyto": "ryeByNe1aX", "invitation": "ICLR.cc/2019/Conference/-/Paper1338/Official_Comment", "content": {"title": "known ideas' outcomes is unclear on SR prior to study / new observations / better & comparable results than other", "comment": "Thank you for your review and your positive comment. Our primary objective is to understand how compression techniques, that previously worked in image discriminative tasks, will work in a previously unstudied task for model compression: Super Resolution (SR). SR architectures differ significantly from those designed for image classification due to the up-sampling structure of SR models. Prior to our empirical study, it was unclear which methods that promote efficiency would perform best. Moreover, the magnitudes of gains were unknown without the extensive empirical analysis that we performed.\n\n> methods that do a comparable or better job in the same range\n\nWe are not aware of any model, including those that you pointed out, that beats our best model in both efficiency (memory and compute) and the image distortion metrics (PSNR/SSIM); there is always some trade-off made. Can you give some examples on such models?\n\n> does not lead to or bring new insights or ideas. does not reveal new operating points.\n\nOur results reveal a list of new insights and operating points in terms of trade-offs between operations/size and performance accuracy that are not previously found in the SR literature:\n\n1. In image discriminative tasks, the proposed architecture changes are comparable in terms of efficiency and accuracy trade-offs. In our work, we show varying effectiveness among these techniques. In particular, the use of low rank tensor decomposition/bottleneck reduction architectures provide the best trade-offs, followed by the use of grouped convolutions, and the use of channel shuffling & splitting. In other words, any usage of grouped convolutions increases image distortion quite significantly and any usage of channel shuffle drastically increase it even further.\n\n2.[A, B] have shown that it is possible to maintain a similar or slight drop in performance by decomposing tensors of known models in image classification. In contrast, we show that as more tensors are decomposed in the model, the worse the trade-offs are in SR. \n\n3. The use of ternary-weighted quantization in SR tasks results in trade-offs similar to that in image discriminative tasks. We are not aware of any other SR papers that try binary/ternary weighted architectures.\n\n[A] Bhattacharya, S., & Lane, N. D. (2016, November). Sparsification and separation of deep learning layers for constrained resource inference on wearables. In Proceedings of the 14th ACM Conference on Embedded Network Sensor Systems CD-ROM (pp. 176-189). ACM.\n\n[B] Kim, Y. D., Park, E., Yoo, S., Choi, T., Yang, L., & Shin, D. (2015). Compression of deep convolutional neural networks for fast and low power mobile applications. arXiv preprint arXiv:1511.06530.\n\n> expand their study, make some novel observations, propose some design that stand out\n\nAlthough we did not propose a novel design, we have made some novel observations and recommend a list of best practices for practitioners to construct or reduce any SR model in the literature.\n\n> recent papers\n\nAs far as we know, the models proposed in the recent PIRM mobile challenge did not use any of the techniques that we tried and are therefore complementary to our work. Moreover, although the smaller models are more efficient, they perform much worse in terms of the image distortion metrics (PSNR/SSIM) and therefore, not a fair comparison with our derived models.\n\nWe have addressed your points extensively in our revised paper attached.\n"}, "signatures": ["ICLR.cc/2019/Conference/Paper1338/Authors"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper1338/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper1338/Authors", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Understanding Opportunities for Efficiency in Single-image Super Resolution Networks", "abstract": "A successful application of convolutional architectures is to increase the resolution of single low-resolution images -- a image restoration task called super-resolution (SR). Naturally, SR is of value to resource constrained devices like mobile phones, electronic photograph frames and televisions to enhance image quality. However, SR demands perhaps the most extreme amounts of memory and compute operations of any mainstream vision task known today, preventing SR from being deployed to devices that require them. In this paper, we perform a early systematic study of system resource efficiency for SR, within the context of a variety of architectural and low-precision approaches originally developed for discriminative neural networks. We present a rich set of insights, representative SR architectures, and efficiency trade-offs; for example, the prioritization of ways to compress models to reach a specific memory and computation target and techniques to compact SR models so that they are suitable for DSPs and FPGAs. As a result of doing so, we manage to achieve better and comparable performance with previous models in the existing literature, highlighting the practicality of using existing efficiency techniques in SR tasks. Collectively, we believe these results provides the foundation for further research into the little explored area of resource efficiency for SR. ", "keywords": ["Super-Resolution", "Resource-Efficiency"], "authorids": ["rs@roysonlee.com", "nicholas.d.lane@gmail.com", "marko.stankovic996@gmail.com", "bsourav@gmail.com"], "authors": ["Royson Lee", "Nic Lane", "Marko Stankovic", "Sourav Bhattacharya"], "TL;DR": "We build an understanding of resource-efficient techniques on Super-Resolution", "pdf": "/pdf/21f463083d76b7439df2380734c1262cb75f6947.pdf", "paperhash": "lee|understanding_opportunities_for_efficiency_in_singleimage_super_resolution_networks", "_bibtex": "@misc{\nlee2019understanding,\ntitle={Understanding Opportunities for Efficiency in Single-image Super Resolution Networks},\nauthor={Royson Lee and Nic Lane and Marko Stankovic and Sourav Bhattacharya},\nyear={2019},\nurl={https://openreview.net/forum?id=BkgGmh09FQ},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper1338/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621609312, "tddate": null, "super": null, "final": null, "reply": {"forum": "BkgGmh09FQ", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper1338/Authors", "ICLR.cc/2019/Conference/Paper1338/Reviewers", "ICLR.cc/2019/Conference/Paper1338/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper1338/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper1338/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper1338/Authors|ICLR.cc/2019/Conference/Paper1338/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper1338/Reviewers", "ICLR.cc/2019/Conference/Paper1338/Authors", "ICLR.cc/2019/Conference/Paper1338/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621609312}}}, {"id": "ryeByNe1aX", "original": null, "number": 3, "cdate": 1541501916543, "ddate": null, "tcdate": 1541501916543, "tmdate": 1541533217727, "tddate": null, "forum": "BkgGmh09FQ", "replyto": "BkgGmh09FQ", "invitation": "ICLR.cc/2019/Conference/-/Paper1338/Official_Review", "content": {"title": "summary of known ideas / no new ideas / no better results than other from the SR literature", "review": "The authors target single-image super-resolution (SR) task and study the efficiency (runtime, memory) of the current neural networks.\n\nOn the positive side, the paper is a good effort of bringing together works and insights related to efficient designs and efficient SR solutions.\n\nIf we report to the baseline architecture (RCAN) then the proposed efficient variants achieves large reductions in number of parameters or multiplications-additions, at the cost of lower accuracy. However, when the newly proposed trade-offs are compared with the existing literature, we see other methods that do a comparable or better job in the same range.\n\nOn the negative side, from my point of view, the study is far from being thorough and does not lead to or bring new insights or ideas. The experimental results does not reveal new operating points (trade-off between complexity/operations and performance accuracy).\n\nI would suggest to the authors to expand their study, to make some novel observations, and to propose some designs that can stand out in the literature.\n\nI am pointing out also to some recent papers that are related to the topic and can be or are applied to SR:\nGu et al, \"Multi-bin Trainable Linear Unit for Fast Image Restoration Networks\", arxiv 2018\nIgnatov et al, \"Pirm challenge on perceptual image enhancement on smartphones: Report\", arxiv 2018\nand some works proposed for that challenge:\nVu et al, \"Fast and efficient image quality enhancement via desubpixel convolutional neural networks\", ECCVW 2018\nLi et al, \"CARN: Convolutional Anchored Regression Network for Fast and Accurate Single Image Super-Resolution\", ECCVW 2018\nPengfei et al, \"Range scaling global u-net for perceptual image enhancement on mobile devices\", ECCVW 2018\n\n", "rating": "4: Ok but not good enough - rejection", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}, "signatures": ["ICLR.cc/2019/Conference/Paper1338/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Understanding Opportunities for Efficiency in Single-image Super Resolution Networks", "abstract": "A successful application of convolutional architectures is to increase the resolution of single low-resolution images -- a image restoration task called super-resolution (SR). Naturally, SR is of value to resource constrained devices like mobile phones, electronic photograph frames and televisions to enhance image quality. However, SR demands perhaps the most extreme amounts of memory and compute operations of any mainstream vision task known today, preventing SR from being deployed to devices that require them. In this paper, we perform a early systematic study of system resource efficiency for SR, within the context of a variety of architectural and low-precision approaches originally developed for discriminative neural networks. We present a rich set of insights, representative SR architectures, and efficiency trade-offs; for example, the prioritization of ways to compress models to reach a specific memory and computation target and techniques to compact SR models so that they are suitable for DSPs and FPGAs. As a result of doing so, we manage to achieve better and comparable performance with previous models in the existing literature, highlighting the practicality of using existing efficiency techniques in SR tasks. Collectively, we believe these results provides the foundation for further research into the little explored area of resource efficiency for SR. ", "keywords": ["Super-Resolution", "Resource-Efficiency"], "authorids": ["rs@roysonlee.com", "nicholas.d.lane@gmail.com", "marko.stankovic996@gmail.com", "bsourav@gmail.com"], "authors": ["Royson Lee", "Nic Lane", "Marko Stankovic", "Sourav Bhattacharya"], "TL;DR": "We build an understanding of resource-efficient techniques on Super-Resolution", "pdf": "/pdf/21f463083d76b7439df2380734c1262cb75f6947.pdf", "paperhash": "lee|understanding_opportunities_for_efficiency_in_singleimage_super_resolution_networks", "_bibtex": "@misc{\nlee2019understanding,\ntitle={Understanding Opportunities for Efficiency in Single-image Super Resolution Networks},\nauthor={Royson Lee and Nic Lane and Marko Stankovic and Sourav Bhattacharya},\nyear={2019},\nurl={https://openreview.net/forum?id=BkgGmh09FQ},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper1338/Official_Review", "cdate": 1542234251643, "expdate": 1552335264000, "duedate": 1541196000000, "reply": {"forum": "BkgGmh09FQ", "replyto": "BkgGmh09FQ", "readers": {"description": "The users who will be allowed to read the reply content.", "values": ["everyone"]}, "nonreaders": {"values": []}, "signatures": {"description": "How your identity will be displayed with the above content.", "values-regex": "ICLR.cc/2019/Conference/Paper1338/AnonReviewer[0-9]+"}, "writers": {"description": "Users that may modify this record.", "values": ["ICLR.cc/2019/Conference"]}, "content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "required": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}}, "multiReply": false, "tcdate": 1552335925214, "tmdate": 1552335925214, "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "invitees": ["ICLR.cc/2019/Conference/Paper1338/Reviewers"], "noninvitees": [], "signatures": ["ICLR.cc/2019/Conference"]}}}, {"id": "HJlpdIWA37", "original": null, "number": 2, "cdate": 1541441141138, "ddate": null, "tcdate": 1541441141138, "tmdate": 1541533217522, "tddate": null, "forum": "BkgGmh09FQ", "replyto": "BkgGmh09FQ", "invitation": "ICLR.cc/2019/Conference/-/Paper1338/Official_Review", "content": {"title": "Official review", "review": "\nThe paper proposes a detailed empirical evaluation of the trade-offs achieved by various convolutional neural networks on the super resolution problem. The paper provides an extensive evaluation of different architectural changes and the trade-off between savings in terms of memory and computational cost and performance, measured in terms of PSNR and SSIM.\n\nThis is an empirical paper, thus it does not provide technical contributions. I do think that the insights obtained from such an empirical evaluation could be of interest for practitioners and researchers working on the problem. My main concern is the method only evaluates the trade-offs between model efficiency (in terms of memory and/or computation) and performance measured using metrics that are known to not be well correlated with perceptual quality. Thus it is not obvious to me that the insights obtained in this work would translate to the other case.\n\nIt is well known that PSNR favors blurry solutions over perceptually more appealing solutions. This comes from the fact that there is no information in the low resolution image to produce the missing high resolution details. Filling up plausible details in a way that is different from the original image would lead to high PSNR. Models that treat the super resolution problem as a regression task using similarity in pixel space, tend to produce blurry solutions and require very large models to improve the score.  \n\nIn recent years, many works have been studying the use of perceptual losses to mitigate this issue or simply treating the super resolution problem as conditional generative modeling.  For instance, models using L2 losses in a perceptually more relevant (or learned) feature spaces [A, B], or including GAN losses [C, D] (to list a few). To my knowledge, these models are the current state of the art in terms of perceptual quality. This has been evaluated empirically via perceptual tests [D].  \n\nThis line of work needs to be cited. In my view, the paper needs to provide a detailed justification on why models using these losses are not considered. Would the conclusions drawn on this work transfer to that setting? Furthermore, it would be good to perform perceptual tests to perform this evaluation. It would be good to provide some canonical examples in the appendix.\n\nThe overall writing of the paper could be improved. Several sentences are difficult to read, due to typos or the construction of the sentences. The paper evaluates many architectural modifications proposed by other works. It would be good to add an appendix with a small description of what these are. This would make the paper self-contained an easier to read (I had too look up a few of them).\n\nThe authors mentioned that they first train models for scaling factor of x2 and then use them for training settings higher magnification. How is this exactly done? Please provide details.\n\nI am curious of weather using some for of distillation techniques would be useful here.\n\nDid you try scaling factors larger than x4? Scaling factors of x2 does not seem very relevant, as simpler methods can achieve already quite competitive results (such as simple interpolation methods)\n\nThe authors seem to be citing Zhang et al (2018) as a reference to attention mechanisms. To my knowledge the paper that proposed these mechanisms is [E].\n\nThe citation style is not used properly throughout the manuscript. As an example:\n\n\u201c\u2026 proposed in StrassenNets Tschannen et al (2017).\u201d Should be \u201c\u2026 proposed in StrassenNets (Tschannen et al, 2017).\u201d Or \u201c\u2026 proposed in StrassenNets proposed by Tschannen et al (2017).\u201d\n\n[A] Johnson, J. et al. \"Perceptual losses for real-time style transfer and super-resolution.\"\u00a0ECCV, 2016.\n[B] Bruna, J. et al \"Super-resolution with deep convolutional sufficient statistics.\"\u00a0ICLR 2016.\n[C] Ledig, C. et al. \"Photo-Realistic Single Image Super-Resolution Using a Generative Adversarial Network.\"\u00a0CVPR. Vol. 2. No. 3. 2017.\n[D] S\u00f8nderby, C. K., et al. \"Amortised map inference for image super-resolution.\"\u00a0arXiv preprint arXiv:1610.04490(2016).\n[E] Bahdanau, D. et al \"Neural machine translation by jointly learning to align and translate.\"\u00a0arXiv (2014).", "rating": "5: Marginally below acceptance threshold", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["ICLR.cc/2019/Conference/Paper1338/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Understanding Opportunities for Efficiency in Single-image Super Resolution Networks", "abstract": "A successful application of convolutional architectures is to increase the resolution of single low-resolution images -- a image restoration task called super-resolution (SR). Naturally, SR is of value to resource constrained devices like mobile phones, electronic photograph frames and televisions to enhance image quality. However, SR demands perhaps the most extreme amounts of memory and compute operations of any mainstream vision task known today, preventing SR from being deployed to devices that require them. In this paper, we perform a early systematic study of system resource efficiency for SR, within the context of a variety of architectural and low-precision approaches originally developed for discriminative neural networks. We present a rich set of insights, representative SR architectures, and efficiency trade-offs; for example, the prioritization of ways to compress models to reach a specific memory and computation target and techniques to compact SR models so that they are suitable for DSPs and FPGAs. As a result of doing so, we manage to achieve better and comparable performance with previous models in the existing literature, highlighting the practicality of using existing efficiency techniques in SR tasks. Collectively, we believe these results provides the foundation for further research into the little explored area of resource efficiency for SR. ", "keywords": ["Super-Resolution", "Resource-Efficiency"], "authorids": ["rs@roysonlee.com", "nicholas.d.lane@gmail.com", "marko.stankovic996@gmail.com", "bsourav@gmail.com"], "authors": ["Royson Lee", "Nic Lane", "Marko Stankovic", "Sourav Bhattacharya"], "TL;DR": "We build an understanding of resource-efficient techniques on Super-Resolution", "pdf": "/pdf/21f463083d76b7439df2380734c1262cb75f6947.pdf", "paperhash": "lee|understanding_opportunities_for_efficiency_in_singleimage_super_resolution_networks", "_bibtex": "@misc{\nlee2019understanding,\ntitle={Understanding Opportunities for Efficiency in Single-image Super Resolution Networks},\nauthor={Royson Lee and Nic Lane and Marko Stankovic and Sourav Bhattacharya},\nyear={2019},\nurl={https://openreview.net/forum?id=BkgGmh09FQ},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper1338/Official_Review", "cdate": 1542234251643, "expdate": 1552335264000, "duedate": 1541196000000, "reply": {"forum": "BkgGmh09FQ", "replyto": "BkgGmh09FQ", "readers": {"description": "The users who will be allowed to read the reply content.", "values": ["everyone"]}, "nonreaders": {"values": []}, "signatures": {"description": "How your identity will be displayed with the above content.", "values-regex": "ICLR.cc/2019/Conference/Paper1338/AnonReviewer[0-9]+"}, "writers": {"description": "Users that may modify this record.", "values": ["ICLR.cc/2019/Conference"]}, "content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "required": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}}, "multiReply": false, "tcdate": 1552335925214, "tmdate": 1552335925214, "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "invitees": ["ICLR.cc/2019/Conference/Paper1338/Reviewers"], "noninvitees": [], "signatures": ["ICLR.cc/2019/Conference"]}}}, {"id": "BJliGqDS2Q", "original": null, "number": 1, "cdate": 1540876819357, "ddate": null, "tcdate": 1540876819357, "tmdate": 1541533217275, "tddate": null, "forum": "BkgGmh09FQ", "replyto": "BkgGmh09FQ", "invitation": "ICLR.cc/2019/Conference/-/Paper1338/Official_Review", "content": {"title": "No new insight is proposed. The techniques are not specifically designed for super-resolution task. The experimental results are also weak.", "review": "This paper proposed to improve the system resource efficiency for super resolution networks. \n\nFirst, I am afraid all the techniques considered in this paper have been investigated in previous works. Thus no new idea is proposed in this work. Also, it is also not clear why these improvement is particularly suitable for the task of super resolution. In my viewpoint, these techniques actually can be used to improve a variety of network architectures in both high-level and low-level vision tasks.\n\nSecond, the experimental results are also weak. As this work is aiming to address the super resolution tasks, at least visual comparisons between the proposed methods and other state-of-the-art approaches should be included in the experimental part. But unfortunately, no such qualitative results are presented in the manuscript. \n\nFinally, the presentation of the paper should also be carefully proofread and revised.\n", "rating": "3: Clear rejection", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}, "signatures": ["ICLR.cc/2019/Conference/Paper1338/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Understanding Opportunities for Efficiency in Single-image Super Resolution Networks", "abstract": "A successful application of convolutional architectures is to increase the resolution of single low-resolution images -- a image restoration task called super-resolution (SR). Naturally, SR is of value to resource constrained devices like mobile phones, electronic photograph frames and televisions to enhance image quality. However, SR demands perhaps the most extreme amounts of memory and compute operations of any mainstream vision task known today, preventing SR from being deployed to devices that require them. In this paper, we perform a early systematic study of system resource efficiency for SR, within the context of a variety of architectural and low-precision approaches originally developed for discriminative neural networks. We present a rich set of insights, representative SR architectures, and efficiency trade-offs; for example, the prioritization of ways to compress models to reach a specific memory and computation target and techniques to compact SR models so that they are suitable for DSPs and FPGAs. As a result of doing so, we manage to achieve better and comparable performance with previous models in the existing literature, highlighting the practicality of using existing efficiency techniques in SR tasks. Collectively, we believe these results provides the foundation for further research into the little explored area of resource efficiency for SR. ", "keywords": ["Super-Resolution", "Resource-Efficiency"], "authorids": ["rs@roysonlee.com", "nicholas.d.lane@gmail.com", "marko.stankovic996@gmail.com", "bsourav@gmail.com"], "authors": ["Royson Lee", "Nic Lane", "Marko Stankovic", "Sourav Bhattacharya"], "TL;DR": "We build an understanding of resource-efficient techniques on Super-Resolution", "pdf": "/pdf/21f463083d76b7439df2380734c1262cb75f6947.pdf", "paperhash": "lee|understanding_opportunities_for_efficiency_in_singleimage_super_resolution_networks", "_bibtex": "@misc{\nlee2019understanding,\ntitle={Understanding Opportunities for Efficiency in Single-image Super Resolution Networks},\nauthor={Royson Lee and Nic Lane and Marko Stankovic and Sourav Bhattacharya},\nyear={2019},\nurl={https://openreview.net/forum?id=BkgGmh09FQ},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper1338/Official_Review", "cdate": 1542234251643, "expdate": 1552335264000, "duedate": 1541196000000, "reply": {"forum": "BkgGmh09FQ", "replyto": "BkgGmh09FQ", "readers": {"description": "The users who will be allowed to read the reply content.", "values": ["everyone"]}, "nonreaders": {"values": []}, "signatures": {"description": "How your identity will be displayed with the above content.", "values-regex": "ICLR.cc/2019/Conference/Paper1338/AnonReviewer[0-9]+"}, "writers": {"description": "Users that may modify this record.", "values": ["ICLR.cc/2019/Conference"]}, "content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "required": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}}, "multiReply": false, "tcdate": 1552335925214, "tmdate": 1552335925214, "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "invitees": ["ICLR.cc/2019/Conference/Paper1338/Reviewers"], "noninvitees": [], "signatures": ["ICLR.cc/2019/Conference"]}}}], "count": 8}