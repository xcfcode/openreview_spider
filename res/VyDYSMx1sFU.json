{"notes": [{"id": "VyDYSMx1sFU", "original": "S1vbMivznmE", "number": 3559, "cdate": 1601308395441, "ddate": null, "tcdate": 1601308395441, "tmdate": 1614985707040, "tddate": null, "forum": "VyDYSMx1sFU", "replyto": null, "invitation": "ICLR.cc/2021/Conference/-/Blind_Submission", "content": {"title": "End-to-End on-device Federated Learning: A case study", "authorids": ["~Hongyi_Zhang4", "jan.bosch@chalmers.se", "helena.holmstrom.olsson@mau.se"], "authors": ["Hongyi Zhang", "Jan Bosch", "Helena Holmstr\u00f6m Olsson"], "keywords": ["Federated Learning", "Machine Learning", "End-to-End Learning", "Artificial Intelligence"], "abstract": "With the development of computation capability in devices, companies are eager to utilize ML/DL methods to improve their service quality. However, with traditional Machine Learning approaches, companies need to build up a powerful data center to collect data and perform centralized model training, which turns out to be expensive and inefficient. Federated Learning has been introduced to solve this challenge. Because of its characteristics such as model-only exchange and parallel training, the technique can not only preserve user data privacy but also accelerate model training speed. In this paper, we introduce an approach to end-to-end on-device Machine Learning by utilizing Federated Learning. We validate our approach with an important industrial use case, the wheel steering angle prediction in the field of autonomous driving. Our results show that Federated Learning can significantly improve the quality of local edge models and reach the same accuracy level as compared to the traditional centralized Machine Learning approach without its negative effects. Furthermore, Federated Learning can accelerate model training speed and reduce the communication overhead, which proves that this approach has great strength when deploying ML/DL components to real-world embedded systems.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "zhang|endtoend_ondevice_federated_learning_a_case_study", "pdf": "/pdf/357633ad7a55259bb296c391710bbd30428946ce.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=G_QrSXeNjG", "_bibtex": "@misc{\nzhang2021endtoend,\ntitle={End-to-End on-device Federated Learning: A case study},\nauthor={Hongyi Zhang and Jan Bosch and Helena Holmstr{\\\"o}m Olsson},\nyear={2021},\nurl={https://openreview.net/forum?id=VyDYSMx1sFU}\n}"}, "signatures": ["ICLR.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference"], "details": {"replyCount": 5, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"reply": {"readers": {"values-regex": ".*"}, "writers": {"values": ["ICLR.cc/2021/Conference"]}, "signatures": {"values": ["ICLR.cc/2021/Conference"]}, "content": {"authors": {"values": ["Anonymous"]}, "authorids": {"values-regex": ".*"}, "reviewed_version_(pdf)": {"required": false, "description": "Upload a PDF file that ends with .pdf", "value-regex": ".*"}}}, "signatures": ["ICLR.cc/2021/Conference"], "readers": ["everyone"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["~", "OpenReview.net/Support"], "tcdate": 1601308008205, "tmdate": 1614984599368, "id": "ICLR.cc/2021/Conference/-/Blind_Submission"}}, "tauthor": "OpenReview.net"}, {"id": "NFVC7kgzNHe", "original": null, "number": 1, "cdate": 1610040436571, "ddate": null, "tcdate": 1610040436571, "tmdate": 1610474037236, "tddate": null, "forum": "VyDYSMx1sFU", "replyto": "VyDYSMx1sFU", "invitation": "ICLR.cc/2021/Conference/Paper3559/-/Decision", "content": {"title": "Final Decision", "decision": "Reject", "comment": "This paper proposes the use of federated learning to the application of steering wheel prediction for autonomous driving. While the application is new and interesting, the reviewers felt that the approach and results were mostly empirical. I suggest that the authors improve the conceptual/algorithmic contribution of the paper in a revised draft. Another suggestion is to include a better explanation of hyper-parameter optimization used in the experiments. I hope that the reviewers' constructive comments will help the authors revise the draft adequately for submission to a future venue!"}, "signatures": ["ICLR.cc/2021/Conference/Program_Chairs"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference/Program_Chairs"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "End-to-End on-device Federated Learning: A case study", "authorids": ["~Hongyi_Zhang4", "jan.bosch@chalmers.se", "helena.holmstrom.olsson@mau.se"], "authors": ["Hongyi Zhang", "Jan Bosch", "Helena Holmstr\u00f6m Olsson"], "keywords": ["Federated Learning", "Machine Learning", "End-to-End Learning", "Artificial Intelligence"], "abstract": "With the development of computation capability in devices, companies are eager to utilize ML/DL methods to improve their service quality. However, with traditional Machine Learning approaches, companies need to build up a powerful data center to collect data and perform centralized model training, which turns out to be expensive and inefficient. Federated Learning has been introduced to solve this challenge. Because of its characteristics such as model-only exchange and parallel training, the technique can not only preserve user data privacy but also accelerate model training speed. In this paper, we introduce an approach to end-to-end on-device Machine Learning by utilizing Federated Learning. We validate our approach with an important industrial use case, the wheel steering angle prediction in the field of autonomous driving. Our results show that Federated Learning can significantly improve the quality of local edge models and reach the same accuracy level as compared to the traditional centralized Machine Learning approach without its negative effects. Furthermore, Federated Learning can accelerate model training speed and reduce the communication overhead, which proves that this approach has great strength when deploying ML/DL components to real-world embedded systems.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "zhang|endtoend_ondevice_federated_learning_a_case_study", "pdf": "/pdf/357633ad7a55259bb296c391710bbd30428946ce.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=G_QrSXeNjG", "_bibtex": "@misc{\nzhang2021endtoend,\ntitle={End-to-End on-device Federated Learning: A case study},\nauthor={Hongyi Zhang and Jan Bosch and Helena Holmstr{\\\"o}m Olsson},\nyear={2021},\nurl={https://openreview.net/forum?id=VyDYSMx1sFU}\n}"}, "tags": [], "invitation": {"reply": {"forum": "VyDYSMx1sFU", "replyto": "VyDYSMx1sFU", "readers": {"values": ["everyone"]}, "writers": {"values": ["ICLR.cc/2021/Conference/Program_Chairs"]}, "signatures": {"values": ["ICLR.cc/2021/Conference/Program_Chairs"]}, "content": {"title": {"value": "Final Decision"}, "decision": {"value-radio": ["Accept (Oral)", "Accept (Spotlight)", "Accept (Poster)", "Reject"]}, "comment": {"value-regex": "[\\S\\s]{0,50000}", "markdown": true}}}, "multiReply": false, "signatures": ["ICLR.cc/2021/Conference"], "readers": ["everyone"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Program_Chairs"], "tcdate": 1610040436559, "tmdate": 1610474037221, "id": "ICLR.cc/2021/Conference/Paper3559/-/Decision"}}}, {"id": "kt5JZTV0Z86", "original": null, "number": 1, "cdate": 1603665550729, "ddate": null, "tcdate": 1603665550729, "tmdate": 1607296902387, "tddate": null, "forum": "VyDYSMx1sFU", "replyto": "VyDYSMx1sFU", "invitation": "ICLR.cc/2021/Conference/Paper3559/-/Official_Review", "content": {"title": "Evaluation of on device federated learning for steering wheel angle prediction", "review": "The study evaluates federated learning (FL) in the context of steering wheel angle prediction, which is relevant for autonomous driving systems. Authors compare against two baselines a centrally-computed and locally-computed models and measure prediction error, training time and bandwidth cost. The work evaluates an existing approach and therefore its novelty and impact is limited. It does provide an interesting evaluation of FL for a relevant use case. Federated learning, as the authors indicate in the manuscript, is a promising approach for training ML applications while preserving user privacy, which is key to many industrial ML applications such as voice assistants and computer vision algorithms. For that reason, the impact of the paper is significant despite not being very original. The authors carry out a very simple study, but which seems sufficient to demonstrate that FL can have computational advantages, namely reduced training times and bandwidth costs. A challenging application of FL are ML applications that run on small devices that people carry around all the time, such as mobile phones and wearable devices.  In that scenario, there is the additional constraint that resources for training models on device are typically limited,  the smaller the device the more limited. An interesting extension of this study would be evaluate amount of computational resources used on the device as an additional evaluation metric. It would be great if the authors could add this metric to the present paper, but it could also be something for a followup publication, in other words, I do not think is needed for this paper to be published.   \n\n[Update after author's rebuttal]\nI do not see any reason to modify my rating. I also identified the self-citation , but it did not affect my rating or evaluation of the paper. ", "rating": "6: Marginally above acceptance threshold", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["ICLR.cc/2021/Conference/Paper3559/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper3559/AnonReviewer2"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "End-to-End on-device Federated Learning: A case study", "authorids": ["~Hongyi_Zhang4", "jan.bosch@chalmers.se", "helena.holmstrom.olsson@mau.se"], "authors": ["Hongyi Zhang", "Jan Bosch", "Helena Holmstr\u00f6m Olsson"], "keywords": ["Federated Learning", "Machine Learning", "End-to-End Learning", "Artificial Intelligence"], "abstract": "With the development of computation capability in devices, companies are eager to utilize ML/DL methods to improve their service quality. However, with traditional Machine Learning approaches, companies need to build up a powerful data center to collect data and perform centralized model training, which turns out to be expensive and inefficient. Federated Learning has been introduced to solve this challenge. Because of its characteristics such as model-only exchange and parallel training, the technique can not only preserve user data privacy but also accelerate model training speed. In this paper, we introduce an approach to end-to-end on-device Machine Learning by utilizing Federated Learning. We validate our approach with an important industrial use case, the wheel steering angle prediction in the field of autonomous driving. Our results show that Federated Learning can significantly improve the quality of local edge models and reach the same accuracy level as compared to the traditional centralized Machine Learning approach without its negative effects. Furthermore, Federated Learning can accelerate model training speed and reduce the communication overhead, which proves that this approach has great strength when deploying ML/DL components to real-world embedded systems.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "zhang|endtoend_ondevice_federated_learning_a_case_study", "pdf": "/pdf/357633ad7a55259bb296c391710bbd30428946ce.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=G_QrSXeNjG", "_bibtex": "@misc{\nzhang2021endtoend,\ntitle={End-to-End on-device Federated Learning: A case study},\nauthor={Hongyi Zhang and Jan Bosch and Helena Holmstr{\\\"o}m Olsson},\nyear={2021},\nurl={https://openreview.net/forum?id=VyDYSMx1sFU}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq . ***Please remember to file the Code-of-Ethics report. Once you submitted the review, a link to the report will be visible in the bottom right corner of your review.***", "required": true, "markdown": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}, "forum": "VyDYSMx1sFU", "replyto": "VyDYSMx1sFU", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"], "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper3559/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1607428800000, "duedate": 1606752000000, "multiReply": false, "readers": ["everyone"], "tcdate": 1602538073741, "tmdate": 1606915782810, "super": "ICLR.cc/2021/Conference/-/Official_Review", "signatures": ["OpenReview.net"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Paper3559/Reviewers", "OpenReview.net/Support"], "id": "ICLR.cc/2021/Conference/Paper3559/-/Official_Review"}}}, {"id": "8pP3s7gp_yX", "original": null, "number": 2, "cdate": 1603665930909, "ddate": null, "tcdate": 1603665930909, "tmdate": 1607243680156, "tddate": null, "forum": "VyDYSMx1sFU", "replyto": "VyDYSMx1sFU", "invitation": "ICLR.cc/2021/Conference/Paper3559/-/Official_Review", "content": {"title": "Nice case study for Federated Learning on autonomous driving application but no actual research proposed.", "review": "This paper presents a case study that applies Federated Learning for steering angle prediction in self-driving cars. All methods used have been previously proposed in the literature.\n\nPros:\n+ A case study for an industrial use of federated learning (in autonomous driving application).\n+ Results do show that Federated Learning can give accuracy close to a centralized model for this application but without having to send data to the server (thus saving training time and communication bandwidth requirements).\n\nCons:\n- No actual research contribution since nothing new is proposed in this paper.\n- While the training time and communication bandwidth savings are a good validation, this is not surprising since Federated Learning has been shown to have this benefit for many applications. \n\n========== UPDATE AFTER REBUTTAL ===========\nI have read the author's response. While the case study for industrial applications is important, it would probably be much more impactful if the same study was done on a much larger/realistic scale. For instance, right now it appears that each edge vehicle gets an already available dataset for federated learning, which may have been cleaned and preprocessed properly. For claiming a real industrial deployment/importance, it would have been great if the study was conducted with vehicles receiving real-time data from real vehicles which is prone to be extremely noisy (although the reviewer is not sure if this would be possible for regulatory reasons (e.g., if such learning experiments would be safe enough on real autonomous vehicles as these applications are safety-critical)). Currently, the paper neither has significant enough contributions from novelty side, nor from industrial deployment angle. Hence, as such, the paper cannot be accepted. Perhaps more application-oriented conferences maybe more suitable for this kind of work. \n\n", "rating": "4: Ok but not good enough - rejection", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["ICLR.cc/2021/Conference/Paper3559/AnonReviewer4"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper3559/AnonReviewer4"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "End-to-End on-device Federated Learning: A case study", "authorids": ["~Hongyi_Zhang4", "jan.bosch@chalmers.se", "helena.holmstrom.olsson@mau.se"], "authors": ["Hongyi Zhang", "Jan Bosch", "Helena Holmstr\u00f6m Olsson"], "keywords": ["Federated Learning", "Machine Learning", "End-to-End Learning", "Artificial Intelligence"], "abstract": "With the development of computation capability in devices, companies are eager to utilize ML/DL methods to improve their service quality. However, with traditional Machine Learning approaches, companies need to build up a powerful data center to collect data and perform centralized model training, which turns out to be expensive and inefficient. Federated Learning has been introduced to solve this challenge. Because of its characteristics such as model-only exchange and parallel training, the technique can not only preserve user data privacy but also accelerate model training speed. In this paper, we introduce an approach to end-to-end on-device Machine Learning by utilizing Federated Learning. We validate our approach with an important industrial use case, the wheel steering angle prediction in the field of autonomous driving. Our results show that Federated Learning can significantly improve the quality of local edge models and reach the same accuracy level as compared to the traditional centralized Machine Learning approach without its negative effects. Furthermore, Federated Learning can accelerate model training speed and reduce the communication overhead, which proves that this approach has great strength when deploying ML/DL components to real-world embedded systems.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "zhang|endtoend_ondevice_federated_learning_a_case_study", "pdf": "/pdf/357633ad7a55259bb296c391710bbd30428946ce.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=G_QrSXeNjG", "_bibtex": "@misc{\nzhang2021endtoend,\ntitle={End-to-End on-device Federated Learning: A case study},\nauthor={Hongyi Zhang and Jan Bosch and Helena Holmstr{\\\"o}m Olsson},\nyear={2021},\nurl={https://openreview.net/forum?id=VyDYSMx1sFU}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq . ***Please remember to file the Code-of-Ethics report. Once you submitted the review, a link to the report will be visible in the bottom right corner of your review.***", "required": true, "markdown": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}, "forum": "VyDYSMx1sFU", "replyto": "VyDYSMx1sFU", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"], "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper3559/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1607428800000, "duedate": 1606752000000, "multiReply": false, "readers": ["everyone"], "tcdate": 1602538073741, "tmdate": 1606915782810, "super": "ICLR.cc/2021/Conference/-/Official_Review", "signatures": ["OpenReview.net"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Paper3559/Reviewers", "OpenReview.net/Support"], "id": "ICLR.cc/2021/Conference/Paper3559/-/Official_Review"}}}, {"id": "Icsyeh_VTOk", "original": null, "number": 4, "cdate": 1603944323377, "ddate": null, "tcdate": 1603944323377, "tmdate": 1606930746640, "tddate": null, "forum": "VyDYSMx1sFU", "replyto": "VyDYSMx1sFU", "invitation": "ICLR.cc/2021/Conference/Paper3559/-/Official_Review", "content": {"title": "maybe consider other more application venues?", "review": "This paper applies federated learning to  steering wheel prediction for autonomous driving. \"Federated learning\" in this draft mainly refers to an on-device distributed training algorithm where each edge device hosts its private data and performs local updates (model training) and send the updates back to a central server to aggregate. More specifically, this paper uses the most well-known algorithm in federated learning, FedAvg (McMahan et al. 2017). \n\nPros\n+ The application is real and seems important. \n+ Distributed/federated learning makes sense for this application. \n\nCons\n- The main contributions of the draft are not clear. It looks to me such empirical studies of a well-known algorithm on a specific application will better fit a more application-oriented or system-oriented venue, e.g., CVPR, SysML. \n- How are the hyperparameters tuned for centralized and federated setting? \n- What are the hardwares on edge devices/vehicles, and what are the hardwares in datacenter for centralized training? The draft mentioned Tesla T4 GPUs, but it seems not clear exactly how much computation power has been used. \n- Could the authors clarify \"companies need to build up a powerful data center to collect data and perform centralized model training, which turns out to be expensive and inefficient. Federated Learning has been introduced to solve this challenge.\"? As far as I know, the primary motivation for federated learning is privacy protection. Edge devices has far less computation power and big communication barrier, why would it solve \"this challenge\"?\n- The following sentences seem to against the anonymous rules? \"Our previous research shows the challenges of deploying AI/ML components into a real-world industrial context. As we defined in \u201dEngineering AI Systems: A Research Agenda\u201d (Bosch et al., 2020), AI engineering refers to AI/ML-driven software development and deployment in production contexts. We found that the transition from prototype to the production-quality deployment of ML models proves to be challenging for many companies (L\u2019heureux et al., 2017b) (Lwakatare et al., 2019).\"\n\nSome minor improvement:\nThe abbreviation \u201cML/DL\u201d seems never introduced\nIt seems unnecessary to capitalized \u201cMachine Learning\u201d, \u201cFederated Learning\u201d. \nConsider cite the original FedAvg (McMahan et al. 2017) paper instead of (Li et al., 2019).\n\n====== post rebuttal ======\n\nI do not think the response addressed my concerns. I would strongly suggest authors reconsider the design choices where I raised questions. Note that these are not only clarification questions, but also fundamentals of machine learning and federated learning.\n", "rating": "4: Ok but not good enough - rejection", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["ICLR.cc/2021/Conference/Paper3559/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper3559/AnonReviewer1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "End-to-End on-device Federated Learning: A case study", "authorids": ["~Hongyi_Zhang4", "jan.bosch@chalmers.se", "helena.holmstrom.olsson@mau.se"], "authors": ["Hongyi Zhang", "Jan Bosch", "Helena Holmstr\u00f6m Olsson"], "keywords": ["Federated Learning", "Machine Learning", "End-to-End Learning", "Artificial Intelligence"], "abstract": "With the development of computation capability in devices, companies are eager to utilize ML/DL methods to improve their service quality. However, with traditional Machine Learning approaches, companies need to build up a powerful data center to collect data and perform centralized model training, which turns out to be expensive and inefficient. Federated Learning has been introduced to solve this challenge. Because of its characteristics such as model-only exchange and parallel training, the technique can not only preserve user data privacy but also accelerate model training speed. In this paper, we introduce an approach to end-to-end on-device Machine Learning by utilizing Federated Learning. We validate our approach with an important industrial use case, the wheel steering angle prediction in the field of autonomous driving. Our results show that Federated Learning can significantly improve the quality of local edge models and reach the same accuracy level as compared to the traditional centralized Machine Learning approach without its negative effects. Furthermore, Federated Learning can accelerate model training speed and reduce the communication overhead, which proves that this approach has great strength when deploying ML/DL components to real-world embedded systems.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "zhang|endtoend_ondevice_federated_learning_a_case_study", "pdf": "/pdf/357633ad7a55259bb296c391710bbd30428946ce.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=G_QrSXeNjG", "_bibtex": "@misc{\nzhang2021endtoend,\ntitle={End-to-End on-device Federated Learning: A case study},\nauthor={Hongyi Zhang and Jan Bosch and Helena Holmstr{\\\"o}m Olsson},\nyear={2021},\nurl={https://openreview.net/forum?id=VyDYSMx1sFU}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq . ***Please remember to file the Code-of-Ethics report. Once you submitted the review, a link to the report will be visible in the bottom right corner of your review.***", "required": true, "markdown": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}, "forum": "VyDYSMx1sFU", "replyto": "VyDYSMx1sFU", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"], "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper3559/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1607428800000, "duedate": 1606752000000, "multiReply": false, "readers": ["everyone"], "tcdate": 1602538073741, "tmdate": 1606915782810, "super": "ICLR.cc/2021/Conference/-/Official_Review", "signatures": ["OpenReview.net"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Paper3559/Reviewers", "OpenReview.net/Support"], "id": "ICLR.cc/2021/Conference/Paper3559/-/Official_Review"}}}, {"id": "PUTR6RM85_v", "original": null, "number": 3, "cdate": 1603862860777, "ddate": null, "tcdate": 1603862860777, "tmdate": 1605023978757, "tddate": null, "forum": "VyDYSMx1sFU", "replyto": "VyDYSMx1sFU", "invitation": "ICLR.cc/2021/Conference/Paper3559/-/Official_Review", "content": {"title": "An implementation of federated learning on a use case in autonomous driving. *The paper is not properly anonymized*", "review": "******************************************************************************\n\nThe paper is not properly anonymized. The intro refers to \u201cOur previous research\u201d and says \u201cAs we defined in Engineering AI Systems: A Research Agenda, (Bosch et al., 2020), \u2026 .\u201d As such it violates the anonymity policy. \n******************************************************************************\n\nThis paper describes end-to-end implementation of Federated Learning (FL) on a use case of steering wheel prediction in autonomous driving. It provides empirical evaluation on real-world autonomous driving datasets and shows improved performance compared to centralized learning methods. \n\nPros:\nIs it interesting to see an implementation of FL on a real-world use-case. The paper also does well in comparing different factors such as training time and bandwidth cost for FL and centralized training.\n\nCons:\nThe paper doesn\u2019t have enough technical depth to be accepted at ICLR and reads more like a report than a paper. It mainly describes the implementation of FL for a real-world application, which, although important, does not contribute to the field in terms of developing better algorithms or better understanding the current ones.  \n\nA large part of the experiment section describes the hardware features, network structure and training method in great details, which seems redundant or unnecessary for an ICLR submission. For example, section 4 reads \u201cThe weights of the CNN are adjusted using back propagation to enforce the model output as close as possible to the desired output.\u201d, which is obvious to most readers.  \n\nThere are also some statements in paper that are not quite scientific or concrete. For example, the intro reads \u201cdue to the characteristics of Federated Learning, on-device training becomes possible.\u201d This is not true as on-device training is not becoming possible due to FL, though FL certainly requires it. \n", "rating": "2: Strong rejection", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}, "signatures": ["ICLR.cc/2021/Conference/Paper3559/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper3559/AnonReviewer3"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "End-to-End on-device Federated Learning: A case study", "authorids": ["~Hongyi_Zhang4", "jan.bosch@chalmers.se", "helena.holmstrom.olsson@mau.se"], "authors": ["Hongyi Zhang", "Jan Bosch", "Helena Holmstr\u00f6m Olsson"], "keywords": ["Federated Learning", "Machine Learning", "End-to-End Learning", "Artificial Intelligence"], "abstract": "With the development of computation capability in devices, companies are eager to utilize ML/DL methods to improve their service quality. However, with traditional Machine Learning approaches, companies need to build up a powerful data center to collect data and perform centralized model training, which turns out to be expensive and inefficient. Federated Learning has been introduced to solve this challenge. Because of its characteristics such as model-only exchange and parallel training, the technique can not only preserve user data privacy but also accelerate model training speed. In this paper, we introduce an approach to end-to-end on-device Machine Learning by utilizing Federated Learning. We validate our approach with an important industrial use case, the wheel steering angle prediction in the field of autonomous driving. Our results show that Federated Learning can significantly improve the quality of local edge models and reach the same accuracy level as compared to the traditional centralized Machine Learning approach without its negative effects. Furthermore, Federated Learning can accelerate model training speed and reduce the communication overhead, which proves that this approach has great strength when deploying ML/DL components to real-world embedded systems.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "zhang|endtoend_ondevice_federated_learning_a_case_study", "pdf": "/pdf/357633ad7a55259bb296c391710bbd30428946ce.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=G_QrSXeNjG", "_bibtex": "@misc{\nzhang2021endtoend,\ntitle={End-to-End on-device Federated Learning: A case study},\nauthor={Hongyi Zhang and Jan Bosch and Helena Holmstr{\\\"o}m Olsson},\nyear={2021},\nurl={https://openreview.net/forum?id=VyDYSMx1sFU}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq . ***Please remember to file the Code-of-Ethics report. Once you submitted the review, a link to the report will be visible in the bottom right corner of your review.***", "required": true, "markdown": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}, "forum": "VyDYSMx1sFU", "replyto": "VyDYSMx1sFU", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"], "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper3559/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1607428800000, "duedate": 1606752000000, "multiReply": false, "readers": ["everyone"], "tcdate": 1602538073741, "tmdate": 1606915782810, "super": "ICLR.cc/2021/Conference/-/Official_Review", "signatures": ["OpenReview.net"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Paper3559/Reviewers", "OpenReview.net/Support"], "id": "ICLR.cc/2021/Conference/Paper3559/-/Official_Review"}}}], "count": 6}