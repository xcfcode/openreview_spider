{"notes": [{"id": "BJxt2aVFPr", "original": "r1loRQl_PS", "number": 790, "cdate": 1569439153437, "ddate": null, "tcdate": 1569439153437, "tmdate": 1577168289307, "tddate": null, "forum": "BJxt2aVFPr", "replyto": null, "invitation": "ICLR.cc/2020/Conference/-/Blind_Submission", "content": {"title": "Optimizing Data Usage via Differentiable Rewards", "authors": ["Xinyi Wang", "Hieu Pham", "Paul Michel", "Antonios Anastasopoulos", "Graham Neubig", "Jaime Carbonell"], "authorids": ["xinyiw1@cs.cmu.edu", "hyhieu@cmu.edu", "pmichel1@cs.cmu.edu", "aanastas@andrew.cmu.edu", "gneubig@cs.cmu.edu", "jgc@cs.cmu.edu"], "keywords": ["data selection", "multilingual neural machine translation", "data usage optimzation", "transfer learning", "classification"], "abstract": "To acquire a new skill, humans learn better and faster if a tutor, based on their current knowledge level, informs them of how much attention they should pay to particular content or practice problems. Similarly, a machine learning model could potentially be trained better with a scorer that \u201cadapts\u201d to its current learning state and estimates the importance of each training data instance. Training such an adaptive scorer efficiently is a challenging problem; in order to precisely quantify the effect of a data instance at a given time during the training, it is typically necessary to first complete the entire training process. To efficiently optimize data usage, we propose a reinforcement learning approach called Differentiable Data Selection (DDS). In DDS, we formulate a scorer network as a learnable function of the training data, which can be efficiently updated along with the main model being trained. Specifically, DDS updates the scorer with an intuitive reward signal: it should up-weigh the data that has a similar gradient with a dev set upon which we would finally like to perform well. Without significant computing overhead, DDS delivers strong and consistent improvements over several strong baselines on two very different tasks of machine translation and image classification.", "pdf": "/pdf/3d572357f0598b1c73d55e8cf8bb64c44ab2f5ea.pdf", "paperhash": "wang|optimizing_data_usage_via_differentiable_rewards", "original_pdf": "/attachment/b9308ec7cfbe1d03bb9d1c761d705078d06d496c.pdf", "_bibtex": "@misc{\nwang2020optimizing,\ntitle={Optimizing Data Usage via Differentiable Rewards},\nauthor={Xinyi Wang and Hieu Pham and Paul Michel and Antonios Anastasopoulos and Graham Neubig and Jaime Carbonell},\nyear={2020},\nurl={https://openreview.net/forum?id=BJxt2aVFPr}\n}"}, "signatures": ["ICLR.cc/2020/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference"], "details": {"replyCount": 9, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"reply": {"readers": {"values-regex": ".*"}, "writers": {"values": ["ICLR.cc/2020/Conference"]}, "signatures": {"values": ["ICLR.cc/2020/Conference"]}, "content": {"spotlight_video": {"value-regex": ".*"}, "full_presentation_video": {"value-regex": ".*"}, "original_pdf": {"required": false, "description": "Upload a PDF file that ends with .pdf", "value-regex": ".*"}, "appendix": {"value-regex": ".*"}, "authorids": {"values-regex": ".*"}, "poster": {"value-regex": ".*"}, "authors": {"values": ["Anonymous"]}, "slides": {"value-regex": ".*"}}}, "final": [], "signatures": ["ICLR.cc/2020/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference"], "noninvitees": [], "tcdate": 1569271260237, "tmdate": 1593459412141, "id": "ICLR.cc/2020/Conference/-/Blind_Submission"}}, "tauthor": "OpenReview.net"}, {"id": "O9HULKUsGf", "original": null, "number": 1, "cdate": 1576798706132, "ddate": null, "tcdate": 1576798706132, "tmdate": 1576800930028, "tddate": null, "forum": "BJxt2aVFPr", "replyto": "BJxt2aVFPr", "invitation": "ICLR.cc/2020/Conference/Paper790/-/Decision", "content": {"decision": "Reject", "comment": "The paper proposes an iterative learning method that jointly trains both a model and a scorer network that places a non-uniform weights on data points, which estimates the importance of each data point for training.  This leads to significant improvement on several benchmarks.  The reviewers mostly agreed that the approach is novel and that the benchmark results were impressive, especially on Imagenet.  There were both clarity issues about methodology and experiments, as well as concerns about several technical issues.  The reviewers felt that the rebuttal resolved the majority of minor technical issues, but did not sufficiently clarify the more significant methodological concerns. Thus, I recommend rejection at this time.", "title": "Paper Decision"}, "signatures": ["ICLR.cc/2020/Conference/Program_Chairs"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Program_Chairs"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Optimizing Data Usage via Differentiable Rewards", "authors": ["Xinyi Wang", "Hieu Pham", "Paul Michel", "Antonios Anastasopoulos", "Graham Neubig", "Jaime Carbonell"], "authorids": ["xinyiw1@cs.cmu.edu", "hyhieu@cmu.edu", "pmichel1@cs.cmu.edu", "aanastas@andrew.cmu.edu", "gneubig@cs.cmu.edu", "jgc@cs.cmu.edu"], "keywords": ["data selection", "multilingual neural machine translation", "data usage optimzation", "transfer learning", "classification"], "abstract": "To acquire a new skill, humans learn better and faster if a tutor, based on their current knowledge level, informs them of how much attention they should pay to particular content or practice problems. Similarly, a machine learning model could potentially be trained better with a scorer that \u201cadapts\u201d to its current learning state and estimates the importance of each training data instance. Training such an adaptive scorer efficiently is a challenging problem; in order to precisely quantify the effect of a data instance at a given time during the training, it is typically necessary to first complete the entire training process. To efficiently optimize data usage, we propose a reinforcement learning approach called Differentiable Data Selection (DDS). In DDS, we formulate a scorer network as a learnable function of the training data, which can be efficiently updated along with the main model being trained. Specifically, DDS updates the scorer with an intuitive reward signal: it should up-weigh the data that has a similar gradient with a dev set upon which we would finally like to perform well. Without significant computing overhead, DDS delivers strong and consistent improvements over several strong baselines on two very different tasks of machine translation and image classification.", "pdf": "/pdf/3d572357f0598b1c73d55e8cf8bb64c44ab2f5ea.pdf", "paperhash": "wang|optimizing_data_usage_via_differentiable_rewards", "original_pdf": "/attachment/b9308ec7cfbe1d03bb9d1c761d705078d06d496c.pdf", "_bibtex": "@misc{\nwang2020optimizing,\ntitle={Optimizing Data Usage via Differentiable Rewards},\nauthor={Xinyi Wang and Hieu Pham and Paul Michel and Antonios Anastasopoulos and Graham Neubig and Jaime Carbonell},\nyear={2020},\nurl={https://openreview.net/forum?id=BJxt2aVFPr}\n}"}, "tags": [], "invitation": {"reply": {"writers": {"description": "How your identity will be displayed.", "values-regex": ["ICLR.cc/2020/Conference/Program_Chairs"]}, "signatures": {"values": ["ICLR.cc/2020/Conference/Program_Chairs"], "description": "How your identity will be displayed."}, "content": {"decision": {"value-radio": ["Accept (Spotlight)", "Accept (Talk)", "Accept (Poster)", "Reject"], "description": "Decision", "required": true, "order": 2}, "title": {"value": "Paper Decision", "required": true, "order": 1}, "comment": {"value-regex": "[\\S\\s]{0,5000}", "description": "", "required": false, "order": 3}}, "forum": "BJxt2aVFPr", "replyto": "BJxt2aVFPr", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}}, "expdate": 1576854540000, "duedate": 1576853940000, "multiReply": false, "readers": ["everyone"], "invitees": ["ICLR.cc/2020/Conference/Program_Chairs"], "tcdate": 1576795723504, "tmdate": 1576800274991, "super": "ICLR.cc/2020/Conference/-/Decision", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper790/-/Decision"}}}, {"id": "rkgz2PwHYB", "original": null, "number": 1, "cdate": 1571284906456, "ddate": null, "tcdate": 1571284906456, "tmdate": 1574137380378, "tddate": null, "forum": "BJxt2aVFPr", "replyto": "BJxt2aVFPr", "invitation": "ICLR.cc/2020/Conference/Paper790/-/Official_Review", "content": {"experience_assessment": "I have read many papers in this area.", "rating": "3: Weak Reject", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "title": "Official Blind Review #1", "review": "The paper proposes an iterative method that jointly trains the model and a scorer network that places a non-uniform distribution over data sets.  The paper proposes a gradient method to learn the scorer network based on reinforcement learning, which is novel as to what the reviewer knows.\n\nThere are several concerns/questions:\n\n1) The paper doesn\u2019t define the D_{dev} clearly. How is D_{dev} chosen? Is it a subset of D_{train}? \n\n2) In section 2.1, why \u201csmaller development set D_{dev} is much closer to the P_{test}(X,Y)\u201d? P_{test}(X,Y) is supposed to be not observed during training?\n\n3) In Eq (5), if D_{dev} is s subset of D_{train}, if \\theta* is the minimal of J, it means the gradient \nat  \\theta* is 0. To calculate the gradient of J with respect to \\psi, by chain rule, it need to calculate gradient to \\theta* first then \\theta* to \\psi. If gradient of \\theta* is 0, the product is also 0? So the \\psi will not be updated if D_{dev}  is sufficiently similar to D_{train} ?\n\n4) In Section 2.3, it omits the second order Hessian term. How does that influence the performance? \n\n5) it mentions \u201cwithout significant computing overhead\u201c in abstract, which is not demonstrated elsewhere.\n\n6) In the experiments, table 1, it seems the major improvement comes from retrain and TCS rather than DDS? In figure 3, it is better to show the weights of an image without DDS and comparing that with DDS.\n\n7) The paper contains many typos such as Eqn.11 is not defined in the main paper, the \u201cEqn ??\u201d Appears in the appendix, \u201ctha minimizes\u201d etc.\n\nIn general, the idea of the paper is natural and the results seem promising. I am looking forward to the reply to my questions/concerns. \n\n#############\n\nI have read the author's feedback. I think the clarity of both methodology and experiment does not reach the acceptance level and would maintain my current rating. \n", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory."}, "signatures": ["ICLR.cc/2020/Conference/Paper790/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper790/AnonReviewer1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Optimizing Data Usage via Differentiable Rewards", "authors": ["Xinyi Wang", "Hieu Pham", "Paul Michel", "Antonios Anastasopoulos", "Graham Neubig", "Jaime Carbonell"], "authorids": ["xinyiw1@cs.cmu.edu", "hyhieu@cmu.edu", "pmichel1@cs.cmu.edu", "aanastas@andrew.cmu.edu", "gneubig@cs.cmu.edu", "jgc@cs.cmu.edu"], "keywords": ["data selection", "multilingual neural machine translation", "data usage optimzation", "transfer learning", "classification"], "abstract": "To acquire a new skill, humans learn better and faster if a tutor, based on their current knowledge level, informs them of how much attention they should pay to particular content or practice problems. Similarly, a machine learning model could potentially be trained better with a scorer that \u201cadapts\u201d to its current learning state and estimates the importance of each training data instance. Training such an adaptive scorer efficiently is a challenging problem; in order to precisely quantify the effect of a data instance at a given time during the training, it is typically necessary to first complete the entire training process. To efficiently optimize data usage, we propose a reinforcement learning approach called Differentiable Data Selection (DDS). In DDS, we formulate a scorer network as a learnable function of the training data, which can be efficiently updated along with the main model being trained. Specifically, DDS updates the scorer with an intuitive reward signal: it should up-weigh the data that has a similar gradient with a dev set upon which we would finally like to perform well. Without significant computing overhead, DDS delivers strong and consistent improvements over several strong baselines on two very different tasks of machine translation and image classification.", "pdf": "/pdf/3d572357f0598b1c73d55e8cf8bb64c44ab2f5ea.pdf", "paperhash": "wang|optimizing_data_usage_via_differentiable_rewards", "original_pdf": "/attachment/b9308ec7cfbe1d03bb9d1c761d705078d06d496c.pdf", "_bibtex": "@misc{\nwang2020optimizing,\ntitle={Optimizing Data Usage via Differentiable Rewards},\nauthor={Xinyi Wang and Hieu Pham and Paul Michel and Antonios Anastasopoulos and Graham Neubig and Jaime Carbonell},\nyear={2020},\nurl={https://openreview.net/forum?id=BJxt2aVFPr}\n}"}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "BJxt2aVFPr", "replyto": "BJxt2aVFPr", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper790/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper790/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1575509791284, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper790/Reviewers"], "noninvitees": [], "tcdate": 1570237747035, "tmdate": 1575509791297, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper790/-/Official_Review"}}}, {"id": "HklQA0wciB", "original": null, "number": 5, "cdate": 1573711562696, "ddate": null, "tcdate": 1573711562696, "tmdate": 1573711562696, "tddate": null, "forum": "BJxt2aVFPr", "replyto": "Byed72zfiS", "invitation": "ICLR.cc/2020/Conference/Paper790/-/Official_Comment", "content": {"title": "Response to the authors", "comment": "Thank you for your response - I read through your note to Reviewer 1. I stick to my current assessment and would defer to other reviewers/AC towards the decision. Thanks!"}, "signatures": ["ICLR.cc/2020/Conference/Paper790/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper790/AnonReviewer2", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Optimizing Data Usage via Differentiable Rewards", "authors": ["Xinyi Wang", "Hieu Pham", "Paul Michel", "Antonios Anastasopoulos", "Graham Neubig", "Jaime Carbonell"], "authorids": ["xinyiw1@cs.cmu.edu", "hyhieu@cmu.edu", "pmichel1@cs.cmu.edu", "aanastas@andrew.cmu.edu", "gneubig@cs.cmu.edu", "jgc@cs.cmu.edu"], "keywords": ["data selection", "multilingual neural machine translation", "data usage optimzation", "transfer learning", "classification"], "abstract": "To acquire a new skill, humans learn better and faster if a tutor, based on their current knowledge level, informs them of how much attention they should pay to particular content or practice problems. Similarly, a machine learning model could potentially be trained better with a scorer that \u201cadapts\u201d to its current learning state and estimates the importance of each training data instance. Training such an adaptive scorer efficiently is a challenging problem; in order to precisely quantify the effect of a data instance at a given time during the training, it is typically necessary to first complete the entire training process. To efficiently optimize data usage, we propose a reinforcement learning approach called Differentiable Data Selection (DDS). In DDS, we formulate a scorer network as a learnable function of the training data, which can be efficiently updated along with the main model being trained. Specifically, DDS updates the scorer with an intuitive reward signal: it should up-weigh the data that has a similar gradient with a dev set upon which we would finally like to perform well. Without significant computing overhead, DDS delivers strong and consistent improvements over several strong baselines on two very different tasks of machine translation and image classification.", "pdf": "/pdf/3d572357f0598b1c73d55e8cf8bb64c44ab2f5ea.pdf", "paperhash": "wang|optimizing_data_usage_via_differentiable_rewards", "original_pdf": "/attachment/b9308ec7cfbe1d03bb9d1c761d705078d06d496c.pdf", "_bibtex": "@misc{\nwang2020optimizing,\ntitle={Optimizing Data Usage via Differentiable Rewards},\nauthor={Xinyi Wang and Hieu Pham and Paul Michel and Antonios Anastasopoulos and Graham Neubig and Jaime Carbonell},\nyear={2020},\nurl={https://openreview.net/forum?id=BJxt2aVFPr}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "BJxt2aVFPr", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper790/Authors", "ICLR.cc/2020/Conference/Paper790/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper790/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper790/Reviewers", "ICLR.cc/2020/Conference/Paper790/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper790/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper790/Authors|ICLR.cc/2020/Conference/Paper790/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504166178, "tmdate": 1576860531589, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper790/Authors", "ICLR.cc/2020/Conference/Paper790/Reviewers", "ICLR.cc/2020/Conference/Paper790/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper790/-/Official_Comment"}}}, {"id": "Byed72zfiS", "original": null, "number": 4, "cdate": 1573166111730, "ddate": null, "tcdate": 1573166111730, "tmdate": 1573167089592, "tddate": null, "forum": "BJxt2aVFPr", "replyto": "r1lqmp15YS", "invitation": "ICLR.cc/2020/Conference/Paper790/-/Official_Comment", "content": {"title": "Response to reviewer #2", "comment": "We thank the reviewer for providing the feedback and suggestions. Please see our response to Reviewer #1, question 4). We have also updated the paper to add some clarifications. We would really appreciate if you could check whether our response has cleared your concern, and that you could consider improving the overall assessment. We would love to continue the discussion and make improvements to our paper. "}, "signatures": ["ICLR.cc/2020/Conference/Paper790/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper790/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Optimizing Data Usage via Differentiable Rewards", "authors": ["Xinyi Wang", "Hieu Pham", "Paul Michel", "Antonios Anastasopoulos", "Graham Neubig", "Jaime Carbonell"], "authorids": ["xinyiw1@cs.cmu.edu", "hyhieu@cmu.edu", "pmichel1@cs.cmu.edu", "aanastas@andrew.cmu.edu", "gneubig@cs.cmu.edu", "jgc@cs.cmu.edu"], "keywords": ["data selection", "multilingual neural machine translation", "data usage optimzation", "transfer learning", "classification"], "abstract": "To acquire a new skill, humans learn better and faster if a tutor, based on their current knowledge level, informs them of how much attention they should pay to particular content or practice problems. Similarly, a machine learning model could potentially be trained better with a scorer that \u201cadapts\u201d to its current learning state and estimates the importance of each training data instance. Training such an adaptive scorer efficiently is a challenging problem; in order to precisely quantify the effect of a data instance at a given time during the training, it is typically necessary to first complete the entire training process. To efficiently optimize data usage, we propose a reinforcement learning approach called Differentiable Data Selection (DDS). In DDS, we formulate a scorer network as a learnable function of the training data, which can be efficiently updated along with the main model being trained. Specifically, DDS updates the scorer with an intuitive reward signal: it should up-weigh the data that has a similar gradient with a dev set upon which we would finally like to perform well. Without significant computing overhead, DDS delivers strong and consistent improvements over several strong baselines on two very different tasks of machine translation and image classification.", "pdf": "/pdf/3d572357f0598b1c73d55e8cf8bb64c44ab2f5ea.pdf", "paperhash": "wang|optimizing_data_usage_via_differentiable_rewards", "original_pdf": "/attachment/b9308ec7cfbe1d03bb9d1c761d705078d06d496c.pdf", "_bibtex": "@misc{\nwang2020optimizing,\ntitle={Optimizing Data Usage via Differentiable Rewards},\nauthor={Xinyi Wang and Hieu Pham and Paul Michel and Antonios Anastasopoulos and Graham Neubig and Jaime Carbonell},\nyear={2020},\nurl={https://openreview.net/forum?id=BJxt2aVFPr}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "BJxt2aVFPr", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper790/Authors", "ICLR.cc/2020/Conference/Paper790/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper790/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper790/Reviewers", "ICLR.cc/2020/Conference/Paper790/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper790/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper790/Authors|ICLR.cc/2020/Conference/Paper790/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504166178, "tmdate": 1576860531589, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper790/Authors", "ICLR.cc/2020/Conference/Paper790/Reviewers", "ICLR.cc/2020/Conference/Paper790/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper790/-/Official_Comment"}}}, {"id": "BygqK5GfiB", "original": null, "number": 1, "cdate": 1573165697746, "ddate": null, "tcdate": 1573165697746, "tmdate": 1573166712967, "tddate": null, "forum": "BJxt2aVFPr", "replyto": "Skgt9dG-9H", "invitation": "ICLR.cc/2020/Conference/Paper790/-/Official_Comment", "content": {"title": "response to reviewer #3", "comment": "We thank the reviewer for providing many good suggestions and questions. We have addressed your concerns here and updated the paper with some clarifications. We would appreciate if you could check our response and revisions (and if these have indeed clarified the concerns, revise the overall assessment). We would also be happy to continue the discussion and make any additional modifications as deemed necessary.\n\nreviewer #3 question1: scoring network architecture\n\nresponse:\nWe are sorry for the lack of clarity with respect to this! This was simply an oversight.\n\nFor image classification, we use an identical network architecture with the main model, but with independent weights and a regressor to predict the score instead of a classifier to predict image classes. For the multilingual NMT experiments, since we only want to model a simple distribution over n training languages, we use a fully connected 2-layer perceptron network. For each target sentence and its corresponding source sentences, the input feature is a n-dimensional vector of 0 and 1, where 1 indicates a source language exists for the given target sentence. We have updated the image classification and NMT instantiation section, as well as the appendix, with clarifications of the network structure, and will release our code once the paper is accepted. \n\n\nreviewer #3 question2: The authors report that their method takes 1.5x to 2x longer to run than the uniform baseline. Yet, they ran all methods for the same number of steps / epochs. It seems to me that a fairer comparison might be letting all methods enjoy the same total budget measure roughly by wall time.\n\nresponse:\nThe main objective of DDS is to improve model performance, while remaining much simpler and more efficient than other methods that optimize a data selector using reinforcement learning that require multiple independent training runs. For example, in the IMDB movie review experiment in  [1], the data filtering agent is also trained for 200 episode, where each episode uses around 40% of the whole dataset, requiring a total of 80x more training time than a single training run. Therefore, the 1.5-2x increase in time afforded by DDS is much more manageable.\n\nFor image classification, training the standard baseline for longer does not help, since the main model will start to overfit, which indicates that spending more time on the baseline would not have a positive effect.\n\nreviewer #3 question3:  I didn't follow why the computation of the per example gradient grad l(x_i, y_i, theta_t-1) is so onerous. Isn't that computed on line 5 already?\n\nresponse:\nIn practice, a single gradient is computed with respect to a mini-batch of training data of size n to improve computational efficiency. However, using the per-example gradient requires one to compute the gradient for each example in a batch, which essentially slows down training by a factor of n. Therefore, we propose the simplification in Eqn. 7 to compute the per example gradient.\n\n\n[1] Learning what data to learn https://arxiv.org/pdf/1702.08635.pdf\n"}, "signatures": ["ICLR.cc/2020/Conference/Paper790/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper790/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Optimizing Data Usage via Differentiable Rewards", "authors": ["Xinyi Wang", "Hieu Pham", "Paul Michel", "Antonios Anastasopoulos", "Graham Neubig", "Jaime Carbonell"], "authorids": ["xinyiw1@cs.cmu.edu", "hyhieu@cmu.edu", "pmichel1@cs.cmu.edu", "aanastas@andrew.cmu.edu", "gneubig@cs.cmu.edu", "jgc@cs.cmu.edu"], "keywords": ["data selection", "multilingual neural machine translation", "data usage optimzation", "transfer learning", "classification"], "abstract": "To acquire a new skill, humans learn better and faster if a tutor, based on their current knowledge level, informs them of how much attention they should pay to particular content or practice problems. Similarly, a machine learning model could potentially be trained better with a scorer that \u201cadapts\u201d to its current learning state and estimates the importance of each training data instance. Training such an adaptive scorer efficiently is a challenging problem; in order to precisely quantify the effect of a data instance at a given time during the training, it is typically necessary to first complete the entire training process. To efficiently optimize data usage, we propose a reinforcement learning approach called Differentiable Data Selection (DDS). In DDS, we formulate a scorer network as a learnable function of the training data, which can be efficiently updated along with the main model being trained. Specifically, DDS updates the scorer with an intuitive reward signal: it should up-weigh the data that has a similar gradient with a dev set upon which we would finally like to perform well. Without significant computing overhead, DDS delivers strong and consistent improvements over several strong baselines on two very different tasks of machine translation and image classification.", "pdf": "/pdf/3d572357f0598b1c73d55e8cf8bb64c44ab2f5ea.pdf", "paperhash": "wang|optimizing_data_usage_via_differentiable_rewards", "original_pdf": "/attachment/b9308ec7cfbe1d03bb9d1c761d705078d06d496c.pdf", "_bibtex": "@misc{\nwang2020optimizing,\ntitle={Optimizing Data Usage via Differentiable Rewards},\nauthor={Xinyi Wang and Hieu Pham and Paul Michel and Antonios Anastasopoulos and Graham Neubig and Jaime Carbonell},\nyear={2020},\nurl={https://openreview.net/forum?id=BJxt2aVFPr}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "BJxt2aVFPr", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper790/Authors", "ICLR.cc/2020/Conference/Paper790/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper790/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper790/Reviewers", "ICLR.cc/2020/Conference/Paper790/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper790/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper790/Authors|ICLR.cc/2020/Conference/Paper790/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504166178, "tmdate": 1576860531589, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper790/Authors", "ICLR.cc/2020/Conference/Paper790/Reviewers", "ICLR.cc/2020/Conference/Paper790/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper790/-/Official_Comment"}}}, {"id": "BJerJhMGiB", "original": null, "number": 3, "cdate": 1573166044562, "ddate": null, "tcdate": 1573166044562, "tmdate": 1573166044562, "tddate": null, "forum": "BJxt2aVFPr", "replyto": "Byl59sfzjB", "invitation": "ICLR.cc/2020/Conference/Paper790/-/Official_Comment", "content": {"title": "Continue response to Reviewer #1", "comment": "Reviewer #1 question 4): In Section 2.3, it omits the second order Hessian term. How does that influence the performance? \n\nResponse:\nOur gradient derivation in Eqn. 6 uses the Markov assumption that in the previous step $\\psi_{t-1}$ is already updated with regard to $\\theta_{t-1}$, so the effect of $\\psi$ on $\\theta_{t-1}$ is likely to be minimal. This assumption can simplify and speed up computation. Moreover, this allows us to have a natural interpretation of the update rule for the data scorer: it should up-weight the training data that have similar gradient direction with the dev data. \n\nThe use of the Markov assumption is based on its use and empirical success in previous work on bi-level optimization, such as Hyper Gradient Descent [1] and many others. Of course, this is a simplifying assumption, but we believe that our empirical results show that the proposed method is useful nonetheless.\n\nRelaxing this assumption would be an interesting avenue for future work. However at the same time how to do so without resulting in large increases in complexity, both with respect to difficulty in implementation,and with respect to computation/memory complexity, is a challenge that would require additional methodological advantages beyond the scope of the current work.\n\n\nReviewer #1 question 5): it mentions \u201cwithout significant computing overhead\u201c in abstract, which is not demonstrated elsewhere.\n\nResponse:\nIn Section 4.2, we describe the nominal increase in training time for DDS. Please see our full response to Reviewer #3, Question 2.\n\nReviewer #1 question 6) In the experiments, table 1, it seems the major improvement comes from retrain and TCS rather than DDS? In figure 3, it is better to show the weights of image without DDS and comparing that with DDS.\n\nResponse:\nIn table 1, the retrained-DDS is still using DDS. We train a scorer with the model until convergence using DDS, then reinitialize the model and train both the scorer and the model again using DDS. Essentially, the first pass of the DDS training moves the scorer parameters to have a good prior distribution over the training data, so that the second DDS training pass is able to improve even further. \nFor the multilingual training, TCS+DDS simply initializes the scorer distribution with the TCS distribution before training using DDS. We compare TCS+DDS with the best baseline, including using only TCS. This shows that DDS brings significant gains over TCS for all four languages.\nThe description of retrained-DDS and TCS+DDS can be found at the end of section 4.1 In the paper.\n\nReviewer #1 question 7): The paper contains many typos such as Eqn.11 is not defined in main paper, the \u201cEqn ??\u201d Appears in appendix, \u201ctha minimizes\u201d etc.\n\nResponse:\nThank you very much for pointing out the typos and providing other good feedback. We have corrected the typos and updated the paper along with the appendix.  \n\n[1] Online learning rate adaptation with hypergradient descent  https://arxiv.org/abs/1703.04782"}, "signatures": ["ICLR.cc/2020/Conference/Paper790/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper790/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Optimizing Data Usage via Differentiable Rewards", "authors": ["Xinyi Wang", "Hieu Pham", "Paul Michel", "Antonios Anastasopoulos", "Graham Neubig", "Jaime Carbonell"], "authorids": ["xinyiw1@cs.cmu.edu", "hyhieu@cmu.edu", "pmichel1@cs.cmu.edu", "aanastas@andrew.cmu.edu", "gneubig@cs.cmu.edu", "jgc@cs.cmu.edu"], "keywords": ["data selection", "multilingual neural machine translation", "data usage optimzation", "transfer learning", "classification"], "abstract": "To acquire a new skill, humans learn better and faster if a tutor, based on their current knowledge level, informs them of how much attention they should pay to particular content or practice problems. Similarly, a machine learning model could potentially be trained better with a scorer that \u201cadapts\u201d to its current learning state and estimates the importance of each training data instance. Training such an adaptive scorer efficiently is a challenging problem; in order to precisely quantify the effect of a data instance at a given time during the training, it is typically necessary to first complete the entire training process. To efficiently optimize data usage, we propose a reinforcement learning approach called Differentiable Data Selection (DDS). In DDS, we formulate a scorer network as a learnable function of the training data, which can be efficiently updated along with the main model being trained. Specifically, DDS updates the scorer with an intuitive reward signal: it should up-weigh the data that has a similar gradient with a dev set upon which we would finally like to perform well. Without significant computing overhead, DDS delivers strong and consistent improvements over several strong baselines on two very different tasks of machine translation and image classification.", "pdf": "/pdf/3d572357f0598b1c73d55e8cf8bb64c44ab2f5ea.pdf", "paperhash": "wang|optimizing_data_usage_via_differentiable_rewards", "original_pdf": "/attachment/b9308ec7cfbe1d03bb9d1c761d705078d06d496c.pdf", "_bibtex": "@misc{\nwang2020optimizing,\ntitle={Optimizing Data Usage via Differentiable Rewards},\nauthor={Xinyi Wang and Hieu Pham and Paul Michel and Antonios Anastasopoulos and Graham Neubig and Jaime Carbonell},\nyear={2020},\nurl={https://openreview.net/forum?id=BJxt2aVFPr}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "BJxt2aVFPr", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper790/Authors", "ICLR.cc/2020/Conference/Paper790/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper790/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper790/Reviewers", "ICLR.cc/2020/Conference/Paper790/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper790/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper790/Authors|ICLR.cc/2020/Conference/Paper790/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504166178, "tmdate": 1576860531589, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper790/Authors", "ICLR.cc/2020/Conference/Paper790/Reviewers", "ICLR.cc/2020/Conference/Paper790/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper790/-/Official_Comment"}}}, {"id": "Byl59sfzjB", "original": null, "number": 2, "cdate": 1573165969547, "ddate": null, "tcdate": 1573165969547, "tmdate": 1573165969547, "tddate": null, "forum": "BJxt2aVFPr", "replyto": "rkgz2PwHYB", "invitation": "ICLR.cc/2020/Conference/Paper790/-/Official_Comment", "content": {"title": "Response to reviewer #1", "comment": "Thank you very much for providing many pieces of good feedback and clarification questions. We believe that in both the response and the revised draft we have clarified or rectified all of the reservations that were stated in the original review. We would appreciate if you could check our response and revisions (and if these have indeed clarified the concerns, revise the overall assessment). We would also be happy to continue the discussion and make any additional modifications as deemed necessary.\n\nReviewer #1 question 1): The paper doesn\u2019t define the D_{dev} clearly. How is D_{dev} chosen? Is it a subset of D_{train}? \n\nResponse:\nFor our machine translation tasks, $D_{dev}$ is simply the dev set that comes with the dataset.\n\nFor our image classification tasks, for $D_{dev}$ we hold out about 10% of the *training* data. For example, in CIFAR-10 (4,000), $D_{dev}$ is the last 400 images, while in ImageNet-10%, since we use the first 102 TFRecord shards, $D_{dev}$ consists of the last 10 shards. Here, \u201clast\u201d follows the order in which the data is posted on their website for CIFAR-10, and the order in which the TFRecord shards are processed for ImageNet. All data in $D_{dev}$ are excluded from $D_{train}$. Thus, for example, with CIFAR-10 (4,000), $|D_{train}| = 3600$, ensuring that in total, we are only using the amount of data that we claim to use.\n\nThus, in all cases, there is no overlap between $D_{train}$ and $D_{dev}$, or $D_{test}$ and $D_{dev}$ (as is standard in machine learning experiments). We have added a clarification in the method section of the paper, and we also updated the details in the appendix.\n\nReviewer #1 question 2): In section 2.1, why \u201csmaller development set D_{dev} is much closer to the P_{test}(X,Y)\u201d? P_{test}(X,Y) is supposed to be not observed during training?\n\nResponse:\nIt is correct that P_{test}(X, Y) is not observed, but practically in model training it is commonly more possible to collect a dev set that reflects the test scenario. To take the example of the multilingual NMT, in this case we would like to use training data from *many different languages* to improve the performance of *a particular low-resource language*. Here, D_{train} is the aggregation of data from all languages, while D_{dev} could be a separate small set of data from the low-resource language we are interested in. This small dev set is possible to gather, even if we can\u2019t gather a large training set in the language. P_{test}(X, Y) in this case is the distribution of the low-resource language, which is much better captured by the small D_{dev} from this low-resource language.\n\nSimilar settings can easily be thought of in other scenarios as well: in a domain adaptation setting we can obtain a small dev set in the target domain, or in a setting of training on noisy data we can often obtain a small clean dev set. We have updated the method section of the paper to clarify this issue.\n\nFinally, even if the training set and dev set come from *exactly* the same data distribution, likelihood on the dev set is still going to be a better estimator of test performance, as the model is not able to train on the dev set directly (which is why we use dev sets in standard machine learning setups in the first place).\n\nReviewer #1 question 3): In Eq (5), if D_{dev} is s subset of D_{train}, if \\theta* is the minimal of J, it means the gradient at  \\theta* is 0. To calculate the gradient of J with respect to \\psi, by chain rule, it need to calculate gradient to \\theta* first then \\theta* to \\psi. If gradient of \\theta* is 0, the product is also 0? So the \\psi will not be updated if D_{dev}  is sufficiently similar to D_{train} ?\n\nResponse:\nAs we mentioned in point (1), $D_{dev}$ does not overlap with $D_{train}$, so these gradients will be inherently different.\n\n\n"}, "signatures": ["ICLR.cc/2020/Conference/Paper790/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper790/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Optimizing Data Usage via Differentiable Rewards", "authors": ["Xinyi Wang", "Hieu Pham", "Paul Michel", "Antonios Anastasopoulos", "Graham Neubig", "Jaime Carbonell"], "authorids": ["xinyiw1@cs.cmu.edu", "hyhieu@cmu.edu", "pmichel1@cs.cmu.edu", "aanastas@andrew.cmu.edu", "gneubig@cs.cmu.edu", "jgc@cs.cmu.edu"], "keywords": ["data selection", "multilingual neural machine translation", "data usage optimzation", "transfer learning", "classification"], "abstract": "To acquire a new skill, humans learn better and faster if a tutor, based on their current knowledge level, informs them of how much attention they should pay to particular content or practice problems. Similarly, a machine learning model could potentially be trained better with a scorer that \u201cadapts\u201d to its current learning state and estimates the importance of each training data instance. Training such an adaptive scorer efficiently is a challenging problem; in order to precisely quantify the effect of a data instance at a given time during the training, it is typically necessary to first complete the entire training process. To efficiently optimize data usage, we propose a reinforcement learning approach called Differentiable Data Selection (DDS). In DDS, we formulate a scorer network as a learnable function of the training data, which can be efficiently updated along with the main model being trained. Specifically, DDS updates the scorer with an intuitive reward signal: it should up-weigh the data that has a similar gradient with a dev set upon which we would finally like to perform well. Without significant computing overhead, DDS delivers strong and consistent improvements over several strong baselines on two very different tasks of machine translation and image classification.", "pdf": "/pdf/3d572357f0598b1c73d55e8cf8bb64c44ab2f5ea.pdf", "paperhash": "wang|optimizing_data_usage_via_differentiable_rewards", "original_pdf": "/attachment/b9308ec7cfbe1d03bb9d1c761d705078d06d496c.pdf", "_bibtex": "@misc{\nwang2020optimizing,\ntitle={Optimizing Data Usage via Differentiable Rewards},\nauthor={Xinyi Wang and Hieu Pham and Paul Michel and Antonios Anastasopoulos and Graham Neubig and Jaime Carbonell},\nyear={2020},\nurl={https://openreview.net/forum?id=BJxt2aVFPr}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "BJxt2aVFPr", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper790/Authors", "ICLR.cc/2020/Conference/Paper790/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper790/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper790/Reviewers", "ICLR.cc/2020/Conference/Paper790/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper790/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper790/Authors|ICLR.cc/2020/Conference/Paper790/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504166178, "tmdate": 1576860531589, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper790/Authors", "ICLR.cc/2020/Conference/Paper790/Reviewers", "ICLR.cc/2020/Conference/Paper790/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper790/-/Official_Comment"}}}, {"id": "r1lqmp15YS", "original": null, "number": 2, "cdate": 1571581217748, "ddate": null, "tcdate": 1571581217748, "tmdate": 1572972551948, "tddate": null, "forum": "BJxt2aVFPr", "replyto": "BJxt2aVFPr", "invitation": "ICLR.cc/2020/Conference/Paper790/-/Official_Review", "content": {"rating": "6: Weak Accept", "experience_assessment": "I do not know much about this area.", "review_assessment:_checking_correctness_of_derivations_and_theory": "N/A", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #2", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review": "This paper presents a reinforcement learning approach towards using data that present best correlation with a validation set\u2019s gradient signal. The broader point of this paper is that there is inevitably some distribution shift going from train to test set - and the validation set can be a small curated set whose distribution is closer to the testing distribution than what the training dataset's distribution is. \n\nThe problem setup bears relationship to several areas including domain adaptation/covariate shift problems, curriculum learning based approaches amongst others. One assumption that I see which needs to be understood more is equation (6) - wherein, somehow, there is a Markov assumption used to zero out the contribution of the scoring network on parameters unto previous time step. Trying to understand the implications of this assumption (how the performance varies with/without this assumption) would be instructive for understanding potential shortcomings of this framework.\n\nI think the paper is well written, handles an important question. That said, I am not too aware of recent work in this area to make a decisive judgement on this paper\u2019s novelty/contributions. "}, "signatures": ["ICLR.cc/2020/Conference/Paper790/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper790/AnonReviewer2"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Optimizing Data Usage via Differentiable Rewards", "authors": ["Xinyi Wang", "Hieu Pham", "Paul Michel", "Antonios Anastasopoulos", "Graham Neubig", "Jaime Carbonell"], "authorids": ["xinyiw1@cs.cmu.edu", "hyhieu@cmu.edu", "pmichel1@cs.cmu.edu", "aanastas@andrew.cmu.edu", "gneubig@cs.cmu.edu", "jgc@cs.cmu.edu"], "keywords": ["data selection", "multilingual neural machine translation", "data usage optimzation", "transfer learning", "classification"], "abstract": "To acquire a new skill, humans learn better and faster if a tutor, based on their current knowledge level, informs them of how much attention they should pay to particular content or practice problems. Similarly, a machine learning model could potentially be trained better with a scorer that \u201cadapts\u201d to its current learning state and estimates the importance of each training data instance. Training such an adaptive scorer efficiently is a challenging problem; in order to precisely quantify the effect of a data instance at a given time during the training, it is typically necessary to first complete the entire training process. To efficiently optimize data usage, we propose a reinforcement learning approach called Differentiable Data Selection (DDS). In DDS, we formulate a scorer network as a learnable function of the training data, which can be efficiently updated along with the main model being trained. Specifically, DDS updates the scorer with an intuitive reward signal: it should up-weigh the data that has a similar gradient with a dev set upon which we would finally like to perform well. Without significant computing overhead, DDS delivers strong and consistent improvements over several strong baselines on two very different tasks of machine translation and image classification.", "pdf": "/pdf/3d572357f0598b1c73d55e8cf8bb64c44ab2f5ea.pdf", "paperhash": "wang|optimizing_data_usage_via_differentiable_rewards", "original_pdf": "/attachment/b9308ec7cfbe1d03bb9d1c761d705078d06d496c.pdf", "_bibtex": "@misc{\nwang2020optimizing,\ntitle={Optimizing Data Usage via Differentiable Rewards},\nauthor={Xinyi Wang and Hieu Pham and Paul Michel and Antonios Anastasopoulos and Graham Neubig and Jaime Carbonell},\nyear={2020},\nurl={https://openreview.net/forum?id=BJxt2aVFPr}\n}"}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "BJxt2aVFPr", "replyto": "BJxt2aVFPr", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper790/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper790/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1575509791284, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper790/Reviewers"], "noninvitees": [], "tcdate": 1570237747035, "tmdate": 1575509791297, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper790/-/Official_Review"}}}, {"id": "Skgt9dG-9H", "original": null, "number": 3, "cdate": 1572051088743, "ddate": null, "tcdate": 1572051088743, "tmdate": 1572972551878, "tddate": null, "forum": "BJxt2aVFPr", "replyto": "BJxt2aVFPr", "invitation": "ICLR.cc/2020/Conference/Paper790/-/Official_Review", "content": {"experience_assessment": "I have read many papers in this area.", "rating": "6: Weak Accept", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #3", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "Summary: This paper introduces a simple idea to optimize the weights of a weighted empirical training distributions. The goal is to optimize the population risk, and the idea is to optimize a distribution over the training examples to maximize the cosine similarity between training set gradients and validation set gradients. The distribution over the training set is parameterized by a neural network taking as arguments the\n\nStrengths:\n- The method is quite simple.\n- The results appear to be strong, although I am less familiar with the NMT baselines. The imagenet results seem quite strong to me.\n\nWeaknesses:\n- I couldn't find a particularly clear description of the scoring networks architecture. Given that it observes the whole dataset, this seems like a critical choice that could have a big impact on the complexity of this approach. At the very least, this should be clearly reported, and I recommend a more thorough investigation of this choice.\n- The authors report that their method takes 1.5x to 2x longer to run than the uniform baseline. Yet, they ran all methods for the same number of steps / epochs. It seems to me that a fairer comparison might be letting all methods enjoy the same total budget measure roughly by wall time.\n\nQuestions:\n- I didn't follow why the computation of the per example gradient grad l(x_i, y_i, theta_t-1) is so onerous. Isn't that computed on line 5 already?"}, "signatures": ["ICLR.cc/2020/Conference/Paper790/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper790/AnonReviewer3"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Optimizing Data Usage via Differentiable Rewards", "authors": ["Xinyi Wang", "Hieu Pham", "Paul Michel", "Antonios Anastasopoulos", "Graham Neubig", "Jaime Carbonell"], "authorids": ["xinyiw1@cs.cmu.edu", "hyhieu@cmu.edu", "pmichel1@cs.cmu.edu", "aanastas@andrew.cmu.edu", "gneubig@cs.cmu.edu", "jgc@cs.cmu.edu"], "keywords": ["data selection", "multilingual neural machine translation", "data usage optimzation", "transfer learning", "classification"], "abstract": "To acquire a new skill, humans learn better and faster if a tutor, based on their current knowledge level, informs them of how much attention they should pay to particular content or practice problems. Similarly, a machine learning model could potentially be trained better with a scorer that \u201cadapts\u201d to its current learning state and estimates the importance of each training data instance. Training such an adaptive scorer efficiently is a challenging problem; in order to precisely quantify the effect of a data instance at a given time during the training, it is typically necessary to first complete the entire training process. To efficiently optimize data usage, we propose a reinforcement learning approach called Differentiable Data Selection (DDS). In DDS, we formulate a scorer network as a learnable function of the training data, which can be efficiently updated along with the main model being trained. Specifically, DDS updates the scorer with an intuitive reward signal: it should up-weigh the data that has a similar gradient with a dev set upon which we would finally like to perform well. Without significant computing overhead, DDS delivers strong and consistent improvements over several strong baselines on two very different tasks of machine translation and image classification.", "pdf": "/pdf/3d572357f0598b1c73d55e8cf8bb64c44ab2f5ea.pdf", "paperhash": "wang|optimizing_data_usage_via_differentiable_rewards", "original_pdf": "/attachment/b9308ec7cfbe1d03bb9d1c761d705078d06d496c.pdf", "_bibtex": "@misc{\nwang2020optimizing,\ntitle={Optimizing Data Usage via Differentiable Rewards},\nauthor={Xinyi Wang and Hieu Pham and Paul Michel and Antonios Anastasopoulos and Graham Neubig and Jaime Carbonell},\nyear={2020},\nurl={https://openreview.net/forum?id=BJxt2aVFPr}\n}"}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "BJxt2aVFPr", "replyto": "BJxt2aVFPr", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper790/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper790/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1575509791284, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper790/Reviewers"], "noninvitees": [], "tcdate": 1570237747035, "tmdate": 1575509791297, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper790/-/Official_Review"}}}], "count": 10}