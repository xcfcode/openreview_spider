{"notes": [{"id": "HbZTcIuiMAG", "original": "bDdjotcFnlG", "number": 354, "cdate": 1601308047134, "ddate": null, "tcdate": 1601308047134, "tmdate": 1614985682620, "tddate": null, "forum": "HbZTcIuiMAG", "replyto": null, "invitation": "ICLR.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Fusion 360 Gallery: A Dataset and Environment for Programmatic CAD Reconstruction", "authorids": ["~Karl_Willis1", "~Yewen_Pu1", "~Jieliang_Luo1", "~Hang_Chu4", "~Tao_Du1", "joseph.lambourne@autodesk.com", "~Armando_Solar-Lezama1", "~Wojciech_Matusik2"], "authors": ["Karl Willis", "Yewen Pu", "Jieliang Luo", "Hang Chu", "Tao Du", "Joseph Lambourne", "Armando Solar-Lezama", "Wojciech Matusik"], "keywords": ["CAD", "dataset", "3D", "reconstruction", "environment", "design", "sequence"], "abstract": "Parametric computer-aided design (CAD) is a standard paradigm used for the design of manufactured objects. CAD designers perform modeling operations, such as sketch and extrude, to form a construction sequence that makes up a final design. Despite the pervasiveness of parametric CAD and growing interest from the research community, a dataset of human designed 3D CAD construction sequences has not been available to-date. In this paper we present the Fusion 360 Gallery reconstruction dataset and environment for learning CAD reconstruction. We provide a dataset of 8,625 designs, comprising sequential sketch and extrude modeling operations, together with a complementary environment called the Fusion 360 Gym, to assist with performing CAD reconstruction. We outline a standard CAD reconstruction task, together with evaluation metrics, and present results from a novel method using neurally guided search to recover a construction sequence from a target geometry.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "willis|fusion_360_gallery_a_dataset_and_environment_for_programmatic_cad_reconstruction", "one-sentence_summary": "The Fusion 360 Gallery reconstruction dataset and environment for learning CAD reconstruction.", "supplementary_material": "", "pdf": "/pdf/3ec59d0f61896944fa3f9101bf9f3be31f7eac11.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=n8YNQi5A3", "_bibtex": "@misc{\nwillis2021fusion,\ntitle={Fusion 360 Gallery: A Dataset and Environment for Programmatic {\\{}CAD{\\}} Reconstruction},\nauthor={Karl Willis and Yewen Pu and Jieliang Luo and Hang Chu and Tao Du and Joseph Lambourne and Armando Solar-Lezama and Wojciech Matusik},\nyear={2021},\nurl={https://openreview.net/forum?id=HbZTcIuiMAG}\n}"}, "signatures": ["ICLR.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference"], "details": {"replyCount": 10, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"reply": {"readers": {"values-regex": ".*"}, "writers": {"values": ["ICLR.cc/2021/Conference"]}, "signatures": {"values": ["ICLR.cc/2021/Conference"]}, "content": {"authors": {"values": ["Anonymous"]}, "authorids": {"values-regex": ".*"}, "reviewed_version_(pdf)": {"required": false, "description": "Upload a PDF file that ends with .pdf", "value-regex": ".*"}}}, "signatures": ["ICLR.cc/2021/Conference"], "readers": ["everyone"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["~", "OpenReview.net/Support"], "tcdate": 1601308008205, "tmdate": 1614984599368, "id": "ICLR.cc/2021/Conference/-/Blind_Submission"}}, "tauthor": "OpenReview.net"}, {"id": "FVL_Uh3MH3", "original": null, "number": 1, "cdate": 1610040470388, "ddate": null, "tcdate": 1610040470388, "tmdate": 1610474074353, "tddate": null, "forum": "HbZTcIuiMAG", "replyto": "HbZTcIuiMAG", "invitation": "ICLR.cc/2021/Conference/Paper354/-/Decision", "content": {"title": "Final Decision", "decision": "Reject", "comment": "This paper received 4 reviews with mixed initial ratings: 4, 8, 5, 7. The main concerns of R1 and R2, who gave unfavorable scores, included limited methodological novelty beyond the data generation and insufficient empirical evaluation of state-of-the-art methods on the proposed dataset. The authors submitted a new revision with a summary of changes and provided detailed responses to each of the reviews separately: it addressed some of the concerns, but did not change the overall position of the reviewers.\nAC agrees with R3 and R4 that the proposed dataset and the environment may have certain practical impact and enable new research in learning CAD reconstruction. However, the contributions are indeed specific to a narrow CAD community, and R1 felt that the paper needs another round of peer reviews before acceptance, as a significant number of new results have been added during the discussion stage. After discussion with PCs, the final recommendation is to reject."}, "signatures": ["ICLR.cc/2021/Conference/Program_Chairs"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference/Program_Chairs"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Fusion 360 Gallery: A Dataset and Environment for Programmatic CAD Reconstruction", "authorids": ["~Karl_Willis1", "~Yewen_Pu1", "~Jieliang_Luo1", "~Hang_Chu4", "~Tao_Du1", "joseph.lambourne@autodesk.com", "~Armando_Solar-Lezama1", "~Wojciech_Matusik2"], "authors": ["Karl Willis", "Yewen Pu", "Jieliang Luo", "Hang Chu", "Tao Du", "Joseph Lambourne", "Armando Solar-Lezama", "Wojciech Matusik"], "keywords": ["CAD", "dataset", "3D", "reconstruction", "environment", "design", "sequence"], "abstract": "Parametric computer-aided design (CAD) is a standard paradigm used for the design of manufactured objects. CAD designers perform modeling operations, such as sketch and extrude, to form a construction sequence that makes up a final design. Despite the pervasiveness of parametric CAD and growing interest from the research community, a dataset of human designed 3D CAD construction sequences has not been available to-date. In this paper we present the Fusion 360 Gallery reconstruction dataset and environment for learning CAD reconstruction. We provide a dataset of 8,625 designs, comprising sequential sketch and extrude modeling operations, together with a complementary environment called the Fusion 360 Gym, to assist with performing CAD reconstruction. We outline a standard CAD reconstruction task, together with evaluation metrics, and present results from a novel method using neurally guided search to recover a construction sequence from a target geometry.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "willis|fusion_360_gallery_a_dataset_and_environment_for_programmatic_cad_reconstruction", "one-sentence_summary": "The Fusion 360 Gallery reconstruction dataset and environment for learning CAD reconstruction.", "supplementary_material": "", "pdf": "/pdf/3ec59d0f61896944fa3f9101bf9f3be31f7eac11.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=n8YNQi5A3", "_bibtex": "@misc{\nwillis2021fusion,\ntitle={Fusion 360 Gallery: A Dataset and Environment for Programmatic {\\{}CAD{\\}} Reconstruction},\nauthor={Karl Willis and Yewen Pu and Jieliang Luo and Hang Chu and Tao Du and Joseph Lambourne and Armando Solar-Lezama and Wojciech Matusik},\nyear={2021},\nurl={https://openreview.net/forum?id=HbZTcIuiMAG}\n}"}, "tags": [], "invitation": {"reply": {"forum": "HbZTcIuiMAG", "replyto": "HbZTcIuiMAG", "readers": {"values": ["everyone"]}, "writers": {"values": ["ICLR.cc/2021/Conference/Program_Chairs"]}, "signatures": {"values": ["ICLR.cc/2021/Conference/Program_Chairs"]}, "content": {"title": {"value": "Final Decision"}, "decision": {"value-radio": ["Accept (Oral)", "Accept (Spotlight)", "Accept (Poster)", "Reject"]}, "comment": {"value-regex": "[\\S\\s]{0,50000}", "markdown": true}}}, "multiReply": false, "signatures": ["ICLR.cc/2021/Conference"], "readers": ["everyone"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Program_Chairs"], "tcdate": 1610040470375, "tmdate": 1610474074337, "id": "ICLR.cc/2021/Conference/Paper354/-/Decision"}}}, {"id": "nD1q51ar7ws", "original": null, "number": 8, "cdate": 1605828067388, "ddate": null, "tcdate": 1605828067388, "tmdate": 1605828067388, "tddate": null, "forum": "HbZTcIuiMAG", "replyto": "HbZTcIuiMAG", "invitation": "ICLR.cc/2021/Conference/Paper354/-/Official_Comment", "content": {"title": "Revised Paper and Summary of Changes", "comment": "Dear Reviewers and AC,\n\nThank you again for your constructive comments. We have revised our paper accordingly and uploaded the latest version. The main changes include:\n\n- We have added additional baselines using a Graph Isomorphism Network (GIN) and Graph Attention Network (GAT) to demonstrate that the CAD reconstruction task cannot be solved trivially.\n- We have added an additional experiment comparing human-designed data to semi-synthetic and synthetic data. The results show the significant advantage of training with human-designed data.\n- We have clarified a number of details in the main paper including: the novel aspect of our method, added details on the task motivation/practicality, clarified how conciseness is calculated, added discussion on the effect of data augmentation, clarified network implementation details, and added suggested references.\n- We provide further details in the appendix including: a full table of results with combinations of agents (gcn, gat, gin, rand) with search (rand, best, beam), an additional plot comparing search strategies, a table of results comparing the performance of synthetic data, additional evaluation details, and a plot illustrating average reconstruction time.\n\nPlease don\u2019t hesitate to respond with any additional feedback. Thank you.\n"}, "signatures": ["ICLR.cc/2021/Conference/Paper354/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper354/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Fusion 360 Gallery: A Dataset and Environment for Programmatic CAD Reconstruction", "authorids": ["~Karl_Willis1", "~Yewen_Pu1", "~Jieliang_Luo1", "~Hang_Chu4", "~Tao_Du1", "joseph.lambourne@autodesk.com", "~Armando_Solar-Lezama1", "~Wojciech_Matusik2"], "authors": ["Karl Willis", "Yewen Pu", "Jieliang Luo", "Hang Chu", "Tao Du", "Joseph Lambourne", "Armando Solar-Lezama", "Wojciech Matusik"], "keywords": ["CAD", "dataset", "3D", "reconstruction", "environment", "design", "sequence"], "abstract": "Parametric computer-aided design (CAD) is a standard paradigm used for the design of manufactured objects. CAD designers perform modeling operations, such as sketch and extrude, to form a construction sequence that makes up a final design. Despite the pervasiveness of parametric CAD and growing interest from the research community, a dataset of human designed 3D CAD construction sequences has not been available to-date. In this paper we present the Fusion 360 Gallery reconstruction dataset and environment for learning CAD reconstruction. We provide a dataset of 8,625 designs, comprising sequential sketch and extrude modeling operations, together with a complementary environment called the Fusion 360 Gym, to assist with performing CAD reconstruction. We outline a standard CAD reconstruction task, together with evaluation metrics, and present results from a novel method using neurally guided search to recover a construction sequence from a target geometry.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "willis|fusion_360_gallery_a_dataset_and_environment_for_programmatic_cad_reconstruction", "one-sentence_summary": "The Fusion 360 Gallery reconstruction dataset and environment for learning CAD reconstruction.", "supplementary_material": "", "pdf": "/pdf/3ec59d0f61896944fa3f9101bf9f3be31f7eac11.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=n8YNQi5A3", "_bibtex": "@misc{\nwillis2021fusion,\ntitle={Fusion 360 Gallery: A Dataset and Environment for Programmatic {\\{}CAD{\\}} Reconstruction},\nauthor={Karl Willis and Yewen Pu and Jieliang Luo and Hang Chu and Tao Du and Joseph Lambourne and Armando Solar-Lezama and Wojciech Matusik},\nyear={2021},\nurl={https://openreview.net/forum?id=HbZTcIuiMAG}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "HbZTcIuiMAG", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper354/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper354/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper354/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper354/Authors|ICLR.cc/2021/Conference/Paper354/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper354/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923871894, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper354/-/Official_Comment"}}}, {"id": "C8Lydeuqbf", "original": null, "number": 7, "cdate": 1605228463551, "ddate": null, "tcdate": 1605228463551, "tmdate": 1605228463551, "tddate": null, "forum": "HbZTcIuiMAG", "replyto": "w-cQ0AdQ1hj", "invitation": "ICLR.cc/2021/Conference/Paper354/-/Official_Comment", "content": {"title": "Response to Reviewer 4", "comment": "We appreciate you taking the time to review our submission. We also apologize for the issues with the PDF crashing your viewer. We will fix that when we post a revised version.\n\n**Re: Important details in the appendix**\nWe will review Section 5 to ensure sufficient details are provided. Including a more detailed explanation of the auto-regressive connection. If there are any additional details you believe should be in the main paper, please let us know.\n"}, "signatures": ["ICLR.cc/2021/Conference/Paper354/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper354/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Fusion 360 Gallery: A Dataset and Environment for Programmatic CAD Reconstruction", "authorids": ["~Karl_Willis1", "~Yewen_Pu1", "~Jieliang_Luo1", "~Hang_Chu4", "~Tao_Du1", "joseph.lambourne@autodesk.com", "~Armando_Solar-Lezama1", "~Wojciech_Matusik2"], "authors": ["Karl Willis", "Yewen Pu", "Jieliang Luo", "Hang Chu", "Tao Du", "Joseph Lambourne", "Armando Solar-Lezama", "Wojciech Matusik"], "keywords": ["CAD", "dataset", "3D", "reconstruction", "environment", "design", "sequence"], "abstract": "Parametric computer-aided design (CAD) is a standard paradigm used for the design of manufactured objects. CAD designers perform modeling operations, such as sketch and extrude, to form a construction sequence that makes up a final design. Despite the pervasiveness of parametric CAD and growing interest from the research community, a dataset of human designed 3D CAD construction sequences has not been available to-date. In this paper we present the Fusion 360 Gallery reconstruction dataset and environment for learning CAD reconstruction. We provide a dataset of 8,625 designs, comprising sequential sketch and extrude modeling operations, together with a complementary environment called the Fusion 360 Gym, to assist with performing CAD reconstruction. We outline a standard CAD reconstruction task, together with evaluation metrics, and present results from a novel method using neurally guided search to recover a construction sequence from a target geometry.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "willis|fusion_360_gallery_a_dataset_and_environment_for_programmatic_cad_reconstruction", "one-sentence_summary": "The Fusion 360 Gallery reconstruction dataset and environment for learning CAD reconstruction.", "supplementary_material": "", "pdf": "/pdf/3ec59d0f61896944fa3f9101bf9f3be31f7eac11.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=n8YNQi5A3", "_bibtex": "@misc{\nwillis2021fusion,\ntitle={Fusion 360 Gallery: A Dataset and Environment for Programmatic {\\{}CAD{\\}} Reconstruction},\nauthor={Karl Willis and Yewen Pu and Jieliang Luo and Hang Chu and Tao Du and Joseph Lambourne and Armando Solar-Lezama and Wojciech Matusik},\nyear={2021},\nurl={https://openreview.net/forum?id=HbZTcIuiMAG}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "HbZTcIuiMAG", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper354/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper354/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper354/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper354/Authors|ICLR.cc/2021/Conference/Paper354/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper354/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923871894, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper354/-/Official_Comment"}}}, {"id": "HB7E3TVNNC_", "original": null, "number": 6, "cdate": 1605227717968, "ddate": null, "tcdate": 1605227717968, "tmdate": 1605227717968, "tddate": null, "forum": "HbZTcIuiMAG", "replyto": "LV4nRcvf82", "invitation": "ICLR.cc/2021/Conference/Paper354/-/Official_Comment", "content": {"title": "Response to Reviewer 3", "comment": "Firstly, thank you for taking the time to review our submission. Below we provide additional discussion and outline planned changes based on your valuable feedback.\n\n**Re: Raw geometry wording**\nWe agree this wording could be confusing and will update the paper to clarify.\n\n**Re: CAD reconstruction task practicality**\nWe will update the paper to further motivate and clarify the practical application of CAD reconstruction from B-rep input. In summary, the CAD sequence, also known as the parametric modeling history, is often lost during data exchange, especially when models are exchanged between CAD applications using neutral file formats like STEP and IGES. The ability to edit the modeling history to modify, or entirely remove operations, is extremely valuable for users of CAD systems. The importance of this capability is reflected in the many industrial CAD packages that attempt to provide tools for restoring CAD history, such as [Inventor](https://knowledge.autodesk.com/support/inventor/troubleshooting/caas/sfdcarticles/sfdcarticles/How-to-recognize-features-in-Inventor-after-import-data-sets.html), [SolidWorks](http://help.solidworks.com/2019/english/SolidWorks/fworks/t_Recognizing_Features_Using_step_by_step.htm), [Creo](http://support.ptc.com/help/creo/creo_pma/usascii/index.html#page/part_modeling/feature_recognition_tool/About_Feature_Recognition.html), and [CATIA](https://www.cadcam-group.eu/catia-v5-part-design-features-recognition).\n\nThese traditional algorithms operate by removing small features (typically holes or pockets) and re-applying them parametrically. Usually this strategy can restore the history for the later modeling operations, but can fail to completely rebuild the parametric modeling history from the first step. The task discussed in this paper restores the entire parametric modeling history, from the very first extrusion. Solving this task successfully has the potential to deliver benefit to CAD users beyond what is currently possible with traditional algorithms.\n\n**Re: CAD reconstruction from point clouds**\nThe task of generating a CAD model with full parametric modeling history from a point cloud or triangle mesh is extremely valuable.  It is also very challenging technically. Very recent work has begun to tackle the first part of this problem by generating parametric surfaces and curves from point clouds [1, 2]. Although these papers show the promise of learning based approaches, they are not yet capable of producing geometry with the fidelity required to generate a solid model. Such a solid model could serve as input for CAD sequence reconstruction; the second part of the problem tackled in this work. A large amount of research is required to reach this goal and we hope the availability of the Fusion 360 Gallery reconstruction dataset will accelerate progress on this much more difficult task.     \n\n1. ParSeNet: A Parametric Surface Fitting Network for 3D Point Clouds, https://arxiv.org/abs/2003.12181\n2. PIE-NET: Parametric Inference of Point Cloud Edges, https://papers.nips.cc/paper/2020/hash/e94550c93cd70fe748e6982b3439ad3b-Abstract.html\n\n\n**Re: Conciseness metric**\nThe conciseness results in the paper are calculated from the exact reconstructions only. We consider conciseness to be a metric that describes the quality of a correct design. For practical use in a CAD tool, we consider an exact reconstruction to be a requirement. In general having a concise sequence is beneficial; designers will often revisit their designs to manually remove and consolidate lengthy sequences. The conciseness metric is designed to penalize reconstruction approaches that achieve good exact reconstruction performance, at the expense of less concise (i.e. longer) sequences.\n\nCurrently we calculate conciseness as the geometric mean across all exact reconstructions for each condition (mpn, mlp etc\u2026) with the number of exact reconstructions ranging from 928-1165 out of 1725 test files. Another approach is to hold the number of exact reconstructions constant across conditions by discarding designs that were not exactly reconstructed by all conditions. However we find that this ends up discarding longer sequences that are difficult to reconstruct and can improve the conciseness score in a potentially misleading manner. We welcome further discussion on the best way to quantify the conciseness of a construction sequence.\n\n\n**Re: Effect of augmentation on IoU**\nYes, we agree this is an important point to better understand. We will provide additional results that compare the performance of neurally-guided search trained on synthetic, semi-synthetic (using human-designed sketches), and human design data. We believe these results will give us insight into the distribution of each dataset and provide evidence for the effect of data augmentation.\n\n**Re: Modeling 3D Shapes by Reinforcement Learning**\nYes, this is an excellent reference to add. Thank you.\n"}, "signatures": ["ICLR.cc/2021/Conference/Paper354/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper354/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Fusion 360 Gallery: A Dataset and Environment for Programmatic CAD Reconstruction", "authorids": ["~Karl_Willis1", "~Yewen_Pu1", "~Jieliang_Luo1", "~Hang_Chu4", "~Tao_Du1", "joseph.lambourne@autodesk.com", "~Armando_Solar-Lezama1", "~Wojciech_Matusik2"], "authors": ["Karl Willis", "Yewen Pu", "Jieliang Luo", "Hang Chu", "Tao Du", "Joseph Lambourne", "Armando Solar-Lezama", "Wojciech Matusik"], "keywords": ["CAD", "dataset", "3D", "reconstruction", "environment", "design", "sequence"], "abstract": "Parametric computer-aided design (CAD) is a standard paradigm used for the design of manufactured objects. CAD designers perform modeling operations, such as sketch and extrude, to form a construction sequence that makes up a final design. Despite the pervasiveness of parametric CAD and growing interest from the research community, a dataset of human designed 3D CAD construction sequences has not been available to-date. In this paper we present the Fusion 360 Gallery reconstruction dataset and environment for learning CAD reconstruction. We provide a dataset of 8,625 designs, comprising sequential sketch and extrude modeling operations, together with a complementary environment called the Fusion 360 Gym, to assist with performing CAD reconstruction. We outline a standard CAD reconstruction task, together with evaluation metrics, and present results from a novel method using neurally guided search to recover a construction sequence from a target geometry.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "willis|fusion_360_gallery_a_dataset_and_environment_for_programmatic_cad_reconstruction", "one-sentence_summary": "The Fusion 360 Gallery reconstruction dataset and environment for learning CAD reconstruction.", "supplementary_material": "", "pdf": "/pdf/3ec59d0f61896944fa3f9101bf9f3be31f7eac11.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=n8YNQi5A3", "_bibtex": "@misc{\nwillis2021fusion,\ntitle={Fusion 360 Gallery: A Dataset and Environment for Programmatic {\\{}CAD{\\}} Reconstruction},\nauthor={Karl Willis and Yewen Pu and Jieliang Luo and Hang Chu and Tao Du and Joseph Lambourne and Armando Solar-Lezama and Wojciech Matusik},\nyear={2021},\nurl={https://openreview.net/forum?id=HbZTcIuiMAG}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "HbZTcIuiMAG", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper354/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper354/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper354/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper354/Authors|ICLR.cc/2021/Conference/Paper354/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper354/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923871894, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper354/-/Official_Comment"}}}, {"id": "8giNvJwEJr3", "original": null, "number": 5, "cdate": 1605206606307, "ddate": null, "tcdate": 1605206606307, "tmdate": 1605206606307, "tddate": null, "forum": "HbZTcIuiMAG", "replyto": "eaEp1oK6PiS", "invitation": "ICLR.cc/2021/Conference/Paper354/-/Official_Comment", "content": {"title": "Response to Reviewer 2", "comment": "Thank you for taking the time to review our submission. We outline below the planned changes in response to your helpful feedback.\n\n**Re: Value of human designed datasets**\nWe agree it is important to make clear the value of learning from human data. We will provide additional results that compare the performance of neurally-guided search trained on synthetic, semi-synthetic (using human-designed sketches), and human design data. We agree that research on producing procedural designs is an important area that can also benefit from access to a human-designed baseline dataset.\n\n**Re: Novelty**\nWe will work to clarify the novelty of our method in the paper. In summary, the face extrusion action representation (Section 4.1, Figure 4) is novel and enables data-driven CAD reconstruction on real world designs for the first time. By contrast, prior work focuses on CSG operations on geometric primitives that are rarely used in professional settings. By providing a dataset and new action representation we hope to encourage future work closely aligned to real world scenarios.\n\n**Re: Relevance to the ICLR community**\nWe believe our work has high relevance to ICLR and the broader machine learning community. Specifically, our work aligns with the emerging area using program synthesis as a representation for graphical output such as 3D shapes [1,2], scenes [3] and sketches [4]. The Fusion 360 Gallery dataset provides such \u201cCAD programs\u201d complete with ground truth human designed program sequence. We believe new approaches to neurosymbolic reasoning can be developed and applied in this domain, following the lead of works such as [5,6].\n\nMore generally, 3D shape datasets have been shown to provide significant value to the machine learning community at large. For example, ShapeNet [7] is an established 3D shape dataset that is widely cited across the machine learning, computer vision, and computer graphics communities. We believe CAD programs are a natural representation of human-designed shapes, and providing a dataset with this representation will be invaluable to the machine learning community.\n\n1. Learning to Infer and Execute 3D Shape Programs, ICLR 2019, https://openreview.net/forum?id=rylNH20qFQ \n2. UCSG-Net -- Unsupervised Discovering of Constructive Solid Geometry Tree, NeurIPS 2020, https://arxiv.org/abs/2006.09102v3 \n3. Learning to Describe Scenes with Programs, ICLR 2019, https://openreview.net/forum?id=SyNPk2R9K7\n4. Learning to Infer Graphics Programs from Hand-Drawn Images, NeurIPS 2018, https://arxiv.org/abs/1707.09627 \n5. Learning Neurosymbolic Generative Models via Program Synthesis, ICML 2019, https://arxiv.org/abs/1901.08565 \n6. Multi-Plane Program Induction with 3D Box Priors, NeurIPS 2020, http://bpi.csail.mit.edu \n7. ShapeNet: An Information-Rich 3D Model Repository, 2015 https://arxiv.org/abs/1512.03012 \n\n"}, "signatures": ["ICLR.cc/2021/Conference/Paper354/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper354/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Fusion 360 Gallery: A Dataset and Environment for Programmatic CAD Reconstruction", "authorids": ["~Karl_Willis1", "~Yewen_Pu1", "~Jieliang_Luo1", "~Hang_Chu4", "~Tao_Du1", "joseph.lambourne@autodesk.com", "~Armando_Solar-Lezama1", "~Wojciech_Matusik2"], "authors": ["Karl Willis", "Yewen Pu", "Jieliang Luo", "Hang Chu", "Tao Du", "Joseph Lambourne", "Armando Solar-Lezama", "Wojciech Matusik"], "keywords": ["CAD", "dataset", "3D", "reconstruction", "environment", "design", "sequence"], "abstract": "Parametric computer-aided design (CAD) is a standard paradigm used for the design of manufactured objects. CAD designers perform modeling operations, such as sketch and extrude, to form a construction sequence that makes up a final design. Despite the pervasiveness of parametric CAD and growing interest from the research community, a dataset of human designed 3D CAD construction sequences has not been available to-date. In this paper we present the Fusion 360 Gallery reconstruction dataset and environment for learning CAD reconstruction. We provide a dataset of 8,625 designs, comprising sequential sketch and extrude modeling operations, together with a complementary environment called the Fusion 360 Gym, to assist with performing CAD reconstruction. We outline a standard CAD reconstruction task, together with evaluation metrics, and present results from a novel method using neurally guided search to recover a construction sequence from a target geometry.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "willis|fusion_360_gallery_a_dataset_and_environment_for_programmatic_cad_reconstruction", "one-sentence_summary": "The Fusion 360 Gallery reconstruction dataset and environment for learning CAD reconstruction.", "supplementary_material": "", "pdf": "/pdf/3ec59d0f61896944fa3f9101bf9f3be31f7eac11.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=n8YNQi5A3", "_bibtex": "@misc{\nwillis2021fusion,\ntitle={Fusion 360 Gallery: A Dataset and Environment for Programmatic {\\{}CAD{\\}} Reconstruction},\nauthor={Karl Willis and Yewen Pu and Jieliang Luo and Hang Chu and Tao Du and Joseph Lambourne and Armando Solar-Lezama and Wojciech Matusik},\nyear={2021},\nurl={https://openreview.net/forum?id=HbZTcIuiMAG}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "HbZTcIuiMAG", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper354/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper354/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper354/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper354/Authors|ICLR.cc/2021/Conference/Paper354/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper354/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923871894, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper354/-/Official_Comment"}}}, {"id": "N8SfAFH3pmf", "original": null, "number": 4, "cdate": 1605128187939, "ddate": null, "tcdate": 1605128187939, "tmdate": 1605128187939, "tddate": null, "forum": "HbZTcIuiMAG", "replyto": "MavPf8OfhXT", "invitation": "ICLR.cc/2021/Conference/Paper354/-/Official_Comment", "content": {"title": "Request for confirmation of SOTA baselines", "comment": "Reviewer 1,\n\nThank you for the thoughtful review. Allow us to first clarify the SOTA baselines.\n\n*Re: 1. Agent model*\nWe look forward to running additional baselines to demonstrate that the CAD reconstruction task from B-rep input is not trivially addressed by known SOTA. Currently we plan to present further results using a Graph Attention Network (GAT) [1] and a Graph Isomorphism Network (GIN) [2]. Please advise if these two baselines are suitable for representing SOTA.\n\n*Re: 2 Search*\nIn the appendix of the paper we currently provide results for two other search strategies: Beam Search and Best First Search. We will add additional plots and discussion to make the comparison of search strategies clearer and provide an update for feedback at that time.\n\n[1] https://arxiv.org/abs/1710.10903\n[2] https://arxiv.org/abs/1810.00826"}, "signatures": ["ICLR.cc/2021/Conference/Paper354/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper354/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Fusion 360 Gallery: A Dataset and Environment for Programmatic CAD Reconstruction", "authorids": ["~Karl_Willis1", "~Yewen_Pu1", "~Jieliang_Luo1", "~Hang_Chu4", "~Tao_Du1", "joseph.lambourne@autodesk.com", "~Armando_Solar-Lezama1", "~Wojciech_Matusik2"], "authors": ["Karl Willis", "Yewen Pu", "Jieliang Luo", "Hang Chu", "Tao Du", "Joseph Lambourne", "Armando Solar-Lezama", "Wojciech Matusik"], "keywords": ["CAD", "dataset", "3D", "reconstruction", "environment", "design", "sequence"], "abstract": "Parametric computer-aided design (CAD) is a standard paradigm used for the design of manufactured objects. CAD designers perform modeling operations, such as sketch and extrude, to form a construction sequence that makes up a final design. Despite the pervasiveness of parametric CAD and growing interest from the research community, a dataset of human designed 3D CAD construction sequences has not been available to-date. In this paper we present the Fusion 360 Gallery reconstruction dataset and environment for learning CAD reconstruction. We provide a dataset of 8,625 designs, comprising sequential sketch and extrude modeling operations, together with a complementary environment called the Fusion 360 Gym, to assist with performing CAD reconstruction. We outline a standard CAD reconstruction task, together with evaluation metrics, and present results from a novel method using neurally guided search to recover a construction sequence from a target geometry.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "willis|fusion_360_gallery_a_dataset_and_environment_for_programmatic_cad_reconstruction", "one-sentence_summary": "The Fusion 360 Gallery reconstruction dataset and environment for learning CAD reconstruction.", "supplementary_material": "", "pdf": "/pdf/3ec59d0f61896944fa3f9101bf9f3be31f7eac11.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=n8YNQi5A3", "_bibtex": "@misc{\nwillis2021fusion,\ntitle={Fusion 360 Gallery: A Dataset and Environment for Programmatic {\\{}CAD{\\}} Reconstruction},\nauthor={Karl Willis and Yewen Pu and Jieliang Luo and Hang Chu and Tao Du and Joseph Lambourne and Armando Solar-Lezama and Wojciech Matusik},\nyear={2021},\nurl={https://openreview.net/forum?id=HbZTcIuiMAG}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "HbZTcIuiMAG", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper354/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper354/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper354/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper354/Authors|ICLR.cc/2021/Conference/Paper354/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper354/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923871894, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper354/-/Official_Comment"}}}, {"id": "LV4nRcvf82", "original": null, "number": 1, "cdate": 1603794643036, "ddate": null, "tcdate": 1603794643036, "tmdate": 1605024708262, "tddate": null, "forum": "HbZTcIuiMAG", "replyto": "HbZTcIuiMAG", "invitation": "ICLR.cc/2021/Conference/Paper354/-/Official_Review", "content": {"title": "Valuable new dataset, environment, and comprehensive evaluation metrics for 3D CAD design ", "review": "Summary:\n\nThe paper presents the first large scale CAD construction sequence dataset together with environment that allows us to synthesize 3D CAD from these sequences. The dataset and environment are essential building blocks for applying machine learning algorithms to CAD design process. Furthermore, the paper proposes comprehensive evaluation metrics and a baseline method for predicting the sequence of 3D CAD design from a CAD model. \n\nThe dataset and environment are highly valuable to the research community. Although the proposed baseline and task have room for improvement, I believe this work merits publication.\n\nPros:\n- The first large scale CAD dataset with the comprehensive construction sequence data. \n- The environment can construct these sequence data and allow us to synthetically generate new data. Together with the 360 Fusion Gallery, this would be a great step towards learning human design processes.\n- A good baseline method with comprehensive evaluation metrics.\n\nCons:\n- The proposed task of CAD sequence reconstruction requires a target geometry in the same CAD format. This would not be called \"raw geometry\u201d as in the abstract. Raw geometry is often referred to as what we can derive from scan data including point clouds and meshes.\n- As the aforementioned CAD reconstruction task is not very practical, adding another practical task such as reconstructing the sequence from raw geometry data is highly recommended. \n- Regarding the evaluation metrics, it is not clear whether the conciseness is computed from only the successful reconstructions or the entire test set. If the former is the case, comparison using this metric across different approaches would not be fair. Otherwise, this does not necessarily provide a sense of how efficient the evaluated algorithm is. Clarification on this is recommended.\n\nQuestions/Remarks:\n- In terms of accuracy, the augmentation rather hurts preciseness with more steps. Why is this happening? Is this due to the limited capacity of the proposed network? Discussion on this would be helpful.\n- The following reference can be cited and discussed. \n\ufeff\"Modeling 3D Shapes by Reinforcement Learning\u201d Cheng Lin, Tingxiang Fan, Wenping Wang, Matthias Nie\u00dfner ECCV 2020", "rating": "7: Good paper, accept", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["ICLR.cc/2021/Conference/Paper354/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper354/AnonReviewer3"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Fusion 360 Gallery: A Dataset and Environment for Programmatic CAD Reconstruction", "authorids": ["~Karl_Willis1", "~Yewen_Pu1", "~Jieliang_Luo1", "~Hang_Chu4", "~Tao_Du1", "joseph.lambourne@autodesk.com", "~Armando_Solar-Lezama1", "~Wojciech_Matusik2"], "authors": ["Karl Willis", "Yewen Pu", "Jieliang Luo", "Hang Chu", "Tao Du", "Joseph Lambourne", "Armando Solar-Lezama", "Wojciech Matusik"], "keywords": ["CAD", "dataset", "3D", "reconstruction", "environment", "design", "sequence"], "abstract": "Parametric computer-aided design (CAD) is a standard paradigm used for the design of manufactured objects. CAD designers perform modeling operations, such as sketch and extrude, to form a construction sequence that makes up a final design. Despite the pervasiveness of parametric CAD and growing interest from the research community, a dataset of human designed 3D CAD construction sequences has not been available to-date. In this paper we present the Fusion 360 Gallery reconstruction dataset and environment for learning CAD reconstruction. We provide a dataset of 8,625 designs, comprising sequential sketch and extrude modeling operations, together with a complementary environment called the Fusion 360 Gym, to assist with performing CAD reconstruction. We outline a standard CAD reconstruction task, together with evaluation metrics, and present results from a novel method using neurally guided search to recover a construction sequence from a target geometry.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "willis|fusion_360_gallery_a_dataset_and_environment_for_programmatic_cad_reconstruction", "one-sentence_summary": "The Fusion 360 Gallery reconstruction dataset and environment for learning CAD reconstruction.", "supplementary_material": "", "pdf": "/pdf/3ec59d0f61896944fa3f9101bf9f3be31f7eac11.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=n8YNQi5A3", "_bibtex": "@misc{\nwillis2021fusion,\ntitle={Fusion 360 Gallery: A Dataset and Environment for Programmatic {\\{}CAD{\\}} Reconstruction},\nauthor={Karl Willis and Yewen Pu and Jieliang Luo and Hang Chu and Tao Du and Joseph Lambourne and Armando Solar-Lezama and Wojciech Matusik},\nyear={2021},\nurl={https://openreview.net/forum?id=HbZTcIuiMAG}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq . ***Please remember to file the Code-of-Ethics report. Once you submitted the review, a link to the report will be visible in the bottom right corner of your review.***", "required": true, "markdown": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}, "forum": "HbZTcIuiMAG", "replyto": "HbZTcIuiMAG", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"], "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper354/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1607428800000, "duedate": 1606752000000, "multiReply": false, "readers": ["everyone"], "tcdate": 1602538145040, "tmdate": 1606915792142, "super": "ICLR.cc/2021/Conference/-/Official_Review", "signatures": ["OpenReview.net"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Paper354/Reviewers", "OpenReview.net/Support"], "id": "ICLR.cc/2021/Conference/Paper354/-/Official_Review"}}}, {"id": "eaEp1oK6PiS", "original": null, "number": 2, "cdate": 1603852267058, "ddate": null, "tcdate": 1603852267058, "tmdate": 1605024708191, "tddate": null, "forum": "HbZTcIuiMAG", "replyto": "HbZTcIuiMAG", "invitation": "ICLR.cc/2021/Conference/Paper354/-/Official_Review", "content": {"title": "Comprehensive submission, albeit somewhat domain specific to CAD community", "review": "The paper describes a new dataset of 3D geometry construction sequences based on sequential sketching (i.e. sets of two-dimensional curves) and extruding (i.e. axes, angles and distances for extrusion profiles from sketches) combined with Boolean solid geometry operations. The dataset comprises the resulting objects as well as the human designed sketch-extrude sequence that lead to the object geometry. The 8625 objects are available in three different geometry representations (boundary representation, mesh, and construction sequence in structured format). Furthermore the submission describes a new infrastructure (\"gym\") to train and evaluate algorithms that estimate such construction sequences, as well as evaluation metrics to gauge the efficiency and effectiveness of such estimation algorithms. The paper also provides a reference method for sequence estimation based on imitation learning as well as several baselines and their empirical evaluation with respect to the posed benchmarks.\n\n### Strengths\n**[S1]** The paper is written well and takes a comprehensive look on a new dataset from the perspective of the data itself, semi-synthetic generation of new data, evaluation metrics and benchmarking on the data as well as a reference method and its performance analysis.\n\n**[S2]** I particularly appreciate the synthetic data generation/augmentation capability. This may enable more structured studies in the future, for instance with respect to specifics of the constructed geometry: Does complexity of the design geometry matter, does the topology make a difference in achievable performance? \n\n**[S3]** New datasets are often valuable contributions to the community, in particular when they allow the discovery of new insight (however see W1 below)\n\n### Weaknesses\n**[W1]** The main contribution of the paper seems to me the database itself and the associated gym. While new datasets are a good contribution in general, I am not convinced that the target audience of ICLR will benefit in a substantial matter from the exposure. Specifically, I feel that the benefit of human-designed vs. synthetically generated designs is not worked out convincingly. What can I learn, what insight can I gain from the human designs that I cannot from, e.g., purely synthetical, procedural designs? Are there difference in the statistics? It would strengthen the paper to highlight evidence that the data does have benefit in the sense that I can achieve something substantially new. \n\n**[W2]** The submission claims a \"novel, neurally guided method\", but I do not see the novelty laid out clearly: outside of \"using common sketch and extrude CAD modeling operations from real human designs\" in section 2, the novelty is vague and the relation to the state of the art imprecise. Is it the use of sketch and extrude operations in an otherwise previously exposed sequence learning task? Is it using human-designed sequences (then, see W1)? It would strengthen the case for the paper if the novelty would be exposed more concisely.\n\n### Further comments:\nI do appreciate the comprehensiveness across data, benchmarks, reference solutions and evaluation of the paper and such data and gyms can be an important piece of the machine and representation learning puzzle. As it is, I am concerned that the submission is not appealing to a sufficiently large audience at ICLR.", "rating": "5: Marginally below acceptance threshold", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "signatures": ["ICLR.cc/2021/Conference/Paper354/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper354/AnonReviewer2"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Fusion 360 Gallery: A Dataset and Environment for Programmatic CAD Reconstruction", "authorids": ["~Karl_Willis1", "~Yewen_Pu1", "~Jieliang_Luo1", "~Hang_Chu4", "~Tao_Du1", "joseph.lambourne@autodesk.com", "~Armando_Solar-Lezama1", "~Wojciech_Matusik2"], "authors": ["Karl Willis", "Yewen Pu", "Jieliang Luo", "Hang Chu", "Tao Du", "Joseph Lambourne", "Armando Solar-Lezama", "Wojciech Matusik"], "keywords": ["CAD", "dataset", "3D", "reconstruction", "environment", "design", "sequence"], "abstract": "Parametric computer-aided design (CAD) is a standard paradigm used for the design of manufactured objects. CAD designers perform modeling operations, such as sketch and extrude, to form a construction sequence that makes up a final design. Despite the pervasiveness of parametric CAD and growing interest from the research community, a dataset of human designed 3D CAD construction sequences has not been available to-date. In this paper we present the Fusion 360 Gallery reconstruction dataset and environment for learning CAD reconstruction. We provide a dataset of 8,625 designs, comprising sequential sketch and extrude modeling operations, together with a complementary environment called the Fusion 360 Gym, to assist with performing CAD reconstruction. We outline a standard CAD reconstruction task, together with evaluation metrics, and present results from a novel method using neurally guided search to recover a construction sequence from a target geometry.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "willis|fusion_360_gallery_a_dataset_and_environment_for_programmatic_cad_reconstruction", "one-sentence_summary": "The Fusion 360 Gallery reconstruction dataset and environment for learning CAD reconstruction.", "supplementary_material": "", "pdf": "/pdf/3ec59d0f61896944fa3f9101bf9f3be31f7eac11.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=n8YNQi5A3", "_bibtex": "@misc{\nwillis2021fusion,\ntitle={Fusion 360 Gallery: A Dataset and Environment for Programmatic {\\{}CAD{\\}} Reconstruction},\nauthor={Karl Willis and Yewen Pu and Jieliang Luo and Hang Chu and Tao Du and Joseph Lambourne and Armando Solar-Lezama and Wojciech Matusik},\nyear={2021},\nurl={https://openreview.net/forum?id=HbZTcIuiMAG}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq . ***Please remember to file the Code-of-Ethics report. Once you submitted the review, a link to the report will be visible in the bottom right corner of your review.***", "required": true, "markdown": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}, "forum": "HbZTcIuiMAG", "replyto": "HbZTcIuiMAG", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"], "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper354/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1607428800000, "duedate": 1606752000000, "multiReply": false, "readers": ["everyone"], "tcdate": 1602538145040, "tmdate": 1606915792142, "super": "ICLR.cc/2021/Conference/-/Official_Review", "signatures": ["OpenReview.net"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Paper354/Reviewers", "OpenReview.net/Support"], "id": "ICLR.cc/2021/Conference/Paper354/-/Official_Review"}}}, {"id": "w-cQ0AdQ1hj", "original": null, "number": 3, "cdate": 1604050433867, "ddate": null, "tcdate": 1604050433867, "tmdate": 1605024708121, "tddate": null, "forum": "HbZTcIuiMAG", "replyto": "HbZTcIuiMAG", "invitation": "ICLR.cc/2021/Conference/Paper354/-/Official_Review", "content": {"title": "Very interesting paper, unfortunately out of my field of expertise", "review": "I have to admit straight away that this paper is far from my field of expertise (computer vision, generative networks). I have not worked with CAD models, and I am not in expert in reinforcement/imitation learning. My review is thus written from the \"educated outsider\" viewpoint.\n\nFrom that viewpoint, the paper is very strong. It introduces a meaningful problem (CAD modeling sequence reconstruction), motivates the need for a new task and the direction of research, describes the full task and the compromises it makes (face extrudes rather than sketch extrudes are considered in the simplified task). The paper then introduces a new training/test dataset and an environment for training agents, and evaluates a reasonable set of agents rather extensively.\n\nAs a slight criticism, I found that too many details are moved from Section 5 to the supmat. E.g. what is meant by MLP with\n\"an auto-regressive connection between the two target faces\" was completely unclear before I looked into the supmat (and the phrase did not refer me to supmat either).\nOtherwise, the paper is well-written and has nice visualizations (though they crash my PDF viewer) that aid understanding.\n\nOverall, I really enjoyed reading the paper, and I am not able to identify any flaws. As far as I can judge based on my limited knowledge, the paper (together with associated dataset and environment) is likely to spur new research and to be impactful. I therefore give it a strong rating, but I cannot exclude that I have missed some flaws that would be identifiable by an expert.", "rating": "8: Top 50% of accepted papers, clear accept", "confidence": "1: The reviewer's evaluation is an educated guess"}, "signatures": ["ICLR.cc/2021/Conference/Paper354/AnonReviewer4"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper354/AnonReviewer4"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Fusion 360 Gallery: A Dataset and Environment for Programmatic CAD Reconstruction", "authorids": ["~Karl_Willis1", "~Yewen_Pu1", "~Jieliang_Luo1", "~Hang_Chu4", "~Tao_Du1", "joseph.lambourne@autodesk.com", "~Armando_Solar-Lezama1", "~Wojciech_Matusik2"], "authors": ["Karl Willis", "Yewen Pu", "Jieliang Luo", "Hang Chu", "Tao Du", "Joseph Lambourne", "Armando Solar-Lezama", "Wojciech Matusik"], "keywords": ["CAD", "dataset", "3D", "reconstruction", "environment", "design", "sequence"], "abstract": "Parametric computer-aided design (CAD) is a standard paradigm used for the design of manufactured objects. CAD designers perform modeling operations, such as sketch and extrude, to form a construction sequence that makes up a final design. Despite the pervasiveness of parametric CAD and growing interest from the research community, a dataset of human designed 3D CAD construction sequences has not been available to-date. In this paper we present the Fusion 360 Gallery reconstruction dataset and environment for learning CAD reconstruction. We provide a dataset of 8,625 designs, comprising sequential sketch and extrude modeling operations, together with a complementary environment called the Fusion 360 Gym, to assist with performing CAD reconstruction. We outline a standard CAD reconstruction task, together with evaluation metrics, and present results from a novel method using neurally guided search to recover a construction sequence from a target geometry.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "willis|fusion_360_gallery_a_dataset_and_environment_for_programmatic_cad_reconstruction", "one-sentence_summary": "The Fusion 360 Gallery reconstruction dataset and environment for learning CAD reconstruction.", "supplementary_material": "", "pdf": "/pdf/3ec59d0f61896944fa3f9101bf9f3be31f7eac11.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=n8YNQi5A3", "_bibtex": "@misc{\nwillis2021fusion,\ntitle={Fusion 360 Gallery: A Dataset and Environment for Programmatic {\\{}CAD{\\}} Reconstruction},\nauthor={Karl Willis and Yewen Pu and Jieliang Luo and Hang Chu and Tao Du and Joseph Lambourne and Armando Solar-Lezama and Wojciech Matusik},\nyear={2021},\nurl={https://openreview.net/forum?id=HbZTcIuiMAG}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq . ***Please remember to file the Code-of-Ethics report. Once you submitted the review, a link to the report will be visible in the bottom right corner of your review.***", "required": true, "markdown": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}, "forum": "HbZTcIuiMAG", "replyto": "HbZTcIuiMAG", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"], "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper354/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1607428800000, "duedate": 1606752000000, "multiReply": false, "readers": ["everyone"], "tcdate": 1602538145040, "tmdate": 1606915792142, "super": "ICLR.cc/2021/Conference/-/Official_Review", "signatures": ["OpenReview.net"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Paper354/Reviewers", "OpenReview.net/Support"], "id": "ICLR.cc/2021/Conference/Paper354/-/Official_Review"}}}, {"id": "MavPf8OfhXT", "original": null, "number": 4, "cdate": 1604365443917, "ddate": null, "tcdate": 1604365443917, "tmdate": 1605024708058, "tddate": null, "forum": "HbZTcIuiMAG", "replyto": "HbZTcIuiMAG", "invitation": "ICLR.cc/2021/Conference/Paper354/-/Official_Review", "content": {"title": "Good dataset paper but insufficient evaluation of SOTA for the baseline approach ", "review": "### Summary and Contributions\nThe CAD reconstruction problem is defined as the recovery of the sequence of modeling operations used to construct the CAD model, from the raw geometry input (triangle meshes, point clouds, or, B-reps). The paper proposes a novel dataset as well as a generic framework implementing an MDP (Markov Decision Process) formulation for training a neural CAD reconstruction agent.  \n\nThis the first dataset which includes the sequence of CAD modeling operations as ground truth containing 8.5K+ human-designed real-world CAD models. The CAD reconstruction task is formulated as that of training a generic neural MDP agent and provided in an programming environment to the research community to train such models. Finally, a novel algorithm is provided as a baseline to solve the CAD reconstruction problem.  \n\n### Detailed Review \nThe following is the detailed review of the paper, organized into strengths and weaknesses subsections. \n\n#### Strengths\n\n##### Relevance and Significance \nThere is a large number of man-made objects that we interact with that are created using computer-aided design. The modeling steps, which are often lost, are important in understanding, editing, simulation and manufacturing such objects, and need to be reconstructed. This topic is of considerable importance to the CAD community. In addition, approaches, that can reverse engineer the generative process should be of general interest to the wider ML and computer vision community, as well.  \n\n##### Relation to Prior Art \nThe paper does a good job of presenting the prior art, identifying the challenges and need for the presented work. The dataset including the modeling sequences for real, human-designed CAD models is the first of its kind. Since it\u2019s a novel problem (first dataset of the kind), the proposed baseline implementing a learning-based approach to this problem is novel as well (though simplistic, see below).  \n\n##### Reproducibility \nSince the entire dataset and the baseline is released in an open-source programming environment, it should be easy to reproduce and verify the results. \n\n##### Clarity \nThe paper is written well and is easy to understand. \n\n#### Weaknesses\n \n##### Methodology \nThis is largely a dataset paper. Introduction of a new dataset to the research community needs to demonstrate that the tasks to be solved on the dataset is not trivially addressed by the known state of the art. The paper falls short of demonstrating that. \n\n1. Agent model: Two models are considered \u2013 MLP (trivial embeddings based on vertex features) and seemingly trivial embeddings of MPNs. The paper doesn't present enough details about the choices made for obtaining meaningful embeddings. This seems to be the heart of the approach and the authors don't present a compelling approach or a comparative evaluation of a set of choices based on the SOTA for graph embeddings, to model the agent. \n\n2. Search: Similarly, the search is trivially implemented using a random rollout. There are much better search strategies available in the SOTA to bring to bear on the problem. \n\n In summary. I don't think that the presented baseline properly brings the SOTA to bear on the problem and thus demonstrates a need for additional research to be spurred on by this dataset.  \n\n##### Novelty \nThe presented approach is a straight-forward application of known techniques.  \n\n##### Empirical Evaluation \nAn important question to consider when proposing a presumably difficult new problem when addressed by known art is to investigate what aspect of the new problem really taxes the state of the art and to stage the experiments and analysis carefully for the same. There are many questions to be addressed here, for e.g. (a) How is stationarity (or, invariance over the topologies) achieved across training, validation and  test sets, (b) Does the training overfit (are the architectures used of enough capacity)?, (c) Is there generalization gap? If so, why? Etc. \n\n### Assessment\nThough the problem seems relevant and of significance to the research community, the dataset of considerable value, the paper doesn't make a strong case whether and how this problem challenges the known state of the art. In its current form, I do not recommend the publication of this paper. \n\n \n\n ", "rating": "4: Ok but not good enough - rejection", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["ICLR.cc/2021/Conference/Paper354/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper354/AnonReviewer1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Fusion 360 Gallery: A Dataset and Environment for Programmatic CAD Reconstruction", "authorids": ["~Karl_Willis1", "~Yewen_Pu1", "~Jieliang_Luo1", "~Hang_Chu4", "~Tao_Du1", "joseph.lambourne@autodesk.com", "~Armando_Solar-Lezama1", "~Wojciech_Matusik2"], "authors": ["Karl Willis", "Yewen Pu", "Jieliang Luo", "Hang Chu", "Tao Du", "Joseph Lambourne", "Armando Solar-Lezama", "Wojciech Matusik"], "keywords": ["CAD", "dataset", "3D", "reconstruction", "environment", "design", "sequence"], "abstract": "Parametric computer-aided design (CAD) is a standard paradigm used for the design of manufactured objects. CAD designers perform modeling operations, such as sketch and extrude, to form a construction sequence that makes up a final design. Despite the pervasiveness of parametric CAD and growing interest from the research community, a dataset of human designed 3D CAD construction sequences has not been available to-date. In this paper we present the Fusion 360 Gallery reconstruction dataset and environment for learning CAD reconstruction. We provide a dataset of 8,625 designs, comprising sequential sketch and extrude modeling operations, together with a complementary environment called the Fusion 360 Gym, to assist with performing CAD reconstruction. We outline a standard CAD reconstruction task, together with evaluation metrics, and present results from a novel method using neurally guided search to recover a construction sequence from a target geometry.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "willis|fusion_360_gallery_a_dataset_and_environment_for_programmatic_cad_reconstruction", "one-sentence_summary": "The Fusion 360 Gallery reconstruction dataset and environment for learning CAD reconstruction.", "supplementary_material": "", "pdf": "/pdf/3ec59d0f61896944fa3f9101bf9f3be31f7eac11.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=n8YNQi5A3", "_bibtex": "@misc{\nwillis2021fusion,\ntitle={Fusion 360 Gallery: A Dataset and Environment for Programmatic {\\{}CAD{\\}} Reconstruction},\nauthor={Karl Willis and Yewen Pu and Jieliang Luo and Hang Chu and Tao Du and Joseph Lambourne and Armando Solar-Lezama and Wojciech Matusik},\nyear={2021},\nurl={https://openreview.net/forum?id=HbZTcIuiMAG}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq . ***Please remember to file the Code-of-Ethics report. Once you submitted the review, a link to the report will be visible in the bottom right corner of your review.***", "required": true, "markdown": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}, "forum": "HbZTcIuiMAG", "replyto": "HbZTcIuiMAG", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"], "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper354/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1607428800000, "duedate": 1606752000000, "multiReply": false, "readers": ["everyone"], "tcdate": 1602538145040, "tmdate": 1606915792142, "super": "ICLR.cc/2021/Conference/-/Official_Review", "signatures": ["OpenReview.net"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Paper354/Reviewers", "OpenReview.net/Support"], "id": "ICLR.cc/2021/Conference/Paper354/-/Official_Review"}}}], "count": 11}