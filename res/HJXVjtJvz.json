{"notes": [{"tddate": null, "replyto": null, "ddate": null, "tmdate": 1528124445261, "tcdate": 1518471978916, "number": 308, "cdate": 1518471978916, "id": "HJXVjtJvz", "invitation": "ICLR.cc/2018/Workshop/-/Submission", "forum": "HJXVjtJvz", "signatures": ["~Fisher_Yu3"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Workshop"], "content": {"title": "Learning Rich Image Representation with Deep Layer Aggregation", "abstract": "Architectural efforts are exploring many dimensions for network backbones, designing deeper or wider architectures, but how to best aggregate layers and blocks across a network deserves further attention. We augment standard architectures with deeper aggregation to better fuse information across layers. Our deep layer aggregation structures iteratively and hierarchically merge the feature hierarchy to make networks with better accuracy and fewer parameters. Experiments across architectures and tasks show that deep layer aggregation improves recognition and resolution compared to existing branching and merging schemes.", "paperhash": "yu|learning_rich_image_representation_with_deep_layer_aggregation", "_bibtex": "@misc{\n  yu2018learning,\n  title={Learning Rich Image Representation with Deep Layer Aggregation},\n  author={Fisher Yu and Dequan Wang and Evan Shelhamer and Trevor Darrell},\n  year={2018},\n  url={https://openreview.net/forum?id=HJXVjtJvz}\n}", "authorids": ["fy@berkeley.edu", "dqwang@eecs.berkeley.edu", "shelhamer@eecs.berkeley.edu", "trevor@eecs.berkeley.edu"], "authors": ["Fisher Yu", "Dequan Wang", "Evan Shelhamer", "Trevor Darrell"], "keywords": [], "pdf": "/pdf/9462dc4e4bfea59c1798df7a09f4befe255df9a6.pdf"}, "nonreaders": [], "details": {"replyCount": 4, "writable": false, "overwriting": [], "revisions": false, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1518472800000, "tmdate": 1518474081690, "id": "ICLR.cc/2018/Workshop/-/Submission", "writers": ["ICLR.cc/2018/Workshop"], "signatures": ["ICLR.cc/2018/Workshop"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": null, "replyto": null, "writers": {"values": ["ICLR.cc/2018/Workshop"]}, "signatures": {"values-regex": "~.*|ICLR.cc/2018/Workshop", "description": "Your authorized identity to be associated with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"pdf": {"required": true, "order": 9, "value-regex": "upload", "description": "Upload a PDF file that ends with .pdf"}, "title": {"required": true, "order": 1, "description": "Title of paper.", "value-regex": ".{1,250}"}, "abstract": {"required": true, "order": 8, "description": "Abstract of paper.", "value-regex": "[\\S\\s]{1,5000}"}, "authors": {"required": true, "order": 2, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of author names. Please provide real names; identities will be anonymized."}, "keywords": {"order": 6, "values-regex": "(^$)|[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of keywords."}, "TL;DR": {"required": false, "order": 7, "description": "\"Too Long; Didn't Read\": a short sentence describing your paper", "value-regex": "[^\\n]{0,500}"}, "authorids": {"required": true, "order": 3, "values-regex": "([a-z0-9_\\-\\.]{2,}@[a-z0-9_\\-\\.]{2,}\\.[a-z]{2,},){0,}([a-z0-9_\\-\\.]{2,}@[a-z0-9_\\-\\.]{2,}\\.[a-z]{2,})", "description": "Comma separated list of author email addresses, lowercased, in the same order as above. For authors with existing OpenReview accounts, please make sure that the provided email address(es) match those listed in the author's profile. Please provide real emails; identities will be anonymized."}}}, "nonreaders": [], "noninvitees": [], "expdate": 1526248800000, "cdate": 1518474081690}}}, {"tddate": null, "ddate": null, "original": null, "tmdate": 1521582983013, "tcdate": 1519751981508, "number": 1, "cdate": 1519751981508, "id": "HkBEQzX_M", "invitation": "ICLR.cc/2018/Workshop/-/Paper308/Official_Review", "forum": "HJXVjtJvz", "replyto": "HJXVjtJvz", "signatures": ["ICLR.cc/2018/Workshop/Paper308/AnonReviewer3"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Workshop/Paper308/AnonReviewer3"], "content": {"title": "An interesting contribution not properly formatted for 3 pages", "rating": "5: Marginally below acceptance threshold", "review": "This paper presents an interesting study that explores different methods for aggregating features across layers of a deep convolutional network, using ResNet and ResNext as baseline architectures. The aggregations are structured in two different types, iterative (IDA) and hierarchical (HDA) deep aggregations, considering three different variations of the HDA one.\n\nThe text is clear and well motivated until reaching the experimental section, where the claims of the text do not match the presented results. While the introduction states that experiments have been run in tasks of large-scale image classification, fine-grained recognition, semantic segmentation and boundary detection, the text only includes a Figure on four datasets for fine-grained classification. Moreover, the Figure is not referred in the text and the legend does not match the text (eg. refers to VGG, to configurations -60 and -102, or in the text they talk about parameter P). Another missing baseline in the results is DenseNet, which is mentioned in the introduction. It seems this workshop paper is a shortened version of a longer paper published on arXiv and pointed by the authors in a footnote, and that the reduction of the length was not made with enough care. \n\nIf focusing on the reported results, they only address accuracy performance. However, it would also be desirable to include a discussion and/or figures regarding the memory requirements of using aggregated features, as well as a clear statement regarding if the proposed architectures increase the amount of parameters in the model. \n\nPROS\n- The significance of the research question is relevant and interesting.\n- Authors with a strong scientific reputation claim state of the art on several fine-grain recognition benchmarks, best-in-class accuracy on semantic segmentation in Cityscapes and state-of-the-art boundary detection on PASCAL.\n- Sections 1 and 2 are well written an motivated.\n\nCONS\n- The excellent results announced in the introduction are not included in the paper, which makes the paper not self-contained. The text should be rewritten to be self-contained. Focusing in a single task and just mentioning the rest at the very end of the text would greatly improve the clarity of the work.\n- Reported results do not explicitly compare with any other result from the state of the art (or, at least, it is not clear that this is done according to the content of Figure 3).\n- Aggregating features seems to require higher memory and computational requirements, which are not considered in the included results.\n", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Learning Rich Image Representation with Deep Layer Aggregation", "abstract": "Architectural efforts are exploring many dimensions for network backbones, designing deeper or wider architectures, but how to best aggregate layers and blocks across a network deserves further attention. We augment standard architectures with deeper aggregation to better fuse information across layers. Our deep layer aggregation structures iteratively and hierarchically merge the feature hierarchy to make networks with better accuracy and fewer parameters. Experiments across architectures and tasks show that deep layer aggregation improves recognition and resolution compared to existing branching and merging schemes.", "paperhash": "yu|learning_rich_image_representation_with_deep_layer_aggregation", "_bibtex": "@misc{\n  yu2018learning,\n  title={Learning Rich Image Representation with Deep Layer Aggregation},\n  author={Fisher Yu and Dequan Wang and Evan Shelhamer and Trevor Darrell},\n  year={2018},\n  url={https://openreview.net/forum?id=HJXVjtJvz}\n}", "authorids": ["fy@berkeley.edu", "dqwang@eecs.berkeley.edu", "shelhamer@eecs.berkeley.edu", "trevor@eecs.berkeley.edu"], "authors": ["Fisher Yu", "Dequan Wang", "Evan Shelhamer", "Trevor Darrell"], "keywords": [], "pdf": "/pdf/9462dc4e4bfea59c1798df7a09f4befe255df9a6.pdf"}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1520657999000, "tmdate": 1521582982777, "id": "ICLR.cc/2018/Workshop/-/Paper308/Official_Review", "writers": ["ICLR.cc/2018/Workshop"], "signatures": ["ICLR.cc/2018/Workshop"], "readers": ["everyone"], "invitees": ["ICLR.cc/2018/Workshop/Paper308/Reviewers"], "noninvitees": ["ICLR.cc/2018/Workshop/Paper308/AnonReviewer3", "ICLR.cc/2018/Workshop/Paper308/AnonReviewer2", "ICLR.cc/2018/Workshop/Paper308/AnonReviewer1"], "reply": {"forum": "HJXVjtJvz", "replyto": "HJXVjtJvz", "writers": {"values-regex": "ICLR.cc/2018/Workshop/Paper308/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2018/Workshop/Paper308/AnonReviewer[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"required": true, "order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"required": true, "order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "value-regex": "[\\S\\s]{1,200000}"}, "rating": {"required": true, "order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"required": true, "order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1528433999000, "cdate": 1521582982777}}}, {"tddate": null, "ddate": null, "original": null, "tmdate": 1521582969104, "tcdate": 1520006045319, "number": 2, "cdate": 1520006045319, "id": "BySoQePdM", "invitation": "ICLR.cc/2018/Workshop/-/Paper308/Official_Review", "forum": "HJXVjtJvz", "replyto": "HJXVjtJvz", "signatures": ["ICLR.cc/2018/Workshop/Paper308/AnonReviewer2"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Workshop/Paper308/AnonReviewer2"], "content": {"title": "Interesting forms of aggregating layers", "rating": "7: Good paper, accept", "review": "This paper proposes a more complex form of aggregation of layers from different parts of the neural netwwork. In particular, the authors proposes two forms of aggregation that are then jointly used in their final models. The first is called iterative deep aggregation, which sequentailly aggregates different stages of the network. The second is called hierarchical deep aggregation and it merges different blocks within a stage of the network. Authors compare a network enriched with the two aggregations and show improved results in 3 out of 4 fine-grained classification datasets.\n\nPros:\n- The paper is in general well presented, and Fig. 1 helps to understand the idea.\n- The idea of generalizing the concept of aggregation is nice, although, in practice there can be so many configuration and details that I am not sure Fig. 1 can really include all forms of aggregation. \n\nCons:\n- Tha authors did not consider Convolutional Neural Fabric [Saxena and Verbeek, NIPS'17], in which the different resolution levels can be though as a form of aggregation.\n- The authors should mention/consider also Dense DenseNet [Huang et al. 2016] and FractalNet [Larsson et al. 2016]. The aggregations are done only at stage level (within convolutions at the same resolution), but they are still based on aggregations of layers and they can resemble the iterative aggregation.\n- The authors should make clear that HDA is done within one stage, while IDA is done over multiple stages. The difference is somehow shown in Fig. 1, but it took me a bit to understand that.\n- The evaluation is limited, but for a workshop paper it can be enough\n\nAdditional comments:\nIt would be interesting to see an ablation study to understand which form of aggregation is the more effective", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Learning Rich Image Representation with Deep Layer Aggregation", "abstract": "Architectural efforts are exploring many dimensions for network backbones, designing deeper or wider architectures, but how to best aggregate layers and blocks across a network deserves further attention. We augment standard architectures with deeper aggregation to better fuse information across layers. Our deep layer aggregation structures iteratively and hierarchically merge the feature hierarchy to make networks with better accuracy and fewer parameters. Experiments across architectures and tasks show that deep layer aggregation improves recognition and resolution compared to existing branching and merging schemes.", "paperhash": "yu|learning_rich_image_representation_with_deep_layer_aggregation", "_bibtex": "@misc{\n  yu2018learning,\n  title={Learning Rich Image Representation with Deep Layer Aggregation},\n  author={Fisher Yu and Dequan Wang and Evan Shelhamer and Trevor Darrell},\n  year={2018},\n  url={https://openreview.net/forum?id=HJXVjtJvz}\n}", "authorids": ["fy@berkeley.edu", "dqwang@eecs.berkeley.edu", "shelhamer@eecs.berkeley.edu", "trevor@eecs.berkeley.edu"], "authors": ["Fisher Yu", "Dequan Wang", "Evan Shelhamer", "Trevor Darrell"], "keywords": [], "pdf": "/pdf/9462dc4e4bfea59c1798df7a09f4befe255df9a6.pdf"}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1520657999000, "tmdate": 1521582982777, "id": "ICLR.cc/2018/Workshop/-/Paper308/Official_Review", "writers": ["ICLR.cc/2018/Workshop"], "signatures": ["ICLR.cc/2018/Workshop"], "readers": ["everyone"], "invitees": ["ICLR.cc/2018/Workshop/Paper308/Reviewers"], "noninvitees": ["ICLR.cc/2018/Workshop/Paper308/AnonReviewer3", "ICLR.cc/2018/Workshop/Paper308/AnonReviewer2", "ICLR.cc/2018/Workshop/Paper308/AnonReviewer1"], "reply": {"forum": "HJXVjtJvz", "replyto": "HJXVjtJvz", "writers": {"values-regex": "ICLR.cc/2018/Workshop/Paper308/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2018/Workshop/Paper308/AnonReviewer[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"required": true, "order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"required": true, "order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "value-regex": "[\\S\\s]{1,200000}"}, "rating": {"required": true, "order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"required": true, "order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1528433999000, "cdate": 1521582982777}}}, {"tddate": null, "ddate": null, "original": null, "tmdate": 1521582884163, "tcdate": 1520532189389, "number": 3, "cdate": 1520532189389, "id": "BJS1olyFM", "invitation": "ICLR.cc/2018/Workshop/-/Paper308/Official_Review", "forum": "HJXVjtJvz", "replyto": "HJXVjtJvz", "signatures": ["ICLR.cc/2018/Workshop/Paper308/AnonReviewer1"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Workshop/Paper308/AnonReviewer1"], "content": {"title": "Effective alternative to skip connections", "rating": "8: Top 50% of accepted papers, clear accept", "review": "The paper looks at several candidate methods for aggregating information across layers in convolutional networks beyond the usual skip and residual connections. Specifically, it considers a simple iterative aggregation scheme, where each stage is aggregated in a side channel from the backbone network, and several hierarchical structures. Also considered is re-entrant aggregation, where the outputs of the aggregation stages fed back to the backbone network. Experiments demonstrate that the proposed deep layer aggregation scheme can outperform several competing methods on four fine grained classification tasks.\n\nThis is essentially a brief, but well-written, summary of a longer arXiv paper, which contains substantially more experiments and details. The workshop paper is a little light on details, but these are readily found in the longer version. One criticism is that the workshop paper is not self-contained: it is not possible to interpret the algorithms referred to in the legend of Fig 3 without reference to the arXiv paper. \n\nStrengths: well-written, novel and sensible alternative to skip connections, extensive experiments (in the arXiv paper), and solid believable conclusions. Should be of broad interest.\n\nWeaknesses: the submitted paper is not self contained. Mainly experimental work; not much in the way of theoretical justification.", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Learning Rich Image Representation with Deep Layer Aggregation", "abstract": "Architectural efforts are exploring many dimensions for network backbones, designing deeper or wider architectures, but how to best aggregate layers and blocks across a network deserves further attention. We augment standard architectures with deeper aggregation to better fuse information across layers. Our deep layer aggregation structures iteratively and hierarchically merge the feature hierarchy to make networks with better accuracy and fewer parameters. Experiments across architectures and tasks show that deep layer aggregation improves recognition and resolution compared to existing branching and merging schemes.", "paperhash": "yu|learning_rich_image_representation_with_deep_layer_aggregation", "_bibtex": "@misc{\n  yu2018learning,\n  title={Learning Rich Image Representation with Deep Layer Aggregation},\n  author={Fisher Yu and Dequan Wang and Evan Shelhamer and Trevor Darrell},\n  year={2018},\n  url={https://openreview.net/forum?id=HJXVjtJvz}\n}", "authorids": ["fy@berkeley.edu", "dqwang@eecs.berkeley.edu", "shelhamer@eecs.berkeley.edu", "trevor@eecs.berkeley.edu"], "authors": ["Fisher Yu", "Dequan Wang", "Evan Shelhamer", "Trevor Darrell"], "keywords": [], "pdf": "/pdf/9462dc4e4bfea59c1798df7a09f4befe255df9a6.pdf"}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1520657999000, "tmdate": 1521582982777, "id": "ICLR.cc/2018/Workshop/-/Paper308/Official_Review", "writers": ["ICLR.cc/2018/Workshop"], "signatures": ["ICLR.cc/2018/Workshop"], "readers": ["everyone"], "invitees": ["ICLR.cc/2018/Workshop/Paper308/Reviewers"], "noninvitees": ["ICLR.cc/2018/Workshop/Paper308/AnonReviewer3", "ICLR.cc/2018/Workshop/Paper308/AnonReviewer2", "ICLR.cc/2018/Workshop/Paper308/AnonReviewer1"], "reply": {"forum": "HJXVjtJvz", "replyto": "HJXVjtJvz", "writers": {"values-regex": "ICLR.cc/2018/Workshop/Paper308/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2018/Workshop/Paper308/AnonReviewer[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"required": true, "order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"required": true, "order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "value-regex": "[\\S\\s]{1,200000}"}, "rating": {"required": true, "order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"required": true, "order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1528433999000, "cdate": 1521582982777}}}, {"tddate": null, "ddate": null, "original": null, "tmdate": 1521573557863, "tcdate": 1521573557863, "number": 65, "cdate": 1521573557521, "id": "B1ChRCAKf", "invitation": "ICLR.cc/2018/Workshop/-/Acceptance_Decision", "forum": "HJXVjtJvz", "replyto": "HJXVjtJvz", "signatures": ["ICLR.cc/2018/Workshop/Program_Chairs"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Workshop/Program_Chairs"], "content": {"decision": "Accept", "title": "ICLR 2018 Workshop Acceptance Decision", "comment": "Congratulations, your paper was accepted to the ICLR workshop."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Learning Rich Image Representation with Deep Layer Aggregation", "abstract": "Architectural efforts are exploring many dimensions for network backbones, designing deeper or wider architectures, but how to best aggregate layers and blocks across a network deserves further attention. We augment standard architectures with deeper aggregation to better fuse information across layers. Our deep layer aggregation structures iteratively and hierarchically merge the feature hierarchy to make networks with better accuracy and fewer parameters. Experiments across architectures and tasks show that deep layer aggregation improves recognition and resolution compared to existing branching and merging schemes.", "paperhash": "yu|learning_rich_image_representation_with_deep_layer_aggregation", "_bibtex": "@misc{\n  yu2018learning,\n  title={Learning Rich Image Representation with Deep Layer Aggregation},\n  author={Fisher Yu and Dequan Wang and Evan Shelhamer and Trevor Darrell},\n  year={2018},\n  url={https://openreview.net/forum?id=HJXVjtJvz}\n}", "authorids": ["fy@berkeley.edu", "dqwang@eecs.berkeley.edu", "shelhamer@eecs.berkeley.edu", "trevor@eecs.berkeley.edu"], "authors": ["Fisher Yu", "Dequan Wang", "Evan Shelhamer", "Trevor Darrell"], "keywords": [], "pdf": "/pdf/9462dc4e4bfea59c1798df7a09f4befe255df9a6.pdf"}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "tmdate": 1518629844880, "id": "ICLR.cc/2018/Workshop/-/Acceptance_Decision", "writers": ["ICLR.cc/2018/Workshop"], "signatures": ["ICLR.cc/2018/Workshop"], "readers": ["everyone"], "invitees": ["ICLR.cc/2018/Workshop/Program_Chairs"], "reply": {"forum": null, "replyto": null, "invitation": "ICLR.cc/2018/Workshop/-/Submission", "writers": {"values": ["ICLR.cc/2018/Workshop/Program_Chairs"]}, "signatures": {"description": "How your identity will be displayed with the above content.", "values": ["ICLR.cc/2018/Workshop/Program_Chairs"]}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["ICLR.cc/2018/Workshop/Program_Chairs", "everyone"]}, "content": {"title": {"required": true, "order": 1, "value": "ICLR 2018 Workshop Acceptance Decision"}, "comment": {"required": false, "order": 3, "description": "(optional) Comment on this decision.", "value-regex": "[\\S\\s]{0,5000}"}, "decision": {"required": true, "order": 2, "value-dropdown": ["Accept", "Reject"]}}}, "nonreaders": [], "noninvitees": [], "cdate": 1518629844880}}}], "count": 5}