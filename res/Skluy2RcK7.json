{"notes": [{"id": "Skluy2RcK7", "original": "S1xXQQFcFm", "number": 1001, "cdate": 1538087904494, "ddate": null, "tcdate": 1538087904494, "tmdate": 1545355381374, "tddate": null, "forum": "Skluy2RcK7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Selectivity metrics can overestimate the selectivity of units: a case study on AlexNet", "abstract": "Various methods of measuring unit selectivity have been developed in order to understand the representations learned by neural networks (NNs).  Here we undertake a comparison of four such measures on AlexNet, namely, localist selectivity, \\precision (Zhou et al, ICLR 2015), class-conditional mean activity selectivity CCMAS; (Morcos et al, ICLR 2018), and a new measure called top-class selectivity. In contrast with previous work on recurrent neural networks (RNNs), we fail to find any 100\\% selective `localist units' in AlexNet, and demonstrate that the \\precision and CCMAS measures provide a much higher level of selectivity than is warranted, with the most selective hidden units only responding strongly to a small minority of images from within a category. We also generated activation maximization (AM) images that maximally activated individual units and found that under (5\\%) of units in fc6 and conv5 produced interpretable images of objects, whereas fc8 produced over 50\\% interpretable images. Furthermore, the interpretable images in the hidden layers were not associated with highly selective units. These findings highlight the problem with current selectivity measures and show that new measures are required in order to provide a better assessment of learned representations in NNs.  We also consider why localist representations are learned in RNNs and not AlexNet.", "keywords": ["AlexNet", "neural networks", "selectivity", "localist", "distributed", "represenataion", "precision", "measures of selectivity", "object detectors", "single directions", "network analysis"], "authorids": ["ella.gale@gmail.com", "anhnguyen@auburn.edu", "ryan.blything@bristol.ac.uk", "nm13850@bristol.ac.uk", "j.bowers@bristol.ac.uk"], "authors": ["Ella M. Gale", "Anh Nguyen", "Ryan Blything", "Nicholas Martin and Jeffrey S. Bowers"], "TL;DR": "Common selectivity metrics overestimate the selectivity of units, true object detectors are extremely rare, but class selectivity does increase with depth. ", "pdf": "/pdf/9572777a07803d527eb4ebb80261356dee527f54.pdf", "paperhash": "gale|selectivity_metrics_can_overestimate_the_selectivity_of_units_a_case_study_on_alexnet", "_bibtex": "@misc{\ngale2019selectivity,\ntitle={Selectivity metrics can overestimate the selectivity of units: a case study on AlexNet},\nauthor={Ella M. Gale and Anh Nguyen and Ryan Blything and Nicholas Martin and Jeffrey S. Bowers},\nyear={2019},\nurl={https://openreview.net/forum?id=Skluy2RcK7},\n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"replyCount": 10, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Blind_Submission", "rdate": null, "ddate": null, "expdate": null, "duedate": 1538085600000, "tmdate": 1538142958393, "tddate": null, "super": null, "final": null, "reply": {"signatures": {"values": ["ICLR.cc/2019/Conference"]}, "forum": null, "readers": {"values": ["everyone"]}, "replyto": null, "content": {"authorids": {"values-regex": ".*"}, "authors": {"values": ["Anonymous"]}}, "writers": {"values": ["ICLR.cc/2019/Conference"]}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["~"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": null, "taskCompletionCount": null, "transform": null, "cdate": 1538142958393}}, "tauthor": "OpenReview.net"}, {"id": "S1lRAhu-eN", "original": null, "number": 1, "cdate": 1544813782255, "ddate": null, "tcdate": 1544813782255, "tmdate": 1545354528198, "tddate": null, "forum": "Skluy2RcK7", "replyto": "Skluy2RcK7", "invitation": "ICLR.cc/2019/Conference/-/Paper1001/Meta_Review", "content": {"metareview": "The paper examined the folk-knowledge that there are highly selective units in popular CNN architectures, and performed a detailed analysis of recent measures of unit selectivity, as well as introducing a novel one. The finding that units are not extremely selective in CNNs was intriguing to some (not all) reviewers. Further, they show recent measures of selectivity dramatically over-estimate selectivity.\n\nThere was not tight agreement amongst the reviewers on the paper's rating, but it trended towards rejection. Weaknesses highlighted by reviewers include lack of visual clarity in their demonstrations, the use of a several-generations-old CNN architecture, as well as a lack of enthusiasm for the findings.", "confidence": "4: The area chair is confident but not absolutely certain", "recommendation": "Reject", "title": "Detailed analysis of unit selectivity, but reviewers unconvinced of impact"}, "signatures": ["ICLR.cc/2019/Conference/Paper1001/Area_Chair1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference/Paper1001/Area_Chair1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Selectivity metrics can overestimate the selectivity of units: a case study on AlexNet", "abstract": "Various methods of measuring unit selectivity have been developed in order to understand the representations learned by neural networks (NNs).  Here we undertake a comparison of four such measures on AlexNet, namely, localist selectivity, \\precision (Zhou et al, ICLR 2015), class-conditional mean activity selectivity CCMAS; (Morcos et al, ICLR 2018), and a new measure called top-class selectivity. In contrast with previous work on recurrent neural networks (RNNs), we fail to find any 100\\% selective `localist units' in AlexNet, and demonstrate that the \\precision and CCMAS measures provide a much higher level of selectivity than is warranted, with the most selective hidden units only responding strongly to a small minority of images from within a category. We also generated activation maximization (AM) images that maximally activated individual units and found that under (5\\%) of units in fc6 and conv5 produced interpretable images of objects, whereas fc8 produced over 50\\% interpretable images. Furthermore, the interpretable images in the hidden layers were not associated with highly selective units. These findings highlight the problem with current selectivity measures and show that new measures are required in order to provide a better assessment of learned representations in NNs.  We also consider why localist representations are learned in RNNs and not AlexNet.", "keywords": ["AlexNet", "neural networks", "selectivity", "localist", "distributed", "represenataion", "precision", "measures of selectivity", "object detectors", "single directions", "network analysis"], "authorids": ["ella.gale@gmail.com", "anhnguyen@auburn.edu", "ryan.blything@bristol.ac.uk", "nm13850@bristol.ac.uk", "j.bowers@bristol.ac.uk"], "authors": ["Ella M. Gale", "Anh Nguyen", "Ryan Blything", "Nicholas Martin and Jeffrey S. Bowers"], "TL;DR": "Common selectivity metrics overestimate the selectivity of units, true object detectors are extremely rare, but class selectivity does increase with depth. ", "pdf": "/pdf/9572777a07803d527eb4ebb80261356dee527f54.pdf", "paperhash": "gale|selectivity_metrics_can_overestimate_the_selectivity_of_units_a_case_study_on_alexnet", "_bibtex": "@misc{\ngale2019selectivity,\ntitle={Selectivity metrics can overestimate the selectivity of units: a case study on AlexNet},\nauthor={Ella M. Gale and Anh Nguyen and Ryan Blything and Nicholas Martin and Jeffrey S. Bowers},\nyear={2019},\nurl={https://openreview.net/forum?id=Skluy2RcK7},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper1001/Meta_Review", "rdate": null, "ddate": null, "expdate": null, "duedate": 1541548800000, "tmdate": 1545353003584, "tddate": null, "super": null, "final": null, "reply": {"forum": "Skluy2RcK7", "replyto": "Skluy2RcK7", "readers": {"description": "Select all user groups that should be able to read this comment. Selecting 'All Users' will allow paper authors, reviewers, area chairs, and program chairs to view this comment.", "values": ["everyone"]}, "signatures": {"description": "How your identity will be displayed with the above content.", "values-regex": "ICLR.cc/2019/Conference/Paper1001/Area_Chair[0-9]+"}, "writers": {"description": "Users that may modify this record.", "values-regex": "ICLR.cc/2019/Conference/Paper1001/Area_Chair[0-9]+"}, "content": {"title": {"order": 1, "value-regex": ".{1,500}", "description": "Brief summary of your review.", "required": true}, "metareview": {"order": 2, "value-regex": "[\\S\\s]{1,5000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "required": true}, "recommendation": {"order": 3, "value-dropdown": ["Accept (Oral)", "Accept (Poster)", "Reject"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The area chair is absolutely certain", "4: The area chair is confident but not absolutely certain", "3: The area chair is somewhat confident", "2: The area chair is not sure", "1: The area chair's evaluation is an educated guess"], "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper1001/Area_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": false, "taskCompletionCount": null, "transform": null, "cdate": 1545353003584}}}, {"id": "r1l_LOiKCm", "original": null, "number": 9, "cdate": 1543252047557, "ddate": null, "tcdate": 1543252047557, "tmdate": 1543786141887, "tddate": null, "forum": "Skluy2RcK7", "replyto": "Skluy2RcK7", "invitation": "ICLR.cc/2019/Conference/-/Paper1001/Official_Comment", "content": {"title": "Our response to all reviewers - part 1: AlexNet was used by the people developing these selectivity measures, and so a good case study", "comment": "We would like to thank the reviewers for their positive comments and their constructive criticisms. \u00a0\u00a0Below we respond to these criticisms, some of which reflect a misunderstanding of our our main objectives (this is our fault--and something we clarify here and in our revision). \u00a0We hope our revision makes it clearer that our paper has identified serious problems with influential and recent papers published in ICLR that overestimate the selectivity of units in CNNs. Here we consider the points that are relevant to all the reviewers, and then respond to the specific comments of the reviewers below their reviews.\n\n1: \u00a0We have only used AlexNet, and accordingly, it is not clear how well our findings will generalize to other more recent networks.\n\nResponse: \u00a0The main goal of our paper was to compare different measures of selectivity, and for this purpose, it makes sense to focus on a single network. \u00a0\n\n(1) Considering alternative models would NOT alter our finding that the different selectivity measures assess very different things.\n\n(2) We decided to use AlexNet given its historical significance and the fact that many papers have explored the selectivity of the hidden units in this network (in fact, two of the three papers which introduced the selectivity measures we\u2019re testing used AlexNet, the third paper used a NN on a similar size to AlexNet, thus AlexNet is the best network for directly comparing our findings to the original papers). \u00a0As described in the title of our paper, we used AlexNet as a \u201ccase study\u201d for this purpose.   \n\n2: \u00a0We are looking for a very strong form of selectivity, and the fact that we do not find 100% selective \u201cgrandmother cell\u201d representations is not that surprising.\n\nResponse: \n\n(1) We are not looking for a strong form of selectivity, but rather, we are comparing different measures of selectivity. \u00a0Our comparison highlights that the words \u201cselective\u201d, \u201cdetector\u201d and \u201cprecision\u201d are being used in somewhat misleading ways. \u00a0eg,, Zhou et al reported multiple \u201cobject detectors\u201d in AlexNet with a precision of above .75, ie.  75% of the top-most active images are members of a single object category. This was published in ICLR, and is highly cited (384 in Google Scholar). By contrast, we show that these object detectors do not strongly respond to the vast majority of images from the category, with the modal response to images from these categories often 0. \u00a0Indeed, we did find many units in AlexNet that should NOT be called \u201cobject detectors\u201d.  We show that all current selectivity measures have their problems, and that new measures are needed.  \n\n(2) We agree that there are no 100% grandmother cell representations in AlexNet might not be too surprising, but it is surprising that when we use Morcos et al\u2019s CCMAS measure (ICLR 2018) we find hidden units with a selectivity score of .94 that would appear to suggest near localist codes (whereas the \u00a0top-class selectivity scores for the same unit is .15%).  \n\n(3) It is also important to note that 100% selective units have been found in recurrent networks (Bowers, 2014, 2016), and this raises interesting questions for future research regarding the conditions in which 100% selective units are found. \u00a0\u00a0\u00a0\n\n3: \u00a0It is not clear what the contribution is.\n\nResponse: There are a number of contributions: \n\n(1) The paper compares for the first-time four different measures of selectivity: (a) localist selectivity (from psychology; Berkeley et al., 1995, Bowers, 2014); (b) Top-Class selectivity, with \u201clocalist\u201d selectivity as a special case of 100% top-class selectivity \u00a0; (c) Precision (Zhou et al. 2015); (d) CCMAS (Morcos et al. 2018). In addition, we evaluate the images by a 4th popular method (e) Activation Maximization (Erhan et al. 2009, Simonyan et al. 2014, Yosinski et al. 2015, Nguyen et al. 2014-2017etc). \n\nWe show that they assess very different things that lead to very different conclusions regarding the selectivity of object information in AlexNet.\n\n(2) The paper introduces the \u201clocalist\u201d measure of selectivity to the machine learning community, which has been used in top psychology journals, but is not reference in the machine learning literature. \u00a0\n\n(3) Our findings motivate \u00a0new areas of research, including questions concerning why 100% selective units have thus far only been observed in recurrent networks (perhaps the \u201csuperposition catastrophe\u201d is central here, but more research is needed), and the need for new and perhaps multiple measures of selectivity given the limitations of all current measures. "}, "signatures": ["ICLR.cc/2019/Conference/Paper1001/Authors"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper1001/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper1001/Authors", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Selectivity metrics can overestimate the selectivity of units: a case study on AlexNet", "abstract": "Various methods of measuring unit selectivity have been developed in order to understand the representations learned by neural networks (NNs).  Here we undertake a comparison of four such measures on AlexNet, namely, localist selectivity, \\precision (Zhou et al, ICLR 2015), class-conditional mean activity selectivity CCMAS; (Morcos et al, ICLR 2018), and a new measure called top-class selectivity. In contrast with previous work on recurrent neural networks (RNNs), we fail to find any 100\\% selective `localist units' in AlexNet, and demonstrate that the \\precision and CCMAS measures provide a much higher level of selectivity than is warranted, with the most selective hidden units only responding strongly to a small minority of images from within a category. We also generated activation maximization (AM) images that maximally activated individual units and found that under (5\\%) of units in fc6 and conv5 produced interpretable images of objects, whereas fc8 produced over 50\\% interpretable images. Furthermore, the interpretable images in the hidden layers were not associated with highly selective units. These findings highlight the problem with current selectivity measures and show that new measures are required in order to provide a better assessment of learned representations in NNs.  We also consider why localist representations are learned in RNNs and not AlexNet.", "keywords": ["AlexNet", "neural networks", "selectivity", "localist", "distributed", "represenataion", "precision", "measures of selectivity", "object detectors", "single directions", "network analysis"], "authorids": ["ella.gale@gmail.com", "anhnguyen@auburn.edu", "ryan.blything@bristol.ac.uk", "nm13850@bristol.ac.uk", "j.bowers@bristol.ac.uk"], "authors": ["Ella M. Gale", "Anh Nguyen", "Ryan Blything", "Nicholas Martin and Jeffrey S. Bowers"], "TL;DR": "Common selectivity metrics overestimate the selectivity of units, true object detectors are extremely rare, but class selectivity does increase with depth. ", "pdf": "/pdf/9572777a07803d527eb4ebb80261356dee527f54.pdf", "paperhash": "gale|selectivity_metrics_can_overestimate_the_selectivity_of_units_a_case_study_on_alexnet", "_bibtex": "@misc{\ngale2019selectivity,\ntitle={Selectivity metrics can overestimate the selectivity of units: a case study on AlexNet},\nauthor={Ella M. Gale and Anh Nguyen and Ryan Blything and Nicholas Martin and Jeffrey S. Bowers},\nyear={2019},\nurl={https://openreview.net/forum?id=Skluy2RcK7},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper1001/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621606424, "tddate": null, "super": null, "final": null, "reply": {"forum": "Skluy2RcK7", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper1001/Authors", "ICLR.cc/2019/Conference/Paper1001/Reviewers", "ICLR.cc/2019/Conference/Paper1001/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper1001/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper1001/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper1001/Authors|ICLR.cc/2019/Conference/Paper1001/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper1001/Reviewers", "ICLR.cc/2019/Conference/Paper1001/Authors", "ICLR.cc/2019/Conference/Paper1001/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621606424}}}, {"id": "SyewgdjtCm", "original": null, "number": 8, "cdate": 1543251951056, "ddate": null, "tcdate": 1543251951056, "tmdate": 1543253356281, "tddate": null, "forum": "Skluy2RcK7", "replyto": "Skluy2RcK7", "invitation": "ICLR.cc/2019/Conference/-/Paper1001/Official_Comment", "content": {"title": "Our response to all reviewers - part 2: we rewrote and reorganised the paper for clarity", "comment": "4:  Paper was not well written or well organized.\n\nResponse:  We have substantially rewritten the paper to clarify our objectives, and to improve the organization of the results.   We have also updated the manuscript with more details to reproduce our findings, including providing a link to h5 file that includes the activations of the units in AlexNet, and provided more details regarding Activation Maximization, which followed the released code by Nguyen et al. (2017).\n\nAn aside\nWe have also identified a bug in our code that altered some of our findings (we discuss this under Point 5). However, the bug does not change our main conclusions, indeed, the results are now stronger.\n\nWe identified a bug in our code that artificially lead to higher levels of selectivity according to our top-class selectivity measure.  By contrast, the effects on precision and CCMAS were not as strongly impacted.  As a consequence the differences between measures has been increased now that we have fixed our code (strengthening our main message).  We have updated tables and figures in response to our mistake.  Briefly, the bug involved copying around a pointer to a memory address containing data, rather than the data itself, leading to some activations not being included in the calculation.  The qualitative findings of the paper have not changed, but the precise values have.\nIn sum, we think we have made a number of important contributions,  and we hope that our comments here and in our revision highlight this better.\n"}, "signatures": ["ICLR.cc/2019/Conference/Paper1001/Authors"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper1001/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper1001/Authors", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Selectivity metrics can overestimate the selectivity of units: a case study on AlexNet", "abstract": "Various methods of measuring unit selectivity have been developed in order to understand the representations learned by neural networks (NNs).  Here we undertake a comparison of four such measures on AlexNet, namely, localist selectivity, \\precision (Zhou et al, ICLR 2015), class-conditional mean activity selectivity CCMAS; (Morcos et al, ICLR 2018), and a new measure called top-class selectivity. In contrast with previous work on recurrent neural networks (RNNs), we fail to find any 100\\% selective `localist units' in AlexNet, and demonstrate that the \\precision and CCMAS measures provide a much higher level of selectivity than is warranted, with the most selective hidden units only responding strongly to a small minority of images from within a category. We also generated activation maximization (AM) images that maximally activated individual units and found that under (5\\%) of units in fc6 and conv5 produced interpretable images of objects, whereas fc8 produced over 50\\% interpretable images. Furthermore, the interpretable images in the hidden layers were not associated with highly selective units. These findings highlight the problem with current selectivity measures and show that new measures are required in order to provide a better assessment of learned representations in NNs.  We also consider why localist representations are learned in RNNs and not AlexNet.", "keywords": ["AlexNet", "neural networks", "selectivity", "localist", "distributed", "represenataion", "precision", "measures of selectivity", "object detectors", "single directions", "network analysis"], "authorids": ["ella.gale@gmail.com", "anhnguyen@auburn.edu", "ryan.blything@bristol.ac.uk", "nm13850@bristol.ac.uk", "j.bowers@bristol.ac.uk"], "authors": ["Ella M. Gale", "Anh Nguyen", "Ryan Blything", "Nicholas Martin and Jeffrey S. Bowers"], "TL;DR": "Common selectivity metrics overestimate the selectivity of units, true object detectors are extremely rare, but class selectivity does increase with depth. ", "pdf": "/pdf/9572777a07803d527eb4ebb80261356dee527f54.pdf", "paperhash": "gale|selectivity_metrics_can_overestimate_the_selectivity_of_units_a_case_study_on_alexnet", "_bibtex": "@misc{\ngale2019selectivity,\ntitle={Selectivity metrics can overestimate the selectivity of units: a case study on AlexNet},\nauthor={Ella M. Gale and Anh Nguyen and Ryan Blything and Nicholas Martin and Jeffrey S. Bowers},\nyear={2019},\nurl={https://openreview.net/forum?id=Skluy2RcK7},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper1001/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621606424, "tddate": null, "super": null, "final": null, "reply": {"forum": "Skluy2RcK7", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper1001/Authors", "ICLR.cc/2019/Conference/Paper1001/Reviewers", "ICLR.cc/2019/Conference/Paper1001/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper1001/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper1001/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper1001/Authors|ICLR.cc/2019/Conference/Paper1001/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper1001/Reviewers", "ICLR.cc/2019/Conference/Paper1001/Authors", "ICLR.cc/2019/Conference/Paper1001/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621606424}}}, {"id": "H1g9WtiYAX", "original": null, "number": 10, "cdate": 1543252226084, "ddate": null, "tcdate": 1543252226084, "tmdate": 1543252391425, "tddate": null, "forum": "Skluy2RcK7", "replyto": "rkgdcTkchX", "invitation": "ICLR.cc/2019/Conference/-/Paper1001/Official_Comment", "content": {"title": "Clarifying our contribution - part 2", "comment": ">> R3 said that our results would be hard to reproduce.  \n\nResponse: The procedures for computing precision and CCMAS measures have been published elsewhere and cited (and we explain how they are computed), and we have provided the equation for computing top-class selectivity.   We also cite the paper that describes how to generate the images that maximally activated the units. In order to facilitate replication we have uploaded a file that contains all the activations of correctly identified images as an h5 file and provide a link in the paper.\n\n>> R3 said the image generation for activating units (assuming it is novel) could be interesting but it is not even described with sufficient details so as to reproduce the results.\n\nResponse: The process of generating Activation Maximization (AM) images follow exactly a state-of-the-art AM method in Nguyen et al. 2017 via their open-source code. We thank the reviewer for pointing this out! :)\nWe have updated the manuscript to add more details and make this clearer.\n\n>> R3 said that \u2018The study is limited to correctly classified images as stated on page 3. This seems like a major confound in a study aimed at understanding the visual representations learned.\u2019 \n\nResponse: We do not understand this point.  It is not appropriate to compute the selectivity of a unit when misclassified images are included.  For the sake of argument, imagine you have found a unit that appears to be 100% selective to DOGS.   What should you conclude if the unit does not activate to an image of a DOG that is misclassified as a CAT.  Should you conclude that it is not a 100% DOG detector? Of course not \u2013 the DOG detector did not fire because the model did not know it was a DOG.  If you are interested in whether a unit is selective to a given category the model needs to correctly identify the category.   It is an interesting question as to why models sometimes misclassify images, but goes beyond the topic of this paper. \n"}, "signatures": ["ICLR.cc/2019/Conference/Paper1001/Authors"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper1001/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper1001/Authors", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Selectivity metrics can overestimate the selectivity of units: a case study on AlexNet", "abstract": "Various methods of measuring unit selectivity have been developed in order to understand the representations learned by neural networks (NNs).  Here we undertake a comparison of four such measures on AlexNet, namely, localist selectivity, \\precision (Zhou et al, ICLR 2015), class-conditional mean activity selectivity CCMAS; (Morcos et al, ICLR 2018), and a new measure called top-class selectivity. In contrast with previous work on recurrent neural networks (RNNs), we fail to find any 100\\% selective `localist units' in AlexNet, and demonstrate that the \\precision and CCMAS measures provide a much higher level of selectivity than is warranted, with the most selective hidden units only responding strongly to a small minority of images from within a category. We also generated activation maximization (AM) images that maximally activated individual units and found that under (5\\%) of units in fc6 and conv5 produced interpretable images of objects, whereas fc8 produced over 50\\% interpretable images. Furthermore, the interpretable images in the hidden layers were not associated with highly selective units. These findings highlight the problem with current selectivity measures and show that new measures are required in order to provide a better assessment of learned representations in NNs.  We also consider why localist representations are learned in RNNs and not AlexNet.", "keywords": ["AlexNet", "neural networks", "selectivity", "localist", "distributed", "represenataion", "precision", "measures of selectivity", "object detectors", "single directions", "network analysis"], "authorids": ["ella.gale@gmail.com", "anhnguyen@auburn.edu", "ryan.blything@bristol.ac.uk", "nm13850@bristol.ac.uk", "j.bowers@bristol.ac.uk"], "authors": ["Ella M. Gale", "Anh Nguyen", "Ryan Blything", "Nicholas Martin and Jeffrey S. Bowers"], "TL;DR": "Common selectivity metrics overestimate the selectivity of units, true object detectors are extremely rare, but class selectivity does increase with depth. ", "pdf": "/pdf/9572777a07803d527eb4ebb80261356dee527f54.pdf", "paperhash": "gale|selectivity_metrics_can_overestimate_the_selectivity_of_units_a_case_study_on_alexnet", "_bibtex": "@misc{\ngale2019selectivity,\ntitle={Selectivity metrics can overestimate the selectivity of units: a case study on AlexNet},\nauthor={Ella M. Gale and Anh Nguyen and Ryan Blything and Nicholas Martin and Jeffrey S. Bowers},\nyear={2019},\nurl={https://openreview.net/forum?id=Skluy2RcK7},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper1001/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621606424, "tddate": null, "super": null, "final": null, "reply": {"forum": "Skluy2RcK7", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper1001/Authors", "ICLR.cc/2019/Conference/Paper1001/Reviewers", "ICLR.cc/2019/Conference/Paper1001/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper1001/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper1001/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper1001/Authors|ICLR.cc/2019/Conference/Paper1001/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper1001/Reviewers", "ICLR.cc/2019/Conference/Paper1001/Authors", "ICLR.cc/2019/Conference/Paper1001/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621606424}}}, {"id": "BJlGDtiYCX", "original": null, "number": 11, "cdate": 1543252313586, "ddate": null, "tcdate": 1543252313586, "tmdate": 1543252330435, "tddate": null, "forum": "Skluy2RcK7", "replyto": "rkgdcTkchX", "invitation": "ICLR.cc/2019/Conference/-/Paper1001/Official_Comment", "content": {"title": "Clarifying our contribution - part 1", "comment": "Please see the main reply to your major points. Below is our reply to your specific comments.\n\n>> R3 does not like the jitterplot method of displaying the results. \n\nResponse: We find this an intuitive method to display the data.  The fact that some regions of the scatter plot have highly overlapping dots is itself informative as it shows that there is no selectivity in this range of activity.  But we have added a histogram to some of our jitterplots so the reader can see how the lower activations are laid out (See Figures 3 and A2 ). \n\n>> R3 writes that our analyses are mostly \u201cdescriptive\u201d.  \n\nResponse: We do not understand this point.  We have compared four quantitative measures of selectivity (localist, top-class, CCMAS, and precision selectivity), and for the first time we have provided quantitative measures of the selectivity from the activation maximization method.\n\n>> R3 wonders how batch normalization would impact our results.  \n\nResponse: Again, this goes beyond the main focus of our paper.  No doubt batch normalization would impact on all our measures (as would dropout, L1 and L2 regularization, using different network architectures, etc.), BUT the discrepancy between measures would remain (this is our main point). \n \n>> R3 claims the comparison between AlexNet and recurrent nets are misleading given that Bowers et al. (2014) worked with words.  \n\nResponse: It is important to note that Bowers (2014, 2016) did not find selective representations for words when the networks were trained on words one-at-a-time, but only when trained to co-activate multiple words at the same time in short-term memory (see Figure 1b).  That is, the critical contrast here is not in words vs. images, but in training conditions.  Bowers et al. (2014, 2016) argued that selective units developed in response to the \u201csuperposition catastrophe\u201d that limits the computation capacities of distributed representations.\nWith regards to whether we were being \u201cmisleading\u201d, we would point out that we explicitly noted that it would be important to determine whether more recent recurrent CNNs would also learn selective representation as predicted on the superposition account.  Specifically, we wrote:\n\u201cHowever, it should be noted that the RNNs that learned localist units were very small in scale compared to AlexNet, and accordingly, it will be interesting to assess the selectivity in larger RNNs that have much larger memory capacity.  Relevant to this issue, Karpathy et al. (2015) reported some striking examples of selective representations in a recurrent long-short term memory (LSTM) networks trained to predict text based on training on Tolstoy's novel `War and Peace' and the Linux Kernel source code. Although they did not systematically assess the degree of selectivity, they reported examples that are consistent with 100% selective units. If in fact the superposition constraint provides a pressure to learn more selective representations, then we should observe more highly selective representations, perhaps localist units, in large RNNs as well.  We will be testing this hypothesis in future work.\u201d  \n"}, "signatures": ["ICLR.cc/2019/Conference/Paper1001/Authors"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper1001/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper1001/Authors", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Selectivity metrics can overestimate the selectivity of units: a case study on AlexNet", "abstract": "Various methods of measuring unit selectivity have been developed in order to understand the representations learned by neural networks (NNs).  Here we undertake a comparison of four such measures on AlexNet, namely, localist selectivity, \\precision (Zhou et al, ICLR 2015), class-conditional mean activity selectivity CCMAS; (Morcos et al, ICLR 2018), and a new measure called top-class selectivity. In contrast with previous work on recurrent neural networks (RNNs), we fail to find any 100\\% selective `localist units' in AlexNet, and demonstrate that the \\precision and CCMAS measures provide a much higher level of selectivity than is warranted, with the most selective hidden units only responding strongly to a small minority of images from within a category. We also generated activation maximization (AM) images that maximally activated individual units and found that under (5\\%) of units in fc6 and conv5 produced interpretable images of objects, whereas fc8 produced over 50\\% interpretable images. Furthermore, the interpretable images in the hidden layers were not associated with highly selective units. These findings highlight the problem with current selectivity measures and show that new measures are required in order to provide a better assessment of learned representations in NNs.  We also consider why localist representations are learned in RNNs and not AlexNet.", "keywords": ["AlexNet", "neural networks", "selectivity", "localist", "distributed", "represenataion", "precision", "measures of selectivity", "object detectors", "single directions", "network analysis"], "authorids": ["ella.gale@gmail.com", "anhnguyen@auburn.edu", "ryan.blything@bristol.ac.uk", "nm13850@bristol.ac.uk", "j.bowers@bristol.ac.uk"], "authors": ["Ella M. Gale", "Anh Nguyen", "Ryan Blything", "Nicholas Martin and Jeffrey S. Bowers"], "TL;DR": "Common selectivity metrics overestimate the selectivity of units, true object detectors are extremely rare, but class selectivity does increase with depth. ", "pdf": "/pdf/9572777a07803d527eb4ebb80261356dee527f54.pdf", "paperhash": "gale|selectivity_metrics_can_overestimate_the_selectivity_of_units_a_case_study_on_alexnet", "_bibtex": "@misc{\ngale2019selectivity,\ntitle={Selectivity metrics can overestimate the selectivity of units: a case study on AlexNet},\nauthor={Ella M. Gale and Anh Nguyen and Ryan Blything and Nicholas Martin and Jeffrey S. Bowers},\nyear={2019},\nurl={https://openreview.net/forum?id=Skluy2RcK7},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper1001/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621606424, "tddate": null, "super": null, "final": null, "reply": {"forum": "Skluy2RcK7", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper1001/Authors", "ICLR.cc/2019/Conference/Paper1001/Reviewers", "ICLR.cc/2019/Conference/Paper1001/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper1001/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper1001/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper1001/Authors|ICLR.cc/2019/Conference/Paper1001/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper1001/Reviewers", "ICLR.cc/2019/Conference/Paper1001/Authors", "ICLR.cc/2019/Conference/Paper1001/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621606424}}}, {"id": "SJlixzjtCm", "original": null, "number": 3, "cdate": 1543250419276, "ddate": null, "tcdate": 1543250419276, "tmdate": 1543252154160, "tddate": null, "forum": "Skluy2RcK7", "replyto": "B1gQqFQq3m", "invitation": "ICLR.cc/2019/Conference/-/Paper1001/Official_Comment", "content": {"title": "We clarified that we are interested in object selectivity", "comment": "We thank R2 for their constructive comments and encouragement! Please see the main reply to all reviewers for the main points. Below is our reply to your specific comments.\n\n>> R2 points out that we are only concerned with object selectivity whereas Zhou et al. (2017) are concerned with different forms of selectivity, including selectivity to colour, etc.  \n\nResponse: This is true, and we have now emphasized that the focus of this paper is on object selectivity.  There may well have been units selective to colour that our analyses may have missed, but this does not impact on our conclusion that the precision measure provides a misleading measure of selectivity (not only misleading for objects, but for the same reason, misleading for colour, etc.).\n\n>> R2 said: It is an open question if the authors work overfits to AlexNet.\n\nResponse:  The method of comparing selectivity measures could be applied to any NN, and AlexNet's activation patterns are similar to other NNs, so we think another NN would also show similar qualitative pattern of low object selectivity in the hidden layers, and we still expect the selectivity metrics to underestimate this. Our preliminary results with other networks do look similar. Where AlexNet differs, perhaps, is in the quality and style of AM images that are found, so that part of our analysis may be different, and this is something we intend to investigate in the future. \n\n"}, "signatures": ["ICLR.cc/2019/Conference/Paper1001/Authors"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper1001/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper1001/Authors", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Selectivity metrics can overestimate the selectivity of units: a case study on AlexNet", "abstract": "Various methods of measuring unit selectivity have been developed in order to understand the representations learned by neural networks (NNs).  Here we undertake a comparison of four such measures on AlexNet, namely, localist selectivity, \\precision (Zhou et al, ICLR 2015), class-conditional mean activity selectivity CCMAS; (Morcos et al, ICLR 2018), and a new measure called top-class selectivity. In contrast with previous work on recurrent neural networks (RNNs), we fail to find any 100\\% selective `localist units' in AlexNet, and demonstrate that the \\precision and CCMAS measures provide a much higher level of selectivity than is warranted, with the most selective hidden units only responding strongly to a small minority of images from within a category. We also generated activation maximization (AM) images that maximally activated individual units and found that under (5\\%) of units in fc6 and conv5 produced interpretable images of objects, whereas fc8 produced over 50\\% interpretable images. Furthermore, the interpretable images in the hidden layers were not associated with highly selective units. These findings highlight the problem with current selectivity measures and show that new measures are required in order to provide a better assessment of learned representations in NNs.  We also consider why localist representations are learned in RNNs and not AlexNet.", "keywords": ["AlexNet", "neural networks", "selectivity", "localist", "distributed", "represenataion", "precision", "measures of selectivity", "object detectors", "single directions", "network analysis"], "authorids": ["ella.gale@gmail.com", "anhnguyen@auburn.edu", "ryan.blything@bristol.ac.uk", "nm13850@bristol.ac.uk", "j.bowers@bristol.ac.uk"], "authors": ["Ella M. Gale", "Anh Nguyen", "Ryan Blything", "Nicholas Martin and Jeffrey S. Bowers"], "TL;DR": "Common selectivity metrics overestimate the selectivity of units, true object detectors are extremely rare, but class selectivity does increase with depth. ", "pdf": "/pdf/9572777a07803d527eb4ebb80261356dee527f54.pdf", "paperhash": "gale|selectivity_metrics_can_overestimate_the_selectivity_of_units_a_case_study_on_alexnet", "_bibtex": "@misc{\ngale2019selectivity,\ntitle={Selectivity metrics can overestimate the selectivity of units: a case study on AlexNet},\nauthor={Ella M. Gale and Anh Nguyen and Ryan Blything and Nicholas Martin and Jeffrey S. Bowers},\nyear={2019},\nurl={https://openreview.net/forum?id=Skluy2RcK7},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper1001/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621606424, "tddate": null, "super": null, "final": null, "reply": {"forum": "Skluy2RcK7", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper1001/Authors", "ICLR.cc/2019/Conference/Paper1001/Reviewers", "ICLR.cc/2019/Conference/Paper1001/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper1001/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper1001/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper1001/Authors|ICLR.cc/2019/Conference/Paper1001/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper1001/Reviewers", "ICLR.cc/2019/Conference/Paper1001/Authors", "ICLR.cc/2019/Conference/Paper1001/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621606424}}}, {"id": "BJeGSxsKRm", "original": null, "number": 2, "cdate": 1543249977530, "ddate": null, "tcdate": 1543249977530, "tmdate": 1543252127113, "tddate": null, "forum": "Skluy2RcK7", "replyto": "rkej1sdjhm", "invitation": "ICLR.cc/2019/Conference/-/Paper1001/Official_Comment", "content": {"title": "Not only are units not perfectly class selective, we show that the selectivity measures previously introduced are misleading as to how unselective they are.", "comment": "We thank R1 for their constructive comments and encouragement!  Please see the main reply to your general, main points. Below is our reply to your specific comments.\n\n>> R1 would like us to assess the role of selectivity and generalization as shown in Morcos (2018).  \n\nResponse: In fact, Morcos et al. did not show this (they showed that generalization related to a concept called \u201csingle directions\u201d, but they never associated their selectivity measure CCMAS to generalization).  We agree this is an interesting question, but it goes outside the scope of comparing selectivity measures.  We would note that the Bowers (2016) paper was specifically concerned with the issue of generalization and selectivity in the context of a recurrent network, and in that paper, selectivity was required in order to generalize.  In future work, it would be interesting to compare how selectivity and generalization relate in feedforward and recurrent networks.\n\n>> R1: Overall this paper critically analyzes single unit selectivity measures, reaching the conclusion that tuning in modern deep networks is usually far more complex than strict localist coding. The significance of this conclusion may not be so high given that this conclusion is probably already the intuition of many.\n\nResponse: We agree that the fact that we did not find 100%-selective units in AlexNet might not too surprising, but that is only one contribution. The main and most important contribution in our work is that existing measures of selectivity in established literature can be misleading. That is impeding the community\u2019s understanding and advancement of the Interpretability research.  As noted above, our findings also highlight an interesting question for future research, namely, what are the conditions that do lead to 100% selectivity, as observed by Bowers et al. (2014, 2016)."}, "signatures": ["ICLR.cc/2019/Conference/Paper1001/Authors"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper1001/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper1001/Authors", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Selectivity metrics can overestimate the selectivity of units: a case study on AlexNet", "abstract": "Various methods of measuring unit selectivity have been developed in order to understand the representations learned by neural networks (NNs).  Here we undertake a comparison of four such measures on AlexNet, namely, localist selectivity, \\precision (Zhou et al, ICLR 2015), class-conditional mean activity selectivity CCMAS; (Morcos et al, ICLR 2018), and a new measure called top-class selectivity. In contrast with previous work on recurrent neural networks (RNNs), we fail to find any 100\\% selective `localist units' in AlexNet, and demonstrate that the \\precision and CCMAS measures provide a much higher level of selectivity than is warranted, with the most selective hidden units only responding strongly to a small minority of images from within a category. We also generated activation maximization (AM) images that maximally activated individual units and found that under (5\\%) of units in fc6 and conv5 produced interpretable images of objects, whereas fc8 produced over 50\\% interpretable images. Furthermore, the interpretable images in the hidden layers were not associated with highly selective units. These findings highlight the problem with current selectivity measures and show that new measures are required in order to provide a better assessment of learned representations in NNs.  We also consider why localist representations are learned in RNNs and not AlexNet.", "keywords": ["AlexNet", "neural networks", "selectivity", "localist", "distributed", "represenataion", "precision", "measures of selectivity", "object detectors", "single directions", "network analysis"], "authorids": ["ella.gale@gmail.com", "anhnguyen@auburn.edu", "ryan.blything@bristol.ac.uk", "nm13850@bristol.ac.uk", "j.bowers@bristol.ac.uk"], "authors": ["Ella M. Gale", "Anh Nguyen", "Ryan Blything", "Nicholas Martin and Jeffrey S. Bowers"], "TL;DR": "Common selectivity metrics overestimate the selectivity of units, true object detectors are extremely rare, but class selectivity does increase with depth. ", "pdf": "/pdf/9572777a07803d527eb4ebb80261356dee527f54.pdf", "paperhash": "gale|selectivity_metrics_can_overestimate_the_selectivity_of_units_a_case_study_on_alexnet", "_bibtex": "@misc{\ngale2019selectivity,\ntitle={Selectivity metrics can overestimate the selectivity of units: a case study on AlexNet},\nauthor={Ella M. Gale and Anh Nguyen and Ryan Blything and Nicholas Martin and Jeffrey S. Bowers},\nyear={2019},\nurl={https://openreview.net/forum?id=Skluy2RcK7},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper1001/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621606424, "tddate": null, "super": null, "final": null, "reply": {"forum": "Skluy2RcK7", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper1001/Authors", "ICLR.cc/2019/Conference/Paper1001/Reviewers", "ICLR.cc/2019/Conference/Paper1001/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper1001/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper1001/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper1001/Authors|ICLR.cc/2019/Conference/Paper1001/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper1001/Reviewers", "ICLR.cc/2019/Conference/Paper1001/Authors", "ICLR.cc/2019/Conference/Paper1001/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621606424}}}, {"id": "rkej1sdjhm", "original": null, "number": 3, "cdate": 1541274339223, "ddate": null, "tcdate": 1541274339223, "tmdate": 1541533507406, "tddate": null, "forum": "Skluy2RcK7", "replyto": "Skluy2RcK7", "invitation": "ICLR.cc/2019/Conference/-/Paper1001/Official_Review", "content": {"title": "Shows that single units are not perfectly class selective, a result that will be intuitive to many", "review": "Summary: \n\nThis paper explores different metrics to measure the \u2018selectivity\u2019 of single neurons for a class in deep neural networks. Using AlexNet as the model under study, the paper shows strengths and weaknesses of several recent methods in the literature. The paper conducts a psychophysics experiment to see if human subjects can reliably label images generated through activation maximization techniques. \n\nMajor comments:\n\nThis paper undertakes a careful analysis of different ways of measuring single-unit selectivity for a class. The conclusions drawn are that no neurons exhibit true localist selectivity, and most have some more complex selectivity. Some of the specific examples make this point very nicely (for instance, a unit that responds very strongly to several custard apples and would appear to be a custard apple detector, except that it responds extremely weakly to other custard apples). This is a somewhat negative result that may be useful in advancing the field away from single neuron analyses, which may be misleading.\n\nOne worry is that the methods applied are looking for a very strong form of selectivity. In particular, even the output layer is judged to contain a low percentage of selective units according to the definitions in the paper. It may be worth considering slightly weakened versions of the metrics that allow for some errors. \n\nIt would be useful to add discussion of the connections between these metrics and generalization performance. The class conditional selectivity metric, for instance, may not measure localist coding very directly, but it does correlate with important performance metrics like generalization performance. The discussion in Morcos 2018 suggests that high single unit selectivity is detrimental to generalization. Do these correlations persist using other metrics?\n\nThe psychophysics experiment with human subjects appears to have been done to a high standard, and yields the result that only the very highest layers of a network yield interpretable images. This is somewhat interesting but unlikely to be that surprising, as selectivity for objects in lower layers is not a claim made by many works. In these lower layers, selectivity for \u2018object parts\u2019 is a claim that has been made and could potentially be addressed by the data collected.\n\nOverall this paper critically analyzes single unit selectivity measures, reaching the conclusion that tuning in modern deep networks is usually far more complex than strict localist coding. The significance of this conclusion may not be so high given that this conclusion is probably already the intuition of many.\n", "rating": "5: Marginally below acceptance threshold", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "signatures": ["ICLR.cc/2019/Conference/Paper1001/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Selectivity metrics can overestimate the selectivity of units: a case study on AlexNet", "abstract": "Various methods of measuring unit selectivity have been developed in order to understand the representations learned by neural networks (NNs).  Here we undertake a comparison of four such measures on AlexNet, namely, localist selectivity, \\precision (Zhou et al, ICLR 2015), class-conditional mean activity selectivity CCMAS; (Morcos et al, ICLR 2018), and a new measure called top-class selectivity. In contrast with previous work on recurrent neural networks (RNNs), we fail to find any 100\\% selective `localist units' in AlexNet, and demonstrate that the \\precision and CCMAS measures provide a much higher level of selectivity than is warranted, with the most selective hidden units only responding strongly to a small minority of images from within a category. We also generated activation maximization (AM) images that maximally activated individual units and found that under (5\\%) of units in fc6 and conv5 produced interpretable images of objects, whereas fc8 produced over 50\\% interpretable images. Furthermore, the interpretable images in the hidden layers were not associated with highly selective units. These findings highlight the problem with current selectivity measures and show that new measures are required in order to provide a better assessment of learned representations in NNs.  We also consider why localist representations are learned in RNNs and not AlexNet.", "keywords": ["AlexNet", "neural networks", "selectivity", "localist", "distributed", "represenataion", "precision", "measures of selectivity", "object detectors", "single directions", "network analysis"], "authorids": ["ella.gale@gmail.com", "anhnguyen@auburn.edu", "ryan.blything@bristol.ac.uk", "nm13850@bristol.ac.uk", "j.bowers@bristol.ac.uk"], "authors": ["Ella M. Gale", "Anh Nguyen", "Ryan Blything", "Nicholas Martin and Jeffrey S. Bowers"], "TL;DR": "Common selectivity metrics overestimate the selectivity of units, true object detectors are extremely rare, but class selectivity does increase with depth. ", "pdf": "/pdf/9572777a07803d527eb4ebb80261356dee527f54.pdf", "paperhash": "gale|selectivity_metrics_can_overestimate_the_selectivity_of_units_a_case_study_on_alexnet", "_bibtex": "@misc{\ngale2019selectivity,\ntitle={Selectivity metrics can overestimate the selectivity of units: a case study on AlexNet},\nauthor={Ella M. Gale and Anh Nguyen and Ryan Blything and Nicholas Martin and Jeffrey S. Bowers},\nyear={2019},\nurl={https://openreview.net/forum?id=Skluy2RcK7},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper1001/Official_Review", "cdate": 1542234328777, "expdate": 1552335264000, "duedate": 1541196000000, "reply": {"forum": "Skluy2RcK7", "replyto": "Skluy2RcK7", "readers": {"description": "The users who will be allowed to read the reply content.", "values": ["everyone"]}, "nonreaders": {"values": []}, "signatures": {"description": "How your identity will be displayed with the above content.", "values-regex": "ICLR.cc/2019/Conference/Paper1001/AnonReviewer[0-9]+"}, "writers": {"description": "Users that may modify this record.", "values": ["ICLR.cc/2019/Conference"]}, "content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "required": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}}, "multiReply": false, "tcdate": 1552335850844, "tmdate": 1552335850844, "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "invitees": ["ICLR.cc/2019/Conference/Paper1001/Reviewers"], "noninvitees": [], "signatures": ["ICLR.cc/2019/Conference"]}}}, {"id": "B1gQqFQq3m", "original": null, "number": 2, "cdate": 1541187978952, "ddate": null, "tcdate": 1541187978952, "tmdate": 1541533507204, "tddate": null, "forum": "Skluy2RcK7", "replyto": "Skluy2RcK7", "invitation": "ICLR.cc/2019/Conference/-/Paper1001/Official_Review", "content": {"title": "Surprising result and raises interesting questions.", "review": "Summary - This paper analyzes the selectivity of individual units in CNNs. The authors analyze existing techniques such as precision selectivity, class-conditional mean activity selection and localist sensitivity. These methods are analyzed in the context of AlexNet and ImageNet. The authors also use Activation Maximization (AM) techniques for visualizing single-unit representations in CNNs.\n\n\nPaper strengths\n- The authors have minutely examined each of the metrics and the underlying assumptions they make. \n    - Example - Number of images used for computing the precision threshold in Zhou et al., 2014; The wrongly stated range of CCMAS [0, 1]. Considering the second highest CCMAS class is a good way of handling multiple classes that activate a single unit.\n- The results of this paper are surprising compared to existing work. The authors have made a surprising discovery and done a good job of both presenting it well and experimentally validating it. The paper raises interesting questions and this should inspire future work in understanding networks.\n- Figure 2 is insightful - It compares the various different interpretations of selectivity for a single unit in fc6. It shows how the mean activating class and the maximally activating class can be semantically very different. It also shows that despite the high precision and CCMAS score, the unit cannot be labelled as a detector for the single concept \"custard apple\". More such results are presented in the Appendix (e.g. Fig A6)\n- The human study in Section 3.3 is a good way to evaluate the generated AM images.\n\n\nPaper weaknesses\n- One of the major weaknesses of this paper is that it uses only ImageNet images to evaluate the units. As this is limited to 1000 classes, the authors cannot probe other visual concepts such as color, texture, materials for the units. As an example, Network dissection (Zhou et al., 2017) proposes a dataset called Broden which has many diverse sets of visual concepts labeled. This paper focuses only on one definition of selectivity - selecting objects. This should be made explicit and the authors have not done a good job of clarifying this assumption or showing that it exists.\n- All of the analysis is limited to AlexNet. With modern architectures that use residual/skip connections, it is not clear how well this analysis will generalize. It is an open question if the authors work overfits to AlexNet.\n- The jitterplots are hard to understand especially if there are many overlapping \"dots\" (samples). Since the y-axis values are not really meaningful anyway, using a histogram to see how many samples have a particular activation value is easier. A possible suggestion for Figure 2(a): split into two parts - 1) histogram of all samples; 2) histogram of the highest mean activating class.\n- The organization of the paper could be improved. The sections in the paper are not well connected.", "rating": "6: Marginally above acceptance threshold", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "signatures": ["ICLR.cc/2019/Conference/Paper1001/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Selectivity metrics can overestimate the selectivity of units: a case study on AlexNet", "abstract": "Various methods of measuring unit selectivity have been developed in order to understand the representations learned by neural networks (NNs).  Here we undertake a comparison of four such measures on AlexNet, namely, localist selectivity, \\precision (Zhou et al, ICLR 2015), class-conditional mean activity selectivity CCMAS; (Morcos et al, ICLR 2018), and a new measure called top-class selectivity. In contrast with previous work on recurrent neural networks (RNNs), we fail to find any 100\\% selective `localist units' in AlexNet, and demonstrate that the \\precision and CCMAS measures provide a much higher level of selectivity than is warranted, with the most selective hidden units only responding strongly to a small minority of images from within a category. We also generated activation maximization (AM) images that maximally activated individual units and found that under (5\\%) of units in fc6 and conv5 produced interpretable images of objects, whereas fc8 produced over 50\\% interpretable images. Furthermore, the interpretable images in the hidden layers were not associated with highly selective units. These findings highlight the problem with current selectivity measures and show that new measures are required in order to provide a better assessment of learned representations in NNs.  We also consider why localist representations are learned in RNNs and not AlexNet.", "keywords": ["AlexNet", "neural networks", "selectivity", "localist", "distributed", "represenataion", "precision", "measures of selectivity", "object detectors", "single directions", "network analysis"], "authorids": ["ella.gale@gmail.com", "anhnguyen@auburn.edu", "ryan.blything@bristol.ac.uk", "nm13850@bristol.ac.uk", "j.bowers@bristol.ac.uk"], "authors": ["Ella M. Gale", "Anh Nguyen", "Ryan Blything", "Nicholas Martin and Jeffrey S. Bowers"], "TL;DR": "Common selectivity metrics overestimate the selectivity of units, true object detectors are extremely rare, but class selectivity does increase with depth. ", "pdf": "/pdf/9572777a07803d527eb4ebb80261356dee527f54.pdf", "paperhash": "gale|selectivity_metrics_can_overestimate_the_selectivity_of_units_a_case_study_on_alexnet", "_bibtex": "@misc{\ngale2019selectivity,\ntitle={Selectivity metrics can overestimate the selectivity of units: a case study on AlexNet},\nauthor={Ella M. Gale and Anh Nguyen and Ryan Blything and Nicholas Martin and Jeffrey S. Bowers},\nyear={2019},\nurl={https://openreview.net/forum?id=Skluy2RcK7},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper1001/Official_Review", "cdate": 1542234328777, "expdate": 1552335264000, "duedate": 1541196000000, "reply": {"forum": "Skluy2RcK7", "replyto": "Skluy2RcK7", "readers": {"description": "The users who will be allowed to read the reply content.", "values": ["everyone"]}, "nonreaders": {"values": []}, "signatures": {"description": "How your identity will be displayed with the above content.", "values-regex": "ICLR.cc/2019/Conference/Paper1001/AnonReviewer[0-9]+"}, "writers": {"description": "Users that may modify this record.", "values": ["ICLR.cc/2019/Conference"]}, "content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "required": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}}, "multiReply": false, "tcdate": 1552335850844, "tmdate": 1552335850844, "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "invitees": ["ICLR.cc/2019/Conference/Paper1001/Reviewers"], "noninvitees": [], "signatures": ["ICLR.cc/2019/Conference"]}}}, {"id": "rkgdcTkchX", "original": null, "number": 1, "cdate": 1541172624013, "ddate": null, "tcdate": 1541172624013, "tmdate": 1541533506994, "tddate": null, "forum": "Skluy2RcK7", "replyto": "Skluy2RcK7", "invitation": "ICLR.cc/2019/Conference/-/Paper1001/Official_Review", "content": {"title": "Poorly written with unclear contributions", "review": "This is a paper with scattered potentially interesting ideas. But the execution is limited and the writing poor with critical details lacking.  A major limitation of the paper is that it is not clear what contribution it makes. Some of the analyses are indeed interesting but 1) these analyses are mostly descriptive and 2) they are limited to one particular (outdated) architecture. How would batch norm or residual connections or any of the developments that have happened since AlexNet affect these results?\n\nAs a side note, the references/comparisons between AlexNet and recurrent nets (see abstract, etc) are misleading. This is based on the claim that Bowers et al (2014) qualitatively different results but this is for entirely different domains (words). Indeed what could have made potentially the work more relevant would have been to show some kind of benchmarking between AlexNet and alternative architectures (possibly RNNs). As such the current study does not contribute much except for comparing different semi-arbitrary measures of selectivity for one specific (outdated) network architecture trained on a particular problem (ILSVRC).\n\n****\nMinor points:\n\nThe study is limited to correctly classified images as stated on page 3. This seems like a major confound in a study aimed at understanding the visual representations learned. It seems to me that the conclusions of the paper could be heavily biased because of this (when computing any measure based on inter and intraclass responses).\n\nIn general, this is a relatively poorly written paper which would be hard to reproduce. For instance, the image generation for activating units (assuming it is novel) could be interesting but it is not even described with sufficient details so as to reproduce the results.", "rating": "3: Clear rejection", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}, "signatures": ["ICLR.cc/2019/Conference/Paper1001/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Selectivity metrics can overestimate the selectivity of units: a case study on AlexNet", "abstract": "Various methods of measuring unit selectivity have been developed in order to understand the representations learned by neural networks (NNs).  Here we undertake a comparison of four such measures on AlexNet, namely, localist selectivity, \\precision (Zhou et al, ICLR 2015), class-conditional mean activity selectivity CCMAS; (Morcos et al, ICLR 2018), and a new measure called top-class selectivity. In contrast with previous work on recurrent neural networks (RNNs), we fail to find any 100\\% selective `localist units' in AlexNet, and demonstrate that the \\precision and CCMAS measures provide a much higher level of selectivity than is warranted, with the most selective hidden units only responding strongly to a small minority of images from within a category. We also generated activation maximization (AM) images that maximally activated individual units and found that under (5\\%) of units in fc6 and conv5 produced interpretable images of objects, whereas fc8 produced over 50\\% interpretable images. Furthermore, the interpretable images in the hidden layers were not associated with highly selective units. These findings highlight the problem with current selectivity measures and show that new measures are required in order to provide a better assessment of learned representations in NNs.  We also consider why localist representations are learned in RNNs and not AlexNet.", "keywords": ["AlexNet", "neural networks", "selectivity", "localist", "distributed", "represenataion", "precision", "measures of selectivity", "object detectors", "single directions", "network analysis"], "authorids": ["ella.gale@gmail.com", "anhnguyen@auburn.edu", "ryan.blything@bristol.ac.uk", "nm13850@bristol.ac.uk", "j.bowers@bristol.ac.uk"], "authors": ["Ella M. Gale", "Anh Nguyen", "Ryan Blything", "Nicholas Martin and Jeffrey S. Bowers"], "TL;DR": "Common selectivity metrics overestimate the selectivity of units, true object detectors are extremely rare, but class selectivity does increase with depth. ", "pdf": "/pdf/9572777a07803d527eb4ebb80261356dee527f54.pdf", "paperhash": "gale|selectivity_metrics_can_overestimate_the_selectivity_of_units_a_case_study_on_alexnet", "_bibtex": "@misc{\ngale2019selectivity,\ntitle={Selectivity metrics can overestimate the selectivity of units: a case study on AlexNet},\nauthor={Ella M. Gale and Anh Nguyen and Ryan Blything and Nicholas Martin and Jeffrey S. Bowers},\nyear={2019},\nurl={https://openreview.net/forum?id=Skluy2RcK7},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper1001/Official_Review", "cdate": 1542234328777, "expdate": 1552335264000, "duedate": 1541196000000, "reply": {"forum": "Skluy2RcK7", "replyto": "Skluy2RcK7", "readers": {"description": "The users who will be allowed to read the reply content.", "values": ["everyone"]}, "nonreaders": {"values": []}, "signatures": {"description": "How your identity will be displayed with the above content.", "values-regex": "ICLR.cc/2019/Conference/Paper1001/AnonReviewer[0-9]+"}, "writers": {"description": "Users that may modify this record.", "values": ["ICLR.cc/2019/Conference"]}, "content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "required": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}}, "multiReply": false, "tcdate": 1552335850844, "tmdate": 1552335850844, "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "invitees": ["ICLR.cc/2019/Conference/Paper1001/Reviewers"], "noninvitees": [], "signatures": ["ICLR.cc/2019/Conference"]}}}], "count": 11}