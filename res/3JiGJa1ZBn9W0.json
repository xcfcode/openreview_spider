{"notes": [{"ddate": null, "legacy_migration": true, "tmdate": 1363573560000, "tcdate": 1363573560000, "number": 3, "id": "7AoBA7CD4T7Fu", "invitation": "ICLR.cc/2013/-/submission/review", "forum": "3JiGJa1ZBn9W0", "replyto": "3JiGJa1ZBn9W0", "signatures": ["Yanqing Chen, Bryan Perozzi, Rami Al-Rfou, Steven Skiena"], "readers": ["everyone"], "writers": ["anonymous"], "content": {"title": "", "review": "We thank the anonymous reviewers for the reference to Huang et al (2012).  We have  added the embeddings generated by Huang to our comparison, and we believe that they are an interesting addition.\r\n\r\nThe latest version of our submission can be found on arxiv."}, "nonreaders": [], "details": {"replyCount": 0, "overwriting": [], "revisions": false, "forumContent": {"decision": "reject", "title": "The Expressive Power of Word Embeddings", "abstract": "We seek to better understand the difference in quality of the several publicly released embeddings. We propose several tasks that help to distinguish the characteristics of different embeddings. Our evaluation shows that embeddings are able to capture deep semantics even in the absence of sentence structure. Moreover, benchmarking the embeddings shows great variance in quality and characteristics of the semantics captured by the tested embeddings. Finally, we show the impact of varying the number of dimensions and the resolution of each dimension on the effective useful features captured by the embedding space. Our contributions highlight the importance of embeddings for NLP tasks and the effect of their quality on the final results.", "pdf": "https://arxiv.org/abs/1301.3226", "paperhash": "chen|the_expressive_power_of_word_embeddings", "keywords": [], "conflicts": [], "authors": ["Yanqing Chen", "Bryan P", "Rami Al-Rfou", "Steven Skiena"], "authorids": ["cyqclark@gmail.com", "bryan.perozzi@gmail.com", "ralfrou@cs.stonybrook.edu", "skiena@cs.stonybrook.edu"]}, "tags": [], "invitation": {}}}, {"ddate": null, "legacy_migration": true, "tmdate": 1362457800000, "tcdate": 1362457800000, "number": 7, "id": "ggT4SGBq4iS57", "invitation": "ICLR.cc/2013/-/submission/review", "forum": "3JiGJa1ZBn9W0", "replyto": "3JiGJa1ZBn9W0", "signatures": ["Yanqing Chen, Bryan Perozzi, Rami Al-Rfou, Steven Skiena"], "readers": ["everyone"], "writers": ["anonymous"], "content": {"title": "", "review": "We thank the anonymous reviewers for their thoughtful comments.  We have taken them into consideration, and have uploaded a revised manuscript to arXiv over the weekend. (it should be available in a few hours)\r\n\r\nSpecific changes include:\r\n1. We have evaluated 3-class versions of our classifiers on the sentiment and synonym/antonym tasks.\r\n2. We have reworked to focus more explicitly on term vs. pair tasks, and believe that this is a more clear presentation of our ideas\r\n3. We have illustrated the convergence of linear vs. nonlinear classifiers as dimensions are reduced by PCA.\r\n4. We have tried to modify specific language and tone that the reviewers found objectionable.\r\n\r\nWe have some specific comments to each of our reviewers:\r\n\r\nAnonymous 406c, (1st reviewer, 2/14/2013)\r\n\r\n- Scaling of embeddings:\r\nWe investigated scaling the embeddings to control the variance after PCA as recommended by Turian (2010).  Results did not significantly change, and so we left the original in there.  We have posted the corresponding plots with scaling:\r\n(by embedding)  http://goo.gl/wpXmD\r\n(by task)   http://goo.gl/hWYkX\r\n\r\nYou might also be interested in the fact that we ran all of our experiments on scaled and unscaled versions of the embeddings, but did not notice significant differences between them.  We attribute both these results to the fact that we only used embeddings as features - Turian (2010) comments that his scaling approach is for mixing embedding features with words represented by binary features.  \r\n\r\nAnonymous af94 (2nd reviewer, 3/1/2013)\r\n\r\n- Similar to Turian (2010)\r\nWe\u2019re quite different actually - Turian (2010) studied enhancing existing NLP tools with a variety of embeddings.  This means that he combined the embeddings with existing features (from words,  n-grams, or characters).\r\nInstead, we use the embeddings as the sole features to understand their quality on their own. Moreover, we propose term/pair classification tasks to isolate the effect of context that influence the results of sequence tagging tasks.\r\n\r\n- Pairwise classification is easier because its an ensemble\r\nYou raise an interesting point here.  To explain our views: in our initial experiments we used the element-wise subtraction between two embeddings as features and they outperformed the single word version of the experiment.  This seems to indicate that the embeddings encode information in the direction of the vector between two points in the space.  We later modified the experiment to the one we report (it seemed more general at the time).\r\n\r\n- Classifiers? Which? Where?\r\nWe use Linear SVM, Logistic Regression, RBF Kernel SVM on all our tasks and report the geometric mean of their results for each task. Each classifier result is obtained with 4-fold cross validation setup. \r\n\r\nWe also have some general comments on the nature of our tasks, and the decision to evaluate existing embeddings instead of training new ones\r\nOn the nature of our tasks:\r\n\r\nMost of the previous evaluation on word embeddings has been done in the context of sequence tagging problems.  While practical, we believe that this approach complicates the actual analysis of the features learned by neural language models.  \r\n\r\nFor example, in a typical part of speech tagging setup the performance of the tagger over out-of-vocabulary words (without using character features) is much higher than random and might reach 70-80% accuracy. The decision, here, is clearly induced by the context. The influence of the context on the performance of classification, makes it harder to estimate the intrinsic quality of the word embeddings.\r\n\r\nWe agree that not all of our tasks map directly to traditional NLP tasks, but this is intended - each task illustrates one type of interesting behavior that can be found in the embedding space.  Some behaviors are ones known to exist (e.g. plurality is a sub-component of Part-of-Speech tagging), one seems practical (sentiment), and one is just cool (e.g. synonym / antonym).  The list is certainly not comprehensive, and we would appreciate additional suggestions.\r\n\r\nOn not training our own embeddings:\r\n\r\nWe are interested in NLP applications of feature learning, and we believe our results are valuable to consumers of such technology. We strove to evaluate the quality of what is available other researchers would use in their work.\r\n\r\nWe do agree it is hard to compare features produced under different conditions. It is a matter of fact that some of the embeddings will be better than others. The differences could be attributed to training specific factors (e.g. training time and datasets), or to the technique itself.  In light of this difficulty we have tried to highlight that we are comparing the embeddings themselves, and not the techniques.  We have toned down language contrary to this message.\r\n\r\nOn a final note, we would like to again thank our anonymous reviewers, and the greater ICLR community."}, "nonreaders": [], "details": {"replyCount": 0, "overwriting": [], "revisions": false, "forumContent": {"decision": "reject", "title": "The Expressive Power of Word Embeddings", "abstract": "We seek to better understand the difference in quality of the several publicly released embeddings. We propose several tasks that help to distinguish the characteristics of different embeddings. Our evaluation shows that embeddings are able to capture deep semantics even in the absence of sentence structure. Moreover, benchmarking the embeddings shows great variance in quality and characteristics of the semantics captured by the tested embeddings. Finally, we show the impact of varying the number of dimensions and the resolution of each dimension on the effective useful features captured by the embedding space. Our contributions highlight the importance of embeddings for NLP tasks and the effect of their quality on the final results.", "pdf": "https://arxiv.org/abs/1301.3226", "paperhash": "chen|the_expressive_power_of_word_embeddings", "keywords": [], "conflicts": [], "authors": ["Yanqing Chen", "Bryan P", "Rami Al-Rfou", "Steven Skiena"], "authorids": ["cyqclark@gmail.com", "bryan.perozzi@gmail.com", "ralfrou@cs.stonybrook.edu", "skiena@cs.stonybrook.edu"]}, "tags": [], "invitation": {}}}, {"ddate": null, "legacy_migration": true, "tmdate": 1362416940000, "tcdate": 1362416940000, "number": 1, "id": "QrngQQuNMcQNZ", "invitation": "ICLR.cc/2013/-/submission/review", "forum": "3JiGJa1ZBn9W0", "replyto": "3JiGJa1ZBn9W0", "signatures": ["anonymous reviewer 24e2"], "readers": ["everyone"], "writers": ["anonymous"], "content": {"title": "review of The Expressive Power of Word Embeddings", "review": "This paper compares three available word vector embeddings on several tasks.\r\n\r\nThe paper lacks somewhat in novelty since the vectors are simply downloaded. This also makes their comparison somewhat harder since the final result is largely dependent on the training corpora.\r\n\r\nA comparison to the vectors of Huang et al 2012 would be interesting since they are very related.\r\n\r\nIt would be somewhat more interesting if the methods had been trained on the same dataset and on harder or real tasks such as NER (as done by Turian).\r\n\r\nFor a more semantic evaluation the datasets of WordSim353 or Huang et al could be used to compare to human judgments.\r\n\r\nIt would be very interesting to find if some of the dimensions are well correlated with some of the labels of the supervised tasks that are considered."}, "nonreaders": [], "details": {"replyCount": 0, "overwriting": [], "revisions": false, "forumContent": {"decision": "reject", "title": "The Expressive Power of Word Embeddings", "abstract": "We seek to better understand the difference in quality of the several publicly released embeddings. We propose several tasks that help to distinguish the characteristics of different embeddings. Our evaluation shows that embeddings are able to capture deep semantics even in the absence of sentence structure. Moreover, benchmarking the embeddings shows great variance in quality and characteristics of the semantics captured by the tested embeddings. Finally, we show the impact of varying the number of dimensions and the resolution of each dimension on the effective useful features captured by the embedding space. Our contributions highlight the importance of embeddings for NLP tasks and the effect of their quality on the final results.", "pdf": "https://arxiv.org/abs/1301.3226", "paperhash": "chen|the_expressive_power_of_word_embeddings", "keywords": [], "conflicts": [], "authors": ["Yanqing Chen", "Bryan P", "Rami Al-Rfou", "Steven Skiena"], "authorids": ["cyqclark@gmail.com", "bryan.perozzi@gmail.com", "ralfrou@cs.stonybrook.edu", "skiena@cs.stonybrook.edu"]}, "tags": [], "invitation": {}}}, {"ddate": null, "legacy_migration": true, "tmdate": 1362189720000, "tcdate": 1362189720000, "number": 6, "id": "KcIrcVwbnRc0P", "invitation": "ICLR.cc/2013/-/submission/review", "forum": "3JiGJa1ZBn9W0", "replyto": "3JiGJa1ZBn9W0", "signatures": ["Andrew Maas"], "readers": ["everyone"], "writers": ["anonymous"], "content": {"title": "", "review": "On the topic of comparing word representations, quality as a function of word frequency is something I've often found to be a problem. For example, rare words are often important for sentiment analysis, but many word representation learners produce poor representations for all but the top 1000 or so most frequent words. As this paper is focused on comparing representations, I think adding an experiment to assess quality of less common words would tremendously help the community understand the tradeoffs between word representation methods."}, "nonreaders": [], "details": {"replyCount": 0, "overwriting": [], "revisions": false, "forumContent": {"decision": "reject", "title": "The Expressive Power of Word Embeddings", "abstract": "We seek to better understand the difference in quality of the several publicly released embeddings. We propose several tasks that help to distinguish the characteristics of different embeddings. Our evaluation shows that embeddings are able to capture deep semantics even in the absence of sentence structure. Moreover, benchmarking the embeddings shows great variance in quality and characteristics of the semantics captured by the tested embeddings. Finally, we show the impact of varying the number of dimensions and the resolution of each dimension on the effective useful features captured by the embedding space. Our contributions highlight the importance of embeddings for NLP tasks and the effect of their quality on the final results.", "pdf": "https://arxiv.org/abs/1301.3226", "paperhash": "chen|the_expressive_power_of_word_embeddings", "keywords": [], "conflicts": [], "authors": ["Yanqing Chen", "Bryan P", "Rami Al-Rfou", "Steven Skiena"], "authorids": ["cyqclark@gmail.com", "bryan.perozzi@gmail.com", "ralfrou@cs.stonybrook.edu", "skiena@cs.stonybrook.edu"]}, "tags": [], "invitation": {}}}, {"ddate": null, "legacy_migration": true, "tmdate": 1362170040000, "tcdate": 1362170040000, "number": 2, "id": "224E22nDWH2Ia", "invitation": "ICLR.cc/2013/-/submission/review", "forum": "3JiGJa1ZBn9W0", "replyto": "3JiGJa1ZBn9W0", "signatures": ["anonymous reviewer af94"], "readers": ["everyone"], "writers": ["anonymous"], "content": {"title": "review of The Expressive Power of Word Embeddings", "review": "The submission considers 3 types of publicly-available distributed representations of words: produced by SENNA (Collobert and Weston, 11), the hierarchical bilinear language model (Mnih and Hinton, 2007) and Turian et al's (2010) implementation of the SENNA method.  They compare performance of classifiers using the embeddings on 5 different tasks (e.g., sentiment polarity, noun gender). \r\n\r\nIn a way, this submission is similar to the work of Turian et al (2010) where different types of word representations are compared, however, here the authors just use available representations rather than induce their own. Consequently, they cannot shed the light on which factors affect the resulting performance the most (e.g., data size, loss used, regularization regime). Consequently, the paper may be useful when deciding which representations to download, but it does not provide sufficiently interesting insights on which methods are preferable.  \r\n\r\nThe discussion of pair classification seems somewhat misleading. The authors attribute improved results on classifying pairs (e.g., where the first word or the second name in a given pair is masculine) w.r.t. classifying words (e.g., whether a name is masculine or feminine) to the lack of linear separability, whereas it is obvious that pairwise classification is always easier. Basically, as we know that there is a single word of each class in a pair, it is an ensemble prediction (one classifier using 1st word, another - the second one). So, I am not really sure what this result is actually telling us. \r\n\r\nI am also not sure how interesting the truncation experiments are.  I would be much more interesting to see which dimensionality of the representation is needed,  but mostly which initial representations, as it  affects training performance (at least linearly).  However, again, this is not really possible without retraining the models. \r\n\r\nPros:\r\n- I believe that a high-quality comparison of existing methods for inducing word representations would be an important contribution.\r\n\r\nCons:\r\n-  The paper compares downloaded representations rather than the methods.  It does not answer the question which method is better (for each task)\r\n-   Some details of the experimental set-up are a little unclear. E.g., the paper mentions that logistic regression, an SVM with the linear kernel, and an SVM with the RBF kernel are used. However, it does not clarify which classifier was used and where. Were classifiers also chosen with cross validation?\r\n-   Some of the tasks (e.g., choosing British vs. American spelling) could benefit from using methods exploiting wider document context (rather than ngrams).  There have been some methods for incorporating this information (see, e.g., Huang  et al, 2012). It would be interesting to have such methods in the list.\r\n\r\nMinor:\r\n- abstract: 'our evaluation shows that embeddings \u2026 capture deep semantics', I am not sure what the authors mean by 'deep' semantics. However, I doubt that any of the considered tasks could be considered as such."}, "nonreaders": [], "details": {"replyCount": 0, "overwriting": [], "revisions": false, "forumContent": {"decision": "reject", "title": "The Expressive Power of Word Embeddings", "abstract": "We seek to better understand the difference in quality of the several publicly released embeddings. We propose several tasks that help to distinguish the characteristics of different embeddings. Our evaluation shows that embeddings are able to capture deep semantics even in the absence of sentence structure. Moreover, benchmarking the embeddings shows great variance in quality and characteristics of the semantics captured by the tested embeddings. Finally, we show the impact of varying the number of dimensions and the resolution of each dimension on the effective useful features captured by the embedding space. Our contributions highlight the importance of embeddings for NLP tasks and the effect of their quality on the final results.", "pdf": "https://arxiv.org/abs/1301.3226", "paperhash": "chen|the_expressive_power_of_word_embeddings", "keywords": [], "conflicts": [], "authors": ["Yanqing Chen", "Bryan P", "Rami Al-Rfou", "Steven Skiena"], "authorids": ["cyqclark@gmail.com", "bryan.perozzi@gmail.com", "ralfrou@cs.stonybrook.edu", "skiena@cs.stonybrook.edu"]}, "tags": [], "invitation": {}}}, {"ddate": null, "legacy_migration": true, "tmdate": 1360886580000, "tcdate": 1360886580000, "number": 5, "id": "0sZLsSijYosjR", "invitation": "ICLR.cc/2013/-/submission/review", "forum": "3JiGJa1ZBn9W0", "replyto": "3JiGJa1ZBn9W0", "signatures": ["Yanqing Chen"], "readers": ["everyone"], "writers": ["anonymous"], "content": {"title": "", "review": "Hello dear reviewer,\r\n    \r\n    Thank you for your well thought out review. We hope to have a draft which addresses some of your comments shortly.\r\n\r\nRegards"}, "nonreaders": [], "details": {"replyCount": 0, "overwriting": [], "revisions": false, "forumContent": {"decision": "reject", "title": "The Expressive Power of Word Embeddings", "abstract": "We seek to better understand the difference in quality of the several publicly released embeddings. We propose several tasks that help to distinguish the characteristics of different embeddings. Our evaluation shows that embeddings are able to capture deep semantics even in the absence of sentence structure. Moreover, benchmarking the embeddings shows great variance in quality and characteristics of the semantics captured by the tested embeddings. Finally, we show the impact of varying the number of dimensions and the resolution of each dimension on the effective useful features captured by the embedding space. Our contributions highlight the importance of embeddings for NLP tasks and the effect of their quality on the final results.", "pdf": "https://arxiv.org/abs/1301.3226", "paperhash": "chen|the_expressive_power_of_word_embeddings", "keywords": [], "conflicts": [], "authors": ["Yanqing Chen", "Bryan P", "Rami Al-Rfou", "Steven Skiena"], "authorids": ["cyqclark@gmail.com", "bryan.perozzi@gmail.com", "ralfrou@cs.stonybrook.edu", "skiena@cs.stonybrook.edu"]}, "tags": [], "invitation": {}}}, {"ddate": null, "legacy_migration": true, "tmdate": 1360855200000, "tcdate": 1360855200000, "number": 4, "id": "-82Lr-SgHKmgJ", "invitation": "ICLR.cc/2013/-/submission/review", "forum": "3JiGJa1ZBn9W0", "replyto": "3JiGJa1ZBn9W0", "signatures": ["anonymous reviewer 406c"], "readers": ["everyone"], "writers": ["anonymous"], "content": {"title": "review of The Expressive Power of Word Embeddings", "review": "The paper proposes a method for evaluating real-valued vector embeddings of words based on several word and word-pair classification tasks. Though evaluation of such embeddings is an interesting and important problem, the experimental setup used it virtually impossible to draw any interesting conclusions.\r\n\r\nSome of the proposed evaluation tasks are a considerably less interesting than others. The Sentiment Polarity, for example, is certainly interesting and practically relevant, while the Regional Spellings task seems artificial. Moreover, performance on the latter is likely to be very sensitive to the regional distribution in the corpus to learn the embeddings. While identifying synonyms and and antonyms is an interesting problem, the formulation of the Synonyms and Antonyms task is too artificial. Instead of classifying a word pair as synonyms or antonyms or it would be far more interesting to perform three-way classification of such pairs into synonyms, antonyms, and neither. Note that there is little reason to think that embeddings learned by neural language models will capture the difference between antonyms and synonyms well because replacing a word with its antonym or synonym often has little effect on the probability of the sentence.\r\n\r\nThe experimental evaluation of the embeddings is unfortunately almost completely uninformative due to several confounding factors. The models used to produce the embeddings were trained on different datasets, with different vocabularies, context sizes, and number of passes through the data. Without controlling for these it is impossible to know the real reasons behind the differences in performance of the embeddings. All that can be concluded from the results in the paper is that some of the publicly available embeddings perform better than others on the proposed tasks. However, without controlling for the above factors, claims like 'Our work illustrates that significant differences in the information captured by each technique exist.' are unjustified.\r\n\r\nThe results obtained by reducing the amount of information in the embeddings are more informative. The fact that quantizing the real values in the embeddings does not drastically affect the classification performance is quite interesting. However, to make this result more convincing the authors need to control for the differences in the variance of the embeddings resulting from quantization. These differences are problematic because, as Turian at al. [14] showed, scaling embeddings by a constant can have a significant effect on classifier performance.\r\n\r\nThe results obtained using PCA to reduce the representation dimensionality are hard to interpret because the paper does not report the numbers for the linear and non-linear classifiers separately. This is a problem because reducing the input dimensionality has a much more drastic effect on the capacity of linear classifiers. Thus it is entirely possible that though the relevant information is stilled contained in the projected embeddings, the linear classifiers simply cannot take advantage of it.\r\n\r\nWhile the authors mention 4-fold cross validation and a development set, it is unclear whether the set was one of the folds. Does it mean that two folds were used for training, one for validation, and one for testing?\r\n\r\nIt is also unclear which method was used to produce Figure 3(b).\r\n\r\nThe probabilities in Table 2 are given in percent but the caption does not\r\nstate that."}, "nonreaders": [], "details": {"replyCount": 0, "overwriting": [], "revisions": false, "forumContent": {"decision": "reject", "title": "The Expressive Power of Word Embeddings", "abstract": "We seek to better understand the difference in quality of the several publicly released embeddings. We propose several tasks that help to distinguish the characteristics of different embeddings. Our evaluation shows that embeddings are able to capture deep semantics even in the absence of sentence structure. Moreover, benchmarking the embeddings shows great variance in quality and characteristics of the semantics captured by the tested embeddings. Finally, we show the impact of varying the number of dimensions and the resolution of each dimension on the effective useful features captured by the embedding space. Our contributions highlight the importance of embeddings for NLP tasks and the effect of their quality on the final results.", "pdf": "https://arxiv.org/abs/1301.3226", "paperhash": "chen|the_expressive_power_of_word_embeddings", "keywords": [], "conflicts": [], "authors": ["Yanqing Chen", "Bryan P", "Rami Al-Rfou", "Steven Skiena"], "authorids": ["cyqclark@gmail.com", "bryan.perozzi@gmail.com", "ralfrou@cs.stonybrook.edu", "skiena@cs.stonybrook.edu"]}, "tags": [], "invitation": {}}}, {"replyto": null, "ddate": null, "legacy_migration": true, "tmdate": 1358316900000, "tcdate": 1358316900000, "number": 55, "id": "3JiGJa1ZBn9W0", "invitation": "ICLR.cc/2013/conference/-/submission", "forum": "3JiGJa1ZBn9W0", "signatures": ["cyqclark@gmail.com"], "readers": ["everyone"], "content": {"decision": "reject", "title": "The Expressive Power of Word Embeddings", "abstract": "We seek to better understand the difference in quality of the several publicly released embeddings. We propose several tasks that help to distinguish the characteristics of different embeddings. Our evaluation shows that embeddings are able to capture deep semantics even in the absence of sentence structure. Moreover, benchmarking the embeddings shows great variance in quality and characteristics of the semantics captured by the tested embeddings. Finally, we show the impact of varying the number of dimensions and the resolution of each dimension on the effective useful features captured by the embedding space. Our contributions highlight the importance of embeddings for NLP tasks and the effect of their quality on the final results.", "pdf": "https://arxiv.org/abs/1301.3226", "paperhash": "chen|the_expressive_power_of_word_embeddings", "keywords": [], "conflicts": [], "authors": ["Yanqing Chen", "Bryan P", "Rami Al-Rfou", "Steven Skiena"], "authorids": ["cyqclark@gmail.com", "bryan.perozzi@gmail.com", "ralfrou@cs.stonybrook.edu", "skiena@cs.stonybrook.edu"]}, "writers": [], "details": {"replyCount": 7, "writable": false, "overwriting": [], "revisions": false, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1369422751717, "tmdate": 1496673673639, "cdate": 1496673673639, "tcdate": 1496673673639, "id": "ICLR.cc/2013/conference/-/submission", "writers": ["ICLR.cc/2013"], "signatures": ["OpenReview.net"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": null, "replyto": null, "writers": {"values-regex": "~.*"}, "signatures": {"values-regex": "~.*", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"pdf": {"required": true, "order": 5, "description": "Either upload a PDF file or provide a direct link to your PDF on ArXiv (link must begin with http(s) and end with .pdf)", "value-regex": "upload|(http|https):\\/\\/.+\\.pdf"}, "title": {"required": true, "order": 1, "description": "Title of paper.", "value-regex": ".{1,250}"}, "abstract": {"required": true, "order": 4, "description": "Abstract of paper.", "value-regex": "[\\S\\s]{1,5000}"}, "authors": {"required": true, "order": 2, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of author names, as they appear in the paper."}, "conflicts": {"required": true, "order": 100, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of email domains of people who would have a conflict of interest in reviewing this paper, (e.g., cs.umass.edu;google.com, etc.)."}, "keywords": {"order": 6, "description": "Comma separated list of keywords.", "values-dropdown": []}, "authorids": {"required": true, "order": 3, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of author email addresses, in the same order as above."}}}, "nonreaders": [], "noninvitees": [], "expdate": 1377198751717}}}], "count": 8}