{"notes": [{"id": "HJz6tiCqYm", "original": "S1xnna59tm", "number": 489, "cdate": 1538087813282, "ddate": null, "tcdate": 1538087813282, "tmdate": 1551809917795, "tddate": null, "forum": "HJz6tiCqYm", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Benchmarking Neural Network Robustness to Common Corruptions and Perturbations", "abstract": "In this paper we establish rigorous benchmarks for image classifier robustness. Our first benchmark, ImageNet-C, standardizes and expands the corruption robustness topic, while showing which classifiers are preferable in safety-critical applications. Then we propose a new dataset called ImageNet-P which enables researchers to benchmark a classifier's robustness to common perturbations. Unlike recent robustness research, this benchmark evaluates performance on common corruptions and perturbations not worst-case adversarial perturbations. We find that there are negligible changes in relative corruption robustness from AlexNet classifiers to ResNet classifiers. Afterward we discover ways to enhance corruption and perturbation robustness. We even find that a bypassed adversarial defense provides substantial common perturbation robustness. Together our benchmarks may aid future work toward networks that robustly generalize.", "keywords": ["robustness", "benchmark", "convnets", "perturbations"], "authorids": ["hendrycks@berkeley.edu", "tgd@oregonstate.edu"], "authors": ["Dan Hendrycks", "Thomas Dietterich"], "TL;DR": "We propose ImageNet-C to measure classifier corruption robustness and ImageNet-P to measure perturbation robustness", "pdf": "/pdf/94c9c0c321074c7acfbf169c69e81edd5ed7a7e9.pdf", "paperhash": "hendrycks|benchmarking_neural_network_robustness_to_common_corruptions_and_perturbations", "_bibtex": "@inproceedings{\nhendrycks2018benchmarking,\ntitle={Benchmarking Neural Network Robustness to Common Corruptions and Perturbations},\nauthor={Dan Hendrycks and Thomas Dietterich},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=HJz6tiCqYm},\n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"replyCount": 22, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Blind_Submission", "rdate": null, "ddate": null, "expdate": null, "duedate": 1538085600000, "tmdate": 1538142958393, "tddate": null, "super": null, "final": null, "reply": {"signatures": {"values": ["ICLR.cc/2019/Conference"]}, "forum": null, "readers": {"values": ["everyone"]}, "replyto": null, "content": {"authorids": {"values-regex": ".*"}, "authors": {"values": ["Anonymous"]}}, "writers": {"values": ["ICLR.cc/2019/Conference"]}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["~"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": null, "taskCompletionCount": null, "transform": null, "cdate": 1538142958393}}, "tauthor": "OpenReview.net"}, {"id": "BygwXHNOlV", "original": null, "number": 16, "cdate": 1545254175504, "ddate": null, "tcdate": 1545254175504, "tmdate": 1545514192404, "tddate": null, "forum": "HJz6tiCqYm", "replyto": "ryxahIfEgE", "invitation": "ICLR.cc/2019/Conference/-/Paper489/Official_Comment", "content": {"title": "Reply", "comment": "Thank you for your interest! Since this task is not adversarial in nature, we do not intend to continually modify the corruptions to subvert new approaches, much like how CIFAR-10 did not continually change to make classification harder for every new architecture and method. Improved generalization to unseen corruptions suggests improved corruption robustness. However if necessary we are open to updating the benchmark, but we will first see whether the research community experiments in this setting."}, "signatures": ["ICLR.cc/2019/Conference/Paper489/Authors"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper489/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper489/Authors", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Benchmarking Neural Network Robustness to Common Corruptions and Perturbations", "abstract": "In this paper we establish rigorous benchmarks for image classifier robustness. Our first benchmark, ImageNet-C, standardizes and expands the corruption robustness topic, while showing which classifiers are preferable in safety-critical applications. Then we propose a new dataset called ImageNet-P which enables researchers to benchmark a classifier's robustness to common perturbations. Unlike recent robustness research, this benchmark evaluates performance on common corruptions and perturbations not worst-case adversarial perturbations. We find that there are negligible changes in relative corruption robustness from AlexNet classifiers to ResNet classifiers. Afterward we discover ways to enhance corruption and perturbation robustness. We even find that a bypassed adversarial defense provides substantial common perturbation robustness. Together our benchmarks may aid future work toward networks that robustly generalize.", "keywords": ["robustness", "benchmark", "convnets", "perturbations"], "authorids": ["hendrycks@berkeley.edu", "tgd@oregonstate.edu"], "authors": ["Dan Hendrycks", "Thomas Dietterich"], "TL;DR": "We propose ImageNet-C to measure classifier corruption robustness and ImageNet-P to measure perturbation robustness", "pdf": "/pdf/94c9c0c321074c7acfbf169c69e81edd5ed7a7e9.pdf", "paperhash": "hendrycks|benchmarking_neural_network_robustness_to_common_corruptions_and_perturbations", "_bibtex": "@inproceedings{\nhendrycks2018benchmarking,\ntitle={Benchmarking Neural Network Robustness to Common Corruptions and Perturbations},\nauthor={Dan Hendrycks and Thomas Dietterich},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=HJz6tiCqYm},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper489/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621605552, "tddate": null, "super": null, "final": null, "reply": {"forum": "HJz6tiCqYm", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper489/Authors", "ICLR.cc/2019/Conference/Paper489/Reviewers", "ICLR.cc/2019/Conference/Paper489/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper489/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper489/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper489/Authors|ICLR.cc/2019/Conference/Paper489/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper489/Reviewers", "ICLR.cc/2019/Conference/Paper489/Authors", "ICLR.cc/2019/Conference/Paper489/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621605552}}}, {"id": "rJxW-nzJyN", "original": null, "number": 9, "cdate": 1543609337334, "ddate": null, "tcdate": 1543609337334, "tmdate": 1545366723969, "tddate": null, "forum": "HJz6tiCqYm", "replyto": "HJz6tiCqYm", "invitation": "ICLR.cc/2019/Conference/-/Paper489/Official_Comment", "content": {"title": "Data Augmentation with Stylized ImageNet Improves Corruption Robustness", "comment": "A parallel submission proposes to train classifiers on stylized ImageNet images. The aim is to make classifiers rely less on texture and more on shape. https://openreview.net/pdf?id=Bygh9j09KX\n\nWe have found that this method indeed improves corruption robustness. A ResNet-50 obtains an mCE of 76.70%, while a ResNet-50 trained on both ImageNet images and stylized ImageNet images has an mCE of 69.32% (with general improvements noise, blur, weather, and digital categories)."}, "signatures": ["ICLR.cc/2019/Conference/Paper489/Authors"], "readers": ["ICLR.cc/2019/Conference/Paper489/Authors", "everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper489/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper489/Authors", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Benchmarking Neural Network Robustness to Common Corruptions and Perturbations", "abstract": "In this paper we establish rigorous benchmarks for image classifier robustness. Our first benchmark, ImageNet-C, standardizes and expands the corruption robustness topic, while showing which classifiers are preferable in safety-critical applications. Then we propose a new dataset called ImageNet-P which enables researchers to benchmark a classifier's robustness to common perturbations. Unlike recent robustness research, this benchmark evaluates performance on common corruptions and perturbations not worst-case adversarial perturbations. We find that there are negligible changes in relative corruption robustness from AlexNet classifiers to ResNet classifiers. Afterward we discover ways to enhance corruption and perturbation robustness. We even find that a bypassed adversarial defense provides substantial common perturbation robustness. Together our benchmarks may aid future work toward networks that robustly generalize.", "keywords": ["robustness", "benchmark", "convnets", "perturbations"], "authorids": ["hendrycks@berkeley.edu", "tgd@oregonstate.edu"], "authors": ["Dan Hendrycks", "Thomas Dietterich"], "TL;DR": "We propose ImageNet-C to measure classifier corruption robustness and ImageNet-P to measure perturbation robustness", "pdf": "/pdf/94c9c0c321074c7acfbf169c69e81edd5ed7a7e9.pdf", "paperhash": "hendrycks|benchmarking_neural_network_robustness_to_common_corruptions_and_perturbations", "_bibtex": "@inproceedings{\nhendrycks2018benchmarking,\ntitle={Benchmarking Neural Network Robustness to Common Corruptions and Perturbations},\nauthor={Dan Hendrycks and Thomas Dietterich},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=HJz6tiCqYm},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper489/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621605552, "tddate": null, "super": null, "final": null, "reply": {"forum": "HJz6tiCqYm", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper489/Authors", "ICLR.cc/2019/Conference/Paper489/Reviewers", "ICLR.cc/2019/Conference/Paper489/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper489/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper489/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper489/Authors|ICLR.cc/2019/Conference/Paper489/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper489/Reviewers", "ICLR.cc/2019/Conference/Paper489/Authors", "ICLR.cc/2019/Conference/Paper489/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621605552}}}, {"id": "HylJlCQklN", "original": null, "number": 1, "cdate": 1544662502855, "ddate": null, "tcdate": 1544662502855, "tmdate": 1545354504464, "tddate": null, "forum": "HJz6tiCqYm", "replyto": "HJz6tiCqYm", "invitation": "ICLR.cc/2019/Conference/-/Paper489/Meta_Review", "content": {"metareview": "The reviewers have all recommended accepting this paper thus I am as well. Based on the reviews and the selectivity of the single track for oral presentations, I am only recommending acceptance as a poster.", "confidence": "5: The area chair is absolutely certain", "recommendation": "Accept (Poster)", "title": "clear consensus to accept this paper"}, "signatures": ["ICLR.cc/2019/Conference/Paper489/Area_Chair1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference/Paper489/Area_Chair1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Benchmarking Neural Network Robustness to Common Corruptions and Perturbations", "abstract": "In this paper we establish rigorous benchmarks for image classifier robustness. Our first benchmark, ImageNet-C, standardizes and expands the corruption robustness topic, while showing which classifiers are preferable in safety-critical applications. Then we propose a new dataset called ImageNet-P which enables researchers to benchmark a classifier's robustness to common perturbations. Unlike recent robustness research, this benchmark evaluates performance on common corruptions and perturbations not worst-case adversarial perturbations. We find that there are negligible changes in relative corruption robustness from AlexNet classifiers to ResNet classifiers. Afterward we discover ways to enhance corruption and perturbation robustness. We even find that a bypassed adversarial defense provides substantial common perturbation robustness. Together our benchmarks may aid future work toward networks that robustly generalize.", "keywords": ["robustness", "benchmark", "convnets", "perturbations"], "authorids": ["hendrycks@berkeley.edu", "tgd@oregonstate.edu"], "authors": ["Dan Hendrycks", "Thomas Dietterich"], "TL;DR": "We propose ImageNet-C to measure classifier corruption robustness and ImageNet-P to measure perturbation robustness", "pdf": "/pdf/94c9c0c321074c7acfbf169c69e81edd5ed7a7e9.pdf", "paperhash": "hendrycks|benchmarking_neural_network_robustness_to_common_corruptions_and_perturbations", "_bibtex": "@inproceedings{\nhendrycks2018benchmarking,\ntitle={Benchmarking Neural Network Robustness to Common Corruptions and Perturbations},\nauthor={Dan Hendrycks and Thomas Dietterich},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=HJz6tiCqYm},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper489/Meta_Review", "rdate": null, "ddate": null, "expdate": null, "duedate": 1541548800000, "tmdate": 1545353199899, "tddate": null, "super": null, "final": null, "reply": {"forum": "HJz6tiCqYm", "replyto": "HJz6tiCqYm", "readers": {"description": "Select all user groups that should be able to read this comment. Selecting 'All Users' will allow paper authors, reviewers, area chairs, and program chairs to view this comment.", "values": ["everyone"]}, "signatures": {"description": "How your identity will be displayed with the above content.", "values-regex": "ICLR.cc/2019/Conference/Paper489/Area_Chair[0-9]+"}, "writers": {"description": "Users that may modify this record.", "values-regex": "ICLR.cc/2019/Conference/Paper489/Area_Chair[0-9]+"}, "content": {"title": {"order": 1, "value-regex": ".{1,500}", "description": "Brief summary of your review.", "required": true}, "metareview": {"order": 2, "value-regex": "[\\S\\s]{1,5000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "required": true}, "recommendation": {"order": 3, "value-dropdown": ["Accept (Oral)", "Accept (Poster)", "Reject"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The area chair is absolutely certain", "4: The area chair is confident but not absolutely certain", "3: The area chair is somewhat confident", "2: The area chair is not sure", "1: The area chair's evaluation is an educated guess"], "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper489/Area_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": false, "taskCompletionCount": null, "transform": null, "cdate": 1545353199899}}}, {"id": "ryxahIfEgE", "original": null, "number": 6, "cdate": 1544984245371, "ddate": null, "tcdate": 1544984245371, "tmdate": 1544984868083, "tddate": null, "forum": "HJz6tiCqYm", "replyto": "HJz6tiCqYm", "invitation": "ICLR.cc/2019/Conference/-/Paper489/Public_Comment", "content": {"comment": "Hi, it\u2019s an interesting work!\n\nI would like to ask the authors how to ensure that the benchmarks are sufficiently representative to evaluate the robustness of models.\n\nWill the benchmarks be updated in the future as new adversarial attacks (Corruptions or Perturbations) emerge?\n\n\n", "title": "Question about the Representativity and the Time-Efficiency of the benchmarks"}, "signatures": ["(anonymous)"], "readers": ["everyone"], "nonreaders": [], "writers": ["(anonymous)", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Benchmarking Neural Network Robustness to Common Corruptions and Perturbations", "abstract": "In this paper we establish rigorous benchmarks for image classifier robustness. Our first benchmark, ImageNet-C, standardizes and expands the corruption robustness topic, while showing which classifiers are preferable in safety-critical applications. Then we propose a new dataset called ImageNet-P which enables researchers to benchmark a classifier's robustness to common perturbations. Unlike recent robustness research, this benchmark evaluates performance on common corruptions and perturbations not worst-case adversarial perturbations. We find that there are negligible changes in relative corruption robustness from AlexNet classifiers to ResNet classifiers. Afterward we discover ways to enhance corruption and perturbation robustness. We even find that a bypassed adversarial defense provides substantial common perturbation robustness. Together our benchmarks may aid future work toward networks that robustly generalize.", "keywords": ["robustness", "benchmark", "convnets", "perturbations"], "authorids": ["hendrycks@berkeley.edu", "tgd@oregonstate.edu"], "authors": ["Dan Hendrycks", "Thomas Dietterich"], "TL;DR": "We propose ImageNet-C to measure classifier corruption robustness and ImageNet-P to measure perturbation robustness", "pdf": "/pdf/94c9c0c321074c7acfbf169c69e81edd5ed7a7e9.pdf", "paperhash": "hendrycks|benchmarking_neural_network_robustness_to_common_corruptions_and_perturbations", "_bibtex": "@inproceedings{\nhendrycks2018benchmarking,\ntitle={Benchmarking Neural Network Robustness to Common Corruptions and Perturbations},\nauthor={Dan Hendrycks and Thomas Dietterich},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=HJz6tiCqYm},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper489/Public_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1542311828377, "tddate": null, "super": null, "final": null, "reply": {"signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed."}, "nonreaders": {"values": []}, "forum": "HJz6tiCqYm", "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper489/Authors", "ICLR.cc/2019/Conference/Paper489/Reviewers", "ICLR.cc/2019/Conference/Paper489/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "replyto": null, "content": {"comment": {"value-regex": "[\\S\\s]{1,5000}", "required": true, "order": 1, "description": "Your comment or reply (max 5000 characters)."}, "title": {"value-regex": ".{1,500}", "required": true, "order": 0, "description": "Brief summary of your comment."}}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["~"], "noninvitees": ["ICLR.cc/2019/Conference/Paper489/Authors", "ICLR.cc/2019/Conference/Paper489/Reviewers", "ICLR.cc/2019/Conference/Paper489/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1542311828377}}}, {"id": "SJefbjX1e4", "original": null, "number": 14, "cdate": 1544661753617, "ddate": null, "tcdate": 1544661753617, "tmdate": 1544661753617, "tddate": null, "forum": "HJz6tiCqYm", "replyto": "rylvrBOmkV", "invitation": "ICLR.cc/2019/Conference/-/Paper489/Official_Comment", "content": {"title": "Unclear to me what these papers add over currently cited papers", "comment": "This work already cites many previous fragility studies, both from robustness to random corruptions/perturbations and with respect to worst-case corruptions, some works which include robustness to translations. Based on a quick reading of the proposed additional citations it is unclear to me what these works add on top of what is already cited. I have no strong opinion either way whether additional citations are added, I leave it up to the authors or other reviewers to decide what is best for the proper context of this work."}, "signatures": ["ICLR.cc/2019/Conference/Paper489/AnonReviewer3"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper489/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper489/AnonReviewer3", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Benchmarking Neural Network Robustness to Common Corruptions and Perturbations", "abstract": "In this paper we establish rigorous benchmarks for image classifier robustness. Our first benchmark, ImageNet-C, standardizes and expands the corruption robustness topic, while showing which classifiers are preferable in safety-critical applications. Then we propose a new dataset called ImageNet-P which enables researchers to benchmark a classifier's robustness to common perturbations. Unlike recent robustness research, this benchmark evaluates performance on common corruptions and perturbations not worst-case adversarial perturbations. We find that there are negligible changes in relative corruption robustness from AlexNet classifiers to ResNet classifiers. Afterward we discover ways to enhance corruption and perturbation robustness. We even find that a bypassed adversarial defense provides substantial common perturbation robustness. Together our benchmarks may aid future work toward networks that robustly generalize.", "keywords": ["robustness", "benchmark", "convnets", "perturbations"], "authorids": ["hendrycks@berkeley.edu", "tgd@oregonstate.edu"], "authors": ["Dan Hendrycks", "Thomas Dietterich"], "TL;DR": "We propose ImageNet-C to measure classifier corruption robustness and ImageNet-P to measure perturbation robustness", "pdf": "/pdf/94c9c0c321074c7acfbf169c69e81edd5ed7a7e9.pdf", "paperhash": "hendrycks|benchmarking_neural_network_robustness_to_common_corruptions_and_perturbations", "_bibtex": "@inproceedings{\nhendrycks2018benchmarking,\ntitle={Benchmarking Neural Network Robustness to Common Corruptions and Perturbations},\nauthor={Dan Hendrycks and Thomas Dietterich},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=HJz6tiCqYm},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper489/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621605552, "tddate": null, "super": null, "final": null, "reply": {"forum": "HJz6tiCqYm", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper489/Authors", "ICLR.cc/2019/Conference/Paper489/Reviewers", "ICLR.cc/2019/Conference/Paper489/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper489/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper489/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper489/Authors|ICLR.cc/2019/Conference/Paper489/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper489/Reviewers", "ICLR.cc/2019/Conference/Paper489/Authors", "ICLR.cc/2019/Conference/Paper489/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621605552}}}, {"id": "S1l6EPphkE", "original": null, "number": 12, "cdate": 1544505141050, "ddate": null, "tcdate": 1544505141050, "tmdate": 1544507782847, "tddate": null, "forum": "HJz6tiCqYm", "replyto": "SJladTB7y4", "invitation": "ICLR.cc/2019/Conference/-/Paper489/Official_Comment", "content": {"title": "Citations", "comment": "Please excuse the delayed response, as we were at NeurIPS.\n\nThe original poster sent an e-mail many months ago including numerous links to many papers, including several of their own. We conclude this because we received only one e-mail with citation suggestions. In consequence, we cited two of the papers authored by the person sending the e-mail, giving a sentence description for each citation. Several months later, the email sender posted the comment above. The only link which appeared in both the e-mail and in the comment above is Engstrom et al. (which is under review). The Fawzi et al. and Kanbak et al. papers are new to us. These may be added to the \"ConvNet Fragility Studies\" section. We think it is a reasonable suggestion to spend more time discussing other ConvNet perturbation fragility findings, although we do already cite works which mention translation instability (such as the parallel work of Azulay & Weiss, 2018)."}, "signatures": ["ICLR.cc/2019/Conference/Paper489/Authors"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper489/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper489/Authors", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Benchmarking Neural Network Robustness to Common Corruptions and Perturbations", "abstract": "In this paper we establish rigorous benchmarks for image classifier robustness. Our first benchmark, ImageNet-C, standardizes and expands the corruption robustness topic, while showing which classifiers are preferable in safety-critical applications. Then we propose a new dataset called ImageNet-P which enables researchers to benchmark a classifier's robustness to common perturbations. Unlike recent robustness research, this benchmark evaluates performance on common corruptions and perturbations not worst-case adversarial perturbations. We find that there are negligible changes in relative corruption robustness from AlexNet classifiers to ResNet classifiers. Afterward we discover ways to enhance corruption and perturbation robustness. We even find that a bypassed adversarial defense provides substantial common perturbation robustness. Together our benchmarks may aid future work toward networks that robustly generalize.", "keywords": ["robustness", "benchmark", "convnets", "perturbations"], "authorids": ["hendrycks@berkeley.edu", "tgd@oregonstate.edu"], "authors": ["Dan Hendrycks", "Thomas Dietterich"], "TL;DR": "We propose ImageNet-C to measure classifier corruption robustness and ImageNet-P to measure perturbation robustness", "pdf": "/pdf/94c9c0c321074c7acfbf169c69e81edd5ed7a7e9.pdf", "paperhash": "hendrycks|benchmarking_neural_network_robustness_to_common_corruptions_and_perturbations", "_bibtex": "@inproceedings{\nhendrycks2018benchmarking,\ntitle={Benchmarking Neural Network Robustness to Common Corruptions and Perturbations},\nauthor={Dan Hendrycks and Thomas Dietterich},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=HJz6tiCqYm},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper489/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621605552, "tddate": null, "super": null, "final": null, "reply": {"forum": "HJz6tiCqYm", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper489/Authors", "ICLR.cc/2019/Conference/Paper489/Reviewers", "ICLR.cc/2019/Conference/Paper489/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper489/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper489/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper489/Authors|ICLR.cc/2019/Conference/Paper489/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper489/Reviewers", "ICLR.cc/2019/Conference/Paper489/Authors", "ICLR.cc/2019/Conference/Paper489/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621605552}}}, {"id": "rylvrBOmkV", "original": null, "number": 5, "cdate": 1543894334824, "ddate": null, "tcdate": 1543894334824, "tmdate": 1543902566978, "tddate": null, "forum": "HJz6tiCqYm", "replyto": "SJladTB7y4", "invitation": "ICLR.cc/2019/Conference/-/Paper489/Public_Comment", "content": {"comment": "If I am interpreting the comment correctly, the author seems to be saying that they have cited the sender of the email's other papers, but does not see the need to cite any of the papers listed above. \n\nThis is a bit confusing as our comments are not an attempt to \"extort\" citations, but rather an effort to put this work in the right context. The fact that the authors cite other (admittedly less relevant) papers of the email sender does not render the suggested work less relevant.\n\nTo reiterate, I believe that all these works are very relevant to the subject of the above paper. If the authors do not want to cite these papers, that is okay - however one would expect them to at least explain in OpenReview why or give a brief comparison.", "title": "response"}, "signatures": ["(anonymous)"], "readers": ["everyone"], "nonreaders": [], "writers": ["(anonymous)", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Benchmarking Neural Network Robustness to Common Corruptions and Perturbations", "abstract": "In this paper we establish rigorous benchmarks for image classifier robustness. Our first benchmark, ImageNet-C, standardizes and expands the corruption robustness topic, while showing which classifiers are preferable in safety-critical applications. Then we propose a new dataset called ImageNet-P which enables researchers to benchmark a classifier's robustness to common perturbations. Unlike recent robustness research, this benchmark evaluates performance on common corruptions and perturbations not worst-case adversarial perturbations. We find that there are negligible changes in relative corruption robustness from AlexNet classifiers to ResNet classifiers. Afterward we discover ways to enhance corruption and perturbation robustness. We even find that a bypassed adversarial defense provides substantial common perturbation robustness. Together our benchmarks may aid future work toward networks that robustly generalize.", "keywords": ["robustness", "benchmark", "convnets", "perturbations"], "authorids": ["hendrycks@berkeley.edu", "tgd@oregonstate.edu"], "authors": ["Dan Hendrycks", "Thomas Dietterich"], "TL;DR": "We propose ImageNet-C to measure classifier corruption robustness and ImageNet-P to measure perturbation robustness", "pdf": "/pdf/94c9c0c321074c7acfbf169c69e81edd5ed7a7e9.pdf", "paperhash": "hendrycks|benchmarking_neural_network_robustness_to_common_corruptions_and_perturbations", "_bibtex": "@inproceedings{\nhendrycks2018benchmarking,\ntitle={Benchmarking Neural Network Robustness to Common Corruptions and Perturbations},\nauthor={Dan Hendrycks and Thomas Dietterich},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=HJz6tiCqYm},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper489/Public_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1542311828377, "tddate": null, "super": null, "final": null, "reply": {"signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed."}, "nonreaders": {"values": []}, "forum": "HJz6tiCqYm", "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper489/Authors", "ICLR.cc/2019/Conference/Paper489/Reviewers", "ICLR.cc/2019/Conference/Paper489/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "replyto": null, "content": {"comment": {"value-regex": "[\\S\\s]{1,5000}", "required": true, "order": 1, "description": "Your comment or reply (max 5000 characters)."}, "title": {"value-regex": ".{1,500}", "required": true, "order": 0, "description": "Brief summary of your comment."}}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["~"], "noninvitees": ["ICLR.cc/2019/Conference/Paper489/Authors", "ICLR.cc/2019/Conference/Paper489/Reviewers", "ICLR.cc/2019/Conference/Paper489/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1542311828377}}}, {"id": "SJladTB7y4", "original": null, "number": 10, "cdate": 1543884149097, "ddate": null, "tcdate": 1543884149097, "tmdate": 1543884149097, "tddate": null, "forum": "HJz6tiCqYm", "replyto": "rklBbUGA0m", "invitation": "ICLR.cc/2019/Conference/-/Paper489/Official_Comment", "content": {"title": "general approach to anonymous remarks about missing citations", "comment": "It sounds as if the authors agree with the suggestion, although I am not completely sure. However, I would like to emphasize that if they did not agree, then it would be up to the reviewers to determine whether adding these citations was important. Without investigating further, I have no position either way.\n\nBut, in general, our obligation as scientists is to cite other work when doing so benefits the reader. We should exercise our own taste in what we cite and avoid citing things that we do not think enhance the experience of the reader. \n\nAuthors: please don't hesitate to ask reviewers+AC to weigh-in if you are even in doubt about the importance of adding a particular citation."}, "signatures": ["ICLR.cc/2019/Conference/Paper489/Area_Chair1"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper489/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper489/Area_Chair1", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Benchmarking Neural Network Robustness to Common Corruptions and Perturbations", "abstract": "In this paper we establish rigorous benchmarks for image classifier robustness. Our first benchmark, ImageNet-C, standardizes and expands the corruption robustness topic, while showing which classifiers are preferable in safety-critical applications. Then we propose a new dataset called ImageNet-P which enables researchers to benchmark a classifier's robustness to common perturbations. Unlike recent robustness research, this benchmark evaluates performance on common corruptions and perturbations not worst-case adversarial perturbations. We find that there are negligible changes in relative corruption robustness from AlexNet classifiers to ResNet classifiers. Afterward we discover ways to enhance corruption and perturbation robustness. We even find that a bypassed adversarial defense provides substantial common perturbation robustness. Together our benchmarks may aid future work toward networks that robustly generalize.", "keywords": ["robustness", "benchmark", "convnets", "perturbations"], "authorids": ["hendrycks@berkeley.edu", "tgd@oregonstate.edu"], "authors": ["Dan Hendrycks", "Thomas Dietterich"], "TL;DR": "We propose ImageNet-C to measure classifier corruption robustness and ImageNet-P to measure perturbation robustness", "pdf": "/pdf/94c9c0c321074c7acfbf169c69e81edd5ed7a7e9.pdf", "paperhash": "hendrycks|benchmarking_neural_network_robustness_to_common_corruptions_and_perturbations", "_bibtex": "@inproceedings{\nhendrycks2018benchmarking,\ntitle={Benchmarking Neural Network Robustness to Common Corruptions and Perturbations},\nauthor={Dan Hendrycks and Thomas Dietterich},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=HJz6tiCqYm},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper489/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621605552, "tddate": null, "super": null, "final": null, "reply": {"forum": "HJz6tiCqYm", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper489/Authors", "ICLR.cc/2019/Conference/Paper489/Reviewers", "ICLR.cc/2019/Conference/Paper489/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper489/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper489/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper489/Authors|ICLR.cc/2019/Conference/Paper489/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper489/Reviewers", "ICLR.cc/2019/Conference/Paper489/Authors", "ICLR.cc/2019/Conference/Paper489/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621605552}}}, {"id": "rklBbUGA0m", "original": null, "number": 8, "cdate": 1543542268656, "ddate": null, "tcdate": 1543542268656, "tmdate": 1543542268656, "tddate": null, "forum": "HJz6tiCqYm", "replyto": "rJxnuikRA7", "invitation": "ICLR.cc/2019/Conference/-/Paper489/Official_Comment", "content": {"title": "Revised Discussion", "comment": "We would be happy to expand the related works further in future revisions of this draft. We have cited the sender of the e-mail from \"a long time ago\" twice in the current draft, but we can add more in a future revision."}, "signatures": ["ICLR.cc/2019/Conference/Paper489/Authors"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper489/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper489/Authors", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Benchmarking Neural Network Robustness to Common Corruptions and Perturbations", "abstract": "In this paper we establish rigorous benchmarks for image classifier robustness. Our first benchmark, ImageNet-C, standardizes and expands the corruption robustness topic, while showing which classifiers are preferable in safety-critical applications. Then we propose a new dataset called ImageNet-P which enables researchers to benchmark a classifier's robustness to common perturbations. Unlike recent robustness research, this benchmark evaluates performance on common corruptions and perturbations not worst-case adversarial perturbations. We find that there are negligible changes in relative corruption robustness from AlexNet classifiers to ResNet classifiers. Afterward we discover ways to enhance corruption and perturbation robustness. We even find that a bypassed adversarial defense provides substantial common perturbation robustness. Together our benchmarks may aid future work toward networks that robustly generalize.", "keywords": ["robustness", "benchmark", "convnets", "perturbations"], "authorids": ["hendrycks@berkeley.edu", "tgd@oregonstate.edu"], "authors": ["Dan Hendrycks", "Thomas Dietterich"], "TL;DR": "We propose ImageNet-C to measure classifier corruption robustness and ImageNet-P to measure perturbation robustness", "pdf": "/pdf/94c9c0c321074c7acfbf169c69e81edd5ed7a7e9.pdf", "paperhash": "hendrycks|benchmarking_neural_network_robustness_to_common_corruptions_and_perturbations", "_bibtex": "@inproceedings{\nhendrycks2018benchmarking,\ntitle={Benchmarking Neural Network Robustness to Common Corruptions and Perturbations},\nauthor={Dan Hendrycks and Thomas Dietterich},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=HJz6tiCqYm},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper489/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621605552, "tddate": null, "super": null, "final": null, "reply": {"forum": "HJz6tiCqYm", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper489/Authors", "ICLR.cc/2019/Conference/Paper489/Reviewers", "ICLR.cc/2019/Conference/Paper489/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper489/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper489/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper489/Authors|ICLR.cc/2019/Conference/Paper489/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper489/Reviewers", "ICLR.cc/2019/Conference/Paper489/Authors", "ICLR.cc/2019/Conference/Paper489/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621605552}}}, {"id": "rJxnuikRA7", "original": null, "number": 4, "cdate": 1543531380131, "ddate": null, "tcdate": 1543531380131, "tmdate": 1543531380131, "tddate": null, "forum": "HJz6tiCqYm", "replyto": "HJz6tiCqYm", "invitation": "ICLR.cc/2019/Conference/-/Paper489/Public_Comment", "content": {"comment": "I would like to point out that this submission is missing a discussion of some very relevant prior work. That work already evaluates the robustness of ML classifiers to naturally occurring transformations such as rotations and translations. Specifically:\n\n\u2022 Fawzi et al. (2015) [https://arxiv.org/abs/1507.06535] compute the minimum transformation (composed of rotations, translations, scaling, etc.) needed to cause a misclassification for a wide variety of models. They find that it is relatively small, and make several observations about the relative robustness of different classifiers.\n\n\u2022 Engstrom et al. (2017) [https://arxiv.org/abs/1712.02779] fix a range of rotations and translations and compute that worst-case accuracy of models over this space. They also find models to be relatively non-robust and propose methods for improving it.\n\n\u2022 Kanbak et al. (2018) [https://arxiv.org/abs/1711.09115] develop a first-order method to find such worst-case transformations fast. They show that this method can then be used to perform adversarial training and improve the model's robustness.\n\n```The authors were already notified about existence of some of this prior work a long time ago, but still seem to dismiss it.", "title": "Discussion of prior work missing"}, "signatures": ["(anonymous)"], "readers": ["everyone"], "nonreaders": [], "writers": ["(anonymous)", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Benchmarking Neural Network Robustness to Common Corruptions and Perturbations", "abstract": "In this paper we establish rigorous benchmarks for image classifier robustness. Our first benchmark, ImageNet-C, standardizes and expands the corruption robustness topic, while showing which classifiers are preferable in safety-critical applications. Then we propose a new dataset called ImageNet-P which enables researchers to benchmark a classifier's robustness to common perturbations. Unlike recent robustness research, this benchmark evaluates performance on common corruptions and perturbations not worst-case adversarial perturbations. We find that there are negligible changes in relative corruption robustness from AlexNet classifiers to ResNet classifiers. Afterward we discover ways to enhance corruption and perturbation robustness. We even find that a bypassed adversarial defense provides substantial common perturbation robustness. Together our benchmarks may aid future work toward networks that robustly generalize.", "keywords": ["robustness", "benchmark", "convnets", "perturbations"], "authorids": ["hendrycks@berkeley.edu", "tgd@oregonstate.edu"], "authors": ["Dan Hendrycks", "Thomas Dietterich"], "TL;DR": "We propose ImageNet-C to measure classifier corruption robustness and ImageNet-P to measure perturbation robustness", "pdf": "/pdf/94c9c0c321074c7acfbf169c69e81edd5ed7a7e9.pdf", "paperhash": "hendrycks|benchmarking_neural_network_robustness_to_common_corruptions_and_perturbations", "_bibtex": "@inproceedings{\nhendrycks2018benchmarking,\ntitle={Benchmarking Neural Network Robustness to Common Corruptions and Perturbations},\nauthor={Dan Hendrycks and Thomas Dietterich},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=HJz6tiCqYm},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper489/Public_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1542311828377, "tddate": null, "super": null, "final": null, "reply": {"signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed."}, "nonreaders": {"values": []}, "forum": "HJz6tiCqYm", "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper489/Authors", "ICLR.cc/2019/Conference/Paper489/Reviewers", "ICLR.cc/2019/Conference/Paper489/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "replyto": null, "content": {"comment": {"value-regex": "[\\S\\s]{1,5000}", "required": true, "order": 1, "description": "Your comment or reply (max 5000 characters)."}, "title": {"value-regex": ".{1,500}", "required": true, "order": 0, "description": "Brief summary of your comment."}}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["~"], "noninvitees": ["ICLR.cc/2019/Conference/Paper489/Authors", "ICLR.cc/2019/Conference/Paper489/Reviewers", "ICLR.cc/2019/Conference/Paper489/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1542311828377}}}, {"id": "SJgvBRYaR7", "original": null, "number": 3, "cdate": 1543507519447, "ddate": null, "tcdate": 1543507519447, "tmdate": 1543507519447, "tddate": null, "forum": "HJz6tiCqYm", "replyto": "B1xEWdwc0Q", "invitation": "ICLR.cc/2019/Conference/-/Paper489/Public_Comment", "content": {"comment": "Thanks for the quick response. Also, I really appreciated the additional section at the end of the paper where you talk about the robustness enhancement attempts, it is good to know not just what worked but also what did not work and why. ", "title": "Thanks"}, "signatures": ["~Dogancan_Temel1"], "readers": ["everyone"], "nonreaders": [], "writers": ["~Dogancan_Temel1", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Benchmarking Neural Network Robustness to Common Corruptions and Perturbations", "abstract": "In this paper we establish rigorous benchmarks for image classifier robustness. Our first benchmark, ImageNet-C, standardizes and expands the corruption robustness topic, while showing which classifiers are preferable in safety-critical applications. Then we propose a new dataset called ImageNet-P which enables researchers to benchmark a classifier's robustness to common perturbations. Unlike recent robustness research, this benchmark evaluates performance on common corruptions and perturbations not worst-case adversarial perturbations. We find that there are negligible changes in relative corruption robustness from AlexNet classifiers to ResNet classifiers. Afterward we discover ways to enhance corruption and perturbation robustness. We even find that a bypassed adversarial defense provides substantial common perturbation robustness. Together our benchmarks may aid future work toward networks that robustly generalize.", "keywords": ["robustness", "benchmark", "convnets", "perturbations"], "authorids": ["hendrycks@berkeley.edu", "tgd@oregonstate.edu"], "authors": ["Dan Hendrycks", "Thomas Dietterich"], "TL;DR": "We propose ImageNet-C to measure classifier corruption robustness and ImageNet-P to measure perturbation robustness", "pdf": "/pdf/94c9c0c321074c7acfbf169c69e81edd5ed7a7e9.pdf", "paperhash": "hendrycks|benchmarking_neural_network_robustness_to_common_corruptions_and_perturbations", "_bibtex": "@inproceedings{\nhendrycks2018benchmarking,\ntitle={Benchmarking Neural Network Robustness to Common Corruptions and Perturbations},\nauthor={Dan Hendrycks and Thomas Dietterich},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=HJz6tiCqYm},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper489/Public_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1542311828377, "tddate": null, "super": null, "final": null, "reply": {"signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed."}, "nonreaders": {"values": []}, "forum": "HJz6tiCqYm", "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper489/Authors", "ICLR.cc/2019/Conference/Paper489/Reviewers", "ICLR.cc/2019/Conference/Paper489/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "replyto": null, "content": {"comment": {"value-regex": "[\\S\\s]{1,5000}", "required": true, "order": 1, "description": "Your comment or reply (max 5000 characters)."}, "title": {"value-regex": ".{1,500}", "required": true, "order": 0, "description": "Brief summary of your comment."}}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["~"], "noninvitees": ["ICLR.cc/2019/Conference/Paper489/Authors", "ICLR.cc/2019/Conference/Paper489/Reviewers", "ICLR.cc/2019/Conference/Paper489/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1542311828377}}}, {"id": "BkxNgFD9RX", "original": null, "number": 5, "cdate": 1543301356445, "ddate": null, "tcdate": 1543301356445, "tmdate": 1543301729003, "tddate": null, "forum": "HJz6tiCqYm", "replyto": "S1xvCfDD6X", "invitation": "ICLR.cc/2019/Conference/-/Paper489/Official_Comment", "content": {"title": "Reviewer 3 Reply", "comment": "Thank you for your interest in this topic and your analysis of our paper.\n\n\u201cI think it might be more realistic to allow training on a subset of the corruptions.\u201d\nResearchers could train on various other corruptions, such as film grain, adversarial noise, HSV noise, uniform noise,\nhigh-pass filtering, median blur, spherical camera distortions, pincushion distortions, out-of-distribution object occlusions, stylized images ( https://openreview.net/forum?id=Bygh9j09KX ), lens scratches, image quilting, color quantization, etc. We have updated the text to make it clearer that researchers can train on more than just cropped and flipped images, but we still do not want researchers training on the test corruptions. In the paper we experimented with uniform noise data augmentation in the stability training experiment and found minor perturbation robustness gains, but not with Gaussian noise with a large standard deviation.\n\nThank you for pointing out that the brief Stone comment requires much more context. For that reason we have removed the citation. Essentially, if f is a model and f^\\hat is an approximation, and if input x is d-dimensional, then if we want | f(x) - f^\\hat (x) | < epsilon, then in some scenarios the number of samples necessary is ~ epsilon^{-d}. Other context is on slide 10 of https://github.com/joanbruna/MathsDL-spring18/blob/master/lectures/lecture1.pdf\n\n\u201cl infinity perturbations on small images\u201d\nThanks to your suggestion, we have changed this to \u201cperturbations on small images.\u201d We kept the word \u201csmall\u201d as the images often have side length 32 pixels. We removed \u201cl_infinity\u201d since that method has had some success for perturbations which are small in an l_2 sense."}, "signatures": ["ICLR.cc/2019/Conference/Paper489/Authors"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper489/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper489/Authors", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Benchmarking Neural Network Robustness to Common Corruptions and Perturbations", "abstract": "In this paper we establish rigorous benchmarks for image classifier robustness. Our first benchmark, ImageNet-C, standardizes and expands the corruption robustness topic, while showing which classifiers are preferable in safety-critical applications. Then we propose a new dataset called ImageNet-P which enables researchers to benchmark a classifier's robustness to common perturbations. Unlike recent robustness research, this benchmark evaluates performance on common corruptions and perturbations not worst-case adversarial perturbations. We find that there are negligible changes in relative corruption robustness from AlexNet classifiers to ResNet classifiers. Afterward we discover ways to enhance corruption and perturbation robustness. We even find that a bypassed adversarial defense provides substantial common perturbation robustness. Together our benchmarks may aid future work toward networks that robustly generalize.", "keywords": ["robustness", "benchmark", "convnets", "perturbations"], "authorids": ["hendrycks@berkeley.edu", "tgd@oregonstate.edu"], "authors": ["Dan Hendrycks", "Thomas Dietterich"], "TL;DR": "We propose ImageNet-C to measure classifier corruption robustness and ImageNet-P to measure perturbation robustness", "pdf": "/pdf/94c9c0c321074c7acfbf169c69e81edd5ed7a7e9.pdf", "paperhash": "hendrycks|benchmarking_neural_network_robustness_to_common_corruptions_and_perturbations", "_bibtex": "@inproceedings{\nhendrycks2018benchmarking,\ntitle={Benchmarking Neural Network Robustness to Common Corruptions and Perturbations},\nauthor={Dan Hendrycks and Thomas Dietterich},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=HJz6tiCqYm},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper489/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621605552, "tddate": null, "super": null, "final": null, "reply": {"forum": "HJz6tiCqYm", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper489/Authors", "ICLR.cc/2019/Conference/Paper489/Reviewers", "ICLR.cc/2019/Conference/Paper489/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper489/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper489/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper489/Authors|ICLR.cc/2019/Conference/Paper489/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper489/Reviewers", "ICLR.cc/2019/Conference/Paper489/Authors", "ICLR.cc/2019/Conference/Paper489/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621605552}}}, {"id": "B1xEWdwc0Q", "original": null, "number": 3, "cdate": 1543301116031, "ddate": null, "tcdate": 1543301116031, "tmdate": 1543301678567, "tddate": null, "forum": "HJz6tiCqYm", "replyto": "SklrTPkU07", "invitation": "ICLR.cc/2019/Conference/-/Paper489/Official_Comment", "content": {"title": "Cited Work", "comment": "Thank you for your interest in this topic and making us aware of your work. An earlier draft of our work appeared months before the time of the ICLR submission deadline, and we have added all citations to your traffic sign recognition work and your parallel works."}, "signatures": ["ICLR.cc/2019/Conference/Paper489/Authors"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper489/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper489/Authors", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Benchmarking Neural Network Robustness to Common Corruptions and Perturbations", "abstract": "In this paper we establish rigorous benchmarks for image classifier robustness. Our first benchmark, ImageNet-C, standardizes and expands the corruption robustness topic, while showing which classifiers are preferable in safety-critical applications. Then we propose a new dataset called ImageNet-P which enables researchers to benchmark a classifier's robustness to common perturbations. Unlike recent robustness research, this benchmark evaluates performance on common corruptions and perturbations not worst-case adversarial perturbations. We find that there are negligible changes in relative corruption robustness from AlexNet classifiers to ResNet classifiers. Afterward we discover ways to enhance corruption and perturbation robustness. We even find that a bypassed adversarial defense provides substantial common perturbation robustness. Together our benchmarks may aid future work toward networks that robustly generalize.", "keywords": ["robustness", "benchmark", "convnets", "perturbations"], "authorids": ["hendrycks@berkeley.edu", "tgd@oregonstate.edu"], "authors": ["Dan Hendrycks", "Thomas Dietterich"], "TL;DR": "We propose ImageNet-C to measure classifier corruption robustness and ImageNet-P to measure perturbation robustness", "pdf": "/pdf/94c9c0c321074c7acfbf169c69e81edd5ed7a7e9.pdf", "paperhash": "hendrycks|benchmarking_neural_network_robustness_to_common_corruptions_and_perturbations", "_bibtex": "@inproceedings{\nhendrycks2018benchmarking,\ntitle={Benchmarking Neural Network Robustness to Common Corruptions and Perturbations},\nauthor={Dan Hendrycks and Thomas Dietterich},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=HJz6tiCqYm},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper489/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621605552, "tddate": null, "super": null, "final": null, "reply": {"forum": "HJz6tiCqYm", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper489/Authors", "ICLR.cc/2019/Conference/Paper489/Reviewers", "ICLR.cc/2019/Conference/Paper489/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper489/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper489/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper489/Authors|ICLR.cc/2019/Conference/Paper489/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper489/Reviewers", "ICLR.cc/2019/Conference/Paper489/Authors", "ICLR.cc/2019/Conference/Paper489/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621605552}}}, {"id": "rye6cKP5Cm", "original": null, "number": 7, "cdate": 1543301524767, "ddate": null, "tcdate": 1543301524767, "tmdate": 1543301524767, "tddate": null, "forum": "HJz6tiCqYm", "replyto": "ryeoWVTch7", "invitation": "ICLR.cc/2019/Conference/-/Paper489/Official_Comment", "content": {"title": "Reviewer 1 Reply", "comment": "We thank you for your careful analysis of our paper.\n\n\u201cQuestion: Why do authors do not recommend training on the new datasets?\u201d\nWe do not suggest this as the datasets are corrupted or perturbed forms of clean ImageNet validation images, and that training on these specific corruptions would no longer provide a test of generalization ability to novel forms of corruptions. Researchers could train on various other corruptions, such as film grain, adversarial noise, HSV noise, uniform noise, high-pass filtering, median blur, spherical camera distortions, pincushion distortions, out-of-distribution object occlusions, stylized images ( https://openreview.net/forum?id=Bygh9j09KX ), lens scratches, image quilting, color quantization, etc.\n\n\u201cAre there other useful adversarial defenses?\u201d\nDifferent adversarial training schemes can degrade accuracy so much that they performed worse on these benchmarks. Many other adversarial defenses which do not use train on adversarial or benign noise have been shown not to provide robustness on noise corruptions (see the thorough work of https://openreview.net/pdf?id=S1xoy3CcYX Figure 3). In the coming month, we intend to explore more combinations of techniques to increase robustness, such as the combinations you suggest. In the appendix we explicate four attempts which did not lead to added robustness."}, "signatures": ["ICLR.cc/2019/Conference/Paper489/Authors"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper489/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper489/Authors", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Benchmarking Neural Network Robustness to Common Corruptions and Perturbations", "abstract": "In this paper we establish rigorous benchmarks for image classifier robustness. Our first benchmark, ImageNet-C, standardizes and expands the corruption robustness topic, while showing which classifiers are preferable in safety-critical applications. Then we propose a new dataset called ImageNet-P which enables researchers to benchmark a classifier's robustness to common perturbations. Unlike recent robustness research, this benchmark evaluates performance on common corruptions and perturbations not worst-case adversarial perturbations. We find that there are negligible changes in relative corruption robustness from AlexNet classifiers to ResNet classifiers. Afterward we discover ways to enhance corruption and perturbation robustness. We even find that a bypassed adversarial defense provides substantial common perturbation robustness. Together our benchmarks may aid future work toward networks that robustly generalize.", "keywords": ["robustness", "benchmark", "convnets", "perturbations"], "authorids": ["hendrycks@berkeley.edu", "tgd@oregonstate.edu"], "authors": ["Dan Hendrycks", "Thomas Dietterich"], "TL;DR": "We propose ImageNet-C to measure classifier corruption robustness and ImageNet-P to measure perturbation robustness", "pdf": "/pdf/94c9c0c321074c7acfbf169c69e81edd5ed7a7e9.pdf", "paperhash": "hendrycks|benchmarking_neural_network_robustness_to_common_corruptions_and_perturbations", "_bibtex": "@inproceedings{\nhendrycks2018benchmarking,\ntitle={Benchmarking Neural Network Robustness to Common Corruptions and Perturbations},\nauthor={Dan Hendrycks and Thomas Dietterich},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=HJz6tiCqYm},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper489/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621605552, "tddate": null, "super": null, "final": null, "reply": {"forum": "HJz6tiCqYm", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper489/Authors", "ICLR.cc/2019/Conference/Paper489/Reviewers", "ICLR.cc/2019/Conference/Paper489/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper489/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper489/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper489/Authors|ICLR.cc/2019/Conference/Paper489/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper489/Reviewers", "ICLR.cc/2019/Conference/Paper489/Authors", "ICLR.cc/2019/Conference/Paper489/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621605552}}}, {"id": "Skg0XKPqR7", "original": null, "number": 6, "cdate": 1543301414006, "ddate": null, "tcdate": 1543301414006, "tmdate": 1543301414006, "tddate": null, "forum": "HJz6tiCqYm", "replyto": "HkgLx3DzpQ", "invitation": "ICLR.cc/2019/Conference/-/Paper489/Official_Comment", "content": {"title": "Augmentation Clarification", "comment": "Noises such as those from gradients or uniform noise are perfectly acceptable forms of augmentation for this task. In the stability training experiment, we observed only minor gains in perturbation robustness when training with uniform noise, but perhaps training with more severe uniform noise could improve corruption robustness. In the revised paper, we make it clearer that training with other forms of data augmentation is acceptable. Please forgive this confusion."}, "signatures": ["ICLR.cc/2019/Conference/Paper489/Authors"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper489/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper489/Authors", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Benchmarking Neural Network Robustness to Common Corruptions and Perturbations", "abstract": "In this paper we establish rigorous benchmarks for image classifier robustness. Our first benchmark, ImageNet-C, standardizes and expands the corruption robustness topic, while showing which classifiers are preferable in safety-critical applications. Then we propose a new dataset called ImageNet-P which enables researchers to benchmark a classifier's robustness to common perturbations. Unlike recent robustness research, this benchmark evaluates performance on common corruptions and perturbations not worst-case adversarial perturbations. We find that there are negligible changes in relative corruption robustness from AlexNet classifiers to ResNet classifiers. Afterward we discover ways to enhance corruption and perturbation robustness. We even find that a bypassed adversarial defense provides substantial common perturbation robustness. Together our benchmarks may aid future work toward networks that robustly generalize.", "keywords": ["robustness", "benchmark", "convnets", "perturbations"], "authorids": ["hendrycks@berkeley.edu", "tgd@oregonstate.edu"], "authors": ["Dan Hendrycks", "Thomas Dietterich"], "TL;DR": "We propose ImageNet-C to measure classifier corruption robustness and ImageNet-P to measure perturbation robustness", "pdf": "/pdf/94c9c0c321074c7acfbf169c69e81edd5ed7a7e9.pdf", "paperhash": "hendrycks|benchmarking_neural_network_robustness_to_common_corruptions_and_perturbations", "_bibtex": "@inproceedings{\nhendrycks2018benchmarking,\ntitle={Benchmarking Neural Network Robustness to Common Corruptions and Perturbations},\nauthor={Dan Hendrycks and Thomas Dietterich},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=HJz6tiCqYm},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper489/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621605552, "tddate": null, "super": null, "final": null, "reply": {"forum": "HJz6tiCqYm", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper489/Authors", "ICLR.cc/2019/Conference/Paper489/Reviewers", "ICLR.cc/2019/Conference/Paper489/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper489/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper489/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper489/Authors|ICLR.cc/2019/Conference/Paper489/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper489/Reviewers", "ICLR.cc/2019/Conference/Paper489/Authors", "ICLR.cc/2019/Conference/Paper489/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621605552}}}, {"id": "r1xJYOvcR7", "original": null, "number": 4, "cdate": 1543301238843, "ddate": null, "tcdate": 1543301238843, "tmdate": 1543301238843, "tddate": null, "forum": "HJz6tiCqYm", "replyto": "rkl_eOltTX", "invitation": "ICLR.cc/2019/Conference/-/Paper489/Official_Comment", "content": {"title": "Reviewer 2 Reply", "comment": "We thank you for taking time to review our work."}, "signatures": ["ICLR.cc/2019/Conference/Paper489/Authors"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper489/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper489/Authors", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Benchmarking Neural Network Robustness to Common Corruptions and Perturbations", "abstract": "In this paper we establish rigorous benchmarks for image classifier robustness. Our first benchmark, ImageNet-C, standardizes and expands the corruption robustness topic, while showing which classifiers are preferable in safety-critical applications. Then we propose a new dataset called ImageNet-P which enables researchers to benchmark a classifier's robustness to common perturbations. Unlike recent robustness research, this benchmark evaluates performance on common corruptions and perturbations not worst-case adversarial perturbations. We find that there are negligible changes in relative corruption robustness from AlexNet classifiers to ResNet classifiers. Afterward we discover ways to enhance corruption and perturbation robustness. We even find that a bypassed adversarial defense provides substantial common perturbation robustness. Together our benchmarks may aid future work toward networks that robustly generalize.", "keywords": ["robustness", "benchmark", "convnets", "perturbations"], "authorids": ["hendrycks@berkeley.edu", "tgd@oregonstate.edu"], "authors": ["Dan Hendrycks", "Thomas Dietterich"], "TL;DR": "We propose ImageNet-C to measure classifier corruption robustness and ImageNet-P to measure perturbation robustness", "pdf": "/pdf/94c9c0c321074c7acfbf169c69e81edd5ed7a7e9.pdf", "paperhash": "hendrycks|benchmarking_neural_network_robustness_to_common_corruptions_and_perturbations", "_bibtex": "@inproceedings{\nhendrycks2018benchmarking,\ntitle={Benchmarking Neural Network Robustness to Common Corruptions and Perturbations},\nauthor={Dan Hendrycks and Thomas Dietterich},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=HJz6tiCqYm},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper489/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621605552, "tddate": null, "super": null, "final": null, "reply": {"forum": "HJz6tiCqYm", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper489/Authors", "ICLR.cc/2019/Conference/Paper489/Reviewers", "ICLR.cc/2019/Conference/Paper489/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper489/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper489/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper489/Authors|ICLR.cc/2019/Conference/Paper489/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper489/Reviewers", "ICLR.cc/2019/Conference/Paper489/Authors", "ICLR.cc/2019/Conference/Paper489/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621605552}}}, {"id": "B1xfnvvc0m", "original": null, "number": 2, "cdate": 1543301034379, "ddate": null, "tcdate": 1543301034379, "tmdate": 1543301034379, "tddate": null, "forum": "HJz6tiCqYm", "replyto": "HJz6tiCqYm", "invitation": "ICLR.cc/2019/Conference/-/Paper489/Official_Comment", "content": {"title": "Minor Revision Posted", "comment": "We should like to thank all of the reviewers and commenters for their constructive comments and kind reception. Independent from their comments, we have created CIFAR-10-C and CIFAR-10-P which could be adequate for rapid experimentation. Also in the revised version is a new appendix where we briefly analyze a different notion of robustness separate from our main contributions. We will respond to each reviewer\u2019s comments individually."}, "signatures": ["ICLR.cc/2019/Conference/Paper489/Authors"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper489/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper489/Authors", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Benchmarking Neural Network Robustness to Common Corruptions and Perturbations", "abstract": "In this paper we establish rigorous benchmarks for image classifier robustness. Our first benchmark, ImageNet-C, standardizes and expands the corruption robustness topic, while showing which classifiers are preferable in safety-critical applications. Then we propose a new dataset called ImageNet-P which enables researchers to benchmark a classifier's robustness to common perturbations. Unlike recent robustness research, this benchmark evaluates performance on common corruptions and perturbations not worst-case adversarial perturbations. We find that there are negligible changes in relative corruption robustness from AlexNet classifiers to ResNet classifiers. Afterward we discover ways to enhance corruption and perturbation robustness. We even find that a bypassed adversarial defense provides substantial common perturbation robustness. Together our benchmarks may aid future work toward networks that robustly generalize.", "keywords": ["robustness", "benchmark", "convnets", "perturbations"], "authorids": ["hendrycks@berkeley.edu", "tgd@oregonstate.edu"], "authors": ["Dan Hendrycks", "Thomas Dietterich"], "TL;DR": "We propose ImageNet-C to measure classifier corruption robustness and ImageNet-P to measure perturbation robustness", "pdf": "/pdf/94c9c0c321074c7acfbf169c69e81edd5ed7a7e9.pdf", "paperhash": "hendrycks|benchmarking_neural_network_robustness_to_common_corruptions_and_perturbations", "_bibtex": "@inproceedings{\nhendrycks2018benchmarking,\ntitle={Benchmarking Neural Network Robustness to Common Corruptions and Perturbations},\nauthor={Dan Hendrycks and Thomas Dietterich},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=HJz6tiCqYm},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper489/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621605552, "tddate": null, "super": null, "final": null, "reply": {"forum": "HJz6tiCqYm", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper489/Authors", "ICLR.cc/2019/Conference/Paper489/Reviewers", "ICLR.cc/2019/Conference/Paper489/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper489/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper489/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper489/Authors|ICLR.cc/2019/Conference/Paper489/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper489/Reviewers", "ICLR.cc/2019/Conference/Paper489/Authors", "ICLR.cc/2019/Conference/Paper489/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621605552}}}, {"id": "SklrTPkU07", "original": null, "number": 2, "cdate": 1543006141272, "ddate": null, "tcdate": 1543006141272, "tmdate": 1543006141272, "tddate": null, "forum": "HJz6tiCqYm", "replyto": "HJz6tiCqYm", "invitation": "ICLR.cc/2019/Conference/-/Paper489/Public_Comment", "content": {"comment": "I would like to thank the authors for focusing on such a critical issue in a comprehensive manner. Algorithmic solutions behind the core technologies have to be robust even under challenging conditions in order for such technologies to be effective and useful in our daily lives. With more and more studies similar to the submitted ICLR work, we can identify the weaknesses and strengths of existing algorithms to develop more reliable perception systems.  One of the main contributions of the submitted work is based on the common corruptions and perturbations not worst-case adversarial perturbations. With a similar mindset, we have introduced three datasets, two for traffic signs (CURE-TSR [2], CURE-TSD [3]) and one for generic objects (CURE-OR [1]) to investigate the robustness of recognition/detection systems under challenging conditions corresponding to adversaries that can naturally occur in real-world environments and systems. The controlled challenging conditions in the CURE-OR [1] dataset include underexposure, overexposure, blur, contrast, dirty lens, image noise, resizing, and loss of color information. And the controlled conditions in the CURE-TSR [2] and CURE-TSD [3] datasets include rain, snow, haze, shadow, underexposure, overexposure, blur, dirtiness, loss of color information, sensor and codec errors.  Based on the similarities between introduced datasets and conducted studies, including aforementioned studies in the literature analysis of the submitted paper can be helpful to reflect recent related work. Looking forward to authors\u2019 upcoming studies, thanks. \n\n[1] D. Temel*, J. Lee*, and G. AlRegib, \u201cCURE-OR: Challenging unreal and real environments for object recognition,\u201d IEEE International Conference on Machine Learning and Applications, Orlando, Florida, USA, December 2018, (*: equal contribution). https://arxiv.org/abs/1810.08293\n[2] D. Temel, G. Kwon*, M. Prabhushankar*, and G. AlRegib, \u201cCURE-TSR: Challenging unreal and real environments for traffic sign recognition,\u201d Advances in Neural Information Processing Systems (NIPS) Workshop on Machine Learning for Intelligent Transportation Systems, Long Beach, U.S., December 2017, (*: equal contribution).https://arxiv.org/abs/1712.02463\n[3] D. Temel and G. AlRegib, \u201cTraffic Signs in the Wild: Highlights from the IEEE Video and Image Processing Cup 2017 Student Competition [SP Competitions],\u201d in IEEE Signal Processing Magazine, vol. 35, no. 2, pp. 154-161, March 2018.https://arxiv.org/abs/1810.06169", "title": "Related Work"}, "signatures": ["~Dogancan_Temel1"], "readers": ["everyone"], "nonreaders": [], "writers": ["~Dogancan_Temel1", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Benchmarking Neural Network Robustness to Common Corruptions and Perturbations", "abstract": "In this paper we establish rigorous benchmarks for image classifier robustness. Our first benchmark, ImageNet-C, standardizes and expands the corruption robustness topic, while showing which classifiers are preferable in safety-critical applications. Then we propose a new dataset called ImageNet-P which enables researchers to benchmark a classifier's robustness to common perturbations. Unlike recent robustness research, this benchmark evaluates performance on common corruptions and perturbations not worst-case adversarial perturbations. We find that there are negligible changes in relative corruption robustness from AlexNet classifiers to ResNet classifiers. Afterward we discover ways to enhance corruption and perturbation robustness. We even find that a bypassed adversarial defense provides substantial common perturbation robustness. Together our benchmarks may aid future work toward networks that robustly generalize.", "keywords": ["robustness", "benchmark", "convnets", "perturbations"], "authorids": ["hendrycks@berkeley.edu", "tgd@oregonstate.edu"], "authors": ["Dan Hendrycks", "Thomas Dietterich"], "TL;DR": "We propose ImageNet-C to measure classifier corruption robustness and ImageNet-P to measure perturbation robustness", "pdf": "/pdf/94c9c0c321074c7acfbf169c69e81edd5ed7a7e9.pdf", "paperhash": "hendrycks|benchmarking_neural_network_robustness_to_common_corruptions_and_perturbations", "_bibtex": "@inproceedings{\nhendrycks2018benchmarking,\ntitle={Benchmarking Neural Network Robustness to Common Corruptions and Perturbations},\nauthor={Dan Hendrycks and Thomas Dietterich},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=HJz6tiCqYm},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper489/Public_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1542311828377, "tddate": null, "super": null, "final": null, "reply": {"signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed."}, "nonreaders": {"values": []}, "forum": "HJz6tiCqYm", "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper489/Authors", "ICLR.cc/2019/Conference/Paper489/Reviewers", "ICLR.cc/2019/Conference/Paper489/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "replyto": null, "content": {"comment": {"value-regex": "[\\S\\s]{1,5000}", "required": true, "order": 1, "description": "Your comment or reply (max 5000 characters)."}, "title": {"value-regex": ".{1,500}", "required": true, "order": 0, "description": "Brief summary of your comment."}}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["~"], "noninvitees": ["ICLR.cc/2019/Conference/Paper489/Authors", "ICLR.cc/2019/Conference/Paper489/Reviewers", "ICLR.cc/2019/Conference/Paper489/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1542311828377}}}, {"id": "rkl_eOltTX", "original": null, "number": 3, "cdate": 1542158320491, "ddate": null, "tcdate": 1542158320491, "tmdate": 1542158320491, "tddate": null, "forum": "HJz6tiCqYm", "replyto": "HJz6tiCqYm", "invitation": "ICLR.cc/2019/Conference/-/Paper489/Official_Review", "content": {"title": "It is an importance work for deep learning research.", "review": "This paper introduces two benchmarks for image classifier robustness, ImageNet-C and Image-P. The benchmarks cover two important cases in classifier robustness  which are ignored by most current researchers. The authors' evaluations also show that current deep learning methods have wide room for improvement. To our best knowledge, this is the first work that provides systematically a common benchmarks for the deep learning community.  The reviewer believes that these two benchmarks can play an important role in the research of image classifier robustness.", "rating": "7: Good paper, accept", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "signatures": ["ICLR.cc/2019/Conference/Paper489/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Benchmarking Neural Network Robustness to Common Corruptions and Perturbations", "abstract": "In this paper we establish rigorous benchmarks for image classifier robustness. Our first benchmark, ImageNet-C, standardizes and expands the corruption robustness topic, while showing which classifiers are preferable in safety-critical applications. Then we propose a new dataset called ImageNet-P which enables researchers to benchmark a classifier's robustness to common perturbations. Unlike recent robustness research, this benchmark evaluates performance on common corruptions and perturbations not worst-case adversarial perturbations. We find that there are negligible changes in relative corruption robustness from AlexNet classifiers to ResNet classifiers. Afterward we discover ways to enhance corruption and perturbation robustness. We even find that a bypassed adversarial defense provides substantial common perturbation robustness. Together our benchmarks may aid future work toward networks that robustly generalize.", "keywords": ["robustness", "benchmark", "convnets", "perturbations"], "authorids": ["hendrycks@berkeley.edu", "tgd@oregonstate.edu"], "authors": ["Dan Hendrycks", "Thomas Dietterich"], "TL;DR": "We propose ImageNet-C to measure classifier corruption robustness and ImageNet-P to measure perturbation robustness", "pdf": "/pdf/94c9c0c321074c7acfbf169c69e81edd5ed7a7e9.pdf", "paperhash": "hendrycks|benchmarking_neural_network_robustness_to_common_corruptions_and_perturbations", "_bibtex": "@inproceedings{\nhendrycks2018benchmarking,\ntitle={Benchmarking Neural Network Robustness to Common Corruptions and Perturbations},\nauthor={Dan Hendrycks and Thomas Dietterich},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=HJz6tiCqYm},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper489/Official_Review", "cdate": 1542234449700, "expdate": 1552335264000, "duedate": 1541196000000, "reply": {"forum": "HJz6tiCqYm", "replyto": "HJz6tiCqYm", "readers": {"description": "The users who will be allowed to read the reply content.", "values": ["everyone"]}, "nonreaders": {"values": []}, "signatures": {"description": "How your identity will be displayed with the above content.", "values-regex": "ICLR.cc/2019/Conference/Paper489/AnonReviewer[0-9]+"}, "writers": {"description": "Users that may modify this record.", "values": ["ICLR.cc/2019/Conference"]}, "content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "required": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}}, "multiReply": false, "tcdate": 1552335735852, "tmdate": 1552335735852, "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "invitees": ["ICLR.cc/2019/Conference/Paper489/Reviewers"], "noninvitees": [], "signatures": ["ICLR.cc/2019/Conference"]}}}, {"id": "S1xvCfDD6X", "original": null, "number": 2, "cdate": 1542054606709, "ddate": null, "tcdate": 1542054606709, "tmdate": 1542131466166, "tddate": null, "forum": "HJz6tiCqYm", "replyto": "HJz6tiCqYm", "invitation": "ICLR.cc/2019/Conference/-/Paper489/Official_Review", "content": {"title": "An important benchmark for measuring the robustness of computer vision models", "review": "This paper introduces new benchmarks for measuring the robustness of computer vision models to various image corruptions. In contrast with the popular notion of \u201cadversarial robustness\u201d, instead of measuring robustness to small, worst-case perturbations this benchmark measures robustness in the average case, where the corruptions are larger and more likely to be encountered at deployment time. The first benchmark \u201cImagenet-C\u201d consists of 15 commonly occurring image corruptions, ranging from additive noise, simulated weather corruptions, to digital corruptions arising from compression artifacts. Each corruption type has several levels of severity and overall corruption score is measured by improved robustness over a baseline model (in this case AlexNet). The second benchmark \u201cImagenet-P\u201d measures the consistency of model predictions in a sequence of slightly perturbed image frames. These image sequences are produced by gradually varying an image corruption (e.g. gradually blurring an image). The stability of model predictions is measured by changes in the order of the top-5 predictions of the model. More stable models should not change their prediction to minute distortions in the image. Extensive experiments are run to benchmark recent architecture developments on this new benchmark. It\u2019s found that more recent architectures are more robust on this benchmark, although this gained robustness is largely due to the architectures being more accurate overall. Some techniques for increasing model robustness are explored, including a recent adversarial defense \u201cAdversarial Logit Pairing\u201d, this method was shown to greatly increase robustness on the proposed benchmark. The authors recommend future work benchmark performance on this suite of common corruptions without training on this corruptions directly, and cite prior work which has found that training on one corruption type typically does not generalize to other corruption types. Thus the benchmark is a method for measuring model performance to \u201cunknown\u201d corruptions which should be expected during test time.\n\nIn my opinion this is an important contribution which could change how we measure the robustness of our models. Adversarial robustness is a closely related and popular metric but it is extremely difficult to measure and reported values of adversarial robustness are continuously being falsified [1,2,3]. In contrast, this benchmark provides a standardized and computationally tractable benchmark for measuring the robustness of neural networks to image corruptions. The proposed image corruptions are also more realistic, and better model the types of corruptions computer vision models are likely to encounter during deployment. I hope that future papers will consider this benchmark when measuring and improving neural network robustness. It remains to be seen how difficult the proposed benchmark will be, but the authors perform experiments on a number of baselines and show that it is non-trivial and interesting. At a minimum, solving this benchmark is a necessary step towards robust vision classifiers. \n\nAlthough I agree with the author\u2019s recommendation that future works not train on all of the Imagenet-C corruptions, I think it might be more realistic to allow training on a subset of the corruptions. The reason why I mention this is it\u2019s unclear whether or not adversarial training should be considered as performing data augmentation on some of these corruptions, it certainly is doing some form of data augmentation. Concurrent work [4] has run experiments on a resnet-50 for Imagenet and found that Gaussian data augmentation with large enough sigma (e.g. sigma = .4 when image pixels are on a [0,1] scale) does improve robustness to pepper noise and Gaussian blurring, with improvements comparable to that of adversarial training. Have the authors tried Gaussian data augmentation to see if it improves robustness to the other corruptions? I think this is an important baseline to compare with adversarial training or ALP.\n\nFew specific comments/typos:\n\nPage 2 \u201cl infinity perturbations on small images\u201d\n\nThe (Stone, 1982) reference is interesting, but it\u2019s not clear to me that their main result has implications for adversarial robustness. Can the authors clarify how to map the L_p norm in function space of ||T_n - T(theta) || to the traditional notion of adversarial robustness?\n\n1. https://arxiv.org/pdf/1705.07263.pdf\n2. https://arxiv.org/pdf/1802.00420.pdf\n3. https://arxiv.org/pdf/1607.04311.pdf\n4. https://openreview.net/forum?id=S1xoy3CcYX&noteId=BklKxJBF57", "rating": "9: Top 15% of accepted papers, strong accept", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}, "signatures": ["ICLR.cc/2019/Conference/Paper489/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": true, "forumContent": {"title": "Benchmarking Neural Network Robustness to Common Corruptions and Perturbations", "abstract": "In this paper we establish rigorous benchmarks for image classifier robustness. Our first benchmark, ImageNet-C, standardizes and expands the corruption robustness topic, while showing which classifiers are preferable in safety-critical applications. Then we propose a new dataset called ImageNet-P which enables researchers to benchmark a classifier's robustness to common perturbations. Unlike recent robustness research, this benchmark evaluates performance on common corruptions and perturbations not worst-case adversarial perturbations. We find that there are negligible changes in relative corruption robustness from AlexNet classifiers to ResNet classifiers. Afterward we discover ways to enhance corruption and perturbation robustness. We even find that a bypassed adversarial defense provides substantial common perturbation robustness. Together our benchmarks may aid future work toward networks that robustly generalize.", "keywords": ["robustness", "benchmark", "convnets", "perturbations"], "authorids": ["hendrycks@berkeley.edu", "tgd@oregonstate.edu"], "authors": ["Dan Hendrycks", "Thomas Dietterich"], "TL;DR": "We propose ImageNet-C to measure classifier corruption robustness and ImageNet-P to measure perturbation robustness", "pdf": "/pdf/94c9c0c321074c7acfbf169c69e81edd5ed7a7e9.pdf", "paperhash": "hendrycks|benchmarking_neural_network_robustness_to_common_corruptions_and_perturbations", "_bibtex": "@inproceedings{\nhendrycks2018benchmarking,\ntitle={Benchmarking Neural Network Robustness to Common Corruptions and Perturbations},\nauthor={Dan Hendrycks and Thomas Dietterich},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=HJz6tiCqYm},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper489/Official_Review", "cdate": 1542234449700, "expdate": 1552335264000, "duedate": 1541196000000, "reply": {"forum": "HJz6tiCqYm", "replyto": "HJz6tiCqYm", "readers": {"description": "The users who will be allowed to read the reply content.", "values": ["everyone"]}, "nonreaders": {"values": []}, "signatures": {"description": "How your identity will be displayed with the above content.", "values-regex": "ICLR.cc/2019/Conference/Paper489/AnonReviewer[0-9]+"}, "writers": {"description": "Users that may modify this record.", "values": ["ICLR.cc/2019/Conference"]}, "content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "required": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}}, "multiReply": false, "tcdate": 1552335735852, "tmdate": 1552335735852, "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "invitees": ["ICLR.cc/2019/Conference/Paper489/Reviewers"], "noninvitees": [], "signatures": ["ICLR.cc/2019/Conference"]}}}, {"id": "HkgLx3DzpQ", "original": null, "number": 1, "cdate": 1541729261518, "ddate": null, "tcdate": 1541729261518, "tmdate": 1541729261518, "tddate": null, "forum": "HJz6tiCqYm", "replyto": "HJz6tiCqYm", "invitation": "ICLR.cc/2019/Conference/-/Paper489/Public_Comment", "content": {"comment": "You've shown that ALP performs so well on this benchmark, but ALP performs some form of data augmentation by training on worst-case perturbations. Therefore, its unclear whether or not this satisfies the recommendation that future work not train on the Imagenet-C corruptions. Have you compared the ALP model with simply performing Gaussian data augmentation? Some recent adversarial defense works have reported that Gaussian data augmentation improves small perturbation robustness.", "title": "Interesting work!"}, "signatures": ["(anonymous)"], "readers": ["everyone"], "nonreaders": [], "writers": ["(anonymous)", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Benchmarking Neural Network Robustness to Common Corruptions and Perturbations", "abstract": "In this paper we establish rigorous benchmarks for image classifier robustness. Our first benchmark, ImageNet-C, standardizes and expands the corruption robustness topic, while showing which classifiers are preferable in safety-critical applications. Then we propose a new dataset called ImageNet-P which enables researchers to benchmark a classifier's robustness to common perturbations. Unlike recent robustness research, this benchmark evaluates performance on common corruptions and perturbations not worst-case adversarial perturbations. We find that there are negligible changes in relative corruption robustness from AlexNet classifiers to ResNet classifiers. Afterward we discover ways to enhance corruption and perturbation robustness. We even find that a bypassed adversarial defense provides substantial common perturbation robustness. Together our benchmarks may aid future work toward networks that robustly generalize.", "keywords": ["robustness", "benchmark", "convnets", "perturbations"], "authorids": ["hendrycks@berkeley.edu", "tgd@oregonstate.edu"], "authors": ["Dan Hendrycks", "Thomas Dietterich"], "TL;DR": "We propose ImageNet-C to measure classifier corruption robustness and ImageNet-P to measure perturbation robustness", "pdf": "/pdf/94c9c0c321074c7acfbf169c69e81edd5ed7a7e9.pdf", "paperhash": "hendrycks|benchmarking_neural_network_robustness_to_common_corruptions_and_perturbations", "_bibtex": "@inproceedings{\nhendrycks2018benchmarking,\ntitle={Benchmarking Neural Network Robustness to Common Corruptions and Perturbations},\nauthor={Dan Hendrycks and Thomas Dietterich},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=HJz6tiCqYm},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper489/Public_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1542311828377, "tddate": null, "super": null, "final": null, "reply": {"signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed."}, "nonreaders": {"values": []}, "forum": "HJz6tiCqYm", "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper489/Authors", "ICLR.cc/2019/Conference/Paper489/Reviewers", "ICLR.cc/2019/Conference/Paper489/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "replyto": null, "content": {"comment": {"value-regex": "[\\S\\s]{1,5000}", "required": true, "order": 1, "description": "Your comment or reply (max 5000 characters)."}, "title": {"value-regex": ".{1,500}", "required": true, "order": 0, "description": "Brief summary of your comment."}}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["~"], "noninvitees": ["ICLR.cc/2019/Conference/Paper489/Authors", "ICLR.cc/2019/Conference/Paper489/Reviewers", "ICLR.cc/2019/Conference/Paper489/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1542311828377}}}, {"id": "ryeoWVTch7", "original": null, "number": 1, "cdate": 1541227522752, "ddate": null, "tcdate": 1541227522752, "tmdate": 1541533952226, "tddate": null, "forum": "HJz6tiCqYm", "replyto": "HJz6tiCqYm", "invitation": "ICLR.cc/2019/Conference/-/Paper489/Official_Review", "content": {"title": "Exciting paper!", "review": "Summary: This paper observes that a major flaw in common image-classification networks is their lack of robustness to common corruptions and perturbations. The authors develop and publish two variants of the ImageNet validation dataset, one for corruptions and one for perturbations. They then propose metrics for evaluating several common networks on their new datasets and find that robustness has not improved much from AlexNet to ResNet. They do, however, find several ways to improve performance including using larger networks, using ResNeXt, and using adversarial logit pairing.\n\nQuality: The datasets and metrics are very thoroughly treated, and are the key contribution of the paper. Some questions: What happens if you combine ResNeXt with ALP or histogram equalization? Or any other combinations? Is ALP equally beneficial across all networks? Are there other useful adversarial defenses?\n\nClarity: The novel validation sets and reasoning for them are well-explained, as are the evaluation metrics. Some explanation of adversarial logit pairing would be welcome, and some intuition (or speculation) as to why it is so effective at improving robustness.\n\nOriginality: Although adversarial robustness is a relatively popular subject, I am not aware of any other work presenting datasets of corrupted/perturbed images.\n\nSignificance: The paper highlights a significant weakness in many image-classification networks, provides a benchmark, and identifies ways to improve robustness. It would be improved by more thorough testing, but that is less important than the dataset, metrics and basic benchmarking provided.\n\nQuestion: Why do authors do not recommend training on the new datasets? ", "rating": "9: Top 15% of accepted papers, strong accept", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["ICLR.cc/2019/Conference/Paper489/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Benchmarking Neural Network Robustness to Common Corruptions and Perturbations", "abstract": "In this paper we establish rigorous benchmarks for image classifier robustness. Our first benchmark, ImageNet-C, standardizes and expands the corruption robustness topic, while showing which classifiers are preferable in safety-critical applications. Then we propose a new dataset called ImageNet-P which enables researchers to benchmark a classifier's robustness to common perturbations. Unlike recent robustness research, this benchmark evaluates performance on common corruptions and perturbations not worst-case adversarial perturbations. We find that there are negligible changes in relative corruption robustness from AlexNet classifiers to ResNet classifiers. Afterward we discover ways to enhance corruption and perturbation robustness. We even find that a bypassed adversarial defense provides substantial common perturbation robustness. Together our benchmarks may aid future work toward networks that robustly generalize.", "keywords": ["robustness", "benchmark", "convnets", "perturbations"], "authorids": ["hendrycks@berkeley.edu", "tgd@oregonstate.edu"], "authors": ["Dan Hendrycks", "Thomas Dietterich"], "TL;DR": "We propose ImageNet-C to measure classifier corruption robustness and ImageNet-P to measure perturbation robustness", "pdf": "/pdf/94c9c0c321074c7acfbf169c69e81edd5ed7a7e9.pdf", "paperhash": "hendrycks|benchmarking_neural_network_robustness_to_common_corruptions_and_perturbations", "_bibtex": "@inproceedings{\nhendrycks2018benchmarking,\ntitle={Benchmarking Neural Network Robustness to Common Corruptions and Perturbations},\nauthor={Dan Hendrycks and Thomas Dietterich},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=HJz6tiCqYm},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper489/Official_Review", "cdate": 1542234449700, "expdate": 1552335264000, "duedate": 1541196000000, "reply": {"forum": "HJz6tiCqYm", "replyto": "HJz6tiCqYm", "readers": {"description": "The users who will be allowed to read the reply content.", "values": ["everyone"]}, "nonreaders": {"values": []}, "signatures": {"description": "How your identity will be displayed with the above content.", "values-regex": "ICLR.cc/2019/Conference/Paper489/AnonReviewer[0-9]+"}, "writers": {"description": "Users that may modify this record.", "values": ["ICLR.cc/2019/Conference"]}, "content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "required": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}}, "multiReply": false, "tcdate": 1552335735852, "tmdate": 1552335735852, "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "invitees": ["ICLR.cc/2019/Conference/Paper489/Reviewers"], "noninvitees": [], "signatures": ["ICLR.cc/2019/Conference"]}}}], "count": 23}