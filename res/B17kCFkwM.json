{"notes": [{"tddate": null, "replyto": null, "ddate": null, "tmdate": 1528124433800, "tcdate": 1518472667384, "number": 337, "cdate": 1518472667384, "id": "B17kCFkwM", "invitation": "ICLR.cc/2018/Workshop/-/Submission", "forum": "B17kCFkwM", "signatures": ["~Tegan_Maharaj1"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Workshop"], "content": {"title": "Reserve Output Units for Deep Open-Set Learning", "abstract": "Open-set learning poses a classification problem where the set of class labels expands over time; a realistic but not widely-studied setting.\nWe propose a deep learning technique for open-set learning based on Reserve Output Units (ROUs), which are designed to help a network anticipate the introduction of new categories during training. \nROUs are additional output units whose representations are trained along with units for already-seen classes, which can be assigned to new classes once a labeled instance of a novel class is observed. We experiment with different initialization methods, compare this method with simply adding an new output vector for the novel class, and find that ROUs achieve better and more consistent performance than the simple add-new baseline.\nWe further experiment with a loss which encourages the output space to match pretrained word embeddings, with the goal of encouraging good semantics of this space. \nIn experiments on MNIST and CIFAR, this technique hurt or does not affect performance, but we're optimistic this technique could be helpful for larger output spaces. ", "paperhash": "maharaj|reserve_output_units_for_deep_openset_learning", "keywords": ["Open set learning", "deep learning", "online learning"], "_bibtex": "@misc{\n  maharaj2018reserve,\n  title={Reserve Output Units for Deep Open-Set Learning},\n  author={Tegan Maharaj and David Krueger},\n  year={2018},\n  url={https://openreview.net/forum?id=B17kCFkwM}\n}", "authorids": ["tegan.jrm@gmail.com", "davidscottkrueger@gmail.com"], "authors": ["Tegan Maharaj", "David Krueger"], "TL;DR": "Reserve output units allow deep networks to anticipate the introduction of novel classes", "pdf": "/pdf/6a29198913ea6f3f41673edc919f2ec57722d609.pdf"}, "nonreaders": [], "details": {"replyCount": 3, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1518472800000, "tmdate": 1518474081690, "id": "ICLR.cc/2018/Workshop/-/Submission", "writers": ["ICLR.cc/2018/Workshop"], "signatures": ["ICLR.cc/2018/Workshop"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": null, "replyto": null, "writers": {"values": ["ICLR.cc/2018/Workshop"]}, "signatures": {"values-regex": "~.*|ICLR.cc/2018/Workshop", "description": "Your authorized identity to be associated with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"pdf": {"required": true, "order": 9, "value-regex": "upload", "description": "Upload a PDF file that ends with .pdf"}, "title": {"required": true, "order": 1, "description": "Title of paper.", "value-regex": ".{1,250}"}, "abstract": {"required": true, "order": 8, "description": "Abstract of paper.", "value-regex": "[\\S\\s]{1,5000}"}, "authors": {"required": true, "order": 2, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of author names. Please provide real names; identities will be anonymized."}, "keywords": {"order": 6, "values-regex": "(^$)|[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of keywords."}, "TL;DR": {"required": false, "order": 7, "description": "\"Too Long; Didn't Read\": a short sentence describing your paper", "value-regex": "[^\\n]{0,500}"}, "authorids": {"required": true, "order": 3, "values-regex": "([a-z0-9_\\-\\.]{2,}@[a-z0-9_\\-\\.]{2,}\\.[a-z]{2,},){0,}([a-z0-9_\\-\\.]{2,}@[a-z0-9_\\-\\.]{2,}\\.[a-z]{2,})", "description": "Comma separated list of author email addresses, lowercased, in the same order as above. For authors with existing OpenReview accounts, please make sure that the provided email address(es) match those listed in the author's profile. Please provide real emails; identities will be anonymized."}}}, "nonreaders": [], "noninvitees": [], "expdate": 1526248800000, "cdate": 1518474081690}}}, {"tddate": null, "ddate": null, "original": null, "tmdate": 1521582863426, "tcdate": 1520557534203, "number": 1, "cdate": 1520557534203, "id": "SJ8yCUkYz", "invitation": "ICLR.cc/2018/Workshop/-/Paper337/Official_Review", "forum": "B17kCFkwM", "replyto": "B17kCFkwM", "signatures": ["ICLR.cc/2018/Workshop/Paper337/AnonReviewer3"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Workshop/Paper337/AnonReviewer3"], "content": {"title": "Missing quite some significant comparison with previous works.", "rating": "4: Ok but not good enough - rejection", "review": "this paper tried to solve open-set learning by using the deep networks. It is claimed to be \" the first to address the problem of generalizing to novel classes with deep networks, and the first to view open-set learning as an online learning problem.\"\n\nHowever, this is definitely not true. The whole idea has been well studied more years before. Please check:\n[1] T. Mensink, J. Verbeek, F. Perronnin, and G. Csurka. Distance-based image classification: Generalizing to new classes at near zero cost. TPAMI, 2013\n[2] iCaRL: Incremental Classifier and Representation Learning, CVPR 2018\n\nAlso it would be great to compare with W-SVM and OPenmax.\n\nSince the workshop is more focused on brilliant ideas, I donot think the idea of this paper if the first one proposed.\n\n", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Reserve Output Units for Deep Open-Set Learning", "abstract": "Open-set learning poses a classification problem where the set of class labels expands over time; a realistic but not widely-studied setting.\nWe propose a deep learning technique for open-set learning based on Reserve Output Units (ROUs), which are designed to help a network anticipate the introduction of new categories during training. \nROUs are additional output units whose representations are trained along with units for already-seen classes, which can be assigned to new classes once a labeled instance of a novel class is observed. We experiment with different initialization methods, compare this method with simply adding an new output vector for the novel class, and find that ROUs achieve better and more consistent performance than the simple add-new baseline.\nWe further experiment with a loss which encourages the output space to match pretrained word embeddings, with the goal of encouraging good semantics of this space. \nIn experiments on MNIST and CIFAR, this technique hurt or does not affect performance, but we're optimistic this technique could be helpful for larger output spaces. ", "paperhash": "maharaj|reserve_output_units_for_deep_openset_learning", "keywords": ["Open set learning", "deep learning", "online learning"], "_bibtex": "@misc{\n  maharaj2018reserve,\n  title={Reserve Output Units for Deep Open-Set Learning},\n  author={Tegan Maharaj and David Krueger},\n  year={2018},\n  url={https://openreview.net/forum?id=B17kCFkwM}\n}", "authorids": ["tegan.jrm@gmail.com", "davidscottkrueger@gmail.com"], "authors": ["Tegan Maharaj", "David Krueger"], "TL;DR": "Reserve output units allow deep networks to anticipate the introduction of novel classes", "pdf": "/pdf/6a29198913ea6f3f41673edc919f2ec57722d609.pdf"}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1520657999000, "tmdate": 1521582863244, "id": "ICLR.cc/2018/Workshop/-/Paper337/Official_Review", "writers": ["ICLR.cc/2018/Workshop"], "signatures": ["ICLR.cc/2018/Workshop"], "readers": ["everyone"], "invitees": ["ICLR.cc/2018/Workshop/Paper337/Reviewers"], "noninvitees": ["ICLR.cc/2018/Workshop/Paper337/AnonReviewer3", "ICLR.cc/2018/Workshop/Paper337/AnonReviewer2"], "reply": {"forum": "B17kCFkwM", "replyto": "B17kCFkwM", "writers": {"values-regex": "ICLR.cc/2018/Workshop/Paper337/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2018/Workshop/Paper337/AnonReviewer[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"required": true, "order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"required": true, "order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "value-regex": "[\\S\\s]{1,200000}"}, "rating": {"required": true, "order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"required": true, "order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1528433999000, "cdate": 1521582863244}}}, {"tddate": null, "ddate": null, "original": null, "tmdate": 1521582607602, "tcdate": 1520901400282, "number": 2, "cdate": 1520901400282, "id": "rJlQTc4YM", "invitation": "ICLR.cc/2018/Workshop/-/Paper337/Official_Review", "forum": "B17kCFkwM", "replyto": "B17kCFkwM", "signatures": ["ICLR.cc/2018/Workshop/Paper337/AnonReviewer2"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Workshop/Paper337/AnonReviewer2"], "content": {"title": "The paper is very unclear", "rating": "5: Marginally below acceptance threshold", "review": "I'm unable to understand how the ROUs are participating to accounts for new words at test time. Figure 1 presents terms such as 'encourage entropy' but they don't feature in the text. \n\nIn this paragraph\n\"When a new category is seen, we assign it to the ROU which assigns it the highest likelihood. We\nthen replace the output vector of that ROU with either a random vector, or a scaled copy of the final\nhidden layer\u2019s activations on that new instance. We experiment with different methods of initializing\nand training ROUs, and find that using ROUs gives a consistent improvement over simply adding a\nnew output vector.\", what do the authors mean by output vector ? What is the motivation behind using random vectors or scaled copies of the final hidden layer's activations. \n\nI'm also unclear on how the model is trained. Is it that during training, they introduce new words every couple of steps ? The results show that their approaches outperform the baseline, but it's not clear on what dataset and what task. Is this language modeling ? If yes, what were your perplexities.\n\nThere might be some very interesting ideas in the paper, but it needs an earnest rewrite to help us understand what is going on. ", "confidence": "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Reserve Output Units for Deep Open-Set Learning", "abstract": "Open-set learning poses a classification problem where the set of class labels expands over time; a realistic but not widely-studied setting.\nWe propose a deep learning technique for open-set learning based on Reserve Output Units (ROUs), which are designed to help a network anticipate the introduction of new categories during training. \nROUs are additional output units whose representations are trained along with units for already-seen classes, which can be assigned to new classes once a labeled instance of a novel class is observed. We experiment with different initialization methods, compare this method with simply adding an new output vector for the novel class, and find that ROUs achieve better and more consistent performance than the simple add-new baseline.\nWe further experiment with a loss which encourages the output space to match pretrained word embeddings, with the goal of encouraging good semantics of this space. \nIn experiments on MNIST and CIFAR, this technique hurt or does not affect performance, but we're optimistic this technique could be helpful for larger output spaces. ", "paperhash": "maharaj|reserve_output_units_for_deep_openset_learning", "keywords": ["Open set learning", "deep learning", "online learning"], "_bibtex": "@misc{\n  maharaj2018reserve,\n  title={Reserve Output Units for Deep Open-Set Learning},\n  author={Tegan Maharaj and David Krueger},\n  year={2018},\n  url={https://openreview.net/forum?id=B17kCFkwM}\n}", "authorids": ["tegan.jrm@gmail.com", "davidscottkrueger@gmail.com"], "authors": ["Tegan Maharaj", "David Krueger"], "TL;DR": "Reserve output units allow deep networks to anticipate the introduction of novel classes", "pdf": "/pdf/6a29198913ea6f3f41673edc919f2ec57722d609.pdf"}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1520657999000, "tmdate": 1521582863244, "id": "ICLR.cc/2018/Workshop/-/Paper337/Official_Review", "writers": ["ICLR.cc/2018/Workshop"], "signatures": ["ICLR.cc/2018/Workshop"], "readers": ["everyone"], "invitees": ["ICLR.cc/2018/Workshop/Paper337/Reviewers"], "noninvitees": ["ICLR.cc/2018/Workshop/Paper337/AnonReviewer3", "ICLR.cc/2018/Workshop/Paper337/AnonReviewer2"], "reply": {"forum": "B17kCFkwM", "replyto": "B17kCFkwM", "writers": {"values-regex": "ICLR.cc/2018/Workshop/Paper337/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2018/Workshop/Paper337/AnonReviewer[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"required": true, "order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"required": true, "order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "value-regex": "[\\S\\s]{1,200000}"}, "rating": {"required": true, "order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"required": true, "order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1528433999000, "cdate": 1521582863244}}}, {"tddate": null, "ddate": null, "original": null, "tmdate": 1521573594482, "tcdate": 1521573594482, "number": 220, "cdate": 1521573594145, "id": "r1GkJky5z", "invitation": "ICLR.cc/2018/Workshop/-/Acceptance_Decision", "forum": "B17kCFkwM", "replyto": "B17kCFkwM", "signatures": ["ICLR.cc/2018/Workshop/Program_Chairs"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Workshop/Program_Chairs"], "content": {"decision": "Reject", "title": "ICLR 2018 Workshop Acceptance Decision", "comment": "Based on the reviews, this paper has not been accepted for presentation at the ICLR workshop. However, the conversation and updates can continue to appear here on OpenReview."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Reserve Output Units for Deep Open-Set Learning", "abstract": "Open-set learning poses a classification problem where the set of class labels expands over time; a realistic but not widely-studied setting.\nWe propose a deep learning technique for open-set learning based on Reserve Output Units (ROUs), which are designed to help a network anticipate the introduction of new categories during training. \nROUs are additional output units whose representations are trained along with units for already-seen classes, which can be assigned to new classes once a labeled instance of a novel class is observed. We experiment with different initialization methods, compare this method with simply adding an new output vector for the novel class, and find that ROUs achieve better and more consistent performance than the simple add-new baseline.\nWe further experiment with a loss which encourages the output space to match pretrained word embeddings, with the goal of encouraging good semantics of this space. \nIn experiments on MNIST and CIFAR, this technique hurt or does not affect performance, but we're optimistic this technique could be helpful for larger output spaces. ", "paperhash": "maharaj|reserve_output_units_for_deep_openset_learning", "keywords": ["Open set learning", "deep learning", "online learning"], "_bibtex": "@misc{\n  maharaj2018reserve,\n  title={Reserve Output Units for Deep Open-Set Learning},\n  author={Tegan Maharaj and David Krueger},\n  year={2018},\n  url={https://openreview.net/forum?id=B17kCFkwM}\n}", "authorids": ["tegan.jrm@gmail.com", "davidscottkrueger@gmail.com"], "authors": ["Tegan Maharaj", "David Krueger"], "TL;DR": "Reserve output units allow deep networks to anticipate the introduction of novel classes", "pdf": "/pdf/6a29198913ea6f3f41673edc919f2ec57722d609.pdf"}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "tmdate": 1518629844880, "id": "ICLR.cc/2018/Workshop/-/Acceptance_Decision", "writers": ["ICLR.cc/2018/Workshop"], "signatures": ["ICLR.cc/2018/Workshop"], "readers": ["everyone"], "invitees": ["ICLR.cc/2018/Workshop/Program_Chairs"], "reply": {"forum": null, "replyto": null, "invitation": "ICLR.cc/2018/Workshop/-/Submission", "writers": {"values": ["ICLR.cc/2018/Workshop/Program_Chairs"]}, "signatures": {"description": "How your identity will be displayed with the above content.", "values": ["ICLR.cc/2018/Workshop/Program_Chairs"]}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["ICLR.cc/2018/Workshop/Program_Chairs", "everyone"]}, "content": {"title": {"required": true, "order": 1, "value": "ICLR 2018 Workshop Acceptance Decision"}, "comment": {"required": false, "order": 3, "description": "(optional) Comment on this decision.", "value-regex": "[\\S\\s]{0,5000}"}, "decision": {"required": true, "order": 2, "value-dropdown": ["Accept", "Reject"]}}}, "nonreaders": [], "noninvitees": [], "cdate": 1518629844880}}}], "count": 4}