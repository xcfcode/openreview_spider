{"notes": [{"tddate": null, "ddate": null, "cdate": null, "original": null, "tmdate": 1490028592800, "tcdate": 1490028592800, "number": 1, "id": "rJK4ut6sl", "invitation": "ICLR.cc/2017/workshop/-/paper91/acceptance", "forum": "SyZiHtVFg", "replyto": "SyZiHtVFg", "signatures": ["ICLR.cc/2017/pcs"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/pcs"], "content": {"decision": "Reject", "title": "ICLR committee final decision"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"TL;DR": "", "title": "Bi-class classification of humpback whale sound units against complex background noise with Deep Convolution Neural Network", "abstract": "Automatically detecting sound units of humpback whales in complex time-varying background noises is a current challenge for scientists. In this paper, we explore the applicability of Convolution Neural Network (CNN) method for this task. In the evaluation stage, we present 6 bi-class classification experimentations of whale sound detection against different background noise types (e.g., rain, wind). In comparison to classical FFT-based representation like spectrograms, we showed that the use of image-based pretrained CNN features brought higher performance to classify whale sounds and background noise. \n", "pdf": "/pdf/906461a201592fe9e58a8fa2428d9809d5b36241.pdf", "paperhash": "d|biclass_classification_of_humpback_whale_sound_units_against_complex_background_noise_with_deep_convolution_neural_network", "conflicts": ["upmc"], "authors": ["Cazau D.", "Lefort R.", "Bonnel", "J.", "Krywyk", "J.", "Zarader JL", "Adam", "O."], "keywords": ["Natural language processing", "Deep learning", "Applications"], "authorids": ["cazaudorian@outlook.fr", "riwal.lefort@ensta-bretagne.fr", "julien.krywyk@gmail.com", "zarader@isir.fr", "olivier.adam@upmc.fr"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "tmdate": 1490028593334, "id": "ICLR.cc/2017/workshop/-/paper91/acceptance", "writers": ["ICLR.cc/2017/workshop"], "signatures": ["ICLR.cc/2017/workshop"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/pcs"], "noninvitees": ["ICLR.cc/2017/pcs"], "reply": {"forum": "SyZiHtVFg", "replyto": "SyZiHtVFg", "writers": {"values-regex": "ICLR.cc/2017/pcs"}, "signatures": {"values-regex": "ICLR.cc/2017/pcs", "description": "Your displayed identity associated with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your decision.", "value": "ICLR committee final decision"}, "decision": {"required": true, "order": 3, "value-radio": ["Accept", "Reject"]}}}, "nonreaders": [], "cdate": 1490028593334}}}, {"tddate": null, "tmdate": 1489199218201, "tcdate": 1489199218201, "number": 2, "id": "HJcdxkWjl", "invitation": "ICLR.cc/2017/workshop/-/paper91/official/review", "forum": "SyZiHtVFg", "replyto": "SyZiHtVFg", "signatures": ["ICLR.cc/2017/workshop/paper91/AnonReviewer1"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/workshop/paper91/AnonReviewer1"], "content": {"title": "Interesting results but not much contribution to the community", "rating": "3: Clear rejection", "review": "The paper shows the image recognition CNNs can be used for whale sound detection.\n\nPros:\n* It's interesting to know the pretrained CNNs work across domains.\n\nCons: \n* Experiments were not well designed. No comparisons were made. \n* The frontend processing is not conventional audio processing steps, no justification was provided why the authors decided to use the presented way. Especially, FFT generated spectrogram has 2048 bins, which are converted to 256x256 pixel images, how? Is the time-frequency structure maintained? If downsampled from 2048 to 256, why not directly output 256 bin FFT?\n* No discussions on why the pretrained CNNs work for this particular task. Is the performance gained by using CNNs or the pretraining on images?\n* No sound detection literature was mentioned. The task of whale sound detection may be rare, but there is a huge literature of speech/voice detection, which share the similar processing framework.", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"TL;DR": "", "title": "Bi-class classification of humpback whale sound units against complex background noise with Deep Convolution Neural Network", "abstract": "Automatically detecting sound units of humpback whales in complex time-varying background noises is a current challenge for scientists. In this paper, we explore the applicability of Convolution Neural Network (CNN) method for this task. In the evaluation stage, we present 6 bi-class classification experimentations of whale sound detection against different background noise types (e.g., rain, wind). In comparison to classical FFT-based representation like spectrograms, we showed that the use of image-based pretrained CNN features brought higher performance to classify whale sounds and background noise. \n", "pdf": "/pdf/906461a201592fe9e58a8fa2428d9809d5b36241.pdf", "paperhash": "d|biclass_classification_of_humpback_whale_sound_units_against_complex_background_noise_with_deep_convolution_neural_network", "conflicts": ["upmc"], "authors": ["Cazau D.", "Lefort R.", "Bonnel", "J.", "Krywyk", "J.", "Zarader JL", "Adam", "O."], "keywords": ["Natural language processing", "Deep learning", "Applications"], "authorids": ["cazaudorian@outlook.fr", "riwal.lefort@ensta-bretagne.fr", "julien.krywyk@gmail.com", "zarader@isir.fr", "olivier.adam@upmc.fr"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1489183200000, "tmdate": 1489199218931, "id": "ICLR.cc/2017/workshop/-/paper91/official/review", "writers": ["ICLR.cc/2017/workshop"], "signatures": ["ICLR.cc/2017/workshop"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/workshop/paper91/reviewers"], "noninvitees": ["ICLR.cc/2017/workshop/paper91/AnonReviewer2", "ICLR.cc/2017/workshop/paper91/AnonReviewer1"], "reply": {"forum": "SyZiHtVFg", "replyto": "SyZiHtVFg", "writers": {"values-regex": "ICLR.cc/2017/workshop/paper91/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/workshop/paper91/AnonReviewer[0-9]+"}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "value-regex": "[\\S\\s]{1,5000}"}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1496959200000, "cdate": 1489199218931}}}, {"tddate": null, "tmdate": 1489168157995, "tcdate": 1489168157995, "number": 1, "id": "rkIQDDgjl", "invitation": "ICLR.cc/2017/workshop/-/paper91/official/review", "forum": "SyZiHtVFg", "replyto": "SyZiHtVFg", "signatures": ["ICLR.cc/2017/workshop/paper91/AnonReviewer2"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/workshop/paper91/AnonReviewer2"], "content": {"title": "Incomplete analysis for a workshop submission", "rating": "3: Clear rejection", "review": "This works presents a single pipeline for whale sound classification using an image classification CNN on top of spectrogram, followed by a SVM classifier.\n\nUnfortunately the paper does not provide any baseline which would verify usefulness of the image-CNN on a spectrogram (e.g. training the SVM directly on top of the spectrogram). The use of CNN trained for image classification for audio data is rather controversial (e.g. due to different statistics and required invariances of the data) and the work does not provide any proof that it is doing anything more than a random projections.\nThe work uses several terms incorrectly (detection vs. classification, incorrectly assigning CNN models to \"imagenet framework\" etc.).\n\nPros:\n- Interesting dataset which may be useful for future research\n- Bravery to use image classification network for sound spectrogram classification\n\nCons:\n- Lack of any simple baseline which would motivate the use of computationally expensive CNN trained for image classification\n- Several technical inaccuracies in the text\n\n", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"TL;DR": "", "title": "Bi-class classification of humpback whale sound units against complex background noise with Deep Convolution Neural Network", "abstract": "Automatically detecting sound units of humpback whales in complex time-varying background noises is a current challenge for scientists. In this paper, we explore the applicability of Convolution Neural Network (CNN) method for this task. In the evaluation stage, we present 6 bi-class classification experimentations of whale sound detection against different background noise types (e.g., rain, wind). In comparison to classical FFT-based representation like spectrograms, we showed that the use of image-based pretrained CNN features brought higher performance to classify whale sounds and background noise. \n", "pdf": "/pdf/906461a201592fe9e58a8fa2428d9809d5b36241.pdf", "paperhash": "d|biclass_classification_of_humpback_whale_sound_units_against_complex_background_noise_with_deep_convolution_neural_network", "conflicts": ["upmc"], "authors": ["Cazau D.", "Lefort R.", "Bonnel", "J.", "Krywyk", "J.", "Zarader JL", "Adam", "O."], "keywords": ["Natural language processing", "Deep learning", "Applications"], "authorids": ["cazaudorian@outlook.fr", "riwal.lefort@ensta-bretagne.fr", "julien.krywyk@gmail.com", "zarader@isir.fr", "olivier.adam@upmc.fr"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1489183200000, "tmdate": 1489199218931, "id": "ICLR.cc/2017/workshop/-/paper91/official/review", "writers": ["ICLR.cc/2017/workshop"], "signatures": ["ICLR.cc/2017/workshop"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/workshop/paper91/reviewers"], "noninvitees": ["ICLR.cc/2017/workshop/paper91/AnonReviewer2", "ICLR.cc/2017/workshop/paper91/AnonReviewer1"], "reply": {"forum": "SyZiHtVFg", "replyto": "SyZiHtVFg", "writers": {"values-regex": "ICLR.cc/2017/workshop/paper91/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/workshop/paper91/AnonReviewer[0-9]+"}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "value-regex": "[\\S\\s]{1,5000}"}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1496959200000, "cdate": 1489199218931}}}, {"tddate": null, "replyto": null, "nonreaders": null, "ddate": null, "tmdate": 1487678488808, "tcdate": 1487340952894, "number": 91, "id": "SyZiHtVFg", "invitation": "ICLR.cc/2017/workshop/-/submission", "forum": "SyZiHtVFg", "signatures": ["~Dorian_Cazau1"], "readers": ["everyone"], "content": {"TL;DR": "", "title": "Bi-class classification of humpback whale sound units against complex background noise with Deep Convolution Neural Network", "abstract": "Automatically detecting sound units of humpback whales in complex time-varying background noises is a current challenge for scientists. In this paper, we explore the applicability of Convolution Neural Network (CNN) method for this task. In the evaluation stage, we present 6 bi-class classification experimentations of whale sound detection against different background noise types (e.g., rain, wind). In comparison to classical FFT-based representation like spectrograms, we showed that the use of image-based pretrained CNN features brought higher performance to classify whale sounds and background noise. \n", "pdf": "/pdf/906461a201592fe9e58a8fa2428d9809d5b36241.pdf", "paperhash": "d|biclass_classification_of_humpback_whale_sound_units_against_complex_background_noise_with_deep_convolution_neural_network", "conflicts": ["upmc"], "authors": ["Cazau D.", "Lefort R.", "Bonnel", "J.", "Krywyk", "J.", "Zarader JL", "Adam", "O."], "keywords": ["Natural language processing", "Deep learning", "Applications"], "authorids": ["cazaudorian@outlook.fr", "riwal.lefort@ensta-bretagne.fr", "julien.krywyk@gmail.com", "zarader@isir.fr", "olivier.adam@upmc.fr"]}, "writers": [], "details": {"replyCount": 3, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1487690420000, "tmdate": 1484242559574, "id": "ICLR.cc/2017/workshop/-/submission", "writers": ["ICLR.cc/2017/workshop"], "signatures": ["ICLR.cc/2017/pcs"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": null, "replyto": null, "writers": {"values-regex": "~.*"}, "signatures": {"values-regex": "~.*", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"pdf": {"required": true, "order": 5, "description": "Either upload a PDF file or provide a direct link to your PDF on ArXiv (link must begin with http(s) and end with .pdf)", "value-regex": "upload|(http|https):\\/\\/.+\\.pdf"}, "title": {"required": true, "order": 1, "description": "Title of paper.", "value-regex": ".{1,250}"}, "abstract": {"required": true, "order": 4, "description": "Abstract of paper.", "value-regex": "[\\S\\s]{1,5000}"}, "authors": {"required": true, "order": 2, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of author names, as they appear in the paper."}, "conflicts": {"required": true, "order": 100, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of email domains of people who would have a conflict of interest in reviewing this paper, (e.g., cs.umass.edu;google.com, etc.)."}, "keywords": {"order": 6, "description": "Comma separated list of keywords.", "values-dropdown": ["Theory", "Computer vision", "Speech", "Natural language processing", "Deep learning", "Unsupervised Learning", "Supervised Learning", "Semi-Supervised Learning", "Reinforcement Learning", "Transfer Learning", "Multi-modal learning", "Applications", "Optimization", "Structured prediction", "Games"]}, "TL;DR": {"required": false, "order": 3, "description": "\"Too Long; Didn't Read\": a short sentence describing your paper", "value-regex": "[^\\n]{0,250}"}, "authorids": {"required": true, "order": 3, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of author email addresses, in the same order as above."}}}, "nonreaders": [], "noninvitees": [], "expdate": 1495466420000, "cdate": 1484242559574}}}], "count": 4}