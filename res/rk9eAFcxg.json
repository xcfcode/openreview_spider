{"notes": [{"tddate": null, "replyto": null, "ddate": null, "tmdate": 1489039669342, "tcdate": 1478299122344, "number": 525, "id": "rk9eAFcxg", "invitation": "ICLR.cc/2017/conference/-/submission", "forum": "rk9eAFcxg", "signatures": ["~Sanjay_Purushotham1"], "readers": ["everyone"], "content": {"title": "Variational Recurrent Adversarial Deep Domain Adaptation", "abstract": "We study the problem of learning domain invariant representations for time series data while transferring the complex temporal latent dependencies between the domains. Our model termed as Variational Recurrent Adversarial Deep Domain Adaptation (VRADA) is built atop a variational recurrent neural network (VRNN) and trains adversarially to capture complex temporal relationships that are domain-invariant. This is (as far as we know) the first to capture and transfer temporal latent dependencies in multivariate time-series data. Through experiments on real-world multivariate healthcare time-series datasets, we empirically demonstrate that learning temporal dependencies helps our model's ability to create domain-invariant representations, allowing our model to outperform current state-of-the-art deep domain adaptation approaches.", "pdf": "/pdf/af99f4be8bec43ed9d2d85713b3966173492c634.pdf", "TL;DR": "We propose Variational Recurrent Adversarial Deep Domain Adaptation approach to capture and transfer temporal latent dependencies in multivariate time-series data", "paperhash": "purushotham|variational_recurrent_adversarial_deep_domain_adaptation", "keywords": ["Deep learning", "Transfer Learning"], "conflicts": ["usc.edu", "nyu.edu", "nec-labs.com"], "authors": ["Sanjay Purushotham", "Wilka Carvalho", "Tanachat Nilanon", "Yan Liu"], "authorids": ["spurusho@usc.edu", "wcarvalh@usc.edu", "nilanon@usc.edu", "yanliu.cs@usc.edu"]}, "writers": [], "nonreaders": [], "details": {"replyCount": 14, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1475686800000, "tmdate": 1478287705855, "id": "ICLR.cc/2017/conference/-/submission", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/pcs"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": null, "replyto": null, "writers": {"values-regex": "~.*"}, "signatures": {"values-regex": "~.*", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"pdf": {"required": true, "order": 5, "description": "Either upload a PDF file or provide a direct link to your PDF on ArXiv (link must begin with http(s) and end with .pdf)", "value-regex": "upload|(http|https):\\/\\/.+\\.pdf"}, "title": {"required": true, "order": 1, "description": "Title of paper.", "value-regex": ".{1,250}"}, "abstract": {"required": true, "order": 4, "description": "Abstract of paper.", "value-regex": "[\\S\\s]{1,5000}"}, "authors": {"required": true, "order": 2, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of author names, as they appear in the paper."}, "conflicts": {"required": true, "order": 100, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of email domains of people who would have a conflict of interest in reviewing this paper, (e.g., cs.umass.edu;google.com, etc.)."}, "keywords": {"order": 6, "description": "Comma separated list of keywords.", "values-dropdown": ["Theory", "Computer vision", "Speech", "Natural language processing", "Deep learning", "Unsupervised Learning", "Supervised Learning", "Semi-Supervised Learning", "Reinforcement Learning", "Transfer Learning", "Multi-modal learning", "Applications", "Optimization", "Structured prediction", "Games"]}, "TL;DR": {"required": false, "order": 3, "description": "\"Too Long; Didn't Read\": a short sentence describing your paper", "value-regex": "[^\\n]{0,250}"}, "authorids": {"required": true, "order": 3, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of author email addresses, in the same order as above."}}}, "nonreaders": [], "noninvitees": [], "expdate": 1483462800000, "cdate": 1478287705855}}}, {"tddate": null, "ddate": null, "cdate": null, "tmdate": 1486396657177, "tcdate": 1486396657177, "number": 1, "id": "r1FxpMI_l", "invitation": "ICLR.cc/2017/conference/-/paper525/acceptance", "forum": "rk9eAFcxg", "replyto": "rk9eAFcxg", "signatures": ["ICLR.cc/2017/pcs"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/pcs"], "content": {"title": "ICLR committee final decision", "comment": "The paper offers a contribution to domain adaptation. The novelty with respect to methodology is modest, utilizing an existing variational RNN formulation and adversarial training method in this setting. But the application is important and results are strong. Improving the analysis of the results, and studying variants of the approach to understand the contribution of each component, will make this paper considerably stronnger. We encourage the authors to revise accordingly.", "decision": "Accept (Poster)"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Variational Recurrent Adversarial Deep Domain Adaptation", "abstract": "We study the problem of learning domain invariant representations for time series data while transferring the complex temporal latent dependencies between the domains. Our model termed as Variational Recurrent Adversarial Deep Domain Adaptation (VRADA) is built atop a variational recurrent neural network (VRNN) and trains adversarially to capture complex temporal relationships that are domain-invariant. This is (as far as we know) the first to capture and transfer temporal latent dependencies in multivariate time-series data. Through experiments on real-world multivariate healthcare time-series datasets, we empirically demonstrate that learning temporal dependencies helps our model's ability to create domain-invariant representations, allowing our model to outperform current state-of-the-art deep domain adaptation approaches.", "pdf": "/pdf/af99f4be8bec43ed9d2d85713b3966173492c634.pdf", "TL;DR": "We propose Variational Recurrent Adversarial Deep Domain Adaptation approach to capture and transfer temporal latent dependencies in multivariate time-series data", "paperhash": "purushotham|variational_recurrent_adversarial_deep_domain_adaptation", "keywords": ["Deep learning", "Transfer Learning"], "conflicts": ["usc.edu", "nyu.edu", "nec-labs.com"], "authors": ["Sanjay Purushotham", "Wilka Carvalho", "Tanachat Nilanon", "Yan Liu"], "authorids": ["spurusho@usc.edu", "wcarvalh@usc.edu", "nilanon@usc.edu", "yanliu.cs@usc.edu"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1486396657658, "id": "ICLR.cc/2017/conference/-/paper525/acceptance", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/pcs"], "noninvitees": ["ICLR.cc/2017/pcs"], "reply": {"forum": "rk9eAFcxg", "replyto": "rk9eAFcxg", "writers": {"values-regex": "ICLR.cc/2017/pcs"}, "signatures": {"values-regex": "ICLR.cc/2017/pcs", "description": "Your displayed identity associated with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your decision.", "value": "ICLR committee final decision"}, "comment": {"required": true, "order": 2, "description": "Decision comments.", "value-regex": "[\\S\\s]{1,5000}"}, "decision": {"required": true, "order": 3, "value-radio": ["Accept (Oral)", "Accept (Poster)", "Reject", "Invite to Workshop Track"]}}}, "nonreaders": [], "cdate": 1486396657658}}}, {"tddate": null, "tmdate": 1485193750906, "tcdate": 1481989079204, "number": 2, "id": "HkJJhAfNx", "invitation": "ICLR.cc/2017/conference/-/paper525/official/review", "forum": "rk9eAFcxg", "replyto": "rk9eAFcxg", "signatures": ["ICLR.cc/2017/conference/paper525/AnonReviewer2"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/conference/paper525/AnonReviewer2"], "content": {"title": "Final review.", "rating": "6: Marginally above acceptance threshold", "review": "Update: I thank the authors for their comments! After reading them, I still think the paper is not novel enough so I'm leaving the rating untouched.\n\nThis paper proposes a domain adaptation technique for time series. The core of the approach is a combination of variational recurrent neural networks and adversarial domain adaptation (at the last time step).\n\nPros:\n\n1. The authors consider a very important application of domain adaptation.\n\n2. The paper is well-written and relatively easy to read.\n\n3. Solid empirical evaluation. The authors compare their method against several recent domain adaptation techniques on a number of datasets.\n\nCons:\n\n1. The novelty of the approach is relatively low: it\u2019s just a straightforward fusion of the existing techniques.\n\n2. The paper lacks any motivation for use of the particular combination (VRNN and RevGrad). I still believe comparable results can be obtained by polishing R-DANN (e.g. carefully penalizing domain discrepancy at every step)\n\nAdditional comments:\n\n1. I\u2019m not convinced by the discussion presented in Section 4.4. I don\u2019t think the visualization of firing patterns can be used to support the efficiency of the proposed method.\n\n2. Figure 1(c) looks very suspicious. I can hardly believe t-SNE could produce this _very_ regular structure for non-degenerate (non-synthetic, real-world) data.\n\nOverall, it\u2019s a solid paper but I\u2019m not sure if it is up to the ICLR standard.", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Variational Recurrent Adversarial Deep Domain Adaptation", "abstract": "We study the problem of learning domain invariant representations for time series data while transferring the complex temporal latent dependencies between the domains. Our model termed as Variational Recurrent Adversarial Deep Domain Adaptation (VRADA) is built atop a variational recurrent neural network (VRNN) and trains adversarially to capture complex temporal relationships that are domain-invariant. This is (as far as we know) the first to capture and transfer temporal latent dependencies in multivariate time-series data. Through experiments on real-world multivariate healthcare time-series datasets, we empirically demonstrate that learning temporal dependencies helps our model's ability to create domain-invariant representations, allowing our model to outperform current state-of-the-art deep domain adaptation approaches.", "pdf": "/pdf/af99f4be8bec43ed9d2d85713b3966173492c634.pdf", "TL;DR": "We propose Variational Recurrent Adversarial Deep Domain Adaptation approach to capture and transfer temporal latent dependencies in multivariate time-series data", "paperhash": "purushotham|variational_recurrent_adversarial_deep_domain_adaptation", "keywords": ["Deep learning", "Transfer Learning"], "conflicts": ["usc.edu", "nyu.edu", "nec-labs.com"], "authors": ["Sanjay Purushotham", "Wilka Carvalho", "Tanachat Nilanon", "Yan Liu"], "authorids": ["spurusho@usc.edu", "wcarvalh@usc.edu", "nilanon@usc.edu", "yanliu.cs@usc.edu"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1481932799000, "tmdate": 1482512554552, "id": "ICLR.cc/2017/conference/-/paper525/official/review", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/conference/paper525/reviewers"], "noninvitees": ["ICLR.cc/2017/conference/paper525/AnonReviewer3", "ICLR.cc/2017/conference/paper525/AnonReviewer2", "ICLR.cc/2017/conference/paper525/AnonReviewer1"], "reply": {"forum": "rk9eAFcxg", "replyto": "rk9eAFcxg", "writers": {"values-regex": "ICLR.cc/2017/conference/paper525/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/conference/paper525/AnonReviewer[0-9]+"}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "value-regex": "[\\S\\s]{1,20000}"}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1489708799000, "cdate": 1482512554552}}}, {"tddate": null, "tmdate": 1484901281531, "tcdate": 1484887324417, "number": 5, "id": "SJN7BGyPl", "invitation": "ICLR.cc/2017/conference/-/paper525/public/comment", "forum": "rk9eAFcxg", "replyto": "SJ3UnkIVe", "signatures": ["~Sanjay_Purushotham1"], "readers": ["everyone"], "writers": ["~Sanjay_Purushotham1"], "content": {"title": "To AnonReviewer1 Re: Interesting applications but with unconvincing results", "comment": "Thank you for your comments and questions. We have revised the paper, added experiments providing additional insights. In the above 'Response to all reviewers' comment, we have clarified our contributions and below we provide detailed response to your questions. We believe these address your concerns and hope you will consider updating your review.\n\nOur framework VRADA is inspired by the recent advances in deep domain adaptation approaches and is built upon the deep domain adversarial training method (Ganin et. al, JMLR, 2016). We employed Variational Recurrent Neural Network (VRNN) to capture the temporal dependencies since it has been shown to perform better than the dynamic Bayesian networks (DBNs) and Recurrent Neural Networks (RNN) is the earlier works (J. Chung, et. al, NIPS 2015). Also, note that VRNN is better than standard RNNs since the complex temporal dependencies present in the data cannot be modelled efficiently by the output probability models used in the RNNs (J. Chung, et. al, NIPS 2015, Boulanger. et. al, ICML 2012). \n\nQ: However, it is not clear where the advantage is coming from?\nNow addressing the source of our stronger performance. Using a VRNN in VRADA, adds two capabilities: capture complex temporal dependencies present in the data and learns to create the data\u2019s reconstruction.  Both of these help our model learn more significant patterns within the data. Earlier when asked about the impact of reconstructing the data, we mistakenly answered that the improvement was marginal. We apologize for this blunder. We ran experiments (results are shown in the appendix section 6.2.2) and found non-trivial increases in performance when including reconstruction loss in our joint optimization vs not. This empirically demonstrates that learning how to reconstruct the data helps VRADA learn structural and temporal dependencies present in the data. \n \nClarifications:\nQ: Please provide more details on what is plotted in Figure 1. Is 1 (b) is the t-sne projection of representations learned by DANN or R-DANN? The text in section 4.4 suggests it\u2019s the later case. It is surprising to see such a regular plot for VRADA.  What do you think are the two dominant latent factors encoded in figure 1 (c)? \nA: Figure 1 b) is the t-SNE for R-DANN. This typo has been fixed in the revised draft. In Figure 1, we are interested in showcasing the effect of adaptation on the distribution of the latent features. From this figure, we see that our method has much better mixing of the source and target domain latent features. It was surprising for us to see a regular t-SNE plot but this is the plot we obtained for the 3-1 source-target pair. We will release our codes to public for reproducibility. We are working with medical experts to interpret the two dominant latent factors used in figure 1.\n\nQ.In Table 2, the two baselines have quite significant difference in performance testing on the entire target (including validation set) vs on the test set only. VRADA, on the other hand, performs almost identical in these two settings. Could you please offer some explanation on this?\nA:Table 2 has been updated. In our earlier draft, AUC for each source-target pair was incorrectly calculated. We sincerely apologize for this error. In the revised draft, we see that in table 2, VRADA obtains slightly better overall AUC scores than R-DANN  (~1.5 to 2% performance gain). \n\n\nQ. Please explain figure 3 and 4 in more details. how to interpret the x-axis of figure 3, and the x and y axes of figure 4. Again the right two plots in figure 4 are extremely regular comparing to the ones on the left. \nA: x-axis of Figure 3 is the time steps of the activation. For example, in AHRF dataset, we have 4 time steps (as discussed in dataset description Section 4.1), thus x-axis of Fig. 3 has 4 time units. Similarly, the x-axis of Figure 4 is cell state activations unrolled over time (here the length is 480), while the y-axis is all data points for the source (group 2) and target domain (group 5) pairs. The right two plots in figure 4 correspond to the cell state activations of our VRADA for all the samples of the source and target domains (for the ICD9 code prediction task). We expect these plots to be similar and this indicates that the temporal dependencies (which appear as regular structural patterns in the plots) captured in the source domain (group 2) are transferred efficiently to the target domain (group 5). We further analyze and discuss the regularity found in Figure 4 in appendix section 6.2.3.\n\n\nReferences:\n[Boulanger. et. al, ICML 2012] Boulanger-Lewandowski, Nicolas, Yoshua Bengio, and Pascal Vincent. \"Modeling temporal dependencies in high-dimensional sequences: Application to polyphonic music generation and transcription.\" ICML (2012).\n[J. Chung. et. al, NIPS 2015] Chung, J., Kastner, K., Dinh, L., Goel, K., Courville, A. C., & Bengio, Y. (2015). A recurrent latent variable model for sequential data. In Advances in neural information processing systems (pp. 2980-2988)."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Variational Recurrent Adversarial Deep Domain Adaptation", "abstract": "We study the problem of learning domain invariant representations for time series data while transferring the complex temporal latent dependencies between the domains. Our model termed as Variational Recurrent Adversarial Deep Domain Adaptation (VRADA) is built atop a variational recurrent neural network (VRNN) and trains adversarially to capture complex temporal relationships that are domain-invariant. This is (as far as we know) the first to capture and transfer temporal latent dependencies in multivariate time-series data. Through experiments on real-world multivariate healthcare time-series datasets, we empirically demonstrate that learning temporal dependencies helps our model's ability to create domain-invariant representations, allowing our model to outperform current state-of-the-art deep domain adaptation approaches.", "pdf": "/pdf/af99f4be8bec43ed9d2d85713b3966173492c634.pdf", "TL;DR": "We propose Variational Recurrent Adversarial Deep Domain Adaptation approach to capture and transfer temporal latent dependencies in multivariate time-series data", "paperhash": "purushotham|variational_recurrent_adversarial_deep_domain_adaptation", "keywords": ["Deep learning", "Transfer Learning"], "conflicts": ["usc.edu", "nyu.edu", "nec-labs.com"], "authors": ["Sanjay Purushotham", "Wilka Carvalho", "Tanachat Nilanon", "Yan Liu"], "authorids": ["spurusho@usc.edu", "wcarvalh@usc.edu", "nilanon@usc.edu", "yanliu.cs@usc.edu"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287537200, "id": "ICLR.cc/2017/conference/-/paper525/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "rk9eAFcxg", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper525/reviewers", "ICLR.cc/2017/conference/paper525/areachairs"], "cdate": 1485287537200}}}, {"tddate": null, "tmdate": 1484888603169, "tcdate": 1484887833190, "number": 7, "id": "SybmDfkPe", "invitation": "ICLR.cc/2017/conference/-/paper525/public/comment", "forum": "rk9eAFcxg", "replyto": "SJ3a_AG4g", "signatures": ["~Sanjay_Purushotham1"], "readers": ["everyone"], "writers": ["~Sanjay_Purushotham1"], "content": {"title": "To AnonReviewer3 Re: A combination of variational RNN and domain adversarial networks", "comment": "Thanks for your comments and suggestions. We have discussed and highlighted our paper\u2019s key novel contributions in the above 'Response to all reviewers' comment.\n\nQ: As the authors have mentioned, DANN in general outperforms MMD based methods, however, the VFAE method which is based on MMD regularization on the representations seems to outperform DANN across the board.  That seems to indicate VRNN + MMD should also be a good combination.\nA: We agree with the reviewer\u2019s observation that VFAE performs better than DANN but does not always outperform R-DANN (For example: See Table 1, on many src-tgt pairs R-DANN outperforms VFAE). Thanks for the suggestion for VRNN+MMD approach. This approach is in our on-going works and we plan to include it in our future work.  \n\nQ: It would be good to analyze further where the performance gain comes from.\nA: As per reviewer\u2019s suggestions, we ran experiments on our VRADA without reconstruction loss. Results are shown in the appendix section 6.2.2. To our surprise, the performance did not change for a few source-target pairs but it did reduce for the many others. This indicates that reconstruction loss is important and might contribute to the performance improvement of our VRADA model. Appendix 6.2.2 empirically demonstrates that learning how to reconstruct the data helps VRADA learn structural and temporal dependencies present in the data. \n"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Variational Recurrent Adversarial Deep Domain Adaptation", "abstract": "We study the problem of learning domain invariant representations for time series data while transferring the complex temporal latent dependencies between the domains. Our model termed as Variational Recurrent Adversarial Deep Domain Adaptation (VRADA) is built atop a variational recurrent neural network (VRNN) and trains adversarially to capture complex temporal relationships that are domain-invariant. This is (as far as we know) the first to capture and transfer temporal latent dependencies in multivariate time-series data. Through experiments on real-world multivariate healthcare time-series datasets, we empirically demonstrate that learning temporal dependencies helps our model's ability to create domain-invariant representations, allowing our model to outperform current state-of-the-art deep domain adaptation approaches.", "pdf": "/pdf/af99f4be8bec43ed9d2d85713b3966173492c634.pdf", "TL;DR": "We propose Variational Recurrent Adversarial Deep Domain Adaptation approach to capture and transfer temporal latent dependencies in multivariate time-series data", "paperhash": "purushotham|variational_recurrent_adversarial_deep_domain_adaptation", "keywords": ["Deep learning", "Transfer Learning"], "conflicts": ["usc.edu", "nyu.edu", "nec-labs.com"], "authors": ["Sanjay Purushotham", "Wilka Carvalho", "Tanachat Nilanon", "Yan Liu"], "authorids": ["spurusho@usc.edu", "wcarvalh@usc.edu", "nilanon@usc.edu", "yanliu.cs@usc.edu"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287537200, "id": "ICLR.cc/2017/conference/-/paper525/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "rk9eAFcxg", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper525/reviewers", "ICLR.cc/2017/conference/paper525/areachairs"], "cdate": 1485287537200}}}, {"tddate": null, "tmdate": 1484888586360, "tcdate": 1484887713282, "number": 6, "id": "r1KiUMJwe", "invitation": "ICLR.cc/2017/conference/-/paper525/public/comment", "forum": "rk9eAFcxg", "replyto": "HkJJhAfNx", "signatures": ["~Sanjay_Purushotham1"], "readers": ["everyone"], "writers": ["~Sanjay_Purushotham1"], "content": {"title": "To AnonReviewer2 Re: Review", "comment": "Thank you for your comments and questions. Below we provide more detailed comments to your questions.\n\n1. The novelty of the approach is relatively low: it\u2019s just a straightforward fusion of the existing techniques.\nA: We have clarified and highlighted our paper\u2019s key novel contributions in the above 'Response to all reviewers' comment. To briefly summarize - in this paper, we have focused on a very important problem in the healthcare application domain. As far as we know, we are the first to propose unsupervised deep domain adaptation techniques to capture and transfer complex temporal dependencies present in healthcare multivariate time series data. Our domain adaptation framework is general and is suitable for applications where dependencies are present in the multivariate time series data. \n\n\n2. The paper lacks any motivation for use of the particular combination (VRNN and RevGrad). I still believe comparable results can be obtained by polishing R-DANN (e.g. carefully penalizing domain discrepancy at every step)\nA: We apologize for not being clear as to why we specifically used VRNN and reversal gradients. Using a VRNN in VRADA, adds two capabilities: capture complex temporal dependencies present in the data and learns to create the data\u2019s reconstruction.  Both of these help our model learn more significant patterns within the data. Using adversarial training via reversal gradients helps to learn domain-invariant representations. We used this particular combination of VRNN with adversarial training since in healthcare applications matching the data distributions is more interesting than minimizing the distance between the data distribution means across domains (such as Mean Maximum Discrepancy (MMD)).  Moreover, from a theoretical perspective, adversarial training idea [Ganin et. al, JMLR 2016] is derived from the seminal works of [Ben-David et . al, MLJ 2010]. \nWe would also like to inform that we have extensively fined tuned R-DANN to show the best results in our paper. We have compared our approach fairly to Variational FAIR Autoencoder (denoted by VFAE) [Louizos C. et. al, ICLR 2016], which uses MMD criterion. We have empirically shown that VRADA outperforms both R-DANN and  VFAE on the healthcare datasets used in our paper. \n\nAdditional comments:\nQ 1. I\u2019m not convinced by the discussion presented in Section 4.4. I don\u2019t think the visualization of firing patterns can be used to support the efficiency of the proposed method.\nA: The discussion in section 4.4 is used to visualize and qualitatively compare the temporal dependencies captured by different domain adaptation approaches. We used memory cell state activations for visualization. In order to show that domain adaptation results in regular firing patterns, we have added plots to the appendix that show how firing patterns differ when domain adaptation isn\u2019t applied. You can then see a clear direction in the regularity of the firing patterns as (a) domain adaptation is applied, and (b) a better domain adaptation technique is applied. We addressed the regularity found in Figure 4 in appendix section 6.2.3.\n\n\nQ 2. Figure 1(c) looks very suspicious. I can hardly believe t-SNE could produce this _very_ regular structure for non-degenerate (non-synthetic, real-world) data.\nA: Inspired by the feature representation visualization shown in [Ganin et. al, JMLR 2016], we also use t-SNE plots to show the domain invariant feature representations learned by various domain adaptation approaches. In Figure 1, we showed the t-SNE results which we consistently obtained for the source-target pairs from Adult-AHRF to Child-AHRF data. It was surprising for us to see a regular t-SNE plot but that is the plot we obtained for the 3-1 source-target pair. We also varied perplexity (from 5 to 100) and obtained similar t-SNE plots from our VRADA model. We will release our codes to public for reproducibility.\n\n\nReferences:\n[Ganin et. al, JMLR 2016] Ganin, Yaroslav, et al. \"Domain-adversarial training of neural networks.\" Journal of Machine Learning Research 17.59 (2016): 1-35.\n[Ben-David et. al, MLJ 2010] Shai Ben-David, John Blitzer, Koby Crammer, Alex Kulesza, Fernando Pereira, and Jennifer Wortman Vaughan. A theory of learning from different domains. Machine Learning, 9(1-2):151\u2013175, 2010.\n[Louizos C. et. al, ICLR 2016] Louizos, Christos, et al. \"The variational fair autoencoder.\" ICLR (2016)."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Variational Recurrent Adversarial Deep Domain Adaptation", "abstract": "We study the problem of learning domain invariant representations for time series data while transferring the complex temporal latent dependencies between the domains. Our model termed as Variational Recurrent Adversarial Deep Domain Adaptation (VRADA) is built atop a variational recurrent neural network (VRNN) and trains adversarially to capture complex temporal relationships that are domain-invariant. This is (as far as we know) the first to capture and transfer temporal latent dependencies in multivariate time-series data. Through experiments on real-world multivariate healthcare time-series datasets, we empirically demonstrate that learning temporal dependencies helps our model's ability to create domain-invariant representations, allowing our model to outperform current state-of-the-art deep domain adaptation approaches.", "pdf": "/pdf/af99f4be8bec43ed9d2d85713b3966173492c634.pdf", "TL;DR": "We propose Variational Recurrent Adversarial Deep Domain Adaptation approach to capture and transfer temporal latent dependencies in multivariate time-series data", "paperhash": "purushotham|variational_recurrent_adversarial_deep_domain_adaptation", "keywords": ["Deep learning", "Transfer Learning"], "conflicts": ["usc.edu", "nyu.edu", "nec-labs.com"], "authors": ["Sanjay Purushotham", "Wilka Carvalho", "Tanachat Nilanon", "Yan Liu"], "authorids": ["spurusho@usc.edu", "wcarvalh@usc.edu", "nilanon@usc.edu", "yanliu.cs@usc.edu"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287537200, "id": "ICLR.cc/2017/conference/-/paper525/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "rk9eAFcxg", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper525/reviewers", "ICLR.cc/2017/conference/paper525/areachairs"], "cdate": 1485287537200}}}, {"tddate": null, "tmdate": 1484888121892, "tcdate": 1484887029181, "number": 4, "id": "rk6eEz1vl", "invitation": "ICLR.cc/2017/conference/-/paper525/public/comment", "forum": "rk9eAFcxg", "replyto": "rk9eAFcxg", "signatures": ["~Sanjay_Purushotham1"], "readers": ["everyone"], "writers": ["~Sanjay_Purushotham1"], "content": {"title": "Response to all reviewers", "comment": "Thank you all for your time and thoughtful comments! We have incorporated your suggestions to improve our paper.\n\nFirst, we would like to clarify the key contributions of our paper. Motivated by challenges within the healthcare domain, we are proposing a novel unsupervised deep domain adaptation framework for knowledge transfer within healthcare time series data. The framework 1) captures temporal dependencies present in the time series data, and 2) transfers these dependencies from  the source to target domain via adversarial training, and 3) is able to obtain state-of-the-art results, outperforming previous domain adaptation approaches. To the best of our knowledge, this is the first time that complex temporal latent dependencies have been used to transfer knowledge in healthcare multivariate time series data. It is worth noting that our domain adaptation framework is general and is suitable for applications where dependencies are present in the multivariate time series data. \n\nThe other major contribution of our work is moreso from an applications perspective. Healthcare data is a new frontier for machine learning. The data we worked with is complex: it\u2019s temporal, it's multivariate, and it\u2019s noisy,. Healthcare data is also quite different from the data that machine learning scientists are accustomed to working with. The dataset we used (which is the largest publicly available medical data healthset) only have a few thousand training examples (which we then further subdivided into multiple domains). This is considered a small dataset. Further, domain adaptation is typically done when there are ample unlabeled target examples which can be used to learn some mutual representation. We did not have this luxury. Despite, our model outperformed all other models.\n\nWe have uploaded a revised draft to address the questions and comments of the reviewers. In the revised draft, we have added an appendix section with the following new results:\n- Discussion on different training methods for our VRADA model and their results\n- Results on variations of VRADA model including\n  --- Adversarial training at each time step\n  --- Impact of adversarial training on the memory cell state visualizations\n  --- Study on the effect of reconstruction loss on the prediction performance\n- R-DANN model architecture block diagram\n"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Variational Recurrent Adversarial Deep Domain Adaptation", "abstract": "We study the problem of learning domain invariant representations for time series data while transferring the complex temporal latent dependencies between the domains. Our model termed as Variational Recurrent Adversarial Deep Domain Adaptation (VRADA) is built atop a variational recurrent neural network (VRNN) and trains adversarially to capture complex temporal relationships that are domain-invariant. This is (as far as we know) the first to capture and transfer temporal latent dependencies in multivariate time-series data. Through experiments on real-world multivariate healthcare time-series datasets, we empirically demonstrate that learning temporal dependencies helps our model's ability to create domain-invariant representations, allowing our model to outperform current state-of-the-art deep domain adaptation approaches.", "pdf": "/pdf/af99f4be8bec43ed9d2d85713b3966173492c634.pdf", "TL;DR": "We propose Variational Recurrent Adversarial Deep Domain Adaptation approach to capture and transfer temporal latent dependencies in multivariate time-series data", "paperhash": "purushotham|variational_recurrent_adversarial_deep_domain_adaptation", "keywords": ["Deep learning", "Transfer Learning"], "conflicts": ["usc.edu", "nyu.edu", "nec-labs.com"], "authors": ["Sanjay Purushotham", "Wilka Carvalho", "Tanachat Nilanon", "Yan Liu"], "authorids": ["spurusho@usc.edu", "wcarvalh@usc.edu", "nilanon@usc.edu", "yanliu.cs@usc.edu"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287537200, "id": "ICLR.cc/2017/conference/-/paper525/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "rk9eAFcxg", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper525/reviewers", "ICLR.cc/2017/conference/paper525/areachairs"], "cdate": 1485287537200}}}, {"tddate": null, "tmdate": 1482189907947, "tcdate": 1482189907947, "number": 3, "id": "SJ3UnkIVe", "invitation": "ICLR.cc/2017/conference/-/paper525/official/review", "forum": "rk9eAFcxg", "replyto": "rk9eAFcxg", "signatures": ["ICLR.cc/2017/conference/paper525/AnonReviewer1"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/conference/paper525/AnonReviewer1"], "content": {"title": "Interesting applications but with unconvincing results", "rating": "5: Marginally below acceptance threshold", "review": "The work combines variational recurrent neural networks, and adversarial neural networks to handle domain adaptation for time series data. The proposed method, along with several competing algorithms are compared on two healthcare datasets constructed from MIMIC-III in domain adaptation settings.\n\nThe new contribution of the work is relatively small. It extends VRNN with adversarial training for learning domain agnostic representations. From the experimental results, the proposed method clearly out-performs competing algorithms. However, it is not clear where the advantage is coming from. The only difference between the proposed method and R-DANN is using variational RNN vs RNN. Little insights were provided on how this could bring such a big difference in terms of performance and the drastic difference in the temporal dependencies captured by these two methods in Figure 4.  \n\nDetailed comments:\n1. Please provide more details on what is plotted in Figure 1. Is 1 (b) is the t-sne projection of representations learned by DANN or R-DANN? The text in section 4.4 suggests it\u2019s the later case. It is surprising to see such a regular plot for VRADA.  What do you think are the two dominant latent factors encoded in figure 1 (c)? \n\n2. In Table 2, the two baselines have quite significant difference in performance testing on the entire target (including validation set) vs on the test set only. VRADA, on the other hand, performs almost identical in these two settings. Could you please offer some explanation on this?\n\n3. Please explain figure 3 and 4 in more details. how to interpret the x-axis of figure 3, and the x and y axes of figure 4. Again the right two plots in figure 4 are extremely regular comparing to the ones on the left. \n", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Variational Recurrent Adversarial Deep Domain Adaptation", "abstract": "We study the problem of learning domain invariant representations for time series data while transferring the complex temporal latent dependencies between the domains. Our model termed as Variational Recurrent Adversarial Deep Domain Adaptation (VRADA) is built atop a variational recurrent neural network (VRNN) and trains adversarially to capture complex temporal relationships that are domain-invariant. This is (as far as we know) the first to capture and transfer temporal latent dependencies in multivariate time-series data. Through experiments on real-world multivariate healthcare time-series datasets, we empirically demonstrate that learning temporal dependencies helps our model's ability to create domain-invariant representations, allowing our model to outperform current state-of-the-art deep domain adaptation approaches.", "pdf": "/pdf/af99f4be8bec43ed9d2d85713b3966173492c634.pdf", "TL;DR": "We propose Variational Recurrent Adversarial Deep Domain Adaptation approach to capture and transfer temporal latent dependencies in multivariate time-series data", "paperhash": "purushotham|variational_recurrent_adversarial_deep_domain_adaptation", "keywords": ["Deep learning", "Transfer Learning"], "conflicts": ["usc.edu", "nyu.edu", "nec-labs.com"], "authors": ["Sanjay Purushotham", "Wilka Carvalho", "Tanachat Nilanon", "Yan Liu"], "authorids": ["spurusho@usc.edu", "wcarvalh@usc.edu", "nilanon@usc.edu", "yanliu.cs@usc.edu"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1481932799000, "tmdate": 1482512554552, "id": "ICLR.cc/2017/conference/-/paper525/official/review", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/conference/paper525/reviewers"], "noninvitees": ["ICLR.cc/2017/conference/paper525/AnonReviewer3", "ICLR.cc/2017/conference/paper525/AnonReviewer2", "ICLR.cc/2017/conference/paper525/AnonReviewer1"], "reply": {"forum": "rk9eAFcxg", "replyto": "rk9eAFcxg", "writers": {"values-regex": "ICLR.cc/2017/conference/paper525/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/conference/paper525/AnonReviewer[0-9]+"}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "value-regex": "[\\S\\s]{1,20000}"}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1489708799000, "cdate": 1482512554552}}}, {"tddate": null, "tmdate": 1481988292049, "tcdate": 1481988292049, "number": 1, "id": "SJ3a_AG4g", "invitation": "ICLR.cc/2017/conference/-/paper525/official/review", "forum": "rk9eAFcxg", "replyto": "rk9eAFcxg", "signatures": ["ICLR.cc/2017/conference/paper525/AnonReviewer3"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/conference/paper525/AnonReviewer3"], "content": {"title": "A combination of variational RNN and domain adversarial networks", "rating": "6: Marginally above acceptance threshold", "review": "This paper combines variational RNN (VRNN) and domain adversarial networks (DANN) for domain adaptation in the sequence modelling domain.  The VRNN is used to learn representations for sequential data, which is the hidden states of the last time step.  The DANN is used to make the representations domain invariant, therefore achieving cross domain adaptation.\n\nExperiments are done on a number of data sets, and the proposed method (VRADA) outperforms baselines including DANN, VFAE and R-DANN on almost all of them.\n\nI don't have questions about the proposed model, the model is quite clear and seems to be a simple combination of VRNN and DANN.  But a few questions came up during the pre-review question phase:\n\n- As the authors have mentioned, DANN in general outperforms MMD based methods, however, the VFAE method which is based on MMD regularization on the representations seems to outperform DANN across the board.  That seems to indicate VRNN + MMD should also be a good combination.\n\n- One baseline the authors showed in the experiments is R-DANN, which is an RNN version of DANN.  There are two differences between R-DANN and VRADA: (1) R-DANN uses deterministic RNN for representation learning, while VRADA uses variational RNN; (2) on target domain R-DANN only optimizes adversarial loss, while VRADA optimizes both adversarial loss and reconstruction loss for feature learning.  It would be good to analyze further where the performance gain comes from.", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Variational Recurrent Adversarial Deep Domain Adaptation", "abstract": "We study the problem of learning domain invariant representations for time series data while transferring the complex temporal latent dependencies between the domains. Our model termed as Variational Recurrent Adversarial Deep Domain Adaptation (VRADA) is built atop a variational recurrent neural network (VRNN) and trains adversarially to capture complex temporal relationships that are domain-invariant. This is (as far as we know) the first to capture and transfer temporal latent dependencies in multivariate time-series data. Through experiments on real-world multivariate healthcare time-series datasets, we empirically demonstrate that learning temporal dependencies helps our model's ability to create domain-invariant representations, allowing our model to outperform current state-of-the-art deep domain adaptation approaches.", "pdf": "/pdf/af99f4be8bec43ed9d2d85713b3966173492c634.pdf", "TL;DR": "We propose Variational Recurrent Adversarial Deep Domain Adaptation approach to capture and transfer temporal latent dependencies in multivariate time-series data", "paperhash": "purushotham|variational_recurrent_adversarial_deep_domain_adaptation", "keywords": ["Deep learning", "Transfer Learning"], "conflicts": ["usc.edu", "nyu.edu", "nec-labs.com"], "authors": ["Sanjay Purushotham", "Wilka Carvalho", "Tanachat Nilanon", "Yan Liu"], "authorids": ["spurusho@usc.edu", "wcarvalh@usc.edu", "nilanon@usc.edu", "yanliu.cs@usc.edu"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1481932799000, "tmdate": 1482512554552, "id": "ICLR.cc/2017/conference/-/paper525/official/review", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/conference/paper525/reviewers"], "noninvitees": ["ICLR.cc/2017/conference/paper525/AnonReviewer3", "ICLR.cc/2017/conference/paper525/AnonReviewer2", "ICLR.cc/2017/conference/paper525/AnonReviewer1"], "reply": {"forum": "rk9eAFcxg", "replyto": "rk9eAFcxg", "writers": {"values-regex": "ICLR.cc/2017/conference/paper525/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/conference/paper525/AnonReviewer[0-9]+"}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "value-regex": "[\\S\\s]{1,20000}"}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1489708799000, "cdate": 1482512554552}}}, {"tddate": null, "tmdate": 1481846533204, "tcdate": 1481026649690, "number": 1, "id": "BJMw3QE7x", "invitation": "ICLR.cc/2017/conference/-/paper525/public/comment", "forum": "rk9eAFcxg", "replyto": "S1lmjUyXg", "signatures": ["~Sanjay_Purushotham1"], "readers": ["everyone"], "writers": ["~Sanjay_Purushotham1"], "content": {"title": "Re: ICLR 2017 conference paper525 AnonReviewer2", "comment": "(Reply Updated) Thanks for your questions!\n\n1. Yes, we will provide these details in the appendix of our revised draft. \n\n2.  We have compared to Variational FAIR Autoencoder (VFAE) (Louizos, 2016, ICLR) which uses MMD to achieve domain invariance. We haven\u2019t compared to the MMD approach presented in (Long, 2015, ICML). As demonstrated in DANN paper (Ganin, JMLR 2016), adversarial training generally outperforms MMD approaches (Long, 2015, ICML). Please note that as shown in Table 1, our proposed model outperforms both DANN and VFAE on many of the source-target pairs. \n\n3. We have tried adversarial training at every time step and its results were not as good as applying adversarial training at the last time step. We will provide the results of adversarial training at every time step in the appendix of our revised draft.\nMoreover, for healthcare problems, propagating the labels at every time step can be misleading for learning the model parameters. Thus, in this paper, we have employed adversarial training at the last time step. \n"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Variational Recurrent Adversarial Deep Domain Adaptation", "abstract": "We study the problem of learning domain invariant representations for time series data while transferring the complex temporal latent dependencies between the domains. Our model termed as Variational Recurrent Adversarial Deep Domain Adaptation (VRADA) is built atop a variational recurrent neural network (VRNN) and trains adversarially to capture complex temporal relationships that are domain-invariant. This is (as far as we know) the first to capture and transfer temporal latent dependencies in multivariate time-series data. Through experiments on real-world multivariate healthcare time-series datasets, we empirically demonstrate that learning temporal dependencies helps our model's ability to create domain-invariant representations, allowing our model to outperform current state-of-the-art deep domain adaptation approaches.", "pdf": "/pdf/af99f4be8bec43ed9d2d85713b3966173492c634.pdf", "TL;DR": "We propose Variational Recurrent Adversarial Deep Domain Adaptation approach to capture and transfer temporal latent dependencies in multivariate time-series data", "paperhash": "purushotham|variational_recurrent_adversarial_deep_domain_adaptation", "keywords": ["Deep learning", "Transfer Learning"], "conflicts": ["usc.edu", "nyu.edu", "nec-labs.com"], "authors": ["Sanjay Purushotham", "Wilka Carvalho", "Tanachat Nilanon", "Yan Liu"], "authorids": ["spurusho@usc.edu", "wcarvalh@usc.edu", "nilanon@usc.edu", "yanliu.cs@usc.edu"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287537200, "id": "ICLR.cc/2017/conference/-/paper525/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "rk9eAFcxg", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper525/reviewers", "ICLR.cc/2017/conference/paper525/areachairs"], "cdate": 1485287537200}}}, {"tddate": null, "tmdate": 1481287711822, "tcdate": 1481272709682, "number": 3, "id": "H1AFpkOmg", "invitation": "ICLR.cc/2017/conference/-/paper525/public/comment", "forum": "rk9eAFcxg", "replyto": "B1s7M1_Qx", "signatures": ["~Sanjay_Purushotham1"], "readers": ["everyone"], "writers": ["~Sanjay_Purushotham1"], "content": {"title": "Re: Clarification", "comment": "Thanks for the question.\n\nReply Updated: There is no typo in equation (1). In equation (1), we show the optimization problem on the source domain data. However, as shown in equation (3), our VRADA uses data from both the source and target domain for training the VRNN part of our model. \n"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Variational Recurrent Adversarial Deep Domain Adaptation", "abstract": "We study the problem of learning domain invariant representations for time series data while transferring the complex temporal latent dependencies between the domains. Our model termed as Variational Recurrent Adversarial Deep Domain Adaptation (VRADA) is built atop a variational recurrent neural network (VRNN) and trains adversarially to capture complex temporal relationships that are domain-invariant. This is (as far as we know) the first to capture and transfer temporal latent dependencies in multivariate time-series data. Through experiments on real-world multivariate healthcare time-series datasets, we empirically demonstrate that learning temporal dependencies helps our model's ability to create domain-invariant representations, allowing our model to outperform current state-of-the-art deep domain adaptation approaches.", "pdf": "/pdf/af99f4be8bec43ed9d2d85713b3966173492c634.pdf", "TL;DR": "We propose Variational Recurrent Adversarial Deep Domain Adaptation approach to capture and transfer temporal latent dependencies in multivariate time-series data", "paperhash": "purushotham|variational_recurrent_adversarial_deep_domain_adaptation", "keywords": ["Deep learning", "Transfer Learning"], "conflicts": ["usc.edu", "nyu.edu", "nec-labs.com"], "authors": ["Sanjay Purushotham", "Wilka Carvalho", "Tanachat Nilanon", "Yan Liu"], "authorids": ["spurusho@usc.edu", "wcarvalh@usc.edu", "nilanon@usc.edu", "yanliu.cs@usc.edu"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287537200, "id": "ICLR.cc/2017/conference/-/paper525/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "rk9eAFcxg", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper525/reviewers", "ICLR.cc/2017/conference/paper525/areachairs"], "cdate": 1485287537200}}}, {"tddate": null, "tmdate": 1481272555018, "tcdate": 1481272555013, "number": 2, "id": "Hk7l6y_7e", "invitation": "ICLR.cc/2017/conference/-/paper525/public/comment", "forum": "rk9eAFcxg", "replyto": "ryYqxnS7g", "signatures": ["~Sanjay_Purushotham1"], "readers": ["everyone"], "writers": ["~Sanjay_Purushotham1"], "content": {"title": "Re: R-DANN baseline", "comment": "Thanks for this question. \n\nIn our preliminary experiments on a few source-target pairs, we did not observe that reconstruction part was critical for performance gain in VRADA. Now, we are conducting more experiments on all the source-target pairs to confirm our preliminary findings."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Variational Recurrent Adversarial Deep Domain Adaptation", "abstract": "We study the problem of learning domain invariant representations for time series data while transferring the complex temporal latent dependencies between the domains. Our model termed as Variational Recurrent Adversarial Deep Domain Adaptation (VRADA) is built atop a variational recurrent neural network (VRNN) and trains adversarially to capture complex temporal relationships that are domain-invariant. This is (as far as we know) the first to capture and transfer temporal latent dependencies in multivariate time-series data. Through experiments on real-world multivariate healthcare time-series datasets, we empirically demonstrate that learning temporal dependencies helps our model's ability to create domain-invariant representations, allowing our model to outperform current state-of-the-art deep domain adaptation approaches.", "pdf": "/pdf/af99f4be8bec43ed9d2d85713b3966173492c634.pdf", "TL;DR": "We propose Variational Recurrent Adversarial Deep Domain Adaptation approach to capture and transfer temporal latent dependencies in multivariate time-series data", "paperhash": "purushotham|variational_recurrent_adversarial_deep_domain_adaptation", "keywords": ["Deep learning", "Transfer Learning"], "conflicts": ["usc.edu", "nyu.edu", "nec-labs.com"], "authors": ["Sanjay Purushotham", "Wilka Carvalho", "Tanachat Nilanon", "Yan Liu"], "authorids": ["spurusho@usc.edu", "wcarvalh@usc.edu", "nilanon@usc.edu", "yanliu.cs@usc.edu"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287537200, "id": "ICLR.cc/2017/conference/-/paper525/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "rk9eAFcxg", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper525/reviewers", "ICLR.cc/2017/conference/paper525/areachairs"], "cdate": 1485287537200}}}, {"tddate": null, "tmdate": 1481269794822, "tcdate": 1481269794816, "number": 3, "id": "B1s7M1_Qx", "invitation": "ICLR.cc/2017/conference/-/paper525/pre-review/question", "forum": "rk9eAFcxg", "replyto": "rk9eAFcxg", "signatures": ["ICLR.cc/2017/conference/paper525/AnonReviewer1"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/conference/paper525/AnonReviewer1"], "content": {"title": "Clarification", "question": "In equation (1), why does the VRNN part only use unlabeled data from source domain, but not those of target ? "}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Variational Recurrent Adversarial Deep Domain Adaptation", "abstract": "We study the problem of learning domain invariant representations for time series data while transferring the complex temporal latent dependencies between the domains. Our model termed as Variational Recurrent Adversarial Deep Domain Adaptation (VRADA) is built atop a variational recurrent neural network (VRNN) and trains adversarially to capture complex temporal relationships that are domain-invariant. This is (as far as we know) the first to capture and transfer temporal latent dependencies in multivariate time-series data. Through experiments on real-world multivariate healthcare time-series datasets, we empirically demonstrate that learning temporal dependencies helps our model's ability to create domain-invariant representations, allowing our model to outperform current state-of-the-art deep domain adaptation approaches.", "pdf": "/pdf/af99f4be8bec43ed9d2d85713b3966173492c634.pdf", "TL;DR": "We propose Variational Recurrent Adversarial Deep Domain Adaptation approach to capture and transfer temporal latent dependencies in multivariate time-series data", "paperhash": "purushotham|variational_recurrent_adversarial_deep_domain_adaptation", "keywords": ["Deep learning", "Transfer Learning"], "conflicts": ["usc.edu", "nyu.edu", "nec-labs.com"], "authors": ["Sanjay Purushotham", "Wilka Carvalho", "Tanachat Nilanon", "Yan Liu"], "authorids": ["spurusho@usc.edu", "wcarvalh@usc.edu", "nilanon@usc.edu", "yanliu.cs@usc.edu"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1480741199000, "tmdate": 1481269795334, "id": "ICLR.cc/2017/conference/-/paper525/pre-review/question", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/conference/paper525/reviewers"], "noninvitees": ["ICLR.cc/2017/conference/paper525/AnonReviewer2", "ICLR.cc/2017/conference/paper525/AnonReviewer3", "ICLR.cc/2017/conference/paper525/AnonReviewer1"], "reply": {"forum": "rk9eAFcxg", "replyto": "rk9eAFcxg", "writers": {"values-regex": "ICLR.cc/2017/conference/paper525/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/conference/paper525/AnonReviewer[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your question.", "value-regex": ".{1,500}"}, "question": {"order": 2, "description": "Your question", "value-regex": "[\\S\\s]{1,5000}"}}}, "nonreaders": [], "expdate": 1488517199000, "cdate": 1481269795334}}}, {"tddate": null, "tmdate": 1481126033561, "tcdate": 1481126033555, "number": 2, "id": "ryYqxnS7g", "invitation": "ICLR.cc/2017/conference/-/paper525/pre-review/question", "forum": "rk9eAFcxg", "replyto": "rk9eAFcxg", "signatures": ["ICLR.cc/2017/conference/paper525/AnonReviewer3"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/conference/paper525/AnonReviewer3"], "content": {"title": "R-DANN baseline", "question": "On unlabeled data, the R-DANN baseline seems to be only trained to fool the adversary, but in the proposed VRADA the RNN part is also trained to do reconstruction, as in the VRNN model.  Is the reconstruction part critical for the performance gain?"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Variational Recurrent Adversarial Deep Domain Adaptation", "abstract": "We study the problem of learning domain invariant representations for time series data while transferring the complex temporal latent dependencies between the domains. Our model termed as Variational Recurrent Adversarial Deep Domain Adaptation (VRADA) is built atop a variational recurrent neural network (VRNN) and trains adversarially to capture complex temporal relationships that are domain-invariant. This is (as far as we know) the first to capture and transfer temporal latent dependencies in multivariate time-series data. Through experiments on real-world multivariate healthcare time-series datasets, we empirically demonstrate that learning temporal dependencies helps our model's ability to create domain-invariant representations, allowing our model to outperform current state-of-the-art deep domain adaptation approaches.", "pdf": "/pdf/af99f4be8bec43ed9d2d85713b3966173492c634.pdf", "TL;DR": "We propose Variational Recurrent Adversarial Deep Domain Adaptation approach to capture and transfer temporal latent dependencies in multivariate time-series data", "paperhash": "purushotham|variational_recurrent_adversarial_deep_domain_adaptation", "keywords": ["Deep learning", "Transfer Learning"], "conflicts": ["usc.edu", "nyu.edu", "nec-labs.com"], "authors": ["Sanjay Purushotham", "Wilka Carvalho", "Tanachat Nilanon", "Yan Liu"], "authorids": ["spurusho@usc.edu", "wcarvalh@usc.edu", "nilanon@usc.edu", "yanliu.cs@usc.edu"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1480741199000, "tmdate": 1481269795334, "id": "ICLR.cc/2017/conference/-/paper525/pre-review/question", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/conference/paper525/reviewers"], "noninvitees": ["ICLR.cc/2017/conference/paper525/AnonReviewer2", "ICLR.cc/2017/conference/paper525/AnonReviewer3", "ICLR.cc/2017/conference/paper525/AnonReviewer1"], "reply": {"forum": "rk9eAFcxg", "replyto": "rk9eAFcxg", "writers": {"values-regex": "ICLR.cc/2017/conference/paper525/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/conference/paper525/AnonReviewer[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your question.", "value-regex": ".{1,500}"}, "question": {"order": 2, "description": "Your question", "value-regex": "[\\S\\s]{1,5000}"}}}, "nonreaders": [], "expdate": 1488517199000, "cdate": 1481269795334}}}, {"tddate": null, "tmdate": 1480710936474, "tcdate": 1480710936469, "number": 1, "id": "S1lmjUyXg", "invitation": "ICLR.cc/2017/conference/-/paper525/pre-review/question", "forum": "rk9eAFcxg", "replyto": "rk9eAFcxg", "signatures": ["ICLR.cc/2017/conference/paper525/AnonReviewer2"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/conference/paper525/AnonReviewer2"], "content": {"title": "Questions", "question": "1. p. 7, 4.2, Could you provide more details for the baseline models (e.g. for DANN or R-DANN)? Diagrams with exact number filter maps/neurons and layer wiring would be perfect.\n2. Have the authors tried simpler alternatives to adversarial training, e.g. MMD (reference: Long, 2015, ICML)?\n3. Do you think your model would benefit from applying adversarial training at every time step (not only at the last one)? It would be interesting to see how your approach compares to R-DANN with a per-step adversary."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Variational Recurrent Adversarial Deep Domain Adaptation", "abstract": "We study the problem of learning domain invariant representations for time series data while transferring the complex temporal latent dependencies between the domains. Our model termed as Variational Recurrent Adversarial Deep Domain Adaptation (VRADA) is built atop a variational recurrent neural network (VRNN) and trains adversarially to capture complex temporal relationships that are domain-invariant. This is (as far as we know) the first to capture and transfer temporal latent dependencies in multivariate time-series data. Through experiments on real-world multivariate healthcare time-series datasets, we empirically demonstrate that learning temporal dependencies helps our model's ability to create domain-invariant representations, allowing our model to outperform current state-of-the-art deep domain adaptation approaches.", "pdf": "/pdf/af99f4be8bec43ed9d2d85713b3966173492c634.pdf", "TL;DR": "We propose Variational Recurrent Adversarial Deep Domain Adaptation approach to capture and transfer temporal latent dependencies in multivariate time-series data", "paperhash": "purushotham|variational_recurrent_adversarial_deep_domain_adaptation", "keywords": ["Deep learning", "Transfer Learning"], "conflicts": ["usc.edu", "nyu.edu", "nec-labs.com"], "authors": ["Sanjay Purushotham", "Wilka Carvalho", "Tanachat Nilanon", "Yan Liu"], "authorids": ["spurusho@usc.edu", "wcarvalh@usc.edu", "nilanon@usc.edu", "yanliu.cs@usc.edu"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1480741199000, "tmdate": 1481269795334, "id": "ICLR.cc/2017/conference/-/paper525/pre-review/question", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/conference/paper525/reviewers"], "noninvitees": ["ICLR.cc/2017/conference/paper525/AnonReviewer2", "ICLR.cc/2017/conference/paper525/AnonReviewer3", "ICLR.cc/2017/conference/paper525/AnonReviewer1"], "reply": {"forum": "rk9eAFcxg", "replyto": "rk9eAFcxg", "writers": {"values-regex": "ICLR.cc/2017/conference/paper525/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/conference/paper525/AnonReviewer[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your question.", "value-regex": ".{1,500}"}, "question": {"order": 2, "description": "Your question", "value-regex": "[\\S\\s]{1,5000}"}}}, "nonreaders": [], "expdate": 1488517199000, "cdate": 1481269795334}}}], "count": 15}