{"notes": [{"id": "HJxqMhC5YQ", "original": "ryeTLW05FX", "number": 1289, "cdate": 1538087953696, "ddate": null, "tcdate": 1538087953696, "tmdate": 1545355380385, "tddate": null, "forum": "HJxqMhC5YQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "End-to-End Multi-Lingual Multi-Speaker Speech Recognition", "abstract": "The expressive power of end-to-end automatic speech recognition (ASR) systems enables direct estimation of the character or word label sequence from  a sequence of acoustic features. Direct optimization of the whole system is advantageous because it not only eliminates the internal linkage necessary for hybrid systems,  but also extends the scope of potential application use cases by training the model for multiple objectives. Several multi-lingual ASR systems were recently proposed based on a monolithic neural network architecture without language-dependent modules, showing that modeling of multiple languages is well within the capabilities of an end-to-end framework. There has also been growing interest in multi-speaker speech recognition, which enables generation of multiple label sequences from single-channel mixed speech. In particular, a multi-speaker end-to-end ASR system that can directly model one-to-many mappings without additional auxiliary clues was recently proposed. In this paper, we propose an all-in-one end-to-end multi-lingual multi-speaker ASR system that integrates the capabilities of these two systems.  The proposed model is evaluated using mixtures of two speakers generated by using 10 languages, including mixed-language utterances. ", "keywords": ["end-to-end ASR", "multi-lingual ASR", "multi-speaker ASR", "code-switching", "encoder-decoder", "connectionist temporal classification"], "authorids": ["seki@slp.cs.tut.ac.jp", "thori@merl.com", "shinjiw@ieee.org", "leilujp@gmail.com", "johnhershey@google.com"], "authors": ["Hiroshi Seki", "Takaaki Hori", "Shinji Watanabe", "Jonathan Le Roux", "John R. Hershey"], "pdf": "/pdf/5a2417c87058d260939b1619f5b703feeaf2e6b3.pdf", "paperhash": "seki|endtoend_multilingual_multispeaker_speech_recognition", "_bibtex": "@misc{\nseki2019endtoend,\ntitle={End-to-End Multi-Lingual Multi-Speaker Speech Recognition},\nauthor={Hiroshi Seki and Takaaki Hori and Shinji Watanabe and Jonathan Le Roux and John R. Hershey},\nyear={2019},\nurl={https://openreview.net/forum?id=HJxqMhC5YQ},\n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"replyCount": 4, "writable": false, "overwriting": [], "revisions": false, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Blind_Submission", "rdate": null, "ddate": null, "expdate": null, "duedate": 1538085600000, "tmdate": 1538142958393, "tddate": null, "super": null, "final": null, "reply": {"signatures": {"values": ["ICLR.cc/2019/Conference"]}, "forum": null, "readers": {"values": ["everyone"]}, "replyto": null, "content": {"authorids": {"values-regex": ".*"}, "authors": {"values": ["Anonymous"]}}, "writers": {"values": ["ICLR.cc/2019/Conference"]}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["~"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": null, "taskCompletionCount": null, "transform": null, "cdate": 1538142958393}}, "tauthor": "OpenReview.net"}, {"id": "SygVniYWgV", "original": null, "number": 1, "cdate": 1544817579999, "ddate": null, "tcdate": 1544817579999, "tmdate": 1545354529064, "tddate": null, "forum": "HJxqMhC5YQ", "replyto": "HJxqMhC5YQ", "invitation": "ICLR.cc/2019/Conference/-/Paper1289/Meta_Review", "content": {"metareview": "The authors present a system for end-to-end multi-lingual and multi-speaker speech recognition. The presented method is based on multiple prior works that propose end-to-end models for multi-lingual ASR and multi-speaker ASR; the work combines these techniques and shows that a single system can do both with minimal changes. \n\nThe main critique from the reviewers is that the paper lacks novelty. It builds heavily on existing work, and  does not make any enough contributions to be accepted at ICLR. Furthermore, training and evaluations are all on simulated test sets that are not very realistic. So it is unclear how well the techniques would generalize to real use-cases. For these reasons, the recommendation is to reject the paper.", "confidence": "5: The area chair is absolutely certain", "recommendation": "Reject", "title": "Limited novelty"}, "signatures": ["ICLR.cc/2019/Conference/Paper1289/Area_Chair1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference/Paper1289/Area_Chair1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "End-to-End Multi-Lingual Multi-Speaker Speech Recognition", "abstract": "The expressive power of end-to-end automatic speech recognition (ASR) systems enables direct estimation of the character or word label sequence from  a sequence of acoustic features. Direct optimization of the whole system is advantageous because it not only eliminates the internal linkage necessary for hybrid systems,  but also extends the scope of potential application use cases by training the model for multiple objectives. Several multi-lingual ASR systems were recently proposed based on a monolithic neural network architecture without language-dependent modules, showing that modeling of multiple languages is well within the capabilities of an end-to-end framework. There has also been growing interest in multi-speaker speech recognition, which enables generation of multiple label sequences from single-channel mixed speech. In particular, a multi-speaker end-to-end ASR system that can directly model one-to-many mappings without additional auxiliary clues was recently proposed. In this paper, we propose an all-in-one end-to-end multi-lingual multi-speaker ASR system that integrates the capabilities of these two systems.  The proposed model is evaluated using mixtures of two speakers generated by using 10 languages, including mixed-language utterances. ", "keywords": ["end-to-end ASR", "multi-lingual ASR", "multi-speaker ASR", "code-switching", "encoder-decoder", "connectionist temporal classification"], "authorids": ["seki@slp.cs.tut.ac.jp", "thori@merl.com", "shinjiw@ieee.org", "leilujp@gmail.com", "johnhershey@google.com"], "authors": ["Hiroshi Seki", "Takaaki Hori", "Shinji Watanabe", "Jonathan Le Roux", "John R. Hershey"], "pdf": "/pdf/5a2417c87058d260939b1619f5b703feeaf2e6b3.pdf", "paperhash": "seki|endtoend_multilingual_multispeaker_speech_recognition", "_bibtex": "@misc{\nseki2019endtoend,\ntitle={End-to-End Multi-Lingual Multi-Speaker Speech Recognition},\nauthor={Hiroshi Seki and Takaaki Hori and Shinji Watanabe and Jonathan Le Roux and John R. Hershey},\nyear={2019},\nurl={https://openreview.net/forum?id=HJxqMhC5YQ},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper1289/Meta_Review", "rdate": null, "ddate": null, "expdate": null, "duedate": 1541548800000, "tmdate": 1545352892693, "tddate": null, "super": null, "final": null, "reply": {"forum": "HJxqMhC5YQ", "replyto": "HJxqMhC5YQ", "readers": {"description": "Select all user groups that should be able to read this comment. Selecting 'All Users' will allow paper authors, reviewers, area chairs, and program chairs to view this comment.", "values": ["everyone"]}, "signatures": {"description": "How your identity will be displayed with the above content.", "values-regex": "ICLR.cc/2019/Conference/Paper1289/Area_Chair[0-9]+"}, "writers": {"description": "Users that may modify this record.", "values-regex": "ICLR.cc/2019/Conference/Paper1289/Area_Chair[0-9]+"}, "content": {"title": {"order": 1, "value-regex": ".{1,500}", "description": "Brief summary of your review.", "required": true}, "metareview": {"order": 2, "value-regex": "[\\S\\s]{1,5000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "required": true}, "recommendation": {"order": 3, "value-dropdown": ["Accept (Oral)", "Accept (Poster)", "Reject"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The area chair is absolutely certain", "4: The area chair is confident but not absolutely certain", "3: The area chair is somewhat confident", "2: The area chair is not sure", "1: The area chair's evaluation is an educated guess"], "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper1289/Area_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": false, "taskCompletionCount": null, "transform": null, "cdate": 1545352892693}}}, {"id": "HkeUS1ulpm", "original": null, "number": 3, "cdate": 1541599038116, "ddate": null, "tcdate": 1541599038116, "tmdate": 1541599038116, "tddate": null, "forum": "HJxqMhC5YQ", "replyto": "HJxqMhC5YQ", "invitation": "ICLR.cc/2019/Conference/-/Paper1289/Official_Review", "content": {"title": "not enough novelty", "review": "This paper presents an end-to-end system that can recognize single-channel multiple-speaker speech with multiple languages.\n\nPros:\n- The paper is well written.\n- It shows the existing end-to-end multi-lingual ASR (Seki et al., 2018b) and end-to-end multi-speaker ASR (Seki et al., 2018a) techniques can be combined without any change to achieve reasonable performance.\n- It demonstrates the challenge of single-channel multi-lingual multiple-speaker speech recognition, and compares the performance of the multiple-speaker system on the mixed speech and the single-speaker system on the isolated speech.\n\nCons:\n- It lacks novelty: the proposed framework just simply combines the two existing techniques as mentioned above.\n- The training and evaluation data are both artificially created by randomly concatenating utterances with different languages from different speakers with different context. I am not sure of how useful the evaluation is, since this situation is not realistic. Also, currently it cannot test the real code-switching since the utterances are not related and not from the same speaker.\n- There are not enough analyses. E.g. it would be good to analyze what contributes to the gap between the single-speaker ASR system performance on the isolated speech and the multi-lingual multi-speaker ASR system on the mixed speech. How well does the proposed end-to-end framework perform compared to a two-step framework with speaker separation followed by multi-lingual single-speaker ASR?", "rating": "3: Clear rejection", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["ICLR.cc/2019/Conference/Paper1289/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "End-to-End Multi-Lingual Multi-Speaker Speech Recognition", "abstract": "The expressive power of end-to-end automatic speech recognition (ASR) systems enables direct estimation of the character or word label sequence from  a sequence of acoustic features. Direct optimization of the whole system is advantageous because it not only eliminates the internal linkage necessary for hybrid systems,  but also extends the scope of potential application use cases by training the model for multiple objectives. Several multi-lingual ASR systems were recently proposed based on a monolithic neural network architecture without language-dependent modules, showing that modeling of multiple languages is well within the capabilities of an end-to-end framework. There has also been growing interest in multi-speaker speech recognition, which enables generation of multiple label sequences from single-channel mixed speech. In particular, a multi-speaker end-to-end ASR system that can directly model one-to-many mappings without additional auxiliary clues was recently proposed. In this paper, we propose an all-in-one end-to-end multi-lingual multi-speaker ASR system that integrates the capabilities of these two systems.  The proposed model is evaluated using mixtures of two speakers generated by using 10 languages, including mixed-language utterances. ", "keywords": ["end-to-end ASR", "multi-lingual ASR", "multi-speaker ASR", "code-switching", "encoder-decoder", "connectionist temporal classification"], "authorids": ["seki@slp.cs.tut.ac.jp", "thori@merl.com", "shinjiw@ieee.org", "leilujp@gmail.com", "johnhershey@google.com"], "authors": ["Hiroshi Seki", "Takaaki Hori", "Shinji Watanabe", "Jonathan Le Roux", "John R. Hershey"], "pdf": "/pdf/5a2417c87058d260939b1619f5b703feeaf2e6b3.pdf", "paperhash": "seki|endtoend_multilingual_multispeaker_speech_recognition", "_bibtex": "@misc{\nseki2019endtoend,\ntitle={End-to-End Multi-Lingual Multi-Speaker Speech Recognition},\nauthor={Hiroshi Seki and Takaaki Hori and Shinji Watanabe and Jonathan Le Roux and John R. Hershey},\nyear={2019},\nurl={https://openreview.net/forum?id=HJxqMhC5YQ},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper1289/Official_Review", "cdate": 1542234262746, "expdate": 1552335264000, "duedate": 1541196000000, "reply": {"forum": "HJxqMhC5YQ", "replyto": "HJxqMhC5YQ", "readers": {"description": "The users who will be allowed to read the reply content.", "values": ["everyone"]}, "nonreaders": {"values": []}, "signatures": {"description": "How your identity will be displayed with the above content.", "values-regex": "ICLR.cc/2019/Conference/Paper1289/AnonReviewer[0-9]+"}, "writers": {"description": "Users that may modify this record.", "values": ["ICLR.cc/2019/Conference"]}, "content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "required": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}}, "multiReply": false, "tcdate": 1552335914128, "tmdate": 1552335914128, "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "invitees": ["ICLR.cc/2019/Conference/Paper1289/Reviewers"], "noninvitees": [], "signatures": ["ICLR.cc/2019/Conference"]}}}, {"id": "H1gjdIl93m", "original": null, "number": 2, "cdate": 1541174898786, "ddate": null, "tcdate": 1541174898786, "tmdate": 1541533264439, "tddate": null, "forum": "HJxqMhC5YQ", "replyto": "HJxqMhC5YQ", "invitation": "ICLR.cc/2019/Conference/-/Paper1289/Official_Review", "content": {"title": "Applying known techniques to a non problem", "review": "The authors propose to build a speech recognition system that has been trained to recognize a recording that has been produced by mixing multiple recordings from different languages together, and allowing for some code switching (also done artificially by concatenating different recordings).\n\nWhile this sounds fancy and like a hard problem, it is in fact easier than recognizing two speakers that have been mixed together speaking the same language, which has already been solved in (Seki, 2018a), from what I can tell. I don't see any contribution in this paper, other than explaining how to create an artificial (un-realistic) database of mixed speech in multiple languages, and then training a multi-speaker end-to-end speech recognition system on that database.\n", "rating": "3: Clear rejection", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}, "signatures": ["ICLR.cc/2019/Conference/Paper1289/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "End-to-End Multi-Lingual Multi-Speaker Speech Recognition", "abstract": "The expressive power of end-to-end automatic speech recognition (ASR) systems enables direct estimation of the character or word label sequence from  a sequence of acoustic features. Direct optimization of the whole system is advantageous because it not only eliminates the internal linkage necessary for hybrid systems,  but also extends the scope of potential application use cases by training the model for multiple objectives. Several multi-lingual ASR systems were recently proposed based on a monolithic neural network architecture without language-dependent modules, showing that modeling of multiple languages is well within the capabilities of an end-to-end framework. There has also been growing interest in multi-speaker speech recognition, which enables generation of multiple label sequences from single-channel mixed speech. In particular, a multi-speaker end-to-end ASR system that can directly model one-to-many mappings without additional auxiliary clues was recently proposed. In this paper, we propose an all-in-one end-to-end multi-lingual multi-speaker ASR system that integrates the capabilities of these two systems.  The proposed model is evaluated using mixtures of two speakers generated by using 10 languages, including mixed-language utterances. ", "keywords": ["end-to-end ASR", "multi-lingual ASR", "multi-speaker ASR", "code-switching", "encoder-decoder", "connectionist temporal classification"], "authorids": ["seki@slp.cs.tut.ac.jp", "thori@merl.com", "shinjiw@ieee.org", "leilujp@gmail.com", "johnhershey@google.com"], "authors": ["Hiroshi Seki", "Takaaki Hori", "Shinji Watanabe", "Jonathan Le Roux", "John R. Hershey"], "pdf": "/pdf/5a2417c87058d260939b1619f5b703feeaf2e6b3.pdf", "paperhash": "seki|endtoend_multilingual_multispeaker_speech_recognition", "_bibtex": "@misc{\nseki2019endtoend,\ntitle={End-to-End Multi-Lingual Multi-Speaker Speech Recognition},\nauthor={Hiroshi Seki and Takaaki Hori and Shinji Watanabe and Jonathan Le Roux and John R. Hershey},\nyear={2019},\nurl={https://openreview.net/forum?id=HJxqMhC5YQ},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper1289/Official_Review", "cdate": 1542234262746, "expdate": 1552335264000, "duedate": 1541196000000, "reply": {"forum": "HJxqMhC5YQ", "replyto": "HJxqMhC5YQ", "readers": {"description": "The users who will be allowed to read the reply content.", "values": ["everyone"]}, "nonreaders": {"values": []}, "signatures": {"description": "How your identity will be displayed with the above content.", "values-regex": "ICLR.cc/2019/Conference/Paper1289/AnonReviewer[0-9]+"}, "writers": {"description": "Users that may modify this record.", "values": ["ICLR.cc/2019/Conference"]}, "content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "required": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}}, "multiReply": false, "tcdate": 1552335914128, "tmdate": 1552335914128, "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "invitees": ["ICLR.cc/2019/Conference/Paper1289/Reviewers"], "noninvitees": [], "signatures": ["ICLR.cc/2019/Conference"]}}}, {"id": "rklQVnJK3X", "original": null, "number": 1, "cdate": 1541106730567, "ddate": null, "tcdate": 1541106730567, "tmdate": 1541533264236, "tddate": null, "forum": "HJxqMhC5YQ", "replyto": "HJxqMhC5YQ", "invitation": "ICLR.cc/2019/Conference/-/Paper1289/Official_Review", "content": {"title": "Interesting but not good enough!", "review": "This paper presents a framework to train an end-to-end multi-lingual multi-speaker speech recognition system. Overall, the paper is quite clear written.\n- Strengthens:\n+ Experimental results show consistent improvements in speech recognition performance and language identification performance.\n\n- Weakness:\n+ I'm not sure whether the framework is novel. The authors have just mixed training data from several languages to train an end-to-end multi-speaker speech recognition system.\n+ I don't see the real motivation why the authors want to make the task harder than needed. The example provided in figure 1 is very rare in reality.\n+ The authors claimed that their system can recognise code-switching but actually randomly mixing data from different languages are not code-switching.\n+ In general, it would be better to have some more analyses showing what the system can do and why.", "rating": "3: Clear rejection", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["ICLR.cc/2019/Conference/Paper1289/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "End-to-End Multi-Lingual Multi-Speaker Speech Recognition", "abstract": "The expressive power of end-to-end automatic speech recognition (ASR) systems enables direct estimation of the character or word label sequence from  a sequence of acoustic features. Direct optimization of the whole system is advantageous because it not only eliminates the internal linkage necessary for hybrid systems,  but also extends the scope of potential application use cases by training the model for multiple objectives. Several multi-lingual ASR systems were recently proposed based on a monolithic neural network architecture without language-dependent modules, showing that modeling of multiple languages is well within the capabilities of an end-to-end framework. There has also been growing interest in multi-speaker speech recognition, which enables generation of multiple label sequences from single-channel mixed speech. In particular, a multi-speaker end-to-end ASR system that can directly model one-to-many mappings without additional auxiliary clues was recently proposed. In this paper, we propose an all-in-one end-to-end multi-lingual multi-speaker ASR system that integrates the capabilities of these two systems.  The proposed model is evaluated using mixtures of two speakers generated by using 10 languages, including mixed-language utterances. ", "keywords": ["end-to-end ASR", "multi-lingual ASR", "multi-speaker ASR", "code-switching", "encoder-decoder", "connectionist temporal classification"], "authorids": ["seki@slp.cs.tut.ac.jp", "thori@merl.com", "shinjiw@ieee.org", "leilujp@gmail.com", "johnhershey@google.com"], "authors": ["Hiroshi Seki", "Takaaki Hori", "Shinji Watanabe", "Jonathan Le Roux", "John R. Hershey"], "pdf": "/pdf/5a2417c87058d260939b1619f5b703feeaf2e6b3.pdf", "paperhash": "seki|endtoend_multilingual_multispeaker_speech_recognition", "_bibtex": "@misc{\nseki2019endtoend,\ntitle={End-to-End Multi-Lingual Multi-Speaker Speech Recognition},\nauthor={Hiroshi Seki and Takaaki Hori and Shinji Watanabe and Jonathan Le Roux and John R. Hershey},\nyear={2019},\nurl={https://openreview.net/forum?id=HJxqMhC5YQ},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper1289/Official_Review", "cdate": 1542234262746, "expdate": 1552335264000, "duedate": 1541196000000, "reply": {"forum": "HJxqMhC5YQ", "replyto": "HJxqMhC5YQ", "readers": {"description": "The users who will be allowed to read the reply content.", "values": ["everyone"]}, "nonreaders": {"values": []}, "signatures": {"description": "How your identity will be displayed with the above content.", "values-regex": "ICLR.cc/2019/Conference/Paper1289/AnonReviewer[0-9]+"}, "writers": {"description": "Users that may modify this record.", "values": ["ICLR.cc/2019/Conference"]}, "content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "required": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}}, "multiReply": false, "tcdate": 1552335914128, "tmdate": 1552335914128, "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "invitees": ["ICLR.cc/2019/Conference/Paper1289/Reviewers"], "noninvitees": [], "signatures": ["ICLR.cc/2019/Conference"]}}}], "count": 5}