{"notes": [{"id": "fV2ScEA03Hg", "original": "rTaw6w21I9s", "number": 3100, "cdate": 1601308344000, "ddate": null, "tcdate": 1601308344000, "tmdate": 1614985733334, "tddate": null, "forum": "fV2ScEA03Hg", "replyto": null, "invitation": "ICLR.cc/2021/Conference/-/Blind_Submission", "content": {"title": "AutoCleansing: Unbiased Estimation of Deep Learning with Mislabeled Data", "authorids": ["~Koichi_Kuriyama1"], "authors": ["Koichi Kuriyama"], "keywords": ["Automatic Data Cleansing", "Incorrect Labels", "Multiple Objects"], "abstract": "Mislabeled samples cause prediction errors. This study proposes a solution to the problem of incorrect labels, called AutoCleansing, to automatically capture the effect of incorrect labels and mitigate it without removing the mislabeled samples. AutoCleansing consists of a base network model and sample-category specific constants. Both parameters of the base model and sample-category constants are estimated simultaneously using the training data. Thereafter, predictions for test data are made using a base model without the constants capturing the mislabeled effects. A theoretical model for AutoCleansing is developed and showing that the gradient of the loss function of the proposed method can be zero at true parameters with mislabeled data if the model is correctly constructed.  Experimental results show that AutoCleansing has better performance in test accuracy than previous studies for CIFAR-10, CIFAR-100, SVHN, and ImageNet datasets.", "one-sentence_summary": "AutoCleansing can capture the effect of incorrect labels and mitigate it without removing the mislabeled samples. ", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "kuriyama|autocleansing_unbiased_estimation_of_deep_learning_with_mislabeled_data", "pdf": "/pdf/3b5902797c2072fc5c0be807ea4b660fd02763a2.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=Ia6A34pNtV", "_bibtex": "@misc{\nkuriyama2021autocleansing,\ntitle={AutoCleansing: Unbiased Estimation of Deep Learning with Mislabeled Data},\nauthor={Koichi Kuriyama},\nyear={2021},\nurl={https://openreview.net/forum?id=fV2ScEA03Hg}\n}"}, "signatures": ["ICLR.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference"], "details": {"replyCount": 12, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"reply": {"readers": {"values-regex": ".*"}, "writers": {"values": ["ICLR.cc/2021/Conference"]}, "signatures": {"values": ["ICLR.cc/2021/Conference"]}, "content": {"authors": {"values": ["Anonymous"]}, "authorids": {"values-regex": ".*"}, "reviewed_version_(pdf)": {"required": false, "description": "Upload a PDF file that ends with .pdf", "value-regex": ".*"}}}, "signatures": ["ICLR.cc/2021/Conference"], "readers": ["everyone"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["~", "OpenReview.net/Support"], "tcdate": 1601308008205, "tmdate": 1614984599368, "id": "ICLR.cc/2021/Conference/-/Blind_Submission"}}, "tauthor": "OpenReview.net"}, {"id": "mNXP2e_QOS", "original": null, "number": 1, "cdate": 1610040405587, "ddate": null, "tcdate": 1610040405587, "tmdate": 1610474002133, "tddate": null, "forum": "fV2ScEA03Hg", "replyto": "fV2ScEA03Hg", "invitation": "ICLR.cc/2021/Conference/Paper3100/-/Decision", "content": {"title": "Final Decision", "decision": "Reject", "comment": "The paper addresses learning with noisy labels, by detecting and correcting samples with noisy labels. Reviewers had concerns about the empirical evaluations, specifically about comparing to additional methods, about hyperparameter tuning, and about the improvements being vey small. There was also a concern that the analysis of the objective does not take into account explicitly the L2 regularization induced by weight decay. Based on these concerns the paper is not ready yet for publication.\n\n\n"}, "signatures": ["ICLR.cc/2021/Conference/Program_Chairs"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference/Program_Chairs"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "AutoCleansing: Unbiased Estimation of Deep Learning with Mislabeled Data", "authorids": ["~Koichi_Kuriyama1"], "authors": ["Koichi Kuriyama"], "keywords": ["Automatic Data Cleansing", "Incorrect Labels", "Multiple Objects"], "abstract": "Mislabeled samples cause prediction errors. This study proposes a solution to the problem of incorrect labels, called AutoCleansing, to automatically capture the effect of incorrect labels and mitigate it without removing the mislabeled samples. AutoCleansing consists of a base network model and sample-category specific constants. Both parameters of the base model and sample-category constants are estimated simultaneously using the training data. Thereafter, predictions for test data are made using a base model without the constants capturing the mislabeled effects. A theoretical model for AutoCleansing is developed and showing that the gradient of the loss function of the proposed method can be zero at true parameters with mislabeled data if the model is correctly constructed.  Experimental results show that AutoCleansing has better performance in test accuracy than previous studies for CIFAR-10, CIFAR-100, SVHN, and ImageNet datasets.", "one-sentence_summary": "AutoCleansing can capture the effect of incorrect labels and mitigate it without removing the mislabeled samples. ", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "kuriyama|autocleansing_unbiased_estimation_of_deep_learning_with_mislabeled_data", "pdf": "/pdf/3b5902797c2072fc5c0be807ea4b660fd02763a2.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=Ia6A34pNtV", "_bibtex": "@misc{\nkuriyama2021autocleansing,\ntitle={AutoCleansing: Unbiased Estimation of Deep Learning with Mislabeled Data},\nauthor={Koichi Kuriyama},\nyear={2021},\nurl={https://openreview.net/forum?id=fV2ScEA03Hg}\n}"}, "tags": [], "invitation": {"reply": {"forum": "fV2ScEA03Hg", "replyto": "fV2ScEA03Hg", "readers": {"values": ["everyone"]}, "writers": {"values": ["ICLR.cc/2021/Conference/Program_Chairs"]}, "signatures": {"values": ["ICLR.cc/2021/Conference/Program_Chairs"]}, "content": {"title": {"value": "Final Decision"}, "decision": {"value-radio": ["Accept (Oral)", "Accept (Spotlight)", "Accept (Poster)", "Reject"]}, "comment": {"value-regex": "[\\S\\s]{0,50000}", "markdown": true}}}, "multiReply": false, "signatures": ["ICLR.cc/2021/Conference"], "readers": ["everyone"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Program_Chairs"], "tcdate": 1610040405572, "tmdate": 1610474002115, "id": "ICLR.cc/2021/Conference/Paper3100/-/Decision"}}}, {"id": "BeTHTeZWNiC", "original": null, "number": 1, "cdate": 1603596787580, "ddate": null, "tcdate": 1603596787580, "tmdate": 1607249674444, "tddate": null, "forum": "fV2ScEA03Hg", "replyto": "fV2ScEA03Hg", "invitation": "ICLR.cc/2021/Conference/Paper3100/-/Official_Review", "content": {"title": "Serious Flaw in Problem Formulation and Subsequent Theorems", "review": "### Paper Summary\n\nIn this paper, the authors proposed to train high quality classifiers from datasets with some mislabels.\n\nFor this purpose, the authors considered adjusting the softmax prediction using an additional term $\\alpha$ as follows:\n$$\nP^C(i | x; \\theta) = \\frac{\\exp(m_i(x; \\theta) + \\alpha_i(x))}{\\sum_j \\exp(m_j(x; \\theta) + \\alpha_j(x))}\n$$\nwhere $m(\\cdot; \\theta)$ is a model and $\\theta$ is its parameter.\nThe authors claimed that, by adjusting $\\alpha$ through training, the trained model $m(\\cdot; \\hat{\\theta})$ with an optimal parameter $\\hat{\\theta}$ is asymptotically consistent with the model trained on a dataset with clean labels, i.e.,  the trained model without $\\alpha$ performs well on clean test data\n$$\nP(i | x; \\theta) =\\frac{\\exp(m_i(x; \\theta))}{\\sum_j \\exp(m_j(x; \\theta))}\n$$\nIn the proposed method, for the training set $D = \\\\{x_n, y_n \\\\}$, we first train the model by minimizing the following loss function:\n$$\n\\hat{\\theta}, \\hat{\\alpha} = \\arg\\min_{\\theta \\in \\Theta, \\alpha \\in \\mathbb{R}^{N \\times K}} -\\frac{1}{N} \\sum_{n=1}^N \\sum_{i=1}^K 1[y_n = i] \\log \\frac{\\exp(m_i(x_n; \\theta) + \\alpha_{ni})}{\\sum_j \\exp(m_j(x_n; \\theta) + \\alpha_{nj})}\n$$\nwhere $K$ is the number of classes. We then classify the new instance $x$ by $\\hat{y} =\\arg\\max_i m_i(x; \\hat{\\theta})$.\n\nIn Theorem 1, the authors claimed that the above estimator $\\hat{\\theta}$ converges to the *true* parameter $\\theta^*$.\n\n\n\n### Pros & Cons\n\n[Pros]\n\nThe experimental results indicate that the proposed method is effective on several datasets.\n\n[Cons]\n\nThe paper contains a serious flaw in its problem formulation and the subsequent theorems. The proposed problem formulation has a trivial solution which is completely useless. The effectiveness reported in the experiments seems to be just an artifact caused by the tunings of hyperparameters. See my comments in \"Quality\" below for the detail.\n\n\n\n### Quality\n\nThe paper contains a serious flaw in its problem formulation.\n\nRecall the training problem:\n$$\n\\hat{\\theta}, \\hat{\\alpha} = \\arg\\min_{\\theta \\in \\Theta, \\alpha \\in \\mathbb{R}^{N \\times K}} -\\frac{1}{N} \\sum_{n=1}^N \\sum_{i=1}^K 1[y_n = i] \\log \\frac{\\exp(m_i(x_n; \\theta) + \\alpha_{ni})}{\\sum_j \\exp(m_j(x_n; \\theta) + \\alpha_{nj})}\n$$\nThis problem has a trivial solution that $\\alpha_{n y_n} \\to +\\infty$ for $\\forall n$, which leads to\n$$\n\\frac{\\exp(m_i(x_n; \\theta) + \\alpha_{ni})}{\\sum_j \\exp(m_j(x_n; \\theta) + \\alpha_{nj})} \\to\n\\delta(y_n = i)\n$$\nwhere $\\delta(y_n = i) = 1$ if $y_n=i$ and 0 otherwise.\nNote that this trivial solution does not depend on the model $m(\\cdot; \\theta)$. Thus, any parameter $\\theta$ can be an optimal solution $\\hat{\\theta}$ as long as $m(\\cdot ;\\theta)$ is finite.\n\nThe above observation indicates that the proposed method do not work as expected if the training problem is solved appropriately. Thus, I conjecture that the good performances reported in the experiments are the artifact caused by the tuning of hyperparameters, e.g., the training converged to local optima that occasionally performed well.\n\nNote that the above observation on the training problem also suggests that the claim of Theorem 1 (the estimator $\\hat{\\theta}$ converges to the *true* parameter $\\theta^*$) is not correct.\n\nIn the proof, the authors considered the following objective function:\n$$\nL^C(\\theta, \\alpha) = - \\mathbb{E} \\sum_{i=1}^K \\left[ \\sum_{k=1}^K \\pi(i | k, x) P(k | x, \\theta^*) \\log P^C(i | x, \\theta) \\right]\n$$\nLet $U(i | x, \\theta^*) = \\sum_{k=1}^K \\pi(i | k, x) P(k | x, \\theta^*)$. We then have\n$$\nL^C(\\theta, \\alpha) = - \\mathbb{E} \\sum_{i=1}^K U(i | x, \\theta^*) \\log \\frac{\\exp(m_i(x; \\theta) + \\alpha_i(x))}{\\sum_j \\exp(m_j(x; \\theta) + \\alpha_j(x))}\n$$\nBy taking the derivative with respect to $\\omega \\in \\\\{\\theta, \\alpha\\\\}$, we have\n$$\n\\frac{\\partial L^C(\\theta, \\alpha)}{\\partial \\omega} = - \\mathbb{E} \\sum_{i=1}^K U(i | x, \\theta^*)\\left( \\frac{\\partial (m_i(x; \\theta) + \\alpha_i(x))}{\\partial \\omega} - \\sum_{k=1}^K \\frac{\\exp(m_k(x; \\theta) + \\alpha_k(x))}{\\sum_j \\exp(m_j(x; \\theta) + \\alpha_j(x))} \\frac{\\partial (m_k(x; \\theta) + \\alpha_k(x))}{\\partial \\omega} \\right) \\\\\n= - \\mathbb{E} \\sum_{i=1}^K \\left( U(i | x, \\theta^*) - \\frac{\\exp(m_i(x; \\theta) + \\alpha_i(x))}{\\sum_j \\exp(m_j(x; \\theta) + \\alpha_j(x))} \\right) \\frac{\\partial (m_i(x; \\theta) + \\alpha_i(x))}{\\partial \\omega}\n$$\nThus, any $\\theta, \\alpha$ that satisfy $U(i | x, \\theta^*) = \\frac{\\exp(m_i(x; \\theta) + \\alpha_i(x))}{\\sum_j \\exp(m_j(x; \\theta) + \\alpha_j(x))}$ are optimal.\n\nIn the proof of Theorem 1, the authors only considered a specific $\\alpha$, and overlooked the existence of other $\\alpha$ that are equally optimal, which led to the wrong claim that $\\hat{\\theta}$ converges to $\\theta^*$.\n\n\n\n### Clarity\n\nApart from the serious flaw above, I think the paper is clearly written and the main claim of the paper is easy to follow.\n\n\n\n### Originality\n\nThe use of the adjustable parameters for fitting noisy data is studied in the literature of robust learning. I would like to suggest the authors to see [Ref1] and references therein. In [Ref1], an additional penalty is imposed on the adjustable parameter to avoid the trivial solution I raised above.\n\n[Ref1] Consistent Robust Regression, NeurIPS17.\n\n\n\n### Significance\n\nBecause of the flaw I raised above, I think the contribution of this paper is not significant.\n\n\n----------\n### Feedback after discussion\n\nI would like to clarify my thought here. Recall that using the weight decay is equivalent to adding the L2 regularization to the training objective. An important observation here is that the addition of the L2 regularization to the proposed objective will make the global optima non-trivial (apart from the trivial ones I raised), and there might be a hope that the new global optima has some useful properties. What this observation indicates is that the use of the L2 regularization (or weight decay) is an essential factor for the proposed method to output something meaningful. This fact also implies that the analysis of the objective function alone (without the regularization, in Section3) is no longer meaningful. Moreover, because the L2 regularization (or weight decay) is an essential factor, the tuning of its weight should have a major impact to the resulting model. I therefore think it will be important to investigate the effect of such a weight in the experiments, instead of just using a standard weight.", "rating": "3: Clear rejection", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}, "signatures": ["ICLR.cc/2021/Conference/Paper3100/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper3100/AnonReviewer2"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "AutoCleansing: Unbiased Estimation of Deep Learning with Mislabeled Data", "authorids": ["~Koichi_Kuriyama1"], "authors": ["Koichi Kuriyama"], "keywords": ["Automatic Data Cleansing", "Incorrect Labels", "Multiple Objects"], "abstract": "Mislabeled samples cause prediction errors. This study proposes a solution to the problem of incorrect labels, called AutoCleansing, to automatically capture the effect of incorrect labels and mitigate it without removing the mislabeled samples. AutoCleansing consists of a base network model and sample-category specific constants. Both parameters of the base model and sample-category constants are estimated simultaneously using the training data. Thereafter, predictions for test data are made using a base model without the constants capturing the mislabeled effects. A theoretical model for AutoCleansing is developed and showing that the gradient of the loss function of the proposed method can be zero at true parameters with mislabeled data if the model is correctly constructed.  Experimental results show that AutoCleansing has better performance in test accuracy than previous studies for CIFAR-10, CIFAR-100, SVHN, and ImageNet datasets.", "one-sentence_summary": "AutoCleansing can capture the effect of incorrect labels and mitigate it without removing the mislabeled samples. ", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "kuriyama|autocleansing_unbiased_estimation_of_deep_learning_with_mislabeled_data", "pdf": "/pdf/3b5902797c2072fc5c0be807ea4b660fd02763a2.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=Ia6A34pNtV", "_bibtex": "@misc{\nkuriyama2021autocleansing,\ntitle={AutoCleansing: Unbiased Estimation of Deep Learning with Mislabeled Data},\nauthor={Koichi Kuriyama},\nyear={2021},\nurl={https://openreview.net/forum?id=fV2ScEA03Hg}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq . ***Please remember to file the Code-of-Ethics report. Once you submitted the review, a link to the report will be visible in the bottom right corner of your review.***", "required": true, "markdown": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}, "forum": "fV2ScEA03Hg", "replyto": "fV2ScEA03Hg", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"], "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper3100/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1607428800000, "duedate": 1606752000000, "multiReply": false, "readers": ["everyone"], "tcdate": 1602538082335, "tmdate": 1606915774161, "super": "ICLR.cc/2021/Conference/-/Official_Review", "signatures": ["OpenReview.net"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Paper3100/Reviewers", "OpenReview.net/Support"], "id": "ICLR.cc/2021/Conference/Paper3100/-/Official_Review"}}}, {"id": "qEO0ICSTWeH", "original": null, "number": 8, "cdate": 1606225669935, "ddate": null, "tcdate": 1606225669935, "tmdate": 1606230747363, "tddate": null, "forum": "fV2ScEA03Hg", "replyto": "6Fhx9M9mOwS", "invitation": "ICLR.cc/2021/Conference/Paper3100/-/Official_Comment", "content": {"title": "Local minima are no longer considered to be a serious problem for neural network optimization", "comment": "Thank you for additional comments for my revised paper.\n \n> What is the justification of preferring a local optima rather than the global optima?\n\nRecent theoretical and empirical results strongly suggest that local minima are no longer considered to be a serious problem for neural network optimization (LeCun et al., 2015; Goodfellow et al., 2016, p529). In this study, I have confirmed the very similar results for five runs with different initial values using the CIFAR-10/100 datasets. Furthermore, the weight decay is a standard procedure to avoid over-fitting in the neural network models.\n\nYann LeCun , Yoshua Bengio, and Geoffrey Hinton (2015) Deep Learning. Nature\n\nIan Goodfellow, Yoshua Bengio, and Aaron Courville Goodfellow (2016) Deep Learning. MIT Press.\n\n> I briefly checked the revision, and found Theorem 1 is still not appropriate. There is no definition what \"minimized locally\" stands for.\n\nFollowing your suggestion, I have removed the description \u201cminimized locally\u201d and revised the Theorem 1, as the gradient of the expected loss function with AutoCleansing is zero at the true parameter value.\n\n> Hence, the only thing what we might be able to claim would be $\\theta, \\alpha \\in \\Theta^*$ as $N \\mathrm{\\to \\infty }$\n\nFollowing your comments, I have added the description of $\\theta^* \\in \\theta^+$ in Theorem 1, where $\\theta^+$ is the set of the solution to ${\\partial L^C}/ {\\partial \\theta} = 0$.  \n\n\nYour comments are very helpfull to clarify the description of the theoretical section of my paper. \nThanks again."}, "signatures": ["ICLR.cc/2021/Conference/Paper3100/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper3100/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "AutoCleansing: Unbiased Estimation of Deep Learning with Mislabeled Data", "authorids": ["~Koichi_Kuriyama1"], "authors": ["Koichi Kuriyama"], "keywords": ["Automatic Data Cleansing", "Incorrect Labels", "Multiple Objects"], "abstract": "Mislabeled samples cause prediction errors. This study proposes a solution to the problem of incorrect labels, called AutoCleansing, to automatically capture the effect of incorrect labels and mitigate it without removing the mislabeled samples. AutoCleansing consists of a base network model and sample-category specific constants. Both parameters of the base model and sample-category constants are estimated simultaneously using the training data. Thereafter, predictions for test data are made using a base model without the constants capturing the mislabeled effects. A theoretical model for AutoCleansing is developed and showing that the gradient of the loss function of the proposed method can be zero at true parameters with mislabeled data if the model is correctly constructed.  Experimental results show that AutoCleansing has better performance in test accuracy than previous studies for CIFAR-10, CIFAR-100, SVHN, and ImageNet datasets.", "one-sentence_summary": "AutoCleansing can capture the effect of incorrect labels and mitigate it without removing the mislabeled samples. ", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "kuriyama|autocleansing_unbiased_estimation_of_deep_learning_with_mislabeled_data", "pdf": "/pdf/3b5902797c2072fc5c0be807ea4b660fd02763a2.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=Ia6A34pNtV", "_bibtex": "@misc{\nkuriyama2021autocleansing,\ntitle={AutoCleansing: Unbiased Estimation of Deep Learning with Mislabeled Data},\nauthor={Koichi Kuriyama},\nyear={2021},\nurl={https://openreview.net/forum?id=fV2ScEA03Hg}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "fV2ScEA03Hg", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper3100/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper3100/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper3100/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper3100/Authors|ICLR.cc/2021/Conference/Paper3100/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper3100/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923841147, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper3100/-/Official_Comment"}}}, {"id": "LHbP4Luq5z", "original": null, "number": 10, "cdate": 1606230552903, "ddate": null, "tcdate": 1606230552903, "tmdate": 1606230552903, "tddate": null, "forum": "fV2ScEA03Hg", "replyto": "fV2ScEA03Hg", "invitation": "ICLR.cc/2021/Conference/Paper3100/-/Official_Comment", "content": {"title": "Summary of Revision", "comment": "Thank you for numerous helpful and constructive comments of my paper. A summary of major updates of the revision is as follows:\n\n1. The critical reviews of related works have been added in section 2.\n2. The description of the local minimum in Theorem 1 is revised as the gradient of the expected loss function with AutoCleansing is zero at the true parameter value.\n3. Table 1 has been introduced to illustrate the theorems using the numerical examples.\n4. The comparison with AUM (the area under the margin) for learning with noisy labels has been added (Table 6). AutoCleansing demonstrates outperforming the AUM on both CIFAR-10 and CIFAR-100.\n"}, "signatures": ["ICLR.cc/2021/Conference/Paper3100/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper3100/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "AutoCleansing: Unbiased Estimation of Deep Learning with Mislabeled Data", "authorids": ["~Koichi_Kuriyama1"], "authors": ["Koichi Kuriyama"], "keywords": ["Automatic Data Cleansing", "Incorrect Labels", "Multiple Objects"], "abstract": "Mislabeled samples cause prediction errors. This study proposes a solution to the problem of incorrect labels, called AutoCleansing, to automatically capture the effect of incorrect labels and mitigate it without removing the mislabeled samples. AutoCleansing consists of a base network model and sample-category specific constants. Both parameters of the base model and sample-category constants are estimated simultaneously using the training data. Thereafter, predictions for test data are made using a base model without the constants capturing the mislabeled effects. A theoretical model for AutoCleansing is developed and showing that the gradient of the loss function of the proposed method can be zero at true parameters with mislabeled data if the model is correctly constructed.  Experimental results show that AutoCleansing has better performance in test accuracy than previous studies for CIFAR-10, CIFAR-100, SVHN, and ImageNet datasets.", "one-sentence_summary": "AutoCleansing can capture the effect of incorrect labels and mitigate it without removing the mislabeled samples. ", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "kuriyama|autocleansing_unbiased_estimation_of_deep_learning_with_mislabeled_data", "pdf": "/pdf/3b5902797c2072fc5c0be807ea4b660fd02763a2.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=Ia6A34pNtV", "_bibtex": "@misc{\nkuriyama2021autocleansing,\ntitle={AutoCleansing: Unbiased Estimation of Deep Learning with Mislabeled Data},\nauthor={Koichi Kuriyama},\nyear={2021},\nurl={https://openreview.net/forum?id=fV2ScEA03Hg}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "fV2ScEA03Hg", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper3100/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper3100/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper3100/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper3100/Authors|ICLR.cc/2021/Conference/Paper3100/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper3100/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923841147, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper3100/-/Official_Comment"}}}, {"id": "6Fhx9M9mOwS", "original": null, "number": 7, "cdate": 1606040933106, "ddate": null, "tcdate": 1606040933106, "tmdate": 1606040933106, "tddate": null, "forum": "fV2ScEA03Hg", "replyto": "EjDVUVCQpL", "invitation": "ICLR.cc/2021/Conference/Paper3100/-/Official_Comment", "content": {"title": "What is the justification of preferring a local optima rather than the global optima?", "comment": "### Major concern is not resolved.\n\nAs I pointed out in my review, the global optima of the proposed training objective is useless.\nThe question is why we need to train models using such a flawed objective.\nI understand that the authors used weight decay to avoid global optima, which might have led to a better local optima.\nThat is, we should not globally optimize the objective, and we instead hope an optimizer to find a good local optima.\nWhat is the role of the objective function if we are not allowed to optimize it globally?\nWhat is the justification of preferring a local optima rather than the global optima?\n\n\n### The revision seems to be not appropriate.\n\nI briefly checked the revision, and found Theorem 1 is still not appropriate.\nThere is no definition what \"minimized locally\" stands for. \n\nMoreover, the proof still says that $\\Theta = \\Theta^*$ which is not correct. \nAs I pointed out,  any $\\theta, \\alpha$ that satisfy $U(i | x, \\theta^*) = \\frac{\\exp(m_i(x; \\theta) + \\alpha_i(x))}{\\sum_j \\exp(m_j(x; \\theta) + \\alpha_j(x))}$ are optimal.\nThat is, there is no unique global optima.\nAll we have is the set of global optimal solutions $\\Theta^* = \\\\left\\\\{ \\theta, \\alpha \\mid U(i | x, \\theta^*) = \\frac{\\exp(m_i(x; \\theta) + \\alpha_i(x))}{\\sum_j \\exp(m_j(x; \\theta) + \\alpha_j(x))} \\\\right\\\\}$.\nHence, the only thing what we might be able to claim would be $\\theta, \\alpha \\in \\Theta^*$ as $N \\to \\infty$."}, "signatures": ["ICLR.cc/2021/Conference/Paper3100/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper3100/AnonReviewer2"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "AutoCleansing: Unbiased Estimation of Deep Learning with Mislabeled Data", "authorids": ["~Koichi_Kuriyama1"], "authors": ["Koichi Kuriyama"], "keywords": ["Automatic Data Cleansing", "Incorrect Labels", "Multiple Objects"], "abstract": "Mislabeled samples cause prediction errors. This study proposes a solution to the problem of incorrect labels, called AutoCleansing, to automatically capture the effect of incorrect labels and mitigate it without removing the mislabeled samples. AutoCleansing consists of a base network model and sample-category specific constants. Both parameters of the base model and sample-category constants are estimated simultaneously using the training data. Thereafter, predictions for test data are made using a base model without the constants capturing the mislabeled effects. A theoretical model for AutoCleansing is developed and showing that the gradient of the loss function of the proposed method can be zero at true parameters with mislabeled data if the model is correctly constructed.  Experimental results show that AutoCleansing has better performance in test accuracy than previous studies for CIFAR-10, CIFAR-100, SVHN, and ImageNet datasets.", "one-sentence_summary": "AutoCleansing can capture the effect of incorrect labels and mitigate it without removing the mislabeled samples. ", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "kuriyama|autocleansing_unbiased_estimation_of_deep_learning_with_mislabeled_data", "pdf": "/pdf/3b5902797c2072fc5c0be807ea4b660fd02763a2.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=Ia6A34pNtV", "_bibtex": "@misc{\nkuriyama2021autocleansing,\ntitle={AutoCleansing: Unbiased Estimation of Deep Learning with Mislabeled Data},\nauthor={Koichi Kuriyama},\nyear={2021},\nurl={https://openreview.net/forum?id=fV2ScEA03Hg}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "fV2ScEA03Hg", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper3100/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper3100/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper3100/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper3100/Authors|ICLR.cc/2021/Conference/Paper3100/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper3100/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923841147, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper3100/-/Official_Comment"}}}, {"id": "EjDVUVCQpL", "original": null, "number": 6, "cdate": 1605624499420, "ddate": null, "tcdate": 1605624499420, "tmdate": 1605675642302, "tddate": null, "forum": "fV2ScEA03Hg", "replyto": "BeTHTeZWNiC", "invitation": "ICLR.cc/2021/Conference/Paper3100/-/Official_Comment", "content": {"title": "Thank you for the helpful comment. The description of the theorem is revised.", "comment": "> Note that the above observation on the training problem also suggests that the claim of Theorem 1 (the estimator $\\theta$ converges to the true parameter $\\theta^\u2217$ is not correct.\n\nAs you pointed out, while this theorem states that the loss function with AutoCleansing is minimized locally at true values, it does not guarantee that minimization of the loss function will converge to the true value, if the loss function has more than one local minimum. Following your suggestion, I have removed the description of the convergence to true value from Theorem 1 and added the note that the loss function with AutoCleansing is minimized locally at true values. \n\n> The above observation indicates that the proposed method do not work as expected if the training problem is solved appropriately. Thus, I conjecture that the good performances reported in the experiments are the artifact caused by the tuning of hyperparameters, e.g., the training converged to local optima that occasionally performed well.\n\nAs mentioned in page 6, all hyperparameters are same as those used in previous works. I did not tune the hyperparameters.\n\n> The use of the adjustable parameters for fitting noisy data is studied in the literature of robust learning. I would like to suggest the authors to see [Ref1] and references therein. In [Ref1], an additional penalty is imposed on the adjustable parameter to avoid the trivial solution I raised above.\n\nTo avoid the trivial solution, I have implemented the weight decay for $\\alpha$ that imposes additional penalty. I have added the description on the regularization in page 6. Following your suggestion, I have referred to the consistent robust regression in section 2. \n\nI believe that I have addressed your concerns. Again, thank you for giving me the opportunity to strengthen the manuscript with your valuable comments. \n"}, "signatures": ["ICLR.cc/2021/Conference/Paper3100/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper3100/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "AutoCleansing: Unbiased Estimation of Deep Learning with Mislabeled Data", "authorids": ["~Koichi_Kuriyama1"], "authors": ["Koichi Kuriyama"], "keywords": ["Automatic Data Cleansing", "Incorrect Labels", "Multiple Objects"], "abstract": "Mislabeled samples cause prediction errors. This study proposes a solution to the problem of incorrect labels, called AutoCleansing, to automatically capture the effect of incorrect labels and mitigate it without removing the mislabeled samples. AutoCleansing consists of a base network model and sample-category specific constants. Both parameters of the base model and sample-category constants are estimated simultaneously using the training data. Thereafter, predictions for test data are made using a base model without the constants capturing the mislabeled effects. A theoretical model for AutoCleansing is developed and showing that the gradient of the loss function of the proposed method can be zero at true parameters with mislabeled data if the model is correctly constructed.  Experimental results show that AutoCleansing has better performance in test accuracy than previous studies for CIFAR-10, CIFAR-100, SVHN, and ImageNet datasets.", "one-sentence_summary": "AutoCleansing can capture the effect of incorrect labels and mitigate it without removing the mislabeled samples. ", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "kuriyama|autocleansing_unbiased_estimation_of_deep_learning_with_mislabeled_data", "pdf": "/pdf/3b5902797c2072fc5c0be807ea4b660fd02763a2.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=Ia6A34pNtV", "_bibtex": "@misc{\nkuriyama2021autocleansing,\ntitle={AutoCleansing: Unbiased Estimation of Deep Learning with Mislabeled Data},\nauthor={Koichi Kuriyama},\nyear={2021},\nurl={https://openreview.net/forum?id=fV2ScEA03Hg}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "fV2ScEA03Hg", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper3100/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper3100/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper3100/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper3100/Authors|ICLR.cc/2021/Conference/Paper3100/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper3100/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923841147, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper3100/-/Official_Comment"}}}, {"id": "3gjvXzOnUV", "original": null, "number": 5, "cdate": 1605624149270, "ddate": null, "tcdate": 1605624149270, "tmdate": 1605624680273, "tddate": null, "forum": "fV2ScEA03Hg", "replyto": "niUrvrnrtNx", "invitation": "ICLR.cc/2021/Conference/Paper3100/-/Official_Comment", "content": {"title": "The experiment on comparison with other method has been added.", "comment": "> As far as I understand, theoretical analysis is only applicable to AC1 model but the more practical approach which is applicable to datasets such as imagenet is AC2. What portion of your results can be extended to AC2?\n\nAC2 corresponds to the special case of the single symmetric case in Theorem 2. For the single symmetric case, $ \\alpha_{nj}=0 ~\\forall n,\\forall j\\ne t,f $. If the true category belongs to the outside of the category set, we cannot estimate the $ \\alpha_{nt} $ of the true category, therefore, all categories except the observed label have zero values of $ \\alpha_{nj} $ . I have added the description in page 6.\n\n> The experiments on CIFAR-10, CIFAR-100 and SVHN do not show a statistically significant improvement over the baselines; specifically after considering the confidence interval for the AA results (from table 2 of the AutoAugment paper).\n\nMy experimental results of the proposed AC1+AA show a significant improvement over AA results in most network models. The confidence interval of AutoAugment paper might be rounded up. For example, test error of Wide-Res-Net 28-10 for CIFAR 10 dataset is 2.6\u00b10.1 in AutoAugment, while 2.58 \u00b1 0.062 in PBA.  \n\n> Adding experiments with synthetic datasets with different levels of noise can be helpful in understanding the advantages of AC1/AC2 over other methods for handling noisy labels.\n\nI agree that the experiments with synthetic datasets can be helpful. However, the purpose of this paper is to analyze incorrect label in the real-world datasets, not artificial label noise. Therefore, I have referred the experiments with synthetic datasets for the future works.\n\n> Experiments in Section 4.2 are only trimming the incorrect training labels; ideally, you also want to remove the noisy labels from the test set too. However, as far as I understand it\u2019s not straightforward to apply AC1 to the test set and trim the noisy labels. Is this correct?\n\nYes. It might be future works to analyze the noisy labels in test dataset using AC1. \n\n> Other methods for learning with noisy labels such as the ones that are mentioned in the Section 2: \u2018Related Works\u2019 should be added in order to provide a better picture of the pros and cons of the method.\n\nFollowing your suggestion, the pros and cons of related works have been added in section 2.\n\n> In the current version of the paper, the emphasis in the experiments is on augmentation methods which may not be the best choice. For instance, \u201cUnsupervised Label Noise Modeling and Loss Correction\u201d by Arazo et al. has a similar approach to AC1 as it also models each sample and doesn\u2019t require a matrix based noise model. This could be a good candidate baseline.\n\nThank you for helpful suggestion. I have added the description of Arazo et al. in section 2 and deleted the experiment on augmentation methods. I agree that the comparison with the method proposed by Arazo et al might to be important. However, their experiment considered the synthetic label noise and they did not provide the experiment of incorrect labels in the real-world datasets. Alternatively, the comparison with the area under the margin (AUM) proposed by Pleiss et al. (2020) has been added (Table 6). They provided the experiments of the label noise in the real-world datasets as well as the artificially generated label noise. Their results show that the AUM has better performance than the previous studies for dataset with synthetic label noise added. AutoCleansing demonstrates outperforming the AUM on both CIFAR-10 and CIFAR-100.\n\nAgain, thank you for giving me the opportunity to strengthen the manuscript with your valuable comments. \n"}, "signatures": ["ICLR.cc/2021/Conference/Paper3100/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper3100/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "AutoCleansing: Unbiased Estimation of Deep Learning with Mislabeled Data", "authorids": ["~Koichi_Kuriyama1"], "authors": ["Koichi Kuriyama"], "keywords": ["Automatic Data Cleansing", "Incorrect Labels", "Multiple Objects"], "abstract": "Mislabeled samples cause prediction errors. This study proposes a solution to the problem of incorrect labels, called AutoCleansing, to automatically capture the effect of incorrect labels and mitigate it without removing the mislabeled samples. AutoCleansing consists of a base network model and sample-category specific constants. Both parameters of the base model and sample-category constants are estimated simultaneously using the training data. Thereafter, predictions for test data are made using a base model without the constants capturing the mislabeled effects. A theoretical model for AutoCleansing is developed and showing that the gradient of the loss function of the proposed method can be zero at true parameters with mislabeled data if the model is correctly constructed.  Experimental results show that AutoCleansing has better performance in test accuracy than previous studies for CIFAR-10, CIFAR-100, SVHN, and ImageNet datasets.", "one-sentence_summary": "AutoCleansing can capture the effect of incorrect labels and mitigate it without removing the mislabeled samples. ", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "kuriyama|autocleansing_unbiased_estimation_of_deep_learning_with_mislabeled_data", "pdf": "/pdf/3b5902797c2072fc5c0be807ea4b660fd02763a2.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=Ia6A34pNtV", "_bibtex": "@misc{\nkuriyama2021autocleansing,\ntitle={AutoCleansing: Unbiased Estimation of Deep Learning with Mislabeled Data},\nauthor={Koichi Kuriyama},\nyear={2021},\nurl={https://openreview.net/forum?id=fV2ScEA03Hg}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "fV2ScEA03Hg", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper3100/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper3100/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper3100/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper3100/Authors|ICLR.cc/2021/Conference/Paper3100/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper3100/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923841147, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper3100/-/Official_Comment"}}}, {"id": "WT3yU9vZafY", "original": null, "number": 4, "cdate": 1605623798554, "ddate": null, "tcdate": 1605623798554, "tmdate": 1605623798554, "tddate": null, "forum": "fV2ScEA03Hg", "replyto": "-LfNiaz3CiU", "invitation": "ICLR.cc/2021/Conference/Paper3100/-/Official_Comment", "content": {"title": "The experiment on comparison with other method has been added.", "comment": "> \u2022 The authors have not rationalized enough the performance of the AutoCleansing over the other methods and on the data sets in detail for better readability.\n\nFollowing your suggestion, the comparison with the area under the margin (AUM) proposed by Pleiss et al. (2020) has been added (Table 6). They provided the experiments of the label noise in the real-world datasets as well as the artificially generated label noise. Their results show that the AUM has better performance than the previous studies for dataset with synthetic label noise added. AutoCleansing demonstrates outperforming the AUM on both CIFAR-10 and CIFAR-100.\n\n> \u2022 Detection of incorrect labels using the proposed method has been described in detail but why AutoCleansing does not require the threshold criteria of the drop rate needs further discussion. Please add additional details.\n\nInstead of dropping the mislabeled samples that requires the threshold criteria of incorrect labels, AutoCleansing drops the sample-category specific constants capturing the mislabeled bias. I have added the description in page 9.  \n\n> \u2022 In addition to the learning rate, weight decay, Epoch etc. the authors can add the time units for each of the datasets helps the future researchers.\n\nThe additional learning time of AutoCleansing with CIFAR-10/100 datasets is only 0.5 % of the learning time of the base network models. I have added the description in page 3.\n\nAgain, thank you for giving me the opportunity to strengthen the manuscript with your valuable comments. \n"}, "signatures": ["ICLR.cc/2021/Conference/Paper3100/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper3100/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "AutoCleansing: Unbiased Estimation of Deep Learning with Mislabeled Data", "authorids": ["~Koichi_Kuriyama1"], "authors": ["Koichi Kuriyama"], "keywords": ["Automatic Data Cleansing", "Incorrect Labels", "Multiple Objects"], "abstract": "Mislabeled samples cause prediction errors. This study proposes a solution to the problem of incorrect labels, called AutoCleansing, to automatically capture the effect of incorrect labels and mitigate it without removing the mislabeled samples. AutoCleansing consists of a base network model and sample-category specific constants. Both parameters of the base model and sample-category constants are estimated simultaneously using the training data. Thereafter, predictions for test data are made using a base model without the constants capturing the mislabeled effects. A theoretical model for AutoCleansing is developed and showing that the gradient of the loss function of the proposed method can be zero at true parameters with mislabeled data if the model is correctly constructed.  Experimental results show that AutoCleansing has better performance in test accuracy than previous studies for CIFAR-10, CIFAR-100, SVHN, and ImageNet datasets.", "one-sentence_summary": "AutoCleansing can capture the effect of incorrect labels and mitigate it without removing the mislabeled samples. ", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "kuriyama|autocleansing_unbiased_estimation_of_deep_learning_with_mislabeled_data", "pdf": "/pdf/3b5902797c2072fc5c0be807ea4b660fd02763a2.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=Ia6A34pNtV", "_bibtex": "@misc{\nkuriyama2021autocleansing,\ntitle={AutoCleansing: Unbiased Estimation of Deep Learning with Mislabeled Data},\nauthor={Koichi Kuriyama},\nyear={2021},\nurl={https://openreview.net/forum?id=fV2ScEA03Hg}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "fV2ScEA03Hg", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper3100/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper3100/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper3100/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper3100/Authors|ICLR.cc/2021/Conference/Paper3100/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper3100/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923841147, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper3100/-/Official_Comment"}}}, {"id": "aeQ-RrqAeGs", "original": null, "number": 3, "cdate": 1605623368878, "ddate": null, "tcdate": 1605623368878, "tmdate": 1605623368878, "tddate": null, "forum": "fV2ScEA03Hg", "replyto": "tT4Lpcdqsyz", "invitation": "ICLR.cc/2021/Conference/Paper3100/-/Official_Comment", "content": {"title": "The numerical example describing the theorem and the experiment on comparison with other method has been added.", "comment": "Following your suggestion, a critical review has been added in section 2. For the description of theoretical analysis in section 3, Table 1 has been introduced to illustrate the theorems using the numerical examples. For the experiments, the comparison with the area under the margin (AUM) proposed by Pleiss et al. (2020) has been added (Table 6). They provided the experiments of the label noise in the real-world datasets as well as the artificially generated label noise. Their results show that the AUM has better performance than the previous studies for dataset with synthetic label noise added. AutoCleansing has better performance than AUM on both CIFAR-10 and CIFAR-100.\n\nI believe that I have addressed your concerns. Again, thank you for giving me the opportunity to strengthen the manuscript with your valuable comments. \n"}, "signatures": ["ICLR.cc/2021/Conference/Paper3100/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper3100/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "AutoCleansing: Unbiased Estimation of Deep Learning with Mislabeled Data", "authorids": ["~Koichi_Kuriyama1"], "authors": ["Koichi Kuriyama"], "keywords": ["Automatic Data Cleansing", "Incorrect Labels", "Multiple Objects"], "abstract": "Mislabeled samples cause prediction errors. This study proposes a solution to the problem of incorrect labels, called AutoCleansing, to automatically capture the effect of incorrect labels and mitigate it without removing the mislabeled samples. AutoCleansing consists of a base network model and sample-category specific constants. Both parameters of the base model and sample-category constants are estimated simultaneously using the training data. Thereafter, predictions for test data are made using a base model without the constants capturing the mislabeled effects. A theoretical model for AutoCleansing is developed and showing that the gradient of the loss function of the proposed method can be zero at true parameters with mislabeled data if the model is correctly constructed.  Experimental results show that AutoCleansing has better performance in test accuracy than previous studies for CIFAR-10, CIFAR-100, SVHN, and ImageNet datasets.", "one-sentence_summary": "AutoCleansing can capture the effect of incorrect labels and mitigate it without removing the mislabeled samples. ", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "kuriyama|autocleansing_unbiased_estimation_of_deep_learning_with_mislabeled_data", "pdf": "/pdf/3b5902797c2072fc5c0be807ea4b660fd02763a2.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=Ia6A34pNtV", "_bibtex": "@misc{\nkuriyama2021autocleansing,\ntitle={AutoCleansing: Unbiased Estimation of Deep Learning with Mislabeled Data},\nauthor={Koichi Kuriyama},\nyear={2021},\nurl={https://openreview.net/forum?id=fV2ScEA03Hg}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "fV2ScEA03Hg", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper3100/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper3100/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper3100/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper3100/Authors|ICLR.cc/2021/Conference/Paper3100/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper3100/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923841147, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper3100/-/Official_Comment"}}}, {"id": "niUrvrnrtNx", "original": null, "number": 2, "cdate": 1603850203538, "ddate": null, "tcdate": 1603850203538, "tmdate": 1605024068553, "tddate": null, "forum": "fV2ScEA03Hg", "replyto": "fV2ScEA03Hg", "invitation": "ICLR.cc/2021/Conference/Paper3100/-/Official_Review", "content": {"title": "Interesting and simple idea but lacks comparison with any other methods for learning with noisy labels", "review": "The paper proposes an approach for handling noisy labels in predictive models without removing them. The approach is based on a base network and a category dependent constant. At test time the prediction is done using the base network. The paper is well-written and the ideas are explained clearly. I have the following comments and questions on the empirical and theoretical aspects of the work:\n\nAs far as I understand, theoretical analysis is only applicable to AC1 model but the more practical approach which is applicable to datasets such as imagenet is AC2. What portion of your results can be extended to AC2? \n\nThe experiments on CIFAR-10, CIFAR-100 and SVHN do not show a statistically significant improvement over the baselines; specifically after considering the confidence interval for the AA results (from table 2 of the AutoAugment paper). Adding experiments with synthetic datasets with different levels of noise can be helpful in understanding the advantages of AC1/AC2 over other methods for handling noisy labels. \n\nExperiments in Section 4.2 are only trimming the incorrect training labels; ideally, you also want to remove the noisy labels from the test set too. However, as far as I understand it\u2019s not straightforward to apply AC1 to the test set and trim the noisy labels. Is this correct?\n\nOther methods for learning with noisy labels such as the ones that are mentioned in the Section 2: \u2018Related Works\u2019 should be added in order to provide a better picture of the pros and cons of the method. In the current version of the paper, the emphasis in the experiments is on augmentation methods which may not be the best choice.  For instance, \u201cUnsupervised Label Noise Modeling and Loss Correction\u201d by Arazo et al. has a similar approach to AC1 as it also models each sample and doesn\u2019t require a matrix based noise model. This could be a good candidate baseline. \n\nOverall, I like the simplicity of the approach but I believe with the current state of the paper, it\u2019s hard to judge the value of the approach over other methods for learning with noisy labels. ", "rating": "4: Ok but not good enough - rejection", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["ICLR.cc/2021/Conference/Paper3100/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper3100/AnonReviewer1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "AutoCleansing: Unbiased Estimation of Deep Learning with Mislabeled Data", "authorids": ["~Koichi_Kuriyama1"], "authors": ["Koichi Kuriyama"], "keywords": ["Automatic Data Cleansing", "Incorrect Labels", "Multiple Objects"], "abstract": "Mislabeled samples cause prediction errors. This study proposes a solution to the problem of incorrect labels, called AutoCleansing, to automatically capture the effect of incorrect labels and mitigate it without removing the mislabeled samples. AutoCleansing consists of a base network model and sample-category specific constants. Both parameters of the base model and sample-category constants are estimated simultaneously using the training data. Thereafter, predictions for test data are made using a base model without the constants capturing the mislabeled effects. A theoretical model for AutoCleansing is developed and showing that the gradient of the loss function of the proposed method can be zero at true parameters with mislabeled data if the model is correctly constructed.  Experimental results show that AutoCleansing has better performance in test accuracy than previous studies for CIFAR-10, CIFAR-100, SVHN, and ImageNet datasets.", "one-sentence_summary": "AutoCleansing can capture the effect of incorrect labels and mitigate it without removing the mislabeled samples. ", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "kuriyama|autocleansing_unbiased_estimation_of_deep_learning_with_mislabeled_data", "pdf": "/pdf/3b5902797c2072fc5c0be807ea4b660fd02763a2.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=Ia6A34pNtV", "_bibtex": "@misc{\nkuriyama2021autocleansing,\ntitle={AutoCleansing: Unbiased Estimation of Deep Learning with Mislabeled Data},\nauthor={Koichi Kuriyama},\nyear={2021},\nurl={https://openreview.net/forum?id=fV2ScEA03Hg}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq . ***Please remember to file the Code-of-Ethics report. Once you submitted the review, a link to the report will be visible in the bottom right corner of your review.***", "required": true, "markdown": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}, "forum": "fV2ScEA03Hg", "replyto": "fV2ScEA03Hg", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"], "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper3100/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1607428800000, "duedate": 1606752000000, "multiReply": false, "readers": ["everyone"], "tcdate": 1602538082335, "tmdate": 1606915774161, "super": "ICLR.cc/2021/Conference/-/Official_Review", "signatures": ["OpenReview.net"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Paper3100/Reviewers", "OpenReview.net/Support"], "id": "ICLR.cc/2021/Conference/Paper3100/-/Official_Review"}}}, {"id": "-LfNiaz3CiU", "original": null, "number": 3, "cdate": 1603914690960, "ddate": null, "tcdate": 1603914690960, "tmdate": 1605024068467, "tddate": null, "forum": "fV2ScEA03Hg", "replyto": "fV2ScEA03Hg", "invitation": "ICLR.cc/2021/Conference/Paper3100/-/Official_Review", "content": {"title": "This study provides a theoretical model to capture biased effect of incorrect labels automatically and address the prediction errors due to incorrect labels in training data.", "review": "This paper seems to be a useful contribution to the literature on deep learning with noisy datasets, showing a good improvement over the state of the art. \nThis work presents a theoretical model formulation to capture the biased effects of incorrect labels automatically \nThe paper is generally well-written and structured clearly. However, there are few small changes or suggestions to improve are as follows:\n\u2022\tThe authors have not rationalized enough the performance of the AutoCleansing over the other methods and on the data sets in detail for better readability.\n\u2022\tSummary of the data sets as a table provides better visibility and readability. \n\u2022\tDetection of incorrect labels using the proposed method has been described in detail but why AutoCleansing does not require the threshold criteria of the drop rate needs further discussion. Please add additional details.\n\u2022\tIn addition to the learning rate, weight decay, Epoch etc. the authors can add the time units for each of the datasets helps the future researchers. Please add.\n\nThe paper and the supplementary provided describes the theoretical formulation and other objective functions in full detail and provides enough information for an expert reader to understand and interpret the results.", "rating": "6: Marginally above acceptance threshold", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "signatures": ["ICLR.cc/2021/Conference/Paper3100/AnonReviewer4"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper3100/AnonReviewer4"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "AutoCleansing: Unbiased Estimation of Deep Learning with Mislabeled Data", "authorids": ["~Koichi_Kuriyama1"], "authors": ["Koichi Kuriyama"], "keywords": ["Automatic Data Cleansing", "Incorrect Labels", "Multiple Objects"], "abstract": "Mislabeled samples cause prediction errors. This study proposes a solution to the problem of incorrect labels, called AutoCleansing, to automatically capture the effect of incorrect labels and mitigate it without removing the mislabeled samples. AutoCleansing consists of a base network model and sample-category specific constants. Both parameters of the base model and sample-category constants are estimated simultaneously using the training data. Thereafter, predictions for test data are made using a base model without the constants capturing the mislabeled effects. A theoretical model for AutoCleansing is developed and showing that the gradient of the loss function of the proposed method can be zero at true parameters with mislabeled data if the model is correctly constructed.  Experimental results show that AutoCleansing has better performance in test accuracy than previous studies for CIFAR-10, CIFAR-100, SVHN, and ImageNet datasets.", "one-sentence_summary": "AutoCleansing can capture the effect of incorrect labels and mitigate it without removing the mislabeled samples. ", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "kuriyama|autocleansing_unbiased_estimation_of_deep_learning_with_mislabeled_data", "pdf": "/pdf/3b5902797c2072fc5c0be807ea4b660fd02763a2.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=Ia6A34pNtV", "_bibtex": "@misc{\nkuriyama2021autocleansing,\ntitle={AutoCleansing: Unbiased Estimation of Deep Learning with Mislabeled Data},\nauthor={Koichi Kuriyama},\nyear={2021},\nurl={https://openreview.net/forum?id=fV2ScEA03Hg}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq . ***Please remember to file the Code-of-Ethics report. Once you submitted the review, a link to the report will be visible in the bottom right corner of your review.***", "required": true, "markdown": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}, "forum": "fV2ScEA03Hg", "replyto": "fV2ScEA03Hg", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"], "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper3100/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1607428800000, "duedate": 1606752000000, "multiReply": false, "readers": ["everyone"], "tcdate": 1602538082335, "tmdate": 1606915774161, "super": "ICLR.cc/2021/Conference/-/Official_Review", "signatures": ["OpenReview.net"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Paper3100/Reviewers", "OpenReview.net/Support"], "id": "ICLR.cc/2021/Conference/Paper3100/-/Official_Review"}}}, {"id": "tT4Lpcdqsyz", "original": null, "number": 4, "cdate": 1604476618017, "ddate": null, "tcdate": 1604476618017, "tmdate": 1605024068397, "tddate": null, "forum": "fV2ScEA03Hg", "replyto": "fV2ScEA03Hg", "invitation": "ICLR.cc/2021/Conference/Paper3100/-/Official_Review", "content": {"title": "The paper method can improve the performance to some extent, but the influence is not prominent.", "review": "This study introduces AutoCleansing to address the biased problem due to incorrect labels. This framework can automatically capture the effect of incorrect labels and mitigate it without removing mislabeled samples. There is some improvement in performance, but not much difference.\n\nWhere to improve:\n\nThe challenges of solving the problem of incorrect labels must be explained in-depth, but they are not introduced at all.\nSection 2 leaves me with an idea of incompleteness, and I would request the authors to make it a critical review and not just a list of methods.\nSection 3 for the proposed method AutoCleansing. The method is primarily described through equations. The authors may want to consider adding more descriptive text (and possibly figures) that would make the paper more accessible to readers without and extensive mathematics background.\nthe section Results should be substantially expanded. The authors should be explicit about the difference between the model proposed here and the models implemented by previous studies and how their model works compared to other methods.\n", "rating": "5: Marginally below acceptance threshold", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "signatures": ["ICLR.cc/2021/Conference/Paper3100/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper3100/AnonReviewer3"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "AutoCleansing: Unbiased Estimation of Deep Learning with Mislabeled Data", "authorids": ["~Koichi_Kuriyama1"], "authors": ["Koichi Kuriyama"], "keywords": ["Automatic Data Cleansing", "Incorrect Labels", "Multiple Objects"], "abstract": "Mislabeled samples cause prediction errors. This study proposes a solution to the problem of incorrect labels, called AutoCleansing, to automatically capture the effect of incorrect labels and mitigate it without removing the mislabeled samples. AutoCleansing consists of a base network model and sample-category specific constants. Both parameters of the base model and sample-category constants are estimated simultaneously using the training data. Thereafter, predictions for test data are made using a base model without the constants capturing the mislabeled effects. A theoretical model for AutoCleansing is developed and showing that the gradient of the loss function of the proposed method can be zero at true parameters with mislabeled data if the model is correctly constructed.  Experimental results show that AutoCleansing has better performance in test accuracy than previous studies for CIFAR-10, CIFAR-100, SVHN, and ImageNet datasets.", "one-sentence_summary": "AutoCleansing can capture the effect of incorrect labels and mitigate it without removing the mislabeled samples. ", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "kuriyama|autocleansing_unbiased_estimation_of_deep_learning_with_mislabeled_data", "pdf": "/pdf/3b5902797c2072fc5c0be807ea4b660fd02763a2.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=Ia6A34pNtV", "_bibtex": "@misc{\nkuriyama2021autocleansing,\ntitle={AutoCleansing: Unbiased Estimation of Deep Learning with Mislabeled Data},\nauthor={Koichi Kuriyama},\nyear={2021},\nurl={https://openreview.net/forum?id=fV2ScEA03Hg}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq . ***Please remember to file the Code-of-Ethics report. Once you submitted the review, a link to the report will be visible in the bottom right corner of your review.***", "required": true, "markdown": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}, "forum": "fV2ScEA03Hg", "replyto": "fV2ScEA03Hg", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"], "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper3100/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1607428800000, "duedate": 1606752000000, "multiReply": false, "readers": ["everyone"], "tcdate": 1602538082335, "tmdate": 1606915774161, "super": "ICLR.cc/2021/Conference/-/Official_Review", "signatures": ["OpenReview.net"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Paper3100/Reviewers", "OpenReview.net/Support"], "id": "ICLR.cc/2021/Conference/Paper3100/-/Official_Review"}}}], "count": 13}