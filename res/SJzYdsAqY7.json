{"notes": [{"id": "SJzYdsAqY7", "original": "S1gUENCYYX", "number": 373, "cdate": 1538087792921, "ddate": null, "tcdate": 1538087792921, "tmdate": 1545355419721, "tddate": null, "forum": "SJzYdsAqY7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Spatial-Winograd Pruning Enabling Sparse Winograd Convolution", "abstract": "Deep convolutional neural networks (CNNs) are deployed in various applications but demand immense computational requirements. Pruning techniques and Winograd convolution are two typical methods to reduce the CNN computation. However, they cannot be directly combined because Winograd transformation fills in the sparsity resulting from pruning. Li et al. (2017) propose sparse Winograd convolution in which weights are directly pruned in the Winograd domain, but this technique is not very practical because Winograd-domain retraining requires low learning rates and hence significantly longer training time. Besides, Liu et al. (2018) move the ReLU function into the Winograd domain, which can help increase the weight sparsity but requires changes in the network structure. To achieve a high Winograd-domain weight sparsity without changing network structures, we propose a new pruning method, spatial-Winograd pruning. As the first step, spatial-domain weights are pruned in a structured way, which efficiently transfers the spatial-domain sparsity into the Winograd domain and avoids Winograd-domain retraining. For the next step, we also perform pruning and retraining directly in the Winograd domain but propose to use an importance factor matrix to adjust weight importance and weight gradients. This adjustment makes it possible to effectively retrain the pruned Winograd-domain network without changing the network structure. For the three models on the datasets of CIFAR-10, CIFAR-100, and ImageNet, our proposed method can achieve the Winograd-domain sparsities of 63%, 50%, and 74%, respectively.", "keywords": ["deep learning", "convolutional neural network", "pruning", "Winograd convolution"], "authorids": ["jiecaoyu@umich.edu", "jongsoo@fb.com", "mnaumov@fb.com"], "authors": ["Jiecao Yu", "Jongsoo Park", "Maxim Naumov"], "TL;DR": "To accelerate the computation of convolutional neural networks, we propose a new two-step pruning technique which achieves a higher Winograd-domain weight sparsity without changing the network structure.", "pdf": "/pdf/4fc9ea87f70428355bb01bcf4ebc408de6e19c73.pdf", "paperhash": "yu|spatialwinograd_pruning_enabling_sparse_winograd_convolution", "_bibtex": "@misc{\nyu2019spatialwinograd,\ntitle={Spatial-Winograd Pruning Enabling Sparse Winograd Convolution},\nauthor={Jiecao Yu and Jongsoo Park and Maxim Naumov},\nyear={2019},\nurl={https://openreview.net/forum?id=SJzYdsAqY7},\n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"replyCount": 12, "writable": false, "overwriting": [], "revisions": false, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Blind_Submission", "rdate": null, "ddate": null, "expdate": null, "duedate": 1538085600000, "tmdate": 1538142958393, "tddate": null, "super": null, "final": null, "reply": {"signatures": {"values": ["ICLR.cc/2019/Conference"]}, "forum": null, "readers": {"values": ["everyone"]}, "replyto": null, "content": {"authorids": {"values-regex": ".*"}, "authors": {"values": ["Anonymous"]}}, "writers": {"values": ["ICLR.cc/2019/Conference"]}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["~"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": null, "taskCompletionCount": null, "transform": null, "cdate": 1538142958393}}, "tauthor": "OpenReview.net"}, {"id": "Bkgq8tC-kN", "original": null, "number": 1, "cdate": 1543788881933, "ddate": null, "tcdate": 1543788881933, "tmdate": 1545354495430, "tddate": null, "forum": "SJzYdsAqY7", "replyto": "SJzYdsAqY7", "invitation": "ICLR.cc/2019/Conference/-/Paper373/Meta_Review", "content": {"metareview": "Reviewer scores straddle the decision boundary but overall this does work does not meet the bar yet. Even after discussion with the authors, the reviewers reconfirmed there 'reject' recommendation and the area chair agrees with that assessment.", "confidence": "4: The area chair is confident but not absolutely certain", "recommendation": "Reject", "title": "Reject"}, "signatures": ["ICLR.cc/2019/Conference/Paper373/Area_Chair1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference/Paper373/Area_Chair1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Spatial-Winograd Pruning Enabling Sparse Winograd Convolution", "abstract": "Deep convolutional neural networks (CNNs) are deployed in various applications but demand immense computational requirements. Pruning techniques and Winograd convolution are two typical methods to reduce the CNN computation. However, they cannot be directly combined because Winograd transformation fills in the sparsity resulting from pruning. Li et al. (2017) propose sparse Winograd convolution in which weights are directly pruned in the Winograd domain, but this technique is not very practical because Winograd-domain retraining requires low learning rates and hence significantly longer training time. Besides, Liu et al. (2018) move the ReLU function into the Winograd domain, which can help increase the weight sparsity but requires changes in the network structure. To achieve a high Winograd-domain weight sparsity without changing network structures, we propose a new pruning method, spatial-Winograd pruning. As the first step, spatial-domain weights are pruned in a structured way, which efficiently transfers the spatial-domain sparsity into the Winograd domain and avoids Winograd-domain retraining. For the next step, we also perform pruning and retraining directly in the Winograd domain but propose to use an importance factor matrix to adjust weight importance and weight gradients. This adjustment makes it possible to effectively retrain the pruned Winograd-domain network without changing the network structure. For the three models on the datasets of CIFAR-10, CIFAR-100, and ImageNet, our proposed method can achieve the Winograd-domain sparsities of 63%, 50%, and 74%, respectively.", "keywords": ["deep learning", "convolutional neural network", "pruning", "Winograd convolution"], "authorids": ["jiecaoyu@umich.edu", "jongsoo@fb.com", "mnaumov@fb.com"], "authors": ["Jiecao Yu", "Jongsoo Park", "Maxim Naumov"], "TL;DR": "To accelerate the computation of convolutional neural networks, we propose a new two-step pruning technique which achieves a higher Winograd-domain weight sparsity without changing the network structure.", "pdf": "/pdf/4fc9ea87f70428355bb01bcf4ebc408de6e19c73.pdf", "paperhash": "yu|spatialwinograd_pruning_enabling_sparse_winograd_convolution", "_bibtex": "@misc{\nyu2019spatialwinograd,\ntitle={Spatial-Winograd Pruning Enabling Sparse Winograd Convolution},\nauthor={Jiecao Yu and Jongsoo Park and Maxim Naumov},\nyear={2019},\nurl={https://openreview.net/forum?id=SJzYdsAqY7},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper373/Meta_Review", "rdate": null, "ddate": null, "expdate": null, "duedate": 1541548800000, "tmdate": 1545353240239, "tddate": null, "super": null, "final": null, "reply": {"forum": "SJzYdsAqY7", "replyto": "SJzYdsAqY7", "readers": {"description": "Select all user groups that should be able to read this comment. Selecting 'All Users' will allow paper authors, reviewers, area chairs, and program chairs to view this comment.", "values": ["everyone"]}, "signatures": {"description": "How your identity will be displayed with the above content.", "values-regex": "ICLR.cc/2019/Conference/Paper373/Area_Chair[0-9]+"}, "writers": {"description": "Users that may modify this record.", "values-regex": "ICLR.cc/2019/Conference/Paper373/Area_Chair[0-9]+"}, "content": {"title": {"order": 1, "value-regex": ".{1,500}", "description": "Brief summary of your review.", "required": true}, "metareview": {"order": 2, "value-regex": "[\\S\\s]{1,5000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "required": true}, "recommendation": {"order": 3, "value-dropdown": ["Accept (Oral)", "Accept (Poster)", "Reject"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The area chair is absolutely certain", "4: The area chair is confident but not absolutely certain", "3: The area chair is somewhat confident", "2: The area chair is not sure", "1: The area chair's evaluation is an educated guess"], "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper373/Area_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": false, "taskCompletionCount": null, "transform": null, "cdate": 1545353240239}}}, {"id": "HkepknPC0Q", "original": null, "number": 11, "cdate": 1543564261102, "ddate": null, "tcdate": 1543564261102, "tmdate": 1543566978588, "tddate": null, "forum": "SJzYdsAqY7", "replyto": "rJlppRjF0Q", "invitation": "ICLR.cc/2019/Conference/-/Paper373/Official_Comment", "content": {"title": "Response for Reviewer's Response ", "comment": "We thank the reviewer for the response.\n\n(1) For the practical considerations, we agree with the reviewer that real speedups verified on hardware platforms are important. We will include more related results in the future version.\n\n(2) For the generality of the result, this is actually what we want to improve compared with the baseline [1]. The baseline solution moves the ReLU function from the spatial domain into the Winograd domain, which fundamentally changes the convolution computation.\n\nIn our solution, we keep the first stage, spatial structured pruning, in the spatial domain since pruning in the spatial domain is well-explored for different network architectures. This stage is as robust as the conventional spatial-domain pruning algorithms. For the next stage of pruning in the Winograd domain, it is difficult to provide a solid mathematical proof. Therefore, we do test different network architectures for different datasets to show that the Winograd direct pruning can be applied to the tested structures.\n\nWe agree with the reviewer that our solution cannot guarantee a performance gain for every single layer of different DNN architectures compared with the conventional spatial pruning algorithms or the baseline dense model. The performance gain/loss we can have varies for different layers in different networks. Therefore, our future work will explore how to determine which layers can benefit more from the proposed spatial-Winograd pruning compared with conventional network compression techniques.\n\nAs for networks with separable convolutions, e.g., MobileNet, those models are not directly the targets for our proposed method. With separable convolutions, the main part of the parameters and computation is for the 1x1 pointwise convolution. 1x1 convolution is not the target of Winograd convolution and, therefore, not the target of our proposed method. Considering that the networks with separable convolutions have traded accuracy for computation efficiency, a potential method for applying our solution is first converting the 3x3 depthwise convolution back into a full 3x3 convolution to increase the accuracy and then applying our technique. This might help achieve a higher accuracy while maintaining a similar computation/parameters requirement.\n\n----\n[1] Liu, Xingyu, Jeff Pool, Song Han, and William J. Dally. \"Efficient sparse-winograd convolutional neural networks.\" arXiv preprint arXiv:1802.06367 (2018). https://arxiv.org/abs/1802.06367"}, "signatures": ["ICLR.cc/2019/Conference/Paper373/Authors"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper373/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper373/Authors", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Spatial-Winograd Pruning Enabling Sparse Winograd Convolution", "abstract": "Deep convolutional neural networks (CNNs) are deployed in various applications but demand immense computational requirements. Pruning techniques and Winograd convolution are two typical methods to reduce the CNN computation. However, they cannot be directly combined because Winograd transformation fills in the sparsity resulting from pruning. Li et al. (2017) propose sparse Winograd convolution in which weights are directly pruned in the Winograd domain, but this technique is not very practical because Winograd-domain retraining requires low learning rates and hence significantly longer training time. Besides, Liu et al. (2018) move the ReLU function into the Winograd domain, which can help increase the weight sparsity but requires changes in the network structure. To achieve a high Winograd-domain weight sparsity without changing network structures, we propose a new pruning method, spatial-Winograd pruning. As the first step, spatial-domain weights are pruned in a structured way, which efficiently transfers the spatial-domain sparsity into the Winograd domain and avoids Winograd-domain retraining. For the next step, we also perform pruning and retraining directly in the Winograd domain but propose to use an importance factor matrix to adjust weight importance and weight gradients. This adjustment makes it possible to effectively retrain the pruned Winograd-domain network without changing the network structure. For the three models on the datasets of CIFAR-10, CIFAR-100, and ImageNet, our proposed method can achieve the Winograd-domain sparsities of 63%, 50%, and 74%, respectively.", "keywords": ["deep learning", "convolutional neural network", "pruning", "Winograd convolution"], "authorids": ["jiecaoyu@umich.edu", "jongsoo@fb.com", "mnaumov@fb.com"], "authors": ["Jiecao Yu", "Jongsoo Park", "Maxim Naumov"], "TL;DR": "To accelerate the computation of convolutional neural networks, we propose a new two-step pruning technique which achieves a higher Winograd-domain weight sparsity without changing the network structure.", "pdf": "/pdf/4fc9ea87f70428355bb01bcf4ebc408de6e19c73.pdf", "paperhash": "yu|spatialwinograd_pruning_enabling_sparse_winograd_convolution", "_bibtex": "@misc{\nyu2019spatialwinograd,\ntitle={Spatial-Winograd Pruning Enabling Sparse Winograd Convolution},\nauthor={Jiecao Yu and Jongsoo Park and Maxim Naumov},\nyear={2019},\nurl={https://openreview.net/forum?id=SJzYdsAqY7},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper373/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621623066, "tddate": null, "super": null, "final": null, "reply": {"forum": "SJzYdsAqY7", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper373/Authors", "ICLR.cc/2019/Conference/Paper373/Reviewers", "ICLR.cc/2019/Conference/Paper373/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper373/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper373/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper373/Authors|ICLR.cc/2019/Conference/Paper373/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper373/Reviewers", "ICLR.cc/2019/Conference/Paper373/Authors", "ICLR.cc/2019/Conference/Paper373/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621623066}}}, {"id": "ryeevww007", "original": null, "number": 10, "cdate": 1543563096227, "ddate": null, "tcdate": 1543563096227, "tmdate": 1543566743232, "tddate": null, "forum": "SJzYdsAqY7", "replyto": "rJxqlOulAX", "invitation": "ICLR.cc/2019/Conference/-/Paper373/Official_Comment", "content": {"title": "Response for Reviewer's Response", "comment": "We thank the reviewer for the response.\n\nConsidering the generalizability, this is actually what we want to improve compared with the baseline [1]. The baseline solution moves the ReLU function from the spatial domain into the Winograd domain, which fundamentally changes the convolution computation.\n\nIn our solution, we keep the first stage, spatial structured pruning, in the spatial domain since pruning in the spatial domain is well-explored for different network architectures. This stage is as robust as the conventional spatial-domain pruning algorithms. For the next stage of pruning in the Winograd domain, it is difficult to provide a solid mathematical proof. Therefore, we do test different network architectures for different datasets to show that the Winograd direct pruning can be applied to the tested structures.\n\nFor the discussion about the speedups, we agree with the reviewer that a study about the end-to-end speedups is important. We will include more results about real speedups in the future version.\n\n----\n[1] Liu, Xingyu, Jeff Pool, Song Han, and William J. Dally. \"Efficient sparse-winograd convolutional neural networks.\" arXiv preprint arXiv:1802.06367 (2018). https://arxiv.org/abs/1802.06367"}, "signatures": ["ICLR.cc/2019/Conference/Paper373/Authors"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper373/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper373/Authors", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Spatial-Winograd Pruning Enabling Sparse Winograd Convolution", "abstract": "Deep convolutional neural networks (CNNs) are deployed in various applications but demand immense computational requirements. Pruning techniques and Winograd convolution are two typical methods to reduce the CNN computation. However, they cannot be directly combined because Winograd transformation fills in the sparsity resulting from pruning. Li et al. (2017) propose sparse Winograd convolution in which weights are directly pruned in the Winograd domain, but this technique is not very practical because Winograd-domain retraining requires low learning rates and hence significantly longer training time. Besides, Liu et al. (2018) move the ReLU function into the Winograd domain, which can help increase the weight sparsity but requires changes in the network structure. To achieve a high Winograd-domain weight sparsity without changing network structures, we propose a new pruning method, spatial-Winograd pruning. As the first step, spatial-domain weights are pruned in a structured way, which efficiently transfers the spatial-domain sparsity into the Winograd domain and avoids Winograd-domain retraining. For the next step, we also perform pruning and retraining directly in the Winograd domain but propose to use an importance factor matrix to adjust weight importance and weight gradients. This adjustment makes it possible to effectively retrain the pruned Winograd-domain network without changing the network structure. For the three models on the datasets of CIFAR-10, CIFAR-100, and ImageNet, our proposed method can achieve the Winograd-domain sparsities of 63%, 50%, and 74%, respectively.", "keywords": ["deep learning", "convolutional neural network", "pruning", "Winograd convolution"], "authorids": ["jiecaoyu@umich.edu", "jongsoo@fb.com", "mnaumov@fb.com"], "authors": ["Jiecao Yu", "Jongsoo Park", "Maxim Naumov"], "TL;DR": "To accelerate the computation of convolutional neural networks, we propose a new two-step pruning technique which achieves a higher Winograd-domain weight sparsity without changing the network structure.", "pdf": "/pdf/4fc9ea87f70428355bb01bcf4ebc408de6e19c73.pdf", "paperhash": "yu|spatialwinograd_pruning_enabling_sparse_winograd_convolution", "_bibtex": "@misc{\nyu2019spatialwinograd,\ntitle={Spatial-Winograd Pruning Enabling Sparse Winograd Convolution},\nauthor={Jiecao Yu and Jongsoo Park and Maxim Naumov},\nyear={2019},\nurl={https://openreview.net/forum?id=SJzYdsAqY7},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper373/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621623066, "tddate": null, "super": null, "final": null, "reply": {"forum": "SJzYdsAqY7", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper373/Authors", "ICLR.cc/2019/Conference/Paper373/Reviewers", "ICLR.cc/2019/Conference/Paper373/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper373/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper373/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper373/Authors|ICLR.cc/2019/Conference/Paper373/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper373/Reviewers", "ICLR.cc/2019/Conference/Paper373/Authors", "ICLR.cc/2019/Conference/Paper373/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621623066}}}, {"id": "rJlppRjF0Q", "original": null, "number": 8, "cdate": 1543253701185, "ddate": null, "tcdate": 1543253701185, "tmdate": 1543255070395, "tddate": null, "forum": "SJzYdsAqY7", "replyto": "SJxFpDUtp7", "invitation": "ICLR.cc/2019/Conference/-/Paper373/Official_Comment", "content": {"title": "Response to rebuttal", "comment": "I have read all of the other reviewer comments as well as the author responses to my original comments.\n\nI thank the authors for their thoughtful responses but my review remains at 4: Ok but not good enough - rejection. The primary reasons that review remains at this level are:\n\n(1) Practical considerations / real world \n\nThe authors argue that they can achieve a higher level of sparsity and provide some evidence for this in Appendix B. First, I would suggest to the authors that this should be placed in the main body of the text since this seems a central result. That said, it is still not clear if their gains are realizable. Currently, the authors argue that this will lead to faster inference -- however, this is a theoretical argument and I have seen many methods fail to achieve their theoretical gains when actually implemented. Given that the faster inference is the central contribution of this paper, I strongly believe this requites a proof of concept implementation.\n\n(2) Generality of the result\n\nAs mentioned by other reviewers, the methods appear fragile and far from guaranteed from providing gains across a broad array of architectures. Rather then focus on 1 architecture (e.g. their custom ResNet-18), I would prefer to see them 'swap in' this method across a broad array of architectures (e.g. In the rebuttal table, the authors should focus on MobileNetV1 vs MobileNetV1-Pruned; XCeption vs XCeptio-Pruned, etc.). This would provide more guarantees that in spite of the fragility of the training method, this method is broadly applicable. Note that this is precisely why decreasing filter bank sizes, swapping in separable convolutions, etc. are considered simple but general methods for speeding up networks with minimal harm in prediction accuracy.\n"}, "signatures": ["ICLR.cc/2019/Conference/Paper373/AnonReviewer2"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper373/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper373/AnonReviewer2", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Spatial-Winograd Pruning Enabling Sparse Winograd Convolution", "abstract": "Deep convolutional neural networks (CNNs) are deployed in various applications but demand immense computational requirements. Pruning techniques and Winograd convolution are two typical methods to reduce the CNN computation. However, they cannot be directly combined because Winograd transformation fills in the sparsity resulting from pruning. Li et al. (2017) propose sparse Winograd convolution in which weights are directly pruned in the Winograd domain, but this technique is not very practical because Winograd-domain retraining requires low learning rates and hence significantly longer training time. Besides, Liu et al. (2018) move the ReLU function into the Winograd domain, which can help increase the weight sparsity but requires changes in the network structure. To achieve a high Winograd-domain weight sparsity without changing network structures, we propose a new pruning method, spatial-Winograd pruning. As the first step, spatial-domain weights are pruned in a structured way, which efficiently transfers the spatial-domain sparsity into the Winograd domain and avoids Winograd-domain retraining. For the next step, we also perform pruning and retraining directly in the Winograd domain but propose to use an importance factor matrix to adjust weight importance and weight gradients. This adjustment makes it possible to effectively retrain the pruned Winograd-domain network without changing the network structure. For the three models on the datasets of CIFAR-10, CIFAR-100, and ImageNet, our proposed method can achieve the Winograd-domain sparsities of 63%, 50%, and 74%, respectively.", "keywords": ["deep learning", "convolutional neural network", "pruning", "Winograd convolution"], "authorids": ["jiecaoyu@umich.edu", "jongsoo@fb.com", "mnaumov@fb.com"], "authors": ["Jiecao Yu", "Jongsoo Park", "Maxim Naumov"], "TL;DR": "To accelerate the computation of convolutional neural networks, we propose a new two-step pruning technique which achieves a higher Winograd-domain weight sparsity without changing the network structure.", "pdf": "/pdf/4fc9ea87f70428355bb01bcf4ebc408de6e19c73.pdf", "paperhash": "yu|spatialwinograd_pruning_enabling_sparse_winograd_convolution", "_bibtex": "@misc{\nyu2019spatialwinograd,\ntitle={Spatial-Winograd Pruning Enabling Sparse Winograd Convolution},\nauthor={Jiecao Yu and Jongsoo Park and Maxim Naumov},\nyear={2019},\nurl={https://openreview.net/forum?id=SJzYdsAqY7},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper373/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621623066, "tddate": null, "super": null, "final": null, "reply": {"forum": "SJzYdsAqY7", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper373/Authors", "ICLR.cc/2019/Conference/Paper373/Reviewers", "ICLR.cc/2019/Conference/Paper373/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper373/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper373/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper373/Authors|ICLR.cc/2019/Conference/Paper373/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper373/Reviewers", "ICLR.cc/2019/Conference/Paper373/Authors", "ICLR.cc/2019/Conference/Paper373/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621623066}}}, {"id": "rJxqlOulAX", "original": null, "number": 7, "cdate": 1542649842080, "ddate": null, "tcdate": 1542649842080, "tmdate": 1542649842080, "tddate": null, "forum": "SJzYdsAqY7", "replyto": "SJlqPc8KTm", "invitation": "ICLR.cc/2019/Conference/-/Paper373/Official_Comment", "content": {"title": "Response to comments", "comment": "Overall this still seems of limited applicability to me, after reading the reviewer response. Clarifying the details of the learning rates used in the pruning and the tradeoffs involved still makes this seem fairly convoluted and unlikely to generalize to different architectures / models.\n\nA more comprehensive discussion of the kinds of speedups (not just sparsity levels but end-to-end speedups) enabled by this and the accuracy tradeoffs we're looking at would help make a future version of this paper more compelling."}, "signatures": ["ICLR.cc/2019/Conference/Paper373/AnonReviewer1"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper373/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper373/AnonReviewer1", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Spatial-Winograd Pruning Enabling Sparse Winograd Convolution", "abstract": "Deep convolutional neural networks (CNNs) are deployed in various applications but demand immense computational requirements. Pruning techniques and Winograd convolution are two typical methods to reduce the CNN computation. However, they cannot be directly combined because Winograd transformation fills in the sparsity resulting from pruning. Li et al. (2017) propose sparse Winograd convolution in which weights are directly pruned in the Winograd domain, but this technique is not very practical because Winograd-domain retraining requires low learning rates and hence significantly longer training time. Besides, Liu et al. (2018) move the ReLU function into the Winograd domain, which can help increase the weight sparsity but requires changes in the network structure. To achieve a high Winograd-domain weight sparsity without changing network structures, we propose a new pruning method, spatial-Winograd pruning. As the first step, spatial-domain weights are pruned in a structured way, which efficiently transfers the spatial-domain sparsity into the Winograd domain and avoids Winograd-domain retraining. For the next step, we also perform pruning and retraining directly in the Winograd domain but propose to use an importance factor matrix to adjust weight importance and weight gradients. This adjustment makes it possible to effectively retrain the pruned Winograd-domain network without changing the network structure. For the three models on the datasets of CIFAR-10, CIFAR-100, and ImageNet, our proposed method can achieve the Winograd-domain sparsities of 63%, 50%, and 74%, respectively.", "keywords": ["deep learning", "convolutional neural network", "pruning", "Winograd convolution"], "authorids": ["jiecaoyu@umich.edu", "jongsoo@fb.com", "mnaumov@fb.com"], "authors": ["Jiecao Yu", "Jongsoo Park", "Maxim Naumov"], "TL;DR": "To accelerate the computation of convolutional neural networks, we propose a new two-step pruning technique which achieves a higher Winograd-domain weight sparsity without changing the network structure.", "pdf": "/pdf/4fc9ea87f70428355bb01bcf4ebc408de6e19c73.pdf", "paperhash": "yu|spatialwinograd_pruning_enabling_sparse_winograd_convolution", "_bibtex": "@misc{\nyu2019spatialwinograd,\ntitle={Spatial-Winograd Pruning Enabling Sparse Winograd Convolution},\nauthor={Jiecao Yu and Jongsoo Park and Maxim Naumov},\nyear={2019},\nurl={https://openreview.net/forum?id=SJzYdsAqY7},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper373/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621623066, "tddate": null, "super": null, "final": null, "reply": {"forum": "SJzYdsAqY7", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper373/Authors", "ICLR.cc/2019/Conference/Paper373/Reviewers", "ICLR.cc/2019/Conference/Paper373/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper373/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper373/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper373/Authors|ICLR.cc/2019/Conference/Paper373/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper373/Reviewers", "ICLR.cc/2019/Conference/Paper373/Authors", "ICLR.cc/2019/Conference/Paper373/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621623066}}}, {"id": "SJlqPc8KTm", "original": null, "number": 4, "cdate": 1542183521750, "ddate": null, "tcdate": 1542183521750, "tmdate": 1542183521750, "tddate": null, "forum": "SJzYdsAqY7", "replyto": "Bygy2gmWhX", "invitation": "ICLR.cc/2019/Conference/-/Paper373/Official_Comment", "content": {"title": "Response to Reviewer 1", "comment": "We thank the reviewers for their feedback and valuable time. Please see our response below.\n\n(1) Tuning the learning rate and sparsity?\nWe follow these simple rules for choosing the hyperparameters:\n\n        (A) Learning rate:\n                (a) Spatial structured pruning: Assume for training the original model, the lowest learning rate is \u03b2. Then the pruned network is retrained with the learning rates of 10*\u03b2 and then \u03b2.\n                (b) Winograd direct pruning: For all the retraining process, we use a fixed learning rate of 1e-6.\n\n        (B) Sparsity rate:\n                (a) Spatial structured pruning: In our evaluation, the sparsity rates used for the iterated levels are mainly based on the settings in the baseline Winograd-ReLU pruning [1]. For practical usage, we can start the pruning with a sparsity of 20%. Then for each iterated level, the sparsity is increased by 10% until the retraining step cannot regain the original accuracy. After this, the sparsity is increased by 5% for every iteration.\n                (b) Winograd direct pruning: In our evaluation, we manually choose the sparsity rate for each iteration. For practical usage, we can use the same strategy as in spatial structure pruning. In the beginning, for each iterated level, the sparsity is increased by 5% until the retraining step cannot regain the required accuracy. After this, the sparsity is increased by 2%/3% for every iteration.\n\n\n(2) Why the first stage is needed?\nAlthough we make the Winograd-domain retraining more effective, Winograd direct pruning still makes the prediction accuracy drop much faster than spatial structured pruning. Therefore, applying only Winograd direct pruning cannot achieve the same sparsity level as the current two-step pruning strategy.\n\n\n(3) Time spent in each phase?\nIn this paper, we are assuming the computational budget is not limited and focusing on how to improve the Winograd-domain sparsity. We will explore how to distribute a limited computational budget in the future work.\n\nAlso, we will try to combine our method with the dynamic network surgery [2] to reduce the computation requirement.  Our current strategy is based on Han et al.\u2019s method [3] in which we generate the pruning mask and then retrain the pruned network. Dynamic network surgery prunes and retrains the network dynamically, which can help reduce the required computation for the pruning process.\n\n---------------------------------------------------------\n[1] Liu, Xingyu, Jeff Pool, Song Han, and William J. Dally. \"Efficient sparse-winograd convolutional neural networks.\" arXiv preprint arXiv:1802.06367 (2018). https://arxiv.org/abs/1802.06367\n[2] Guo, Yiwen, Anbang Yao, and Yurong Chen. \"Dynamic network surgery for efficient dnns.\" Advances In Neural Information Processing Systems. 2016. https://arxiv.org/abs/1608.04493\n[3] Song Han, Jeff Pool, John Tran, and William J. Dally. \u201cLearning both weights and connections for efficient neural networks.\u201d In NIPS, 2015. https://arxiv.org/abs/1506.02626"}, "signatures": ["ICLR.cc/2019/Conference/Paper373/Authors"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper373/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper373/Authors", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Spatial-Winograd Pruning Enabling Sparse Winograd Convolution", "abstract": "Deep convolutional neural networks (CNNs) are deployed in various applications but demand immense computational requirements. Pruning techniques and Winograd convolution are two typical methods to reduce the CNN computation. However, they cannot be directly combined because Winograd transformation fills in the sparsity resulting from pruning. Li et al. (2017) propose sparse Winograd convolution in which weights are directly pruned in the Winograd domain, but this technique is not very practical because Winograd-domain retraining requires low learning rates and hence significantly longer training time. Besides, Liu et al. (2018) move the ReLU function into the Winograd domain, which can help increase the weight sparsity but requires changes in the network structure. To achieve a high Winograd-domain weight sparsity without changing network structures, we propose a new pruning method, spatial-Winograd pruning. As the first step, spatial-domain weights are pruned in a structured way, which efficiently transfers the spatial-domain sparsity into the Winograd domain and avoids Winograd-domain retraining. For the next step, we also perform pruning and retraining directly in the Winograd domain but propose to use an importance factor matrix to adjust weight importance and weight gradients. This adjustment makes it possible to effectively retrain the pruned Winograd-domain network without changing the network structure. For the three models on the datasets of CIFAR-10, CIFAR-100, and ImageNet, our proposed method can achieve the Winograd-domain sparsities of 63%, 50%, and 74%, respectively.", "keywords": ["deep learning", "convolutional neural network", "pruning", "Winograd convolution"], "authorids": ["jiecaoyu@umich.edu", "jongsoo@fb.com", "mnaumov@fb.com"], "authors": ["Jiecao Yu", "Jongsoo Park", "Maxim Naumov"], "TL;DR": "To accelerate the computation of convolutional neural networks, we propose a new two-step pruning technique which achieves a higher Winograd-domain weight sparsity without changing the network structure.", "pdf": "/pdf/4fc9ea87f70428355bb01bcf4ebc408de6e19c73.pdf", "paperhash": "yu|spatialwinograd_pruning_enabling_sparse_winograd_convolution", "_bibtex": "@misc{\nyu2019spatialwinograd,\ntitle={Spatial-Winograd Pruning Enabling Sparse Winograd Convolution},\nauthor={Jiecao Yu and Jongsoo Park and Maxim Naumov},\nyear={2019},\nurl={https://openreview.net/forum?id=SJzYdsAqY7},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper373/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621623066, "tddate": null, "super": null, "final": null, "reply": {"forum": "SJzYdsAqY7", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper373/Authors", "ICLR.cc/2019/Conference/Paper373/Reviewers", "ICLR.cc/2019/Conference/Paper373/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper373/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper373/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper373/Authors|ICLR.cc/2019/Conference/Paper373/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper373/Reviewers", "ICLR.cc/2019/Conference/Paper373/Authors", "ICLR.cc/2019/Conference/Paper373/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621623066}}}, {"id": "HklodPUF6Q", "original": null, "number": 2, "cdate": 1542182770789, "ddate": null, "tcdate": 1542182770789, "tmdate": 1542183341924, "tddate": null, "forum": "SJzYdsAqY7", "replyto": "Syl7K_eS37", "invitation": "ICLR.cc/2019/Conference/-/Paper373/Official_Comment", "content": {"title": "Response to Reviewer 2 for the Minor Comments (Part 2/2)", "comment": "Response for the minor comments:\n\n(1) Whether trained in tandem or in series?\nWe do not start Winograd-domain pruning until we finish spatial structured pruning because the retrained Winograd-domain weights cannot be transformed back into the spatial domain. In both pruning techniques, each pruning+retraining iteration is working on the pruned model generated by the previous iteration.\n\n(2) 20% sparsity in the first layer?\nTo make a fair comparison with the baseline [2], we use the same setting that prunes the first layer with a sparsity of 20% (density of 100%-20%=80%). For conventional DNN models, the first layer has much less redundancy than other layers. Without an accuracy loss, we cannot achieve a high sparsity in the first layer. Therefore, for the goal of speedup, we usually do not prune the first layer.\n\n(3) Different range of sparsities in Figure 3a and Figure 3b?\nAll figures in Figure 3 and Figure 4 show the results until we lose around 1.0% accuracy. Since only <0.1% accuracy loss is allowed for the experiments, we do not show results for the sparsities beyond 60% in Figure 3b.\n\n(4) The variability of sparsity?\nWe hope to answer this question thoroughly. There are two variabilities/non-monotonicity in the plots:\n    A. For either spatial structured pruning or Winograd direct pruning, the accuracy may first go up and then go down. This is because, in the beginning, pruning can reduce overfitting and help achieve higher accuracy. Then with more weights get pruned, the network capacity is reduced and the accuracy goes down. This tendency has been explored in the previous work [7].\n    B. For Winograd direct pruning, we may achieve higher accuracy than the spatial-domain model. This is because the Winograd transformation will increase the number of weight parameters. Also, when directly retraining the Winograd-domain network, we do not need to keep the one-to-one correspondence between the spatial-domain and Winograd-domain weight filters. Each Winograd-domain weight can be trained independently. Therefore, the retrained Winograd-domain network has a higher capability than the spatial-domain network and can achieve higher accuracy.\n\nWe agree with the reviewer that the performance (prediction accuracy) across a range of sparsity is unpredictable. However, this is a common problem for the pruning techniques. Due to the lack of mathematical explanations of DNN models, it is difficult to predict the achievable accuracy with a certain sparsity.\n\n(5) Blue and purple curves in Figure 4 not spacing the entire range of sparsities?\nAs discussed in response (3) for the minor comments, in the evaluation, we only allow a <0.1% accuracy loss. The endpoints of the blue and purple curves already have a much higher accuracy loss.\n\n(6) What is the relative accuracy measured with respect to?\nThe relative accuracy is measured with respect to the baseline accuracy of the original unpruned model (top-1/top-5 prediction accuracy of 69.82%/89.55%).\n\n---------------------------------------------------------\n[1] Li, Sheng, Jongsoo Park, and Ping Tak Peter Tang. \"Enabling sparse Winograd convolution by native pruning.\" arXiv preprint arXiv:1702.08597 (2017). https://arxiv.org/abs/1702.08597\n[2] Liu, Xingyu, Jeff Pool, Song Han, and William J. Dally. \"Efficient sparse-winograd convolutional neural networks.\" arXiv preprint arXiv:1802.06367 (2018).  https://arxiv.org/abs/1802.06367\n[3] Howard, Andrew G., Menglong Zhu, Bo Chen, Dmitry Kalenichenko, Weijun Wang, Tobias Weyand, Marco Andreetto, and Hartwig Adam. \"Mobilenets: Efficient convolutional neural networks for mobile vision applications.\" arXiv preprint arXiv:1704.04861 (2017). https://arxiv.org/abs/1704.04861\n[4] Zhang, Xiangyu, Xinyu Zhou, Mengxiao Lin, and Jian Sun. \"ShuffleNet: An Extremely Efficient Convolutional Neural Network for Mobile Devices.\" https://arxiv.org/abs/1707.01083\n[5] Sandler, Mark, Andrew Howard, Menglong Zhu, Andrey Zhmoginov, and Liang-Chieh Chen. \"Inverted residuals and linear bottlenecks: Mobile networks for classification, detection and segmentation.\" arXiv preprint arXiv:1801.04381 (2018). https://arxiv.org/abs/1801.04381\n[6] Chollet, Fran\u00e7ois. \"Xception: Deep learning with depthwise separable convolutions.\" arXiv preprint (2017): 1610-02357. https://arxiv.org/abs/1610.02357\n[7] Song Han, Jeff Pool, John Tran, and William J. Dally. \u201cLearning both weights and connections for efficient neural networks.\u201d In NIPS, 2015. https://arxiv.org/abs/1506.02626"}, "signatures": ["ICLR.cc/2019/Conference/Paper373/Authors"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper373/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper373/Authors", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Spatial-Winograd Pruning Enabling Sparse Winograd Convolution", "abstract": "Deep convolutional neural networks (CNNs) are deployed in various applications but demand immense computational requirements. Pruning techniques and Winograd convolution are two typical methods to reduce the CNN computation. However, they cannot be directly combined because Winograd transformation fills in the sparsity resulting from pruning. Li et al. (2017) propose sparse Winograd convolution in which weights are directly pruned in the Winograd domain, but this technique is not very practical because Winograd-domain retraining requires low learning rates and hence significantly longer training time. Besides, Liu et al. (2018) move the ReLU function into the Winograd domain, which can help increase the weight sparsity but requires changes in the network structure. To achieve a high Winograd-domain weight sparsity without changing network structures, we propose a new pruning method, spatial-Winograd pruning. As the first step, spatial-domain weights are pruned in a structured way, which efficiently transfers the spatial-domain sparsity into the Winograd domain and avoids Winograd-domain retraining. For the next step, we also perform pruning and retraining directly in the Winograd domain but propose to use an importance factor matrix to adjust weight importance and weight gradients. This adjustment makes it possible to effectively retrain the pruned Winograd-domain network without changing the network structure. For the three models on the datasets of CIFAR-10, CIFAR-100, and ImageNet, our proposed method can achieve the Winograd-domain sparsities of 63%, 50%, and 74%, respectively.", "keywords": ["deep learning", "convolutional neural network", "pruning", "Winograd convolution"], "authorids": ["jiecaoyu@umich.edu", "jongsoo@fb.com", "mnaumov@fb.com"], "authors": ["Jiecao Yu", "Jongsoo Park", "Maxim Naumov"], "TL;DR": "To accelerate the computation of convolutional neural networks, we propose a new two-step pruning technique which achieves a higher Winograd-domain weight sparsity without changing the network structure.", "pdf": "/pdf/4fc9ea87f70428355bb01bcf4ebc408de6e19c73.pdf", "paperhash": "yu|spatialwinograd_pruning_enabling_sparse_winograd_convolution", "_bibtex": "@misc{\nyu2019spatialwinograd,\ntitle={Spatial-Winograd Pruning Enabling Sparse Winograd Convolution},\nauthor={Jiecao Yu and Jongsoo Park and Maxim Naumov},\nyear={2019},\nurl={https://openreview.net/forum?id=SJzYdsAqY7},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper373/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621623066, "tddate": null, "super": null, "final": null, "reply": {"forum": "SJzYdsAqY7", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper373/Authors", "ICLR.cc/2019/Conference/Paper373/Reviewers", "ICLR.cc/2019/Conference/Paper373/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper373/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper373/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper373/Authors|ICLR.cc/2019/Conference/Paper373/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper373/Reviewers", "ICLR.cc/2019/Conference/Paper373/Authors", "ICLR.cc/2019/Conference/Paper373/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621623066}}}, {"id": "SJxFpDUtp7", "original": null, "number": 3, "cdate": 1542182849107, "ddate": null, "tcdate": 1542182849107, "tmdate": 1542183304966, "tddate": null, "forum": "SJzYdsAqY7", "replyto": "Syl7K_eS37", "invitation": "ICLR.cc/2019/Conference/-/Paper373/Official_Comment", "content": {"title": "Response to Reviewer 2 for the Major Comments (Part 1/2)", "comment": "We thank the reviewers for their feedback and valuable time. Please see our response below.\n\nResponse for the major comments:\n\n(1) The number of parameters?\nAs the reviewer comments, the goal of our technique is for faster inferences. Since Winograd convolution only applies to convolutional layers, all the saving shown in this paper is from the convolutional layers.\n\n\n(2/3) Faster inference in a real-world system?\nThe goal of our technique is for faster inferences.\n\nFor the layers with 3x3 kernels in AlexNet, the previous sparse Winograd convolution technique [1] can help achieve an up to 5.4x speedup compared with the spatial convolution on Intel Xeon processors. The baseline used in our paper, Winograd-ReLU pruning [2], can already achieve a higher sparsity than the sparse Winograd convolution. Therefore, we expect our technique to achieve a similar or higher speedup.\n\nIn networks like ResNet-18, our proposed method can achieve a sparsity of around 70%. As the reviewer comments, it is difficult to utilize this level of sparsity for speedup. Therefore, in Appendix B, we try only pruning the second convolutional layer in each residual block (8 convolutional layers in total). As the results show, we can achieve an average sparsity of 87.6% across the pruned layers, which reaches a level of usable sparsity. We are currently working on implementing the sparse Winograd convolution kernel. In the future work, we will also try pruning channel filters for the other unpruned layers to test the highest speedup we can get for the entire network.\n\nOur work focuses on Winograd convolution. Therefore, as the same with the baseline [2], we are not pruning fully-connected layers but only the convolutional layers. Other pruning techniques applicable to fully-connected layers can be combined with our technique for further acceleration.\n\n\n(4) Comparison with methods changing the network architecture.\nDirectly decreasing the number of filters or the kernel sizes usually leads to an accuracy drop while our technique can help accelerate the computation and maintain the same level of accuracy.\n\nIn the following table, we list the numbers of the required parameters and computation for various light-weight designs, Xception and also our pruned ResNet-18 model (74% Winograd-domain sparsity) for the ImageNet challenge.\n\n==============================================\nNetworks                             | Top1   | Params |  MAdds \n-------------------------------------------------------------------------\nMobileNetV1 [3]                  |  70.6   |   4.2M    |   575M\nShuffleNet [4] (1.5*)           |  71.5   |   3.4M    |   292M\nShuffleNet (x2)                    |  73.7   |   5.4M    |   524M\nMobileNetV2 [5] (0.7)         |  69.8   |   2.6M    |   209M\nMobileNetV2                        |  72.0   |   3.4M    |   300M\nMobileNetV2 (1.4)               |  74.7   |   6.9M    |   585M\nXception [6]                          |  79.0   |  22.8M   |  8484M\n-------------------------------------------------------------------------\nPruned ResNet-18 (ours)   | 70.0    |  11.7M   |  262M\n==============================================\n* For the networks, inside the parentheses is the multiplier for the layer size\n\nFor our pruned ResNet-18 model, the remaining parameters and MAdds (multiply-add) are comparable with those light-weight designs. One thing needs to be mentioned is that the first convolutional layer (which is not pruned) in our ResNet-18 model costs 118M MAdds which is 118M/262M = 45% of the total computation.\n\nHowever, our pruned model performs sparse computation which is less efficient than the conventional dense computation. Therefore, in the future work, we will work on implementing an efficient sparse Winograd convolution library. Also, it is promising to investigate combining the light-weight designs and our proposed spatial-Winograd pruning technique. This combination may help further reduce the computation required for achieving a certain accuracy.\n\n---------------------------------------------------------\nFor the references, please check the next part."}, "signatures": ["ICLR.cc/2019/Conference/Paper373/Authors"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper373/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper373/Authors", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Spatial-Winograd Pruning Enabling Sparse Winograd Convolution", "abstract": "Deep convolutional neural networks (CNNs) are deployed in various applications but demand immense computational requirements. Pruning techniques and Winograd convolution are two typical methods to reduce the CNN computation. However, they cannot be directly combined because Winograd transformation fills in the sparsity resulting from pruning. Li et al. (2017) propose sparse Winograd convolution in which weights are directly pruned in the Winograd domain, but this technique is not very practical because Winograd-domain retraining requires low learning rates and hence significantly longer training time. Besides, Liu et al. (2018) move the ReLU function into the Winograd domain, which can help increase the weight sparsity but requires changes in the network structure. To achieve a high Winograd-domain weight sparsity without changing network structures, we propose a new pruning method, spatial-Winograd pruning. As the first step, spatial-domain weights are pruned in a structured way, which efficiently transfers the spatial-domain sparsity into the Winograd domain and avoids Winograd-domain retraining. For the next step, we also perform pruning and retraining directly in the Winograd domain but propose to use an importance factor matrix to adjust weight importance and weight gradients. This adjustment makes it possible to effectively retrain the pruned Winograd-domain network without changing the network structure. For the three models on the datasets of CIFAR-10, CIFAR-100, and ImageNet, our proposed method can achieve the Winograd-domain sparsities of 63%, 50%, and 74%, respectively.", "keywords": ["deep learning", "convolutional neural network", "pruning", "Winograd convolution"], "authorids": ["jiecaoyu@umich.edu", "jongsoo@fb.com", "mnaumov@fb.com"], "authors": ["Jiecao Yu", "Jongsoo Park", "Maxim Naumov"], "TL;DR": "To accelerate the computation of convolutional neural networks, we propose a new two-step pruning technique which achieves a higher Winograd-domain weight sparsity without changing the network structure.", "pdf": "/pdf/4fc9ea87f70428355bb01bcf4ebc408de6e19c73.pdf", "paperhash": "yu|spatialwinograd_pruning_enabling_sparse_winograd_convolution", "_bibtex": "@misc{\nyu2019spatialwinograd,\ntitle={Spatial-Winograd Pruning Enabling Sparse Winograd Convolution},\nauthor={Jiecao Yu and Jongsoo Park and Maxim Naumov},\nyear={2019},\nurl={https://openreview.net/forum?id=SJzYdsAqY7},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper373/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621623066, "tddate": null, "super": null, "final": null, "reply": {"forum": "SJzYdsAqY7", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper373/Authors", "ICLR.cc/2019/Conference/Paper373/Reviewers", "ICLR.cc/2019/Conference/Paper373/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper373/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper373/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper373/Authors|ICLR.cc/2019/Conference/Paper373/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper373/Reviewers", "ICLR.cc/2019/Conference/Paper373/Authors", "ICLR.cc/2019/Conference/Paper373/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621623066}}}, {"id": "B1g1k7LKpm", "original": null, "number": 1, "cdate": 1542181591149, "ddate": null, "tcdate": 1542181591149, "tmdate": 1542182529023, "tddate": null, "forum": "SJzYdsAqY7", "replyto": "B1x8ypt0nQ", "invitation": "ICLR.cc/2019/Conference/-/Paper373/Official_Comment", "content": {"title": "Response to Reviewer 3", "comment": "We thank the reviewers for their feedback and valuable time. Please see our response below.\n\n\n(1) Marginal improvements?\nAlthough our proposed method does not achieve a much higher sparsity than the baseline [1], the expected performance improvement is considerable. With the sparse Winograd convolution, the execution time of the convolutional layer is proportional to the density of the weights. Therefore, as an example, with <0.1% top-1 accuracy loss on the ResNet-18 model, our technique can increase the sparsity from 70% to 74%. The expected execution time reduction is 100% - (100%-74%)/(100%-70%) = 13%.\n\nAlso, our proposed technique can help avoid changing the network structure.\n\nIn the future work, for the baseline Winograd-ReLU pruning [1], we will test whether adjusting the gradients with our proposed importance factor matrix can help further increase the Winograd-domain sparsity on certain networks.\n\n\n(2) Comparison with the light-weight designs?\nIn the following table, we list the numbers of the required parameters and computation for various light-weight designs, Xception and also our pruned ResNet-18 model (74% Winograd-domain sparsity) for the ImageNet challenge.\n\n==============================================\nNetworks                             | Top1   | Params |  MAdds \n-------------------------------------------------------------------------\nMobileNetV1 [2]                  |  70.6   |   4.2M    |   575M\nShuffleNet [3] (1.5*)           |  71.5   |   3.4M    |   292M\nShuffleNet (x2)                    |  73.7   |   5.4M    |   524M\nMobileNetV2 [4] (0.7)         |  69.8   |   2.6M    |   209M\nMobileNetV2                        |  72.0   |   3.4M    |   300M\nMobileNetV2 (1.4)               |  74.7   |   6.9M    |   585M\nXception [5]                          |  79.0   |  22.8M   |  8484M\n-------------------------------------------------------------------------\nPruned ResNet-18 (ours)   | 70.0    |  11.7M   |  262M\n==============================================\n* For the networks, inside the parentheses is the multiplier for layer size\n\nFor our pruned ResNet-18 model, the remaining parameters and MAdds (multiply-add) are comparable with those light-weight designs. One thing needs to be mentioned is that the first convolutional layer (which is not pruned) in our ResNet-18 model costs 118M MAdds which is 118M/262M = 45% of the total computation.\n\nHowever, our pruned model performs sparse computation which is less efficient than the conventional dense computation. Therefore, in the future work, we will work on implementing an efficient sparse Winograd convolution library. Also, it is promising to investigate combining the light-weight designs and our proposed spatial-Winograd pruning technique. This combination may help further reduce the computation required for achieving a certain accuracy.\n\n---------------------------------------------------------\n[1] Liu, Xingyu, Jeff Pool, Song Han, and William J. Dally. \"Efficient sparse-winograd convolutional neural networks.\" arXiv preprint arXiv:1802.06367 (2018).   https://arxiv.org/abs/1802.06367\n[2] Howard, Andrew G., Menglong Zhu, Bo Chen, Dmitry Kalenichenko, Weijun Wang, Tobias Weyand, Marco Andreetto, and Hartwig Adam. \"Mobilenets: Efficient convolutional neural networks for mobile vision applications.\" arXiv preprint arXiv:1704.04861 (2017). https://arxiv.org/abs/1704.04861\n[3] Zhang, Xiangyu, Xinyu Zhou, Mengxiao Lin, and Jian Sun. \"ShuffleNet: An Extremely Efficient Convolutional Neural Network for Mobile Devices.\" https://arxiv.org/abs/1707.01083\n[4] Sandler, Mark, Andrew Howard, Menglong Zhu, Andrey Zhmoginov, and Liang-Chieh Chen. \"Inverted residuals and linear bottlenecks: Mobile networks for classification, detection and segmentation.\" arXiv preprint arXiv:1801.04381 (2018). https://arxiv.org/abs/1801.04381\n[5] Chollet, Fran\u00e7ois. \"Xception: Deep learning with depthwise separable convolutions.\" arXiv preprint (2017): 1610-02357. https://arxiv.org/abs/1610.02357\n"}, "signatures": ["ICLR.cc/2019/Conference/Paper373/Authors"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper373/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper373/Authors", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Spatial-Winograd Pruning Enabling Sparse Winograd Convolution", "abstract": "Deep convolutional neural networks (CNNs) are deployed in various applications but demand immense computational requirements. Pruning techniques and Winograd convolution are two typical methods to reduce the CNN computation. However, they cannot be directly combined because Winograd transformation fills in the sparsity resulting from pruning. Li et al. (2017) propose sparse Winograd convolution in which weights are directly pruned in the Winograd domain, but this technique is not very practical because Winograd-domain retraining requires low learning rates and hence significantly longer training time. Besides, Liu et al. (2018) move the ReLU function into the Winograd domain, which can help increase the weight sparsity but requires changes in the network structure. To achieve a high Winograd-domain weight sparsity without changing network structures, we propose a new pruning method, spatial-Winograd pruning. As the first step, spatial-domain weights are pruned in a structured way, which efficiently transfers the spatial-domain sparsity into the Winograd domain and avoids Winograd-domain retraining. For the next step, we also perform pruning and retraining directly in the Winograd domain but propose to use an importance factor matrix to adjust weight importance and weight gradients. This adjustment makes it possible to effectively retrain the pruned Winograd-domain network without changing the network structure. For the three models on the datasets of CIFAR-10, CIFAR-100, and ImageNet, our proposed method can achieve the Winograd-domain sparsities of 63%, 50%, and 74%, respectively.", "keywords": ["deep learning", "convolutional neural network", "pruning", "Winograd convolution"], "authorids": ["jiecaoyu@umich.edu", "jongsoo@fb.com", "mnaumov@fb.com"], "authors": ["Jiecao Yu", "Jongsoo Park", "Maxim Naumov"], "TL;DR": "To accelerate the computation of convolutional neural networks, we propose a new two-step pruning technique which achieves a higher Winograd-domain weight sparsity without changing the network structure.", "pdf": "/pdf/4fc9ea87f70428355bb01bcf4ebc408de6e19c73.pdf", "paperhash": "yu|spatialwinograd_pruning_enabling_sparse_winograd_convolution", "_bibtex": "@misc{\nyu2019spatialwinograd,\ntitle={Spatial-Winograd Pruning Enabling Sparse Winograd Convolution},\nauthor={Jiecao Yu and Jongsoo Park and Maxim Naumov},\nyear={2019},\nurl={https://openreview.net/forum?id=SJzYdsAqY7},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper373/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621623066, "tddate": null, "super": null, "final": null, "reply": {"forum": "SJzYdsAqY7", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper373/Authors", "ICLR.cc/2019/Conference/Paper373/Reviewers", "ICLR.cc/2019/Conference/Paper373/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper373/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper373/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper373/Authors|ICLR.cc/2019/Conference/Paper373/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper373/Reviewers", "ICLR.cc/2019/Conference/Paper373/Authors", "ICLR.cc/2019/Conference/Paper373/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621623066}}}, {"id": "B1x8ypt0nQ", "original": null, "number": 3, "cdate": 1541475549768, "ddate": null, "tcdate": 1541475549768, "tmdate": 1541534050202, "tddate": null, "forum": "SJzYdsAqY7", "replyto": "SJzYdsAqY7", "invitation": "ICLR.cc/2019/Conference/-/Paper373/Official_Review", "content": {"title": "spatial-Winograd pruning", "review": "In this paper, the authors propose a spatial-Winograd pruning framework, consisting of spatial structured pruning and Winograd direct pruning.  First, spatial structured pruning allows the pruned weight in the spatial domain to be kept in the Winograd domain. Then, Winograd direct pruning can further improve the sparsity in the Winograd domain. The organization of paper is OK.  The main concern is about the practical part. In the experiment, the advantage of propose framework is marginal, compared to the relevant approaches.  More comparisons with the state-of-the-art approaches should be investigated, such as light-weight design (MobileNet, ShuffleNet).  ", "rating": "5: Marginally below acceptance threshold", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "signatures": ["ICLR.cc/2019/Conference/Paper373/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Spatial-Winograd Pruning Enabling Sparse Winograd Convolution", "abstract": "Deep convolutional neural networks (CNNs) are deployed in various applications but demand immense computational requirements. Pruning techniques and Winograd convolution are two typical methods to reduce the CNN computation. However, they cannot be directly combined because Winograd transformation fills in the sparsity resulting from pruning. Li et al. (2017) propose sparse Winograd convolution in which weights are directly pruned in the Winograd domain, but this technique is not very practical because Winograd-domain retraining requires low learning rates and hence significantly longer training time. Besides, Liu et al. (2018) move the ReLU function into the Winograd domain, which can help increase the weight sparsity but requires changes in the network structure. To achieve a high Winograd-domain weight sparsity without changing network structures, we propose a new pruning method, spatial-Winograd pruning. As the first step, spatial-domain weights are pruned in a structured way, which efficiently transfers the spatial-domain sparsity into the Winograd domain and avoids Winograd-domain retraining. For the next step, we also perform pruning and retraining directly in the Winograd domain but propose to use an importance factor matrix to adjust weight importance and weight gradients. This adjustment makes it possible to effectively retrain the pruned Winograd-domain network without changing the network structure. For the three models on the datasets of CIFAR-10, CIFAR-100, and ImageNet, our proposed method can achieve the Winograd-domain sparsities of 63%, 50%, and 74%, respectively.", "keywords": ["deep learning", "convolutional neural network", "pruning", "Winograd convolution"], "authorids": ["jiecaoyu@umich.edu", "jongsoo@fb.com", "mnaumov@fb.com"], "authors": ["Jiecao Yu", "Jongsoo Park", "Maxim Naumov"], "TL;DR": "To accelerate the computation of convolutional neural networks, we propose a new two-step pruning technique which achieves a higher Winograd-domain weight sparsity without changing the network structure.", "pdf": "/pdf/4fc9ea87f70428355bb01bcf4ebc408de6e19c73.pdf", "paperhash": "yu|spatialwinograd_pruning_enabling_sparse_winograd_convolution", "_bibtex": "@misc{\nyu2019spatialwinograd,\ntitle={Spatial-Winograd Pruning Enabling Sparse Winograd Convolution},\nauthor={Jiecao Yu and Jongsoo Park and Maxim Naumov},\nyear={2019},\nurl={https://openreview.net/forum?id=SJzYdsAqY7},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper373/Official_Review", "cdate": 1542234476083, "expdate": 1552335264000, "duedate": 1541196000000, "reply": {"forum": "SJzYdsAqY7", "replyto": "SJzYdsAqY7", "readers": {"description": "The users who will be allowed to read the reply content.", "values": ["everyone"]}, "nonreaders": {"values": []}, "signatures": {"description": "How your identity will be displayed with the above content.", "values-regex": "ICLR.cc/2019/Conference/Paper373/AnonReviewer[0-9]+"}, "writers": {"description": "Users that may modify this record.", "values": ["ICLR.cc/2019/Conference"]}, "content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "required": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}}, "multiReply": false, "tcdate": 1552335709671, "tmdate": 1552335709671, "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "invitees": ["ICLR.cc/2019/Conference/Paper373/Reviewers"], "noninvitees": [], "signatures": ["ICLR.cc/2019/Conference"]}}}, {"id": "Syl7K_eS37", "original": null, "number": 2, "cdate": 1540847739038, "ddate": null, "tcdate": 1540847739038, "tmdate": 1541534049991, "tddate": null, "forum": "SJzYdsAqY7", "replyto": "SJzYdsAqY7", "invitation": "ICLR.cc/2019/Conference/-/Paper373/Official_Review", "content": {"title": "Official Review of Spatial-Winograd Pruning", "review": "Review of Spatial-Winograd Pruning Enabling Sparse Winograd Convolution\n\nSummary:\nIn this submission, the authors propose a new method for pruning weights in the presence in CNNs in which the convolution is expressed as a CNN. The goal of the project is to demonstrate that they can achieve a network which contains fewer weights (and runs faster) then the original network with minimal sacrifice in network performance and without altering the network architecture.\n\nMajor Comments:\nMy largest comments and concerns revolve around the degree to which the proposed pruning methods results in a model that is applicable for real world devices.\n\n1. At the minimum, the authors should provide a table with the number of parameters in the (a) original networks, (b) network with baseline pruning method and (c) network with their pruning methods. (Are the savings entirely in convolutional filters or are there savings from fully connected layers?)\n\n2. If the authors are indeed arguing that a goal of network pruning is to perform faster inference, then results must be shown to justify this -- as it is not obvious that speed-ups could be achieved by just pruning weights. In the case of other methods, speed-ups may be achieved by selectively pruning channel filters (as opposed to spatial positions in the convolutional filter) or pruning fully connected layers (in fact, for VGG and AlexNet, a majority of the reduction in parameters due to pruning were found in these layers).\n\n3. Are these levels of sparsity useable in a real-world system? Often the degree of sparsity in \"vanilla\" CNNs are at levels (e.g. in AlexNet, 30-50% sparsity in higher layers) not high enough to be harnessed for a fast implementation. Selectively zero-ing out individual spatial components of a filter might reduce the parameter count but not achieve any speed up gains. That is, the sparsity must be structured in such a way as to permit a faster implementation [e.g. 1]\n\n4. Considering that one of the baselines changes the network architecture itself [2], I would be curious to understand how effective this method is versus other, simple baselines that change the network architecture such as (1) decreasing the number of filter, (2) decreasing the kernel sizes, (3) swapping a convolutional filter for a separable convolution [3, 4]. All of these baselines are simple to train and experiment with and a practitioner would probably consider in many situations where speed or # parameters are a constraint.\n\nMinor Comments:\n\n- It is unclear from the presentation whether both proposed pruning methods may be trained in tandem or in series. Please clarify in the manuscript.\n\n- Why does Figure 3a, 3b focus on maintaining 20% sparsity on the 1st layer of the network systematically all other layers in sparsity? What is special about the first layer?\n\n- Why do the authors explore a different range of sparsities in Figure 3a and Figure 3b?\n\n- The authors should discuss the source of the variability (and non-monotonicity) in the plots in Figure 3 and 4 for their proposed method. How are we to interpret this? Naively, it would be appear that the method is somewhat unpredictable in performance across a range of sparsity.\n\n- Why do the blue and purple curves in Figure 4 not space the entire range of sparsities?\n\n- Figure 5b. What is the relative accuracy measured with respect to? The baseline model at that particular epoch or at final asymptotic performance?\n\n[1] Outrageously Large Neural Networks: The Sparsely-Gated Mixture-of-Experts Layer\nhttps://openreview.net/forum?id=B1ckMDqlg\n\n[2] Efficient sparse-winograd convolutional neural networks.\nXingyu Liu, Jeff Pool, Song Han, and William J Dally.\n\n[3] MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications\nAndrew G. Howard, Menglong Zhu, Bo Chen, Dmitry Kalenichenko, Weijun Wang, Tobias Weyand, Marco Andreetto, Hartwig Adam\nhttps://arxiv.org/abs/1704.04861\n\n[4] Xception: Deep Learning with Depthwise Separable Convolutions\nFran\u00e7ois Chollet\nhttps://arxiv.org/abs/1610.02357\n", "rating": "4: Ok but not good enough - rejection", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "signatures": ["ICLR.cc/2019/Conference/Paper373/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Spatial-Winograd Pruning Enabling Sparse Winograd Convolution", "abstract": "Deep convolutional neural networks (CNNs) are deployed in various applications but demand immense computational requirements. Pruning techniques and Winograd convolution are two typical methods to reduce the CNN computation. However, they cannot be directly combined because Winograd transformation fills in the sparsity resulting from pruning. Li et al. (2017) propose sparse Winograd convolution in which weights are directly pruned in the Winograd domain, but this technique is not very practical because Winograd-domain retraining requires low learning rates and hence significantly longer training time. Besides, Liu et al. (2018) move the ReLU function into the Winograd domain, which can help increase the weight sparsity but requires changes in the network structure. To achieve a high Winograd-domain weight sparsity without changing network structures, we propose a new pruning method, spatial-Winograd pruning. As the first step, spatial-domain weights are pruned in a structured way, which efficiently transfers the spatial-domain sparsity into the Winograd domain and avoids Winograd-domain retraining. For the next step, we also perform pruning and retraining directly in the Winograd domain but propose to use an importance factor matrix to adjust weight importance and weight gradients. This adjustment makes it possible to effectively retrain the pruned Winograd-domain network without changing the network structure. For the three models on the datasets of CIFAR-10, CIFAR-100, and ImageNet, our proposed method can achieve the Winograd-domain sparsities of 63%, 50%, and 74%, respectively.", "keywords": ["deep learning", "convolutional neural network", "pruning", "Winograd convolution"], "authorids": ["jiecaoyu@umich.edu", "jongsoo@fb.com", "mnaumov@fb.com"], "authors": ["Jiecao Yu", "Jongsoo Park", "Maxim Naumov"], "TL;DR": "To accelerate the computation of convolutional neural networks, we propose a new two-step pruning technique which achieves a higher Winograd-domain weight sparsity without changing the network structure.", "pdf": "/pdf/4fc9ea87f70428355bb01bcf4ebc408de6e19c73.pdf", "paperhash": "yu|spatialwinograd_pruning_enabling_sparse_winograd_convolution", "_bibtex": "@misc{\nyu2019spatialwinograd,\ntitle={Spatial-Winograd Pruning Enabling Sparse Winograd Convolution},\nauthor={Jiecao Yu and Jongsoo Park and Maxim Naumov},\nyear={2019},\nurl={https://openreview.net/forum?id=SJzYdsAqY7},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper373/Official_Review", "cdate": 1542234476083, "expdate": 1552335264000, "duedate": 1541196000000, "reply": {"forum": "SJzYdsAqY7", "replyto": "SJzYdsAqY7", "readers": {"description": "The users who will be allowed to read the reply content.", "values": ["everyone"]}, "nonreaders": {"values": []}, "signatures": {"description": "How your identity will be displayed with the above content.", "values-regex": "ICLR.cc/2019/Conference/Paper373/AnonReviewer[0-9]+"}, "writers": {"description": "Users that may modify this record.", "values": ["ICLR.cc/2019/Conference"]}, "content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "required": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}}, "multiReply": false, "tcdate": 1552335709671, "tmdate": 1552335709671, "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "invitees": ["ICLR.cc/2019/Conference/Paper373/Reviewers"], "noninvitees": [], "signatures": ["ICLR.cc/2019/Conference"]}}}, {"id": "Bygy2gmWhX", "original": null, "number": 1, "cdate": 1540595878940, "ddate": null, "tcdate": 1540595878940, "tmdate": 1541534049750, "tddate": null, "forum": "SJzYdsAqY7", "replyto": "SJzYdsAqY7", "invitation": "ICLR.cc/2019/Conference/-/Paper373/Official_Review", "content": {"title": "Winograd-aware pruning of convolutions", "review": "The paper proposes a technique (well, two) to prune convolutional layers to reduce the required amount of computation when  the convolutions are done using the winograd algorithm. Winograd convolutions first transform the image and the filter, apply a multiplication in the transformed space, and then retransform the image back to the intended image space. The transformation of the filter, however, means that sparsity in the regular domain does not translate to sparsity in the winograd domain.\n\nThis paper presents two techniques to achieve sparsity in the winograd domain: approximating winograd sparsity based on sparsity in the regular domain (thereby pruning with a non uniform cost model) and pruning in winograd space directly. The actual implementation alternates the first pruning technique and retraining the network with fixed sparsity followed by alternating winograd-space pruning and retraining. The tricky part is retraining in winograd space, which seems to require fine tuned per coordinate learning rates.\n\nMy main concern is that the method feels fairly fragile and hyperparameter-heavy: tuning all the learning rates and sparsity rates for all these iterated levels of pruning doesn't seem easy. Similarly, it's unclear why the first stage of pruning is even needed if it's possible to prune and fine tune in winograd space directly. It's unclear from reading the paper how, given a computational budget, to decide the time spent in each phase of the process.\n\n", "rating": "6: Marginally above acceptance threshold", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "signatures": ["ICLR.cc/2019/Conference/Paper373/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Spatial-Winograd Pruning Enabling Sparse Winograd Convolution", "abstract": "Deep convolutional neural networks (CNNs) are deployed in various applications but demand immense computational requirements. Pruning techniques and Winograd convolution are two typical methods to reduce the CNN computation. However, they cannot be directly combined because Winograd transformation fills in the sparsity resulting from pruning. Li et al. (2017) propose sparse Winograd convolution in which weights are directly pruned in the Winograd domain, but this technique is not very practical because Winograd-domain retraining requires low learning rates and hence significantly longer training time. Besides, Liu et al. (2018) move the ReLU function into the Winograd domain, which can help increase the weight sparsity but requires changes in the network structure. To achieve a high Winograd-domain weight sparsity without changing network structures, we propose a new pruning method, spatial-Winograd pruning. As the first step, spatial-domain weights are pruned in a structured way, which efficiently transfers the spatial-domain sparsity into the Winograd domain and avoids Winograd-domain retraining. For the next step, we also perform pruning and retraining directly in the Winograd domain but propose to use an importance factor matrix to adjust weight importance and weight gradients. This adjustment makes it possible to effectively retrain the pruned Winograd-domain network without changing the network structure. For the three models on the datasets of CIFAR-10, CIFAR-100, and ImageNet, our proposed method can achieve the Winograd-domain sparsities of 63%, 50%, and 74%, respectively.", "keywords": ["deep learning", "convolutional neural network", "pruning", "Winograd convolution"], "authorids": ["jiecaoyu@umich.edu", "jongsoo@fb.com", "mnaumov@fb.com"], "authors": ["Jiecao Yu", "Jongsoo Park", "Maxim Naumov"], "TL;DR": "To accelerate the computation of convolutional neural networks, we propose a new two-step pruning technique which achieves a higher Winograd-domain weight sparsity without changing the network structure.", "pdf": "/pdf/4fc9ea87f70428355bb01bcf4ebc408de6e19c73.pdf", "paperhash": "yu|spatialwinograd_pruning_enabling_sparse_winograd_convolution", "_bibtex": "@misc{\nyu2019spatialwinograd,\ntitle={Spatial-Winograd Pruning Enabling Sparse Winograd Convolution},\nauthor={Jiecao Yu and Jongsoo Park and Maxim Naumov},\nyear={2019},\nurl={https://openreview.net/forum?id=SJzYdsAqY7},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper373/Official_Review", "cdate": 1542234476083, "expdate": 1552335264000, "duedate": 1541196000000, "reply": {"forum": "SJzYdsAqY7", "replyto": "SJzYdsAqY7", "readers": {"description": "The users who will be allowed to read the reply content.", "values": ["everyone"]}, "nonreaders": {"values": []}, "signatures": {"description": "How your identity will be displayed with the above content.", "values-regex": "ICLR.cc/2019/Conference/Paper373/AnonReviewer[0-9]+"}, "writers": {"description": "Users that may modify this record.", "values": ["ICLR.cc/2019/Conference"]}, "content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "required": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}}, "multiReply": false, "tcdate": 1552335709671, "tmdate": 1552335709671, "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "invitees": ["ICLR.cc/2019/Conference/Paper373/Reviewers"], "noninvitees": [], "signatures": ["ICLR.cc/2019/Conference"]}}}], "count": 13}