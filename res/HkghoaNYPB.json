{"notes": [{"id": "HkghoaNYPB", "original": "B1ed8uJdPr", "number": 760, "cdate": 1569439140513, "ddate": null, "tcdate": 1569439140513, "tmdate": 1577168233157, "tddate": null, "forum": "HkghoaNYPB", "replyto": null, "invitation": "ICLR.cc/2020/Conference/-/Blind_Submission", "content": {"authorids": ["felix.petersen@uni.kn", "christian@borgelt.net", "oliver.deussen@uni.kn"], "title": "AlgoNet: $C^\\infty$ Smooth Algorithmic Neural Networks", "authors": ["Felix Petersen", "Christian Borgelt", "Oliver Deussen"], "pdf": "/pdf/92775c162aad0300227b970954d7c1b3737fa668.pdf", "TL;DR": "Integrating classical algorithms into neural networks.", "abstract": "Artificial neural networks have revolutionized many areas of computer science in recent years, providing solutions to a number of previously unsolved problems.\nOn the other hand, for many problems, classic algorithms exist, which typically exceed the accuracy and stability of neural networks.\nTo combine these two concepts, we present a new kind of neural networks\u2014algorithmic neural networks (AlgoNets).\nThese networks integrate smooth versions of classic algorithms into the topology of neural networks.\nA forward AlgoNet includes algorithmic layers into existing architectures to enhance performance and explainability while a backward AlgoNet enables solving inverse problems without or with only weak supervision.\nIn addition, we present the algonet package, a PyTorch based library that includes, inter alia, a smoothly evaluated programming language, a smooth 3D mesh renderer, and smooth sorting algorithms.", "keywords": ["Algorithms", "Smoothness", "Differentiable", "Inverse Problems", "Adversarial Training", "Neural Networks", "Deep Learning", "Differentiable Renderer", "3D Mesh", "Turing-completeness", "Library"], "paperhash": "petersen|algonet_c^\\infty_smooth_algorithmic_neural_networks", "original_pdf": "/attachment/92775c162aad0300227b970954d7c1b3737fa668.pdf", "_bibtex": "@misc{\npetersen2020algonet,\ntitle={AlgoNet: {\\$}C^{\\textbackslash}infty{\\$} Smooth Algorithmic Neural Networks},\nauthor={Felix Petersen and Christian Borgelt and Oliver Deussen},\nyear={2020},\nurl={https://openreview.net/forum?id=HkghoaNYPB}\n}"}, "signatures": ["ICLR.cc/2020/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference"], "details": {"replyCount": 4, "writable": false, "overwriting": [], "revisions": false, "tags": [], "invitation": {"reply": {"readers": {"values-regex": ".*"}, "writers": {"values": ["ICLR.cc/2020/Conference"]}, "signatures": {"values": ["ICLR.cc/2020/Conference"]}, "content": {"spotlight_video": {"value-regex": ".*"}, "full_presentation_video": {"value-regex": ".*"}, "original_pdf": {"required": false, "description": "Upload a PDF file that ends with .pdf", "value-regex": ".*"}, "appendix": {"value-regex": ".*"}, "authorids": {"values-regex": ".*"}, "poster": {"value-regex": ".*"}, "authors": {"values": ["Anonymous"]}, "slides": {"value-regex": ".*"}}}, "final": [], "signatures": ["ICLR.cc/2020/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference"], "noninvitees": [], "tcdate": 1569271260237, "tmdate": 1593459412141, "id": "ICLR.cc/2020/Conference/-/Blind_Submission"}}, "tauthor": "OpenReview.net"}, {"id": "YfCeyhV6Nz", "original": null, "number": 1, "cdate": 1576798705302, "ddate": null, "tcdate": 1576798705302, "tmdate": 1576800930817, "tddate": null, "forum": "HkghoaNYPB", "replyto": "HkghoaNYPB", "invitation": "ICLR.cc/2020/Conference/Paper760/-/Decision", "content": {"decision": "Reject", "comment": "The paper does not provide theory or experiment to justify the various proposed relaxations. In its current form, it has very limited scope.", "title": "Paper Decision"}, "signatures": ["ICLR.cc/2020/Conference/Program_Chairs"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Program_Chairs"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["felix.petersen@uni.kn", "christian@borgelt.net", "oliver.deussen@uni.kn"], "title": "AlgoNet: $C^\\infty$ Smooth Algorithmic Neural Networks", "authors": ["Felix Petersen", "Christian Borgelt", "Oliver Deussen"], "pdf": "/pdf/92775c162aad0300227b970954d7c1b3737fa668.pdf", "TL;DR": "Integrating classical algorithms into neural networks.", "abstract": "Artificial neural networks have revolutionized many areas of computer science in recent years, providing solutions to a number of previously unsolved problems.\nOn the other hand, for many problems, classic algorithms exist, which typically exceed the accuracy and stability of neural networks.\nTo combine these two concepts, we present a new kind of neural networks\u2014algorithmic neural networks (AlgoNets).\nThese networks integrate smooth versions of classic algorithms into the topology of neural networks.\nA forward AlgoNet includes algorithmic layers into existing architectures to enhance performance and explainability while a backward AlgoNet enables solving inverse problems without or with only weak supervision.\nIn addition, we present the algonet package, a PyTorch based library that includes, inter alia, a smoothly evaluated programming language, a smooth 3D mesh renderer, and smooth sorting algorithms.", "keywords": ["Algorithms", "Smoothness", "Differentiable", "Inverse Problems", "Adversarial Training", "Neural Networks", "Deep Learning", "Differentiable Renderer", "3D Mesh", "Turing-completeness", "Library"], "paperhash": "petersen|algonet_c^\\infty_smooth_algorithmic_neural_networks", "original_pdf": "/attachment/92775c162aad0300227b970954d7c1b3737fa668.pdf", "_bibtex": "@misc{\npetersen2020algonet,\ntitle={AlgoNet: {\\$}C^{\\textbackslash}infty{\\$} Smooth Algorithmic Neural Networks},\nauthor={Felix Petersen and Christian Borgelt and Oliver Deussen},\nyear={2020},\nurl={https://openreview.net/forum?id=HkghoaNYPB}\n}"}, "tags": [], "invitation": {"reply": {"writers": {"description": "How your identity will be displayed.", "values-regex": ["ICLR.cc/2020/Conference/Program_Chairs"]}, "signatures": {"values": ["ICLR.cc/2020/Conference/Program_Chairs"], "description": "How your identity will be displayed."}, "content": {"decision": {"value-radio": ["Accept (Spotlight)", "Accept (Talk)", "Accept (Poster)", "Reject"], "description": "Decision", "required": true, "order": 2}, "title": {"value": "Paper Decision", "required": true, "order": 1}, "comment": {"value-regex": "[\\S\\s]{0,5000}", "description": "", "required": false, "order": 3}}, "forum": "HkghoaNYPB", "replyto": "HkghoaNYPB", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}}, "expdate": 1576854540000, "duedate": 1576853940000, "multiReply": false, "readers": ["everyone"], "invitees": ["ICLR.cc/2020/Conference/Program_Chairs"], "tcdate": 1576795728605, "tmdate": 1576800281041, "super": "ICLR.cc/2020/Conference/-/Decision", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper760/-/Decision"}}}, {"id": "rylUQbwIiB", "original": null, "number": 3, "cdate": 1573445917593, "ddate": null, "tcdate": 1573445917593, "tmdate": 1573445917593, "tddate": null, "forum": "HkghoaNYPB", "replyto": "HkghoaNYPB", "invitation": "ICLR.cc/2020/Conference/Paper760/-/Official_Review", "content": {"experience_assessment": "I have published in this field for several years.", "rating": "1: Reject", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "title": "Official Blind Review #1", "review": "This paper describes \"AlgoNets\", which are differentiable implementations of classical algorithms. Several AlgoNets are described, including multiplication algorithm implemented in the WHILE programming language, smooth sorting, a smooth while loop, smooth finite differences and a softmedian.\n\nThe paper additionally presents RANs (similar to GANs but with an AlgoNet embedded) and Forward AlgoNets (where the the AlgoNet is embedded in a feedforward net). \n\nThe smooth implementations normally amount to replacing hard functions with soft equivalents, for example \"if\" conditions are replaced by logistic sigmoids.\n\nThe research direction in this paper is very interesting and could lead to important advancements, however a strong argument needs to be presented to the readers about why this way of making algorithms smooth is better than other published or obvious techniques.\n\nThe argument could be theoretical, proving for example faster convergence under certain assumptions, or it could be empirical, showing that the method achieves better results than other techniques on some benchmarks. I could not see however any such arguments in this paper.", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory."}, "signatures": ["ICLR.cc/2020/Conference/Paper760/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper760/AnonReviewer1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["felix.petersen@uni.kn", "christian@borgelt.net", "oliver.deussen@uni.kn"], "title": "AlgoNet: $C^\\infty$ Smooth Algorithmic Neural Networks", "authors": ["Felix Petersen", "Christian Borgelt", "Oliver Deussen"], "pdf": "/pdf/92775c162aad0300227b970954d7c1b3737fa668.pdf", "TL;DR": "Integrating classical algorithms into neural networks.", "abstract": "Artificial neural networks have revolutionized many areas of computer science in recent years, providing solutions to a number of previously unsolved problems.\nOn the other hand, for many problems, classic algorithms exist, which typically exceed the accuracy and stability of neural networks.\nTo combine these two concepts, we present a new kind of neural networks\u2014algorithmic neural networks (AlgoNets).\nThese networks integrate smooth versions of classic algorithms into the topology of neural networks.\nA forward AlgoNet includes algorithmic layers into existing architectures to enhance performance and explainability while a backward AlgoNet enables solving inverse problems without or with only weak supervision.\nIn addition, we present the algonet package, a PyTorch based library that includes, inter alia, a smoothly evaluated programming language, a smooth 3D mesh renderer, and smooth sorting algorithms.", "keywords": ["Algorithms", "Smoothness", "Differentiable", "Inverse Problems", "Adversarial Training", "Neural Networks", "Deep Learning", "Differentiable Renderer", "3D Mesh", "Turing-completeness", "Library"], "paperhash": "petersen|algonet_c^\\infty_smooth_algorithmic_neural_networks", "original_pdf": "/attachment/92775c162aad0300227b970954d7c1b3737fa668.pdf", "_bibtex": "@misc{\npetersen2020algonet,\ntitle={AlgoNet: {\\$}C^{\\textbackslash}infty{\\$} Smooth Algorithmic Neural Networks},\nauthor={Felix Petersen and Christian Borgelt and Oliver Deussen},\nyear={2020},\nurl={https://openreview.net/forum?id=HkghoaNYPB}\n}"}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "HkghoaNYPB", "replyto": "HkghoaNYPB", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper760/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper760/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1575836966882, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper760/Reviewers"], "noninvitees": [], "tcdate": 1570237747491, "tmdate": 1575836966896, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper760/-/Official_Review"}}}, {"id": "BylqVJ3pKr", "original": null, "number": 1, "cdate": 1571827505880, "ddate": null, "tcdate": 1571827505880, "tmdate": 1572972555679, "tddate": null, "forum": "HkghoaNYPB", "replyto": "HkghoaNYPB", "invitation": "ICLR.cc/2020/Conference/Paper760/-/Official_Review", "content": {"experience_assessment": "I have published one or two papers in this area.", "rating": "3: Weak Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #2", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "This paper presents a few different results surrounding smooth relaxations of classical algorithms. While the ideas (particularly the smooth rendering system) are interesting, the limited nature of the experiments and the lack of comparisons with baselines or prior work makes it difficult for me to support acceptance.\n\nSome feedback:\n\n- Re: \"the output of C\u221e smooth WHILE-programs differs from the discrete WHILE-programs by a small factor.\" Can you talk about the math here? Maybe mention bump functions (some of your relaxations have infinite support, and others have finite support, i.e. they use bump functions--this is likely to be an important distinction in practice).\n\n- I'd want to see examples of softsort in action; especially examples that help me understand that the gradients are meaningful.\n\n- The smooth renderer, and in particular the advantages it has over existing differentiable renderers, seem like the most important contributions of the paper (although they're relegated to the appendix). Can you expand on what you mean by \"fully\" vs \"locally\" differentiable? Can you provide empirical comparisons with other differentiable renderers?\n\n- Can you optimize a scene with an unknown or variable number of triangles?\n\n- I'm skeptical that all of the complexity of the RAN architecture and training setup is necessary. Is it possible to compare with other options, including baselines that leave out one or more of the components or training losses?"}, "signatures": ["ICLR.cc/2020/Conference/Paper760/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper760/AnonReviewer2"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["felix.petersen@uni.kn", "christian@borgelt.net", "oliver.deussen@uni.kn"], "title": "AlgoNet: $C^\\infty$ Smooth Algorithmic Neural Networks", "authors": ["Felix Petersen", "Christian Borgelt", "Oliver Deussen"], "pdf": "/pdf/92775c162aad0300227b970954d7c1b3737fa668.pdf", "TL;DR": "Integrating classical algorithms into neural networks.", "abstract": "Artificial neural networks have revolutionized many areas of computer science in recent years, providing solutions to a number of previously unsolved problems.\nOn the other hand, for many problems, classic algorithms exist, which typically exceed the accuracy and stability of neural networks.\nTo combine these two concepts, we present a new kind of neural networks\u2014algorithmic neural networks (AlgoNets).\nThese networks integrate smooth versions of classic algorithms into the topology of neural networks.\nA forward AlgoNet includes algorithmic layers into existing architectures to enhance performance and explainability while a backward AlgoNet enables solving inverse problems without or with only weak supervision.\nIn addition, we present the algonet package, a PyTorch based library that includes, inter alia, a smoothly evaluated programming language, a smooth 3D mesh renderer, and smooth sorting algorithms.", "keywords": ["Algorithms", "Smoothness", "Differentiable", "Inverse Problems", "Adversarial Training", "Neural Networks", "Deep Learning", "Differentiable Renderer", "3D Mesh", "Turing-completeness", "Library"], "paperhash": "petersen|algonet_c^\\infty_smooth_algorithmic_neural_networks", "original_pdf": "/attachment/92775c162aad0300227b970954d7c1b3737fa668.pdf", "_bibtex": "@misc{\npetersen2020algonet,\ntitle={AlgoNet: {\\$}C^{\\textbackslash}infty{\\$} Smooth Algorithmic Neural Networks},\nauthor={Felix Petersen and Christian Borgelt and Oliver Deussen},\nyear={2020},\nurl={https://openreview.net/forum?id=HkghoaNYPB}\n}"}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "HkghoaNYPB", "replyto": "HkghoaNYPB", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper760/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper760/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1575836966882, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper760/Reviewers"], "noninvitees": [], "tcdate": 1570237747491, "tmdate": 1575836966896, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper760/-/Official_Review"}}}, {"id": "rylxfnmRFB", "original": null, "number": 2, "cdate": 1571859464166, "ddate": null, "tcdate": 1571859464166, "tmdate": 1572972555636, "tddate": null, "forum": "HkghoaNYPB", "replyto": "HkghoaNYPB", "invitation": "ICLR.cc/2020/Conference/Paper760/-/Official_Review", "content": {"experience_assessment": "I have read many papers in this area.", "rating": "1: Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #3", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "The paper conceptualizes a neural network architecture that integrates smoothed versions of traditional algorithms into the network topology. The AlgoNet concept employs smoothed versions of algorithms implemented in the WHILE language, with options for different levels of differentiability. The paper outlines a forward version of AlgoNet based on traditional, skip, and residual connections, and a backward version for solving inverse problems in a reconstructive, autoencoder-like fashion. As smoothing introduces a form of domain shift, the paper the reconstructive adversarial network that that employs \"domain translators\" as well as a discriminator that are trained in an adversarial fashion. The paper concludes by describing versions of AlgoNet for various different algorithms.\n\nThe general idea of being able to better control the behavior of neural networks by better leveraging known structure (e.g., algorithms) is appealing. However, the paper does not go beyond conceptualizing how this might be done in a hand wavy manner. It is difficult to see what if anything can be learned from the paper, let alone what practical utility it has, which is important given that the paper claims to propose a new neural network architecture.\n\nThe paper would benefit from a discussion of empirical results in the main text, with baseline comparisons. With the exception of a single figure, the details are relegated to the appendices.\n\nThe related work discussion is surprisingly short, given the attention that has been paid to designing/optimizing different network topologies. The work that is discussed is very narrow in scope (see below).\n\nThe  paper devotes too much discussion to the challenges introduced by non-differentiable layers and the advantages of increasing degrees of differentiability (this is about half of the intro and most of the related work).\n\nDespite the lack of experimental demonstrations, the paper is one page over the suggested 8 page limit."}, "signatures": ["ICLR.cc/2020/Conference/Paper760/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper760/AnonReviewer3"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["felix.petersen@uni.kn", "christian@borgelt.net", "oliver.deussen@uni.kn"], "title": "AlgoNet: $C^\\infty$ Smooth Algorithmic Neural Networks", "authors": ["Felix Petersen", "Christian Borgelt", "Oliver Deussen"], "pdf": "/pdf/92775c162aad0300227b970954d7c1b3737fa668.pdf", "TL;DR": "Integrating classical algorithms into neural networks.", "abstract": "Artificial neural networks have revolutionized many areas of computer science in recent years, providing solutions to a number of previously unsolved problems.\nOn the other hand, for many problems, classic algorithms exist, which typically exceed the accuracy and stability of neural networks.\nTo combine these two concepts, we present a new kind of neural networks\u2014algorithmic neural networks (AlgoNets).\nThese networks integrate smooth versions of classic algorithms into the topology of neural networks.\nA forward AlgoNet includes algorithmic layers into existing architectures to enhance performance and explainability while a backward AlgoNet enables solving inverse problems without or with only weak supervision.\nIn addition, we present the algonet package, a PyTorch based library that includes, inter alia, a smoothly evaluated programming language, a smooth 3D mesh renderer, and smooth sorting algorithms.", "keywords": ["Algorithms", "Smoothness", "Differentiable", "Inverse Problems", "Adversarial Training", "Neural Networks", "Deep Learning", "Differentiable Renderer", "3D Mesh", "Turing-completeness", "Library"], "paperhash": "petersen|algonet_c^\\infty_smooth_algorithmic_neural_networks", "original_pdf": "/attachment/92775c162aad0300227b970954d7c1b3737fa668.pdf", "_bibtex": "@misc{\npetersen2020algonet,\ntitle={AlgoNet: {\\$}C^{\\textbackslash}infty{\\$} Smooth Algorithmic Neural Networks},\nauthor={Felix Petersen and Christian Borgelt and Oliver Deussen},\nyear={2020},\nurl={https://openreview.net/forum?id=HkghoaNYPB}\n}"}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "HkghoaNYPB", "replyto": "HkghoaNYPB", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper760/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper760/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1575836966882, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper760/Reviewers"], "noninvitees": [], "tcdate": 1570237747491, "tmdate": 1575836966896, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper760/-/Official_Review"}}}], "count": 5}