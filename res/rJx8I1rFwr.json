{"notes": [{"id": "rJx8I1rFwr", "original": "Hkg_p8a_DS", "number": 1729, "cdate": 1569439565644, "ddate": null, "tcdate": 1569439565644, "tmdate": 1577168223094, "tddate": null, "forum": "rJx8I1rFwr", "replyto": null, "invitation": "ICLR.cc/2020/Conference/-/Blind_Submission", "content": {"authorids": ["yuxiongw@cs.cmu.edu", "braverthan2@gmail.com", "hebert@ri.cmu.edu", "karteek.alahari@inria.fr"], "title": "Meta-Learning by Hallucinating Useful Examples", "authors": ["Yu-Xiong Wang", "Yuki Uchiyama", "Martial Hebert", "Karteek Alahari"], "pdf": "/pdf/c5c53a6e6cefd1a495a582b3f2c1f7723d513b8b.pdf", "abstract": "Learning to hallucinate additional examples has recently been shown as a promising direction to address few-shot learning tasks, which aim to learn novel concepts from very few examples. The hallucination process, however, is still far from generating effective samples for learning. In this work, we investigate two important requirements for the hallucinator --- (i) precision: the generated examples should lead to good classifier performance, and (ii) collaboration: both the hallucinator and the classification component need to be trained jointly. By integrating these requirements as novel loss functions into a general meta-learning with hallucination framework, our model-agnostic PrecisE Collaborative hAlluciNator (PECAN) facilitates data hallucination to improve the performance of new classification tasks. Extensive experiments demonstrate state-of-the-art performance on competitive miniImageNet and ImageNet based few-shot benchmarks in various scenarios.", "keywords": ["few-shot learning", "meta-learning"], "paperhash": "wang|metalearning_by_hallucinating_useful_examples", "original_pdf": "/attachment/130bfa4f475a784291c18a9613619b673622b313.pdf", "_bibtex": "@misc{\nwang2020metalearning,\ntitle={Meta-Learning by Hallucinating Useful Examples},\nauthor={Yu-Xiong Wang and Yuki Uchiyama and Martial Hebert and Karteek Alahari},\nyear={2020},\nurl={https://openreview.net/forum?id=rJx8I1rFwr}\n}"}, "signatures": ["ICLR.cc/2020/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference"], "details": {"replyCount": 10, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"reply": {"readers": {"values-regex": ".*"}, "writers": {"values": ["ICLR.cc/2020/Conference"]}, "signatures": {"values": ["ICLR.cc/2020/Conference"]}, "content": {"spotlight_video": {"value-regex": ".*"}, "full_presentation_video": {"value-regex": ".*"}, "original_pdf": {"required": false, "description": "Upload a PDF file that ends with .pdf", "value-regex": ".*"}, "appendix": {"value-regex": ".*"}, "authorids": {"values-regex": ".*"}, "poster": {"value-regex": ".*"}, "authors": {"values": ["Anonymous"]}, "slides": {"value-regex": ".*"}}}, "final": [], "signatures": ["ICLR.cc/2020/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference"], "noninvitees": [], "tcdate": 1569271260237, "tmdate": 1593459412141, "id": "ICLR.cc/2020/Conference/-/Blind_Submission"}}, "tauthor": "OpenReview.net"}, {"id": "hq08Bo79qc", "original": null, "number": 1, "cdate": 1576798730956, "ddate": null, "tcdate": 1576798730956, "tmdate": 1576800905520, "tddate": null, "forum": "rJx8I1rFwr", "replyto": "rJx8I1rFwr", "invitation": "ICLR.cc/2020/Conference/Paper1729/-/Decision", "content": {"decision": "Reject", "comment": "This paper describes a new approach to meta-learning with generating new useful examples.\n\nThe reviewers liked the paper but overall felt that the paper is not ready for publication as it stands.\n\nRejection is recommended. ", "title": "Paper Decision"}, "signatures": ["ICLR.cc/2020/Conference/Program_Chairs"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Program_Chairs"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["yuxiongw@cs.cmu.edu", "braverthan2@gmail.com", "hebert@ri.cmu.edu", "karteek.alahari@inria.fr"], "title": "Meta-Learning by Hallucinating Useful Examples", "authors": ["Yu-Xiong Wang", "Yuki Uchiyama", "Martial Hebert", "Karteek Alahari"], "pdf": "/pdf/c5c53a6e6cefd1a495a582b3f2c1f7723d513b8b.pdf", "abstract": "Learning to hallucinate additional examples has recently been shown as a promising direction to address few-shot learning tasks, which aim to learn novel concepts from very few examples. The hallucination process, however, is still far from generating effective samples for learning. In this work, we investigate two important requirements for the hallucinator --- (i) precision: the generated examples should lead to good classifier performance, and (ii) collaboration: both the hallucinator and the classification component need to be trained jointly. By integrating these requirements as novel loss functions into a general meta-learning with hallucination framework, our model-agnostic PrecisE Collaborative hAlluciNator (PECAN) facilitates data hallucination to improve the performance of new classification tasks. Extensive experiments demonstrate state-of-the-art performance on competitive miniImageNet and ImageNet based few-shot benchmarks in various scenarios.", "keywords": ["few-shot learning", "meta-learning"], "paperhash": "wang|metalearning_by_hallucinating_useful_examples", "original_pdf": "/attachment/130bfa4f475a784291c18a9613619b673622b313.pdf", "_bibtex": "@misc{\nwang2020metalearning,\ntitle={Meta-Learning by Hallucinating Useful Examples},\nauthor={Yu-Xiong Wang and Yuki Uchiyama and Martial Hebert and Karteek Alahari},\nyear={2020},\nurl={https://openreview.net/forum?id=rJx8I1rFwr}\n}"}, "tags": [], "invitation": {"reply": {"writers": {"description": "How your identity will be displayed.", "values-regex": ["ICLR.cc/2020/Conference/Program_Chairs"]}, "signatures": {"values": ["ICLR.cc/2020/Conference/Program_Chairs"], "description": "How your identity will be displayed."}, "content": {"decision": {"value-radio": ["Accept (Spotlight)", "Accept (Talk)", "Accept (Poster)", "Reject"], "description": "Decision", "required": true, "order": 2}, "title": {"value": "Paper Decision", "required": true, "order": 1}, "comment": {"value-regex": "[\\S\\s]{0,5000}", "description": "", "required": false, "order": 3}}, "forum": "rJx8I1rFwr", "replyto": "rJx8I1rFwr", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}}, "expdate": 1576854540000, "duedate": 1576853940000, "multiReply": false, "readers": ["everyone"], "invitees": ["ICLR.cc/2020/Conference/Program_Chairs"], "tcdate": 1576795703509, "tmdate": 1576800250896, "super": "ICLR.cc/2020/Conference/-/Decision", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper1729/-/Decision"}}}, {"id": "BylL9a5hsS", "original": null, "number": 6, "cdate": 1573854605845, "ddate": null, "tcdate": 1573854605845, "tmdate": 1573854605845, "tddate": null, "forum": "rJx8I1rFwr", "replyto": "Hklpg8yk9r", "invitation": "ICLR.cc/2020/Conference/Paper1729/-/Official_Comment", "content": {"title": "Thank you for the comments and interest in our approach.", "comment": "1. \u2026 imposing that Performance(Query | Augmented data) = Performance(Query | Support):\n\nWe are not imposing that Performance(Query | Augmented data) = Performance(Query | Support). Instead, we target Performance(Query | Augmented data) = Performance(Query | Larger set of real data). This is explained in the paragraph \u201cSoft precision-inducing hallucinator\u201d in Section 4, page 5. Specifically, given an initial large training set S^*_{train}, which contains n^\u2217 examples for each of the m classes, we randomly sample n (n << n^\u2217 ) examples per class, and obtain a subset S_{train}. From S_{train}, the hallucinator G generates n^\u2217 examples per class as S^G_{train}. This produces two training sets: S^*_{train} with real examples and S^G_{train} with hallucinated examples, where both contain the same number of examples. Importantly, note that S^G_{train} is hallucinated from the subset S_{train} instead of the initial large set S^*_{train}, and because n << n^\u2217 , we rule out the trivial hallucinator.\n\n2. Would you have some visualizations of the hallucinated images:\n\nOur hallucination is performed in the pre-trained feature space, and visualizing them directly is not intuitive. Instead, we provided a t-SNE plot of hallucinated samples in Figure 3. In the appendix A.8, we have included an additional visualization of hallucinated examples in the pixel space, using the nearest neighbor real image in the feature space, corresponding to each hallucinated feature sample."}, "signatures": ["ICLR.cc/2020/Conference/Paper1729/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1729/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["yuxiongw@cs.cmu.edu", "braverthan2@gmail.com", "hebert@ri.cmu.edu", "karteek.alahari@inria.fr"], "title": "Meta-Learning by Hallucinating Useful Examples", "authors": ["Yu-Xiong Wang", "Yuki Uchiyama", "Martial Hebert", "Karteek Alahari"], "pdf": "/pdf/c5c53a6e6cefd1a495a582b3f2c1f7723d513b8b.pdf", "abstract": "Learning to hallucinate additional examples has recently been shown as a promising direction to address few-shot learning tasks, which aim to learn novel concepts from very few examples. The hallucination process, however, is still far from generating effective samples for learning. In this work, we investigate two important requirements for the hallucinator --- (i) precision: the generated examples should lead to good classifier performance, and (ii) collaboration: both the hallucinator and the classification component need to be trained jointly. By integrating these requirements as novel loss functions into a general meta-learning with hallucination framework, our model-agnostic PrecisE Collaborative hAlluciNator (PECAN) facilitates data hallucination to improve the performance of new classification tasks. Extensive experiments demonstrate state-of-the-art performance on competitive miniImageNet and ImageNet based few-shot benchmarks in various scenarios.", "keywords": ["few-shot learning", "meta-learning"], "paperhash": "wang|metalearning_by_hallucinating_useful_examples", "original_pdf": "/attachment/130bfa4f475a784291c18a9613619b673622b313.pdf", "_bibtex": "@misc{\nwang2020metalearning,\ntitle={Meta-Learning by Hallucinating Useful Examples},\nauthor={Yu-Xiong Wang and Yuki Uchiyama and Martial Hebert and Karteek Alahari},\nyear={2020},\nurl={https://openreview.net/forum?id=rJx8I1rFwr}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "rJx8I1rFwr", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper1729/Authors", "ICLR.cc/2020/Conference/Paper1729/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper1729/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper1729/Reviewers", "ICLR.cc/2020/Conference/Paper1729/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper1729/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper1729/Authors|ICLR.cc/2020/Conference/Paper1729/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504151734, "tmdate": 1576860557967, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper1729/Authors", "ICLR.cc/2020/Conference/Paper1729/Reviewers", "ICLR.cc/2020/Conference/Paper1729/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper1729/-/Official_Comment"}}}, {"id": "Hklm7p93jS", "original": null, "number": 5, "cdate": 1573854491225, "ddate": null, "tcdate": 1573854491225, "tmdate": 1573854491225, "tddate": null, "forum": "rJx8I1rFwr", "replyto": "SJlzWIKX5r", "invitation": "ICLR.cc/2020/Conference/Paper1729/-/Official_Comment", "content": {"title": "Response to Review #1", "comment": "We thank the reviewer for the comments. The comments focus mostly on the generality of our approach and additional comparison. We address all these points as follows.\n\n1. \u2026 applying their proposed technique to meta-learning based techniques that do not involve learning a metric-embedding space and instead learn the learning procedure via nested optimization, e.g. MAML and its variant:\n\nIn principle, our meta-learning with hallucination framework requires that the learner (i.e., the classification model h) is differentiable with respect to the examples in the augmented training set, thus allowing us to back-propagate the final loss and update not just the parameters of the classification model, but also the parameters of the hallucinator. This is true for many meta-learning algorithms, including the optimization-based meta-learning approaches such as MAML.\n\nTo show the generality of our framework, we apply it to MAML. Implementation details of this integration are provided below. We have included the result of MAML, \u2018MAML w/ G' which corresponds to hallucination-based MAML (i.e., hallucination framework following Wang et al., 2018), and \u2018MAML w/ G + PECAN\u2019 (i.e., our proposed hallucination framework) in Table 4, and updated the submission accordingly. As shown in the summary below, our approach is generic and applies to MAML as well.\n\nMethod                                                               n=1                  n=5\nMAML (ResNet-10) (Finn et al., 2017)     54.69\u00b10.89     66.62\u00b10.83\nMAML w/ G (Wang et al., 2018)               56.37\u00b10.63     68.91\u00b10.57\nMAML w/ G + PECAN (Ours)                    58.39\u00b10.37     71.36\u00b10.44\n\nImplementation details: Following the procedure described in our submission, we use a ResNet-10 architecture as the feature extractor. We perform meta-learning over these pre-trained features. The embedding architecture of the MAML classification network h is composed of two-layer MLPs. The architecture of the generator G remains the same as in our submission.\n\nIn each meta-training episode, we sample a batch of few-shot classification tasks. For each of the tasks, following the process in Figure 2, we sample training sets S_train^\u2217 and S_train, sample a test test S_test, hallucinate S_train^G, and obtain an augmented training set S_train^aug. In the MAML inner loop, for each task, conditioning on its S_train^aug (S_train^G, or S_train^*), we adapt the parameters of h^cls (h^G, or h^real) using few gradient updates. For each task, the adapted h^cls (h^G, or h^real) is evaluated on the corresponding S_test. In the MAML outer loop, we average the classification objective on S_test across the batch of tasks. In a similar way, we compute the collaborative objective in the pre-trained feature space. The final loss is used to update the initial MAML model and the hallucinator.\n\n2. Table 4 \u2026 the results of PMN w/G:\n\nWe have included the result of PMN w/ G (Wang et al, 2018) in Table 4, and updated the submission accordingly. Our approach significantly outperforms Wang et al., 2018. Here, we summarize the comparison:\n\nMethod                                                  n=1                  n=5\nPMN w/ G (Wang et al, 2018)     62.28\u00b10.53     78.28\u00b10.62\nPMN w/ G + PECAN (Ours)         63.93\u00b10.40     80.58\u00b10.29\n\n3. \u2026 hallucinating examples for regression tasks:\n\nIn our paper, we mainly focus on few-shot classification tasks. However, our approach is general and applies to few-shot regression tasks as well. When extending our approach to address regression tasks, we need to slightly modify the design of the hallucinator G. Specifically, in classification tasks, the hallucinator G takes as input a seed example (x, y) and outputs a hallucinated example (x\u2019, y\u2019)=(G (x, z), y), where the class label y\u2019=y, indicating that the hallucinated example belongs to the same class as the seed example. In contrast, in regression tasks, y becomes a continuous quantity, thus we cannot enforce the constraint y\u2019=y. To address this issue, we modify the hallucinator G to directly generate the tuple (x\u2019, y\u2019) = G (x, y, z). This is achieved by the concatenation of x and y as input to G.\n\nWe incorporated our hallucinator with MAML and evaluate on the sinusoidal regression task proposed in (Finn et al., 2017). Our \u2018MAML w/ G + PECAN\u2019 outperforms MAML and \u2018MAML w/ G\u2019 for the regression task as well. Here we briefly summarize the mean squared error comparison:\n\nMethod                                               n=5\nMAML (Finn et al., 2017)                 0.84\nMAML w/ G (Wang et al, 2018)      0.67\nMAML w/ G + PECAN (Ours)          0.52\n\nWe have revised the submission accordingly to emphasize classification tasks, especially in the summary of contributions in Section 1, as well as showing our generality to regression tasks in the appendix A.7."}, "signatures": ["ICLR.cc/2020/Conference/Paper1729/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1729/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["yuxiongw@cs.cmu.edu", "braverthan2@gmail.com", "hebert@ri.cmu.edu", "karteek.alahari@inria.fr"], "title": "Meta-Learning by Hallucinating Useful Examples", "authors": ["Yu-Xiong Wang", "Yuki Uchiyama", "Martial Hebert", "Karteek Alahari"], "pdf": "/pdf/c5c53a6e6cefd1a495a582b3f2c1f7723d513b8b.pdf", "abstract": "Learning to hallucinate additional examples has recently been shown as a promising direction to address few-shot learning tasks, which aim to learn novel concepts from very few examples. The hallucination process, however, is still far from generating effective samples for learning. In this work, we investigate two important requirements for the hallucinator --- (i) precision: the generated examples should lead to good classifier performance, and (ii) collaboration: both the hallucinator and the classification component need to be trained jointly. By integrating these requirements as novel loss functions into a general meta-learning with hallucination framework, our model-agnostic PrecisE Collaborative hAlluciNator (PECAN) facilitates data hallucination to improve the performance of new classification tasks. Extensive experiments demonstrate state-of-the-art performance on competitive miniImageNet and ImageNet based few-shot benchmarks in various scenarios.", "keywords": ["few-shot learning", "meta-learning"], "paperhash": "wang|metalearning_by_hallucinating_useful_examples", "original_pdf": "/attachment/130bfa4f475a784291c18a9613619b673622b313.pdf", "_bibtex": "@misc{\nwang2020metalearning,\ntitle={Meta-Learning by Hallucinating Useful Examples},\nauthor={Yu-Xiong Wang and Yuki Uchiyama and Martial Hebert and Karteek Alahari},\nyear={2020},\nurl={https://openreview.net/forum?id=rJx8I1rFwr}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "rJx8I1rFwr", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper1729/Authors", "ICLR.cc/2020/Conference/Paper1729/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper1729/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper1729/Reviewers", "ICLR.cc/2020/Conference/Paper1729/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper1729/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper1729/Authors|ICLR.cc/2020/Conference/Paper1729/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504151734, "tmdate": 1576860557967, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper1729/Authors", "ICLR.cc/2020/Conference/Paper1729/Reviewers", "ICLR.cc/2020/Conference/Paper1729/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper1729/-/Official_Comment"}}}, {"id": "rJggDiqhoB", "original": null, "number": 4, "cdate": 1573854039847, "ddate": null, "tcdate": 1573854039847, "tmdate": 1573854039847, "tddate": null, "forum": "rJx8I1rFwr", "replyto": "rJx8I1rFwr", "invitation": "ICLR.cc/2020/Conference/Paper1729/-/Official_Comment", "content": {"title": "General Response", "comment": "We thank the reviewers for their positive comments --- our \u201cnovel and interesting idea\u201d (R3) to few-shot learning achieves \u201cconsistent improvement in performance versus various state-of-the-art meta-learning algorithms\u2019\u2019 (R1) with \u201cmany experiments\u201d (R1) and \u201cquite nice and thorough ablation studies\u201d (R1). We address all the comments below and have also updated the submission accordingly.\n\nIn the revised submission, we: (1) emphasized few-shot classification and included few-shot regression results in the appendix A.7, (2) included additional comparisons suggested by the reviewers, and (3) included visualization of the hallucinated examples suggested by the public comment in the appendix A.8."}, "signatures": ["ICLR.cc/2020/Conference/Paper1729/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1729/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["yuxiongw@cs.cmu.edu", "braverthan2@gmail.com", "hebert@ri.cmu.edu", "karteek.alahari@inria.fr"], "title": "Meta-Learning by Hallucinating Useful Examples", "authors": ["Yu-Xiong Wang", "Yuki Uchiyama", "Martial Hebert", "Karteek Alahari"], "pdf": "/pdf/c5c53a6e6cefd1a495a582b3f2c1f7723d513b8b.pdf", "abstract": "Learning to hallucinate additional examples has recently been shown as a promising direction to address few-shot learning tasks, which aim to learn novel concepts from very few examples. The hallucination process, however, is still far from generating effective samples for learning. In this work, we investigate two important requirements for the hallucinator --- (i) precision: the generated examples should lead to good classifier performance, and (ii) collaboration: both the hallucinator and the classification component need to be trained jointly. By integrating these requirements as novel loss functions into a general meta-learning with hallucination framework, our model-agnostic PrecisE Collaborative hAlluciNator (PECAN) facilitates data hallucination to improve the performance of new classification tasks. Extensive experiments demonstrate state-of-the-art performance on competitive miniImageNet and ImageNet based few-shot benchmarks in various scenarios.", "keywords": ["few-shot learning", "meta-learning"], "paperhash": "wang|metalearning_by_hallucinating_useful_examples", "original_pdf": "/attachment/130bfa4f475a784291c18a9613619b673622b313.pdf", "_bibtex": "@misc{\nwang2020metalearning,\ntitle={Meta-Learning by Hallucinating Useful Examples},\nauthor={Yu-Xiong Wang and Yuki Uchiyama and Martial Hebert and Karteek Alahari},\nyear={2020},\nurl={https://openreview.net/forum?id=rJx8I1rFwr}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "rJx8I1rFwr", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper1729/Authors", "ICLR.cc/2020/Conference/Paper1729/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper1729/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper1729/Reviewers", "ICLR.cc/2020/Conference/Paper1729/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper1729/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper1729/Authors|ICLR.cc/2020/Conference/Paper1729/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504151734, "tmdate": 1576860557967, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper1729/Authors", "ICLR.cc/2020/Conference/Paper1729/Reviewers", "ICLR.cc/2020/Conference/Paper1729/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper1729/-/Official_Comment"}}}, {"id": "HkeTeIBiiB", "original": null, "number": 3, "cdate": 1573766644961, "ddate": null, "tcdate": 1573766644961, "tmdate": 1573766644961, "tddate": null, "forum": "rJx8I1rFwr", "replyto": "rJl3L37nYB", "invitation": "ICLR.cc/2020/Conference/Paper1729/-/Official_Comment", "content": {"title": "Response to Review #3", "comment": "We thank the reviewer for the comments. The comments focus mostly on the clarity of some details and additional comparison. We address all these points as follows.\n\n(1) In Figure 2 \u2026 why not generate the S_{train} directly and then measure your precision-inducing loss over the real set S_{train} and S^G_{train}:\n\nThis is because S^G_{train} is hallucinated from S_{train}. If we measure the precision-inducing loss over S^G_{train} and S_{train}, we will then end up with a trivial hallucinator which only needs to memorize S_{train} and is not useful for improving classification performance. In contrast, in our approach, we measure the precision-inducing loss over S^G_{train} and a much larger real set S^*_{train}. By doing so, the hallucinator is forced to generate additional useful examples from the small training set S_{train}, so that the classifier trained on them matches the performance of a classifier trained on a larger set of real examples S^*_{train}. Please refer to Section 1, paragraph 4, page 2, and Section 4, paragraph \u201cSoft precision-inducing hallucinator\u201d, page 5, for more details.\n\nIn fact, introducing a large set of real examples S^*_{train} as learning guidance is one of our key contributions: we not only extract shared knowledge across a collection of few-shot learning tasks, but also leverage additional knowledge in large-sample models to guide hallucination and few-shot learning.\n\n(2) For Function 2 \u2026 could we compute the distance on the probability vectors that contains the logit for ground-truth label:\n\nOur final classification objective consists of the soft precision-inducing loss (i.e., Function 2), which is measured in the absence of ground-truth labels, and the hard precision loss, which is the standard cross-entropy classification loss measured with respect to ground-truth labels only (the last two sentences below Function 2, in the paragraph \u201cSoft precision-inducing hallucinator\u201d, Section 4, page 5).\n\nBy doing so, we: (i) separate the impacts of the predictions associated with ground-truth labels and other entries in prediction probability vectors, and (ii) ensure that the soft precision-inducing loss is not dominated by the predictions associated with ground-truth labels, given that they have already contributed to the hard precision loss.\n\nEmpirically, in the ablation study of \u201cChoice of similarity measure in soft precision-inducing loss\u201d and Table 3 (page 8), we showed that our loss function without ground-truth labels consistently and significantly outperformed the loss with ground-truth labels, for the cosine as well as other measures.\n\n(3) Some latest work \u2026 \u201cFew-shot Learning via Saliency-guided Hallucination of Samples\u201d (Ref1) and \u201cEdge-Labeling Graph Neural Network for Few-shot Learning\u201d (Ref2) \u2026 compare with these two methods:\n\nWe have included the comparison with these two methods on miniImageNet in Table 4, and updated the submission accordingly. Our approach significantly outperforms these methods. Here we summarize the results:\n\nMethod                                             n=1                 n=5\nSalNet (Ref1)                              57.45\u00b10.88     72.01\u00b10.67\nEGNN+Transduction (Ref2)             NA                 76.37\nOurs                                            63.93\u00b10.40     80.58\u00b10.29"}, "signatures": ["ICLR.cc/2020/Conference/Paper1729/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1729/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["yuxiongw@cs.cmu.edu", "braverthan2@gmail.com", "hebert@ri.cmu.edu", "karteek.alahari@inria.fr"], "title": "Meta-Learning by Hallucinating Useful Examples", "authors": ["Yu-Xiong Wang", "Yuki Uchiyama", "Martial Hebert", "Karteek Alahari"], "pdf": "/pdf/c5c53a6e6cefd1a495a582b3f2c1f7723d513b8b.pdf", "abstract": "Learning to hallucinate additional examples has recently been shown as a promising direction to address few-shot learning tasks, which aim to learn novel concepts from very few examples. The hallucination process, however, is still far from generating effective samples for learning. In this work, we investigate two important requirements for the hallucinator --- (i) precision: the generated examples should lead to good classifier performance, and (ii) collaboration: both the hallucinator and the classification component need to be trained jointly. By integrating these requirements as novel loss functions into a general meta-learning with hallucination framework, our model-agnostic PrecisE Collaborative hAlluciNator (PECAN) facilitates data hallucination to improve the performance of new classification tasks. Extensive experiments demonstrate state-of-the-art performance on competitive miniImageNet and ImageNet based few-shot benchmarks in various scenarios.", "keywords": ["few-shot learning", "meta-learning"], "paperhash": "wang|metalearning_by_hallucinating_useful_examples", "original_pdf": "/attachment/130bfa4f475a784291c18a9613619b673622b313.pdf", "_bibtex": "@misc{\nwang2020metalearning,\ntitle={Meta-Learning by Hallucinating Useful Examples},\nauthor={Yu-Xiong Wang and Yuki Uchiyama and Martial Hebert and Karteek Alahari},\nyear={2020},\nurl={https://openreview.net/forum?id=rJx8I1rFwr}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "rJx8I1rFwr", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper1729/Authors", "ICLR.cc/2020/Conference/Paper1729/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper1729/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper1729/Reviewers", "ICLR.cc/2020/Conference/Paper1729/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper1729/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper1729/Authors|ICLR.cc/2020/Conference/Paper1729/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504151734, "tmdate": 1576860557967, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper1729/Authors", "ICLR.cc/2020/Conference/Paper1729/Reviewers", "ICLR.cc/2020/Conference/Paper1729/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper1729/-/Official_Comment"}}}, {"id": "ByxBNMRKjr", "original": null, "number": 2, "cdate": 1573671468529, "ddate": null, "tcdate": 1573671468529, "tmdate": 1573671468529, "tddate": null, "forum": "rJx8I1rFwr", "replyto": "HkeCv6fj_B", "invitation": "ICLR.cc/2020/Conference/Paper1729/-/Official_Comment", "content": {"title": "Response to Review #2", "comment": "We thank the reviewer for the comments. The comments focus mostly on the novelty and the clarity of some details. We address all these points as follows.\n\n1. The novelty ... hallucinating in Wang et al., 2018 ... knowledge distillation (Hinton et al., 2015):\n\nWhile we agree with the reviewer that our approach falls into the category of meta-learning with data hallucination (Wang et al., 2018), it is not a trivial extension to any of the existing work. Different from Wang et al., 2018, which learns the data hallucinator solely through end-to-end training with the classifier and without any additional constraints, we investigated critical and unexplored properties (i.e., precision and collaboration) that the data hallucinator should satisfy. We instantiated these properties as novel loss functions to improve the precision of the hallucinated examples, and enhance the collaboration between the hallucinator and the classifier. In addition, from a broader perspective, our approach not only extracts shared knowledge across a collection of few-shot learning tasks as most of the existing meta-learning approaches normally do, but also leverages additional knowledge in large-sample models to guide hallucination and few-shot learning. As we have shown in the experiments, our approach consistently and significantly outperforms Wang et al., 2018 for different meta-learning approaches and across different datasets.\n\nWhile our soft precision-inducing loss is related to knowledge distillation (Hinton et al., 2015), as mentioned in Section 4, paragraph \u201cSoft precision-inducing hallucinator\u201d, page 5, it is different in three important ways. First, knowledge distillation typically focuses on model compression, which trains a shallow \u201cstudent\u201d neural network by mimicking the output of a deep \u201cteacher\u201d model. These two models are trained on the same data but are of different capacities. In contrast, our soft precision-inducing loss compares two models of the same capacity but trained on different types of data: a classifier trained on real data, and another trained on hallucinated examples. Second, our formulation measures the similarity of two probabilities in the absence of ground-truth labels, which is different from the formulation in Hinton et al., 2015. Third, in the ablation study of \u201cChoice of similarity measure in soft precision-inducing loss\u201d and Table 3 (page 8), we empirically showed that our loss function significantly outperformed the loss used in Hinton et al., 2015, as well as other similarity measures.\n\n2. how to use the collaborative objective on the hallucinator \u2026 the soft precision-inducing loss (l_hal^pre) for hallucinator:\n\nThe soft precision-inducing losses are computed in a similar way for l_hal^pre and l_learner^pre. The difference lies in that l_learner^pre is a loss in the classifier embedding space, while l_hal^pre is in the pre-trained feature space. This is also noted in Review #1: the collaborative objective applies \u201cdirect early supervision in the feature space in which the hallucination is conducted in addition to in the classifier embedding space.\u201d\n\nMore precisely, we first pre-train a deep convolutional network using a standard cross-entropy loss, and use it to extract image features. Meta-learning is then performed over these pre-trained features (the last paragraph in Section 3, page 4). Without loss of generality, we take prototypical networks (PN) as an example (the last paragraph in Section 4, page 6). PN learns a new embedding space \u03a6 on top of the pre-trained feature space X, and uses a non-parametric nearest centroid classifier to assign class probabilities for a test example based on its distances from class means in \u03a6. The embedding architecture of PN is composed of two-layer MLPs (implementation details in Section A.1).\n\nIn each meta-training episode, after sampling S_train^\u2217, S_train, and S_test and hallucinating S_train^G in the pre-trained feature space X, we perform nearest centroid classification, and produce the collaborative objective L_hal on S_test, including the soft precision-inducing loss l_hal^pre. We then feed the examples to the PN learner, obtain their embedded features in \u03a6, perform nearest centroid classification, and produce the classification objective L_learner on S_test, including the soft precision-inducing loss l_learner^pre (the last paragraph in Section 4, page 6)."}, "signatures": ["ICLR.cc/2020/Conference/Paper1729/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1729/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["yuxiongw@cs.cmu.edu", "braverthan2@gmail.com", "hebert@ri.cmu.edu", "karteek.alahari@inria.fr"], "title": "Meta-Learning by Hallucinating Useful Examples", "authors": ["Yu-Xiong Wang", "Yuki Uchiyama", "Martial Hebert", "Karteek Alahari"], "pdf": "/pdf/c5c53a6e6cefd1a495a582b3f2c1f7723d513b8b.pdf", "abstract": "Learning to hallucinate additional examples has recently been shown as a promising direction to address few-shot learning tasks, which aim to learn novel concepts from very few examples. The hallucination process, however, is still far from generating effective samples for learning. In this work, we investigate two important requirements for the hallucinator --- (i) precision: the generated examples should lead to good classifier performance, and (ii) collaboration: both the hallucinator and the classification component need to be trained jointly. By integrating these requirements as novel loss functions into a general meta-learning with hallucination framework, our model-agnostic PrecisE Collaborative hAlluciNator (PECAN) facilitates data hallucination to improve the performance of new classification tasks. Extensive experiments demonstrate state-of-the-art performance on competitive miniImageNet and ImageNet based few-shot benchmarks in various scenarios.", "keywords": ["few-shot learning", "meta-learning"], "paperhash": "wang|metalearning_by_hallucinating_useful_examples", "original_pdf": "/attachment/130bfa4f475a784291c18a9613619b673622b313.pdf", "_bibtex": "@misc{\nwang2020metalearning,\ntitle={Meta-Learning by Hallucinating Useful Examples},\nauthor={Yu-Xiong Wang and Yuki Uchiyama and Martial Hebert and Karteek Alahari},\nyear={2020},\nurl={https://openreview.net/forum?id=rJx8I1rFwr}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "rJx8I1rFwr", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper1729/Authors", "ICLR.cc/2020/Conference/Paper1729/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper1729/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper1729/Reviewers", "ICLR.cc/2020/Conference/Paper1729/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper1729/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper1729/Authors|ICLR.cc/2020/Conference/Paper1729/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504151734, "tmdate": 1576860557967, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper1729/Authors", "ICLR.cc/2020/Conference/Paper1729/Reviewers", "ICLR.cc/2020/Conference/Paper1729/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper1729/-/Official_Comment"}}}, {"id": "HkeCv6fj_B", "original": null, "number": 1, "cdate": 1570610533931, "ddate": null, "tcdate": 1570610533931, "tmdate": 1572972431041, "tddate": null, "forum": "rJx8I1rFwr", "replyto": "rJx8I1rFwr", "invitation": "ICLR.cc/2020/Conference/Paper1729/-/Official_Review", "content": {"rating": "3: Weak Reject", "experience_assessment": "I have published one or two papers in this area.", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #2", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review": "In this paper, the authors address few-shot learning via a precise collaborative hallucinator. In particular, they follow the framework of (Wang et al., 2018), and introduce two kinds of training regularization. The soft precision-inducing loss follows the spirit of adversarial learning, by using knowledge distillation. Additionally, a collaborative objective is introduced as middle supervision to enhance the learning capacity of hallucinator. \n\nHere are some comments:\n1. The novelty is relatively limited. The idea of hallucinating has been mainly introduced in (Wang et al., 2018). The soft precision-inducing loss is a straightforward extension of knowledge distillation (Hinton et al., 2015). \n\n2. It is not quite clear about how to use the collaborative objective on the hallucinator. Fig.2 and the text in ' Collaboration between hallucinator and learner ' (page 5) are not quite informative. Especially, how to perform the soft precision-inducing loss (l_hal^pre) for hallucinator?"}, "signatures": ["ICLR.cc/2020/Conference/Paper1729/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1729/AnonReviewer2"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["yuxiongw@cs.cmu.edu", "braverthan2@gmail.com", "hebert@ri.cmu.edu", "karteek.alahari@inria.fr"], "title": "Meta-Learning by Hallucinating Useful Examples", "authors": ["Yu-Xiong Wang", "Yuki Uchiyama", "Martial Hebert", "Karteek Alahari"], "pdf": "/pdf/c5c53a6e6cefd1a495a582b3f2c1f7723d513b8b.pdf", "abstract": "Learning to hallucinate additional examples has recently been shown as a promising direction to address few-shot learning tasks, which aim to learn novel concepts from very few examples. The hallucination process, however, is still far from generating effective samples for learning. In this work, we investigate two important requirements for the hallucinator --- (i) precision: the generated examples should lead to good classifier performance, and (ii) collaboration: both the hallucinator and the classification component need to be trained jointly. By integrating these requirements as novel loss functions into a general meta-learning with hallucination framework, our model-agnostic PrecisE Collaborative hAlluciNator (PECAN) facilitates data hallucination to improve the performance of new classification tasks. Extensive experiments demonstrate state-of-the-art performance on competitive miniImageNet and ImageNet based few-shot benchmarks in various scenarios.", "keywords": ["few-shot learning", "meta-learning"], "paperhash": "wang|metalearning_by_hallucinating_useful_examples", "original_pdf": "/attachment/130bfa4f475a784291c18a9613619b673622b313.pdf", "_bibtex": "@misc{\nwang2020metalearning,\ntitle={Meta-Learning by Hallucinating Useful Examples},\nauthor={Yu-Xiong Wang and Yuki Uchiyama and Martial Hebert and Karteek Alahari},\nyear={2020},\nurl={https://openreview.net/forum?id=rJx8I1rFwr}\n}"}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "rJx8I1rFwr", "replyto": "rJx8I1rFwr", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper1729/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper1729/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1574773550720, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper1729/Reviewers"], "noninvitees": [], "tcdate": 1570237733150, "tmdate": 1574773550732, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper1729/-/Official_Review"}}}, {"id": "rJl3L37nYB", "original": null, "number": 2, "cdate": 1571728468427, "ddate": null, "tcdate": 1571728468427, "tmdate": 1572972431006, "tddate": null, "forum": "rJx8I1rFwr", "replyto": "rJx8I1rFwr", "invitation": "ICLR.cc/2020/Conference/Paper1729/-/Official_Review", "content": {"rating": "6: Weak Accept", "experience_assessment": "I have published one or two papers in this area.", "review_assessment:_checking_correctness_of_derivations_and_theory": "I carefully checked the derivations and theory.", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #3", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review": "This paper proposes a general meta-learning with hallucination framework called PECAN. It is model-agnostic and can be combined with any meta-learning models to consistent boost their few-shot learning performance. \n\nThere are two key points for the proposed model. On the one hand, the authors introduce a novel precision-inducing loss which encourages the hallucinator to generate examples so that a classifier trained on them makes predictions similar to the one trained on a large amount of real examples. On the other hand, the authors introduce a collaborative objective for the hallucinator as early supervision, which directly facilitates the generation process and improves the cooperation between the hallucinator and the learner.\n\nOn the whole, the paper is well-written, and the proposed idea is novel and interesting.\n\nI have some following major concerns about the paper:\n(1) In Figure 2, the authors first sample the training set S^*_{train}, which contains n^* examples for each of the m classes, and then they randomly sample n examples per class, and obtain a subset S_{train}. Why not generate the S_{train} directly and then measure your precision-inducing loss over the real set S_{train} and S^G_{train}? I hope the authors explain it in their paper.\n(2) For Function 2 in the paper, why compute the cosine distance on the probability vectors that are obtained by removing the logit for ground-truth label in original probability distributions? Could we compute the distance on the probability vectors that contains the logit for ground-truth label? I hope the authors explain it in detail.\n(3) As far as I know, there are some latest work on few-shot learning in 2019, especially the work \u201cFew-shot Learning via Saliency-guided Hallucination of Samples\u201d and \u201cEdge-Labeling Graph Neural Network for Few-shot Learning\u201d. I hope the authors can compare with these two methods to further demonstrate the effectiveness of the proposed model."}, "signatures": ["ICLR.cc/2020/Conference/Paper1729/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1729/AnonReviewer3"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["yuxiongw@cs.cmu.edu", "braverthan2@gmail.com", "hebert@ri.cmu.edu", "karteek.alahari@inria.fr"], "title": "Meta-Learning by Hallucinating Useful Examples", "authors": ["Yu-Xiong Wang", "Yuki Uchiyama", "Martial Hebert", "Karteek Alahari"], "pdf": "/pdf/c5c53a6e6cefd1a495a582b3f2c1f7723d513b8b.pdf", "abstract": "Learning to hallucinate additional examples has recently been shown as a promising direction to address few-shot learning tasks, which aim to learn novel concepts from very few examples. The hallucination process, however, is still far from generating effective samples for learning. In this work, we investigate two important requirements for the hallucinator --- (i) precision: the generated examples should lead to good classifier performance, and (ii) collaboration: both the hallucinator and the classification component need to be trained jointly. By integrating these requirements as novel loss functions into a general meta-learning with hallucination framework, our model-agnostic PrecisE Collaborative hAlluciNator (PECAN) facilitates data hallucination to improve the performance of new classification tasks. Extensive experiments demonstrate state-of-the-art performance on competitive miniImageNet and ImageNet based few-shot benchmarks in various scenarios.", "keywords": ["few-shot learning", "meta-learning"], "paperhash": "wang|metalearning_by_hallucinating_useful_examples", "original_pdf": "/attachment/130bfa4f475a784291c18a9613619b673622b313.pdf", "_bibtex": "@misc{\nwang2020metalearning,\ntitle={Meta-Learning by Hallucinating Useful Examples},\nauthor={Yu-Xiong Wang and Yuki Uchiyama and Martial Hebert and Karteek Alahari},\nyear={2020},\nurl={https://openreview.net/forum?id=rJx8I1rFwr}\n}"}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "rJx8I1rFwr", "replyto": "rJx8I1rFwr", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper1729/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper1729/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1574773550720, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper1729/Reviewers"], "noninvitees": [], "tcdate": 1570237733150, "tmdate": 1574773550732, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper1729/-/Official_Review"}}}, {"id": "SJlzWIKX5r", "original": null, "number": 3, "cdate": 1572210170368, "ddate": null, "tcdate": 1572210170368, "tmdate": 1572972430972, "tddate": null, "forum": "rJx8I1rFwr", "replyto": "rJx8I1rFwr", "invitation": "ICLR.cc/2020/Conference/Paper1729/-/Official_Review", "content": {"experience_assessment": "I have published in this field for several years.", "rating": "6: Weak Accept", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #1", "review_assessment:_checking_correctness_of_derivations_and_theory": "N/A", "review": "This paper describes a method that builds upon the work of Wang et al. It meta-learns to hallucinate additional samples for few-shot learning for classification tasks. Their two main insights of this paper are to propose a soft-precision term which compares the classifiers' predictions for all classes other than the ground truth class for both a few-shot training set and the hallucinated set and b) to introduce the idea of applying direct early supervision in the feature space in which the hallucination is conducted in addition to in the classifier embedding space. This allows for stronger supervision and prevents the hallucinated samples from not being representative of the classes. The authors show small, but consistent improvement in performance on two benchmarks: ImageNet and miniImageNet with two different network architectures versus various state-of-the-art meta-learning algorithms with and without hallucination. The authors have adequately cited and reviewed the existing literature. They have also conducted many experiments (both in the main paper and in the supplementary material) to show the superior performance of their approach versus the existing ones. Furthermore their ablation studies both for the type of soft precision loss and for their various individual losses are quite nice and thorough. \n\nOverall the contribution of this paper is incremental over Wang et al and is mainly in the introduction of their new loss terms to regularize the hallucination process. This is clearly evident from Table 2 (comparing rows 1 and 3), where much of the performance gain is attained by including the l_learner^cls term versus the collaborative loss term (comparing row 1 and row 4).\n\nFurthermore, I would like the author to answer the following two questions:\n\n1. The authors claim that their method is general applicable to all meta-learning methods and can be combined with them. Yet, the meta learning methods that they apply it to: prototypical networks, prototypical matching networks and cosine classifiers are all metric-learning-based meta-learning techniques. I would like the authors to outline the procedure (and preferably also show experiments) for applying their proposed technique to meta-learning based techniques that do not involve learning a metric-embedding space and instead learn the learning procedure via nested optimization, e.g. MAML and its variants.\n\n2. In Table 4, I would like to see the results of PNM w/G or in other words the results of (Wang et al, 2018)'s method in comparison to the authors' proposed method.\n\n3. The authors make no attempt to solve the problem of hallucinating examples for regression tasks. This is fine as it is perhaps outside he scope of their current work. However, I would like the authors to fully qualify their claims everywhere in the paper and restrict the contribution of their work to classification tasks only.\n\n"}, "signatures": ["ICLR.cc/2020/Conference/Paper1729/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1729/AnonReviewer1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["yuxiongw@cs.cmu.edu", "braverthan2@gmail.com", "hebert@ri.cmu.edu", "karteek.alahari@inria.fr"], "title": "Meta-Learning by Hallucinating Useful Examples", "authors": ["Yu-Xiong Wang", "Yuki Uchiyama", "Martial Hebert", "Karteek Alahari"], "pdf": "/pdf/c5c53a6e6cefd1a495a582b3f2c1f7723d513b8b.pdf", "abstract": "Learning to hallucinate additional examples has recently been shown as a promising direction to address few-shot learning tasks, which aim to learn novel concepts from very few examples. The hallucination process, however, is still far from generating effective samples for learning. In this work, we investigate two important requirements for the hallucinator --- (i) precision: the generated examples should lead to good classifier performance, and (ii) collaboration: both the hallucinator and the classification component need to be trained jointly. By integrating these requirements as novel loss functions into a general meta-learning with hallucination framework, our model-agnostic PrecisE Collaborative hAlluciNator (PECAN) facilitates data hallucination to improve the performance of new classification tasks. Extensive experiments demonstrate state-of-the-art performance on competitive miniImageNet and ImageNet based few-shot benchmarks in various scenarios.", "keywords": ["few-shot learning", "meta-learning"], "paperhash": "wang|metalearning_by_hallucinating_useful_examples", "original_pdf": "/attachment/130bfa4f475a784291c18a9613619b673622b313.pdf", "_bibtex": "@misc{\nwang2020metalearning,\ntitle={Meta-Learning by Hallucinating Useful Examples},\nauthor={Yu-Xiong Wang and Yuki Uchiyama and Martial Hebert and Karteek Alahari},\nyear={2020},\nurl={https://openreview.net/forum?id=rJx8I1rFwr}\n}"}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "rJx8I1rFwr", "replyto": "rJx8I1rFwr", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper1729/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper1729/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1574773550720, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper1729/Reviewers"], "noninvitees": [], "tcdate": 1570237733150, "tmdate": 1574773550732, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper1729/-/Official_Review"}}}, {"id": "Hklpg8yk9r", "original": null, "number": 1, "cdate": 1571907061279, "ddate": null, "tcdate": 1571907061279, "tmdate": 1571907061279, "tddate": null, "forum": "rJx8I1rFwr", "replyto": "rJx8I1rFwr", "invitation": "ICLR.cc/2020/Conference/Paper1729/-/Public_Comment", "content": {"title": "Clarification on constraint", "comment": "Thanks for the work, and congratulations on achieving such good results!\n\nI have concerns regarding the objective function. \n\nAs far as I understand, you are imposing that Performance(Query | Augmented data) = Performance(Query | Support). If this is the case, then a trivial solution would be when the augmented data = support data (i.e. the hallucinator is essentially an autoencoder). \n\nAm I missing something? Would you have some visualisations of the hallucinated images?"}, "signatures": ["~Temporary_Temp1"], "readers": ["everyone"], "nonreaders": [], "writers": ["~Temporary_Temp1", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["yuxiongw@cs.cmu.edu", "braverthan2@gmail.com", "hebert@ri.cmu.edu", "karteek.alahari@inria.fr"], "title": "Meta-Learning by Hallucinating Useful Examples", "authors": ["Yu-Xiong Wang", "Yuki Uchiyama", "Martial Hebert", "Karteek Alahari"], "pdf": "/pdf/c5c53a6e6cefd1a495a582b3f2c1f7723d513b8b.pdf", "abstract": "Learning to hallucinate additional examples has recently been shown as a promising direction to address few-shot learning tasks, which aim to learn novel concepts from very few examples. The hallucination process, however, is still far from generating effective samples for learning. In this work, we investigate two important requirements for the hallucinator --- (i) precision: the generated examples should lead to good classifier performance, and (ii) collaboration: both the hallucinator and the classification component need to be trained jointly. By integrating these requirements as novel loss functions into a general meta-learning with hallucination framework, our model-agnostic PrecisE Collaborative hAlluciNator (PECAN) facilitates data hallucination to improve the performance of new classification tasks. Extensive experiments demonstrate state-of-the-art performance on competitive miniImageNet and ImageNet based few-shot benchmarks in various scenarios.", "keywords": ["few-shot learning", "meta-learning"], "paperhash": "wang|metalearning_by_hallucinating_useful_examples", "original_pdf": "/attachment/130bfa4f475a784291c18a9613619b673622b313.pdf", "_bibtex": "@misc{\nwang2020metalearning,\ntitle={Meta-Learning by Hallucinating Useful Examples},\nauthor={Yu-Xiong Wang and Yuki Uchiyama and Martial Hebert and Karteek Alahari},\nyear={2020},\nurl={https://openreview.net/forum?id=rJx8I1rFwr}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "rJx8I1rFwr", "readers": {"values": ["everyone"], "description": "User groups that will be able to read this comment."}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "~.*"}}, "readers": ["everyone"], "tcdate": 1569504190612, "tmdate": 1576860591078, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["everyone"], "noninvitees": ["ICLR.cc/2020/Conference/Paper1729/Authors", "ICLR.cc/2020/Conference/Paper1729/Reviewers", "ICLR.cc/2020/Conference/Paper1729/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper1729/-/Public_Comment"}}}], "count": 11}