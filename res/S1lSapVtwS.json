{"notes": [{"id": "S1lSapVtwS", "original": "rkgEknguDB", "number": 817, "cdate": 1569439165037, "ddate": null, "tcdate": 1569439165037, "tmdate": 1583912038191, "tddate": null, "forum": "S1lSapVtwS", "replyto": null, "invitation": "ICLR.cc/2020/Conference/-/Blind_Submission", "content": {"title": "Stochastic Conditional Generative Networks with Basis Decomposition", "authors": ["Ze Wang", "Xiuyuan Cheng", "Guillermo Sapiro", "Qiang Qiu"], "authorids": ["ze.w@duke.edu", "xiuyuan.cheng@duke.edu", "guillermo.sapiro@duke.edu", "qiang.qiu@duke.edu"], "keywords": [], "abstract": "While generative adversarial networks (GANs) have revolutionized machine learning, a number of open questions remain to fully understand them and exploit their power. One of these questions is how to efficiently achieve proper diversity and sampling of the multi-mode data space. To address this, we introduce BasisGAN, a stochastic conditional multi-mode image generator. By exploiting the observation that a convolutional filter can be well approximated as a linear combination of a small set of basis elements, we learn a plug-and-played basis generator to stochastically generate basis elements, with just a few hundred of parameters, to fully embed stochasticity into convolutional filters. By sampling basis elements instead of filters, we dramatically reduce the cost of modeling the parameter space with no sacrifice on either image diversity or fidelity. To illustrate this proposed plug-and-play framework, we construct variants of BasisGAN based on state-of-the-art conditional image generation networks, and train the networks by simply plugging in a basis generator, without additional auxiliary components, hyperparameters, or training objectives. The experimental success is complemented with theoretical results indicating how the perturbations introduced by the proposed sampling of basis elements can propagate to the appearance of generated images.", "pdf": "/pdf/8e4c7efd2555c085a449a3d1db3bff1bac0c4e59.pdf", "paperhash": "wang|stochastic_conditional_generative_networks_with_basis_decomposition", "_bibtex": "@inproceedings{\nWang2020Stochastic,\ntitle={Stochastic Conditional Generative Networks with Basis Decomposition},\nauthor={Ze Wang and Xiuyuan Cheng and Guillermo Sapiro and Qiang Qiu},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=S1lSapVtwS}\n}", "full_presentation_video": "", "original_pdf": "/attachment/a16c038c96333b552aff523b7115a3fb2e40724b.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "signatures": ["ICLR.cc/2020/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference"], "details": {"replyCount": 9, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"reply": {"readers": {"values-regex": ".*"}, "writers": {"values": ["ICLR.cc/2020/Conference"]}, "signatures": {"values": ["ICLR.cc/2020/Conference"]}, "content": {"spotlight_video": {"value-regex": ".*"}, "full_presentation_video": {"value-regex": ".*"}, "original_pdf": {"required": false, "description": "Upload a PDF file that ends with .pdf", "value-regex": ".*"}, "appendix": {"value-regex": ".*"}, "authorids": {"values-regex": ".*"}, "poster": {"value-regex": ".*"}, "authors": {"values": ["Anonymous"]}, "slides": {"value-regex": ".*"}}}, "final": [], "signatures": ["ICLR.cc/2020/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference"], "noninvitees": [], "tcdate": 1569271260237, "tmdate": 1593459412141, "id": "ICLR.cc/2020/Conference/-/Blind_Submission"}}, "tauthor": "ICLR.cc/2020/Conference"}, {"id": "9RpaSZI3D8", "original": null, "number": 1, "cdate": 1576798706955, "ddate": null, "tcdate": 1576798706955, "tmdate": 1576800929311, "tddate": null, "forum": "S1lSapVtwS", "replyto": "S1lSapVtwS", "invitation": "ICLR.cc/2020/Conference/Paper817/-/Decision", "content": {"decision": "Accept (Poster)", "comment": "Main content: BasiGAN, a novel method for  introducing stochasticity in conditional GANs\nSummary of discussion:\nreviewer1: interesting work and results on GANs. Reviewer had a question on pre-defned basis but i think it was answered by the authors. \nreviewer3: interesting and novel work on GANS, wel-written paper and improves on SOTA. The main uestion is around bases again like reviewer 1, but it seems the authors have addressed this.\nreviewer4: Novel interesting work. Main comments are around making Theorem 1 more theoretically correct, which it sounds like the authors addressed.\nRecommendation: Poster. Well written and novel paper and authors addressed a lot of concerns. ", "title": "Paper Decision"}, "signatures": ["ICLR.cc/2020/Conference/Program_Chairs"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Program_Chairs"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Stochastic Conditional Generative Networks with Basis Decomposition", "authors": ["Ze Wang", "Xiuyuan Cheng", "Guillermo Sapiro", "Qiang Qiu"], "authorids": ["ze.w@duke.edu", "xiuyuan.cheng@duke.edu", "guillermo.sapiro@duke.edu", "qiang.qiu@duke.edu"], "keywords": [], "abstract": "While generative adversarial networks (GANs) have revolutionized machine learning, a number of open questions remain to fully understand them and exploit their power. One of these questions is how to efficiently achieve proper diversity and sampling of the multi-mode data space. To address this, we introduce BasisGAN, a stochastic conditional multi-mode image generator. By exploiting the observation that a convolutional filter can be well approximated as a linear combination of a small set of basis elements, we learn a plug-and-played basis generator to stochastically generate basis elements, with just a few hundred of parameters, to fully embed stochasticity into convolutional filters. By sampling basis elements instead of filters, we dramatically reduce the cost of modeling the parameter space with no sacrifice on either image diversity or fidelity. To illustrate this proposed plug-and-play framework, we construct variants of BasisGAN based on state-of-the-art conditional image generation networks, and train the networks by simply plugging in a basis generator, without additional auxiliary components, hyperparameters, or training objectives. The experimental success is complemented with theoretical results indicating how the perturbations introduced by the proposed sampling of basis elements can propagate to the appearance of generated images.", "pdf": "/pdf/8e4c7efd2555c085a449a3d1db3bff1bac0c4e59.pdf", "paperhash": "wang|stochastic_conditional_generative_networks_with_basis_decomposition", "_bibtex": "@inproceedings{\nWang2020Stochastic,\ntitle={Stochastic Conditional Generative Networks with Basis Decomposition},\nauthor={Ze Wang and Xiuyuan Cheng and Guillermo Sapiro and Qiang Qiu},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=S1lSapVtwS}\n}", "full_presentation_video": "", "original_pdf": "/attachment/a16c038c96333b552aff523b7115a3fb2e40724b.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "tags": [], "invitation": {"reply": {"writers": {"description": "How your identity will be displayed.", "values-regex": ["ICLR.cc/2020/Conference/Program_Chairs"]}, "signatures": {"values": ["ICLR.cc/2020/Conference/Program_Chairs"], "description": "How your identity will be displayed."}, "content": {"decision": {"value-radio": ["Accept (Spotlight)", "Accept (Talk)", "Accept (Poster)", "Reject"], "description": "Decision", "required": true, "order": 2}, "title": {"value": "Paper Decision", "required": true, "order": 1}, "comment": {"value-regex": "[\\S\\s]{0,5000}", "description": "", "required": false, "order": 3}}, "forum": "S1lSapVtwS", "replyto": "S1lSapVtwS", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}}, "expdate": 1576854540000, "duedate": 1576853940000, "multiReply": false, "readers": ["everyone"], "invitees": ["ICLR.cc/2020/Conference/Program_Chairs"], "tcdate": 1576795704577, "tmdate": 1576800252182, "super": "ICLR.cc/2020/Conference/-/Decision", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper817/-/Decision"}}}, {"id": "BJlUubq2jS", "original": null, "number": 5, "cdate": 1573851502134, "ddate": null, "tcdate": 1573851502134, "tmdate": 1573851502134, "tddate": null, "forum": "S1lSapVtwS", "replyto": "BklLXs42iS", "invitation": "ICLR.cc/2020/Conference/Paper817/-/Official_Comment", "content": {"title": "Additional explanations", "comment": "\nThanks for the additional valuable comments. \n\n* Smaller K\n\nThe current experiment setting of K=7 was selected as performing the best after evaluating different K values starting from K=1 when preparing for the submission. \nTypically, when using K=5 or K=6, the performance drops slightly with good diversity but lower fidelity. When K drops to 4, the fidelity becomes much worse with obvious artifacts being observed in the generated images. And the network starts to have convergence problem in the adversarial training when K is small than 4.\n\n\n* Basis clarifications\n\nThanks for pointing this out. \nStrictly linear dependence is allowed within the K elements, and in Theorem 1 we do not use the term \u2018basis\u2019. We inherit the term \u2018basis\u2019 from DCFNet more to illustrate the intuition behind the proposed framework. We added a further clarification in Section 4 to prevent confusions. \n\n\n* Mode collapse\n\nThanks for the suggestions. The prevention of model collapse is actually not only reflected by the high diversity score, but also low FID score. As introduced in [1], FID is explicitly developed to compare the distance between the probability of observing real world data and the probability of generating model data. Low FID (especially for the map to satellite experiment) indicates the good coverage of generated samples to probability space of the target real-world data. Otherwise, if large areas of the probability space are missing, we cannot get such good scores on FID.\n\nWe develop BasisGAN specifically for conditional image generation, where the diversity of the sample mainly comes from the spatial appearance of images. The setting is different from toy example as in [2]. We will definitely keep investigating the problem of mode collapse as a direction of future efforts.\n\n\n[1] GANs Trained by a Two Time-scale Update Rule Converge to a Local Nash Equilibrium, NIPS 2017.\n[2] FFJORD: Free-Form Continuous Dynamics for Scalable Reversible Generative Models, ICLR 2019.\n"}, "signatures": ["ICLR.cc/2020/Conference/Paper817/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper817/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Stochastic Conditional Generative Networks with Basis Decomposition", "authors": ["Ze Wang", "Xiuyuan Cheng", "Guillermo Sapiro", "Qiang Qiu"], "authorids": ["ze.w@duke.edu", "xiuyuan.cheng@duke.edu", "guillermo.sapiro@duke.edu", "qiang.qiu@duke.edu"], "keywords": [], "abstract": "While generative adversarial networks (GANs) have revolutionized machine learning, a number of open questions remain to fully understand them and exploit their power. One of these questions is how to efficiently achieve proper diversity and sampling of the multi-mode data space. To address this, we introduce BasisGAN, a stochastic conditional multi-mode image generator. By exploiting the observation that a convolutional filter can be well approximated as a linear combination of a small set of basis elements, we learn a plug-and-played basis generator to stochastically generate basis elements, with just a few hundred of parameters, to fully embed stochasticity into convolutional filters. By sampling basis elements instead of filters, we dramatically reduce the cost of modeling the parameter space with no sacrifice on either image diversity or fidelity. To illustrate this proposed plug-and-play framework, we construct variants of BasisGAN based on state-of-the-art conditional image generation networks, and train the networks by simply plugging in a basis generator, without additional auxiliary components, hyperparameters, or training objectives. The experimental success is complemented with theoretical results indicating how the perturbations introduced by the proposed sampling of basis elements can propagate to the appearance of generated images.", "pdf": "/pdf/8e4c7efd2555c085a449a3d1db3bff1bac0c4e59.pdf", "paperhash": "wang|stochastic_conditional_generative_networks_with_basis_decomposition", "_bibtex": "@inproceedings{\nWang2020Stochastic,\ntitle={Stochastic Conditional Generative Networks with Basis Decomposition},\nauthor={Ze Wang and Xiuyuan Cheng and Guillermo Sapiro and Qiang Qiu},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=S1lSapVtwS}\n}", "full_presentation_video": "", "original_pdf": "/attachment/a16c038c96333b552aff523b7115a3fb2e40724b.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "S1lSapVtwS", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper817/Authors", "ICLR.cc/2020/Conference/Paper817/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper817/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper817/Reviewers", "ICLR.cc/2020/Conference/Paper817/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper817/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper817/Authors|ICLR.cc/2020/Conference/Paper817/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504165760, "tmdate": 1576860554621, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper817/Authors", "ICLR.cc/2020/Conference/Paper817/Reviewers", "ICLR.cc/2020/Conference/Paper817/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper817/-/Official_Comment"}}}, {"id": "BklLXs42iS", "original": null, "number": 4, "cdate": 1573829405991, "ddate": null, "tcdate": 1573829405991, "tmdate": 1573829405991, "tddate": null, "forum": "S1lSapVtwS", "replyto": "BklGOIsiiH", "invitation": "ICLR.cc/2020/Conference/Paper817/-/Official_Comment", "content": {"title": "Additional tests and explanations improve the paper", "comment": "Many thanks to the authors for making the changes into the paper.\n\n\" In the revised version, we additionally present an ablation study in supplemental material Section E and Table A.2 to show that increasing K, i.e. using more basis elements, does not provide any performance improvement.\"\nThe new ablation study improves the experimental assessment; however, as the best value is also the smallest, the question would appear why not to  decrease the basis size even further (would the performance still be the same or similar?)\n\n\"Theoretically, linear independence is not needed for Theorem 1 to hold.\"\nThe reviewer  can see the point that it is not needed for the theorem but the name might be conflicting with the commonly used linear algebra definition for the basis, e.g.:\n\"A basis for a vector space is a sequence of vectors that is linearly independent and that spans the space.\" Jim Hefferon, 2017 Linear Algebra (p. 114)\n\n\"In all experiments on real-world datasets, our model does not develop mode collapse as shown by the good diversity score.\"\nThe reviewer thinks that it might be hard to see it on real world datasets whether or not the model develops mode collapse; furthermore, how would it be possible to factor out capturing many diverse modes of the distribution which still do not cover many areas of the probability space? While the reviewer acknowledges that it might be impossible to do it for this revision due to the amount of time and work, it might be possible to demonstrate it by the experiments on the multimodal toy examples (8 gaussians, for example, as per  (Grathwohl et al (2019) / FFJORD)) for different values of K. "}, "signatures": ["ICLR.cc/2020/Conference/Paper817/AnonReviewer4"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper817/AnonReviewer4", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Stochastic Conditional Generative Networks with Basis Decomposition", "authors": ["Ze Wang", "Xiuyuan Cheng", "Guillermo Sapiro", "Qiang Qiu"], "authorids": ["ze.w@duke.edu", "xiuyuan.cheng@duke.edu", "guillermo.sapiro@duke.edu", "qiang.qiu@duke.edu"], "keywords": [], "abstract": "While generative adversarial networks (GANs) have revolutionized machine learning, a number of open questions remain to fully understand them and exploit their power. One of these questions is how to efficiently achieve proper diversity and sampling of the multi-mode data space. To address this, we introduce BasisGAN, a stochastic conditional multi-mode image generator. By exploiting the observation that a convolutional filter can be well approximated as a linear combination of a small set of basis elements, we learn a plug-and-played basis generator to stochastically generate basis elements, with just a few hundred of parameters, to fully embed stochasticity into convolutional filters. By sampling basis elements instead of filters, we dramatically reduce the cost of modeling the parameter space with no sacrifice on either image diversity or fidelity. To illustrate this proposed plug-and-play framework, we construct variants of BasisGAN based on state-of-the-art conditional image generation networks, and train the networks by simply plugging in a basis generator, without additional auxiliary components, hyperparameters, or training objectives. The experimental success is complemented with theoretical results indicating how the perturbations introduced by the proposed sampling of basis elements can propagate to the appearance of generated images.", "pdf": "/pdf/8e4c7efd2555c085a449a3d1db3bff1bac0c4e59.pdf", "paperhash": "wang|stochastic_conditional_generative_networks_with_basis_decomposition", "_bibtex": "@inproceedings{\nWang2020Stochastic,\ntitle={Stochastic Conditional Generative Networks with Basis Decomposition},\nauthor={Ze Wang and Xiuyuan Cheng and Guillermo Sapiro and Qiang Qiu},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=S1lSapVtwS}\n}", "full_presentation_video": "", "original_pdf": "/attachment/a16c038c96333b552aff523b7115a3fb2e40724b.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "S1lSapVtwS", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper817/Authors", "ICLR.cc/2020/Conference/Paper817/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper817/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper817/Reviewers", "ICLR.cc/2020/Conference/Paper817/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper817/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper817/Authors|ICLR.cc/2020/Conference/Paper817/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504165760, "tmdate": 1576860554621, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper817/Authors", "ICLR.cc/2020/Conference/Paper817/Reviewers", "ICLR.cc/2020/Conference/Paper817/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper817/-/Official_Comment"}}}, {"id": "BklGOIsiiH", "original": null, "number": 3, "cdate": 1573791337869, "ddate": null, "tcdate": 1573791337869, "tmdate": 1573796548560, "tddate": null, "forum": "S1lSapVtwS", "replyto": "BkgrY8ih9S", "invitation": "ICLR.cc/2020/Conference/Paper817/-/Official_Comment", "content": {"title": "Thanks and response to Reviewer #4", "comment": "\nThanks for your support and all the insightful suggestions.\n\n*Construction procedure for the basis\n\nThe network construction procedure meets the condition of Theorem 1, that is, we constrain the number of basis to a small number of K (e.g. K=7), which imposes low-rankness of the generated filters as stated in Theorem 1.\nAs discussed in Section 4, when we directly generate random convolution filters, we consistently observe that the obtained filters are always of low effective rank. This observation of low-rankness motivates our construction of non-random (trainable) 1x1 convolutional layers ($a_k$'s) and randomly generated basis layers. In the revised version, we additionally present an ablation study in supplemental material Section E and Table A.2 to show that increasing K, i.e. using more basis elements, does not provide any performance improvement. We thus think K may serve as a parameter to regularize the model, also see below in \"Model collapse\".\n\n\n*Linear Independence\n\nTheoretically, linear independence is not needed for Theorem 1 to hold. In case that $a_k$'s are linearly dependent, it does not affect the existence result of the theorem, and the dimensionality of the subspace (the true rank) will be K' < K. We have revised the proof in supplemental material Section B to clarify this point. In practice, the trained $a_k$'s are of rank-K, due to that the choice of relatively small K is a tight restriction of the model. \n\n\n*Mode collapse\n\nIn all experiments on real-world datasets, our model does not develop mode collapse as shown by the good diversity score. We are working to understand the precise relation between the fidelity-diversity trade-off. Based on the experiments (see supplemental material Table A.2) so far, we think the constraint rank K serves as a parameter to regularize the generative model. We will keep this as a direction of future efforts.\n\n\nThe content of Section 4 is organized as following: we start with filter generation, which introduces stochasticity with considerable cost. \nBased on the low rank observation of generated filters, we further propose to decompose filters into bases with stochasticity and deterministic coefficients. And the decomposition is further supported by Theorem 1, which shows that it suffices to generate bases in order to generate the desired distribution of filters. \nWe then provide detail on the process of basis generation, and how we construct the proposed BasisGAN with basis generators.\n"}, "signatures": ["ICLR.cc/2020/Conference/Paper817/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper817/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Stochastic Conditional Generative Networks with Basis Decomposition", "authors": ["Ze Wang", "Xiuyuan Cheng", "Guillermo Sapiro", "Qiang Qiu"], "authorids": ["ze.w@duke.edu", "xiuyuan.cheng@duke.edu", "guillermo.sapiro@duke.edu", "qiang.qiu@duke.edu"], "keywords": [], "abstract": "While generative adversarial networks (GANs) have revolutionized machine learning, a number of open questions remain to fully understand them and exploit their power. One of these questions is how to efficiently achieve proper diversity and sampling of the multi-mode data space. To address this, we introduce BasisGAN, a stochastic conditional multi-mode image generator. By exploiting the observation that a convolutional filter can be well approximated as a linear combination of a small set of basis elements, we learn a plug-and-played basis generator to stochastically generate basis elements, with just a few hundred of parameters, to fully embed stochasticity into convolutional filters. By sampling basis elements instead of filters, we dramatically reduce the cost of modeling the parameter space with no sacrifice on either image diversity or fidelity. To illustrate this proposed plug-and-play framework, we construct variants of BasisGAN based on state-of-the-art conditional image generation networks, and train the networks by simply plugging in a basis generator, without additional auxiliary components, hyperparameters, or training objectives. The experimental success is complemented with theoretical results indicating how the perturbations introduced by the proposed sampling of basis elements can propagate to the appearance of generated images.", "pdf": "/pdf/8e4c7efd2555c085a449a3d1db3bff1bac0c4e59.pdf", "paperhash": "wang|stochastic_conditional_generative_networks_with_basis_decomposition", "_bibtex": "@inproceedings{\nWang2020Stochastic,\ntitle={Stochastic Conditional Generative Networks with Basis Decomposition},\nauthor={Ze Wang and Xiuyuan Cheng and Guillermo Sapiro and Qiang Qiu},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=S1lSapVtwS}\n}", "full_presentation_video": "", "original_pdf": "/attachment/a16c038c96333b552aff523b7115a3fb2e40724b.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "S1lSapVtwS", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper817/Authors", "ICLR.cc/2020/Conference/Paper817/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper817/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper817/Reviewers", "ICLR.cc/2020/Conference/Paper817/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper817/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper817/Authors|ICLR.cc/2020/Conference/Paper817/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504165760, "tmdate": 1576860554621, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper817/Authors", "ICLR.cc/2020/Conference/Paper817/Reviewers", "ICLR.cc/2020/Conference/Paper817/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper817/-/Official_Comment"}}}, {"id": "SyljhBiosr", "original": null, "number": 1, "cdate": 1573791154581, "ddate": null, "tcdate": 1573791154581, "tmdate": 1573796518263, "tddate": null, "forum": "S1lSapVtwS", "replyto": "rJed5l9tqH", "invitation": "ICLR.cc/2020/Conference/Paper817/-/Official_Comment", "content": {"title": "Thanks and response to Reviewer #1", "comment": "Thanks for the support.\n\nInstead of sampling predefined random basis, we learn in our network basis generators, in the form of tiny neural networks, that generate stochastic basis elements from random latent codes (details in Figure 1), which thus introduces great variability to the features and the output images without increasing dimensions to an unmanageable level. \n\nWe have revised the last paragraph of Section 4 to further clarify this. "}, "signatures": ["ICLR.cc/2020/Conference/Paper817/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper817/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Stochastic Conditional Generative Networks with Basis Decomposition", "authors": ["Ze Wang", "Xiuyuan Cheng", "Guillermo Sapiro", "Qiang Qiu"], "authorids": ["ze.w@duke.edu", "xiuyuan.cheng@duke.edu", "guillermo.sapiro@duke.edu", "qiang.qiu@duke.edu"], "keywords": [], "abstract": "While generative adversarial networks (GANs) have revolutionized machine learning, a number of open questions remain to fully understand them and exploit their power. One of these questions is how to efficiently achieve proper diversity and sampling of the multi-mode data space. To address this, we introduce BasisGAN, a stochastic conditional multi-mode image generator. By exploiting the observation that a convolutional filter can be well approximated as a linear combination of a small set of basis elements, we learn a plug-and-played basis generator to stochastically generate basis elements, with just a few hundred of parameters, to fully embed stochasticity into convolutional filters. By sampling basis elements instead of filters, we dramatically reduce the cost of modeling the parameter space with no sacrifice on either image diversity or fidelity. To illustrate this proposed plug-and-play framework, we construct variants of BasisGAN based on state-of-the-art conditional image generation networks, and train the networks by simply plugging in a basis generator, without additional auxiliary components, hyperparameters, or training objectives. The experimental success is complemented with theoretical results indicating how the perturbations introduced by the proposed sampling of basis elements can propagate to the appearance of generated images.", "pdf": "/pdf/8e4c7efd2555c085a449a3d1db3bff1bac0c4e59.pdf", "paperhash": "wang|stochastic_conditional_generative_networks_with_basis_decomposition", "_bibtex": "@inproceedings{\nWang2020Stochastic,\ntitle={Stochastic Conditional Generative Networks with Basis Decomposition},\nauthor={Ze Wang and Xiuyuan Cheng and Guillermo Sapiro and Qiang Qiu},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=S1lSapVtwS}\n}", "full_presentation_video": "", "original_pdf": "/attachment/a16c038c96333b552aff523b7115a3fb2e40724b.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "S1lSapVtwS", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper817/Authors", "ICLR.cc/2020/Conference/Paper817/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper817/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper817/Reviewers", "ICLR.cc/2020/Conference/Paper817/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper817/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper817/Authors|ICLR.cc/2020/Conference/Paper817/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504165760, "tmdate": 1576860554621, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper817/Authors", "ICLR.cc/2020/Conference/Paper817/Reviewers", "ICLR.cc/2020/Conference/Paper817/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper817/-/Official_Comment"}}}, {"id": "Bkguf8jsjS", "original": null, "number": 2, "cdate": 1573791248032, "ddate": null, "tcdate": 1573791248032, "tmdate": 1573791915293, "tddate": null, "forum": "S1lSapVtwS", "replyto": "SkxALfA6YS", "invitation": "ICLR.cc/2020/Conference/Paper817/-/Official_Comment", "content": {"title": "Thanks and response to Reviewer #3", "comment": "\nThanks for the support and the valuable suggestions.\n\n*Basis generation\n\nIn our training, we do not explicitly regularize the orthogonality of the generated basis elements. We provide additional discussion on linear independence in the response to R4, and have incorporated such additional details in Section 4 and Theorem 1.\n\n\n*Number of parameters\n\nThe number of trainable parameters is updated in supplemental material Table A.3.  Adopting basis generator achieves fewer trainable parameters, thanks to the small number of basis elements and tiny structure of basis generators. This is critical to make the proposed framework and system trainable and manageable. Regularization based method like MSGAN and DSGAN do not reduce parameter numbers of the underlying network models. We have further discussed this in Section 5.2.\n\n\n*Qualitative results\n\nThanks for your valuable suggestions and we have included qualitative comparisons in supplemental material Figure A.3.\n"}, "signatures": ["ICLR.cc/2020/Conference/Paper817/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper817/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Stochastic Conditional Generative Networks with Basis Decomposition", "authors": ["Ze Wang", "Xiuyuan Cheng", "Guillermo Sapiro", "Qiang Qiu"], "authorids": ["ze.w@duke.edu", "xiuyuan.cheng@duke.edu", "guillermo.sapiro@duke.edu", "qiang.qiu@duke.edu"], "keywords": [], "abstract": "While generative adversarial networks (GANs) have revolutionized machine learning, a number of open questions remain to fully understand them and exploit their power. One of these questions is how to efficiently achieve proper diversity and sampling of the multi-mode data space. To address this, we introduce BasisGAN, a stochastic conditional multi-mode image generator. By exploiting the observation that a convolutional filter can be well approximated as a linear combination of a small set of basis elements, we learn a plug-and-played basis generator to stochastically generate basis elements, with just a few hundred of parameters, to fully embed stochasticity into convolutional filters. By sampling basis elements instead of filters, we dramatically reduce the cost of modeling the parameter space with no sacrifice on either image diversity or fidelity. To illustrate this proposed plug-and-play framework, we construct variants of BasisGAN based on state-of-the-art conditional image generation networks, and train the networks by simply plugging in a basis generator, without additional auxiliary components, hyperparameters, or training objectives. The experimental success is complemented with theoretical results indicating how the perturbations introduced by the proposed sampling of basis elements can propagate to the appearance of generated images.", "pdf": "/pdf/8e4c7efd2555c085a449a3d1db3bff1bac0c4e59.pdf", "paperhash": "wang|stochastic_conditional_generative_networks_with_basis_decomposition", "_bibtex": "@inproceedings{\nWang2020Stochastic,\ntitle={Stochastic Conditional Generative Networks with Basis Decomposition},\nauthor={Ze Wang and Xiuyuan Cheng and Guillermo Sapiro and Qiang Qiu},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=S1lSapVtwS}\n}", "full_presentation_video": "", "original_pdf": "/attachment/a16c038c96333b552aff523b7115a3fb2e40724b.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "S1lSapVtwS", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper817/Authors", "ICLR.cc/2020/Conference/Paper817/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper817/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper817/Reviewers", "ICLR.cc/2020/Conference/Paper817/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper817/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper817/Authors|ICLR.cc/2020/Conference/Paper817/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504165760, "tmdate": 1576860554621, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper817/Authors", "ICLR.cc/2020/Conference/Paper817/Reviewers", "ICLR.cc/2020/Conference/Paper817/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper817/-/Official_Comment"}}}, {"id": "SkxALfA6YS", "original": null, "number": 1, "cdate": 1571836501899, "ddate": null, "tcdate": 1571836501899, "tmdate": 1572972548697, "tddate": null, "forum": "S1lSapVtwS", "replyto": "S1lSapVtwS", "invitation": "ICLR.cc/2020/Conference/Paper817/-/Official_Review", "content": {"experience_assessment": "I have read many papers in this area.", "rating": "6: Weak Accept", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #3", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "In this paper, the authors introduce BasisGAN, a novel method for introducing stochasticity in conditional GANs, i.e., a way of conducting one-to-many mappings. This is a good addition in the literature as: (a) most of the widely-used conditional GANs such as pix2pix (Isola et al., 2016) or pix2pixHD (Wang et al., 2018) are deterministic (i.e., for a specific input a single output is always generated), (b) it improves upon the current SOTA in one-to-many mappings, (c) it is very useful application-wise. As also stated in the paper, there is a number of applications where this method is handy (e.g., converting a sketch to images varying in colors, etc.).\n\nI am leaning towards accepting this paper as this work is well-motivated and found the idea of using the basis generator to learn the bases for the generation of the parameters quite interesting. This is the main contribution and difference of this paper in comparison to DCFNet (Qiu et al., ICML 2018), where the bases are not learned. \n\nNevertheless, I have the following questions/requests:\n\n- How can we tell that the generated bases are indeed bases (e.g., are they orthogonal?)\n- Please report the number of parameters used in your implementation in comparison to the rest of the methods. \n- Please provide qualitative results against the compared methods and especially against DSGAN (Qin et al., 2018)."}, "signatures": ["ICLR.cc/2020/Conference/Paper817/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper817/AnonReviewer3"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Stochastic Conditional Generative Networks with Basis Decomposition", "authors": ["Ze Wang", "Xiuyuan Cheng", "Guillermo Sapiro", "Qiang Qiu"], "authorids": ["ze.w@duke.edu", "xiuyuan.cheng@duke.edu", "guillermo.sapiro@duke.edu", "qiang.qiu@duke.edu"], "keywords": [], "abstract": "While generative adversarial networks (GANs) have revolutionized machine learning, a number of open questions remain to fully understand them and exploit their power. One of these questions is how to efficiently achieve proper diversity and sampling of the multi-mode data space. To address this, we introduce BasisGAN, a stochastic conditional multi-mode image generator. By exploiting the observation that a convolutional filter can be well approximated as a linear combination of a small set of basis elements, we learn a plug-and-played basis generator to stochastically generate basis elements, with just a few hundred of parameters, to fully embed stochasticity into convolutional filters. By sampling basis elements instead of filters, we dramatically reduce the cost of modeling the parameter space with no sacrifice on either image diversity or fidelity. To illustrate this proposed plug-and-play framework, we construct variants of BasisGAN based on state-of-the-art conditional image generation networks, and train the networks by simply plugging in a basis generator, without additional auxiliary components, hyperparameters, or training objectives. The experimental success is complemented with theoretical results indicating how the perturbations introduced by the proposed sampling of basis elements can propagate to the appearance of generated images.", "pdf": "/pdf/8e4c7efd2555c085a449a3d1db3bff1bac0c4e59.pdf", "paperhash": "wang|stochastic_conditional_generative_networks_with_basis_decomposition", "_bibtex": "@inproceedings{\nWang2020Stochastic,\ntitle={Stochastic Conditional Generative Networks with Basis Decomposition},\nauthor={Ze Wang and Xiuyuan Cheng and Guillermo Sapiro and Qiang Qiu},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=S1lSapVtwS}\n}", "full_presentation_video": "", "original_pdf": "/attachment/a16c038c96333b552aff523b7115a3fb2e40724b.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "S1lSapVtwS", "replyto": "S1lSapVtwS", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper817/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper817/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1575770036781, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper817/Reviewers"], "noninvitees": [], "tcdate": 1570237746575, "tmdate": 1575770036794, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper817/-/Official_Review"}}}, {"id": "rJed5l9tqH", "original": null, "number": 2, "cdate": 1572606096051, "ddate": null, "tcdate": 1572606096051, "tmdate": 1572972548651, "tddate": null, "forum": "S1lSapVtwS", "replyto": "S1lSapVtwS", "invitation": "ICLR.cc/2020/Conference/Paper817/-/Official_Review", "content": {"rating": "6: Weak Accept", "experience_assessment": "I have published in this field for several years.", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #1", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review": "The paper proposes a new conditional GAN architecture. In particular, in order to allow for further diversity in conditional signal generation, the BasiGAN proposes to model the convolutional layers as a combination of basis which is stochastically sampled. The idea of the paper is interesting and some interesting experiments are presented. Nevertheless, I do not quite get why a set of predefined random basis would enforce more variability than the non-parametric way of training which is currently applied for conditional-GANs. If I get a convincing answer from the authors, I would definitely accept the paper (which otherwise is well-written and quite interesting to read). "}, "signatures": ["ICLR.cc/2020/Conference/Paper817/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper817/AnonReviewer1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Stochastic Conditional Generative Networks with Basis Decomposition", "authors": ["Ze Wang", "Xiuyuan Cheng", "Guillermo Sapiro", "Qiang Qiu"], "authorids": ["ze.w@duke.edu", "xiuyuan.cheng@duke.edu", "guillermo.sapiro@duke.edu", "qiang.qiu@duke.edu"], "keywords": [], "abstract": "While generative adversarial networks (GANs) have revolutionized machine learning, a number of open questions remain to fully understand them and exploit their power. One of these questions is how to efficiently achieve proper diversity and sampling of the multi-mode data space. To address this, we introduce BasisGAN, a stochastic conditional multi-mode image generator. By exploiting the observation that a convolutional filter can be well approximated as a linear combination of a small set of basis elements, we learn a plug-and-played basis generator to stochastically generate basis elements, with just a few hundred of parameters, to fully embed stochasticity into convolutional filters. By sampling basis elements instead of filters, we dramatically reduce the cost of modeling the parameter space with no sacrifice on either image diversity or fidelity. To illustrate this proposed plug-and-play framework, we construct variants of BasisGAN based on state-of-the-art conditional image generation networks, and train the networks by simply plugging in a basis generator, without additional auxiliary components, hyperparameters, or training objectives. The experimental success is complemented with theoretical results indicating how the perturbations introduced by the proposed sampling of basis elements can propagate to the appearance of generated images.", "pdf": "/pdf/8e4c7efd2555c085a449a3d1db3bff1bac0c4e59.pdf", "paperhash": "wang|stochastic_conditional_generative_networks_with_basis_decomposition", "_bibtex": "@inproceedings{\nWang2020Stochastic,\ntitle={Stochastic Conditional Generative Networks with Basis Decomposition},\nauthor={Ze Wang and Xiuyuan Cheng and Guillermo Sapiro and Qiang Qiu},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=S1lSapVtwS}\n}", "full_presentation_video": "", "original_pdf": "/attachment/a16c038c96333b552aff523b7115a3fb2e40724b.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "S1lSapVtwS", "replyto": "S1lSapVtwS", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper817/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper817/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1575770036781, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper817/Reviewers"], "noninvitees": [], "tcdate": 1570237746575, "tmdate": 1575770036794, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper817/-/Official_Review"}}}, {"id": "BkgrY8ih9S", "original": null, "number": 3, "cdate": 1572808317324, "ddate": null, "tcdate": 1572808317324, "tmdate": 1572972548604, "tddate": null, "forum": "S1lSapVtwS", "replyto": "S1lSapVtwS", "invitation": "ICLR.cc/2020/Conference/Paper817/-/Official_Review", "content": {"rating": "6: Weak Accept", "experience_assessment": "I have read many papers in this area.", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #4", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review": "The paper proposes a model for stochasticity for conditional image generation, building upon the previously available (DCFNet) results on composition of  convolutional filters out of the elements of the filter basis. \n\nThe idea of introducing stochasticity by convolutional filters into the conditional generative models seems to be novel and the reviewer thinks it could be of interest for the community.\n\nThe following remarks could be given to improve the presentation:\n1) Theorem 1 is an existence theorem, so it does not give the procedure for construction of the basis. Does the construction procedure for the basis, described under the theorem formulation, meet the conditions of Theorem 1? \n2) The Theorem 1 formulation states that \u201c If there exists a set of deterministic linear transforms\u201d. Should the linear independence be stated as well as one of the theorem conditions ( so that the space dimensionality would indeed be K)? \n3) The reviewer finds the structure of Section 4 confusing: it starts from the problem statement (first paragraph 'Using the method above, filters of each stochastic layer\u2026\u2019), then provides the description of the approach and only then outlines Theorem 1. It might be that stating Theorem 1 and then defining the method for generation of the basis (how exactly could we get to the basis? ) could improve readability of the paper. Essentially, the question is: is there any way to emphasise the procedure for filter generation and inform the reader in which circumstances these filters would be the basis (e.g. why it wouldn't be prone to the analogue of mode collapse when the filters do not effectively have enough diversity for linear independence)? \n***\nIn addition to this list, it might be useful to provide some evidence on whether there is any inherent mechanism to regulate the diversity of filters and therefore of samples (so that to change the variability of the conditional samples from the model with the impact analogous to the one of temperature in Glow (Kingma et al, 2018)). If there is one, further experimental evidence, which shows the impact on diversity of filters, would contribute to improvement of the paper.  \n"}, "signatures": ["ICLR.cc/2020/Conference/Paper817/AnonReviewer4"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper817/AnonReviewer4"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Stochastic Conditional Generative Networks with Basis Decomposition", "authors": ["Ze Wang", "Xiuyuan Cheng", "Guillermo Sapiro", "Qiang Qiu"], "authorids": ["ze.w@duke.edu", "xiuyuan.cheng@duke.edu", "guillermo.sapiro@duke.edu", "qiang.qiu@duke.edu"], "keywords": [], "abstract": "While generative adversarial networks (GANs) have revolutionized machine learning, a number of open questions remain to fully understand them and exploit their power. One of these questions is how to efficiently achieve proper diversity and sampling of the multi-mode data space. To address this, we introduce BasisGAN, a stochastic conditional multi-mode image generator. By exploiting the observation that a convolutional filter can be well approximated as a linear combination of a small set of basis elements, we learn a plug-and-played basis generator to stochastically generate basis elements, with just a few hundred of parameters, to fully embed stochasticity into convolutional filters. By sampling basis elements instead of filters, we dramatically reduce the cost of modeling the parameter space with no sacrifice on either image diversity or fidelity. To illustrate this proposed plug-and-play framework, we construct variants of BasisGAN based on state-of-the-art conditional image generation networks, and train the networks by simply plugging in a basis generator, without additional auxiliary components, hyperparameters, or training objectives. The experimental success is complemented with theoretical results indicating how the perturbations introduced by the proposed sampling of basis elements can propagate to the appearance of generated images.", "pdf": "/pdf/8e4c7efd2555c085a449a3d1db3bff1bac0c4e59.pdf", "paperhash": "wang|stochastic_conditional_generative_networks_with_basis_decomposition", "_bibtex": "@inproceedings{\nWang2020Stochastic,\ntitle={Stochastic Conditional Generative Networks with Basis Decomposition},\nauthor={Ze Wang and Xiuyuan Cheng and Guillermo Sapiro and Qiang Qiu},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=S1lSapVtwS}\n}", "full_presentation_video": "", "original_pdf": "/attachment/a16c038c96333b552aff523b7115a3fb2e40724b.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "S1lSapVtwS", "replyto": "S1lSapVtwS", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper817/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper817/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1575770036781, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper817/Reviewers"], "noninvitees": [], "tcdate": 1570237746575, "tmdate": 1575770036794, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper817/-/Official_Review"}}}], "count": 10}