{"notes": [{"id": "rJlNKCNtPB", "original": "r1eOKmOdwr", "number": 1244, "cdate": 1569439356174, "ddate": null, "tcdate": 1569439356174, "tmdate": 1577168228886, "tddate": null, "forum": "rJlNKCNtPB", "replyto": null, "invitation": "ICLR.cc/2020/Conference/-/Blind_Submission", "content": {"title": "Adaptive Learned Bloom Filter (Ada-BF): Efficient Utilization of the Classifier", "authors": ["Zhenwei Dai", "Anshumali Shrivastava"], "authorids": ["zd11@rice.edu", "anshumali@rice.edu"], "keywords": ["Ada-BF", "Bloom filter", "machine learning", "memory efficient"], "TL;DR": "Propose an efficient algorithm to improve the Bloom filter by incorporating the machine learning model in a clever way", "abstract": "Recent work suggests improving the performance of Bloom filter by incorporating a machine learning model as a binary classifier. However, such learned Bloom filter does not take full advantage of the predicted probability scores. We proposed new algorithms that generalize the learned Bloom filter by using the complete spectrum of the scores regions. We proved our algorithms have lower False Positive Rate (FPR) and memory usage compared with the existing approaches to learned Bloom filter. We also demonstrated the improved performance of our algorithms on real-world datasets.", "pdf": "/pdf/1d455c57569ef90999a9ce5235fb005720bd916a.pdf", "paperhash": "dai|adaptive_learned_bloom_filter_adabf_efficient_utilization_of_the_classifier", "original_pdf": "/attachment/f96a3f1ce5ce889f4c28c7b5cf641204552efd4a.pdf", "_bibtex": "@misc{\ndai2020adaptive,\ntitle={Adaptive Learned Bloom Filter (Ada-{\\{}BF{\\}}): Efficient Utilization of the Classifier},\nauthor={Zhenwei Dai and Anshumali Shrivastava},\nyear={2020},\nurl={https://openreview.net/forum?id=rJlNKCNtPB}\n}"}, "signatures": ["ICLR.cc/2020/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference"], "details": {"replyCount": 8, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"reply": {"readers": {"values-regex": ".*"}, "writers": {"values": ["ICLR.cc/2020/Conference"]}, "signatures": {"values": ["ICLR.cc/2020/Conference"]}, "content": {"spotlight_video": {"value-regex": ".*"}, "full_presentation_video": {"value-regex": ".*"}, "original_pdf": {"required": false, "description": "Upload a PDF file that ends with .pdf", "value-regex": ".*"}, "appendix": {"value-regex": ".*"}, "authorids": {"values-regex": ".*"}, "poster": {"value-regex": ".*"}, "authors": {"values": ["Anonymous"]}, "slides": {"value-regex": ".*"}}}, "final": [], "signatures": ["ICLR.cc/2020/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference"], "noninvitees": [], "tcdate": 1569271260237, "tmdate": 1593459412141, "id": "ICLR.cc/2020/Conference/-/Blind_Submission"}}, "tauthor": "OpenReview.net"}, {"id": "Vfh0M9AG5p", "original": null, "number": 1, "cdate": 1576798718452, "ddate": null, "tcdate": 1576798718452, "tmdate": 1576800918104, "tddate": null, "forum": "rJlNKCNtPB", "replyto": "rJlNKCNtPB", "invitation": "ICLR.cc/2020/Conference/Paper1244/-/Decision", "content": {"decision": "Reject", "comment": "The paper improves the Bloom filter learning by utilizing the complete spectrum of the scores regions. \n\nThe paper is nicely written with strong motivation and theoretical analysis of the proposed model. The evaluation could be improved: all the experiments are only tested on the small datasets, which makes it hard to assess the practicality of the proposed method. The paper could lead to a strong publication in the future if the issue on evaluation can be addressed. \n", "title": "Paper Decision"}, "signatures": ["ICLR.cc/2020/Conference/Program_Chairs"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Program_Chairs"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Adaptive Learned Bloom Filter (Ada-BF): Efficient Utilization of the Classifier", "authors": ["Zhenwei Dai", "Anshumali Shrivastava"], "authorids": ["zd11@rice.edu", "anshumali@rice.edu"], "keywords": ["Ada-BF", "Bloom filter", "machine learning", "memory efficient"], "TL;DR": "Propose an efficient algorithm to improve the Bloom filter by incorporating the machine learning model in a clever way", "abstract": "Recent work suggests improving the performance of Bloom filter by incorporating a machine learning model as a binary classifier. However, such learned Bloom filter does not take full advantage of the predicted probability scores. We proposed new algorithms that generalize the learned Bloom filter by using the complete spectrum of the scores regions. We proved our algorithms have lower False Positive Rate (FPR) and memory usage compared with the existing approaches to learned Bloom filter. We also demonstrated the improved performance of our algorithms on real-world datasets.", "pdf": "/pdf/1d455c57569ef90999a9ce5235fb005720bd916a.pdf", "paperhash": "dai|adaptive_learned_bloom_filter_adabf_efficient_utilization_of_the_classifier", "original_pdf": "/attachment/f96a3f1ce5ce889f4c28c7b5cf641204552efd4a.pdf", "_bibtex": "@misc{\ndai2020adaptive,\ntitle={Adaptive Learned Bloom Filter (Ada-{\\{}BF{\\}}): Efficient Utilization of the Classifier},\nauthor={Zhenwei Dai and Anshumali Shrivastava},\nyear={2020},\nurl={https://openreview.net/forum?id=rJlNKCNtPB}\n}"}, "tags": [], "invitation": {"reply": {"writers": {"description": "How your identity will be displayed.", "values-regex": ["ICLR.cc/2020/Conference/Program_Chairs"]}, "signatures": {"values": ["ICLR.cc/2020/Conference/Program_Chairs"], "description": "How your identity will be displayed."}, "content": {"decision": {"value-radio": ["Accept (Spotlight)", "Accept (Talk)", "Accept (Poster)", "Reject"], "description": "Decision", "required": true, "order": 2}, "title": {"value": "Paper Decision", "required": true, "order": 1}, "comment": {"value-regex": "[\\S\\s]{0,5000}", "description": "", "required": false, "order": 3}}, "forum": "rJlNKCNtPB", "replyto": "rJlNKCNtPB", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}}, "expdate": 1576854540000, "duedate": 1576853940000, "multiReply": false, "readers": ["everyone"], "invitees": ["ICLR.cc/2020/Conference/Program_Chairs"], "tcdate": 1576795706309, "tmdate": 1576800254325, "super": "ICLR.cc/2020/Conference/-/Decision", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper1244/-/Decision"}}}, {"id": "Hklk4UTuiB", "original": null, "number": 3, "cdate": 1573602855225, "ddate": null, "tcdate": 1573602855225, "tmdate": 1573849718058, "tddate": null, "forum": "rJlNKCNtPB", "replyto": "Byx9PWQ6tH", "invitation": "ICLR.cc/2020/Conference/Paper1244/-/Official_Comment", "content": {"title": "Response to Reviewer 2", "comment": "Thanks for giving us the chance to address your misunderstandings and being open to change in scores!\n\nThe machine learning model is critical because it has discrimination power between the keys and non-keys, which cannot be replaced by a random hash function. Hierarchical random hashing is not any different from one random hashing, in fact, it is a little worse as hierarchy leads to biased randomness (For more details, please refer to the related literature on tabulation based hashing by Mikkel Thorup). So, hierarchical random hashing can be at best (assuming entropy in the data) as good as the vanilla Bloom filter. Since we have shown the vanilla Bloom filter is worse than Ada-BF in our paper, hierarchical random hashing does not outperform our algorithms. \n\nOn the other hand, since the discrimination power of the machine learning model is independent of the size of queries, a learner can be more efficient for membership tests compared with the Bloom filter in many cases. For example, if thousands of malicious URLs include the pattern \u2018abcabc\u2019, then for a decision tree, it only takes several bits to remember this pattern while for the Bloom filter, it may take thousands of bits to \u2018remember\u2019 these thousands of URLs with the pattern \u2018abcabc\u2019 as its memory usage grows with the size of queries. Clearly, when the queries can be classified with simple patterns that are easy to be learned by a machine learning model, incorporating a learner to the Bloom filter saves more bits. \n\nRegarding the number of hash functions used in the high score group, we set the minimum number of hash functions to 0 for the group with the highest scores (Page 4, before lemma 1) for both of our experiments, where the membership testing purely relies on the machine learning model.  So, we were doing exactly the same thing as you mentioned in your first concern.\n\nAda-BF generalizes the learned Bloom filter, and the number of hash functions in the backup filter varies across different groups.  Our hyper-parameter tuning strategy requires setting the minimum and the maximum number of hash functions. When the learner provides an accurate prediction for the queries falling in the high score region, we may just set the minimum number of hash functions to 0 to save the memory usage and reduce the overall false-positive rate.\n\n"}, "signatures": ["ICLR.cc/2020/Conference/Paper1244/Authors"], "readers": ["everyone", "ICLR.cc/2020/Conference/Paper1244/Authors", "ICLR.cc/2020/Conference/Paper1244/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper1244/Reviewers", "ICLR.cc/2020/Conference/Paper1244/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1244/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Adaptive Learned Bloom Filter (Ada-BF): Efficient Utilization of the Classifier", "authors": ["Zhenwei Dai", "Anshumali Shrivastava"], "authorids": ["zd11@rice.edu", "anshumali@rice.edu"], "keywords": ["Ada-BF", "Bloom filter", "machine learning", "memory efficient"], "TL;DR": "Propose an efficient algorithm to improve the Bloom filter by incorporating the machine learning model in a clever way", "abstract": "Recent work suggests improving the performance of Bloom filter by incorporating a machine learning model as a binary classifier. However, such learned Bloom filter does not take full advantage of the predicted probability scores. We proposed new algorithms that generalize the learned Bloom filter by using the complete spectrum of the scores regions. We proved our algorithms have lower False Positive Rate (FPR) and memory usage compared with the existing approaches to learned Bloom filter. We also demonstrated the improved performance of our algorithms on real-world datasets.", "pdf": "/pdf/1d455c57569ef90999a9ce5235fb005720bd916a.pdf", "paperhash": "dai|adaptive_learned_bloom_filter_adabf_efficient_utilization_of_the_classifier", "original_pdf": "/attachment/f96a3f1ce5ce889f4c28c7b5cf641204552efd4a.pdf", "_bibtex": "@misc{\ndai2020adaptive,\ntitle={Adaptive Learned Bloom Filter (Ada-{\\{}BF{\\}}): Efficient Utilization of the Classifier},\nauthor={Zhenwei Dai and Anshumali Shrivastava},\nyear={2020},\nurl={https://openreview.net/forum?id=rJlNKCNtPB}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "rJlNKCNtPB", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper1244/Authors", "ICLR.cc/2020/Conference/Paper1244/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper1244/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper1244/Reviewers", "ICLR.cc/2020/Conference/Paper1244/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper1244/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper1244/Authors|ICLR.cc/2020/Conference/Paper1244/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504158991, "tmdate": 1576860555694, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper1244/Authors", "ICLR.cc/2020/Conference/Paper1244/Reviewers", "ICLR.cc/2020/Conference/Paper1244/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper1244/-/Official_Comment"}}}, {"id": "rke_-zv3jB", "original": null, "number": 4, "cdate": 1573839360071, "ddate": null, "tcdate": 1573839360071, "tmdate": 1573839360071, "tddate": null, "forum": "rJlNKCNtPB", "replyto": "Hklk4UTuiB", "invitation": "ICLR.cc/2020/Conference/Paper1244/-/Official_Comment", "content": {"title": "Further Experiments on Hierarchical Hashing", "comment": "We implemented hierarchical random hashing on the malicious URL dataset (for more details, please see the appendix C figure 7). We spared 50% of the bit budget to the initial Bloom filter and used the other bits to build the backup filter. It shows that the hierarchical Bloom filter does not outperform the standard Bloom filter under all the bit budgets. In some cases,  it even reaches a worse false positive rate. Hence, our experiment results validate the reasoning in the previous paragraphs, suggesting the critical role of the machine learning model in Ada-BF (and other learned Bloom filters). "}, "signatures": ["ICLR.cc/2020/Conference/Paper1244/Authors"], "readers": ["everyone", "ICLR.cc/2020/Conference/Paper1244/Authors", "ICLR.cc/2020/Conference/Paper1244/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper1244/Reviewers", "ICLR.cc/2020/Conference/Paper1244/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1244/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Adaptive Learned Bloom Filter (Ada-BF): Efficient Utilization of the Classifier", "authors": ["Zhenwei Dai", "Anshumali Shrivastava"], "authorids": ["zd11@rice.edu", "anshumali@rice.edu"], "keywords": ["Ada-BF", "Bloom filter", "machine learning", "memory efficient"], "TL;DR": "Propose an efficient algorithm to improve the Bloom filter by incorporating the machine learning model in a clever way", "abstract": "Recent work suggests improving the performance of Bloom filter by incorporating a machine learning model as a binary classifier. However, such learned Bloom filter does not take full advantage of the predicted probability scores. We proposed new algorithms that generalize the learned Bloom filter by using the complete spectrum of the scores regions. We proved our algorithms have lower False Positive Rate (FPR) and memory usage compared with the existing approaches to learned Bloom filter. We also demonstrated the improved performance of our algorithms on real-world datasets.", "pdf": "/pdf/1d455c57569ef90999a9ce5235fb005720bd916a.pdf", "paperhash": "dai|adaptive_learned_bloom_filter_adabf_efficient_utilization_of_the_classifier", "original_pdf": "/attachment/f96a3f1ce5ce889f4c28c7b5cf641204552efd4a.pdf", "_bibtex": "@misc{\ndai2020adaptive,\ntitle={Adaptive Learned Bloom Filter (Ada-{\\{}BF{\\}}): Efficient Utilization of the Classifier},\nauthor={Zhenwei Dai and Anshumali Shrivastava},\nyear={2020},\nurl={https://openreview.net/forum?id=rJlNKCNtPB}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "rJlNKCNtPB", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper1244/Authors", "ICLR.cc/2020/Conference/Paper1244/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper1244/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper1244/Reviewers", "ICLR.cc/2020/Conference/Paper1244/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper1244/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper1244/Authors|ICLR.cc/2020/Conference/Paper1244/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504158991, "tmdate": 1576860555694, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper1244/Authors", "ICLR.cc/2020/Conference/Paper1244/Reviewers", "ICLR.cc/2020/Conference/Paper1244/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper1244/-/Official_Comment"}}}, {"id": "BkgkzhoOsr", "original": null, "number": 2, "cdate": 1573596167505, "ddate": null, "tcdate": 1573596167505, "tmdate": 1573836100253, "tddate": null, "forum": "rJlNKCNtPB", "replyto": "ByeFmAOpYr", "invitation": "ICLR.cc/2020/Conference/Paper1244/-/Official_Comment", "content": {"title": "Response to Reviewer 3", "comment": "Thanks for your thoughtful comments and support for the paper! \n\nAs you pointed out, the success of Ada-BF is based on the observation that the keys' score distribution density has an opposite trend compared to the non-keys. This observation is quite general since when the learner has a good discrimination power, the score distribution of keys and non-keys cannot be similar. Our algorithms make full use of this observation. Moreover, our experiment 2 also shows that even when the score density is a bit noisy, both Ada-BF and disjoint Ada-BF still outperform other state-of-the-art methods by a great margin, suggesting their robustness to the noisy score distributions."}, "signatures": ["ICLR.cc/2020/Conference/Paper1244/Authors"], "readers": ["everyone", "ICLR.cc/2020/Conference/Paper1244/Authors", "ICLR.cc/2020/Conference/Paper1244/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper1244/Reviewers", "ICLR.cc/2020/Conference/Paper1244/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1244/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Adaptive Learned Bloom Filter (Ada-BF): Efficient Utilization of the Classifier", "authors": ["Zhenwei Dai", "Anshumali Shrivastava"], "authorids": ["zd11@rice.edu", "anshumali@rice.edu"], "keywords": ["Ada-BF", "Bloom filter", "machine learning", "memory efficient"], "TL;DR": "Propose an efficient algorithm to improve the Bloom filter by incorporating the machine learning model in a clever way", "abstract": "Recent work suggests improving the performance of Bloom filter by incorporating a machine learning model as a binary classifier. However, such learned Bloom filter does not take full advantage of the predicted probability scores. We proposed new algorithms that generalize the learned Bloom filter by using the complete spectrum of the scores regions. We proved our algorithms have lower False Positive Rate (FPR) and memory usage compared with the existing approaches to learned Bloom filter. We also demonstrated the improved performance of our algorithms on real-world datasets.", "pdf": "/pdf/1d455c57569ef90999a9ce5235fb005720bd916a.pdf", "paperhash": "dai|adaptive_learned_bloom_filter_adabf_efficient_utilization_of_the_classifier", "original_pdf": "/attachment/f96a3f1ce5ce889f4c28c7b5cf641204552efd4a.pdf", "_bibtex": "@misc{\ndai2020adaptive,\ntitle={Adaptive Learned Bloom Filter (Ada-{\\{}BF{\\}}): Efficient Utilization of the Classifier},\nauthor={Zhenwei Dai and Anshumali Shrivastava},\nyear={2020},\nurl={https://openreview.net/forum?id=rJlNKCNtPB}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "rJlNKCNtPB", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper1244/Authors", "ICLR.cc/2020/Conference/Paper1244/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper1244/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper1244/Reviewers", "ICLR.cc/2020/Conference/Paper1244/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper1244/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper1244/Authors|ICLR.cc/2020/Conference/Paper1244/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504158991, "tmdate": 1576860555694, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper1244/Authors", "ICLR.cc/2020/Conference/Paper1244/Reviewers", "ICLR.cc/2020/Conference/Paper1244/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper1244/-/Official_Comment"}}}, {"id": "HyeW6wi_or", "original": null, "number": 1, "cdate": 1573595064824, "ddate": null, "tcdate": 1573595064824, "tmdate": 1573836072984, "tddate": null, "forum": "rJlNKCNtPB", "replyto": "SkgM4JEJcH", "invitation": "ICLR.cc/2020/Conference/Paper1244/-/Official_Comment", "content": {"title": "Response to Reviewer 1", "comment": "Thanks for your thoughtful comments and support for the paper! \n\nOur malicious URL experiment uses over half-a-million URLs which is a very reasonable size for  Bloom filters as used for caching malicious URLs in the web-browser.  \n\nRegarding execution time and memory usage, weak classifiers (as used in the paper) can actually be more efficient than 2-universal hash functions, which is the case in our first experiment. We use 6 hash functions (bit array length = 500K) for vanilla Bloom filter. On a URL string, each of this hash function requires the operation of the order of the size of the string. Each of the 2-universal hash function is equivalent to inference (not training) with a linear classifier such as SVM or regression. In experiments, our classifier is a simple decision tree with less than 10 decisions based on simple features in the URL string. Clearly, the classifier operation is negligible and is even smaller than universal hashing if the object is heavy (like URL string).  \n\nIn our malicious URL experiment, the hashing operation (sklearn.utils.murmurhash3_32 in python) takes over 9s while the classifier inference takes less than 1s. So, our experiment shows the inference time is much shorter than the hashing time. \n\nIt is the case that training the decision trees are slow but that is a one-time operation and hence is not a concern while querying.  So machine learning presents an interesting amortization tradeoff with a very slow one-time training process (like slower than other data structures) but super-efficient query, even faster than universal hash functions.  \n"}, "signatures": ["ICLR.cc/2020/Conference/Paper1244/Authors"], "readers": ["everyone", "ICLR.cc/2020/Conference/Paper1244/Authors", "ICLR.cc/2020/Conference/Paper1244/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper1244/Reviewers", "ICLR.cc/2020/Conference/Paper1244/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1244/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Adaptive Learned Bloom Filter (Ada-BF): Efficient Utilization of the Classifier", "authors": ["Zhenwei Dai", "Anshumali Shrivastava"], "authorids": ["zd11@rice.edu", "anshumali@rice.edu"], "keywords": ["Ada-BF", "Bloom filter", "machine learning", "memory efficient"], "TL;DR": "Propose an efficient algorithm to improve the Bloom filter by incorporating the machine learning model in a clever way", "abstract": "Recent work suggests improving the performance of Bloom filter by incorporating a machine learning model as a binary classifier. However, such learned Bloom filter does not take full advantage of the predicted probability scores. We proposed new algorithms that generalize the learned Bloom filter by using the complete spectrum of the scores regions. We proved our algorithms have lower False Positive Rate (FPR) and memory usage compared with the existing approaches to learned Bloom filter. We also demonstrated the improved performance of our algorithms on real-world datasets.", "pdf": "/pdf/1d455c57569ef90999a9ce5235fb005720bd916a.pdf", "paperhash": "dai|adaptive_learned_bloom_filter_adabf_efficient_utilization_of_the_classifier", "original_pdf": "/attachment/f96a3f1ce5ce889f4c28c7b5cf641204552efd4a.pdf", "_bibtex": "@misc{\ndai2020adaptive,\ntitle={Adaptive Learned Bloom Filter (Ada-{\\{}BF{\\}}): Efficient Utilization of the Classifier},\nauthor={Zhenwei Dai and Anshumali Shrivastava},\nyear={2020},\nurl={https://openreview.net/forum?id=rJlNKCNtPB}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "rJlNKCNtPB", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper1244/Authors", "ICLR.cc/2020/Conference/Paper1244/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper1244/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper1244/Reviewers", "ICLR.cc/2020/Conference/Paper1244/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper1244/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper1244/Authors|ICLR.cc/2020/Conference/Paper1244/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504158991, "tmdate": 1576860555694, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper1244/Authors", "ICLR.cc/2020/Conference/Paper1244/Reviewers", "ICLR.cc/2020/Conference/Paper1244/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper1244/-/Official_Comment"}}}, {"id": "Byx9PWQ6tH", "original": null, "number": 1, "cdate": 1571791201763, "ddate": null, "tcdate": 1571791201763, "tmdate": 1572972494127, "tddate": null, "forum": "rJlNKCNtPB", "replyto": "rJlNKCNtPB", "invitation": "ICLR.cc/2020/Conference/Paper1244/-/Official_Review", "content": {"experience_assessment": "I do not know much about this area.", "rating": "3: Weak Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #2", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "The paper proposed an adaptive learned bloom filter. Rather than setting a threshold of prediction score, the paper partitions the score into several intervals; for query insider each interval, the paper either uses a group of independent hash functions to hash the query in one unified bloom filter or introduce an independent bloom filter. The paper proposes efficient ways to tune the hyper-parameters, and provides the analysis of the error. Experiments on two applications show the effectiveness of the proposed methods. \n\nThe idea seems useful. However, I have a few concerns/questions. My decision depends on the responses of the author(s). \n\n(1) Although the paper claims the score information can be fully exploited, the paper seems to do hashing for all possible queries. Why not set up a tau such that only when the score is below tau, we conduct the adaptive hashing? When the score is bigger than tau, we still claim an identification of the key? In this way, a bunch of keys can still be saved and without extra hashing. \n\n(2) The proposed method seems to be a hierarchical hashing strategy.  The first level is to hash the queries into different intervals through a score function learned from data. Why not compose another group of random hash to do the first level hashing? What is the major benefit of collecting training examples to run a machine learning model? Accordingly, why not compare with such a baseline using a group of random hashing to do the first level? "}, "signatures": ["ICLR.cc/2020/Conference/Paper1244/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1244/AnonReviewer2"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Adaptive Learned Bloom Filter (Ada-BF): Efficient Utilization of the Classifier", "authors": ["Zhenwei Dai", "Anshumali Shrivastava"], "authorids": ["zd11@rice.edu", "anshumali@rice.edu"], "keywords": ["Ada-BF", "Bloom filter", "machine learning", "memory efficient"], "TL;DR": "Propose an efficient algorithm to improve the Bloom filter by incorporating the machine learning model in a clever way", "abstract": "Recent work suggests improving the performance of Bloom filter by incorporating a machine learning model as a binary classifier. However, such learned Bloom filter does not take full advantage of the predicted probability scores. We proposed new algorithms that generalize the learned Bloom filter by using the complete spectrum of the scores regions. We proved our algorithms have lower False Positive Rate (FPR) and memory usage compared with the existing approaches to learned Bloom filter. We also demonstrated the improved performance of our algorithms on real-world datasets.", "pdf": "/pdf/1d455c57569ef90999a9ce5235fb005720bd916a.pdf", "paperhash": "dai|adaptive_learned_bloom_filter_adabf_efficient_utilization_of_the_classifier", "original_pdf": "/attachment/f96a3f1ce5ce889f4c28c7b5cf641204552efd4a.pdf", "_bibtex": "@misc{\ndai2020adaptive,\ntitle={Adaptive Learned Bloom Filter (Ada-{\\{}BF{\\}}): Efficient Utilization of the Classifier},\nauthor={Zhenwei Dai and Anshumali Shrivastava},\nyear={2020},\nurl={https://openreview.net/forum?id=rJlNKCNtPB}\n}"}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "rJlNKCNtPB", "replyto": "rJlNKCNtPB", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper1244/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper1244/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1575872147513, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper1244/Reviewers"], "noninvitees": [], "tcdate": 1570237740206, "tmdate": 1575872147525, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper1244/-/Official_Review"}}}, {"id": "ByeFmAOpYr", "original": null, "number": 2, "cdate": 1571814944776, "ddate": null, "tcdate": 1571814944776, "tmdate": 1572972494080, "tddate": null, "forum": "rJlNKCNtPB", "replyto": "rJlNKCNtPB", "invitation": "ICLR.cc/2020/Conference/Paper1244/-/Official_Review", "content": {"experience_assessment": "I do not know much about this area.", "rating": "6: Weak Accept", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #3", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "This paper extends the Bloom filter learning by using the complete spectrum of the scores regions. It uses multiple thresholds and then varies the number of hash functions among different scores regions to obtain better trade-off. Detailed theoretical analysis provides guaranteed superiority over learned Bloom filter under some conditions. The experiments also show the two proposed methods outperform learned Bloom filter in FPR and memory usage.\n\nThe motivation is based on the observation that the keys' score distribution density has an opposite trend to the non-keys. Though the experiment results support this observation, some theoretical analysis on this and its relationship with the final FPR could be provided. "}, "signatures": ["ICLR.cc/2020/Conference/Paper1244/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1244/AnonReviewer3"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Adaptive Learned Bloom Filter (Ada-BF): Efficient Utilization of the Classifier", "authors": ["Zhenwei Dai", "Anshumali Shrivastava"], "authorids": ["zd11@rice.edu", "anshumali@rice.edu"], "keywords": ["Ada-BF", "Bloom filter", "machine learning", "memory efficient"], "TL;DR": "Propose an efficient algorithm to improve the Bloom filter by incorporating the machine learning model in a clever way", "abstract": "Recent work suggests improving the performance of Bloom filter by incorporating a machine learning model as a binary classifier. However, such learned Bloom filter does not take full advantage of the predicted probability scores. We proposed new algorithms that generalize the learned Bloom filter by using the complete spectrum of the scores regions. We proved our algorithms have lower False Positive Rate (FPR) and memory usage compared with the existing approaches to learned Bloom filter. We also demonstrated the improved performance of our algorithms on real-world datasets.", "pdf": "/pdf/1d455c57569ef90999a9ce5235fb005720bd916a.pdf", "paperhash": "dai|adaptive_learned_bloom_filter_adabf_efficient_utilization_of_the_classifier", "original_pdf": "/attachment/f96a3f1ce5ce889f4c28c7b5cf641204552efd4a.pdf", "_bibtex": "@misc{\ndai2020adaptive,\ntitle={Adaptive Learned Bloom Filter (Ada-{\\{}BF{\\}}): Efficient Utilization of the Classifier},\nauthor={Zhenwei Dai and Anshumali Shrivastava},\nyear={2020},\nurl={https://openreview.net/forum?id=rJlNKCNtPB}\n}"}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "rJlNKCNtPB", "replyto": "rJlNKCNtPB", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper1244/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper1244/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1575872147513, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper1244/Reviewers"], "noninvitees": [], "tcdate": 1570237740206, "tmdate": 1575872147525, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper1244/-/Official_Review"}}}, {"id": "SkgM4JEJcH", "original": null, "number": 3, "cdate": 1571925801962, "ddate": null, "tcdate": 1571925801962, "tmdate": 1572972494033, "tddate": null, "forum": "rJlNKCNtPB", "replyto": "rJlNKCNtPB", "invitation": "ICLR.cc/2020/Conference/Paper1244/-/Official_Review", "content": {"experience_assessment": "I do not know much about this area.", "rating": "6: Weak Accept", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #1", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "This paper proposes two new bloom filter algorithms that incorporate a learnt model for estimating if an input is in the set or not. These methods blend the space between pure BF and learnt BF with one threshold by creating regions over the score and having varying number of hash functions for each region.\n\nI really like the paper and the approach taken. However, the experiments are on such small datasets that the true impact of these models aren't as impressive as they could be. In practice, BFs are used when dealing with millions/billions of entries to achieve real-time performance in real-world. For such applications, not only the memory is of concern but also the run-time part of the equation. In other words, if we have a learnt classifier for BF, how much will it impact the execution time vs memory usage as both are needed to be traded-off. It would have been great if the authors had experimented with larger datasets and had practical considerations for run-time and memory vs FPR investigated."}, "signatures": ["ICLR.cc/2020/Conference/Paper1244/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1244/AnonReviewer1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Adaptive Learned Bloom Filter (Ada-BF): Efficient Utilization of the Classifier", "authors": ["Zhenwei Dai", "Anshumali Shrivastava"], "authorids": ["zd11@rice.edu", "anshumali@rice.edu"], "keywords": ["Ada-BF", "Bloom filter", "machine learning", "memory efficient"], "TL;DR": "Propose an efficient algorithm to improve the Bloom filter by incorporating the machine learning model in a clever way", "abstract": "Recent work suggests improving the performance of Bloom filter by incorporating a machine learning model as a binary classifier. However, such learned Bloom filter does not take full advantage of the predicted probability scores. We proposed new algorithms that generalize the learned Bloom filter by using the complete spectrum of the scores regions. We proved our algorithms have lower False Positive Rate (FPR) and memory usage compared with the existing approaches to learned Bloom filter. We also demonstrated the improved performance of our algorithms on real-world datasets.", "pdf": "/pdf/1d455c57569ef90999a9ce5235fb005720bd916a.pdf", "paperhash": "dai|adaptive_learned_bloom_filter_adabf_efficient_utilization_of_the_classifier", "original_pdf": "/attachment/f96a3f1ce5ce889f4c28c7b5cf641204552efd4a.pdf", "_bibtex": "@misc{\ndai2020adaptive,\ntitle={Adaptive Learned Bloom Filter (Ada-{\\{}BF{\\}}): Efficient Utilization of the Classifier},\nauthor={Zhenwei Dai and Anshumali Shrivastava},\nyear={2020},\nurl={https://openreview.net/forum?id=rJlNKCNtPB}\n}"}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "rJlNKCNtPB", "replyto": "rJlNKCNtPB", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper1244/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper1244/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1575872147513, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper1244/Reviewers"], "noninvitees": [], "tcdate": 1570237740206, "tmdate": 1575872147525, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper1244/-/Official_Review"}}}], "count": 9}