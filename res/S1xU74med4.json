{"notes": [{"id": "S1xU74med4", "original": "B1gop9j_vE", "number": 20, "cdate": 1553114142061, "ddate": null, "tcdate": 1553114142061, "tmdate": 1562082107027, "tddate": null, "forum": "S1xU74med4", "replyto": null, "invitation": "ICLR.cc/2019/Workshop/LLD/-/Blind_Submission", "content": {"title": "Skip-connection and batch-normalization improve data separation ability", "authors": ["Yasutaka Furusho", "Kazushi Ikeda"], "authorids": ["furusho.yasutaka.fm1@is.naist.jp", "kazushi@is.naist.jp"], "keywords": ["Deep learning", "ResNet", "Skip-connection", "Batch-normalization"], "TL;DR": "The Skip-connection in ResNet and the batch-normalization improve the data separation ability and help to train a deep neural network.", "abstract": "The ResNet and the batch-normalization (BN) achieved high performance even when only a few labeled data are available. However, the reasons for its high performance are unclear. To clear the reasons, we analyzed the effect of the skip-connection in ResNet and the BN on the data separation ability, which is an important ability for the classification problem. Our results show that, in the multilayer perceptron with randomly initialized weights, the angle between two input vectors converges to zero in an exponential order of its depth, that the skip-connection makes this exponential decrease into a sub-exponential decrease, and that the BN relaxes this sub-exponential decrease into a reciprocal decrease. Moreover, our analysis shows that the preservation of the angle at initialization encourages trained neural networks to separate points from different classes. These imply that the skip-connection and the BN improve the data separation ability and achieve high performance even when only a few labeled data are available.", "pdf": "/pdf/69be1b3f4cf276ef8727f3decbe4492538b44506.pdf", "paperhash": "furusho|skipconnection_and_batchnormalization_improve_data_separation_ability"}, "signatures": ["ICLR.cc/2019/Workshop/LLD"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Workshop/LLD"], "details": {"replyCount": 3, "writable": false, "overwriting": [], "revisions": false, "tags": [], "invitation": {"id": "ICLR.cc/2019/Workshop/LLD/-/Blind_Submission", "cdate": 1548689671889, "reply": {"forum": null, "replyto": null, "readers": {"values-regex": ".*"}, "writers": {"values": ["ICLR.cc/2019/Workshop/LLD"]}, "signatures": {"values": ["ICLR.cc/2019/Workshop/LLD"]}, "content": {"authors": {"values-regex": ".*"}, "authorids": {"values-regex": ".*"}}}, "tcdate": 1548689671889, "tmdate": 1557933709646, "readers": ["everyone"], "writers": ["ICLR.cc/2019/Workshop/LLD"], "invitees": ["~"], "signatures": ["ICLR.cc/2019/Workshop/LLD"], "details": {"writable": true}}}, "tauthor": "OpenReview.net"}, {"id": "B1eJCEuUYV", "original": null, "number": 1, "cdate": 1554576583101, "ddate": null, "tcdate": 1554576583101, "tmdate": 1555512022862, "tddate": null, "forum": "S1xU74med4", "replyto": "S1xU74med4", "invitation": "ICLR.cc/2019/Workshop/LLD/-/Paper20/Official_Review", "content": {"title": "A nice paper studying angles of vectors through layers for data separation", "review": "The authors here present an interesting analysis on how skip-connections in residual networks and batch-normalization affect data separation. Their analysis included observing the transformation of the input vectors through hidden layers of the neural networks, like a standard multilayer perceptron, a resnet and a resnet with batch normalization. They did that by studying the angle and cosine similarity through the layers. This property is critical to decide if the model is able to separate points in different classes.\n\nThe paper is well written and easy to read. The settings and configurations are carefully explained and carry the detail needed to understand the analysis. The study of angles and cosine similarities between the layers is very interesting, although its relation to the data separation property (section 3.3) could be written in a more clear way. \n\nPros:\n- connecting the dynamics of angles with data separation\n- extensive analysis\n\nCons: \n- more settings could be explored\n\nSome questions that the authors could address as well: why are the specific resnet models selected by the authors (Yang, Hardt)? what are the effects of using different initialization methods for the internal weights? how much important is the specific initialization chosen by the authors? what happens when the number of training examples increases or decreases? ", "rating": "4: Top 50% of accepted papers, clear accept", "confidence": "2: The reviewer is fairly confident that the evaluation is correct"}, "signatures": ["ICLR.cc/2019/Workshop/LLD/Paper20/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Workshop/LLD/Paper20/AnonReviewer2"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Skip-connection and batch-normalization improve data separation ability", "authors": ["Yasutaka Furusho", "Kazushi Ikeda"], "authorids": ["furusho.yasutaka.fm1@is.naist.jp", "kazushi@is.naist.jp"], "keywords": ["Deep learning", "ResNet", "Skip-connection", "Batch-normalization"], "TL;DR": "The Skip-connection in ResNet and the batch-normalization improve the data separation ability and help to train a deep neural network.", "abstract": "The ResNet and the batch-normalization (BN) achieved high performance even when only a few labeled data are available. However, the reasons for its high performance are unclear. To clear the reasons, we analyzed the effect of the skip-connection in ResNet and the BN on the data separation ability, which is an important ability for the classification problem. Our results show that, in the multilayer perceptron with randomly initialized weights, the angle between two input vectors converges to zero in an exponential order of its depth, that the skip-connection makes this exponential decrease into a sub-exponential decrease, and that the BN relaxes this sub-exponential decrease into a reciprocal decrease. Moreover, our analysis shows that the preservation of the angle at initialization encourages trained neural networks to separate points from different classes. These imply that the skip-connection and the BN improve the data separation ability and achieve high performance even when only a few labeled data are available.", "pdf": "/pdf/69be1b3f4cf276ef8727f3decbe4492538b44506.pdf", "paperhash": "furusho|skipconnection_and_batchnormalization_improve_data_separation_ability"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Workshop/LLD/-/Paper20/Official_Review", "cdate": 1553713418995, "expdate": 1555718400000, "duedate": 1554681600000, "reply": {"forum": "S1xU74med4", "replyto": "S1xU74med4", "writers": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2019/Workshop/LLD/Paper20/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2019/Workshop/LLD/Paper20/AnonReviewer[0-9]+"}, "readers": {"values": ["everyone"], "description": "The users who will be allowed to read the above content."}, "content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "required": true}, "rating": {"order": 3, "value-dropdown": ["5: Top 15% of accepted papers, strong accept", "4: Top 50% of accepted papers, clear accept", "3: Marginally above acceptance threshold", "2: Marginally below acceptance threshold", "1: Strong rejection"], "required": true}, "confidence": {"order": 4, "value-radio": ["3: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "2: The reviewer is fairly confident that the evaluation is correct", "1: The reviewer's evaluation is an educated guess"], "required": true}}}, "tcdate": 1553713418995, "tmdate": 1555511816750, "readers": ["everyone"], "writers": ["ICLR.cc/2019/Workshop/LLD"], "invitees": ["ICLR.cc/2019/Workshop/LLD/Paper20/Reviewers"], "signatures": ["ICLR.cc/2019/Workshop/LLD"]}}}, {"id": "BkgBC8Z3tV", "original": null, "number": 2, "cdate": 1554941644613, "ddate": null, "tcdate": 1554941644613, "tmdate": 1555511877800, "tddate": null, "forum": "S1xU74med4", "replyto": "S1xU74med4", "invitation": "ICLR.cc/2019/Workshop/LLD/-/Paper20/Official_Review", "content": {"title": "Angle preservation analysis in BN and ResNet shortcuts with questionable conclusion", "review": "Summary:\n\nThe authors argue, that BN and ResNet shortcuts encourage angle preservation throughout the layers.\n\nNovelty:\n\nThe analysis of angle preservation seems novel to me.\n\nRating:\n\nI do not think the paper makes a compelling point for why preservation of angle is a desirable property. Conservation of norm could be just as important and even that might not be important if classification would e.g. be based on the norm of a feature vector. I don't see why angles are a particularly desirable feature to preserve and the paper fails to make a strong point for this either. Thus, I vote for reject.", "rating": "2: Marginally below acceptance threshold", "confidence": "2: The reviewer is fairly confident that the evaluation is correct"}, "signatures": ["ICLR.cc/2019/Workshop/LLD/Paper20/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Workshop/LLD/Paper20/AnonReviewer1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Skip-connection and batch-normalization improve data separation ability", "authors": ["Yasutaka Furusho", "Kazushi Ikeda"], "authorids": ["furusho.yasutaka.fm1@is.naist.jp", "kazushi@is.naist.jp"], "keywords": ["Deep learning", "ResNet", "Skip-connection", "Batch-normalization"], "TL;DR": "The Skip-connection in ResNet and the batch-normalization improve the data separation ability and help to train a deep neural network.", "abstract": "The ResNet and the batch-normalization (BN) achieved high performance even when only a few labeled data are available. However, the reasons for its high performance are unclear. To clear the reasons, we analyzed the effect of the skip-connection in ResNet and the BN on the data separation ability, which is an important ability for the classification problem. Our results show that, in the multilayer perceptron with randomly initialized weights, the angle between two input vectors converges to zero in an exponential order of its depth, that the skip-connection makes this exponential decrease into a sub-exponential decrease, and that the BN relaxes this sub-exponential decrease into a reciprocal decrease. Moreover, our analysis shows that the preservation of the angle at initialization encourages trained neural networks to separate points from different classes. These imply that the skip-connection and the BN improve the data separation ability and achieve high performance even when only a few labeled data are available.", "pdf": "/pdf/69be1b3f4cf276ef8727f3decbe4492538b44506.pdf", "paperhash": "furusho|skipconnection_and_batchnormalization_improve_data_separation_ability"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Workshop/LLD/-/Paper20/Official_Review", "cdate": 1553713418995, "expdate": 1555718400000, "duedate": 1554681600000, "reply": {"forum": "S1xU74med4", "replyto": "S1xU74med4", "writers": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2019/Workshop/LLD/Paper20/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2019/Workshop/LLD/Paper20/AnonReviewer[0-9]+"}, "readers": {"values": ["everyone"], "description": "The users who will be allowed to read the above content."}, "content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "required": true}, "rating": {"order": 3, "value-dropdown": ["5: Top 15% of accepted papers, strong accept", "4: Top 50% of accepted papers, clear accept", "3: Marginally above acceptance threshold", "2: Marginally below acceptance threshold", "1: Strong rejection"], "required": true}, "confidence": {"order": 4, "value-radio": ["3: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "2: The reviewer is fairly confident that the evaluation is correct", "1: The reviewer's evaluation is an educated guess"], "required": true}}}, "tcdate": 1553713418995, "tmdate": 1555511816750, "readers": ["everyone"], "writers": ["ICLR.cc/2019/Workshop/LLD"], "invitees": ["ICLR.cc/2019/Workshop/LLD/Paper20/Reviewers"], "signatures": ["ICLR.cc/2019/Workshop/LLD"]}}}, {"id": "B1lKa93zcE", "original": null, "number": 1, "cdate": 1555380929188, "ddate": null, "tcdate": 1555380929188, "tmdate": 1555510979187, "tddate": null, "forum": "S1xU74med4", "replyto": "S1xU74med4", "invitation": "ICLR.cc/2019/Workshop/LLD/-/Paper20/Decision", "content": {"title": "Acceptance Decision", "decision": "Reject", "comment": "R1 had several issues with the arguments in the paper. The paper is also not a great fit for the workshop topic"}, "signatures": ["ICLR.cc/2019/Workshop/LLD/Program_Chairs"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Workshop/LLD/Program_Chairs"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Skip-connection and batch-normalization improve data separation ability", "authors": ["Yasutaka Furusho", "Kazushi Ikeda"], "authorids": ["furusho.yasutaka.fm1@is.naist.jp", "kazushi@is.naist.jp"], "keywords": ["Deep learning", "ResNet", "Skip-connection", "Batch-normalization"], "TL;DR": "The Skip-connection in ResNet and the batch-normalization improve the data separation ability and help to train a deep neural network.", "abstract": "The ResNet and the batch-normalization (BN) achieved high performance even when only a few labeled data are available. However, the reasons for its high performance are unclear. To clear the reasons, we analyzed the effect of the skip-connection in ResNet and the BN on the data separation ability, which is an important ability for the classification problem. Our results show that, in the multilayer perceptron with randomly initialized weights, the angle between two input vectors converges to zero in an exponential order of its depth, that the skip-connection makes this exponential decrease into a sub-exponential decrease, and that the BN relaxes this sub-exponential decrease into a reciprocal decrease. Moreover, our analysis shows that the preservation of the angle at initialization encourages trained neural networks to separate points from different classes. These imply that the skip-connection and the BN improve the data separation ability and achieve high performance even when only a few labeled data are available.", "pdf": "/pdf/69be1b3f4cf276ef8727f3decbe4492538b44506.pdf", "paperhash": "furusho|skipconnection_and_batchnormalization_improve_data_separation_ability"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Workshop/LLD/-/Paper20/Decision", "cdate": 1554736067935, "reply": {"forum": "S1xU74med4", "replyto": "S1xU74med4", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-regex": ["ICLR.cc/2019/Workshop/LLD/Program_Chairs"], "description": "How your identity will be displayed."}, "signatures": {"values": ["ICLR.cc/2019/Workshop/LLD/Program_Chairs"], "description": "How your identity will be displayed."}, "content": {"title": {"order": 1, "required": true, "value": "Acceptance Decision"}, "decision": {"order": 2, "required": true, "value-radio": ["Accept", "Reject"], "description": "Acceptance decision"}, "comment": {"order": 3, "required": false, "value-regex": "[\\S\\s]{0,5000}", "description": ""}}}, "tcdate": 1554736067935, "tmdate": 1555510970745, "readers": ["everyone"], "writers": ["ICLR.cc/2019/Workshop/LLD"], "invitees": ["ICLR.cc/2019/Workshop/LLD/Program_Chairs"], "signatures": ["ICLR.cc/2019/Workshop/LLD"]}}}], "count": 4}