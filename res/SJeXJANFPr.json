{"notes": [{"id": "SJeXJANFPr", "original": "H1leO8f_DB", "number": 887, "cdate": 1569439194962, "ddate": null, "tcdate": 1569439194962, "tmdate": 1577168216819, "tddate": null, "forum": "SJeXJANFPr", "replyto": null, "invitation": "ICLR.cc/2020/Conference/-/Blind_Submission", "content": {"title": "Regularizing Deep Multi-Task Networks using Orthogonal Gradients", "authors": ["Mihai Suteu", "Yi-ke Guo"], "authorids": ["m.suteu16@imperial.ac.uk", "y.guo@imperial.ac.uk"], "keywords": ["multi-task learning", "gradient regularization", "orthogonal gradients"], "TL;DR": "We propose a novel gradient regularization term that minimizes task interference by enforcing near orthogonal gradients.", "abstract": "Deep neural networks are a promising approach towards multi-task learning because of their capability to leverage knowledge across domains and learn general purpose representations. Nevertheless, they can fail to live up to these promises as tasks often compete for a model's limited resources, potentially leading to lower overall performance. In this work we tackle the issue of interfering tasks through a comprehensive analysis of their training, derived from looking at the interaction between gradients within their shared parameters. Our empirical results show that well-performing models have low variance in the angles between task gradients and that popular regularization methods implicitly reduce this measure. Based on this observation, we propose a novel gradient regularization term that minimizes task interference by enforcing near orthogonal gradients. Updating the shared parameters using this property encourages task specific decoders to optimize different parts of the feature extractor, thus reducing competition. We evaluate our method with classification and regression tasks on the multiDigitMNIST and NYUv2 dataset where we obtain competitive results. This work is a first step towards non-interfering multi-task optimization.", "pdf": "/pdf/b778a4fac18e1c67194f2fd57e9390a5908cf8ef.pdf", "paperhash": "suteu|regularizing_deep_multitask_networks_using_orthogonal_gradients", "original_pdf": "/attachment/a7b9fb372b5d2258d0f3e6b513775ccd09afe5f4.pdf", "_bibtex": "@misc{\nsuteu2020regularizing,\ntitle={Regularizing Deep Multi-Task Networks using Orthogonal Gradients},\nauthor={Mihai Suteu and Yi-ke Guo},\nyear={2020},\nurl={https://openreview.net/forum?id=SJeXJANFPr}\n}"}, "signatures": ["ICLR.cc/2020/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference"], "details": {"replyCount": 7, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"reply": {"readers": {"values-regex": ".*"}, "writers": {"values": ["ICLR.cc/2020/Conference"]}, "signatures": {"values": ["ICLR.cc/2020/Conference"]}, "content": {"spotlight_video": {"value-regex": ".*"}, "full_presentation_video": {"value-regex": ".*"}, "original_pdf": {"required": false, "description": "Upload a PDF file that ends with .pdf", "value-regex": ".*"}, "appendix": {"value-regex": ".*"}, "authorids": {"values-regex": ".*"}, "poster": {"value-regex": ".*"}, "authors": {"values": ["Anonymous"]}, "slides": {"value-regex": ".*"}}}, "final": [], "signatures": ["ICLR.cc/2020/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference"], "noninvitees": [], "tcdate": 1569271260237, "tmdate": 1593459412141, "id": "ICLR.cc/2020/Conference/-/Blind_Submission"}}, "tauthor": "OpenReview.net"}, {"id": "BuDufNvwG", "original": null, "number": 1, "cdate": 1576798708821, "ddate": null, "tcdate": 1576798708821, "tmdate": 1576800927562, "tddate": null, "forum": "SJeXJANFPr", "replyto": "SJeXJANFPr", "invitation": "ICLR.cc/2020/Conference/Paper887/-/Decision", "content": {"decision": "Reject", "comment": "This paper proposes a training approach that orthogonalizes gradients to enable better learning across multiple tasks. The idea is simple and intuitive.\n\nGiven that there is past work following the same kind of ideas, it would be need to further: \n(a) expand the experimental evaluation section with comparisons to prior work and, ideally, demonstrate stronger results.\n (b) study in more depth the assumptions behind gradient orthogonality for transfer. This would increase impact on top of past literature by explaining, besides intuitions, why gradient orthogonality helps for transfer in the first place.\n", "title": "Paper Decision"}, "signatures": ["ICLR.cc/2020/Conference/Program_Chairs"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Program_Chairs"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Regularizing Deep Multi-Task Networks using Orthogonal Gradients", "authors": ["Mihai Suteu", "Yi-ke Guo"], "authorids": ["m.suteu16@imperial.ac.uk", "y.guo@imperial.ac.uk"], "keywords": ["multi-task learning", "gradient regularization", "orthogonal gradients"], "TL;DR": "We propose a novel gradient regularization term that minimizes task interference by enforcing near orthogonal gradients.", "abstract": "Deep neural networks are a promising approach towards multi-task learning because of their capability to leverage knowledge across domains and learn general purpose representations. Nevertheless, they can fail to live up to these promises as tasks often compete for a model's limited resources, potentially leading to lower overall performance. In this work we tackle the issue of interfering tasks through a comprehensive analysis of their training, derived from looking at the interaction between gradients within their shared parameters. Our empirical results show that well-performing models have low variance in the angles between task gradients and that popular regularization methods implicitly reduce this measure. Based on this observation, we propose a novel gradient regularization term that minimizes task interference by enforcing near orthogonal gradients. Updating the shared parameters using this property encourages task specific decoders to optimize different parts of the feature extractor, thus reducing competition. We evaluate our method with classification and regression tasks on the multiDigitMNIST and NYUv2 dataset where we obtain competitive results. This work is a first step towards non-interfering multi-task optimization.", "pdf": "/pdf/b778a4fac18e1c67194f2fd57e9390a5908cf8ef.pdf", "paperhash": "suteu|regularizing_deep_multitask_networks_using_orthogonal_gradients", "original_pdf": "/attachment/a7b9fb372b5d2258d0f3e6b513775ccd09afe5f4.pdf", "_bibtex": "@misc{\nsuteu2020regularizing,\ntitle={Regularizing Deep Multi-Task Networks using Orthogonal Gradients},\nauthor={Mihai Suteu and Yi-ke Guo},\nyear={2020},\nurl={https://openreview.net/forum?id=SJeXJANFPr}\n}"}, "tags": [], "invitation": {"reply": {"writers": {"description": "How your identity will be displayed.", "values-regex": ["ICLR.cc/2020/Conference/Program_Chairs"]}, "signatures": {"values": ["ICLR.cc/2020/Conference/Program_Chairs"], "description": "How your identity will be displayed."}, "content": {"decision": {"value-radio": ["Accept (Spotlight)", "Accept (Talk)", "Accept (Poster)", "Reject"], "description": "Decision", "required": true, "order": 2}, "title": {"value": "Paper Decision", "required": true, "order": 1}, "comment": {"value-regex": "[\\S\\s]{0,5000}", "description": "", "required": false, "order": 3}}, "forum": "SJeXJANFPr", "replyto": "SJeXJANFPr", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}}, "expdate": 1576854540000, "duedate": 1576853940000, "multiReply": false, "readers": ["everyone"], "invitees": ["ICLR.cc/2020/Conference/Program_Chairs"], "tcdate": 1576795713774, "tmdate": 1576800263462, "super": "ICLR.cc/2020/Conference/-/Decision", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper887/-/Decision"}}}, {"id": "rJgBsEQgqH", "original": null, "number": 3, "cdate": 1571988637506, "ddate": null, "tcdate": 1571988637506, "tmdate": 1575009208702, "tddate": null, "forum": "SJeXJANFPr", "replyto": "SJeXJANFPr", "invitation": "ICLR.cc/2020/Conference/Paper887/-/Official_Review", "content": {"experience_assessment": "I have published in this field for several years.", "rating": "3: Weak Reject", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "title": "Official Blind Review #3", "review": "The submission argues that when training the multiple objectives in a multi task learning framework, orthogonalizing gradients is beneficial toward reducing task competitions and efficient allocation of the learning capacity in the parameters.  This is demonstrated experimentally and subsequently a second order method is used for incorporating this in training. \n\nPositives: \n1. The concept is sensible, intuitive, and simple. There has a been quite few works (Sener and Koltun 2018) that similarly argue analyzing/regularizing the gradient direction when training multiple task objectives is beneficial. This submission reinforces those. \n\n2. The implementation of the concept using a second order method is sensible and simple.  \n\nWeaknesses: \n1. Missing comparisons: As reiterated above, several existing works have augmented training of neural networks with terms that are based on directions of gradients of multiple objectives. Some of them, e.g. Sener and Koltun 2018 or Du et al 2018, are very related. Though the submission cites them, no experimental comparison or convincing verbal critique of the differences are provided. The experiments could have included baselines that correspond to the concepts proposed in those prior papers to support the novelty of this submission. If the authors believe the concept of those papers are basically the same as theirs, then this submission should change to an analysis paper rather than appearing to pitch a new regularization term. I would have found an analysis paper as valuable as one with a novel method, but the stance should be clear. \n\n2. I found the experiments too toy to be convincing. The MultiDigitMNIST is artificial and with limited benchmarking value as its construct doesn't really reflect the construct of multi task learning in the real world (e.g. as in the multi task vision datasets). NYUv2 dataset is more realistic, but the reported results are not clear to show significant and meaningful differences (see table 2). Particularly since the NYUv2 dataset has certain biases with imperfect ground truth from the kinect sensor which questions if differences in 0.001 range are meaningful. The authors can consider more recent and comparatively more reliable multi label datasets like Taskonomy for benchmarking. \n\n3. Inline with the above comment, qualitative results or any other method for convincing that the achieved results (on datasets other than MultiDigitMNIST) is meaningful seems crucial. \n\nFurther comments: \n4. The single task baselines in table 2 often perform inferior to the multi task baselines. This suggests the NYUv2 dataset could be too small to learn individual networks, whereas many other multi task papers often find single task baselines are hard to beat if they're not starved of parameters (e.g. see Standley 2018 \"Which Tasks Should Be Learned Together in Multi-task Learning?\"). Please clarify and/or consider using large enough datasets that allow you to benchmark under both high data and low data regimes. \n\n5. why there is no single task baseline in table 1? \n\n6. why CosReg is not included in figure 3 plot? \n\n7. A closer look at the recent works on analyzing task competitions in multi task learning could be useful, and probably supportive of the concept of this submission. For instance standley 2018 Which Tasks Should Be Learned Together in Multi-task Learning seem to suggest that tasks that are related under transfer learning setting did not help each other in multi task setting. Their observation seems related to the pitch of this paper that orthogonal gradients (ie tasks with dissimilar updates) can be optimized better. \n\n8. In page 4 authors state that computing the regularization term for all layers is complex, hence they do that only for the last layer. This seems okay to me, though I would have found an experiment demonstrating the consequences of this simplification useful (e.g. am experiment showing which layer to pick and a one-time expensive experiment demonstrating that picking one layer vs more layers is not too damaging). \n\n-------\nComments after rebuttal: \nI read the rebuttal and appreciate authors responses and the attempted improvement. It helped. I think the submission has the potential to be ultimately a useful read for the community, but at this stage more work/revision that wouldn't fit rebuttal time constraints would be needed to achieve that. I still think an experimental comparison with the related methods would be more convincing than verbal. \n\nThe added experiment on SUN RGB-D dataset is appreciated, but all results appear too close (table 2) to suggest one should adopt the proposed method. Also SUN RGB-D limits the tasks that could be learned together in a multi-task experiment given the limited number of labels per datapoint. I would have found using more recent  datasets with higher number of labels (rather than forcing to use depth+semantics which doesn't have to be a good mix, see Standley 2018) and more significant quantitate improvements more convincing. \n\nOverall I lean toward not accepting the current submission but acknowledge the potential value in resubmission after further work. \n", "review_assessment:_checking_correctness_of_derivations_and_theory": "I carefully checked the derivations and theory."}, "signatures": ["ICLR.cc/2020/Conference/Paper887/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper887/AnonReviewer3"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Regularizing Deep Multi-Task Networks using Orthogonal Gradients", "authors": ["Mihai Suteu", "Yi-ke Guo"], "authorids": ["m.suteu16@imperial.ac.uk", "y.guo@imperial.ac.uk"], "keywords": ["multi-task learning", "gradient regularization", "orthogonal gradients"], "TL;DR": "We propose a novel gradient regularization term that minimizes task interference by enforcing near orthogonal gradients.", "abstract": "Deep neural networks are a promising approach towards multi-task learning because of their capability to leverage knowledge across domains and learn general purpose representations. Nevertheless, they can fail to live up to these promises as tasks often compete for a model's limited resources, potentially leading to lower overall performance. In this work we tackle the issue of interfering tasks through a comprehensive analysis of their training, derived from looking at the interaction between gradients within their shared parameters. Our empirical results show that well-performing models have low variance in the angles between task gradients and that popular regularization methods implicitly reduce this measure. Based on this observation, we propose a novel gradient regularization term that minimizes task interference by enforcing near orthogonal gradients. Updating the shared parameters using this property encourages task specific decoders to optimize different parts of the feature extractor, thus reducing competition. We evaluate our method with classification and regression tasks on the multiDigitMNIST and NYUv2 dataset where we obtain competitive results. This work is a first step towards non-interfering multi-task optimization.", "pdf": "/pdf/b778a4fac18e1c67194f2fd57e9390a5908cf8ef.pdf", "paperhash": "suteu|regularizing_deep_multitask_networks_using_orthogonal_gradients", "original_pdf": "/attachment/a7b9fb372b5d2258d0f3e6b513775ccd09afe5f4.pdf", "_bibtex": "@misc{\nsuteu2020regularizing,\ntitle={Regularizing Deep Multi-Task Networks using Orthogonal Gradients},\nauthor={Mihai Suteu and Yi-ke Guo},\nyear={2020},\nurl={https://openreview.net/forum?id=SJeXJANFPr}\n}"}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "SJeXJANFPr", "replyto": "SJeXJANFPr", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper887/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper887/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1575738346338, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper887/Reviewers"], "noninvitees": [], "tcdate": 1570237745540, "tmdate": 1575738346351, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper887/-/Official_Review"}}}, {"id": "rkgCFiIAKS", "original": null, "number": 2, "cdate": 1571871621887, "ddate": null, "tcdate": 1571871621887, "tmdate": 1574399374995, "tddate": null, "forum": "SJeXJANFPr", "replyto": "SJeXJANFPr", "invitation": "ICLR.cc/2020/Conference/Paper887/-/Official_Review", "content": {"experience_assessment": "I have published in this field for several years.", "rating": "3: Weak Reject", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "title": "Official Blind Review #1", "review": "This paper embraces the idea that better multi-task/lifelong learning can be achieved if tasks produce gradients that are orthogonal to the gradients produced by other tasks. The authors propose an approach to regularizing learning in order to incentivize this to happen. However, as they mention themselves, the regularized loss is computationally intractable in general and they only apply it to a subset of their network as a result. Given the computational scalability concerns, it is natural to wonder why researchers in the community would adopt this approach rather than other approaches that also aim to make gradients orthogonal. \n\nThe idea of producing orthogonal gradients across tasks or examples is not new in the context of lifelong/multi-task learning. In fact, just to name a few, [1] demonstrated that noise alone can lead to orthogonal gradients, [2] demonstrated that modular neural network architectures can lead to orthogonal gradients and less interference. Additionally, sparsity naturally leads to orthogonal gradients as does the recent approach in [3].  These approaches achieve orthogonal gradients without adding a significant computational burden to learning. This paper can be greatly improved by discussing past approaches to producing orthogonal gradients and why they are theoretically / empirically worse than CosReg. \n\n[1] \"A theory for how sensorimotor skills are learned and retained in noisy and nonstationary neural circuits\". Robert Ajemian, Alessandro D\u2019Ausilio,  Helene Moorman, and  Emilio Bizzi. PNAS'13. \n\n[2] \"Routing Networks: Adaptive Selection of Non-linear Functions for Multi-Task Learning\". Clemens Rosenbaum, Tim Klinger, and Matthew Riemer. ICLR'18. \n\n[3] \"Meta-Learning Representations for Continual Learning\". Khurram Javed and Martha White. 2019. \n\nAdditionally, despite much past work, I tend to think that the entire quest for orthogonal gradients is not particularly well motivated as it is missing half of the story. Orthogonal gradients only address the problem of interference during learning, but don't help maximize transfer during learning. In fact, intuitively Figure 2 showcases that CosReg diminishes transfer during learning in comparison to baselines. Some recent work, such as [4] and [5], argues that what we really want is to maximize the dot product of gradients i.e. their alignment. This perspective achieves the best of both worlds as it incentivizes orthogonality to address interference while also incentivizing positive transfer. I wonder how the authors would position their work relative to the body of work that optimizes for the gradient dot product. Why would we like gradients to be orthogonal if there would otherwise be transfer? Why focus on the cosine rather than the dot product, which naturally comes out of the first order Taylor expansion derivation for each task? \n\n[4] \"On First-Order Meta-Learning Algorithms\". Alex Nichol, Joshua Achiam, John Schulman. 2018. \n\n[5] \"Learning to Learn without Forgetting by Maximizing Transfer and Minimizing Interference\". Matthew Riemer, Ignacio Cases, Robert Ajemian, Miao Liu, Irina Rish, Yuhai Tu, and Gerald Tesauro. ICLR'19. \n\nGiven my major concerns about the theoretical motivation and comparisons to past work, I do not find the experiments comprehensive enough to prove the value of the proposed approach to the community. At the very least, I would be interested in comparison with additional very relevant baselines and in experiments with more tasks.  \n\nUpdate After Author Feedback: \n\nWhile I really appreciate the authors providing some context about the references, I still feel like the paper would benefit from increased empirical comparison with these past approaches. Unfortunately, I don\u2019t really follow the point they are making about why it is better to produce orthogonality vs. high dot products.  I agree that catastrophic forgetting is more of a problem related to continual learning, but I am not sure why we wouldn't want to maximize transfer even if there was no forgetting or interference.   Given my continued concerns, I am inclined to keep my score the same. ", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory."}, "signatures": ["ICLR.cc/2020/Conference/Paper887/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper887/AnonReviewer1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Regularizing Deep Multi-Task Networks using Orthogonal Gradients", "authors": ["Mihai Suteu", "Yi-ke Guo"], "authorids": ["m.suteu16@imperial.ac.uk", "y.guo@imperial.ac.uk"], "keywords": ["multi-task learning", "gradient regularization", "orthogonal gradients"], "TL;DR": "We propose a novel gradient regularization term that minimizes task interference by enforcing near orthogonal gradients.", "abstract": "Deep neural networks are a promising approach towards multi-task learning because of their capability to leverage knowledge across domains and learn general purpose representations. Nevertheless, they can fail to live up to these promises as tasks often compete for a model's limited resources, potentially leading to lower overall performance. In this work we tackle the issue of interfering tasks through a comprehensive analysis of their training, derived from looking at the interaction between gradients within their shared parameters. Our empirical results show that well-performing models have low variance in the angles between task gradients and that popular regularization methods implicitly reduce this measure. Based on this observation, we propose a novel gradient regularization term that minimizes task interference by enforcing near orthogonal gradients. Updating the shared parameters using this property encourages task specific decoders to optimize different parts of the feature extractor, thus reducing competition. We evaluate our method with classification and regression tasks on the multiDigitMNIST and NYUv2 dataset where we obtain competitive results. This work is a first step towards non-interfering multi-task optimization.", "pdf": "/pdf/b778a4fac18e1c67194f2fd57e9390a5908cf8ef.pdf", "paperhash": "suteu|regularizing_deep_multitask_networks_using_orthogonal_gradients", "original_pdf": "/attachment/a7b9fb372b5d2258d0f3e6b513775ccd09afe5f4.pdf", "_bibtex": "@misc{\nsuteu2020regularizing,\ntitle={Regularizing Deep Multi-Task Networks using Orthogonal Gradients},\nauthor={Mihai Suteu and Yi-ke Guo},\nyear={2020},\nurl={https://openreview.net/forum?id=SJeXJANFPr}\n}"}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "SJeXJANFPr", "replyto": "SJeXJANFPr", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper887/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper887/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1575738346338, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper887/Reviewers"], "noninvitees": [], "tcdate": 1570237745540, "tmdate": 1575738346351, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper887/-/Official_Review"}}}, {"id": "Hkg0F-a2Kr", "original": null, "number": 1, "cdate": 1571766661980, "ddate": null, "tcdate": 1571766661980, "tmdate": 1573777493519, "tddate": null, "forum": "SJeXJANFPr", "replyto": "SJeXJANFPr", "invitation": "ICLR.cc/2020/Conference/Paper887/-/Official_Review", "content": {"experience_assessment": "I have published one or two papers in this area.", "rating": "3: Weak Reject", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "title": "Official Blind Review #2", "review": "Summary: In this paper, the author analyzed gradient regularization in deep multitask learning. They empirically discovered a sharper concentration (low variance) in angles between the task gradient distributions could potentially improve the performance in multi-task learning. Then they proposed a new gradient regularization to enforce the gradient for each task be orthogonal. Empirical results (on Multi-digits MNIST and NYUv2 data-sets) indicate a marginal improvement, comparing with baselines.\n\nMain Comments:\n\nThe discovering in the paper sounds interesting while the work looks like preliminary and unpolished. Particularly I have the following technical and conceptual concerns:\n1.  In high dimensional geometrical space, ** the random high dimensional vectors will be orthogonal with high probability**. The authors can find this conclusion in many places, for example: \n\nhttps://courses.cs.washington.edu/courses/cse521/16sp/521-lecture-6.pdf\n(Theorem 6.3)\nhttps://www.cs.princeton.edu/courses/archive/fall14/cos521/lecnotes/lec11.pdf\n(Corollary 2)\n\nI noticed the author claimed in the paper \u201cBased on empirical observations presented later on we argue that multi-task networks not only benefit when the cosine is non-negative but more so when task gradients are close to orthogonal.\u201d (Page 3).  However, this empirical claim is not convincing for me.  Since gradient of the over-parameterized neural network is in very high dimension, the task gradients closing to orthogonal may happen because of \n(a) the internal high-dimensional geometry property\n(b) or the phenomene caused by the deep multi-task learning \n\nIt will be much better and more clear if the author can provide more analytical, theoretical (e.g provable bound even on linear model) or empirical (e.g ablation study) support to understand the behaviors of gradient in high dimensional problem. \n\n2. In the proposed approach, I am not clear how the author choose the **task weights** (e.g in Eq.1) \u201cw_{t_i}\u201d ? It seems that the author set them as hyper-parameters. Since understanding the task relations and automatically estimating their relationships is the key factor for avoiding negative transfer in multitask learning (e.g Sener [2018]), I think it is not a proper way to simply adjust them as hyper-parameters.\n\n3. In the experimental part, the proposed approach showed almost no or very marginal improved performance. The author should provide more evidences to show the utility or potentials, in order to convince the community to adopt the proposed approach. \n\nMinor comments:\n1. From equation (4) to (5) is not obvious, it will be better to provide the derivation details.\n2. The analyzed problem sounds more like the \u201cmulti-output\u201d or \u201cmulti-label\u201d problem (Section 3 in the paper). In the multi-task learning generally the inputs for each task X are different.\n\nOverall, I feel it is an interesting and promising direction to consider gradient regularization based approach in multi-task learning. However, the current manuscript is not mature for the acceptance.\n\n\nReference:\nMulti-Task Learning as Multi-Objective Optimization.  Ozan Sener, Vladlen Koltun, NeurIPS, 2018\n----------------------------------------------------------------------------------------------------\n\nAfter rebuttal\n\nI thank the author for detailed rebuttal and efforts for making the paper better.\n\nI accept points  (1), (2) and (5) , then I update my score to weak reject -- 3.\n\nThe main reason that I still keep the decision toward rejection is the experimental part. \n\nSince it is an empirical paper, I suggest the author either systematically show more comparisons and more datasets. \nOr the author can develop some theoretical insights/bounds (e.g point (1)) for enhancing the contribution of the paper.\n\n\n\n", "review_assessment:_checking_correctness_of_derivations_and_theory": "N/A"}, "signatures": ["ICLR.cc/2020/Conference/Paper887/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper887/AnonReviewer2"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Regularizing Deep Multi-Task Networks using Orthogonal Gradients", "authors": ["Mihai Suteu", "Yi-ke Guo"], "authorids": ["m.suteu16@imperial.ac.uk", "y.guo@imperial.ac.uk"], "keywords": ["multi-task learning", "gradient regularization", "orthogonal gradients"], "TL;DR": "We propose a novel gradient regularization term that minimizes task interference by enforcing near orthogonal gradients.", "abstract": "Deep neural networks are a promising approach towards multi-task learning because of their capability to leverage knowledge across domains and learn general purpose representations. Nevertheless, they can fail to live up to these promises as tasks often compete for a model's limited resources, potentially leading to lower overall performance. In this work we tackle the issue of interfering tasks through a comprehensive analysis of their training, derived from looking at the interaction between gradients within their shared parameters. Our empirical results show that well-performing models have low variance in the angles between task gradients and that popular regularization methods implicitly reduce this measure. Based on this observation, we propose a novel gradient regularization term that minimizes task interference by enforcing near orthogonal gradients. Updating the shared parameters using this property encourages task specific decoders to optimize different parts of the feature extractor, thus reducing competition. We evaluate our method with classification and regression tasks on the multiDigitMNIST and NYUv2 dataset where we obtain competitive results. This work is a first step towards non-interfering multi-task optimization.", "pdf": "/pdf/b778a4fac18e1c67194f2fd57e9390a5908cf8ef.pdf", "paperhash": "suteu|regularizing_deep_multitask_networks_using_orthogonal_gradients", "original_pdf": "/attachment/a7b9fb372b5d2258d0f3e6b513775ccd09afe5f4.pdf", "_bibtex": "@misc{\nsuteu2020regularizing,\ntitle={Regularizing Deep Multi-Task Networks using Orthogonal Gradients},\nauthor={Mihai Suteu and Yi-ke Guo},\nyear={2020},\nurl={https://openreview.net/forum?id=SJeXJANFPr}\n}"}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "SJeXJANFPr", "replyto": "SJeXJANFPr", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper887/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper887/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1575738346338, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper887/Reviewers"], "noninvitees": [], "tcdate": 1570237745540, "tmdate": 1575738346351, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper887/-/Official_Review"}}}, {"id": "SklFdbSooB", "original": null, "number": 4, "cdate": 1573765488818, "ddate": null, "tcdate": 1573765488818, "tmdate": 1573765488818, "tddate": null, "forum": "SJeXJANFPr", "replyto": "Hkg0F-a2Kr", "invitation": "ICLR.cc/2020/Conference/Paper887/-/Official_Comment", "content": {"title": "Response", "comment": "We thank the reviewer for the feedback and the provided references.\n\n\n1. Orthogonal gradients in high dimensional spaces\nWe agree with the reviewer that due to the curse of dimensionality any pair of random vectors will be nearly orthogonal in high dimensional spaces. Nevertheless, we would like to point out that even though deep neural networks are heavily over-parametrized they also have highly correlated features, redundancies and dead neurons. In practice this often leads to representations and gradients that form sharp or obtuse angles. We have added an additional figure which shows the cosine distribution between gradients of related tasks. We use the SUN RGB-D dataset which contains two segmentation tasks, one coarse and another one that is fine grained. The tasks are very similar as pixels are often attributed to the same class in both tasks. We can observe that throughout training the two task gradients point in similar directions, even though we are talking about a space with over 2 million dimensions.\n\n2. Task weights as hyper-parameters\nWe realize that we didn't emphasize that our method does not require setting task weights. This is one aspect on how we differentiate ourselves from other MTL approaches, since our method is solely focused on regularizing gradient angles and does not seek to alter their magnitude. For all our experiments the task weights $w_t$ are set to 1 and we have updated our paper to explicitly state so.\n\n3. Performance\nWe have provided benchmarks on an additional dataset (SUN RGB-D), where we obtain improved results.\n\n4. Generalization of CosReg\nWe have updated our paper to include more details about the generalization of CosReg to T tasks in equation 5.\n\n5. Multi-task vs multi-output\nFrom the point of view of the used datasets our problem setting is indeed related to multi-output. This however does not contradict the multi-task paradigm, as each output belongs to a different task which has its own conditional distribution, objective function, complexity and evaluation metric. We do acknowledge the similarity, especially if multi-output is viewed as a subset of multi-task learning. We would also like to add that our method is not restricted to this setup and can potentially be used for tasks with different inputs."}, "signatures": ["ICLR.cc/2020/Conference/Paper887/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper887/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Regularizing Deep Multi-Task Networks using Orthogonal Gradients", "authors": ["Mihai Suteu", "Yi-ke Guo"], "authorids": ["m.suteu16@imperial.ac.uk", "y.guo@imperial.ac.uk"], "keywords": ["multi-task learning", "gradient regularization", "orthogonal gradients"], "TL;DR": "We propose a novel gradient regularization term that minimizes task interference by enforcing near orthogonal gradients.", "abstract": "Deep neural networks are a promising approach towards multi-task learning because of their capability to leverage knowledge across domains and learn general purpose representations. Nevertheless, they can fail to live up to these promises as tasks often compete for a model's limited resources, potentially leading to lower overall performance. In this work we tackle the issue of interfering tasks through a comprehensive analysis of their training, derived from looking at the interaction between gradients within their shared parameters. Our empirical results show that well-performing models have low variance in the angles between task gradients and that popular regularization methods implicitly reduce this measure. Based on this observation, we propose a novel gradient regularization term that minimizes task interference by enforcing near orthogonal gradients. Updating the shared parameters using this property encourages task specific decoders to optimize different parts of the feature extractor, thus reducing competition. We evaluate our method with classification and regression tasks on the multiDigitMNIST and NYUv2 dataset where we obtain competitive results. This work is a first step towards non-interfering multi-task optimization.", "pdf": "/pdf/b778a4fac18e1c67194f2fd57e9390a5908cf8ef.pdf", "paperhash": "suteu|regularizing_deep_multitask_networks_using_orthogonal_gradients", "original_pdf": "/attachment/a7b9fb372b5d2258d0f3e6b513775ccd09afe5f4.pdf", "_bibtex": "@misc{\nsuteu2020regularizing,\ntitle={Regularizing Deep Multi-Task Networks using Orthogonal Gradients},\nauthor={Mihai Suteu and Yi-ke Guo},\nyear={2020},\nurl={https://openreview.net/forum?id=SJeXJANFPr}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "SJeXJANFPr", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper887/Authors", "ICLR.cc/2020/Conference/Paper887/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper887/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper887/Reviewers", "ICLR.cc/2020/Conference/Paper887/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper887/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper887/Authors|ICLR.cc/2020/Conference/Paper887/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504164683, "tmdate": 1576860560430, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper887/Authors", "ICLR.cc/2020/Conference/Paper887/Reviewers", "ICLR.cc/2020/Conference/Paper887/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper887/-/Official_Comment"}}}, {"id": "BJeYyWSoiH", "original": null, "number": 3, "cdate": 1573765344565, "ddate": null, "tcdate": 1573765344565, "tmdate": 1573765344565, "tddate": null, "forum": "SJeXJANFPr", "replyto": "rkgCFiIAKS", "invitation": "ICLR.cc/2020/Conference/Paper887/-/Official_Comment", "content": {"title": "Response", "comment": "We thank the reviewer for the feedback and for pointing out related work we have missed.\n\n\n1. Cited papers related to orthogonal gradients.\n\n[1] focuses on the stability-plasticity dilemma in hyper-plastic noisy networks. The point they are making is that under conditions of large redundancy, extreme noise and high learning rates a multi-task network can still reach a dynamic equilibrium. They state that this is possible because at the point of convergence the solution will have orthogonal task gradients. As far as we can assess they don't make any reference to the orthogonality of task gradients during training. Furthermore, their theory is in line with our observations that in later stages of training the variance of the gradient distribution decreases as the cosine converges to 0. Our contribution however, lies in obtaining orthogonality throughout training which obtains competitive multi-task solutions.\n\n[2] propose a method for dynamically assigning parameters, or functional blocks, depending on the input and task. Their contribution is an architecture focused approach that is closely related to the soft parameter sharing paradigm. Our method on the other hand is a loss focused method suited exclusively for hard parameter sharing models. Consequently they achieve non interference by using different parameter partitions for different tasks, while we achieve this by regularizing gradients that affect the same set of parameters for all tasks. While both methods reduce task interference, the nature of the models they are designed for is entirely different.\n\n[3] devise a meta-learning algorithm that reduces task interference in a continual learning setting. Their method nudges learning of representations that are robust to interference, which turn out to be sparse. We agree that having sparse representations reduces task interference, and in a way it is related to our motivation behind CosReg - to force the optimizer to update parameters differently for each task during an iteration. Our method however doesn't directly induce sparsity constraints, which means it is less invasive on how the network should learn its representations. Future work can however investigate the learned representations.\n\nWith respect to computational tractability - the execution time increases with the number of layers used for the gradient computation. Preliminary results seem to suggest however that CosReg is most effective on the layers closer to the encoders, which incur only a limited computational overhead. We will further quantify the performance when using gradients of different sizes and at varying positions.\n\n2. Using the dot product as a penalty term.\nWe believe there is a distinction to be made between training interference/transfer and overall performance in a MTL setting. Transfer is indeed maximized when gradients are pointing in the same direction but it is unclear whether this would also lead to a better performing solution in a multi-task setting. Standley et al. seem to make such a finding when analyzing what tasks can be learned together and our recent results on the SUN RGB-D dataset agree. Furthermore, the cited papers are in the domain of continual learning for which the main problem is catastrophic forgetting. In that setup it makes sense to have gradients of new tasks align with those of previous tasks. In a multi-task setting however there is no risk of forgetting as data from all tasks are available at all times.\n\n\nRefs:\nWhich Tasks Should Be Learned Together in Multi-task Learning? Standley 2018"}, "signatures": ["ICLR.cc/2020/Conference/Paper887/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper887/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Regularizing Deep Multi-Task Networks using Orthogonal Gradients", "authors": ["Mihai Suteu", "Yi-ke Guo"], "authorids": ["m.suteu16@imperial.ac.uk", "y.guo@imperial.ac.uk"], "keywords": ["multi-task learning", "gradient regularization", "orthogonal gradients"], "TL;DR": "We propose a novel gradient regularization term that minimizes task interference by enforcing near orthogonal gradients.", "abstract": "Deep neural networks are a promising approach towards multi-task learning because of their capability to leverage knowledge across domains and learn general purpose representations. Nevertheless, they can fail to live up to these promises as tasks often compete for a model's limited resources, potentially leading to lower overall performance. In this work we tackle the issue of interfering tasks through a comprehensive analysis of their training, derived from looking at the interaction between gradients within their shared parameters. Our empirical results show that well-performing models have low variance in the angles between task gradients and that popular regularization methods implicitly reduce this measure. Based on this observation, we propose a novel gradient regularization term that minimizes task interference by enforcing near orthogonal gradients. Updating the shared parameters using this property encourages task specific decoders to optimize different parts of the feature extractor, thus reducing competition. We evaluate our method with classification and regression tasks on the multiDigitMNIST and NYUv2 dataset where we obtain competitive results. This work is a first step towards non-interfering multi-task optimization.", "pdf": "/pdf/b778a4fac18e1c67194f2fd57e9390a5908cf8ef.pdf", "paperhash": "suteu|regularizing_deep_multitask_networks_using_orthogonal_gradients", "original_pdf": "/attachment/a7b9fb372b5d2258d0f3e6b513775ccd09afe5f4.pdf", "_bibtex": "@misc{\nsuteu2020regularizing,\ntitle={Regularizing Deep Multi-Task Networks using Orthogonal Gradients},\nauthor={Mihai Suteu and Yi-ke Guo},\nyear={2020},\nurl={https://openreview.net/forum?id=SJeXJANFPr}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "SJeXJANFPr", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper887/Authors", "ICLR.cc/2020/Conference/Paper887/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper887/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper887/Reviewers", "ICLR.cc/2020/Conference/Paper887/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper887/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper887/Authors|ICLR.cc/2020/Conference/Paper887/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504164683, "tmdate": 1576860560430, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper887/Authors", "ICLR.cc/2020/Conference/Paper887/Reviewers", "ICLR.cc/2020/Conference/Paper887/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper887/-/Official_Comment"}}}, {"id": "ryxMElSjoB", "original": null, "number": 2, "cdate": 1573765161848, "ddate": null, "tcdate": 1573765161848, "tmdate": 1573765161848, "tddate": null, "forum": "SJeXJANFPr", "replyto": "rJgBsEQgqH", "invitation": "ICLR.cc/2020/Conference/Paper887/-/Official_Comment", "content": {"title": "Response", "comment": "We thank the reviewer for the detailed and constructive feedback, giving us a useful direction for improving our paper.\n\n\n1. Comparison with Sener et al.\nSener et al. also take a close look at the task gradients of the shared parameters but with the goal to then rescale these such that their convex combination will satisfy the necessary conditions to reach a Pareto optimal solution. In that sense they are closer aligned to Gradnorm and Kendall, who find task weights that ultimately resize the gradient magnitudes. Our method forces a different optimization trajectory by favoring specific locations on the loss surface which have orthogonal task gradients, without using task weights. From a point of view of the resulting gradient a similarity we share is that non-interference is assured at each update. For us this is done by having orthogonal task gradients, for Sener et al. it is achieved by using MGDA updates, which guarantee that the direction of the final gradient improves all tasks. We have added this differentiation to our paper, but unfortunately didn't have enough time to conduct benchmark experiments.\n\n2 & 3. Experiments on more/larger datasets\nWe have added experiments on the SUN RGB-D dataset, which is not as large as Taskonomy but still offers an order of magnitude more data than NYUv2. These new experiments allow us to test our method when there is a strong relatedness/transfer between tasks - fine and coarse semantic segmentation. We have also added a figure showing the cosine distribution during training and how our method successfully concentrates it around 0. This further strengthens our argument since we manage to outperform the benchmarks for which task gradients point in a similar direction.\n\n4 & 5. Low/High data regimes and single task benchmarks\nWe believe the inferior performance of the single task baselines is due to the complexity of the dataset relative to the amount of available data, as we have observed a similar pattern on the SUN RGB-D dataset. Regarding the missing single task baselines for the multiDigitMNIST dataset, we initially just wanted to emphasize the effect of regularization in a multi-task setting but agree that including these baselines shows the bigger picture. In this case the single task baselines outperform the multi-task approaches, which agrees with our hypothesis since the dataset offers a large amount of data compared to its difficulty.\n\n6. We have not included CosReg in figure 3 as we wanted to show the naturally occurring relationship between cosine standard deviation and final performance of different regularization methods. For CosReg there would be close to no variation in standard deviation since the method seeks to minimize it.\n\n7. Task relatedness and MTL performance\nWe agree and thank the reviewer for pointing this out. Our recent experiments with related segmentation tasks on the SUN RGB-D dataset seem enforce this view.\n\n8. CosReg ablation\nWe agree about the usefulness of such experiments, but unfortunately weren't able to complete a comprehensive set of experiments on time. Preliminary results seem to indicate that it is best to place CosReg on the layers closest to the encoders.\n\n"}, "signatures": ["ICLR.cc/2020/Conference/Paper887/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper887/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Regularizing Deep Multi-Task Networks using Orthogonal Gradients", "authors": ["Mihai Suteu", "Yi-ke Guo"], "authorids": ["m.suteu16@imperial.ac.uk", "y.guo@imperial.ac.uk"], "keywords": ["multi-task learning", "gradient regularization", "orthogonal gradients"], "TL;DR": "We propose a novel gradient regularization term that minimizes task interference by enforcing near orthogonal gradients.", "abstract": "Deep neural networks are a promising approach towards multi-task learning because of their capability to leverage knowledge across domains and learn general purpose representations. Nevertheless, they can fail to live up to these promises as tasks often compete for a model's limited resources, potentially leading to lower overall performance. In this work we tackle the issue of interfering tasks through a comprehensive analysis of their training, derived from looking at the interaction between gradients within their shared parameters. Our empirical results show that well-performing models have low variance in the angles between task gradients and that popular regularization methods implicitly reduce this measure. Based on this observation, we propose a novel gradient regularization term that minimizes task interference by enforcing near orthogonal gradients. Updating the shared parameters using this property encourages task specific decoders to optimize different parts of the feature extractor, thus reducing competition. We evaluate our method with classification and regression tasks on the multiDigitMNIST and NYUv2 dataset where we obtain competitive results. This work is a first step towards non-interfering multi-task optimization.", "pdf": "/pdf/b778a4fac18e1c67194f2fd57e9390a5908cf8ef.pdf", "paperhash": "suteu|regularizing_deep_multitask_networks_using_orthogonal_gradients", "original_pdf": "/attachment/a7b9fb372b5d2258d0f3e6b513775ccd09afe5f4.pdf", "_bibtex": "@misc{\nsuteu2020regularizing,\ntitle={Regularizing Deep Multi-Task Networks using Orthogonal Gradients},\nauthor={Mihai Suteu and Yi-ke Guo},\nyear={2020},\nurl={https://openreview.net/forum?id=SJeXJANFPr}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "SJeXJANFPr", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper887/Authors", "ICLR.cc/2020/Conference/Paper887/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper887/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper887/Reviewers", "ICLR.cc/2020/Conference/Paper887/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper887/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper887/Authors|ICLR.cc/2020/Conference/Paper887/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504164683, "tmdate": 1576860560430, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper887/Authors", "ICLR.cc/2020/Conference/Paper887/Reviewers", "ICLR.cc/2020/Conference/Paper887/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper887/-/Official_Comment"}}}], "count": 8}