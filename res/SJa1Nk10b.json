{"notes": [{"tddate": null, "ddate": null, "tmdate": 1518730188683, "tcdate": 1508991972780, "number": 111, "cdate": 1518730188672, "id": "SJa1Nk10b", "invitation": "ICLR.cc/2018/Conference/-/Blind_Submission", "forum": "SJa1Nk10b", "original": "HyhyEkyC-", "signatures": ["ICLR.cc/2018/Conference"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Conference"], "content": {"title": "Anytime Neural Network: a Versatile Trade-off Between Computation and Accuracy", "abstract": "We present an approach for anytime predictions in deep neural networks (DNNs). For each test sample, an anytime predictor produces a coarse result quickly, and then continues to refine it until the test-time computational budget is depleted. Such predictors can address the growing computational problem of DNNs by automatically adjusting to varying test-time budgets. In this work, we study a \\emph{general} augmentation to feed-forward networks to form anytime neural networks (ANNs) via auxiliary predictions and losses. Specifically, we point out a blind-spot in recent studies in such ANNs: the importance of high final accuracy. In fact, we show on multiple recognition data-sets and architectures that by having near-optimal final predictions in small anytime models, we can effectively double the speed of large ones to reach corresponding accuracy level. We achieve such speed-up with simple weighting of anytime losses that oscillate during training. We also assemble a sequence of exponentially deepening ANNs, to achieve both theoretically and practically near-optimal anytime results at any budget, at the cost of a constant fraction of additional consumed budget.", "pdf": "/pdf/011ca597b2f91c674b738341ac82d2b102c6ac29.pdf", "TL;DR": "By focusing more on the final predictions in anytime predictors (such as the very recent Multi-Scale-DenseNets), we make small anytime models to outperform large ones that don't have such focus. ", "paperhash": "hu|anytime_neural_network_a_versatile_tradeoff_between_computation_and_accuracy", "_bibtex": "@misc{\nhu2018anytime,\ntitle={Anytime Neural Network: a Versatile Trade-off Between Computation and Accuracy},\nauthor={Hanzhang Hu and Debadeepta Dey and Martial Hebert and J. Andrew Bagnell},\nyear={2018},\nurl={https://openreview.net/forum?id=SJa1Nk10b},\n}", "keywords": ["anytime", "neural network", "adaptive prediction", "budgeted prediction"], "authors": ["Hanzhang Hu", "Debadeepta Dey", "Martial Hebert", "J. Andrew Bagnell"], "authorids": ["hanzhang@cs.cmu.edu", "dedey@microsoft.com", "hebert@ri.cmu.edu", "dbagnell@ri.cmu.edu"]}, "nonreaders": [], "details": {"replyCount": 4, "writable": false, "overwriting": ["H1PRwFkDG"], "revisions": true, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "tmdate": 1506717071958, "id": "ICLR.cc/2018/Conference/-/Blind_Submission", "writers": ["ICLR.cc/2018/Conference"], "signatures": ["ICLR.cc/2018/Conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2018/Conference"], "reply": {"forum": null, "replyto": null, "writers": {"values": ["ICLR.cc/2018/Conference"]}, "signatures": {"description": "How your identity will be displayed with the above content.", "values": ["ICLR.cc/2018/Conference"]}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"authors": {"required": false, "order": 1, "values-regex": ".*", "description": "Comma separated list of author names, as they appear in the paper."}, "authorids": {"required": false, "order": 2, "values-regex": ".*", "description": "Comma separated list of author email addresses, in the same order as above."}}}, "nonreaders": [], "noninvitees": [], "cdate": 1506717071958}}, "tauthor": "ICLR.cc/2018/Conference"}, {"tddate": null, "ddate": null, "original": null, "tmdate": 1517260083613, "tcdate": 1517249944790, "number": 636, "cdate": 1517249944771, "id": "rJ-sH1Trf", "invitation": "ICLR.cc/2018/Conference/-/Acceptance_Decision", "forum": "SJa1Nk10b", "replyto": "SJa1Nk10b", "signatures": ["ICLR.cc/2018/Conference/Program_Chairs"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Conference/Program_Chairs"], "content": {"decision": "Reject", "title": "ICLR 2018 Conference Acceptance Decision", "comment": "The paper received mixed reviews with scores of 5 (R1), 5 (R2),  7 (R3).  All three reviewers raise concerns about the lack of comparisons to other methods. The rebuttal is not compelling on this point. There are quite a few methods that could be used for this application available (often with source code) and should be compared to, e.g. DenseNets (Huang et al.). Given that the proposed method isn't in of itself hugely novel, a thorough experimental evaluation is crucial to the justifying the approach. The AC has closely looked at the rebuttal and the paper and feels that it cannot be accepted for this reason at this time. "}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Anytime Neural Network: a Versatile Trade-off Between Computation and Accuracy", "abstract": "We present an approach for anytime predictions in deep neural networks (DNNs). For each test sample, an anytime predictor produces a coarse result quickly, and then continues to refine it until the test-time computational budget is depleted. Such predictors can address the growing computational problem of DNNs by automatically adjusting to varying test-time budgets. In this work, we study a \\emph{general} augmentation to feed-forward networks to form anytime neural networks (ANNs) via auxiliary predictions and losses. Specifically, we point out a blind-spot in recent studies in such ANNs: the importance of high final accuracy. In fact, we show on multiple recognition data-sets and architectures that by having near-optimal final predictions in small anytime models, we can effectively double the speed of large ones to reach corresponding accuracy level. We achieve such speed-up with simple weighting of anytime losses that oscillate during training. We also assemble a sequence of exponentially deepening ANNs, to achieve both theoretically and practically near-optimal anytime results at any budget, at the cost of a constant fraction of additional consumed budget.", "pdf": "/pdf/011ca597b2f91c674b738341ac82d2b102c6ac29.pdf", "TL;DR": "By focusing more on the final predictions in anytime predictors (such as the very recent Multi-Scale-DenseNets), we make small anytime models to outperform large ones that don't have such focus. ", "paperhash": "hu|anytime_neural_network_a_versatile_tradeoff_between_computation_and_accuracy", "_bibtex": "@misc{\nhu2018anytime,\ntitle={Anytime Neural Network: a Versatile Trade-off Between Computation and Accuracy},\nauthor={Hanzhang Hu and Debadeepta Dey and Martial Hebert and J. Andrew Bagnell},\nyear={2018},\nurl={https://openreview.net/forum?id=SJa1Nk10b},\n}", "keywords": ["anytime", "neural network", "adaptive prediction", "budgeted prediction"], "authors": ["Hanzhang Hu", "Debadeepta Dey", "Martial Hebert", "J. Andrew Bagnell"], "authorids": ["hanzhang@cs.cmu.edu", "dedey@microsoft.com", "hebert@ri.cmu.edu", "dbagnell@ri.cmu.edu"]}, "tags": [], "invitation": {"id": "ICLR.cc/2018/Conference/-/Acceptance_Decision", "rdate": null, "ddate": null, "expdate": 1541175629000, "duedate": null, "tmdate": 1541177635767, "tddate": null, "super": null, "final": null, "reply": {"forum": null, "replyto": null, "invitation": "ICLR.cc/2018/Conference/-/Blind_Submission", "writers": {"values": ["ICLR.cc/2018/Conference/Program_Chairs"]}, "signatures": {"description": "How your identity will be displayed with the above content.", "values": ["ICLR.cc/2018/Conference/Program_Chairs"]}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["ICLR.cc/2018/Conference/Program_Chairs", "everyone"]}, "content": {"title": {"required": true, "order": 1, "value": "ICLR 2018 Conference Acceptance Decision"}, "comment": {"required": false, "order": 3, "description": "(optional) Comment on this decision.", "value-regex": "[\\S\\s]{0,5000}"}, "decision": {"required": true, "order": 2, "value-dropdown": ["Accept (Oral)", "Accept (Poster)", "Reject", "Invite to Workshop Track"]}}}, "signatures": ["ICLR.cc/2018/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": [], "noninvitees": [], "writers": ["ICLR.cc/2018/Conference"], "multiReply": null, "taskCompletionCount": null, "transform": null, "cdate": 1541177635767}}}, {"tddate": null, "ddate": null, "original": null, "tmdate": 1515642385261, "tcdate": 1511782698094, "number": 1, "cdate": 1511782698094, "id": "HJMEt_FeM", "invitation": "ICLR.cc/2018/Conference/-/Paper111/Official_Review", "forum": "SJa1Nk10b", "replyto": "SJa1Nk10b", "signatures": ["ICLR.cc/2018/Conference/Paper111/AnonReviewer3"], "readers": ["everyone"], "content": {"title": "Anytime neural network", "rating": "7: Good paper, accept", "review": "This paper proposes an anytime neural network, which can predict anytime while training. To achieve that, the model includes auxiliary predictions which can make early predictions. Specifically, the paper presents a loss weighting scheme that considers high correlation among nearby predictions, an oscillating loss weighting scheme for further improvement, and an ensemble of anytime neural networks. In the experiments, test error of the proposed model was shown to be comparable to the optimal one at each time budget. \n\nIt is an interesting idea to add auxiliary predictions to enable early predictions and the experimental results look promising as they are close to optimal at each time budget. \n\n1. In Section 3.2, there are some discussions on the parallel computations of EANN. The parallel training is not clear to me and it would be great to have more explanation on this with examples.  \n\n2. It seems that EANN is not scalable because the depth is increasing exponentially. For example, given 10 machines, the model with the largest depth would have 2^10 layers, which is difficult to train. It would be great to discuss this issue.\n\n3. In the experiments, it would be great to add a few alternatives to be compared for anytime predictions. \n\n\n\n\n\n\n\n", "confidence": "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper"}, "writers": [], "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Anytime Neural Network: a Versatile Trade-off Between Computation and Accuracy", "abstract": "We present an approach for anytime predictions in deep neural networks (DNNs). For each test sample, an anytime predictor produces a coarse result quickly, and then continues to refine it until the test-time computational budget is depleted. Such predictors can address the growing computational problem of DNNs by automatically adjusting to varying test-time budgets. In this work, we study a \\emph{general} augmentation to feed-forward networks to form anytime neural networks (ANNs) via auxiliary predictions and losses. Specifically, we point out a blind-spot in recent studies in such ANNs: the importance of high final accuracy. In fact, we show on multiple recognition data-sets and architectures that by having near-optimal final predictions in small anytime models, we can effectively double the speed of large ones to reach corresponding accuracy level. We achieve such speed-up with simple weighting of anytime losses that oscillate during training. We also assemble a sequence of exponentially deepening ANNs, to achieve both theoretically and practically near-optimal anytime results at any budget, at the cost of a constant fraction of additional consumed budget.", "pdf": "/pdf/011ca597b2f91c674b738341ac82d2b102c6ac29.pdf", "TL;DR": "By focusing more on the final predictions in anytime predictors (such as the very recent Multi-Scale-DenseNets), we make small anytime models to outperform large ones that don't have such focus. ", "paperhash": "hu|anytime_neural_network_a_versatile_tradeoff_between_computation_and_accuracy", "_bibtex": "@misc{\nhu2018anytime,\ntitle={Anytime Neural Network: a Versatile Trade-off Between Computation and Accuracy},\nauthor={Hanzhang Hu and Debadeepta Dey and Martial Hebert and J. Andrew Bagnell},\nyear={2018},\nurl={https://openreview.net/forum?id=SJa1Nk10b},\n}", "keywords": ["anytime", "neural network", "adaptive prediction", "budgeted prediction"], "authors": ["Hanzhang Hu", "Debadeepta Dey", "Martial Hebert", "J. Andrew Bagnell"], "authorids": ["hanzhang@cs.cmu.edu", "dedey@microsoft.com", "hebert@ri.cmu.edu", "dbagnell@ri.cmu.edu"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1511845199000, "tmdate": 1515642385164, "id": "ICLR.cc/2018/Conference/-/Paper111/Official_Review", "writers": ["ICLR.cc/2018/Conference"], "signatures": ["ICLR.cc/2018/Conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2018/Conference/Paper111/Reviewers"], "noninvitees": ["ICLR.cc/2018/Conference/Paper111/AnonReviewer3", "ICLR.cc/2018/Conference/Paper111/AnonReviewer1", "ICLR.cc/2018/Conference/Paper111/AnonReviewer2"], "reply": {"forum": "SJa1Nk10b", "replyto": "SJa1Nk10b", "writers": {"values": []}, "signatures": {"values-regex": "ICLR.cc/2018/Conference/Paper111/AnonReviewer[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"required": true, "order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"required": true, "order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "value-regex": "[\\S\\s]{1,200000}"}, "rating": {"required": true, "order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"required": true, "order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1519621199000, "cdate": 1515642385164}}}, {"tddate": null, "ddate": null, "original": null, "tmdate": 1515642385223, "tcdate": 1511904199879, "number": 2, "cdate": 1511904199879, "id": "rJeC7UixM", "invitation": "ICLR.cc/2018/Conference/-/Paper111/Official_Review", "forum": "SJa1Nk10b", "replyto": "SJa1Nk10b", "signatures": ["ICLR.cc/2018/Conference/Paper111/AnonReviewer1"], "readers": ["everyone"], "content": {"title": "Similar to Prior Cascade Work, Unclear Weighing Schemes, and Lack of Experimental Comparison", "rating": "5: Marginally below acceptance threshold", "review": "1. Paper Summary\n\nThis paper adds a separate network at every layer of a residual network that performs classification. They minimize the loss of every classifier using two proposed weighting schemes. They also ensemble this model.\n\n\n2. High level paper\n\nThe organization of this paper is a bit confusing. Two weighing schemes are introduced in Section 3.1, then the ensemble model is described in Section 3.2, then the weighing schemes are justified in Section 4.1.\nOverall this method is essentially an cascade where each cascade classifier is a residual block. Every input is passed through as many stages as possible until the budget is reached. While this model is likely quite useful in industrial settings, I don't think the model itself is wholly original.\nThe authors have done extensive experiments evaluating their method in different settings. I would have liked to see a comparison with at least one other anytime method. I think it is slightly unfair to say that you are comparing with Xie & Tu, 2015 and Huang et al., 2017 just because they use the CONSTANT weighing schemes.\n\n\n3. High level technical\n\nI have a few concerns:\n- Why does AANN+LINEAR nearly match the accuracy of EANN+SIEVE near 3e9 FLOPS in Figure 4b but EANN+LINEAR does not in Figure 4a? Shouldn't EANN+LINEAR be strictly better than AANN+LINEAR?\n- Why do the authors choose these specific weighing schemes? Section 4.1 is devoted to explaining this but it is still unclear to me. They talk about there being correlation between the predictors near the end of the model so they don't want to distribute weight near the final predictors but this general observation doesn't obviously lead to these weighing schemes, they still seem a bit adhoc.\n\nA few other comments:\n- Figure 3b seems to contain strictly less information than Figure 4a, I would remove Figure 3b and draw lines showing the speedup you get for one or two accuracy levels.\n\nQuestions:\n- Section 3.1: \"Such an ideal \u03b8* does not exist in general and often does not exist in practice.\" Why is this the case? \n- Section 3.1: \" In particular, spreading weights evenly as in (Lee et al., 2015) keeps all i away from their possible respective minimum\" Why is this true?\n- Section 3.1: \"Since we will evaluate near depth b3L/4e, and it\nis the center of L/2 low-weight layers, we increase it weight by 1/8.\" I am completely lost here, why do you do this?\n\n\n4. Review summary\n\nUltimately because the model itself resembles previous cascade models, the selected weighings have little justification, and there isn't a comparison with another anytime method, I think this paper isn't yet ready for acceptance at ICLR.", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "writers": [], "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Anytime Neural Network: a Versatile Trade-off Between Computation and Accuracy", "abstract": "We present an approach for anytime predictions in deep neural networks (DNNs). For each test sample, an anytime predictor produces a coarse result quickly, and then continues to refine it until the test-time computational budget is depleted. Such predictors can address the growing computational problem of DNNs by automatically adjusting to varying test-time budgets. In this work, we study a \\emph{general} augmentation to feed-forward networks to form anytime neural networks (ANNs) via auxiliary predictions and losses. Specifically, we point out a blind-spot in recent studies in such ANNs: the importance of high final accuracy. In fact, we show on multiple recognition data-sets and architectures that by having near-optimal final predictions in small anytime models, we can effectively double the speed of large ones to reach corresponding accuracy level. We achieve such speed-up with simple weighting of anytime losses that oscillate during training. We also assemble a sequence of exponentially deepening ANNs, to achieve both theoretically and practically near-optimal anytime results at any budget, at the cost of a constant fraction of additional consumed budget.", "pdf": "/pdf/011ca597b2f91c674b738341ac82d2b102c6ac29.pdf", "TL;DR": "By focusing more on the final predictions in anytime predictors (such as the very recent Multi-Scale-DenseNets), we make small anytime models to outperform large ones that don't have such focus. ", "paperhash": "hu|anytime_neural_network_a_versatile_tradeoff_between_computation_and_accuracy", "_bibtex": "@misc{\nhu2018anytime,\ntitle={Anytime Neural Network: a Versatile Trade-off Between Computation and Accuracy},\nauthor={Hanzhang Hu and Debadeepta Dey and Martial Hebert and J. Andrew Bagnell},\nyear={2018},\nurl={https://openreview.net/forum?id=SJa1Nk10b},\n}", "keywords": ["anytime", "neural network", "adaptive prediction", "budgeted prediction"], "authors": ["Hanzhang Hu", "Debadeepta Dey", "Martial Hebert", "J. Andrew Bagnell"], "authorids": ["hanzhang@cs.cmu.edu", "dedey@microsoft.com", "hebert@ri.cmu.edu", "dbagnell@ri.cmu.edu"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1511845199000, "tmdate": 1515642385164, "id": "ICLR.cc/2018/Conference/-/Paper111/Official_Review", "writers": ["ICLR.cc/2018/Conference"], "signatures": ["ICLR.cc/2018/Conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2018/Conference/Paper111/Reviewers"], "noninvitees": ["ICLR.cc/2018/Conference/Paper111/AnonReviewer3", "ICLR.cc/2018/Conference/Paper111/AnonReviewer1", "ICLR.cc/2018/Conference/Paper111/AnonReviewer2"], "reply": {"forum": "SJa1Nk10b", "replyto": "SJa1Nk10b", "writers": {"values": []}, "signatures": {"values-regex": "ICLR.cc/2018/Conference/Paper111/AnonReviewer[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"required": true, "order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"required": true, "order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "value-regex": "[\\S\\s]{1,200000}"}, "rating": {"required": true, "order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"required": true, "order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1519621199000, "cdate": 1515642385164}}}, {"tddate": null, "ddate": null, "original": null, "tmdate": 1515642385182, "tcdate": 1513756137346, "number": 3, "cdate": 1513756137346, "id": "ry-xL5Dfz", "invitation": "ICLR.cc/2018/Conference/-/Paper111/Official_Review", "forum": "SJa1Nk10b", "replyto": "SJa1Nk10b", "signatures": ["ICLR.cc/2018/Conference/Paper111/AnonReviewer2"], "readers": ["everyone"], "content": {"title": "well written paper but lack of justification and comparison", "rating": "5: Marginally below acceptance threshold", "review": "This paper aims to endow neural networks the ability to produce anytime prediction. The authors propose several heuristics to reweight and oscillate the loss to improve the anytime performance. In addition, they propose to use a sequence of exponentially deepening anytime neural networks to reduce the performance gap for early classifiers. The proposed approaches are validated on two image classification datasets.\nPros:\n- The paper is well written and easy to follow. \n- It addresses an interesting problem with reasonable approaches. \nCons:\n- The loss reweighting and oscillating schemes appear to be just heuristics. It is not clear what the scientific contributions are.  \n- I do not fully agree with the explanation given for the \u201calternating weights\u201d. If the joint loss leads to zero gradient for some weights, then why would you consider it problematic?\n- There are few baselines compared in the result section. In addition, the proposed method underperforms the MSDNet (Huang et al., 2017) on ILSVRC2012.\n- The EANN is similar to the method used by Adaptive Networks (Bolukbasi et al., 2017), and the baseline \u201cEnsemble of ResNets (varying depth)\u201d in the MSDNet paper. \n-  Could you show the error bar In Figure 2(a)? Usually an error difference less than 0.5% on CIFAR-100 is not considered as significant. \n- I\u2019m not convinced that AANN really works significantly better than ANN according to the results in Table 1(a). It seems that ANN still outperform AANN in many cases.\n- I would suggest to show the results in Table 1(b) with a figure.", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "writers": [], "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Anytime Neural Network: a Versatile Trade-off Between Computation and Accuracy", "abstract": "We present an approach for anytime predictions in deep neural networks (DNNs). For each test sample, an anytime predictor produces a coarse result quickly, and then continues to refine it until the test-time computational budget is depleted. Such predictors can address the growing computational problem of DNNs by automatically adjusting to varying test-time budgets. In this work, we study a \\emph{general} augmentation to feed-forward networks to form anytime neural networks (ANNs) via auxiliary predictions and losses. Specifically, we point out a blind-spot in recent studies in such ANNs: the importance of high final accuracy. In fact, we show on multiple recognition data-sets and architectures that by having near-optimal final predictions in small anytime models, we can effectively double the speed of large ones to reach corresponding accuracy level. We achieve such speed-up with simple weighting of anytime losses that oscillate during training. We also assemble a sequence of exponentially deepening ANNs, to achieve both theoretically and practically near-optimal anytime results at any budget, at the cost of a constant fraction of additional consumed budget.", "pdf": "/pdf/011ca597b2f91c674b738341ac82d2b102c6ac29.pdf", "TL;DR": "By focusing more on the final predictions in anytime predictors (such as the very recent Multi-Scale-DenseNets), we make small anytime models to outperform large ones that don't have such focus. ", "paperhash": "hu|anytime_neural_network_a_versatile_tradeoff_between_computation_and_accuracy", "_bibtex": "@misc{\nhu2018anytime,\ntitle={Anytime Neural Network: a Versatile Trade-off Between Computation and Accuracy},\nauthor={Hanzhang Hu and Debadeepta Dey and Martial Hebert and J. Andrew Bagnell},\nyear={2018},\nurl={https://openreview.net/forum?id=SJa1Nk10b},\n}", "keywords": ["anytime", "neural network", "adaptive prediction", "budgeted prediction"], "authors": ["Hanzhang Hu", "Debadeepta Dey", "Martial Hebert", "J. Andrew Bagnell"], "authorids": ["hanzhang@cs.cmu.edu", "dedey@microsoft.com", "hebert@ri.cmu.edu", "dbagnell@ri.cmu.edu"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1511845199000, "tmdate": 1515642385164, "id": "ICLR.cc/2018/Conference/-/Paper111/Official_Review", "writers": ["ICLR.cc/2018/Conference"], "signatures": ["ICLR.cc/2018/Conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2018/Conference/Paper111/Reviewers"], "noninvitees": ["ICLR.cc/2018/Conference/Paper111/AnonReviewer3", "ICLR.cc/2018/Conference/Paper111/AnonReviewer1", "ICLR.cc/2018/Conference/Paper111/AnonReviewer2"], "reply": {"forum": "SJa1Nk10b", "replyto": "SJa1Nk10b", "writers": {"values": []}, "signatures": {"values-regex": "ICLR.cc/2018/Conference/Paper111/AnonReviewer[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"required": true, "order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"required": true, "order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "value-regex": "[\\S\\s]{1,200000}"}, "rating": {"required": true, "order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"required": true, "order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1519621199000, "cdate": 1515642385164}}}], "count": 5}