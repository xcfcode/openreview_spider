{"notes": [{"ddate": null, "legacy_migration": true, "tmdate": 1363644660000, "tcdate": 1363644660000, "number": 1, "id": "JqnQqLEIc6q5e", "invitation": "ICLR.cc/2013/-/submission/reply", "forum": "TT0bFo9VZpFWg", "replyto": "wjvpl_b23glfA", "signatures": ["Yann Dauphin"], "readers": ["everyone"], "writers": ["anonymous"], "content": {"title": "", "reply": "Thanks for your suggestion. We didn't plot the cross-entropy it is harder to interpret, but it might be interesting in comparison with the training error curve."}, "nonreaders": [], "details": {"replyCount": 0, "overwriting": [], "revisions": false, "forumContent": {"title": "Big Neural Networks Waste Capacity", "decision": "conferenceOral-iclr2013-workshop", "abstract": "This article exposes the failure of some big neural networks to leverage added capacity to reduce underfitting. Past research suggest diminishing returns when increasing the size of neural networks. Our experiments on ImageNet LSVRC-2010 show that this may be due to the fact that bigger networks underfit the training objective, sometimes performing worse on the training set than smaller networks. This suggests that the optimization method - first order gradient descent - fails at this regime. Directly attacking this problem, either through the optimization method or the choices of parametrization, may allow to improve the generalization error on large datasets, for which a large capacity is required.", "pdf": "https://arxiv.org/abs/1301.3583", "paperhash": "dauphin|big_neural_networks_waste_capacity", "keywords": [], "conflicts": [], "authors": ["Yann Dauphin", "Yoshua Bengio"], "authorids": ["dauphiya@iro.umontreal.ca", "yoshua.bengio@gmail.com"]}, "tags": [], "invitation": {}}}, {"ddate": null, "legacy_migration": true, "tmdate": 1363381980000, "tcdate": 1363381980000, "number": 1, "id": "wjvpl_b23glfA", "invitation": "ICLR.cc/2013/-/submission/reply", "forum": "TT0bFo9VZpFWg", "replyto": "IyZiWpNTixIVv", "signatures": ["Marc Shivers"], "readers": ["everyone"], "writers": ["anonymous"], "content": {"title": "", "reply": "Have you looked at the decrease in the cross-entropy optimization objective, rather than training error, as a function of number of hidden units?  It would be interesting to see a version of Figure 2 that compared the decrease in cross-entropy as you add hidden units with the decrease you would get if your additional hidden units memorized the previously most costly mislabellings."}, "nonreaders": [], "details": {"replyCount": 0, "overwriting": [], "revisions": false, "forumContent": {"title": "Big Neural Networks Waste Capacity", "decision": "conferenceOral-iclr2013-workshop", "abstract": "This article exposes the failure of some big neural networks to leverage added capacity to reduce underfitting. Past research suggest diminishing returns when increasing the size of neural networks. Our experiments on ImageNet LSVRC-2010 show that this may be due to the fact that bigger networks underfit the training objective, sometimes performing worse on the training set than smaller networks. This suggests that the optimization method - first order gradient descent - fails at this regime. Directly attacking this problem, either through the optimization method or the choices of parametrization, may allow to improve the generalization error on large datasets, for which a large capacity is required.", "pdf": "https://arxiv.org/abs/1301.3583", "paperhash": "dauphin|big_neural_networks_waste_capacity", "keywords": [], "conflicts": [], "authors": ["Yann Dauphin", "Yoshua Bengio"], "authorids": ["dauphiya@iro.umontreal.ca", "yoshua.bengio@gmail.com"]}, "tags": [], "invitation": {}}}, {"ddate": null, "legacy_migration": true, "tmdate": 1363311720000, "tcdate": 1363311720000, "number": 1, "id": "CqF6fhZ9QLCrY", "invitation": "ICLR.cc/2013/-/submission/reply", "forum": "TT0bFo9VZpFWg", "replyto": "PPZdA2YqSgAq6", "signatures": ["Yann Dauphin"], "readers": ["everyone"], "writers": ["anonymous"], "content": {"title": "", "reply": "Thanks to your comment, we have clarified our argument. The main point is not that the training error does not fall beyond a certain point, the main point is that there are *quickly diminishing returns for added number of hidden units* to the point where adding capacity is almost useless.  Since measuring VC-dimension is impractical (and not practically relevant here, because we really care about a notion of effective capacity taking into\r\naccount the limitation of the optimization algorithm), the notion of 'capacity' that we care about is basically measured by the number of training examples we are able to nail with a given network size and a given budget of training iterations.  So in terms of the paper, you have to look at Figure 2, not Figure 1. We have redone Figure 2 to clarify that after 5000 examples, each hidden unit brings less benefit than if it was hardcoded to handle one of the training errors. A fading ROI on the *training error* means that it's harder and harder to make use of the added hidden units, i.e., that the extra capacity brought in by each added hidden unit *decreases* as we consider larger nets. We hypothesize this low ROI on the training error is why people have observed low ROI on the *test* set. That is why we suggest it is worthwhile to investigate methods that will increase the ROI from larger models.\r\n\r\nWe are not saying that the optimization issue is necessarily due to local minima.  We say it could be local minima or ill-conditioning (the two main types of optimization difficulties one can imagine for neural nets).\r\n\r\nRegarding the results with infinite number of hidden units and convex training, there is no contradiction: with an infinite number of hidden units (or equivalently, one per training example), you only need to train the output weights, and that is convex. Here, the number of hidden units is still smaller than the number of training examples. The we believe that the optimization difficulty is with training the lower layers.\r\n\r\nThe learning rate is decreased by 5% each time the training error goes up after an epoch.\r\n\r\nWe are planning in a second phase of this work to experiment with a wider array of training techniques and architectures to compare their ROI curves, and momentum."}, "nonreaders": [], "details": {"replyCount": 0, "overwriting": [], "revisions": false, "forumContent": {"title": "Big Neural Networks Waste Capacity", "decision": "conferenceOral-iclr2013-workshop", "abstract": "This article exposes the failure of some big neural networks to leverage added capacity to reduce underfitting. Past research suggest diminishing returns when increasing the size of neural networks. Our experiments on ImageNet LSVRC-2010 show that this may be due to the fact that bigger networks underfit the training objective, sometimes performing worse on the training set than smaller networks. This suggests that the optimization method - first order gradient descent - fails at this regime. Directly attacking this problem, either through the optimization method or the choices of parametrization, may allow to improve the generalization error on large datasets, for which a large capacity is required.", "pdf": "https://arxiv.org/abs/1301.3583", "paperhash": "dauphin|big_neural_networks_waste_capacity", "keywords": [], "conflicts": [], "authors": ["Yann Dauphin", "Yoshua Bengio"], "authorids": ["dauphiya@iro.umontreal.ca", "yoshua.bengio@gmail.com"]}, "tags": [], "invitation": {}}}, {"ddate": null, "legacy_migration": true, "tmdate": 1363311660000, "tcdate": 1363311660000, "number": 1, "id": "IyZiWpNTixIVv", "invitation": "ICLR.cc/2013/-/submission/reply", "forum": "TT0bFo9VZpFWg", "replyto": "5w24FePB4ywro", "signatures": ["Yann Dauphin"], "readers": ["everyone"], "writers": ["anonymous"], "content": {"title": "", "reply": "Interesting point, the asymptote in Figure 1 could be explained by the optimization problem becoming more difficult. However, this does not conflict with our argument. We have clarified this in the paper. Our argument relies on Figure 2, which shows the return on investement for adding units. We see that the ROI quickly decreases, even when going from 2000 to 5000 units it decreases an order of magnitude. If the optimization problem did not get harder, we would have expected the ROI to be close to constant, but it seems the optimization becomes harder as more units are added. What's more, beyond 5000 units the ROI falls below the line of 1 error reduced per unit. If there was no optimization problem, the ROI should at least be 1 because the additional unit can be used as a template matcher for one of the training errors."}, "nonreaders": [], "details": {"replyCount": 0, "overwriting": [], "revisions": false, "forumContent": {"title": "Big Neural Networks Waste Capacity", "decision": "conferenceOral-iclr2013-workshop", "abstract": "This article exposes the failure of some big neural networks to leverage added capacity to reduce underfitting. Past research suggest diminishing returns when increasing the size of neural networks. Our experiments on ImageNet LSVRC-2010 show that this may be due to the fact that bigger networks underfit the training objective, sometimes performing worse on the training set than smaller networks. This suggests that the optimization method - first order gradient descent - fails at this regime. Directly attacking this problem, either through the optimization method or the choices of parametrization, may allow to improve the generalization error on large datasets, for which a large capacity is required.", "pdf": "https://arxiv.org/abs/1301.3583", "paperhash": "dauphin|big_neural_networks_waste_capacity", "keywords": [], "conflicts": [], "authors": ["Yann Dauphin", "Yoshua Bengio"], "authorids": ["dauphiya@iro.umontreal.ca", "yoshua.bengio@gmail.com"]}, "tags": [], "invitation": {}}}, {"ddate": null, "legacy_migration": true, "tmdate": 1363311600000, "tcdate": 1363311600000, "number": 1, "id": "URyDlbBNoEUIn", "invitation": "ICLR.cc/2013/-/submission/reply", "forum": "TT0bFo9VZpFWg", "replyto": "ChpzCSZ9zqCTR", "signatures": ["Yann Dauphin"], "readers": ["everyone"], "writers": ["anonymous"], "content": {"title": "", "reply": "The 3 assumptions can be thought of has 3 conditions that are necessary for the model to be able to fit ImageNet. In traditional experiments this would be true, however, in this case we are only monitoring *training* error. To learn the training set, only one assumption is necessary: no training image has an exact duplicate with a different label. In this case, the model can at least learn a KNN-like function that gives 0 error. \r\n\r\nAs for more experiments, we are planning experiments starting from the raw images."}, "nonreaders": [], "details": {"replyCount": 0, "overwriting": [], "revisions": false, "forumContent": {"title": "Big Neural Networks Waste Capacity", "decision": "conferenceOral-iclr2013-workshop", "abstract": "This article exposes the failure of some big neural networks to leverage added capacity to reduce underfitting. Past research suggest diminishing returns when increasing the size of neural networks. Our experiments on ImageNet LSVRC-2010 show that this may be due to the fact that bigger networks underfit the training objective, sometimes performing worse on the training set than smaller networks. This suggests that the optimization method - first order gradient descent - fails at this regime. Directly attacking this problem, either through the optimization method or the choices of parametrization, may allow to improve the generalization error on large datasets, for which a large capacity is required.", "pdf": "https://arxiv.org/abs/1301.3583", "paperhash": "dauphin|big_neural_networks_waste_capacity", "keywords": [], "conflicts": [], "authors": ["Yann Dauphin", "Yoshua Bengio"], "authorids": ["dauphiya@iro.umontreal.ca", "yoshua.bengio@gmail.com"]}, "tags": [], "invitation": {}}}, {"ddate": null, "legacy_migration": true, "tmdate": 1362402480000, "tcdate": 1362402480000, "number": 4, "id": "PPZdA2YqSgAq6", "invitation": "ICLR.cc/2013/-/submission/review", "forum": "TT0bFo9VZpFWg", "replyto": "TT0bFo9VZpFWg", "signatures": ["George Dahl"], "readers": ["everyone"], "writers": ["anonymous"], "content": {"title": "", "review": "The authors speculate that the inability of additional units to reduce\r\nthe training error beyond a certain point in their experiments might\r\nbe because 'networks with more capacity have more local minima.' How\r\ncan this claim about local minima be reconciled with theoretical\r\nasymptotic results that show that, for certain types of neural\r\nnetworks, in the limit of infinite hidden units, the training problem\r\nbecomes convex?\r\n\r\nAs far as I can tell from the description of the experiments, they\r\nused constant learning rates and no momentum. If getting the best\r\ntraining error is the goal, in my experience I have found it crucial\r\nto use momentum, especially if I am not shrinking the learning\r\nrate. The experimental results would be far more convincing to me if\r\nthey used momentum or at least tried changing the learning rate during\r\ntraining.\r\n\r\nThe learning curves in figure 3 show that larger nets reach a given\r\ntraining error with drastically fewer updates than smaller nets. In\r\nwhat sense is this an optimization failure? Without a more precise\r\nnotion of the capacity of a net and how it changes as hidden units are\r\nadded, the results are very hard to interpret. If, for some notion of\r\ncapacity, the increase in capacity from adding a hidden unit decreases\r\nas more hidden units are added, then we would also expect to see\r\nsimilar results, even without any optimization failure. How many\r\nhidden units are required to guarantee that there exists a setting of\r\nthe weights with zero training error? Why should we expect a net with\r\n15,000 units to be capable of getting arbitrarily low training error\r\non this dataset? If instead of sigmoid units the net used radial basis\r\nfunctions, then with a hidden unit for each of the 1.2 million\r\ntraining cases I would expect the net to be capable of zero\r\nerror. Since the data are not pure random noise images, surely fewer\r\nunits will be required for zero error, but how many approximately? \r\nWithout some evidence that there exists a setting of the weights that\r\nachieve lower error than actually obtained, we can't conclude that the\r\noptimization procedure has failed."}, "nonreaders": [], "details": {"replyCount": 0, "overwriting": [], "revisions": false, "forumContent": {"title": "Big Neural Networks Waste Capacity", "decision": "conferenceOral-iclr2013-workshop", "abstract": "This article exposes the failure of some big neural networks to leverage added capacity to reduce underfitting. Past research suggest diminishing returns when increasing the size of neural networks. Our experiments on ImageNet LSVRC-2010 show that this may be due to the fact that bigger networks underfit the training objective, sometimes performing worse on the training set than smaller networks. This suggests that the optimization method - first order gradient descent - fails at this regime. Directly attacking this problem, either through the optimization method or the choices of parametrization, may allow to improve the generalization error on large datasets, for which a large capacity is required.", "pdf": "https://arxiv.org/abs/1301.3583", "paperhash": "dauphin|big_neural_networks_waste_capacity", "keywords": [], "conflicts": [], "authors": ["Yann Dauphin", "Yoshua Bengio"], "authorids": ["dauphiya@iro.umontreal.ca", "yoshua.bengio@gmail.com"]}, "tags": [], "invitation": {}}}, {"ddate": null, "legacy_migration": true, "tmdate": 1362373200000, "tcdate": 1362373200000, "number": 1, "id": "5w24FePB4ywro", "invitation": "ICLR.cc/2013/-/submission/review", "forum": "TT0bFo9VZpFWg", "replyto": "TT0bFo9VZpFWg", "signatures": ["Andrew Maas"], "readers": ["everyone"], "writers": ["anonymous"], "content": {"title": "", "review": "Interesting topic. Another potential explanation for the diminishing return is the already good performance of networks with 5k hidden units. It could be that last bit of training performance requires fitting an especially difficult / nonlinear function and thus even 15k units in a single layer MLP can't do it. On such a large training set any reduction is likely statistically significant though, so it might help to zoom in on the plot or give error rates for the 5k and larger networks. Right now I think it's unclear whether the training error asymptotes because that's the best nearly any learning algorithm could do or because the single hidden layer is wasting capacity. More comparisons or analysis can help eliminate the alternate explanation."}, "nonreaders": [], "details": {"replyCount": 0, "overwriting": [], "revisions": false, "forumContent": {"title": "Big Neural Networks Waste Capacity", "decision": "conferenceOral-iclr2013-workshop", "abstract": "This article exposes the failure of some big neural networks to leverage added capacity to reduce underfitting. Past research suggest diminishing returns when increasing the size of neural networks. Our experiments on ImageNet LSVRC-2010 show that this may be due to the fact that bigger networks underfit the training objective, sometimes performing worse on the training set than smaller networks. This suggests that the optimization method - first order gradient descent - fails at this regime. Directly attacking this problem, either through the optimization method or the choices of parametrization, may allow to improve the generalization error on large datasets, for which a large capacity is required.", "pdf": "https://arxiv.org/abs/1301.3583", "paperhash": "dauphin|big_neural_networks_waste_capacity", "keywords": [], "conflicts": [], "authors": ["Yann Dauphin", "Yoshua Bengio"], "authorids": ["dauphiya@iro.umontreal.ca", "yoshua.bengio@gmail.com"]}, "tags": [], "invitation": {}}}, {"ddate": null, "legacy_migration": true, "tmdate": 1362019740000, "tcdate": 1362019740000, "number": 3, "id": "MvRrJo2NhwMOE", "invitation": "ICLR.cc/2013/-/submission/review", "forum": "TT0bFo9VZpFWg", "replyto": "TT0bFo9VZpFWg", "signatures": ["anonymous reviewer b2da"], "readers": ["everyone"], "writers": ["anonymous"], "content": {"title": "review of Big Neural Networks Waste Capacity", "review": "The net gets bigger, yet keeps underfitting the training set. Authors suspect that gradient descent is the culprit. An interesting study!"}, "nonreaders": [], "details": {"replyCount": 0, "overwriting": [], "revisions": false, "forumContent": {"title": "Big Neural Networks Waste Capacity", "decision": "conferenceOral-iclr2013-workshop", "abstract": "This article exposes the failure of some big neural networks to leverage added capacity to reduce underfitting. Past research suggest diminishing returns when increasing the size of neural networks. Our experiments on ImageNet LSVRC-2010 show that this may be due to the fact that bigger networks underfit the training objective, sometimes performing worse on the training set than smaller networks. This suggests that the optimization method - first order gradient descent - fails at this regime. Directly attacking this problem, either through the optimization method or the choices of parametrization, may allow to improve the generalization error on large datasets, for which a large capacity is required.", "pdf": "https://arxiv.org/abs/1301.3583", "paperhash": "dauphin|big_neural_networks_waste_capacity", "keywords": [], "conflicts": [], "authors": ["Yann Dauphin", "Yoshua Bengio"], "authorids": ["dauphiya@iro.umontreal.ca", "yoshua.bengio@gmail.com"]}, "tags": [], "invitation": {}}}, {"ddate": null, "legacy_migration": true, "tmdate": 1361967300000, "tcdate": 1361967300000, "number": 2, "id": "ChpzCSZ9zqCTR", "invitation": "ICLR.cc/2013/-/submission/review", "forum": "TT0bFo9VZpFWg", "replyto": "TT0bFo9VZpFWg", "signatures": ["anonymous reviewer 9741"], "readers": ["everyone"], "writers": ["anonymous"], "content": {"title": "review of Big Neural Networks Waste Capacity", "review": "This papers show the effects of under-fitting in a neural network as the size of a single neural network layer increases. The overall model is composed of SIFT extraction, k-mean, and this single hidden layer neural network. The paper suggest that this under-fitting problem is due to optimization problems with stochastic gradient descent.\r\n\r\nPros\r\nFor a certain configurations of network architecture the paper shows under-fitting remains as the number of hidden units increases.\r\n\r\nCons\r\nThis paper makes many big assumptions:\r\n1) that the training set of millions of images is labelled correctly.\r\n2) training on sift features followed by kmeans retains enough information from the images in the training set to allow for proper learning to proceed.\r\n3) a single hidden layer network is capable of completely fitting (or over-fitting) Imagenet.\r\n\r\nWhile the idea seems novel, it does appear to be a little rushed. Perhaps more experimentation with larger models and directly on the input image would reveal more."}, "nonreaders": [], "details": {"replyCount": 0, "overwriting": [], "revisions": false, "forumContent": {"title": "Big Neural Networks Waste Capacity", "decision": "conferenceOral-iclr2013-workshop", "abstract": "This article exposes the failure of some big neural networks to leverage added capacity to reduce underfitting. Past research suggest diminishing returns when increasing the size of neural networks. Our experiments on ImageNet LSVRC-2010 show that this may be due to the fact that bigger networks underfit the training objective, sometimes performing worse on the training set than smaller networks. This suggests that the optimization method - first order gradient descent - fails at this regime. Directly attacking this problem, either through the optimization method or the choices of parametrization, may allow to improve the generalization error on large datasets, for which a large capacity is required.", "pdf": "https://arxiv.org/abs/1301.3583", "paperhash": "dauphin|big_neural_networks_waste_capacity", "keywords": [], "conflicts": [], "authors": ["Yann Dauphin", "Yoshua Bengio"], "authorids": ["dauphiya@iro.umontreal.ca", "yoshua.bengio@gmail.com"]}, "tags": [], "invitation": {}}}, {"replyto": null, "ddate": null, "legacy_migration": true, "tmdate": 1358405100000, "tcdate": 1358405100000, "number": 46, "id": "TT0bFo9VZpFWg", "invitation": "ICLR.cc/2013/conference/-/submission", "forum": "TT0bFo9VZpFWg", "signatures": ["dauphiya@iro.umontreal.ca"], "readers": ["everyone"], "content": {"title": "Big Neural Networks Waste Capacity", "decision": "conferenceOral-iclr2013-workshop", "abstract": "This article exposes the failure of some big neural networks to leverage added capacity to reduce underfitting. Past research suggest diminishing returns when increasing the size of neural networks. Our experiments on ImageNet LSVRC-2010 show that this may be due to the fact that bigger networks underfit the training objective, sometimes performing worse on the training set than smaller networks. This suggests that the optimization method - first order gradient descent - fails at this regime. Directly attacking this problem, either through the optimization method or the choices of parametrization, may allow to improve the generalization error on large datasets, for which a large capacity is required.", "pdf": "https://arxiv.org/abs/1301.3583", "paperhash": "dauphin|big_neural_networks_waste_capacity", "keywords": [], "conflicts": [], "authors": ["Yann Dauphin", "Yoshua Bengio"], "authorids": ["dauphiya@iro.umontreal.ca", "yoshua.bengio@gmail.com"]}, "writers": [], "details": {"replyCount": 9, "writable": false, "overwriting": [], "revisions": false, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1369422751717, "tmdate": 1496673673639, "cdate": 1496673673639, "tcdate": 1496673673639, "id": "ICLR.cc/2013/conference/-/submission", "writers": ["ICLR.cc/2013"], "signatures": ["OpenReview.net"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": null, "replyto": null, "writers": {"values-regex": "~.*"}, "signatures": {"values-regex": "~.*", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"pdf": {"required": true, "order": 5, "description": "Either upload a PDF file or provide a direct link to your PDF on ArXiv (link must begin with http(s) and end with .pdf)", "value-regex": "upload|(http|https):\\/\\/.+\\.pdf"}, "title": {"required": true, "order": 1, "description": "Title of paper.", "value-regex": ".{1,250}"}, "abstract": {"required": true, "order": 4, "description": "Abstract of paper.", "value-regex": "[\\S\\s]{1,5000}"}, "authors": {"required": true, "order": 2, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of author names, as they appear in the paper."}, "conflicts": {"required": true, "order": 100, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of email domains of people who would have a conflict of interest in reviewing this paper, (e.g., cs.umass.edu;google.com, etc.)."}, "keywords": {"order": 6, "description": "Comma separated list of keywords.", "values-dropdown": []}, "authorids": {"required": true, "order": 3, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of author email addresses, in the same order as above."}}}, "nonreaders": [], "noninvitees": [], "expdate": 1377198751717}}}], "count": 10}