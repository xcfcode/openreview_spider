{"notes": [{"tddate": null, "replyto": null, "ddate": null, "tmdate": 1528124481688, "tcdate": 1518419656247, "number": 97, "cdate": 1518419656247, "id": "SJgAA3AUG", "invitation": "ICLR.cc/2018/Workshop/-/Submission", "forum": "SJgAA3AUG", "signatures": ["~Zhe_Li2"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Workshop"], "content": {"title": "Efficient Recurrent Neural Networks using Structured Matrices in FPGAs", "abstract": "Recurrent Neural Networks (RNNs) are becoming increasingly important for time series-related applications which require efficient and real-time implementations.The recent pruning based work \\textit{ESE}~\\citep{han2017ese} suffers from degradation of performance/energy efficiency due to the irregular network structure after pruning.\nWe propose block-circulant matrices for weight matrix representation in RNNs, thereby achieving simultaneous model compression and acceleration. We aim to implement RNNs in FPGA with highest performance and energy efficiency, with certain accuracy requirement (negligible accuracy degradation). Experimental results on actual FPGA deployments shows that the proposed framework achieves a maximum energy efficiency improvement of 35.7$\\times$ compared with ESE.", "paperhash": "li|efficient_recurrent_neural_networks_using_structured_matrices_in_fpgas", "keywords": ["Deep Learning", "Speech Recognition", "Model Compression", "Hardware Acceleration", "Circulant Matrix", "FPGA"], "_bibtex": "@misc{\n  li2018efficient,\n  title={Efficient Recurrent Neural Networks using Structured Matrices in FPGAs},\n  author={Zhe Li and Shuo Wang and Caiwen Ding and Qinru Qiu and Yanzhi Wang and Yun Liang},\n  year={2018},\n  url={https://openreview.net/forum?id=SJgAA3AUG}\n}", "authorids": ["zli89@syr.edu", "shvowang@pku.edu.cn", "cading@syr.edu", "qiqiu@syr.edu", "ywang393@syr.edu", "ericlyun@pku.edu.cn"], "authors": ["Zhe Li", "Shuo Wang", "Caiwen Ding", "Qinru Qiu", "Yanzhi Wang", "Yun Liang"], "TL;DR": "We propose block-circulant matrices for weight matrix representation in RNNs, thereby achieving simultaneous model compression and acceleration. ", "pdf": "/pdf/f633e094ffca5d1457167c6a76e426f83e2c213b.pdf"}, "nonreaders": [], "details": {"replyCount": 4, "writable": false, "overwriting": [], "revisions": false, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1518472800000, "tmdate": 1518474081690, "id": "ICLR.cc/2018/Workshop/-/Submission", "writers": ["ICLR.cc/2018/Workshop"], "signatures": ["ICLR.cc/2018/Workshop"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": null, "replyto": null, "writers": {"values": ["ICLR.cc/2018/Workshop"]}, "signatures": {"values-regex": "~.*|ICLR.cc/2018/Workshop", "description": "Your authorized identity to be associated with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"pdf": {"required": true, "order": 9, "value-regex": "upload", "description": "Upload a PDF file that ends with .pdf"}, "title": {"required": true, "order": 1, "description": "Title of paper.", "value-regex": ".{1,250}"}, "abstract": {"required": true, "order": 8, "description": "Abstract of paper.", "value-regex": "[\\S\\s]{1,5000}"}, "authors": {"required": true, "order": 2, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of author names. Please provide real names; identities will be anonymized."}, "keywords": {"order": 6, "values-regex": "(^$)|[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of keywords."}, "TL;DR": {"required": false, "order": 7, "description": "\"Too Long; Didn't Read\": a short sentence describing your paper", "value-regex": "[^\\n]{0,500}"}, "authorids": {"required": true, "order": 3, "values-regex": "([a-z0-9_\\-\\.]{2,}@[a-z0-9_\\-\\.]{2,}\\.[a-z]{2,},){0,}([a-z0-9_\\-\\.]{2,}@[a-z0-9_\\-\\.]{2,}\\.[a-z]{2,})", "description": "Comma separated list of author email addresses, lowercased, in the same order as above. For authors with existing OpenReview accounts, please make sure that the provided email address(es) match those listed in the author's profile. Please provide real emails; identities will be anonymized."}}}, "nonreaders": [], "noninvitees": [], "expdate": 1526248800000, "cdate": 1518474081690}}}, {"tddate": null, "ddate": null, "original": null, "tmdate": 1521582830833, "tcdate": 1520604920300, "number": 1, "cdate": 1520604920300, "id": "BJl-vMlKG", "invitation": "ICLR.cc/2018/Workshop/-/Paper97/Official_Review", "forum": "SJgAA3AUG", "replyto": "SJgAA3AUG", "signatures": ["ICLR.cc/2018/Workshop/Paper97/AnonReviewer1"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Workshop/Paper97/AnonReviewer1"], "content": {"title": "More details are needed", "rating": "7: Good paper, accept", "review": "This paper targets at compressing RNN models to reduce model size, computation cost and enhance model efficiency, without  too much performance drop. This paper proposes to utilize block circulant matrix to speed up the computation as BC matrix multiplication can be computed fast in FFT domain. \n\nThe idea is straightforward. It seems similar idea has been explored for compressing CNN models  (Ding et al., 2017). But this should be the first work applying BC matrix to compress RNN models. The performance is much better than ESE, in terms of both model computation efficiency and performance in speech applications. \n\nThe paper is written well. The only issue is it is not clear how BC matrix can be used to compress LSTM, considering LSTM has several different gates with complex interaction. I understand the space is limited but would appreciate if the authors would provide more implementation details for LSTM.", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Efficient Recurrent Neural Networks using Structured Matrices in FPGAs", "abstract": "Recurrent Neural Networks (RNNs) are becoming increasingly important for time series-related applications which require efficient and real-time implementations.The recent pruning based work \\textit{ESE}~\\citep{han2017ese} suffers from degradation of performance/energy efficiency due to the irregular network structure after pruning.\nWe propose block-circulant matrices for weight matrix representation in RNNs, thereby achieving simultaneous model compression and acceleration. We aim to implement RNNs in FPGA with highest performance and energy efficiency, with certain accuracy requirement (negligible accuracy degradation). Experimental results on actual FPGA deployments shows that the proposed framework achieves a maximum energy efficiency improvement of 35.7$\\times$ compared with ESE.", "paperhash": "li|efficient_recurrent_neural_networks_using_structured_matrices_in_fpgas", "keywords": ["Deep Learning", "Speech Recognition", "Model Compression", "Hardware Acceleration", "Circulant Matrix", "FPGA"], "_bibtex": "@misc{\n  li2018efficient,\n  title={Efficient Recurrent Neural Networks using Structured Matrices in FPGAs},\n  author={Zhe Li and Shuo Wang and Caiwen Ding and Qinru Qiu and Yanzhi Wang and Yun Liang},\n  year={2018},\n  url={https://openreview.net/forum?id=SJgAA3AUG}\n}", "authorids": ["zli89@syr.edu", "shvowang@pku.edu.cn", "cading@syr.edu", "qiqiu@syr.edu", "ywang393@syr.edu", "ericlyun@pku.edu.cn"], "authors": ["Zhe Li", "Shuo Wang", "Caiwen Ding", "Qinru Qiu", "Yanzhi Wang", "Yun Liang"], "TL;DR": "We propose block-circulant matrices for weight matrix representation in RNNs, thereby achieving simultaneous model compression and acceleration. ", "pdf": "/pdf/f633e094ffca5d1457167c6a76e426f83e2c213b.pdf"}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1520657999000, "tmdate": 1521582830641, "id": "ICLR.cc/2018/Workshop/-/Paper97/Official_Review", "writers": ["ICLR.cc/2018/Workshop"], "signatures": ["ICLR.cc/2018/Workshop"], "readers": ["everyone"], "invitees": ["ICLR.cc/2018/Workshop/Paper97/Reviewers"], "noninvitees": ["ICLR.cc/2018/Workshop/Paper97/AnonReviewer1", "ICLR.cc/2018/Workshop/Paper97/AnonReviewer3", "ICLR.cc/2018/Workshop/Paper97/AnonReviewer2"], "reply": {"forum": "SJgAA3AUG", "replyto": "SJgAA3AUG", "writers": {"values-regex": "ICLR.cc/2018/Workshop/Paper97/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2018/Workshop/Paper97/AnonReviewer[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"required": true, "order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"required": true, "order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "value-regex": "[\\S\\s]{1,200000}"}, "rating": {"required": true, "order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"required": true, "order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1528433999000, "cdate": 1521582830641}}}, {"tddate": null, "ddate": null, "original": null, "tmdate": 1521582741853, "tcdate": 1520660943375, "number": 2, "cdate": 1520660943375, "id": "SJwR-xWFz", "invitation": "ICLR.cc/2018/Workshop/-/Paper97/Official_Review", "forum": "SJgAA3AUG", "replyto": "SJgAA3AUG", "signatures": ["ICLR.cc/2018/Workshop/Paper97/AnonReviewer3"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Workshop/Paper97/AnonReviewer3"], "content": {"title": "interesting work, though results would be strengthened if reported on a larger task (e.g., Switchboard)", "rating": "6: Marginally above acceptance threshold", "review": "Overall, this is an interesting paper which discusses techniques to build compact and efficient RNN models.\nThe work presented is similar to work presented previously, and I think the authors should list the following paper and discuss similarity/differences with this work: (Sindhwani et al., 15) \nV. Sindhwani, T. Sainath, S. Kumar, \u201cStructured Transforms for Small-footprint Deep Learning,\u201d Neural Information Processing Systems (NIPS), 2015.\nIdeally, it would be interesting to compare results with the proposed techniques on a larger ASR task with more data than TIMIT, e.g., Switchboard. While the TIMIT results are certainly compelling, it would be more interesting to consider performance on a larger word recognition task. Another related question: What was the variance in performance across runs?\nMinor comment: Section 2: \u201cThe computational complexity is reduced from O(n^2)\u201d. Should this be O(mn)?\nMinor comment: ESE - Please explain what this acronym is in the text.\n", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Efficient Recurrent Neural Networks using Structured Matrices in FPGAs", "abstract": "Recurrent Neural Networks (RNNs) are becoming increasingly important for time series-related applications which require efficient and real-time implementations.The recent pruning based work \\textit{ESE}~\\citep{han2017ese} suffers from degradation of performance/energy efficiency due to the irregular network structure after pruning.\nWe propose block-circulant matrices for weight matrix representation in RNNs, thereby achieving simultaneous model compression and acceleration. We aim to implement RNNs in FPGA with highest performance and energy efficiency, with certain accuracy requirement (negligible accuracy degradation). Experimental results on actual FPGA deployments shows that the proposed framework achieves a maximum energy efficiency improvement of 35.7$\\times$ compared with ESE.", "paperhash": "li|efficient_recurrent_neural_networks_using_structured_matrices_in_fpgas", "keywords": ["Deep Learning", "Speech Recognition", "Model Compression", "Hardware Acceleration", "Circulant Matrix", "FPGA"], "_bibtex": "@misc{\n  li2018efficient,\n  title={Efficient Recurrent Neural Networks using Structured Matrices in FPGAs},\n  author={Zhe Li and Shuo Wang and Caiwen Ding and Qinru Qiu and Yanzhi Wang and Yun Liang},\n  year={2018},\n  url={https://openreview.net/forum?id=SJgAA3AUG}\n}", "authorids": ["zli89@syr.edu", "shvowang@pku.edu.cn", "cading@syr.edu", "qiqiu@syr.edu", "ywang393@syr.edu", "ericlyun@pku.edu.cn"], "authors": ["Zhe Li", "Shuo Wang", "Caiwen Ding", "Qinru Qiu", "Yanzhi Wang", "Yun Liang"], "TL;DR": "We propose block-circulant matrices for weight matrix representation in RNNs, thereby achieving simultaneous model compression and acceleration. ", "pdf": "/pdf/f633e094ffca5d1457167c6a76e426f83e2c213b.pdf"}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1520657999000, "tmdate": 1521582830641, "id": "ICLR.cc/2018/Workshop/-/Paper97/Official_Review", "writers": ["ICLR.cc/2018/Workshop"], "signatures": ["ICLR.cc/2018/Workshop"], "readers": ["everyone"], "invitees": ["ICLR.cc/2018/Workshop/Paper97/Reviewers"], "noninvitees": ["ICLR.cc/2018/Workshop/Paper97/AnonReviewer1", "ICLR.cc/2018/Workshop/Paper97/AnonReviewer3", "ICLR.cc/2018/Workshop/Paper97/AnonReviewer2"], "reply": {"forum": "SJgAA3AUG", "replyto": "SJgAA3AUG", "writers": {"values-regex": "ICLR.cc/2018/Workshop/Paper97/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2018/Workshop/Paper97/AnonReviewer[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"required": true, "order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"required": true, "order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "value-regex": "[\\S\\s]{1,200000}"}, "rating": {"required": true, "order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"required": true, "order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1528433999000, "cdate": 1521582830641}}}, {"tddate": null, "ddate": null, "original": null, "tmdate": 1521582659845, "tcdate": 1520772763036, "number": 3, "cdate": 1520772763036, "id": "BJXjLizKM", "invitation": "ICLR.cc/2018/Workshop/-/Paper97/Official_Review", "forum": "SJgAA3AUG", "replyto": "SJgAA3AUG", "signatures": ["ICLR.cc/2018/Workshop/Paper97/AnonReviewer2"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Workshop/Paper97/AnonReviewer2"], "content": {"title": "This paper is about exploiting block-structured matrices for efficient implementation of RNN in FPGA. Good paper. The source code should be shared.", "rating": "7: Good paper, accept", "review": "This paper is about exploiting block-structured matrices for efficient implementation of RNN in FPGA. Previous work have showed  that implementing  LSTM in FPGA  achieves higher energy efficiency than GPU, but performs poor in accuracy. This work proposes to overcome this by relying on block-structured matrices. \n\nThe paper is well written. Of course, several parts need to be detailed, but as a three pages workshop paper the essence is there. However I highly recommend to the authors to share their code so as the community could regenerate the empirical results. This is mandatory in my opinion for the paper to be accepted. ", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Efficient Recurrent Neural Networks using Structured Matrices in FPGAs", "abstract": "Recurrent Neural Networks (RNNs) are becoming increasingly important for time series-related applications which require efficient and real-time implementations.The recent pruning based work \\textit{ESE}~\\citep{han2017ese} suffers from degradation of performance/energy efficiency due to the irregular network structure after pruning.\nWe propose block-circulant matrices for weight matrix representation in RNNs, thereby achieving simultaneous model compression and acceleration. We aim to implement RNNs in FPGA with highest performance and energy efficiency, with certain accuracy requirement (negligible accuracy degradation). Experimental results on actual FPGA deployments shows that the proposed framework achieves a maximum energy efficiency improvement of 35.7$\\times$ compared with ESE.", "paperhash": "li|efficient_recurrent_neural_networks_using_structured_matrices_in_fpgas", "keywords": ["Deep Learning", "Speech Recognition", "Model Compression", "Hardware Acceleration", "Circulant Matrix", "FPGA"], "_bibtex": "@misc{\n  li2018efficient,\n  title={Efficient Recurrent Neural Networks using Structured Matrices in FPGAs},\n  author={Zhe Li and Shuo Wang and Caiwen Ding and Qinru Qiu and Yanzhi Wang and Yun Liang},\n  year={2018},\n  url={https://openreview.net/forum?id=SJgAA3AUG}\n}", "authorids": ["zli89@syr.edu", "shvowang@pku.edu.cn", "cading@syr.edu", "qiqiu@syr.edu", "ywang393@syr.edu", "ericlyun@pku.edu.cn"], "authors": ["Zhe Li", "Shuo Wang", "Caiwen Ding", "Qinru Qiu", "Yanzhi Wang", "Yun Liang"], "TL;DR": "We propose block-circulant matrices for weight matrix representation in RNNs, thereby achieving simultaneous model compression and acceleration. ", "pdf": "/pdf/f633e094ffca5d1457167c6a76e426f83e2c213b.pdf"}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1520657999000, "tmdate": 1521582830641, "id": "ICLR.cc/2018/Workshop/-/Paper97/Official_Review", "writers": ["ICLR.cc/2018/Workshop"], "signatures": ["ICLR.cc/2018/Workshop"], "readers": ["everyone"], "invitees": ["ICLR.cc/2018/Workshop/Paper97/Reviewers"], "noninvitees": ["ICLR.cc/2018/Workshop/Paper97/AnonReviewer1", "ICLR.cc/2018/Workshop/Paper97/AnonReviewer3", "ICLR.cc/2018/Workshop/Paper97/AnonReviewer2"], "reply": {"forum": "SJgAA3AUG", "replyto": "SJgAA3AUG", "writers": {"values-regex": "ICLR.cc/2018/Workshop/Paper97/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2018/Workshop/Paper97/AnonReviewer[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"required": true, "order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"required": true, "order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "value-regex": "[\\S\\s]{1,200000}"}, "rating": {"required": true, "order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"required": true, "order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1528433999000, "cdate": 1521582830641}}}, {"tddate": null, "ddate": null, "original": null, "tmdate": 1521573555624, "tcdate": 1521573555624, "number": 55, "cdate": 1521573555275, "id": "Sy32C00tM", "invitation": "ICLR.cc/2018/Workshop/-/Acceptance_Decision", "forum": "SJgAA3AUG", "replyto": "SJgAA3AUG", "signatures": ["ICLR.cc/2018/Workshop/Program_Chairs"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Workshop/Program_Chairs"], "content": {"decision": "Accept", "title": "ICLR 2018 Workshop Acceptance Decision", "comment": "Congratulations, your paper was accepted to the ICLR workshop."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Efficient Recurrent Neural Networks using Structured Matrices in FPGAs", "abstract": "Recurrent Neural Networks (RNNs) are becoming increasingly important for time series-related applications which require efficient and real-time implementations.The recent pruning based work \\textit{ESE}~\\citep{han2017ese} suffers from degradation of performance/energy efficiency due to the irregular network structure after pruning.\nWe propose block-circulant matrices for weight matrix representation in RNNs, thereby achieving simultaneous model compression and acceleration. We aim to implement RNNs in FPGA with highest performance and energy efficiency, with certain accuracy requirement (negligible accuracy degradation). Experimental results on actual FPGA deployments shows that the proposed framework achieves a maximum energy efficiency improvement of 35.7$\\times$ compared with ESE.", "paperhash": "li|efficient_recurrent_neural_networks_using_structured_matrices_in_fpgas", "keywords": ["Deep Learning", "Speech Recognition", "Model Compression", "Hardware Acceleration", "Circulant Matrix", "FPGA"], "_bibtex": "@misc{\n  li2018efficient,\n  title={Efficient Recurrent Neural Networks using Structured Matrices in FPGAs},\n  author={Zhe Li and Shuo Wang and Caiwen Ding and Qinru Qiu and Yanzhi Wang and Yun Liang},\n  year={2018},\n  url={https://openreview.net/forum?id=SJgAA3AUG}\n}", "authorids": ["zli89@syr.edu", "shvowang@pku.edu.cn", "cading@syr.edu", "qiqiu@syr.edu", "ywang393@syr.edu", "ericlyun@pku.edu.cn"], "authors": ["Zhe Li", "Shuo Wang", "Caiwen Ding", "Qinru Qiu", "Yanzhi Wang", "Yun Liang"], "TL;DR": "We propose block-circulant matrices for weight matrix representation in RNNs, thereby achieving simultaneous model compression and acceleration. ", "pdf": "/pdf/f633e094ffca5d1457167c6a76e426f83e2c213b.pdf"}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "tmdate": 1518629844880, "id": "ICLR.cc/2018/Workshop/-/Acceptance_Decision", "writers": ["ICLR.cc/2018/Workshop"], "signatures": ["ICLR.cc/2018/Workshop"], "readers": ["everyone"], "invitees": ["ICLR.cc/2018/Workshop/Program_Chairs"], "reply": {"forum": null, "replyto": null, "invitation": "ICLR.cc/2018/Workshop/-/Submission", "writers": {"values": ["ICLR.cc/2018/Workshop/Program_Chairs"]}, "signatures": {"description": "How your identity will be displayed with the above content.", "values": ["ICLR.cc/2018/Workshop/Program_Chairs"]}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["ICLR.cc/2018/Workshop/Program_Chairs", "everyone"]}, "content": {"title": {"required": true, "order": 1, "value": "ICLR 2018 Workshop Acceptance Decision"}, "comment": {"required": false, "order": 3, "description": "(optional) Comment on this decision.", "value-regex": "[\\S\\s]{0,5000}"}, "decision": {"required": true, "order": 2, "value-dropdown": ["Accept", "Reject"]}}}, "nonreaders": [], "noninvitees": [], "cdate": 1518629844880}}}], "count": 5}