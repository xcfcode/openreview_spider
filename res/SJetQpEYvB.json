{"notes": [{"id": "SJetQpEYvB", "original": "HkeJSzlwvB", "number": 458, "cdate": 1569439009361, "ddate": null, "tcdate": 1569439009361, "tmdate": 1583912024816, "tddate": null, "forum": "SJetQpEYvB", "replyto": null, "invitation": "ICLR.cc/2020/Conference/-/Blind_Submission", "content": {"title": "LEARNING EXECUTION THROUGH NEURAL CODE FUSION", "authors": ["Zhan Shi", "Kevin Swersky", "Daniel Tarlow", "Parthasarathy Ranganathan", "Milad Hashemi"], "authorids": ["zshi17@cs.utexas.edu", "kswersky@google.com", "dtarlow@google.com", "parthas@google.com", "miladh@google.com"], "keywords": ["code understanding", "graph neural networks", "learning program execution", "execution traces", "program performance"], "abstract": "As the performance of computer systems stagnates due to the end of Moore\u2019s Law,\nthere is a need for new models that can understand and optimize the execution\nof general purpose code. While there is a growing body of work on using Graph\nNeural Networks (GNNs) to learn static representations of source code, these\nrepresentations do not understand how code executes at runtime. In this work, we\npropose a new approach using GNNs to learn fused representations of general\nsource code and its execution. Our approach defines a multi-task GNN over\nlow-level representations of source code and program state (i.e., assembly code\nand dynamic memory states), converting complex source code constructs and data\nstructures into a simpler, more uniform format. We show that this leads to improved\nperformance over similar methods that do not use execution and it opens the door\nto applying GNN models to new tasks that would not be feasible from static code\nalone. As an illustration of this, we apply the new model to challenging dynamic\ntasks (branch prediction and prefetching) from the SPEC CPU benchmark suite,\noutperforming the state-of-the-art by 26% and 45% respectively. Moreover, we\nuse the learned fused graph embeddings to demonstrate transfer learning with high\nperformance on an indirectly related algorithm classification task.", "pdf": "/pdf/607dc220d4f786c1a3b440746c261155e31143d5.pdf", "code": "https://www.dropbox.com/s/yrjhx8ifowdktwh/ncf_code.zip?dl=0", "paperhash": "shi|learning_execution_through_neural_code_fusion", "_bibtex": "@inproceedings{\nShi2020LEARNING,\ntitle={LEARNING EXECUTION THROUGH NEURAL CODE FUSION},\nauthor={Zhan Shi and Kevin Swersky and Daniel Tarlow and Parthasarathy Ranganathan and Milad Hashemi},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=SJetQpEYvB}\n}", "full_presentation_video": "", "original_pdf": "/attachment/3d2c49efa4de6c2495d67de08cf42b77e1c33147.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "signatures": ["ICLR.cc/2020/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference"], "details": {"replyCount": 7, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"reply": {"readers": {"values-regex": ".*"}, "writers": {"values": ["ICLR.cc/2020/Conference"]}, "signatures": {"values": ["ICLR.cc/2020/Conference"]}, "content": {"spotlight_video": {"value-regex": ".*"}, "full_presentation_video": {"value-regex": ".*"}, "original_pdf": {"required": false, "description": "Upload a PDF file that ends with .pdf", "value-regex": ".*"}, "appendix": {"value-regex": ".*"}, "authorids": {"values-regex": ".*"}, "poster": {"value-regex": ".*"}, "authors": {"values": ["Anonymous"]}, "slides": {"value-regex": ".*"}}}, "final": [], "signatures": ["ICLR.cc/2020/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference"], "noninvitees": [], "tcdate": 1569271260237, "tmdate": 1593459412141, "id": "ICLR.cc/2020/Conference/-/Blind_Submission"}}, "tauthor": "ICLR.cc/2020/Conference"}, {"id": "UVjzdwO1h1", "original": null, "number": 1, "cdate": 1576798697002, "ddate": null, "tcdate": 1576798697002, "tmdate": 1576800938701, "tddate": null, "forum": "SJetQpEYvB", "replyto": "SJetQpEYvB", "invitation": "ICLR.cc/2020/Conference/Paper458/-/Decision", "content": {"decision": "Accept (Poster)", "comment": "This paper presents a method to learn representations of programs via code and execution.\n\nThe paper presents an interesting method, and results on branch prediction and address pre-fetching are conclusive. The only main critiques associated with this paper seemed to be (1) potential lack of interest to the ICLR community, and (2) lack of comparison to other methods that similarly improve performance using other varieties of information. I am satisfied by the authors' responses to these concerns, and believe the paper warrants acceptance.", "title": "Paper Decision"}, "signatures": ["ICLR.cc/2020/Conference/Program_Chairs"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Program_Chairs"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "LEARNING EXECUTION THROUGH NEURAL CODE FUSION", "authors": ["Zhan Shi", "Kevin Swersky", "Daniel Tarlow", "Parthasarathy Ranganathan", "Milad Hashemi"], "authorids": ["zshi17@cs.utexas.edu", "kswersky@google.com", "dtarlow@google.com", "parthas@google.com", "miladh@google.com"], "keywords": ["code understanding", "graph neural networks", "learning program execution", "execution traces", "program performance"], "abstract": "As the performance of computer systems stagnates due to the end of Moore\u2019s Law,\nthere is a need for new models that can understand and optimize the execution\nof general purpose code. While there is a growing body of work on using Graph\nNeural Networks (GNNs) to learn static representations of source code, these\nrepresentations do not understand how code executes at runtime. In this work, we\npropose a new approach using GNNs to learn fused representations of general\nsource code and its execution. Our approach defines a multi-task GNN over\nlow-level representations of source code and program state (i.e., assembly code\nand dynamic memory states), converting complex source code constructs and data\nstructures into a simpler, more uniform format. We show that this leads to improved\nperformance over similar methods that do not use execution and it opens the door\nto applying GNN models to new tasks that would not be feasible from static code\nalone. As an illustration of this, we apply the new model to challenging dynamic\ntasks (branch prediction and prefetching) from the SPEC CPU benchmark suite,\noutperforming the state-of-the-art by 26% and 45% respectively. Moreover, we\nuse the learned fused graph embeddings to demonstrate transfer learning with high\nperformance on an indirectly related algorithm classification task.", "pdf": "/pdf/607dc220d4f786c1a3b440746c261155e31143d5.pdf", "code": "https://www.dropbox.com/s/yrjhx8ifowdktwh/ncf_code.zip?dl=0", "paperhash": "shi|learning_execution_through_neural_code_fusion", "_bibtex": "@inproceedings{\nShi2020LEARNING,\ntitle={LEARNING EXECUTION THROUGH NEURAL CODE FUSION},\nauthor={Zhan Shi and Kevin Swersky and Daniel Tarlow and Parthasarathy Ranganathan and Milad Hashemi},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=SJetQpEYvB}\n}", "full_presentation_video": "", "original_pdf": "/attachment/3d2c49efa4de6c2495d67de08cf42b77e1c33147.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "tags": [], "invitation": {"reply": {"writers": {"description": "How your identity will be displayed.", "values-regex": ["ICLR.cc/2020/Conference/Program_Chairs"]}, "signatures": {"values": ["ICLR.cc/2020/Conference/Program_Chairs"], "description": "How your identity will be displayed."}, "content": {"decision": {"value-radio": ["Accept (Spotlight)", "Accept (Talk)", "Accept (Poster)", "Reject"], "description": "Decision", "required": true, "order": 2}, "title": {"value": "Paper Decision", "required": true, "order": 1}, "comment": {"value-regex": "[\\S\\s]{0,5000}", "description": "", "required": false, "order": 3}}, "forum": "SJetQpEYvB", "replyto": "SJetQpEYvB", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}}, "expdate": 1576854540000, "duedate": 1576853940000, "multiReply": false, "readers": ["everyone"], "invitees": ["ICLR.cc/2020/Conference/Program_Chairs"], "tcdate": 1576795729483, "tmdate": 1576800282079, "super": "ICLR.cc/2020/Conference/-/Decision", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper458/-/Decision"}}}, {"id": "Hkl6SPwGiS", "original": null, "number": 3, "cdate": 1573185349002, "ddate": null, "tcdate": 1573185349002, "tmdate": 1573185349002, "tddate": null, "forum": "SJetQpEYvB", "replyto": "H1e_TZJS9H", "invitation": "ICLR.cc/2020/Conference/Paper458/-/Official_Comment", "content": {"title": "Author response", "comment": "Thank you for taking the time to review the paper. \n\nBinary: We only mean this as an empirical claim. We observed surprisingly good performance with the binary representation, and we dug into how it was generalizing by running the experiments in section 4.6. These results show the generalization of the binary representation outside the training range for the k-loop example, to the highest numbers whose bits have been seen during training. We agree that there's no provable reason for why this generalization would occur, and we'll soften the claims in the paper to make it clear that this is just an empirical observation.\n\nTransfer Learning:   First, we'd like to note that our goal here is not to establish SOTA vs. Ben-Nun. Rather, the high-level idea is simply to show that it's sensible to pre-train on the execution behavior of code and then transfer the representations to a task that is typically addressed statically (just by looking at the code, not running it). This is an idea that we do not believe has previously appeared in the literature. Our goal in these experiments is just to argue that this is a potentially interesting idea going forward. \n\nBen-Nun uses an unsupervised approach to similarly learn embeddings that can be used for indirectly related tasks via an LSTM. If we were to train both models in identical settings, it\u2019s equivalent to removing the pre-trained embeddings (which will likely hurt the model performance), and training an LSTM on the algorithm classification dataset. We can run this experiment if the reviewer would like, but are not sure that it adds additional context, as our point is to demonstrate the richness of our graph representation.\n\nApplication: We disagree that the paper is simply an application. We are tackling the research problem of how to build machine learning models that are aware of both a programmatic representation of code and its execution behavior. We study the implications on tasks related to the execution of programs (branch prediction and prefetching) and tasks that are typically done based only on the static programmatic representation of code (algorithm classification), showing that there is benefit to learning these joint representations even when the task is not explicitly about program execution. This means the results potentially have broad applicability to learning representations of programs, which is a popular and active area within the machine learning community.\n\nIntuitively, when a person wishes to understand a piece of code, they often both inspect the static source code and manually trace it with different input values. We show how to learn representations inspired by this.\n\nFinally, we believe our results demonstrating the effectiveness of the binary representation of numbers could be of interest to the broader community.\n\nThe paper is related to and builds on many works in the machine learning community (please see the related work section for a more comprehensive set of references). In particular, prior work has utilized dynamic intermediate program state (Neural Program Interpreters, ICLR 2016), but their state is crafted by hand. This work is the first that leverages intermediate state from real programs (un-modified, non domain-specific languages) to build program representations. The most relevant related work was published at ICML 2018 (Hashemi et al.), NeurIPS 2018 (Ben-Nun et al, Trask et al, Chen et al), and ICLR 2018 (Allamanis et al). Many more relevant references can be found at https://ml4code.github.io/papers.html. Given the large number of publications in this area at core machine learning conferences, we believe that this paper will indeed be of interest to the general community."}, "signatures": ["ICLR.cc/2020/Conference/Paper458/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper458/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "LEARNING EXECUTION THROUGH NEURAL CODE FUSION", "authors": ["Zhan Shi", "Kevin Swersky", "Daniel Tarlow", "Parthasarathy Ranganathan", "Milad Hashemi"], "authorids": ["zshi17@cs.utexas.edu", "kswersky@google.com", "dtarlow@google.com", "parthas@google.com", "miladh@google.com"], "keywords": ["code understanding", "graph neural networks", "learning program execution", "execution traces", "program performance"], "abstract": "As the performance of computer systems stagnates due to the end of Moore\u2019s Law,\nthere is a need for new models that can understand and optimize the execution\nof general purpose code. While there is a growing body of work on using Graph\nNeural Networks (GNNs) to learn static representations of source code, these\nrepresentations do not understand how code executes at runtime. In this work, we\npropose a new approach using GNNs to learn fused representations of general\nsource code and its execution. Our approach defines a multi-task GNN over\nlow-level representations of source code and program state (i.e., assembly code\nand dynamic memory states), converting complex source code constructs and data\nstructures into a simpler, more uniform format. We show that this leads to improved\nperformance over similar methods that do not use execution and it opens the door\nto applying GNN models to new tasks that would not be feasible from static code\nalone. As an illustration of this, we apply the new model to challenging dynamic\ntasks (branch prediction and prefetching) from the SPEC CPU benchmark suite,\noutperforming the state-of-the-art by 26% and 45% respectively. Moreover, we\nuse the learned fused graph embeddings to demonstrate transfer learning with high\nperformance on an indirectly related algorithm classification task.", "pdf": "/pdf/607dc220d4f786c1a3b440746c261155e31143d5.pdf", "code": "https://www.dropbox.com/s/yrjhx8ifowdktwh/ncf_code.zip?dl=0", "paperhash": "shi|learning_execution_through_neural_code_fusion", "_bibtex": "@inproceedings{\nShi2020LEARNING,\ntitle={LEARNING EXECUTION THROUGH NEURAL CODE FUSION},\nauthor={Zhan Shi and Kevin Swersky and Daniel Tarlow and Parthasarathy Ranganathan and Milad Hashemi},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=SJetQpEYvB}\n}", "full_presentation_video": "", "original_pdf": "/attachment/3d2c49efa4de6c2495d67de08cf42b77e1c33147.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "SJetQpEYvB", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper458/Authors", "ICLR.cc/2020/Conference/Paper458/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper458/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper458/Reviewers", "ICLR.cc/2020/Conference/Paper458/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper458/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper458/Authors|ICLR.cc/2020/Conference/Paper458/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504171192, "tmdate": 1576860549388, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper458/Authors", "ICLR.cc/2020/Conference/Paper458/Reviewers", "ICLR.cc/2020/Conference/Paper458/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper458/-/Official_Comment"}}}, {"id": "H1lysUvzjr", "original": null, "number": 2, "cdate": 1573185174950, "ddate": null, "tcdate": 1573185174950, "tmdate": 1573185174950, "tddate": null, "forum": "SJetQpEYvB", "replyto": "HJlUX4sTFH", "invitation": "ICLR.cc/2020/Conference/Paper458/-/Official_Comment", "content": {"title": "Author response", "comment": "Thanks for taking the time to review our work. We\u2019d be happy to answer any questions that you may have."}, "signatures": ["ICLR.cc/2020/Conference/Paper458/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper458/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "LEARNING EXECUTION THROUGH NEURAL CODE FUSION", "authors": ["Zhan Shi", "Kevin Swersky", "Daniel Tarlow", "Parthasarathy Ranganathan", "Milad Hashemi"], "authorids": ["zshi17@cs.utexas.edu", "kswersky@google.com", "dtarlow@google.com", "parthas@google.com", "miladh@google.com"], "keywords": ["code understanding", "graph neural networks", "learning program execution", "execution traces", "program performance"], "abstract": "As the performance of computer systems stagnates due to the end of Moore\u2019s Law,\nthere is a need for new models that can understand and optimize the execution\nof general purpose code. While there is a growing body of work on using Graph\nNeural Networks (GNNs) to learn static representations of source code, these\nrepresentations do not understand how code executes at runtime. In this work, we\npropose a new approach using GNNs to learn fused representations of general\nsource code and its execution. Our approach defines a multi-task GNN over\nlow-level representations of source code and program state (i.e., assembly code\nand dynamic memory states), converting complex source code constructs and data\nstructures into a simpler, more uniform format. We show that this leads to improved\nperformance over similar methods that do not use execution and it opens the door\nto applying GNN models to new tasks that would not be feasible from static code\nalone. As an illustration of this, we apply the new model to challenging dynamic\ntasks (branch prediction and prefetching) from the SPEC CPU benchmark suite,\noutperforming the state-of-the-art by 26% and 45% respectively. Moreover, we\nuse the learned fused graph embeddings to demonstrate transfer learning with high\nperformance on an indirectly related algorithm classification task.", "pdf": "/pdf/607dc220d4f786c1a3b440746c261155e31143d5.pdf", "code": "https://www.dropbox.com/s/yrjhx8ifowdktwh/ncf_code.zip?dl=0", "paperhash": "shi|learning_execution_through_neural_code_fusion", "_bibtex": "@inproceedings{\nShi2020LEARNING,\ntitle={LEARNING EXECUTION THROUGH NEURAL CODE FUSION},\nauthor={Zhan Shi and Kevin Swersky and Daniel Tarlow and Parthasarathy Ranganathan and Milad Hashemi},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=SJetQpEYvB}\n}", "full_presentation_video": "", "original_pdf": "/attachment/3d2c49efa4de6c2495d67de08cf42b77e1c33147.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "SJetQpEYvB", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper458/Authors", "ICLR.cc/2020/Conference/Paper458/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper458/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper458/Reviewers", "ICLR.cc/2020/Conference/Paper458/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper458/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper458/Authors|ICLR.cc/2020/Conference/Paper458/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504171192, "tmdate": 1576860549388, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper458/Authors", "ICLR.cc/2020/Conference/Paper458/Reviewers", "ICLR.cc/2020/Conference/Paper458/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper458/-/Official_Comment"}}}, {"id": "Byl-vIwziB", "original": null, "number": 1, "cdate": 1573185113062, "ddate": null, "tcdate": 1573185113062, "tmdate": 1573185113062, "tddate": null, "forum": "SJetQpEYvB", "replyto": "BkeiWrw1qH", "invitation": "ICLR.cc/2020/Conference/Paper458/-/Official_Comment", "content": {"title": "Author response", "comment": "Thanks for taking the time to review our work, we\u2019d be happy to answer any questions that you may have. \n\nRegarding differences vs. the other baselines, we were wondering if you could be more specific as to the baselines you\u2019re considering. The primary baselines we compare with (for branch prediction/prefetching) do not use any source or assembly code, but rather historical decisions/access patterns. We are using a different, and potentially complementary set of features with assembly code/memory snapshots. We use assembly code because there is a clear correspondence between symbols in the code and values in the memory snapshots, but this isn't the case with source code. It isn\u2019t clear how to get the same benefits using source code."}, "signatures": ["ICLR.cc/2020/Conference/Paper458/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper458/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "LEARNING EXECUTION THROUGH NEURAL CODE FUSION", "authors": ["Zhan Shi", "Kevin Swersky", "Daniel Tarlow", "Parthasarathy Ranganathan", "Milad Hashemi"], "authorids": ["zshi17@cs.utexas.edu", "kswersky@google.com", "dtarlow@google.com", "parthas@google.com", "miladh@google.com"], "keywords": ["code understanding", "graph neural networks", "learning program execution", "execution traces", "program performance"], "abstract": "As the performance of computer systems stagnates due to the end of Moore\u2019s Law,\nthere is a need for new models that can understand and optimize the execution\nof general purpose code. While there is a growing body of work on using Graph\nNeural Networks (GNNs) to learn static representations of source code, these\nrepresentations do not understand how code executes at runtime. In this work, we\npropose a new approach using GNNs to learn fused representations of general\nsource code and its execution. Our approach defines a multi-task GNN over\nlow-level representations of source code and program state (i.e., assembly code\nand dynamic memory states), converting complex source code constructs and data\nstructures into a simpler, more uniform format. We show that this leads to improved\nperformance over similar methods that do not use execution and it opens the door\nto applying GNN models to new tasks that would not be feasible from static code\nalone. As an illustration of this, we apply the new model to challenging dynamic\ntasks (branch prediction and prefetching) from the SPEC CPU benchmark suite,\noutperforming the state-of-the-art by 26% and 45% respectively. Moreover, we\nuse the learned fused graph embeddings to demonstrate transfer learning with high\nperformance on an indirectly related algorithm classification task.", "pdf": "/pdf/607dc220d4f786c1a3b440746c261155e31143d5.pdf", "code": "https://www.dropbox.com/s/yrjhx8ifowdktwh/ncf_code.zip?dl=0", "paperhash": "shi|learning_execution_through_neural_code_fusion", "_bibtex": "@inproceedings{\nShi2020LEARNING,\ntitle={LEARNING EXECUTION THROUGH NEURAL CODE FUSION},\nauthor={Zhan Shi and Kevin Swersky and Daniel Tarlow and Parthasarathy Ranganathan and Milad Hashemi},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=SJetQpEYvB}\n}", "full_presentation_video": "", "original_pdf": "/attachment/3d2c49efa4de6c2495d67de08cf42b77e1c33147.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "SJetQpEYvB", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper458/Authors", "ICLR.cc/2020/Conference/Paper458/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper458/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper458/Reviewers", "ICLR.cc/2020/Conference/Paper458/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper458/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper458/Authors|ICLR.cc/2020/Conference/Paper458/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504171192, "tmdate": 1576860549388, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper458/Authors", "ICLR.cc/2020/Conference/Paper458/Reviewers", "ICLR.cc/2020/Conference/Paper458/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper458/-/Official_Comment"}}}, {"id": "HJlUX4sTFH", "original": null, "number": 1, "cdate": 1571824669799, "ddate": null, "tcdate": 1571824669799, "tmdate": 1572972592825, "tddate": null, "forum": "SJetQpEYvB", "replyto": "SJetQpEYvB", "invitation": "ICLR.cc/2020/Conference/Paper458/-/Official_Review", "content": {"experience_assessment": "I do not know much about this area.", "rating": "6: Weak Accept", "review_assessment:_thoroughness_in_paper_reading": "N/A", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #3", "review_assessment:_checking_correctness_of_derivations_and_theory": "N/A", "review": "The paper proposes using Graph Neural Networks to learn representations of source code and its execution. They test their method on the SPEC CPU benchmark suite and show substantial improvement over methods that do not use execution. \n\nThe paper's main question is to answer how to learn code representations. The main novelty introduced in their approach is to build a graph representation not of high level code but of assembly code. They also develop a way to use what they call a \"snapshot mechanism\" that feeds limited memory states into the graph. The downstream consequences of their methods are improved methods for example for branch prediction. Interestingly NCF can be also used to represent programs for use in downstream tasks. This is demonstrated via transfer learning in an algorithm classification problem. The paper is well written and the background / related work makes it easy for the reader to understand the problem's relevance within the related literature. \n\nThe results look well justified and empirically verified. "}, "signatures": ["ICLR.cc/2020/Conference/Paper458/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper458/AnonReviewer3"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "LEARNING EXECUTION THROUGH NEURAL CODE FUSION", "authors": ["Zhan Shi", "Kevin Swersky", "Daniel Tarlow", "Parthasarathy Ranganathan", "Milad Hashemi"], "authorids": ["zshi17@cs.utexas.edu", "kswersky@google.com", "dtarlow@google.com", "parthas@google.com", "miladh@google.com"], "keywords": ["code understanding", "graph neural networks", "learning program execution", "execution traces", "program performance"], "abstract": "As the performance of computer systems stagnates due to the end of Moore\u2019s Law,\nthere is a need for new models that can understand and optimize the execution\nof general purpose code. While there is a growing body of work on using Graph\nNeural Networks (GNNs) to learn static representations of source code, these\nrepresentations do not understand how code executes at runtime. In this work, we\npropose a new approach using GNNs to learn fused representations of general\nsource code and its execution. Our approach defines a multi-task GNN over\nlow-level representations of source code and program state (i.e., assembly code\nand dynamic memory states), converting complex source code constructs and data\nstructures into a simpler, more uniform format. We show that this leads to improved\nperformance over similar methods that do not use execution and it opens the door\nto applying GNN models to new tasks that would not be feasible from static code\nalone. As an illustration of this, we apply the new model to challenging dynamic\ntasks (branch prediction and prefetching) from the SPEC CPU benchmark suite,\noutperforming the state-of-the-art by 26% and 45% respectively. Moreover, we\nuse the learned fused graph embeddings to demonstrate transfer learning with high\nperformance on an indirectly related algorithm classification task.", "pdf": "/pdf/607dc220d4f786c1a3b440746c261155e31143d5.pdf", "code": "https://www.dropbox.com/s/yrjhx8ifowdktwh/ncf_code.zip?dl=0", "paperhash": "shi|learning_execution_through_neural_code_fusion", "_bibtex": "@inproceedings{\nShi2020LEARNING,\ntitle={LEARNING EXECUTION THROUGH NEURAL CODE FUSION},\nauthor={Zhan Shi and Kevin Swersky and Daniel Tarlow and Parthasarathy Ranganathan and Milad Hashemi},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=SJetQpEYvB}\n}", "full_presentation_video": "", "original_pdf": "/attachment/3d2c49efa4de6c2495d67de08cf42b77e1c33147.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "SJetQpEYvB", "replyto": "SJetQpEYvB", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper458/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper458/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1574722376000, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper458/Reviewers"], "noninvitees": [], "tcdate": 1570237751832, "tmdate": 1574723092257, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper458/-/Official_Review"}}}, {"id": "BkeiWrw1qH", "original": null, "number": 2, "cdate": 1571939586706, "ddate": null, "tcdate": 1571939586706, "tmdate": 1572972592783, "tddate": null, "forum": "SJetQpEYvB", "replyto": "SJetQpEYvB", "invitation": "ICLR.cc/2020/Conference/Paper458/-/Official_Review", "content": {"experience_assessment": "I do not know much about this area.", "rating": "8: Accept", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #1", "review_assessment:_checking_correctness_of_derivations_and_theory": "N/A", "review": "This paper presents a novel improvement in methodology for learning code execution (at the level of branch-predictions and prefetching).  They combine static program description with dynamic program state into one graph neural network, for the first time, to achieve significant performance gains on standard benchmarks.\n\nI would vote to accept this paper.  They appear to have developed a new model structure and interface to the program information (i.e. inputs to the model), and the design decisions appear thoughtful, sensible, and well-justified (e.g. use of assembly code).  The presentation is mostly clear, with a good balance of background material, method description, and experiment results.  \n\nTaken at face value, the results are impressive, although I am not familiar enough with this field to assess the fairness of comparison against the baselines.  For example, it's a little unclear what the difference is vs previous baselines just from switching to source-code-as-input to assembly-code-as-input?\n\nThe study on memory representations (categorical vs scalar vs binary) is a helpful component which adds its own value, and the context for popularity of the alternatives is described.\n\nFew details as to implementation are discussed, although the code is included in the submission, and after a quick glance appears substantial."}, "signatures": ["ICLR.cc/2020/Conference/Paper458/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper458/AnonReviewer1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "LEARNING EXECUTION THROUGH NEURAL CODE FUSION", "authors": ["Zhan Shi", "Kevin Swersky", "Daniel Tarlow", "Parthasarathy Ranganathan", "Milad Hashemi"], "authorids": ["zshi17@cs.utexas.edu", "kswersky@google.com", "dtarlow@google.com", "parthas@google.com", "miladh@google.com"], "keywords": ["code understanding", "graph neural networks", "learning program execution", "execution traces", "program performance"], "abstract": "As the performance of computer systems stagnates due to the end of Moore\u2019s Law,\nthere is a need for new models that can understand and optimize the execution\nof general purpose code. While there is a growing body of work on using Graph\nNeural Networks (GNNs) to learn static representations of source code, these\nrepresentations do not understand how code executes at runtime. In this work, we\npropose a new approach using GNNs to learn fused representations of general\nsource code and its execution. Our approach defines a multi-task GNN over\nlow-level representations of source code and program state (i.e., assembly code\nand dynamic memory states), converting complex source code constructs and data\nstructures into a simpler, more uniform format. We show that this leads to improved\nperformance over similar methods that do not use execution and it opens the door\nto applying GNN models to new tasks that would not be feasible from static code\nalone. As an illustration of this, we apply the new model to challenging dynamic\ntasks (branch prediction and prefetching) from the SPEC CPU benchmark suite,\noutperforming the state-of-the-art by 26% and 45% respectively. Moreover, we\nuse the learned fused graph embeddings to demonstrate transfer learning with high\nperformance on an indirectly related algorithm classification task.", "pdf": "/pdf/607dc220d4f786c1a3b440746c261155e31143d5.pdf", "code": "https://www.dropbox.com/s/yrjhx8ifowdktwh/ncf_code.zip?dl=0", "paperhash": "shi|learning_execution_through_neural_code_fusion", "_bibtex": "@inproceedings{\nShi2020LEARNING,\ntitle={LEARNING EXECUTION THROUGH NEURAL CODE FUSION},\nauthor={Zhan Shi and Kevin Swersky and Daniel Tarlow and Parthasarathy Ranganathan and Milad Hashemi},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=SJetQpEYvB}\n}", "full_presentation_video": "", "original_pdf": "/attachment/3d2c49efa4de6c2495d67de08cf42b77e1c33147.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "SJetQpEYvB", "replyto": "SJetQpEYvB", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper458/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper458/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1574722376000, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper458/Reviewers"], "noninvitees": [], "tcdate": 1570237751832, "tmdate": 1574723092257, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper458/-/Official_Review"}}}, {"id": "H1e_TZJS9H", "original": null, "number": 3, "cdate": 1572299200110, "ddate": null, "tcdate": 1572299200110, "tmdate": 1572972592741, "tddate": null, "forum": "SJetQpEYvB", "replyto": "SJetQpEYvB", "invitation": "ICLR.cc/2020/Conference/Paper458/-/Official_Review", "content": {"experience_assessment": "I do not know much about this area.", "rating": "3: Weak Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #2", "review_assessment:_checking_correctness_of_derivations_and_theory": "N/A", "review": "Using Deep Learning and especially, GNNs seems to be a popular area of research. I am no \nexpert at optimizing code performance, so please take my review with a grain of salt. The algorithmic contributions of the paper are as following: \n\n(a) GNN that combines static code and dynamic execution trace. \n(b) Binary encoding of features leads to better performance in comparison to categorical and scalar representations. \n\nThe results show that the proposed method outperforms existing methods on standard benchmarks in the program execution community. \n\nFrom a machine learning stand point, the contributions are straightforward and the results make sense. I have the following questions: \n\n(I) Authors argue that binary representations are better because of their hierarchical nature. They mention that they can generalize even if not all combinations of bits are seen, but a subset is seen in a manner that every bit has been flipped a couple of times. I don\u2019t agree with this reasoning, as seeing the individual bits flip has no guarantee that a NN would generalize to a new combination of bits unless the distance in the binary code makes sense. Is there some special way in which the binary code is constructed?\n \n(ii) Transfer learning experiments: Its unclear to me if the comparison presented in the paper is a fair one. Comparison is made against Ben-Nun et al. pre-training on LLVM IR. I am not sure how different is LLVM IR dataset from the algorithm classification dataset. If the dataset is very different, then obviously a lot of pre-training will only result in modest performance gain. What happens with Ben-Nun method is pre-trained on the same dataset as the proposed method? Also, what is the difference in performance between the cases when the proposed method is applied to algorithm classification with and without pre-training? \n\nOverall, the paper is a application of GNN to optimizing code execution. The technical innovations are domain-specific and do not inform the general machine learning community. Given lack of expertise in the area of program execution, I cannot judge the significance of the performance improvements reported in the paper. \n\nGiven my current concerns, I cannot recommend acceptance. I might change my ratings based on the review discussions and the author\u2019s responses to the above questions. \n"}, "signatures": ["ICLR.cc/2020/Conference/Paper458/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper458/AnonReviewer2"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "LEARNING EXECUTION THROUGH NEURAL CODE FUSION", "authors": ["Zhan Shi", "Kevin Swersky", "Daniel Tarlow", "Parthasarathy Ranganathan", "Milad Hashemi"], "authorids": ["zshi17@cs.utexas.edu", "kswersky@google.com", "dtarlow@google.com", "parthas@google.com", "miladh@google.com"], "keywords": ["code understanding", "graph neural networks", "learning program execution", "execution traces", "program performance"], "abstract": "As the performance of computer systems stagnates due to the end of Moore\u2019s Law,\nthere is a need for new models that can understand and optimize the execution\nof general purpose code. While there is a growing body of work on using Graph\nNeural Networks (GNNs) to learn static representations of source code, these\nrepresentations do not understand how code executes at runtime. In this work, we\npropose a new approach using GNNs to learn fused representations of general\nsource code and its execution. Our approach defines a multi-task GNN over\nlow-level representations of source code and program state (i.e., assembly code\nand dynamic memory states), converting complex source code constructs and data\nstructures into a simpler, more uniform format. We show that this leads to improved\nperformance over similar methods that do not use execution and it opens the door\nto applying GNN models to new tasks that would not be feasible from static code\nalone. As an illustration of this, we apply the new model to challenging dynamic\ntasks (branch prediction and prefetching) from the SPEC CPU benchmark suite,\noutperforming the state-of-the-art by 26% and 45% respectively. Moreover, we\nuse the learned fused graph embeddings to demonstrate transfer learning with high\nperformance on an indirectly related algorithm classification task.", "pdf": "/pdf/607dc220d4f786c1a3b440746c261155e31143d5.pdf", "code": "https://www.dropbox.com/s/yrjhx8ifowdktwh/ncf_code.zip?dl=0", "paperhash": "shi|learning_execution_through_neural_code_fusion", "_bibtex": "@inproceedings{\nShi2020LEARNING,\ntitle={LEARNING EXECUTION THROUGH NEURAL CODE FUSION},\nauthor={Zhan Shi and Kevin Swersky and Daniel Tarlow and Parthasarathy Ranganathan and Milad Hashemi},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=SJetQpEYvB}\n}", "full_presentation_video": "", "original_pdf": "/attachment/3d2c49efa4de6c2495d67de08cf42b77e1c33147.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "SJetQpEYvB", "replyto": "SJetQpEYvB", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper458/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper458/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1574722376000, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper458/Reviewers"], "noninvitees": [], "tcdate": 1570237751832, "tmdate": 1574723092257, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper458/-/Official_Review"}}}], "count": 8}