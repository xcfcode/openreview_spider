{"notes": [{"tddate": null, "replyto": null, "ddate": null, "tmdate": 1528124435058, "tcdate": 1518472825326, "number": 350, "cdate": 1518472825326, "id": "rJWF0Fywf", "invitation": "ICLR.cc/2018/Workshop/-/Submission", "forum": "rJWF0Fywf", "signatures": ["~Jasper_Snoek1"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Workshop"], "content": {"title": "Winner's Curse?  On Pace, Progress, and Empirical Rigor", "abstract": "The field of ML is distinguished both by rapid innovation and rapid dissemination of results. While the pace of progress has been extraordinary by any measure, in this paper we explore potential issues that we believe to be arising as a result.  In particular, we observe that the rate of empirical advancement may not have been matched by consistent increase in the level of empirical rigor across the field as a whole.  This short position paper highlights examples where progress has actually been slowed as a result, offers thoughts on incentive structures currently at play, and gives suggestions as seeds for discussions on productive change.", "paperhash": "sculley|winners_curse_on_pace_progress_and_empirical_rigor", "keywords": ["empirical rigor"], "_bibtex": "@misc{\n  sculley2018winner's,\n  title={Winner's Curse?  On Pace, Progress, and Empirical Rigor},\n  author={D. Sculley and Jasper Snoek and Alex Wiltschko and Ali Rahimi},\n  year={2018},\n  url={https://openreview.net/forum?id=rJWF0Fywf}\n}", "authorids": ["dsculley@google.com", "jsnoek@google.com", "alexbw@google.com", "arahimi@google.com"], "authors": ["D. Sculley", "Jasper Snoek", "Alex Wiltschko", "Ali Rahimi"], "TL;DR": "A position paper on empirical rigor in machine learning, meant to foster a discussion on the subject.", "pdf": "/pdf/c6e508deffc243a3de6489be3868264961df6fe3.pdf"}, "nonreaders": [], "details": {"replyCount": 9, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1518472800000, "tmdate": 1518474081690, "id": "ICLR.cc/2018/Workshop/-/Submission", "writers": ["ICLR.cc/2018/Workshop"], "signatures": ["ICLR.cc/2018/Workshop"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": null, "replyto": null, "writers": {"values": ["ICLR.cc/2018/Workshop"]}, "signatures": {"values-regex": "~.*|ICLR.cc/2018/Workshop", "description": "Your authorized identity to be associated with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"pdf": {"required": true, "order": 9, "value-regex": "upload", "description": "Upload a PDF file that ends with .pdf"}, "title": {"required": true, "order": 1, "description": "Title of paper.", "value-regex": ".{1,250}"}, "abstract": {"required": true, "order": 8, "description": "Abstract of paper.", "value-regex": "[\\S\\s]{1,5000}"}, "authors": {"required": true, "order": 2, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of author names. Please provide real names; identities will be anonymized."}, "keywords": {"order": 6, "values-regex": "(^$)|[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of keywords."}, "TL;DR": {"required": false, "order": 7, "description": "\"Too Long; Didn't Read\": a short sentence describing your paper", "value-regex": "[^\\n]{0,500}"}, "authorids": {"required": true, "order": 3, "values-regex": "([a-z0-9_\\-\\.]{2,}@[a-z0-9_\\-\\.]{2,}\\.[a-z]{2,},){0,}([a-z0-9_\\-\\.]{2,}@[a-z0-9_\\-\\.]{2,}\\.[a-z]{2,})", "description": "Comma separated list of author email addresses, lowercased, in the same order as above. For authors with existing OpenReview accounts, please make sure that the provided email address(es) match those listed in the author's profile. Please provide real emails; identities will be anonymized."}}}, "nonreaders": [], "noninvitees": [], "expdate": 1526248800000, "cdate": 1518474081690}}}, {"tddate": null, "ddate": null, "tmdate": 1521839474432, "tcdate": 1521839474432, "number": 5, "cdate": 1521839474432, "id": "rJ9daJQcM", "invitation": "ICLR.cc/2018/Workshop/-/Paper350/Public_Comment", "forum": "rJWF0Fywf", "replyto": "rJWF0Fywf", "signatures": ["(anonymous)"], "readers": ["everyone"], "writers": ["(anonymous)"], "content": {"title": "Very nice! Maybe also mention openml.org?", "comment": "Very nice paper!\n\nSome of the paper's ideas are very much in line with the open machine learning website openml.org -- maybe a reference could be added? (https://www.openml.org/cite) That website has thousands of datasets available with a nice API (kind of like UCI++), and there are also benchmarking suites and notebooks available for directly comparing a new algorithm's results with previously known ones; e.g., https://arxiv.org/abs/1708.03731\n\n\nAlso, it's not that far fetched for ML conferences to require / reward best practices for reproducibility. E.g., ECML-PKDD allows authors to flag their submissions as \"reproducible research\", which gives them a bonus, but which requires posting code and data on standard repository hosting services. Probably ICLR, ICML, and NIPS should follow suit, and I hope this paper helps make this happen rather sooner than later."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Winner's Curse?  On Pace, Progress, and Empirical Rigor", "abstract": "The field of ML is distinguished both by rapid innovation and rapid dissemination of results. While the pace of progress has been extraordinary by any measure, in this paper we explore potential issues that we believe to be arising as a result.  In particular, we observe that the rate of empirical advancement may not have been matched by consistent increase in the level of empirical rigor across the field as a whole.  This short position paper highlights examples where progress has actually been slowed as a result, offers thoughts on incentive structures currently at play, and gives suggestions as seeds for discussions on productive change.", "paperhash": "sculley|winners_curse_on_pace_progress_and_empirical_rigor", "keywords": ["empirical rigor"], "_bibtex": "@misc{\n  sculley2018winner's,\n  title={Winner's Curse?  On Pace, Progress, and Empirical Rigor},\n  author={D. Sculley and Jasper Snoek and Alex Wiltschko and Ali Rahimi},\n  year={2018},\n  url={https://openreview.net/forum?id=rJWF0Fywf}\n}", "authorids": ["dsculley@google.com", "jsnoek@google.com", "alexbw@google.com", "arahimi@google.com"], "authors": ["D. Sculley", "Jasper Snoek", "Alex Wiltschko", "Ali Rahimi"], "TL;DR": "A position paper on empirical rigor in machine learning, meant to foster a discussion on the subject.", "pdf": "/pdf/c6e508deffc243a3de6489be3868264961df6fe3.pdf"}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "tmdate": 1518712622563, "id": "ICLR.cc/2018/Workshop/-/Paper350/Public_Comment", "writers": ["ICLR.cc/2018/Workshop"], "signatures": ["ICLR.cc/2018/Workshop"], "readers": ["everyone"], "invitees": ["~"], "noninvitees": ["ICLR.cc/2018/Workshop/Paper350/Reviewers"], "reply": {"replyto": null, "forum": "rJWF0Fywf", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone"]}, "content": {"title": {"required": true, "order": 0, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"required": true, "order": 1, "description": "Your comment or reply (max 5000 characters).", "value-regex": "[\\S\\s]{1,5000}"}}}, "nonreaders": [], "cdate": 1518712622563}}}, {"tddate": null, "ddate": null, "original": null, "tmdate": 1521582974917, "tcdate": 1519947108729, "number": 1, "cdate": 1519947108729, "id": "S16DpbLOM", "invitation": "ICLR.cc/2018/Workshop/-/Paper350/Official_Review", "forum": "rJWF0Fywf", "replyto": "rJWF0Fywf", "signatures": ["ICLR.cc/2018/Workshop/Paper350/AnonReviewer1"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Workshop/Paper350/AnonReviewer1"], "content": {"title": "Fantastic paper for discussion and basically I could not agree more", "rating": "10: Top 5% of accepted papers, seminal paper", "review": "The issues presented here are very important for the community to discuss.   This paper extends on, concertizes and substantiates with references  of key ideas of the talk Ali Rahimi gave at NIPS in his acceptance of the Test of Time award with Ben Recht.   That talk was highly influential in that talk with the addition of references , more substance and a path forward.  Most notable, Yann LeCunn has come out to contradict some of these ideas, inspiring a debate on Facebook.   Great.  Let's talk more.  The community needs to have these discussions and this is an excellent position paper that is sure to have impact.\n\nHere are the points I like, that I am glad are being documented in this paper and that I think should be recorded and discussed in this forum:\n\n>The price of compute is relative. Large research groups (often based in industry) may have\n>the resources, for example, to tune models on 450 GPUs for 7 days (Esteban Real, 2018),\n>but individual researchers may be harder pressed.   \n\nI am glad someone wrote this down.  At ICML 2016 in New York I remember one presenter (on deep reinforcement learning) saying to the audience (and this is a likely incorrect paraphrased memory) \"this step you can do on your home PC, and this one, this step basically brought down one of Google's data centers, I don't recommend trying this one at home <laughter> \" and I remember thinking to myself how great it would be to see that kind of honest commentary in the actual paper.  \n\nMuch in the spirit of this paper and the OpenReview protocol, the more rigorous we can be and the more truly honest we can be about our methods (requirements, limitations) the better it will be for the field overall.\n\nWith respect to the recommendations, I am a particular fan of: At Least One Negative Result and Tuning Methodology.  Although they are all probably good ideas, these in particular resonate.\n\nWe should all be talking about: \"Alternative paper formats, including smart notebooks like iPython and Colaboratory 1\nthat include code, data, and analysis along with text should be first-class publication media.\"  In my opinion these should be first class and paper alone can go back to coach.  \n\nI would also like to applaud the authors for their appeal for \"Standards for Reviews and Reviewers - Review quality is a key factor to raising the bar on empirical rigor in the field.\"  I am hoping that tools like OpenReview will help here as more popular works will hopefully attract more discussion and criticism.  As part of the \"Winner's Curse\" - review quality has (almost necessarily) gone down due to volume.  With record numbers of submissions at NIPS and ICML there has been a crisis in finding a sufficient number of qualified reviewers for papers.  The NIPS consistency experiment was an incredibly bold move to evaluate the review process and take steps to improve it, but implemented changes, for the better are up against a flood of submissions.  Also with the amount of review requests many of us receive the amount of time we can give each paper drops.  \"The ability to add line-item comments directly in text\" would be excellent as we could all better contribute what we can to the process.  Imagine being able to see a research paper like a word document with all the mark-up and edits from your collaborators (maybe one at a time).  Would we even get to the point of \"publishing\" rejected papers where critical flaws in proof s are revealed and the reviewers who found them are rewarded.  In this case the authors would remain anonymous and the reviewer would be named.\n\nFurthermore: \"We suggest working more creatively with alternative media (including video and video conferencing) to flexibly create additional opportunity to accept papers that focus on issues other than wins, such as in depth meta-analyses commonly found in other fields.\" - also I could not agree more.  It would be great to not have to travel as much, to deal with visa issues, to be able to have extended conversations.  Instead of repeating the opening comments to your poster, these could be recorded - imagine every poster presenter giving their generic intro presentation on a video and submitting that to the conference website.  Then you could ask questions in the comments or even arrange a video chat - and maybe if you are daring - record the chat and add it to the conversation.   \n\nOverall, this paper is very good and should be accepted.  Hopefully there will be other reviews that strongly disagree and add more perspectives to the conversation, but I would submit that such disagreement would only strengthen the reasons I think this paper should be published: it provides excellent talking for the community.\n\n\n", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Winner's Curse?  On Pace, Progress, and Empirical Rigor", "abstract": "The field of ML is distinguished both by rapid innovation and rapid dissemination of results. While the pace of progress has been extraordinary by any measure, in this paper we explore potential issues that we believe to be arising as a result.  In particular, we observe that the rate of empirical advancement may not have been matched by consistent increase in the level of empirical rigor across the field as a whole.  This short position paper highlights examples where progress has actually been slowed as a result, offers thoughts on incentive structures currently at play, and gives suggestions as seeds for discussions on productive change.", "paperhash": "sculley|winners_curse_on_pace_progress_and_empirical_rigor", "keywords": ["empirical rigor"], "_bibtex": "@misc{\n  sculley2018winner's,\n  title={Winner's Curse?  On Pace, Progress, and Empirical Rigor},\n  author={D. Sculley and Jasper Snoek and Alex Wiltschko and Ali Rahimi},\n  year={2018},\n  url={https://openreview.net/forum?id=rJWF0Fywf}\n}", "authorids": ["dsculley@google.com", "jsnoek@google.com", "alexbw@google.com", "arahimi@google.com"], "authors": ["D. Sculley", "Jasper Snoek", "Alex Wiltschko", "Ali Rahimi"], "TL;DR": "A position paper on empirical rigor in machine learning, meant to foster a discussion on the subject.", "pdf": "/pdf/c6e508deffc243a3de6489be3868264961df6fe3.pdf"}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1520657999000, "tmdate": 1521582974703, "id": "ICLR.cc/2018/Workshop/-/Paper350/Official_Review", "writers": ["ICLR.cc/2018/Workshop"], "signatures": ["ICLR.cc/2018/Workshop"], "readers": ["everyone"], "invitees": ["ICLR.cc/2018/Workshop/Paper350/Reviewers"], "noninvitees": ["ICLR.cc/2018/Workshop/Paper350/AnonReviewer1", "ICLR.cc/2018/Workshop/Paper350/AnonReviewer3", "ICLR.cc/2018/Workshop/Paper350/AnonReviewer2"], "reply": {"forum": "rJWF0Fywf", "replyto": "rJWF0Fywf", "writers": {"values-regex": "ICLR.cc/2018/Workshop/Paper350/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2018/Workshop/Paper350/AnonReviewer[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"required": true, "order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"required": true, "order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "value-regex": "[\\S\\s]{1,200000}"}, "rating": {"required": true, "order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"required": true, "order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1528433999000, "cdate": 1521582974703}}}, {"tddate": null, "ddate": null, "original": null, "tmdate": 1521582757813, "tcdate": 1520646470789, "number": 2, "cdate": 1520646470789, "id": "SyJUY2lYf", "invitation": "ICLR.cc/2018/Workshop/-/Paper350/Official_Review", "forum": "rJWF0Fywf", "replyto": "rJWF0Fywf", "signatures": ["ICLR.cc/2018/Workshop/Paper350/AnonReviewer3"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Workshop/Paper350/AnonReviewer3"], "content": {"title": "Important questions are raised but few answers are given", "rating": "7: Good paper, accept", "review": "As we have seen in the replication crisis in many scientific areas, good incentives and good institutional structures are critical to scientific work.  This paper presents a welcome perspective and will yield a welcome discussion on this topic.\n\nI would say that the paper raises important questions and points of discussion but offers few tenable answers.\n\nThis is an interesting proposition: \"Papers that only show wins are potentially suspect and may be rejected for that reason alone.\"\n\nBut laying out standards for best practice is different from creating institutional incentives that support these best practices.\n\nWe need conferences and journals to enforce what we think are the best practices in the field.  E.g., the Journal of Experimental Psychology has adopted stringent requirements for papers submitted to the journal.  Your paper is not accepted for review unless it meets the basic standards outlined.\n\nThe Options for Paper Structure seem a bit half-baked. Submitting python notebooks along with a paper seems fine, but there is definitely value to the written word. Many people will not be interested enough in your paper to dig into the details, but some will, and we should accommodate both types of readers as best as possible.\n\nNo reasonable solutions are offered for the credit assignment problem. Granted, it's a hard problem.\n\nI think it's good to discuss these problems, but more work is needed to find viable interventions.", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Winner's Curse?  On Pace, Progress, and Empirical Rigor", "abstract": "The field of ML is distinguished both by rapid innovation and rapid dissemination of results. While the pace of progress has been extraordinary by any measure, in this paper we explore potential issues that we believe to be arising as a result.  In particular, we observe that the rate of empirical advancement may not have been matched by consistent increase in the level of empirical rigor across the field as a whole.  This short position paper highlights examples where progress has actually been slowed as a result, offers thoughts on incentive structures currently at play, and gives suggestions as seeds for discussions on productive change.", "paperhash": "sculley|winners_curse_on_pace_progress_and_empirical_rigor", "keywords": ["empirical rigor"], "_bibtex": "@misc{\n  sculley2018winner's,\n  title={Winner's Curse?  On Pace, Progress, and Empirical Rigor},\n  author={D. Sculley and Jasper Snoek and Alex Wiltschko and Ali Rahimi},\n  year={2018},\n  url={https://openreview.net/forum?id=rJWF0Fywf}\n}", "authorids": ["dsculley@google.com", "jsnoek@google.com", "alexbw@google.com", "arahimi@google.com"], "authors": ["D. Sculley", "Jasper Snoek", "Alex Wiltschko", "Ali Rahimi"], "TL;DR": "A position paper on empirical rigor in machine learning, meant to foster a discussion on the subject.", "pdf": "/pdf/c6e508deffc243a3de6489be3868264961df6fe3.pdf"}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1520657999000, "tmdate": 1521582974703, "id": "ICLR.cc/2018/Workshop/-/Paper350/Official_Review", "writers": ["ICLR.cc/2018/Workshop"], "signatures": ["ICLR.cc/2018/Workshop"], "readers": ["everyone"], "invitees": ["ICLR.cc/2018/Workshop/Paper350/Reviewers"], "noninvitees": ["ICLR.cc/2018/Workshop/Paper350/AnonReviewer1", "ICLR.cc/2018/Workshop/Paper350/AnonReviewer3", "ICLR.cc/2018/Workshop/Paper350/AnonReviewer2"], "reply": {"forum": "rJWF0Fywf", "replyto": "rJWF0Fywf", "writers": {"values-regex": "ICLR.cc/2018/Workshop/Paper350/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2018/Workshop/Paper350/AnonReviewer[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"required": true, "order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"required": true, "order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "value-regex": "[\\S\\s]{1,200000}"}, "rating": {"required": true, "order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"required": true, "order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1528433999000, "cdate": 1521582974703}}}, {"tddate": null, "ddate": null, "original": null, "tmdate": 1521582597080, "tcdate": 1521014451456, "number": 3, "cdate": 1521014451456, "id": "SkihUI8tM", "invitation": "ICLR.cc/2018/Workshop/-/Paper350/Official_Review", "forum": "rJWF0Fywf", "replyto": "rJWF0Fywf", "signatures": ["ICLR.cc/2018/Workshop/Paper350/AnonReviewer2"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Workshop/Paper350/AnonReviewer2"], "content": {"title": "Much needed position paper", "rating": "9: Top 15% of accepted papers, strong accept", "review": "This is a nicely written position paper that points out many important aspects of the current  state of empirical rigor and analysis present in the ML field. Authors highlight very important (if not critical for the true advancement of science) aspects (mainly issues) related to the empirical studies conducted and reported in the recent past. \nAuthors emphasize that the lack of standards in empirical rigor is a most recent trend. It would be good to talk about how recent is most recent. \nIn the last part of the paper authors give suggestions on how improvement could be made. I don't certainly agree with some of the ideas in full. In general I find it appealing that the authors list and describe specific ideas through which improvements could be made. As they point out these are suggestions for further discussions. \nFor example, the idea of enabling appendix where each author's contribution would be summarized. Authors could contribute on many levels including discussions where ideas could be spurred which won't necessarily be implemented by the same person that originally came up with that idea. I doubt that could be easily summarized. \n\nI find it especially important that the authors emphasize the standards for reviews and reviewers. In regards to enforcing higher review standards I would encourage the authors to discuss the idea of having a proper \"training\" of reviewers that goes beyond having a single \"guidelines\" page provided by the conference organizers. Perhaps even a short conference specific online course that each reviewer ought to take prior to reviewing. Such a course would ensure that all reviewers would properly familiarize themselves and abide to the conference standards. Even if better tools are created for the reviewers there are no guarantees that reviewers would make proper use of the them unless they are properly instructed - an online course could certainly help with that as well.\n", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Winner's Curse?  On Pace, Progress, and Empirical Rigor", "abstract": "The field of ML is distinguished both by rapid innovation and rapid dissemination of results. While the pace of progress has been extraordinary by any measure, in this paper we explore potential issues that we believe to be arising as a result.  In particular, we observe that the rate of empirical advancement may not have been matched by consistent increase in the level of empirical rigor across the field as a whole.  This short position paper highlights examples where progress has actually been slowed as a result, offers thoughts on incentive structures currently at play, and gives suggestions as seeds for discussions on productive change.", "paperhash": "sculley|winners_curse_on_pace_progress_and_empirical_rigor", "keywords": ["empirical rigor"], "_bibtex": "@misc{\n  sculley2018winner's,\n  title={Winner's Curse?  On Pace, Progress, and Empirical Rigor},\n  author={D. Sculley and Jasper Snoek and Alex Wiltschko and Ali Rahimi},\n  year={2018},\n  url={https://openreview.net/forum?id=rJWF0Fywf}\n}", "authorids": ["dsculley@google.com", "jsnoek@google.com", "alexbw@google.com", "arahimi@google.com"], "authors": ["D. Sculley", "Jasper Snoek", "Alex Wiltschko", "Ali Rahimi"], "TL;DR": "A position paper on empirical rigor in machine learning, meant to foster a discussion on the subject.", "pdf": "/pdf/c6e508deffc243a3de6489be3868264961df6fe3.pdf"}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1520657999000, "tmdate": 1521582974703, "id": "ICLR.cc/2018/Workshop/-/Paper350/Official_Review", "writers": ["ICLR.cc/2018/Workshop"], "signatures": ["ICLR.cc/2018/Workshop"], "readers": ["everyone"], "invitees": ["ICLR.cc/2018/Workshop/Paper350/Reviewers"], "noninvitees": ["ICLR.cc/2018/Workshop/Paper350/AnonReviewer1", "ICLR.cc/2018/Workshop/Paper350/AnonReviewer3", "ICLR.cc/2018/Workshop/Paper350/AnonReviewer2"], "reply": {"forum": "rJWF0Fywf", "replyto": "rJWF0Fywf", "writers": {"values-regex": "ICLR.cc/2018/Workshop/Paper350/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2018/Workshop/Paper350/AnonReviewer[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"required": true, "order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"required": true, "order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "value-regex": "[\\S\\s]{1,200000}"}, "rating": {"required": true, "order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"required": true, "order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1528433999000, "cdate": 1521582974703}}}, {"tddate": null, "ddate": null, "original": null, "tmdate": 1521573546465, "tcdate": 1521573546465, "number": 15, "cdate": 1521573546127, "id": "S1M2A0AFM", "invitation": "ICLR.cc/2018/Workshop/-/Acceptance_Decision", "forum": "rJWF0Fywf", "replyto": "rJWF0Fywf", "signatures": ["ICLR.cc/2018/Workshop/Program_Chairs"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Workshop/Program_Chairs"], "content": {"decision": "Accept", "title": "ICLR 2018 Workshop Acceptance Decision", "comment": "Congratulations, your paper was accepted to the ICLR workshop."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Winner's Curse?  On Pace, Progress, and Empirical Rigor", "abstract": "The field of ML is distinguished both by rapid innovation and rapid dissemination of results. While the pace of progress has been extraordinary by any measure, in this paper we explore potential issues that we believe to be arising as a result.  In particular, we observe that the rate of empirical advancement may not have been matched by consistent increase in the level of empirical rigor across the field as a whole.  This short position paper highlights examples where progress has actually been slowed as a result, offers thoughts on incentive structures currently at play, and gives suggestions as seeds for discussions on productive change.", "paperhash": "sculley|winners_curse_on_pace_progress_and_empirical_rigor", "keywords": ["empirical rigor"], "_bibtex": "@misc{\n  sculley2018winner's,\n  title={Winner's Curse?  On Pace, Progress, and Empirical Rigor},\n  author={D. Sculley and Jasper Snoek and Alex Wiltschko and Ali Rahimi},\n  year={2018},\n  url={https://openreview.net/forum?id=rJWF0Fywf}\n}", "authorids": ["dsculley@google.com", "jsnoek@google.com", "alexbw@google.com", "arahimi@google.com"], "authors": ["D. Sculley", "Jasper Snoek", "Alex Wiltschko", "Ali Rahimi"], "TL;DR": "A position paper on empirical rigor in machine learning, meant to foster a discussion on the subject.", "pdf": "/pdf/c6e508deffc243a3de6489be3868264961df6fe3.pdf"}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "tmdate": 1518629844880, "id": "ICLR.cc/2018/Workshop/-/Acceptance_Decision", "writers": ["ICLR.cc/2018/Workshop"], "signatures": ["ICLR.cc/2018/Workshop"], "readers": ["everyone"], "invitees": ["ICLR.cc/2018/Workshop/Program_Chairs"], "reply": {"forum": null, "replyto": null, "invitation": "ICLR.cc/2018/Workshop/-/Submission", "writers": {"values": ["ICLR.cc/2018/Workshop/Program_Chairs"]}, "signatures": {"description": "How your identity will be displayed with the above content.", "values": ["ICLR.cc/2018/Workshop/Program_Chairs"]}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["ICLR.cc/2018/Workshop/Program_Chairs", "everyone"]}, "content": {"title": {"required": true, "order": 1, "value": "ICLR 2018 Workshop Acceptance Decision"}, "comment": {"required": false, "order": 3, "description": "(optional) Comment on this decision.", "value-regex": "[\\S\\s]{0,5000}"}, "decision": {"required": true, "order": 2, "value-dropdown": ["Accept", "Reject"]}}}, "nonreaders": [], "noninvitees": [], "cdate": 1518629844880}}}, {"tddate": null, "ddate": null, "tmdate": 1520353874751, "tcdate": 1520353874751, "number": 4, "cdate": 1520353874751, "id": "Hyi8zS3uG", "invitation": "ICLR.cc/2018/Workshop/-/Paper350/Public_Comment", "forum": "rJWF0Fywf", "replyto": "rkjp7e2df", "signatures": ["~D._Sculley1"], "readers": ["everyone"], "writers": ["~D._Sculley1"], "content": {"title": "thanks for the thoughtful comment", "comment": "Thanks for this thoughtful comment.  I think we totally agree here -- releasing research code is a key step, and we should find additional structural incentives to reward (or potentially require) this as part of publication.\n\nFor what it's worth, the only additional comment I'd make here is that this may not be enough, as ML code without data is only part of the story.  So in the paper, we prefer to go a step further and ask / reward / require not just code, but also data and analysis that accompany experiments.  This is the motivation behind our suggestion to begin considering alternative paper formats such as smart notebooks (like iPython and CoLaboratory) as first-class publication media.  But I agree more can be said here to emphasize this important point."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Winner's Curse?  On Pace, Progress, and Empirical Rigor", "abstract": "The field of ML is distinguished both by rapid innovation and rapid dissemination of results. While the pace of progress has been extraordinary by any measure, in this paper we explore potential issues that we believe to be arising as a result.  In particular, we observe that the rate of empirical advancement may not have been matched by consistent increase in the level of empirical rigor across the field as a whole.  This short position paper highlights examples where progress has actually been slowed as a result, offers thoughts on incentive structures currently at play, and gives suggestions as seeds for discussions on productive change.", "paperhash": "sculley|winners_curse_on_pace_progress_and_empirical_rigor", "keywords": ["empirical rigor"], "_bibtex": "@misc{\n  sculley2018winner's,\n  title={Winner's Curse?  On Pace, Progress, and Empirical Rigor},\n  author={D. Sculley and Jasper Snoek and Alex Wiltschko and Ali Rahimi},\n  year={2018},\n  url={https://openreview.net/forum?id=rJWF0Fywf}\n}", "authorids": ["dsculley@google.com", "jsnoek@google.com", "alexbw@google.com", "arahimi@google.com"], "authors": ["D. Sculley", "Jasper Snoek", "Alex Wiltschko", "Ali Rahimi"], "TL;DR": "A position paper on empirical rigor in machine learning, meant to foster a discussion on the subject.", "pdf": "/pdf/c6e508deffc243a3de6489be3868264961df6fe3.pdf"}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "tmdate": 1518712622563, "id": "ICLR.cc/2018/Workshop/-/Paper350/Public_Comment", "writers": ["ICLR.cc/2018/Workshop"], "signatures": ["ICLR.cc/2018/Workshop"], "readers": ["everyone"], "invitees": ["~"], "noninvitees": ["ICLR.cc/2018/Workshop/Paper350/Reviewers"], "reply": {"replyto": null, "forum": "rJWF0Fywf", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone"]}, "content": {"title": {"required": true, "order": 0, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"required": true, "order": 1, "description": "Your comment or reply (max 5000 characters).", "value-regex": "[\\S\\s]{1,5000}"}}}, "nonreaders": [], "cdate": 1518712622563}}}, {"tddate": null, "ddate": null, "tmdate": 1520333762611, "tcdate": 1520333762611, "number": 3, "cdate": 1520333762611, "id": "rkjp7e2df", "invitation": "ICLR.cc/2018/Workshop/-/Paper350/Public_Comment", "forum": "rJWF0Fywf", "replyto": "rJWF0Fywf", "signatures": ["~Frank_Hutter1"], "readers": ["everyone"], "writers": ["~Frank_Hutter1"], "content": {"title": "Thanks, these are important topics! Should also mention reproducibility / making available code", "comment": "Thanks a lot for writing this paper, I believe it is important that these points are made.\n\nI strongly believe that one additional point should be made, though: reproducibility / making available code.\nSo much of our algorithms' performance depends on their implementation, and the full details are *never* in the paper, even if the authors have the best of intentions. The only way to ensure reproducible research is therefore to make available code. In contrast to basically all other sciences, in computer science we have a great opportunity: for us, it is trivial to make results reproducible, by simply making code available. (Even in the extreme case of requiring 450 GPUs for a week, there likely exists at least one other group who could directly reproduce the results.)\n\nAt the same time, note that the incentive system with respect to releasing code is completely broken. \nTake two hypothetical research labs A and B that both work on the same topic. A makes all their code available for reproducibility; B doesn't. This immediately provides B a competitive advantage because they can put all of A's advances into their code, whereas A cannot use any of B's advances, because that would entail reproducing B's work first. Writing a paper combining A+B's work will therefore be trivial for B and almost impossible for A. So, there is no incentive for B to change their policy and make code available, but there is actually incentive for A to change their policy and *stop* making their code available. This is a clear example of the prisoners' dilemma.\n\nDeep learning thrives because a lot of people are still making available code for their research. But unfortunately, most of the big research labs are of type B and don't make their research code available. (They have made a lot of fantastic framework code available, and for that I am very thankful! The argument I'm making here is purely about research code.) The typical argument made by authors at industrial research labs, even those with the best of intentions, is that their research code depends on too many company-internal packages or specific compute infrastructure, and nobody else could get it to run. However, if the incentive system was such that making code available is rewarded, this would change immediately. Say, all of NIPS, ICML, and ICLR decided that they only publish papers for which code is available to reproduce all experiments in the paper. I strongly believe that within a year all research labs would then find ways to make their code available. They simply would have to in order to keep the best researchers. That's the power of incentive systems. \n\nI'm not proposing to do this against companies, but *with them*. I fully understand that industrial research labs need to keep in mind who pays their bills and can't just give all their code away to competitors. But I believe that could be solved by appropriate licenses; e.g., a license that allows free use for non-commercial purposes would fully suffice for reproducibility but still guard against other companies using the code for their products. \n\nI think it would improve the paper to address this issue of reproducibility. \nThanks for an important call for more empirical rigor in the community!"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Winner's Curse?  On Pace, Progress, and Empirical Rigor", "abstract": "The field of ML is distinguished both by rapid innovation and rapid dissemination of results. While the pace of progress has been extraordinary by any measure, in this paper we explore potential issues that we believe to be arising as a result.  In particular, we observe that the rate of empirical advancement may not have been matched by consistent increase in the level of empirical rigor across the field as a whole.  This short position paper highlights examples where progress has actually been slowed as a result, offers thoughts on incentive structures currently at play, and gives suggestions as seeds for discussions on productive change.", "paperhash": "sculley|winners_curse_on_pace_progress_and_empirical_rigor", "keywords": ["empirical rigor"], "_bibtex": "@misc{\n  sculley2018winner's,\n  title={Winner's Curse?  On Pace, Progress, and Empirical Rigor},\n  author={D. Sculley and Jasper Snoek and Alex Wiltschko and Ali Rahimi},\n  year={2018},\n  url={https://openreview.net/forum?id=rJWF0Fywf}\n}", "authorids": ["dsculley@google.com", "jsnoek@google.com", "alexbw@google.com", "arahimi@google.com"], "authors": ["D. Sculley", "Jasper Snoek", "Alex Wiltschko", "Ali Rahimi"], "TL;DR": "A position paper on empirical rigor in machine learning, meant to foster a discussion on the subject.", "pdf": "/pdf/c6e508deffc243a3de6489be3868264961df6fe3.pdf"}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "tmdate": 1518712622563, "id": "ICLR.cc/2018/Workshop/-/Paper350/Public_Comment", "writers": ["ICLR.cc/2018/Workshop"], "signatures": ["ICLR.cc/2018/Workshop"], "readers": ["everyone"], "invitees": ["~"], "noninvitees": ["ICLR.cc/2018/Workshop/Paper350/Reviewers"], "reply": {"replyto": null, "forum": "rJWF0Fywf", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone"]}, "content": {"title": {"required": true, "order": 0, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"required": true, "order": 1, "description": "Your comment or reply (max 5000 characters).", "value-regex": "[\\S\\s]{1,5000}"}}}, "nonreaders": [], "cdate": 1518712622563}}}, {"tddate": null, "ddate": null, "tmdate": 1520019294934, "tcdate": 1520019294934, "number": 2, "cdate": 1520019294934, "id": "S1vDvQvOf", "invitation": "ICLR.cc/2018/Workshop/-/Paper350/Public_Comment", "forum": "rJWF0Fywf", "replyto": "BymnmRBdz", "signatures": ["~Jasper_Snoek1"], "readers": ["everyone"], "writers": ["~Jasper_Snoek1"], "content": {"title": "Thanks for the reference", "comment": "Thanks for the feedback.  This seems relevant and we'll add it as a citation in the paper!"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Winner's Curse?  On Pace, Progress, and Empirical Rigor", "abstract": "The field of ML is distinguished both by rapid innovation and rapid dissemination of results. While the pace of progress has been extraordinary by any measure, in this paper we explore potential issues that we believe to be arising as a result.  In particular, we observe that the rate of empirical advancement may not have been matched by consistent increase in the level of empirical rigor across the field as a whole.  This short position paper highlights examples where progress has actually been slowed as a result, offers thoughts on incentive structures currently at play, and gives suggestions as seeds for discussions on productive change.", "paperhash": "sculley|winners_curse_on_pace_progress_and_empirical_rigor", "keywords": ["empirical rigor"], "_bibtex": "@misc{\n  sculley2018winner's,\n  title={Winner's Curse?  On Pace, Progress, and Empirical Rigor},\n  author={D. Sculley and Jasper Snoek and Alex Wiltschko and Ali Rahimi},\n  year={2018},\n  url={https://openreview.net/forum?id=rJWF0Fywf}\n}", "authorids": ["dsculley@google.com", "jsnoek@google.com", "alexbw@google.com", "arahimi@google.com"], "authors": ["D. Sculley", "Jasper Snoek", "Alex Wiltschko", "Ali Rahimi"], "TL;DR": "A position paper on empirical rigor in machine learning, meant to foster a discussion on the subject.", "pdf": "/pdf/c6e508deffc243a3de6489be3868264961df6fe3.pdf"}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "tmdate": 1518712622563, "id": "ICLR.cc/2018/Workshop/-/Paper350/Public_Comment", "writers": ["ICLR.cc/2018/Workshop"], "signatures": ["ICLR.cc/2018/Workshop"], "readers": ["everyone"], "invitees": ["~"], "noninvitees": ["ICLR.cc/2018/Workshop/Paper350/Reviewers"], "reply": {"replyto": null, "forum": "rJWF0Fywf", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone"]}, "content": {"title": {"required": true, "order": 0, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"required": true, "order": 1, "description": "Your comment or reply (max 5000 characters).", "value-regex": "[\\S\\s]{1,5000}"}}}, "nonreaders": [], "cdate": 1518712622563}}}, {"tddate": null, "ddate": null, "tmdate": 1519932330823, "tcdate": 1519932330823, "number": 1, "cdate": 1519932330823, "id": "BymnmRBdz", "invitation": "ICLR.cc/2018/Workshop/-/Paper350/Public_Comment", "forum": "rJWF0Fywf", "replyto": "rJWF0Fywf", "signatures": ["(anonymous)"], "readers": ["everyone"], "writers": ["(anonymous)"], "content": {"title": "thanks for the perspective", "comment": "Thanks so much for writing this paper and sharing these perspectives! One important work that aimed to established rigor, but is not mentioned in this paper, is [1]. In this work, the authors show that many of the popular benchmark tasks used in hundreds of deep reinforcement learning papers, can in fact be solved with linear policies or policies using random features. This is probably the perfect illustration of jumping the gun -- trying neural networks without trying linear regression, and also very much in line with what the authors of this ICLR submission are attempting to illustrate.\n\n[1] Rajeswaran et al. Towards Generalization and Simplicity in Continuous Control, NIPS 2017."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Winner's Curse?  On Pace, Progress, and Empirical Rigor", "abstract": "The field of ML is distinguished both by rapid innovation and rapid dissemination of results. While the pace of progress has been extraordinary by any measure, in this paper we explore potential issues that we believe to be arising as a result.  In particular, we observe that the rate of empirical advancement may not have been matched by consistent increase in the level of empirical rigor across the field as a whole.  This short position paper highlights examples where progress has actually been slowed as a result, offers thoughts on incentive structures currently at play, and gives suggestions as seeds for discussions on productive change.", "paperhash": "sculley|winners_curse_on_pace_progress_and_empirical_rigor", "keywords": ["empirical rigor"], "_bibtex": "@misc{\n  sculley2018winner's,\n  title={Winner's Curse?  On Pace, Progress, and Empirical Rigor},\n  author={D. Sculley and Jasper Snoek and Alex Wiltschko and Ali Rahimi},\n  year={2018},\n  url={https://openreview.net/forum?id=rJWF0Fywf}\n}", "authorids": ["dsculley@google.com", "jsnoek@google.com", "alexbw@google.com", "arahimi@google.com"], "authors": ["D. Sculley", "Jasper Snoek", "Alex Wiltschko", "Ali Rahimi"], "TL;DR": "A position paper on empirical rigor in machine learning, meant to foster a discussion on the subject.", "pdf": "/pdf/c6e508deffc243a3de6489be3868264961df6fe3.pdf"}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "tmdate": 1518712622563, "id": "ICLR.cc/2018/Workshop/-/Paper350/Public_Comment", "writers": ["ICLR.cc/2018/Workshop"], "signatures": ["ICLR.cc/2018/Workshop"], "readers": ["everyone"], "invitees": ["~"], "noninvitees": ["ICLR.cc/2018/Workshop/Paper350/Reviewers"], "reply": {"replyto": null, "forum": "rJWF0Fywf", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone"]}, "content": {"title": {"required": true, "order": 0, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"required": true, "order": 1, "description": "Your comment or reply (max 5000 characters).", "value-regex": "[\\S\\s]{1,5000}"}}}, "nonreaders": [], "cdate": 1518712622563}}}], "count": 10}