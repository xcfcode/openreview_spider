{"notes": [{"id": "yOQbCLSWg0b", "original": "8ptLse-QXB0", "number": 8, "cdate": 1615595597794, "ddate": null, "tcdate": 1615595597794, "tmdate": 1615844206969, "tddate": null, "forum": "yOQbCLSWg0b", "replyto": null, "invitation": "ICLR.cc/2021/Workshop/Learning_to_Learn/-/Blind_Submission", "content": {"title": "Exploring the Similarity of Representations in Model-Agnostic Meta-Learning", "authorids": ["ICLR.cc/2021/Workshop/Learning_to_Learn/Paper8/Authors"], "authors": ["Anonymous"], "keywords": [], "abstract": "In past years model-agnostic meta-learning (MAML) has been one of the most promising approaches in meta-learning. It can be applied to different kinds of problems, e.g., reinforcement learning, but also shows good results on few-shot learning tasks. \nBesides their tremendous success in these tasks, it has still not been fully revealed yet, why it performs work so well. Recent work proposes that MAML rather reuses features than rapidly learns. \nTo analyze MAML, we apply representation similarity analysis (RSA), a well-established method in neuroscience, to the few-shot learning instantiation of it. \nAlthough some part of our analysis supports their general results that feature reuse is predominant, we also reveal that the representations after inner gradient steps make a broader change to the representation than the changes during meta-training. This supports the opposite proposition that MAML rapidly learns.", "pdf": "/pdf/7653a09a10a89ab46b8ed8d241f82174996638dd.pdf", "proposed_reviewers": "", "paperhash": "anonymous|exploring_the_similarity_of_representations_in_modelagnostic_metalearning", "_bibtex": "@inproceedings{\nanonymous2021exploring,\ntitle={Exploring the Similarity of Representations in Model-Agnostic Meta-Learning},\nauthor={Anonymous},\nbooktitle={Submitted to Learning to Learn - Workshop at ICLR 2021},\nyear={2021},\nurl={https://openreview.net/forum?id=yOQbCLSWg0b},\nnote={under review}\n}"}, "signatures": ["ICLR.cc/2021/Workshop/Learning_to_Learn"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Workshop/Learning_to_Learn"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "tags": [], "invitation": {"reply": {"readers": {"values-regex": ".*"}, "writers": {"values": ["ICLR.cc/2021/Workshop/Learning_to_Learn"]}, "signatures": {"values": ["ICLR.cc/2021/Workshop/Learning_to_Learn"]}, "content": {"authors": {"values": ["Anonymous"]}, "authorids": {"values-regex": ".*"}, "proposed_reviewers": {"value-regex": ".*"}}}, "signatures": ["ICLR.cc/2021/Workshop/Learning_to_Learn"], "readers": ["everyone"], "writers": ["ICLR.cc/2021/Workshop/Learning_to_Learn"], "invitees": ["~", "OpenReview.net/Support"], "tcdate": 1615595596483, "tmdate": 1615844205826, "id": "ICLR.cc/2021/Workshop/Learning_to_Learn/-/Blind_Submission"}}, "tauthor": "~Super_User1"}], "count": 1}