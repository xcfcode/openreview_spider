{"notes": [{"id": "eQe8DEWNN2W", "original": "l7qw2YjPlVf", "number": 812, "cdate": 1601308094005, "ddate": null, "tcdate": 1601308094005, "tmdate": 1615962463946, "tddate": null, "forum": "eQe8DEWNN2W", "replyto": null, "invitation": "ICLR.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Calibration of Neural Networks using Splines", "authorids": ["~Kartik_Gupta2", "~Amir_Rahimi1", "~Thalaiyasingam_Ajanthan1", "~Thomas_Mensink1", "~Cristian_Sminchisescu1", "~Richard_Hartley1"], "authors": ["Kartik Gupta", "Amir Rahimi", "Thalaiyasingam Ajanthan", "Thomas Mensink", "Cristian Sminchisescu", "Richard Hartley"], "keywords": ["neural network calibration", "uncertainty", "calibration measure"], "abstract": "Calibrating neural networks is of utmost importance when employing them in safety-critical applications where the downstream decision making depends on the predicted probabilities. Measuring calibration error amounts to comparing two empirical distributions. In this work, we introduce a binning-free calibration measure inspired by the classical Kolmogorov-Smirnov (KS) statistical test in which the main idea is to compare the respective cumulative probability distributions. From this, by approximating the empirical cumulative distribution using a differentiable function via splines, we obtain a recalibration function, which maps the network outputs to actual (calibrated) class assignment probabilities. The spline-fitting is performed using a held-out calibration set and the obtained recalibration function is evaluated on an unseen test set. We tested our method against existing calibration approaches on various image classification datasets and our spline-based recalibration approach consistently outperforms existing methods on KS error as well as other commonly used calibration measures. Code is available online at https://github.com/kartikgupta-at-anu/spline-calibration.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "gupta|calibration_of_neural_networks_using_splines", "one-sentence_summary": "We introduce a binning-free calibration measure inspired by the classical Kolmogorov-Smirnov statistical test and obtain a recalibration function by approximating the empirical cumulative distribution using a differentiable function via splines.", "supplementary_material": "/attachment/8d30e322ef8da40e311ef60e33ebe0d48f7fb2d1.zip", "pdf": "/pdf/9b7a1091871efa36fec2c10f52c8cef289c89a5f.pdf", "venue": "ICLR 2021 Poster", "venueid": "ICLR.cc/2021/Conference", "_bibtex": "@inproceedings{\ngupta2021calibration,\ntitle={Calibration of Neural Networks using Splines},\nauthor={Kartik Gupta and Amir Rahimi and Thalaiyasingam Ajanthan and Thomas Mensink and Cristian Sminchisescu and Richard Hartley},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=eQe8DEWNN2W}\n}"}, "signatures": ["ICLR.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference"], "details": {"replyCount": 14, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"reply": {"readers": {"values-regex": ".*"}, "writers": {"values": ["ICLR.cc/2021/Conference"]}, "signatures": {"values": ["ICLR.cc/2021/Conference"]}, "content": {"authors": {"values": ["Anonymous"]}, "authorids": {"values-regex": ".*"}, "reviewed_version_(pdf)": {"required": false, "description": "Upload a PDF file that ends with .pdf", "value-regex": ".*"}}}, "signatures": ["ICLR.cc/2021/Conference"], "readers": ["everyone"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["~", "OpenReview.net/Support"], "tcdate": 1601308008205, "tmdate": 1614984599368, "id": "ICLR.cc/2021/Conference/-/Blind_Submission"}}, "tauthor": "OpenReview.net"}, {"id": "FQBI6-dLOz", "original": null, "number": 1, "cdate": 1610040441392, "ddate": null, "tcdate": 1610040441392, "tmdate": 1610474042432, "tddate": null, "forum": "eQe8DEWNN2W", "replyto": "eQe8DEWNN2W", "invitation": "ICLR.cc/2021/Conference/Paper812/-/Decision", "content": {"title": "Final Decision", "decision": "Accept (Poster)", "comment": "Many papers have been written on calibrating neural networks recently.  This paper presents a definition of calibration that is more robust than the popular ECE measure while also being more discerning than the Brier score.  Then it proposes a practical spline-based method of post-editing the output softmax scores to make them more calibrated.  The method is shown to be better than existing methods both on their measure and established measure (thanks to reviewer's questions on that.).\nThe paper should be of much interest to the community."}, "signatures": ["ICLR.cc/2021/Conference/Program_Chairs"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference/Program_Chairs"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Calibration of Neural Networks using Splines", "authorids": ["~Kartik_Gupta2", "~Amir_Rahimi1", "~Thalaiyasingam_Ajanthan1", "~Thomas_Mensink1", "~Cristian_Sminchisescu1", "~Richard_Hartley1"], "authors": ["Kartik Gupta", "Amir Rahimi", "Thalaiyasingam Ajanthan", "Thomas Mensink", "Cristian Sminchisescu", "Richard Hartley"], "keywords": ["neural network calibration", "uncertainty", "calibration measure"], "abstract": "Calibrating neural networks is of utmost importance when employing them in safety-critical applications where the downstream decision making depends on the predicted probabilities. Measuring calibration error amounts to comparing two empirical distributions. In this work, we introduce a binning-free calibration measure inspired by the classical Kolmogorov-Smirnov (KS) statistical test in which the main idea is to compare the respective cumulative probability distributions. From this, by approximating the empirical cumulative distribution using a differentiable function via splines, we obtain a recalibration function, which maps the network outputs to actual (calibrated) class assignment probabilities. The spline-fitting is performed using a held-out calibration set and the obtained recalibration function is evaluated on an unseen test set. We tested our method against existing calibration approaches on various image classification datasets and our spline-based recalibration approach consistently outperforms existing methods on KS error as well as other commonly used calibration measures. Code is available online at https://github.com/kartikgupta-at-anu/spline-calibration.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "gupta|calibration_of_neural_networks_using_splines", "one-sentence_summary": "We introduce a binning-free calibration measure inspired by the classical Kolmogorov-Smirnov statistical test and obtain a recalibration function by approximating the empirical cumulative distribution using a differentiable function via splines.", "supplementary_material": "/attachment/8d30e322ef8da40e311ef60e33ebe0d48f7fb2d1.zip", "pdf": "/pdf/9b7a1091871efa36fec2c10f52c8cef289c89a5f.pdf", "venue": "ICLR 2021 Poster", "venueid": "ICLR.cc/2021/Conference", "_bibtex": "@inproceedings{\ngupta2021calibration,\ntitle={Calibration of Neural Networks using Splines},\nauthor={Kartik Gupta and Amir Rahimi and Thalaiyasingam Ajanthan and Thomas Mensink and Cristian Sminchisescu and Richard Hartley},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=eQe8DEWNN2W}\n}"}, "tags": [], "invitation": {"reply": {"forum": "eQe8DEWNN2W", "replyto": "eQe8DEWNN2W", "readers": {"values": ["everyone"]}, "writers": {"values": ["ICLR.cc/2021/Conference/Program_Chairs"]}, "signatures": {"values": ["ICLR.cc/2021/Conference/Program_Chairs"]}, "content": {"title": {"value": "Final Decision"}, "decision": {"value-radio": ["Accept (Oral)", "Accept (Spotlight)", "Accept (Poster)", "Reject"]}, "comment": {"value-regex": "[\\S\\s]{0,50000}", "markdown": true}}}, "multiReply": false, "signatures": ["ICLR.cc/2021/Conference"], "readers": ["everyone"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Program_Chairs"], "tcdate": 1610040441379, "tmdate": 1610474042416, "id": "ICLR.cc/2021/Conference/Paper812/-/Decision"}}}, {"id": "oebnWdKOUtk", "original": null, "number": 4, "cdate": 1603981139974, "ddate": null, "tcdate": 1603981139974, "tmdate": 1606774512785, "tddate": null, "forum": "eQe8DEWNN2W", "replyto": "eQe8DEWNN2W", "invitation": "ICLR.cc/2021/Conference/Paper812/-/Official_Review", "content": {"title": "Elegant calibration method, beautifully described. Experiments may need more explaining.", "review": "Pros: originality, clarity, technical correctness.\nCons: experiments need some clarifications.\n\nCalibration typically relies heavily on binning the data, both for the calibration itself  (Histogram Binning) and how to measure its quality (ECE). Thus both operations suffer from sampling issues that are a cause for both bias and variance. The idea to rather perform the analysis using cumulative distributions would seem obvious, as it has been tried on so many other problems, but I have not seen it used for calibration. They do it for both calibration and its measure:\n-\tThe use of the Kolmogorov-Smirnov test to measure calibration between the target and the output distributions.\n-\tSpline fitting of the cumulative distribution to compute its derivative\nAs the implementation details are far from obvious , there are several original contributions, especially in implementing the splines.\n\nI found the description both very clear and concise, switching between intuition and equations.\nThe only part I found confusing is the second paragraph of section 4.2 (\u201cOne method of calibration..\u201d). Fortunately, the next paragraph gives a very simple intuitive explanation by just stating how it is implemented.\n\nExperiments are very comprehensive and show improvements over Temp scaling and other methods. However, there are also some results that contradict previously reported experiments and need to be clarified:\n-\tBesides Temp scaling, the main other methods are borrowed from Kull et al, so one could expect some consistency. However ECE results from Table 6 look very different from Table 3 in Kull et al. I assume these are different types of ECE: confidence vs. class-wise? In Table 1, KS result for the ODIR methods of Kull et Al are much worse than Temp scaling, in particular for CIFAR-100 and Imagenet. This contradicts results reported in Table 2 (this paper) and Table 3 (Kull et al) and should be explained.\n\n-\tI am no expert in image classification,  but the 70% accuracy reported for CIFAR-100 seems way below current numbers, which have exceeded 80% since 2017, in particular for the proposed architectures (for instance Wide Resnet or DenseNet) https://benchmarks.ai/cifar-100.  However these numbers seem to be consistent with what is reported by Kull et al (Table 18 in https://arxiv.org/pdf/1910.12656.pdf), so I assume the issue comes from borrowing their architecture and scores. While this should not impact comparative results, it would have been more satisfactory to use baseline architectures that match the state-of-the-art.\n\nAdditional experiments or discussions on the following would greatly help:\n-\tAs the spline method is not always better than Temp scaling, how do they compare from a computational viewpoint? How long does the binary search over thousands of calibration examples take compared to the DNN feed-forward?\n-\tFrom Tables 1,2 and 6, KS error and ECE rank methods quite differently. One reason one should trust KS more is that it does not depend on binning choices, and rely on a time-proven test. But could one come up with an experiment that shows that KS is provably more reliable? \n\nPost rebuttal: I have read the authors responses with to my 4 questions, and appreciate how detailed and honest they are. They satisfy my concerns.\n", "rating": "8: Top 50% of accepted papers, clear accept", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["ICLR.cc/2021/Conference/Paper812/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper812/AnonReviewer2"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Calibration of Neural Networks using Splines", "authorids": ["~Kartik_Gupta2", "~Amir_Rahimi1", "~Thalaiyasingam_Ajanthan1", "~Thomas_Mensink1", "~Cristian_Sminchisescu1", "~Richard_Hartley1"], "authors": ["Kartik Gupta", "Amir Rahimi", "Thalaiyasingam Ajanthan", "Thomas Mensink", "Cristian Sminchisescu", "Richard Hartley"], "keywords": ["neural network calibration", "uncertainty", "calibration measure"], "abstract": "Calibrating neural networks is of utmost importance when employing them in safety-critical applications where the downstream decision making depends on the predicted probabilities. Measuring calibration error amounts to comparing two empirical distributions. In this work, we introduce a binning-free calibration measure inspired by the classical Kolmogorov-Smirnov (KS) statistical test in which the main idea is to compare the respective cumulative probability distributions. From this, by approximating the empirical cumulative distribution using a differentiable function via splines, we obtain a recalibration function, which maps the network outputs to actual (calibrated) class assignment probabilities. The spline-fitting is performed using a held-out calibration set and the obtained recalibration function is evaluated on an unseen test set. We tested our method against existing calibration approaches on various image classification datasets and our spline-based recalibration approach consistently outperforms existing methods on KS error as well as other commonly used calibration measures. Code is available online at https://github.com/kartikgupta-at-anu/spline-calibration.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "gupta|calibration_of_neural_networks_using_splines", "one-sentence_summary": "We introduce a binning-free calibration measure inspired by the classical Kolmogorov-Smirnov statistical test and obtain a recalibration function by approximating the empirical cumulative distribution using a differentiable function via splines.", "supplementary_material": "/attachment/8d30e322ef8da40e311ef60e33ebe0d48f7fb2d1.zip", "pdf": "/pdf/9b7a1091871efa36fec2c10f52c8cef289c89a5f.pdf", "venue": "ICLR 2021 Poster", "venueid": "ICLR.cc/2021/Conference", "_bibtex": "@inproceedings{\ngupta2021calibration,\ntitle={Calibration of Neural Networks using Splines},\nauthor={Kartik Gupta and Amir Rahimi and Thalaiyasingam Ajanthan and Thomas Mensink and Cristian Sminchisescu and Richard Hartley},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=eQe8DEWNN2W}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq . ***Please remember to file the Code-of-Ethics report. Once you submitted the review, a link to the report will be visible in the bottom right corner of your review.***", "required": true, "markdown": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}, "forum": "eQe8DEWNN2W", "replyto": "eQe8DEWNN2W", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"], "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper812/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1607428800000, "duedate": 1606752000000, "multiReply": false, "readers": ["everyone"], "tcdate": 1602538134468, "tmdate": 1606915784161, "super": "ICLR.cc/2021/Conference/-/Official_Review", "signatures": ["OpenReview.net"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Paper812/Reviewers", "OpenReview.net/Support"], "id": "ICLR.cc/2021/Conference/Paper812/-/Official_Review"}}}, {"id": "bdo1zx5yBrX", "original": null, "number": 6, "cdate": 1605871348145, "ddate": null, "tcdate": 1605871348145, "tmdate": 1606181903843, "tddate": null, "forum": "eQe8DEWNN2W", "replyto": "sW1-EF_mcTx", "invitation": "ICLR.cc/2021/Conference/Paper812/-/Official_Comment", "content": {"title": "AR4: Our work is found to be \u201coriginal and elegant\u201d by other reviewers. {Response to AR4 [1/2]}", "comment": "We thank the reviewer for the feedback and we appreciate that the reviewer finds that the introduced binning-free calibration measure is a good idea and our spline fitting method yields better calibration. We would like to emphasize that our method is found to be \u201celegant and technically correct with excellent scientific practice\u201d by the other reviewers and AR2 noted that \u201cthe final method is far from obvious with several original contributions\u201d. Below, we address the reviewer\u2019s concerns and we have added the requested discussions in the updated version of the paper. If any answer requires further clarification to the reviewer, we will make our best effort to improve the clarity.\n\n### The authors should stick to either $x$ or $X$\n- Following the standard notation, $X$ denotes the random variable and $x$ denotes an assignment to the random variable $X$. \n\n### The definition of the KS statistic\n- The standard definition of the KS statistic is given after Eq. 7 and this is the definition that is used in our computation as noted in Eq. 12. \n\n### Confusion with Eq. 8\n- We would like to clarify that _we do not make any assumptions_ and Eq. 8 is only used to provide insights into the KS metric. Specifically, KS metric becomes the same as the expected calibration error if $P(k|z_k) - z_k$ has the same sign for all samples. This case means the scores provided by the network consistently overestimate or underestimate the probability, which is usually the case (see eg., Guo et al). Even though this condition is satisfied in most cases, it is not necessary for our method or for the introduced binning-free calibration metric.\n\n### Why KS statistic and not Wasserstein or calibration slope?\n- KS is chosen over Wasserstein distance, as we are interested in measuring calibration of each class score (or top-k score) individually, ie, *classwise calibration error*. Furthermore, as shown in our paper, KS provides an effective way to obtain a recalibration function using spline fitting. If one wishes to consider the full probability vector, Wasserstein distance may be preferred. Note that we also provided the ECE measure (Table 6) in addition to the KS statistic to show the generality of our method.\n- We\u2019re not sure what is meant by \u201ccalibration slope\u201d.\n\n### Distinct values for $f_k(x_i)$\n- Eq. 11 does _not_ assume distinct values for scores $f_k(x_i)$ and if the scores are equal for two samples ties can be broken arbitrarily.\n\n### Calibration vs accuracy\n- Since our spline based recalibration function is applied after identifying the top-1 score (or in general top-r), technically our method does not alter the classification accuracy. However, even if one wishes to evaluate the classification accuracy after applying the recalibration function, the change in accuracy with spline fitting is negligible (_<0.2%_) and it sometimes even improves the accuracy of the uncalibrated model as noted in Table 5. \n\n### Extending to regression problems\n- We fully agree that calibration of neural networks is important beyond classification. We have highlighted this and included binning free regression calibration as a possible direction for future work. In this work, similar to the majority of the previous works on calibration, we focus on classification problems.\n\n### Temperature scaling vs spline fitting\n- Since calibration is a statistical process, it is possible that in certain circumstances one method may work better than the other. To this end, we are not sure about the reason for temperature scaling being better in some cases. According to our experiments, our method performs better than temperature scaling in most cases.\n\n### Calibration results vary across different networks\n- Different architectures have different calibration properties, for example, Resnet is known to be more prone to be overconfident than Lenet, see (Guo et al.) So, even for the same dataset, different architectures behave differently, have different accuracies and can have different calibration performance.\n\n### Calibrating top-1 vs top-2 predictions \n- The distributions of top-1 and top-2 scores are very different, and we observed that the top-2 scores are very close to 0 in many cases. Since the values are very small, spline fitting may not seem to be as accurate as for the top-1 case. But it is important to note in Table 2 that our method still achieves (_<1%_) calibration error even for top-2 predictions and ranks as the best method in majority of the cases. One could potentially vary the spline fitting parameters (such as the number of knots) to obtain better results. Note, for majority of our experiments only 6 knots are used unless stated otherwise.\n"}, "signatures": ["ICLR.cc/2021/Conference/Paper812/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper812/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Calibration of Neural Networks using Splines", "authorids": ["~Kartik_Gupta2", "~Amir_Rahimi1", "~Thalaiyasingam_Ajanthan1", "~Thomas_Mensink1", "~Cristian_Sminchisescu1", "~Richard_Hartley1"], "authors": ["Kartik Gupta", "Amir Rahimi", "Thalaiyasingam Ajanthan", "Thomas Mensink", "Cristian Sminchisescu", "Richard Hartley"], "keywords": ["neural network calibration", "uncertainty", "calibration measure"], "abstract": "Calibrating neural networks is of utmost importance when employing them in safety-critical applications where the downstream decision making depends on the predicted probabilities. Measuring calibration error amounts to comparing two empirical distributions. In this work, we introduce a binning-free calibration measure inspired by the classical Kolmogorov-Smirnov (KS) statistical test in which the main idea is to compare the respective cumulative probability distributions. From this, by approximating the empirical cumulative distribution using a differentiable function via splines, we obtain a recalibration function, which maps the network outputs to actual (calibrated) class assignment probabilities. The spline-fitting is performed using a held-out calibration set and the obtained recalibration function is evaluated on an unseen test set. We tested our method against existing calibration approaches on various image classification datasets and our spline-based recalibration approach consistently outperforms existing methods on KS error as well as other commonly used calibration measures. Code is available online at https://github.com/kartikgupta-at-anu/spline-calibration.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "gupta|calibration_of_neural_networks_using_splines", "one-sentence_summary": "We introduce a binning-free calibration measure inspired by the classical Kolmogorov-Smirnov statistical test and obtain a recalibration function by approximating the empirical cumulative distribution using a differentiable function via splines.", "supplementary_material": "/attachment/8d30e322ef8da40e311ef60e33ebe0d48f7fb2d1.zip", "pdf": "/pdf/9b7a1091871efa36fec2c10f52c8cef289c89a5f.pdf", "venue": "ICLR 2021 Poster", "venueid": "ICLR.cc/2021/Conference", "_bibtex": "@inproceedings{\ngupta2021calibration,\ntitle={Calibration of Neural Networks using Splines},\nauthor={Kartik Gupta and Amir Rahimi and Thalaiyasingam Ajanthan and Thomas Mensink and Cristian Sminchisescu and Richard Hartley},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=eQe8DEWNN2W}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "eQe8DEWNN2W", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper812/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper812/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper812/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper812/Authors|ICLR.cc/2021/Conference/Paper812/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper812/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923866945, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper812/-/Official_Comment"}}}, {"id": "KC_m55Yd27", "original": null, "number": 4, "cdate": 1605869410283, "ddate": null, "tcdate": 1605869410283, "tmdate": 1606181863353, "tddate": null, "forum": "eQe8DEWNN2W", "replyto": "oebnWdKOUtk", "invitation": "ICLR.cc/2021/Conference/Paper812/-/Official_Comment", "content": {"title": "AR2: Thank you for the positive feedback.", "comment": "We appreciate that the reviewer finds our method to be original, technically correct, and well written. Below, we address the reviewer\u2019s questions/comments on some experiments and we have included these discussions in the updated version of the paper. If any answer needs further clarification to the reviewer, we'll make the best effort to improve the clarity.\n\n### Our results vs Kull et. al. \n- We would like to clarify that our results _do not contradict_ with the results reported in Kull et al. As noted by the reviewer, Kull et. al. only report the average classwise ECE (cw-ECE) in the main paper (Table 3) whereas we report top-1 calibration error. The top-1 ECE results are reported in Table 15 in Kull et. al., which clearly demonstrates that ODIR methods are inferior to temperature scaling in this measure as observed by our experiments. We have made this clear in the updated manuscript, by explicitly referring to Table 15.\n\n### Calibration on state-of-the-art networks\n- As noted by the reviewer, the trained models are obtained from Kull et. al. to be consistent with the reported numbers. Nevertheless, as requested by the reviewer, we compared our method against temperature scaling on a state-of-the-art network i.e. WideResNet-28-10 trained on CIFAR-100 (achieving 80.1% accuracy) and the results are as follows: \n|Calibration Metric|Uncalibrated|Temp. Scaling|Ours(Spline)\n|-|-|-|-|\n|KS (top-1)|0.058367|0.023443|**0.015145**|\n|ECE (25 bins)|0.062159|0.034364|**0.018672**|\n\n### Running time of the spline method\n- The running time of our spline method (also temperature scaling) is negligible compared to one forward pass through the network. The most complex step of our method is sorting which is indeed very efficient. For example, on the calibration set of ImageNet with 25000 images, spline fitting takes only about 0.4 seconds. Note, both temperature scaling and our approach are post-hoc calibration methods that can be applied offline (very efficiently) once logits of the network are stored for calibration set.\n\n### KS vs ECE\n- As discussed in the paper and noted by the reviewer, binning in ECE has multiple issues such as dependency on the number of bins, non-equal number of samples in each bin, etc. Clearly, being independent on the binning scheme, KS is more reliable. We believe designing an experiment to show the reliability of KS is an interesting open research problem and we are unable to provide a concrete answer as of now.\n"}, "signatures": ["ICLR.cc/2021/Conference/Paper812/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper812/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Calibration of Neural Networks using Splines", "authorids": ["~Kartik_Gupta2", "~Amir_Rahimi1", "~Thalaiyasingam_Ajanthan1", "~Thomas_Mensink1", "~Cristian_Sminchisescu1", "~Richard_Hartley1"], "authors": ["Kartik Gupta", "Amir Rahimi", "Thalaiyasingam Ajanthan", "Thomas Mensink", "Cristian Sminchisescu", "Richard Hartley"], "keywords": ["neural network calibration", "uncertainty", "calibration measure"], "abstract": "Calibrating neural networks is of utmost importance when employing them in safety-critical applications where the downstream decision making depends on the predicted probabilities. Measuring calibration error amounts to comparing two empirical distributions. In this work, we introduce a binning-free calibration measure inspired by the classical Kolmogorov-Smirnov (KS) statistical test in which the main idea is to compare the respective cumulative probability distributions. From this, by approximating the empirical cumulative distribution using a differentiable function via splines, we obtain a recalibration function, which maps the network outputs to actual (calibrated) class assignment probabilities. The spline-fitting is performed using a held-out calibration set and the obtained recalibration function is evaluated on an unseen test set. We tested our method against existing calibration approaches on various image classification datasets and our spline-based recalibration approach consistently outperforms existing methods on KS error as well as other commonly used calibration measures. Code is available online at https://github.com/kartikgupta-at-anu/spline-calibration.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "gupta|calibration_of_neural_networks_using_splines", "one-sentence_summary": "We introduce a binning-free calibration measure inspired by the classical Kolmogorov-Smirnov statistical test and obtain a recalibration function by approximating the empirical cumulative distribution using a differentiable function via splines.", "supplementary_material": "/attachment/8d30e322ef8da40e311ef60e33ebe0d48f7fb2d1.zip", "pdf": "/pdf/9b7a1091871efa36fec2c10f52c8cef289c89a5f.pdf", "venue": "ICLR 2021 Poster", "venueid": "ICLR.cc/2021/Conference", "_bibtex": "@inproceedings{\ngupta2021calibration,\ntitle={Calibration of Neural Networks using Splines},\nauthor={Kartik Gupta and Amir Rahimi and Thalaiyasingam Ajanthan and Thomas Mensink and Cristian Sminchisescu and Richard Hartley},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=eQe8DEWNN2W}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "eQe8DEWNN2W", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper812/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper812/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper812/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper812/Authors|ICLR.cc/2021/Conference/Paper812/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper812/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923866945, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper812/-/Official_Comment"}}}, {"id": "YYLb3Y21Wez", "original": null, "number": 8, "cdate": 1605873920356, "ddate": null, "tcdate": 1605873920356, "tmdate": 1606180823101, "tddate": null, "forum": "eQe8DEWNN2W", "replyto": "ThYCYAtWQqC", "invitation": "ICLR.cc/2021/Conference/Paper812/-/Official_Comment", "content": {"title": "AR1: Thank you for the positive feedback.", "comment": "We appreciate that the reviewer finds that our method is a novel solution and the paper follows an excellent scientific writing practice. Below we address the reviewer\u2019s comments. If any answer requires further clarification to the reviewer, we will make our best effort to improve the clarity.\n\n### Python semantics\n- We use the \u201cminus\u201d notation to distinguish top-r score with the r-th class score. So in our notation, f^{(-r)} denotes the r-th top score while f^{(r)} denotes the score of the r-th class.\n\n### Proposition 4.1\n- We agree that Proposition 4.1 echoes the standard relationship between PDF and CDF. However, we think it might not be obvious to all the readers and we wanted to make it absolutely clear by having the proof.\n\n### Other calibration measures\n- We note that ECE results are already reported in Table 6. While we share the same opinion as the reviewer, we want to clarify that Brier score and NLL are not good measures of the calibration error. The reason is that both Brier score and NLL can be zero only if the classification accuracy is 100%, however, it is not necessary for a classifier to have 100% accuracy for it to be perfectly calibrated. Nevertheless, we computed different calibration measures (including the Brier score) on ImageNet for different networks and the results are reported below. In summary, spline fitting outperforms other methods in most cases. We have also reported these results in our updated manuscript in Table 7.\n\n**KDE-ECE**[a]:\n\n|Network|Uncalibrated|Temp. Scaling|MS-ODIR|Dir-ODIR|Ours(Spline)|\n|-|-|-|-|-|-|\n|Densenet-161|0.03786|0.01501|0.02874|0.02979|**0.00637**|\n|Resnet-152|0.04650|0.01864|0.03448|0.03488|**0.00847**|\n\n**MCE (Maximum Calibration Error)**[b]:\n\n|Network|Uncalibrated|Temp. Scaling|MS-ODIR|Dir-ODIR|Ours(Spline)|\n|-|-|-|-|-|-|\n|Densenet-161|0.13123|**0.05442**|0.09077|0.09653|0.06289|\n|Resnet-152|0.15930|0.09051|0.11201|0.09868|**0.04950**|\n\n**BRIER Score**:\n\n|Network|Uncalibrated|Temp. Scaling|MS-ODIR|Dir-ODIR|Ours(Spline)|\n|-|-|-|-|-|-|\n|Densenet-161|0.00033|0.00032|0.00032|0.00032|0.00032|\n|Resnet-152|0.00034|0.00034|0.00033|0.00033|0.00033|\n\n- One can clearly notice that Brier score is almost same for all methods even for uncalibrated models, clearly illustrating it as not a good measure for calibration. This observation is infact not surprising since Brier Score in essence also measures how accurate a function is. Since, we specifically calibrate top-1 scores, we also evaluate top-1 Brier score which is mean squared error between top-1 scores and accuracy and the results are reported as follows:\n\n|Network|Uncalibrated|Temp. Scaling|MS-ODIR|Dir-ODIR|Ours(Spline)|\n|-|-|-|-|-|-|\n|Densenet-161|0.12172|0.11852|0.11982|0.11978|**0.11734**|\n|Resnet-152|0.12626|0.12145|0.12406|0.12308|**0.12034**|\n\n### References\n[a] Jize Zhang, Bhavya Kailkhura, and T Han. \"Mix-n-Match: Ensemble and compositional methods for uncertainty calibration in deep learning.\", ICML 2020,\n\n[b] Chuan Guo, Geoff Pleiss, Yu Sun, and Kilian Q Weinberger. On calibration of modern neural networks. ICML, 2017.\n"}, "signatures": ["ICLR.cc/2021/Conference/Paper812/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper812/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Calibration of Neural Networks using Splines", "authorids": ["~Kartik_Gupta2", "~Amir_Rahimi1", "~Thalaiyasingam_Ajanthan1", "~Thomas_Mensink1", "~Cristian_Sminchisescu1", "~Richard_Hartley1"], "authors": ["Kartik Gupta", "Amir Rahimi", "Thalaiyasingam Ajanthan", "Thomas Mensink", "Cristian Sminchisescu", "Richard Hartley"], "keywords": ["neural network calibration", "uncertainty", "calibration measure"], "abstract": "Calibrating neural networks is of utmost importance when employing them in safety-critical applications where the downstream decision making depends on the predicted probabilities. Measuring calibration error amounts to comparing two empirical distributions. In this work, we introduce a binning-free calibration measure inspired by the classical Kolmogorov-Smirnov (KS) statistical test in which the main idea is to compare the respective cumulative probability distributions. From this, by approximating the empirical cumulative distribution using a differentiable function via splines, we obtain a recalibration function, which maps the network outputs to actual (calibrated) class assignment probabilities. The spline-fitting is performed using a held-out calibration set and the obtained recalibration function is evaluated on an unseen test set. We tested our method against existing calibration approaches on various image classification datasets and our spline-based recalibration approach consistently outperforms existing methods on KS error as well as other commonly used calibration measures. Code is available online at https://github.com/kartikgupta-at-anu/spline-calibration.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "gupta|calibration_of_neural_networks_using_splines", "one-sentence_summary": "We introduce a binning-free calibration measure inspired by the classical Kolmogorov-Smirnov statistical test and obtain a recalibration function by approximating the empirical cumulative distribution using a differentiable function via splines.", "supplementary_material": "/attachment/8d30e322ef8da40e311ef60e33ebe0d48f7fb2d1.zip", "pdf": "/pdf/9b7a1091871efa36fec2c10f52c8cef289c89a5f.pdf", "venue": "ICLR 2021 Poster", "venueid": "ICLR.cc/2021/Conference", "_bibtex": "@inproceedings{\ngupta2021calibration,\ntitle={Calibration of Neural Networks using Splines},\nauthor={Kartik Gupta and Amir Rahimi and Thalaiyasingam Ajanthan and Thomas Mensink and Cristian Sminchisescu and Richard Hartley},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=eQe8DEWNN2W}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "eQe8DEWNN2W", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper812/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper812/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper812/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper812/Authors|ICLR.cc/2021/Conference/Paper812/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper812/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923866945, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper812/-/Official_Comment"}}}, {"id": "IK8EkKPZbj", "original": null, "number": 11, "cdate": 1606176420912, "ddate": null, "tcdate": 1606176420912, "tmdate": 1606176420912, "tddate": null, "forum": "eQe8DEWNN2W", "replyto": "Dzh7nKLwRkU", "invitation": "ICLR.cc/2021/Conference/Paper812/-/Official_Comment", "content": {"title": "Thanks for your interest in our paper.", "comment": "We appreciate that the reader liked our idea of KS based calibration measure. Below we answer the reader's questions.\n\n### Comparisons using KDE-ECE\n- Thanks for pointing us to your paper. We evaluated different calibration methods for networks trained on ImageNet dataset using KDE-ECE. We have added these results in Table 7 in our paper. Under evaluations with KDE-ECE, our method outperforms baseline methods.\n\n### Sensitivity of KS\n- Since KS is the maximum difference between two CDFs, it is quite a robust estimate of calibration error. Infact irrespective of whether the distribution is peaky, KS is the same as the expected calibration error when one CDF consistently lies above the other (that is usually the case), which is what we want to measure. We would welcome any thoughts on this.\n"}, "signatures": ["ICLR.cc/2021/Conference/Paper812/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper812/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Calibration of Neural Networks using Splines", "authorids": ["~Kartik_Gupta2", "~Amir_Rahimi1", "~Thalaiyasingam_Ajanthan1", "~Thomas_Mensink1", "~Cristian_Sminchisescu1", "~Richard_Hartley1"], "authors": ["Kartik Gupta", "Amir Rahimi", "Thalaiyasingam Ajanthan", "Thomas Mensink", "Cristian Sminchisescu", "Richard Hartley"], "keywords": ["neural network calibration", "uncertainty", "calibration measure"], "abstract": "Calibrating neural networks is of utmost importance when employing them in safety-critical applications where the downstream decision making depends on the predicted probabilities. Measuring calibration error amounts to comparing two empirical distributions. In this work, we introduce a binning-free calibration measure inspired by the classical Kolmogorov-Smirnov (KS) statistical test in which the main idea is to compare the respective cumulative probability distributions. From this, by approximating the empirical cumulative distribution using a differentiable function via splines, we obtain a recalibration function, which maps the network outputs to actual (calibrated) class assignment probabilities. The spline-fitting is performed using a held-out calibration set and the obtained recalibration function is evaluated on an unseen test set. We tested our method against existing calibration approaches on various image classification datasets and our spline-based recalibration approach consistently outperforms existing methods on KS error as well as other commonly used calibration measures. Code is available online at https://github.com/kartikgupta-at-anu/spline-calibration.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "gupta|calibration_of_neural_networks_using_splines", "one-sentence_summary": "We introduce a binning-free calibration measure inspired by the classical Kolmogorov-Smirnov statistical test and obtain a recalibration function by approximating the empirical cumulative distribution using a differentiable function via splines.", "supplementary_material": "/attachment/8d30e322ef8da40e311ef60e33ebe0d48f7fb2d1.zip", "pdf": "/pdf/9b7a1091871efa36fec2c10f52c8cef289c89a5f.pdf", "venue": "ICLR 2021 Poster", "venueid": "ICLR.cc/2021/Conference", "_bibtex": "@inproceedings{\ngupta2021calibration,\ntitle={Calibration of Neural Networks using Splines},\nauthor={Kartik Gupta and Amir Rahimi and Thalaiyasingam Ajanthan and Thomas Mensink and Cristian Sminchisescu and Richard Hartley},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=eQe8DEWNN2W}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "eQe8DEWNN2W", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper812/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper812/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper812/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper812/Authors|ICLR.cc/2021/Conference/Paper812/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper812/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923866945, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper812/-/Official_Comment"}}}, {"id": "nflTNg7_kf", "original": null, "number": 10, "cdate": 1606134308061, "ddate": null, "tcdate": 1606134308061, "tmdate": 1606134423851, "tddate": null, "forum": "eQe8DEWNN2W", "replyto": "tb1xs5y38hM", "invitation": "ICLR.cc/2021/Conference/Paper812/-/Official_Comment", "content": {"title": "Thanks for your interest in our paper.", "comment": "We appreciate that the reader found our paper interesting and enjoyable to read. Below we answer the reader's questions.\n\n### Spline fitting with less samples on ImageNet \n- The only requirement for spline fitting to work well is to have smooth CDF. To achieve this, even a smaller number of samples would be sufficient.\n- We ran few experiments for DenseNet-16 trained on ImageNet to see how our calibration method works if we randomly chose only a subset of samples for spline fitting instead of 25000 samples in calibration set and the results are reported below:\n|# of samples|KS|\n|-|-|\n|25000|0.00406|\n|15000|0.00421|\n|5000|0.00448|\n- It can be clearly observed that our method is quite robust in terms of number of samples used in the calibration set consistently beating all the baselines even using only 5000 samples in the calibration set. The second best method in this case is temperature scaling which achieves KS error of 0.00744 with 25000 samples in the calibration set.\n\n### Temperature scaling on other metric instead of NLL\n- In this paper, we have followed Kull et al. implementation of temperature scaling which minimizes NLL but one can choose to minimize calibration metrics such as ECE or KS.\n- We believe that the main limitation of using temperature scaling is that it can only estimate the recalibration function using a single parameter which may not be sufficient in many cases.\n"}, "signatures": ["ICLR.cc/2021/Conference/Paper812/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper812/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Calibration of Neural Networks using Splines", "authorids": ["~Kartik_Gupta2", "~Amir_Rahimi1", "~Thalaiyasingam_Ajanthan1", "~Thomas_Mensink1", "~Cristian_Sminchisescu1", "~Richard_Hartley1"], "authors": ["Kartik Gupta", "Amir Rahimi", "Thalaiyasingam Ajanthan", "Thomas Mensink", "Cristian Sminchisescu", "Richard Hartley"], "keywords": ["neural network calibration", "uncertainty", "calibration measure"], "abstract": "Calibrating neural networks is of utmost importance when employing them in safety-critical applications where the downstream decision making depends on the predicted probabilities. Measuring calibration error amounts to comparing two empirical distributions. In this work, we introduce a binning-free calibration measure inspired by the classical Kolmogorov-Smirnov (KS) statistical test in which the main idea is to compare the respective cumulative probability distributions. From this, by approximating the empirical cumulative distribution using a differentiable function via splines, we obtain a recalibration function, which maps the network outputs to actual (calibrated) class assignment probabilities. The spline-fitting is performed using a held-out calibration set and the obtained recalibration function is evaluated on an unseen test set. We tested our method against existing calibration approaches on various image classification datasets and our spline-based recalibration approach consistently outperforms existing methods on KS error as well as other commonly used calibration measures. Code is available online at https://github.com/kartikgupta-at-anu/spline-calibration.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "gupta|calibration_of_neural_networks_using_splines", "one-sentence_summary": "We introduce a binning-free calibration measure inspired by the classical Kolmogorov-Smirnov statistical test and obtain a recalibration function by approximating the empirical cumulative distribution using a differentiable function via splines.", "supplementary_material": "/attachment/8d30e322ef8da40e311ef60e33ebe0d48f7fb2d1.zip", "pdf": "/pdf/9b7a1091871efa36fec2c10f52c8cef289c89a5f.pdf", "venue": "ICLR 2021 Poster", "venueid": "ICLR.cc/2021/Conference", "_bibtex": "@inproceedings{\ngupta2021calibration,\ntitle={Calibration of Neural Networks using Splines},\nauthor={Kartik Gupta and Amir Rahimi and Thalaiyasingam Ajanthan and Thomas Mensink and Cristian Sminchisescu and Richard Hartley},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=eQe8DEWNN2W}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "eQe8DEWNN2W", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper812/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper812/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper812/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper812/Authors|ICLR.cc/2021/Conference/Paper812/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper812/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923866945, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper812/-/Official_Comment"}}}, {"id": "931Mbowz-rH", "original": null, "number": 7, "cdate": 1605871463598, "ddate": null, "tcdate": 1605871463598, "tmdate": 1605871463598, "tddate": null, "forum": "eQe8DEWNN2W", "replyto": "bdo1zx5yBrX", "invitation": "ICLR.cc/2021/Conference/Paper812/-/Official_Comment", "content": {"title": "Other comments {Response to AR4[2/2]}", "comment": "### Scalability of spline fitting\n- Both in theory as well as in practice, spline fitting is very fast (about 0.4 seconds on the ImageNet calibration set with 25000 images). Much faster than one forward pass through the network and it is learning free. See also our response to AR2. The most complex step of spline fitting is sorting which is very efficient. So we believe, our method would be highly scalable compared to methods that require learning."}, "signatures": ["ICLR.cc/2021/Conference/Paper812/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper812/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Calibration of Neural Networks using Splines", "authorids": ["~Kartik_Gupta2", "~Amir_Rahimi1", "~Thalaiyasingam_Ajanthan1", "~Thomas_Mensink1", "~Cristian_Sminchisescu1", "~Richard_Hartley1"], "authors": ["Kartik Gupta", "Amir Rahimi", "Thalaiyasingam Ajanthan", "Thomas Mensink", "Cristian Sminchisescu", "Richard Hartley"], "keywords": ["neural network calibration", "uncertainty", "calibration measure"], "abstract": "Calibrating neural networks is of utmost importance when employing them in safety-critical applications where the downstream decision making depends on the predicted probabilities. Measuring calibration error amounts to comparing two empirical distributions. In this work, we introduce a binning-free calibration measure inspired by the classical Kolmogorov-Smirnov (KS) statistical test in which the main idea is to compare the respective cumulative probability distributions. From this, by approximating the empirical cumulative distribution using a differentiable function via splines, we obtain a recalibration function, which maps the network outputs to actual (calibrated) class assignment probabilities. The spline-fitting is performed using a held-out calibration set and the obtained recalibration function is evaluated on an unseen test set. We tested our method against existing calibration approaches on various image classification datasets and our spline-based recalibration approach consistently outperforms existing methods on KS error as well as other commonly used calibration measures. Code is available online at https://github.com/kartikgupta-at-anu/spline-calibration.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "gupta|calibration_of_neural_networks_using_splines", "one-sentence_summary": "We introduce a binning-free calibration measure inspired by the classical Kolmogorov-Smirnov statistical test and obtain a recalibration function by approximating the empirical cumulative distribution using a differentiable function via splines.", "supplementary_material": "/attachment/8d30e322ef8da40e311ef60e33ebe0d48f7fb2d1.zip", "pdf": "/pdf/9b7a1091871efa36fec2c10f52c8cef289c89a5f.pdf", "venue": "ICLR 2021 Poster", "venueid": "ICLR.cc/2021/Conference", "_bibtex": "@inproceedings{\ngupta2021calibration,\ntitle={Calibration of Neural Networks using Splines},\nauthor={Kartik Gupta and Amir Rahimi and Thalaiyasingam Ajanthan and Thomas Mensink and Cristian Sminchisescu and Richard Hartley},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=eQe8DEWNN2W}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "eQe8DEWNN2W", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper812/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper812/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper812/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper812/Authors|ICLR.cc/2021/Conference/Paper812/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper812/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923866945, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper812/-/Official_Comment"}}}, {"id": "_l11AfgFxol", "original": null, "number": 5, "cdate": 1605869710524, "ddate": null, "tcdate": 1605869710524, "tmdate": 1605869828201, "tddate": null, "forum": "eQe8DEWNN2W", "replyto": "LgPTXcR4kp2", "invitation": "ICLR.cc/2021/Conference/Paper812/-/Official_Comment", "content": {"title": "AR3: Thank you for the positive feedback.", "comment": "We thank the reviewer for the positive feedback and appreciate that the reviewer finds our paper to be clearly written and the proposed method to be well-founded.\n"}, "signatures": ["ICLR.cc/2021/Conference/Paper812/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper812/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Calibration of Neural Networks using Splines", "authorids": ["~Kartik_Gupta2", "~Amir_Rahimi1", "~Thalaiyasingam_Ajanthan1", "~Thomas_Mensink1", "~Cristian_Sminchisescu1", "~Richard_Hartley1"], "authors": ["Kartik Gupta", "Amir Rahimi", "Thalaiyasingam Ajanthan", "Thomas Mensink", "Cristian Sminchisescu", "Richard Hartley"], "keywords": ["neural network calibration", "uncertainty", "calibration measure"], "abstract": "Calibrating neural networks is of utmost importance when employing them in safety-critical applications where the downstream decision making depends on the predicted probabilities. Measuring calibration error amounts to comparing two empirical distributions. In this work, we introduce a binning-free calibration measure inspired by the classical Kolmogorov-Smirnov (KS) statistical test in which the main idea is to compare the respective cumulative probability distributions. From this, by approximating the empirical cumulative distribution using a differentiable function via splines, we obtain a recalibration function, which maps the network outputs to actual (calibrated) class assignment probabilities. The spline-fitting is performed using a held-out calibration set and the obtained recalibration function is evaluated on an unseen test set. We tested our method against existing calibration approaches on various image classification datasets and our spline-based recalibration approach consistently outperforms existing methods on KS error as well as other commonly used calibration measures. Code is available online at https://github.com/kartikgupta-at-anu/spline-calibration.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "gupta|calibration_of_neural_networks_using_splines", "one-sentence_summary": "We introduce a binning-free calibration measure inspired by the classical Kolmogorov-Smirnov statistical test and obtain a recalibration function by approximating the empirical cumulative distribution using a differentiable function via splines.", "supplementary_material": "/attachment/8d30e322ef8da40e311ef60e33ebe0d48f7fb2d1.zip", "pdf": "/pdf/9b7a1091871efa36fec2c10f52c8cef289c89a5f.pdf", "venue": "ICLR 2021 Poster", "venueid": "ICLR.cc/2021/Conference", "_bibtex": "@inproceedings{\ngupta2021calibration,\ntitle={Calibration of Neural Networks using Splines},\nauthor={Kartik Gupta and Amir Rahimi and Thalaiyasingam Ajanthan and Thomas Mensink and Cristian Sminchisescu and Richard Hartley},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=eQe8DEWNN2W}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "eQe8DEWNN2W", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper812/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper812/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper812/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper812/Authors|ICLR.cc/2021/Conference/Paper812/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper812/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923866945, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper812/-/Official_Comment"}}}, {"id": "tb1xs5y38hM", "original": null, "number": 2, "cdate": 1605581135649, "ddate": null, "tcdate": 1605581135649, "tmdate": 1605581135649, "tddate": null, "forum": "eQe8DEWNN2W", "replyto": "eQe8DEWNN2W", "invitation": "ICLR.cc/2021/Conference/Paper812/-/Public_Comment", "content": {"title": "Questions from an interested reader", "comment": "It was quite enjoyable to read the paper. When reading it, I had the following two questions:\n- The results presented for Imagenet use 25000 images for the calibration set which could potentially be one of the disadvantages of the method. How do the results change with fewer images, say only 5000 images?\n- In temperature scaling, the parameter T is chosen to minimize the NLL on a calibration set. Could one instead minimize the KS error?"}, "signatures": ["~Tiago_Salvador1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "~Tiago_Salvador1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Calibration of Neural Networks using Splines", "authorids": ["~Kartik_Gupta2", "~Amir_Rahimi1", "~Thalaiyasingam_Ajanthan1", "~Thomas_Mensink1", "~Cristian_Sminchisescu1", "~Richard_Hartley1"], "authors": ["Kartik Gupta", "Amir Rahimi", "Thalaiyasingam Ajanthan", "Thomas Mensink", "Cristian Sminchisescu", "Richard Hartley"], "keywords": ["neural network calibration", "uncertainty", "calibration measure"], "abstract": "Calibrating neural networks is of utmost importance when employing them in safety-critical applications where the downstream decision making depends on the predicted probabilities. Measuring calibration error amounts to comparing two empirical distributions. In this work, we introduce a binning-free calibration measure inspired by the classical Kolmogorov-Smirnov (KS) statistical test in which the main idea is to compare the respective cumulative probability distributions. From this, by approximating the empirical cumulative distribution using a differentiable function via splines, we obtain a recalibration function, which maps the network outputs to actual (calibrated) class assignment probabilities. The spline-fitting is performed using a held-out calibration set and the obtained recalibration function is evaluated on an unseen test set. We tested our method against existing calibration approaches on various image classification datasets and our spline-based recalibration approach consistently outperforms existing methods on KS error as well as other commonly used calibration measures. Code is available online at https://github.com/kartikgupta-at-anu/spline-calibration.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "gupta|calibration_of_neural_networks_using_splines", "one-sentence_summary": "We introduce a binning-free calibration measure inspired by the classical Kolmogorov-Smirnov statistical test and obtain a recalibration function by approximating the empirical cumulative distribution using a differentiable function via splines.", "supplementary_material": "/attachment/8d30e322ef8da40e311ef60e33ebe0d48f7fb2d1.zip", "pdf": "/pdf/9b7a1091871efa36fec2c10f52c8cef289c89a5f.pdf", "venue": "ICLR 2021 Poster", "venueid": "ICLR.cc/2021/Conference", "_bibtex": "@inproceedings{\ngupta2021calibration,\ntitle={Calibration of Neural Networks using Splines},\nauthor={Kartik Gupta and Amir Rahimi and Thalaiyasingam Ajanthan and Thomas Mensink and Cristian Sminchisescu and Richard Hartley},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=eQe8DEWNN2W}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "eQe8DEWNN2W", "readers": {"description": "User groups that will be able to read this comment.", "values": ["everyone"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "~.*", "description": "How your identity will be displayed."}}, "expdate": 1605630600000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["everyone"], "noninvitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper812/Authors", "ICLR.cc/2021/Conference/Paper812/Reviewers", "ICLR.cc/2021/Conference/Paper812/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs"], "tcdate": 1605024978655, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper812/-/Public_Comment"}}}, {"id": "Dzh7nKLwRkU", "original": null, "number": 1, "cdate": 1605520822360, "ddate": null, "tcdate": 1605520822360, "tmdate": 1605520822360, "tddate": null, "forum": "eQe8DEWNN2W", "replyto": "eQe8DEWNN2W", "invitation": "ICLR.cc/2021/Conference/Paper812/-/Public_Comment", "content": {"title": "Sensitivity of KS test & one related work", "comment": "Really like the idea on using KS test on calibration! My only conservation about KS is about its sensitivity, i.e., the KS discrepancy can be high if the considered distributions are both highly peaked, even if they are otherwise very similar. I'm wondering if this could be an issue in the calibration context?\n\nI also want to refer to our recent work on an alternative binning-free ECE estimator [1]. As you have discussed in the intro, there exist several issues of histogram-based ECE estimators. In our work, we replaced histogram with KDE and provided a more reliable evaluation of calibration while mitigating the bias & binning sensitivity of histograms. The code is also available online if you are interested.\n\n[1] Jize Zhang, Bhavya Kailkhura, and T Han. \"Mix-n-Match: Ensemble and compositional methods for uncertainty calibration in deep learning.\", ICML 2020, https://arxiv.org/pdf/2003.07329.pdf"}, "signatures": ["~Jize_Zhang1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "~Jize_Zhang1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Calibration of Neural Networks using Splines", "authorids": ["~Kartik_Gupta2", "~Amir_Rahimi1", "~Thalaiyasingam_Ajanthan1", "~Thomas_Mensink1", "~Cristian_Sminchisescu1", "~Richard_Hartley1"], "authors": ["Kartik Gupta", "Amir Rahimi", "Thalaiyasingam Ajanthan", "Thomas Mensink", "Cristian Sminchisescu", "Richard Hartley"], "keywords": ["neural network calibration", "uncertainty", "calibration measure"], "abstract": "Calibrating neural networks is of utmost importance when employing them in safety-critical applications where the downstream decision making depends on the predicted probabilities. Measuring calibration error amounts to comparing two empirical distributions. In this work, we introduce a binning-free calibration measure inspired by the classical Kolmogorov-Smirnov (KS) statistical test in which the main idea is to compare the respective cumulative probability distributions. From this, by approximating the empirical cumulative distribution using a differentiable function via splines, we obtain a recalibration function, which maps the network outputs to actual (calibrated) class assignment probabilities. The spline-fitting is performed using a held-out calibration set and the obtained recalibration function is evaluated on an unseen test set. We tested our method against existing calibration approaches on various image classification datasets and our spline-based recalibration approach consistently outperforms existing methods on KS error as well as other commonly used calibration measures. Code is available online at https://github.com/kartikgupta-at-anu/spline-calibration.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "gupta|calibration_of_neural_networks_using_splines", "one-sentence_summary": "We introduce a binning-free calibration measure inspired by the classical Kolmogorov-Smirnov statistical test and obtain a recalibration function by approximating the empirical cumulative distribution using a differentiable function via splines.", "supplementary_material": "/attachment/8d30e322ef8da40e311ef60e33ebe0d48f7fb2d1.zip", "pdf": "/pdf/9b7a1091871efa36fec2c10f52c8cef289c89a5f.pdf", "venue": "ICLR 2021 Poster", "venueid": "ICLR.cc/2021/Conference", "_bibtex": "@inproceedings{\ngupta2021calibration,\ntitle={Calibration of Neural Networks using Splines},\nauthor={Kartik Gupta and Amir Rahimi and Thalaiyasingam Ajanthan and Thomas Mensink and Cristian Sminchisescu and Richard Hartley},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=eQe8DEWNN2W}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "eQe8DEWNN2W", "readers": {"description": "User groups that will be able to read this comment.", "values": ["everyone"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "~.*", "description": "How your identity will be displayed."}}, "expdate": 1605630600000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["everyone"], "noninvitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper812/Authors", "ICLR.cc/2021/Conference/Paper812/Reviewers", "ICLR.cc/2021/Conference/Paper812/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs"], "tcdate": 1605024978655, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper812/-/Public_Comment"}}}, {"id": "ThYCYAtWQqC", "original": null, "number": 1, "cdate": 1603549491942, "ddate": null, "tcdate": 1603549491942, "tmdate": 1605024600090, "tddate": null, "forum": "eQe8DEWNN2W", "replyto": "eQe8DEWNN2W", "invitation": "ICLR.cc/2021/Conference/Paper812/-/Official_Review", "content": {"title": "Solid work on an important topic", "review": "The paper presents a post-hoc calibration method for deep neural net classification. The method proposes to first reduces the well-known ECE score to a special case of the Kolmogorov-Smirnov (KS) test, and this way solves the dependency of ECE on the limiting binning assumption. The method proposes next to recalibrate the classification probabilities by fitting a cubic spline to the KS test score.\n\nStrengths:\n * The proposed approach is a clearly novel solution to an essential problem for the safety-critical use of deep learning.\n * The paper presents the material in a very clear and neat way, following an excellent scientific writing practice.\n * Both the KS test based treatment of network calibration and the elegant way to improve the calibration by cubic spline fitting are interesting and likely to attract the attention of the deep learning uncertainty community.\n * The paper presents an exhaustive set of experiments that report performances of quite deep state-of-the-art network architectures on four different benchmark tasks. It also provides comparisons against a decent number of state-of-the-art calibration methods. The results demonstrate the benefits of the proposed method.\n\n(Minor) Weaknesses: The paper can be improved with a few small adjustments in the presentation:\n\n * The so-called \"python semantics\" notation in Sec 2 only introduces complexity and does not bring any concrete value to the story line. What is wrong with denoting the r-th top score simply as f^{(n)}. Why do we need the minus? We can simply assume that the first element of the sorted list is the top score.\n\n * Why do we need Proposition 4.1 and its proof (sketch and full) in this paper? It only echoes the standard relationship between a PDF and CDF. The former is the derivative of the latter.\n\n * Although the results in Tables 1 and 2 are groundbreaking in favor of the proposed method, they are calibration scores based on the KS score. That is only one way of measuring the calibratedness of a network, and furthermore that is the score the proposed method is maximizing. It would be interesting to see how well the proposed method generalizes across other calibration scores that may highlight complementary aspects of the uncertainty treatment capabilities of the predictor, such as the Brier score.\n\nOverall, this is a solid piece of work that qualifies to appear at the ICLR'21 proceedings.", "rating": "7: Good paper, accept", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["ICLR.cc/2021/Conference/Paper812/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper812/AnonReviewer1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Calibration of Neural Networks using Splines", "authorids": ["~Kartik_Gupta2", "~Amir_Rahimi1", "~Thalaiyasingam_Ajanthan1", "~Thomas_Mensink1", "~Cristian_Sminchisescu1", "~Richard_Hartley1"], "authors": ["Kartik Gupta", "Amir Rahimi", "Thalaiyasingam Ajanthan", "Thomas Mensink", "Cristian Sminchisescu", "Richard Hartley"], "keywords": ["neural network calibration", "uncertainty", "calibration measure"], "abstract": "Calibrating neural networks is of utmost importance when employing them in safety-critical applications where the downstream decision making depends on the predicted probabilities. Measuring calibration error amounts to comparing two empirical distributions. In this work, we introduce a binning-free calibration measure inspired by the classical Kolmogorov-Smirnov (KS) statistical test in which the main idea is to compare the respective cumulative probability distributions. From this, by approximating the empirical cumulative distribution using a differentiable function via splines, we obtain a recalibration function, which maps the network outputs to actual (calibrated) class assignment probabilities. The spline-fitting is performed using a held-out calibration set and the obtained recalibration function is evaluated on an unseen test set. We tested our method against existing calibration approaches on various image classification datasets and our spline-based recalibration approach consistently outperforms existing methods on KS error as well as other commonly used calibration measures. Code is available online at https://github.com/kartikgupta-at-anu/spline-calibration.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "gupta|calibration_of_neural_networks_using_splines", "one-sentence_summary": "We introduce a binning-free calibration measure inspired by the classical Kolmogorov-Smirnov statistical test and obtain a recalibration function by approximating the empirical cumulative distribution using a differentiable function via splines.", "supplementary_material": "/attachment/8d30e322ef8da40e311ef60e33ebe0d48f7fb2d1.zip", "pdf": "/pdf/9b7a1091871efa36fec2c10f52c8cef289c89a5f.pdf", "venue": "ICLR 2021 Poster", "venueid": "ICLR.cc/2021/Conference", "_bibtex": "@inproceedings{\ngupta2021calibration,\ntitle={Calibration of Neural Networks using Splines},\nauthor={Kartik Gupta and Amir Rahimi and Thalaiyasingam Ajanthan and Thomas Mensink and Cristian Sminchisescu and Richard Hartley},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=eQe8DEWNN2W}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq . ***Please remember to file the Code-of-Ethics report. Once you submitted the review, a link to the report will be visible in the bottom right corner of your review.***", "required": true, "markdown": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}, "forum": "eQe8DEWNN2W", "replyto": "eQe8DEWNN2W", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"], "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper812/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1607428800000, "duedate": 1606752000000, "multiReply": false, "readers": ["everyone"], "tcdate": 1602538134468, "tmdate": 1606915784161, "super": "ICLR.cc/2021/Conference/-/Official_Review", "signatures": ["OpenReview.net"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Paper812/Reviewers", "OpenReview.net/Support"], "id": "ICLR.cc/2021/Conference/Paper812/-/Official_Review"}}}, {"id": "LgPTXcR4kp2", "original": null, "number": 3, "cdate": 1603849028744, "ddate": null, "tcdate": 1603849028744, "tmdate": 1605024600026, "tddate": null, "forum": "eQe8DEWNN2W", "replyto": "eQe8DEWNN2W", "invitation": "ICLR.cc/2021/Conference/Paper812/-/Official_Review", "content": {"title": "The paper presents an interesting contribution with potential applicability in the deep learning community.", "review": "The authors present a binning-free calibration measure from a Kolmogorov-Smirnov-based test. Besides, the cumulative probability distribution is estimated using a spline-based fitting from percentiles. The approach allows correcting the probability estimation from trained deep learning models. The paper is clear and well-founded. \n", "rating": "8: Top 50% of accepted papers, clear accept", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["ICLR.cc/2021/Conference/Paper812/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper812/AnonReviewer3"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Calibration of Neural Networks using Splines", "authorids": ["~Kartik_Gupta2", "~Amir_Rahimi1", "~Thalaiyasingam_Ajanthan1", "~Thomas_Mensink1", "~Cristian_Sminchisescu1", "~Richard_Hartley1"], "authors": ["Kartik Gupta", "Amir Rahimi", "Thalaiyasingam Ajanthan", "Thomas Mensink", "Cristian Sminchisescu", "Richard Hartley"], "keywords": ["neural network calibration", "uncertainty", "calibration measure"], "abstract": "Calibrating neural networks is of utmost importance when employing them in safety-critical applications where the downstream decision making depends on the predicted probabilities. Measuring calibration error amounts to comparing two empirical distributions. In this work, we introduce a binning-free calibration measure inspired by the classical Kolmogorov-Smirnov (KS) statistical test in which the main idea is to compare the respective cumulative probability distributions. From this, by approximating the empirical cumulative distribution using a differentiable function via splines, we obtain a recalibration function, which maps the network outputs to actual (calibrated) class assignment probabilities. The spline-fitting is performed using a held-out calibration set and the obtained recalibration function is evaluated on an unseen test set. We tested our method against existing calibration approaches on various image classification datasets and our spline-based recalibration approach consistently outperforms existing methods on KS error as well as other commonly used calibration measures. Code is available online at https://github.com/kartikgupta-at-anu/spline-calibration.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "gupta|calibration_of_neural_networks_using_splines", "one-sentence_summary": "We introduce a binning-free calibration measure inspired by the classical Kolmogorov-Smirnov statistical test and obtain a recalibration function by approximating the empirical cumulative distribution using a differentiable function via splines.", "supplementary_material": "/attachment/8d30e322ef8da40e311ef60e33ebe0d48f7fb2d1.zip", "pdf": "/pdf/9b7a1091871efa36fec2c10f52c8cef289c89a5f.pdf", "venue": "ICLR 2021 Poster", "venueid": "ICLR.cc/2021/Conference", "_bibtex": "@inproceedings{\ngupta2021calibration,\ntitle={Calibration of Neural Networks using Splines},\nauthor={Kartik Gupta and Amir Rahimi and Thalaiyasingam Ajanthan and Thomas Mensink and Cristian Sminchisescu and Richard Hartley},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=eQe8DEWNN2W}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq . ***Please remember to file the Code-of-Ethics report. Once you submitted the review, a link to the report will be visible in the bottom right corner of your review.***", "required": true, "markdown": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}, "forum": "eQe8DEWNN2W", "replyto": "eQe8DEWNN2W", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"], "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper812/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1607428800000, "duedate": 1606752000000, "multiReply": false, "readers": ["everyone"], "tcdate": 1602538134468, "tmdate": 1606915784161, "super": "ICLR.cc/2021/Conference/-/Official_Review", "signatures": ["OpenReview.net"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Paper812/Reviewers", "OpenReview.net/Support"], "id": "ICLR.cc/2021/Conference/Paper812/-/Official_Review"}}}, {"id": "sW1-EF_mcTx", "original": null, "number": 2, "cdate": 1603814018716, "ddate": null, "tcdate": 1603814018716, "tmdate": 1605024599965, "tddate": null, "forum": "eQe8DEWNN2W", "replyto": "eQe8DEWNN2W", "invitation": "ICLR.cc/2021/Conference/Paper812/-/Official_Review", "content": {"title": "An ok submission but incremental. ", "review": "The paper proposes a post re-calibration spline-based approach for the re-calibration of multiclass predictions.  Experiment results on image datasets are provided and evaluated according to the Kolmogorov\u2013Smirnov (KS) statistic. \n\n**Strengths**:\n - The proposed binning-free calibration measure is a good idea and widely used in binary classification problems\n\n- As expected, experimental results demonstrate that optimizing calibration with a spline-based approach results in better calibration\n\n**Weaknesses**:\n\n*Inconsistent notation*:\n-  The authors should stick to either $x $ or $X$\n-  The definition of the KS statistic is inconsistent with standard formulations Eq (8). Also, the paper claims to obtain the maximum value at $\\sigma=1$; this is a strong assumption.\n\n*Weak experiments*:\n- Why KS statistic and not Wasserstein or calibration slope?\n-  Eq (11) assumes $f_k(x_i)$ are distinct, which is not always the case.\n- Calibration and accuracy are orthogonal concerns, where the proposed post re-calibration approach is prone to overfit on calibration at the expense of accuracy (and this is the case, as experimental results show a loss in accuracy)\n-  Demonstrating an approach that accounts for the calibration-accuracy tradeoff is crucial\n- Extending the proposed approach to regression problems would strengthen the submission\n- A  qualitative discussion on:\n1)  Why Temp. Scaling is better calibrated in some instances\n2)  Why calibration results of proposed solution (and alternatives) vary across different network architectures for the same dataset\n3) Why the proposed approach drops in performance between top-1 and top-2 predictions\n- The proposed re-calibration approach may not scale well with large datasets; a computational complexity comparison against alternatives is crucial", "rating": "5: Marginally below acceptance threshold", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["ICLR.cc/2021/Conference/Paper812/AnonReviewer4"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper812/AnonReviewer4"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Calibration of Neural Networks using Splines", "authorids": ["~Kartik_Gupta2", "~Amir_Rahimi1", "~Thalaiyasingam_Ajanthan1", "~Thomas_Mensink1", "~Cristian_Sminchisescu1", "~Richard_Hartley1"], "authors": ["Kartik Gupta", "Amir Rahimi", "Thalaiyasingam Ajanthan", "Thomas Mensink", "Cristian Sminchisescu", "Richard Hartley"], "keywords": ["neural network calibration", "uncertainty", "calibration measure"], "abstract": "Calibrating neural networks is of utmost importance when employing them in safety-critical applications where the downstream decision making depends on the predicted probabilities. Measuring calibration error amounts to comparing two empirical distributions. In this work, we introduce a binning-free calibration measure inspired by the classical Kolmogorov-Smirnov (KS) statistical test in which the main idea is to compare the respective cumulative probability distributions. From this, by approximating the empirical cumulative distribution using a differentiable function via splines, we obtain a recalibration function, which maps the network outputs to actual (calibrated) class assignment probabilities. The spline-fitting is performed using a held-out calibration set and the obtained recalibration function is evaluated on an unseen test set. We tested our method against existing calibration approaches on various image classification datasets and our spline-based recalibration approach consistently outperforms existing methods on KS error as well as other commonly used calibration measures. Code is available online at https://github.com/kartikgupta-at-anu/spline-calibration.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "gupta|calibration_of_neural_networks_using_splines", "one-sentence_summary": "We introduce a binning-free calibration measure inspired by the classical Kolmogorov-Smirnov statistical test and obtain a recalibration function by approximating the empirical cumulative distribution using a differentiable function via splines.", "supplementary_material": "/attachment/8d30e322ef8da40e311ef60e33ebe0d48f7fb2d1.zip", "pdf": "/pdf/9b7a1091871efa36fec2c10f52c8cef289c89a5f.pdf", "venue": "ICLR 2021 Poster", "venueid": "ICLR.cc/2021/Conference", "_bibtex": "@inproceedings{\ngupta2021calibration,\ntitle={Calibration of Neural Networks using Splines},\nauthor={Kartik Gupta and Amir Rahimi and Thalaiyasingam Ajanthan and Thomas Mensink and Cristian Sminchisescu and Richard Hartley},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=eQe8DEWNN2W}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq . ***Please remember to file the Code-of-Ethics report. Once you submitted the review, a link to the report will be visible in the bottom right corner of your review.***", "required": true, "markdown": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}, "forum": "eQe8DEWNN2W", "replyto": "eQe8DEWNN2W", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"], "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper812/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1607428800000, "duedate": 1606752000000, "multiReply": false, "readers": ["everyone"], "tcdate": 1602538134468, "tmdate": 1606915784161, "super": "ICLR.cc/2021/Conference/-/Official_Review", "signatures": ["OpenReview.net"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Paper812/Reviewers", "OpenReview.net/Support"], "id": "ICLR.cc/2021/Conference/Paper812/-/Official_Review"}}}], "count": 15}