{"notes": [{"tddate": null, "ddate": null, "cdate": null, "tmdate": 1486396360267, "tcdate": 1486396360267, "number": 1, "id": "S1lCizL_x", "invitation": "ICLR.cc/2017/conference/-/paper106/acceptance", "forum": "rJzaDdYxx", "replyto": "rJzaDdYxx", "signatures": ["ICLR.cc/2017/pcs"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/pcs"], "content": {"decision": "Reject", "title": "ICLR committee final decision", "comment": "This paper was reviewed by 3 experts. All 3 seem unconvinced of the contributions, point to several shortcomings, and recommend rejection. I see no basis for overturning their recommendation. To be clear, the problem of achieving insight into the inner workings of deep networks is of significant importance and I encourage the authors to use the feedback to improve the manuscript."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Gradients of Counterfactuals", "abstract": "Gradients have been used to quantify feature importance in machine learning models. Unfortunately, in nonlinear deep networks, not only individual neurons but also the whole network can saturate, and as a result an important input feature can have a tiny gradient. We study various networks, and observe that this phenomena is indeed widespread, across many inputs.\n\nWe propose to examine interior gradients, which are gradients of counterfactual inputs constructed by scaling down the original input. We apply our method to the GoogleNet architecture for object recognition in images, as well as a ligand-based virtual screening network with categorical features and an LSTM based language model for the Penn Treebank dataset. We visualize how interior gradients better capture feature importance. Furthermore, interior gradients are applicable to a wide variety of deep networks, and have the attribution property that the feature importance scores sum to the the prediction score. \n\nBest of all, interior gradients can be computed just as easily as gradients. In contrast, previous methods are complex to implement, which hinders practical adoption.", "pdf": "/pdf/95894e6fa8b21d5e355bb0167096107df64f71d5.pdf", "TL;DR": "A method for identifying feature importance in deep networks using gradients of counterfactual inputs", "paperhash": "sundararajan|gradients_of_counterfactuals", "conflicts": ["google.com"], "keywords": ["Deep learning", "Computer vision", "Theory"], "authors": ["Mukund Sundararajan", "Ankur Taly", "Qiqi Yan"], "authorids": ["mukunds@google.com", "ataly@google.com", "qiqiyan@google.com"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1486396360785, "id": "ICLR.cc/2017/conference/-/paper106/acceptance", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/pcs"], "noninvitees": ["ICLR.cc/2017/pcs"], "reply": {"forum": "rJzaDdYxx", "replyto": "rJzaDdYxx", "writers": {"values-regex": "ICLR.cc/2017/pcs"}, "signatures": {"values-regex": "ICLR.cc/2017/pcs", "description": "Your displayed identity associated with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your decision.", "value": "ICLR committee final decision"}, "comment": {"required": true, "order": 2, "description": "Decision comments.", "value-regex": "[\\S\\s]{1,5000}"}, "decision": {"required": true, "order": 3, "value-radio": ["Accept (Oral)", "Accept (Poster)", "Reject", "Invite to Workshop Track"]}}}, "nonreaders": [], "cdate": 1486396360785}}}, {"tddate": null, "tmdate": 1484174955677, "tcdate": 1484174955677, "number": 4, "id": "Sk4dUN4Ix", "invitation": "ICLR.cc/2017/conference/-/paper106/public/comment", "forum": "rJzaDdYxx", "replyto": "rJzaDdYxx", "signatures": ["~Ankur_Taly1"], "readers": ["everyone"], "writers": ["~Ankur_Taly1"], "content": {"title": "New material added to the paper", "comment": "We added two new sections (2.5 and 2.6) to the paper. Section 2.5\nproposes two very desirable axioms for attribution methods,\nand uses them to rule out other attribution methods from the literature.\nSection 2.6 proposes a full axiomatization under which our method is\nunique.\n\nIt is possible that sections 2.3-2.7 may constitute a shorter 6-page\nself-contained paper with the title --- \"attributions using interior\ngradients\".\n"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Gradients of Counterfactuals", "abstract": "Gradients have been used to quantify feature importance in machine learning models. Unfortunately, in nonlinear deep networks, not only individual neurons but also the whole network can saturate, and as a result an important input feature can have a tiny gradient. We study various networks, and observe that this phenomena is indeed widespread, across many inputs.\n\nWe propose to examine interior gradients, which are gradients of counterfactual inputs constructed by scaling down the original input. We apply our method to the GoogleNet architecture for object recognition in images, as well as a ligand-based virtual screening network with categorical features and an LSTM based language model for the Penn Treebank dataset. We visualize how interior gradients better capture feature importance. Furthermore, interior gradients are applicable to a wide variety of deep networks, and have the attribution property that the feature importance scores sum to the the prediction score. \n\nBest of all, interior gradients can be computed just as easily as gradients. In contrast, previous methods are complex to implement, which hinders practical adoption.", "pdf": "/pdf/95894e6fa8b21d5e355bb0167096107df64f71d5.pdf", "TL;DR": "A method for identifying feature importance in deep networks using gradients of counterfactual inputs", "paperhash": "sundararajan|gradients_of_counterfactuals", "conflicts": ["google.com"], "keywords": ["Deep learning", "Computer vision", "Theory"], "authors": ["Mukund Sundararajan", "Ankur Taly", "Qiqi Yan"], "authorids": ["mukunds@google.com", "ataly@google.com", "qiqiyan@google.com"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287725585, "id": "ICLR.cc/2017/conference/-/paper106/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "rJzaDdYxx", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper106/reviewers", "ICLR.cc/2017/conference/paper106/areachairs"], "cdate": 1485287725585}}}, {"tddate": null, "replyto": null, "ddate": null, "tmdate": 1484174883271, "tcdate": 1478227898210, "number": 106, "id": "rJzaDdYxx", "invitation": "ICLR.cc/2017/conference/-/submission", "forum": "rJzaDdYxx", "signatures": ["~Ankur_Taly1"], "readers": ["everyone"], "content": {"title": "Gradients of Counterfactuals", "abstract": "Gradients have been used to quantify feature importance in machine learning models. Unfortunately, in nonlinear deep networks, not only individual neurons but also the whole network can saturate, and as a result an important input feature can have a tiny gradient. We study various networks, and observe that this phenomena is indeed widespread, across many inputs.\n\nWe propose to examine interior gradients, which are gradients of counterfactual inputs constructed by scaling down the original input. We apply our method to the GoogleNet architecture for object recognition in images, as well as a ligand-based virtual screening network with categorical features and an LSTM based language model for the Penn Treebank dataset. We visualize how interior gradients better capture feature importance. Furthermore, interior gradients are applicable to a wide variety of deep networks, and have the attribution property that the feature importance scores sum to the the prediction score. \n\nBest of all, interior gradients can be computed just as easily as gradients. In contrast, previous methods are complex to implement, which hinders practical adoption.", "pdf": "/pdf/95894e6fa8b21d5e355bb0167096107df64f71d5.pdf", "TL;DR": "A method for identifying feature importance in deep networks using gradients of counterfactual inputs", "paperhash": "sundararajan|gradients_of_counterfactuals", "conflicts": ["google.com"], "keywords": ["Deep learning", "Computer vision", "Theory"], "authors": ["Mukund Sundararajan", "Ankur Taly", "Qiqi Yan"], "authorids": ["mukunds@google.com", "ataly@google.com", "qiqiyan@google.com"]}, "writers": [], "nonreaders": [], "details": {"replyCount": 9, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1475686800000, "tmdate": 1478287705855, "id": "ICLR.cc/2017/conference/-/submission", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/pcs"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": null, "replyto": null, "writers": {"values-regex": "~.*"}, "signatures": {"values-regex": "~.*", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"pdf": {"required": true, "order": 5, "description": "Either upload a PDF file or provide a direct link to your PDF on ArXiv (link must begin with http(s) and end with .pdf)", "value-regex": "upload|(http|https):\\/\\/.+\\.pdf"}, "title": {"required": true, "order": 1, "description": "Title of paper.", "value-regex": ".{1,250}"}, "abstract": {"required": true, "order": 4, "description": "Abstract of paper.", "value-regex": "[\\S\\s]{1,5000}"}, "authors": {"required": true, "order": 2, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of author names, as they appear in the paper."}, "conflicts": {"required": true, "order": 100, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of email domains of people who would have a conflict of interest in reviewing this paper, (e.g., cs.umass.edu;google.com, etc.)."}, "keywords": {"order": 6, "description": "Comma separated list of keywords.", "values-dropdown": ["Theory", "Computer vision", "Speech", "Natural language processing", "Deep learning", "Unsupervised Learning", "Supervised Learning", "Semi-Supervised Learning", "Reinforcement Learning", "Transfer Learning", "Multi-modal learning", "Applications", "Optimization", "Structured prediction", "Games"]}, "TL;DR": {"required": false, "order": 3, "description": "\"Too Long; Didn't Read\": a short sentence describing your paper", "value-regex": "[^\\n]{0,250}"}, "authorids": {"required": true, "order": 3, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of author email addresses, in the same order as above."}}}, "nonreaders": [], "noninvitees": [], "expdate": 1483462800000, "cdate": 1478287705855}}}, {"tddate": null, "tmdate": 1482510769443, "tcdate": 1482510769443, "number": 3, "id": "HJFn-CqNx", "invitation": "ICLR.cc/2017/conference/-/paper106/public/comment", "forum": "rJzaDdYxx", "replyto": "HkiWSoKVe", "signatures": ["~Ankur_Taly1"], "readers": ["everyone"], "writers": ["~Ankur_Taly1"], "content": {"title": "Regarding batch normalization", "comment": "The Inception model we analyzed did not use batch normalization, but the drug discovery network did. We do not think batch normalization affects saturation in the network---at least we don't have any theory or empirical evidence for it yet."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Gradients of Counterfactuals", "abstract": "Gradients have been used to quantify feature importance in machine learning models. Unfortunately, in nonlinear deep networks, not only individual neurons but also the whole network can saturate, and as a result an important input feature can have a tiny gradient. We study various networks, and observe that this phenomena is indeed widespread, across many inputs.\n\nWe propose to examine interior gradients, which are gradients of counterfactual inputs constructed by scaling down the original input. We apply our method to the GoogleNet architecture for object recognition in images, as well as a ligand-based virtual screening network with categorical features and an LSTM based language model for the Penn Treebank dataset. We visualize how interior gradients better capture feature importance. Furthermore, interior gradients are applicable to a wide variety of deep networks, and have the attribution property that the feature importance scores sum to the the prediction score. \n\nBest of all, interior gradients can be computed just as easily as gradients. In contrast, previous methods are complex to implement, which hinders practical adoption.", "pdf": "/pdf/95894e6fa8b21d5e355bb0167096107df64f71d5.pdf", "TL;DR": "A method for identifying feature importance in deep networks using gradients of counterfactual inputs", "paperhash": "sundararajan|gradients_of_counterfactuals", "conflicts": ["google.com"], "keywords": ["Deep learning", "Computer vision", "Theory"], "authors": ["Mukund Sundararajan", "Ankur Taly", "Qiqi Yan"], "authorids": ["mukunds@google.com", "ataly@google.com", "qiqiyan@google.com"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287725585, "id": "ICLR.cc/2017/conference/-/paper106/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "rJzaDdYxx", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper106/reviewers", "ICLR.cc/2017/conference/paper106/areachairs"], "cdate": 1485287725585}}}, {"tddate": null, "tmdate": 1482433794967, "tcdate": 1482433794967, "number": 2, "id": "HkiWSoKVe", "invitation": "ICLR.cc/2017/conference/-/paper106/public/comment", "forum": "rJzaDdYxx", "replyto": "B1qHBhx4x", "signatures": ["~Ankur_Taly1"], "readers": ["everyone"], "writers": ["~Ankur_Taly1"], "content": {"title": "Response to AnonReviewer1", "comment": "We thank the reviewer for the review.\n \nRegarding \u201cauthors do not explain why visualizing regular gradients isn't correlated with the importance of features relevant\u201d. \n\nWe do think we discuss this. Notice that Section 2.1 (\u201cGradients do not reflect feature importance\u201d) gives examples of gradients not reflecting feature importance, and Section 2.2 (\u201cSaturation\u201d) discusses why to an extent. \n\nThe thesis proposed by the reviewer \u201cIs it the case that the gradients of the features that are confident of the prediction remain low, while those with high uncertainty will have strong gradients\u201d seems plausible empirically. For instance, see this GIF for the label \u201cdrilling platform\u201d obtained by combining the visualizations of interior gradients at various scaling intensities https://github.com/ankurtaly/Attributions/blob/master/Visualizations/Gifs/6717aba6a10b230f.gif). Gradients at lower intensities seem to emphasize prominent features while those at higher intensities emphasize less important ones (peripheral?). Notice also that ablating the gradient at the image often does not change the prediction, another data point toward the thesis that they are unimportant (see Section 2.1 for an example).  \n\nOne exercise is we plan to carry out is to find the set of neurons that contribute to the gradient (and via Proposition 1 to the final prediction), at lower values of the scaling parameter (alpha)---these gradients look to us like they capture meaningful features and therefore the neurons through which they flow seem critical. We could check whether these critical neurons remain saturated at higher alpha, including for alpha=1. This exercise serves to connect the apparent variation in the interior gradients as alpha increases to the operation of important neurons within the network. "}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Gradients of Counterfactuals", "abstract": "Gradients have been used to quantify feature importance in machine learning models. Unfortunately, in nonlinear deep networks, not only individual neurons but also the whole network can saturate, and as a result an important input feature can have a tiny gradient. We study various networks, and observe that this phenomena is indeed widespread, across many inputs.\n\nWe propose to examine interior gradients, which are gradients of counterfactual inputs constructed by scaling down the original input. We apply our method to the GoogleNet architecture for object recognition in images, as well as a ligand-based virtual screening network with categorical features and an LSTM based language model for the Penn Treebank dataset. We visualize how interior gradients better capture feature importance. Furthermore, interior gradients are applicable to a wide variety of deep networks, and have the attribution property that the feature importance scores sum to the the prediction score. \n\nBest of all, interior gradients can be computed just as easily as gradients. In contrast, previous methods are complex to implement, which hinders practical adoption.", "pdf": "/pdf/95894e6fa8b21d5e355bb0167096107df64f71d5.pdf", "TL;DR": "A method for identifying feature importance in deep networks using gradients of counterfactual inputs", "paperhash": "sundararajan|gradients_of_counterfactuals", "conflicts": ["google.com"], "keywords": ["Deep learning", "Computer vision", "Theory"], "authors": ["Mukund Sundararajan", "Ankur Taly", "Qiqi Yan"], "authorids": ["mukunds@google.com", "ataly@google.com", "qiqiyan@google.com"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287725585, "id": "ICLR.cc/2017/conference/-/paper106/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "rJzaDdYxx", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper106/reviewers", "ICLR.cc/2017/conference/paper106/areachairs"], "cdate": 1485287725585}}}, {"tddate": null, "tmdate": 1482433584148, "tcdate": 1482433584148, "number": 1, "id": "H1_4ViKEl", "invitation": "ICLR.cc/2017/conference/-/paper106/public/comment", "forum": "rJzaDdYxx", "replyto": "rJzaDdYxx", "signatures": ["~Ankur_Taly1"], "readers": ["everyone"], "writers": ["~Ankur_Taly1"], "content": {"title": "Response to AnonReviewer2 and AnonReviewer3", "comment": "We thank the reviewers for a detailed review.  The rebuttal below addresses some of the mentioned concerns.\n\nRegarding \u201cfar too long\u201d and \u201cunnecessarily grandiose name for literally, a scaled image\u201d: \n\nWe\u2019d agree that the paper is long for the ideas in it. The length stems from the difficulty of not having a crisp evaluation technique for feature importance. So we try to resort to qualitative discussions together with images. But we  can definitely try to tighten the writing. We are open to changing the title of the paper to \u201cInterior Gradients\u201d or something like it, though it is worth noting that while scaling intensities seems natural for images, analogous scaling for Text or Drug Discovery models results in inputs that are more obviously fake, i.e., counterfactual.\n\nRegarding \u201chow the proposed scheme for feature importance ranking is useful\u201d: \n\nWhile debugging deep networks is hard in general, examining feature importance scores offers a limited but useful insight into the operation of the network on a particular input. For us, the experience with the Drug Discovery network where we found, via our attributions, that the bond features were severely underused (see Section 3.1) was a concrete instance of how feature importance analysis could help debug and improve networks. As we discussed in section 2.7, we do mention the limitations of our technique in understanding what the network does. The same pros and cons would seem to apply to other feature importance techniques (see Section 2.8). The key difference is that ours is much easier to implement--- as simple as computing a gradient.\n\nRegarding \u201cThe quantitative evidence is quite limited and most of the paper is spent on qualitative results\u201d: \n\nWe address with the following multipart response; apologies for the lengthy response.\n\nFirst, we do plan to produce a comparison with side by sides for LRP and our method for the MNIST data set over the next few weeks as a sanity check.\n\nHowever, we don\u2019t think that that there is a strong metric to compare different feature importance techniques. This is acknowledged by Samek et al in their 2015 ICML Visualization Workshop work. We elaborate on this further at the end of this rebuttal.  \n\nMethods like DeepLift and Layer-wise Relevance Propagation (LRP) break a fundamental axiom in our mind: the attributions depend on the implementation, i.e. two networks that implement identical input-output  relationships can have different attributions. This seems odd---see Section 2.4 and Figure 14.  Perhaps, we did not emphasize this enough in the paper. \n\nThe main focus for us in the evaluation conducted so far has been to ensure that our output was sensible. In Section 2.5, we discuss a combination of approaches that we used to assess the attributions, including eyeballing, localization, and ablations. We welcome you to visualize more attributions at: https://github.com/ankurtaly/Attributions.\n\nOn the lack of a good evaluation metric:\n\nFundamentally,  it is hard to tell apart inaccuracies in the attribution from inaccuracies in the network\u2019s predictions. The two metrics we know of --- ablations and localization---both come with their own downsides (though we did implement both of them for our attribution technique).\n\nAblation:  The idea here is to ablate features that receive a high attribution and measure the corresponding drop (or increase) in the network\u2019s prediction score. There are two main issues with such an ablation based metric.\n* First, ablating features may lead to unnatural inputs which the network has never seen before and therefore the prediction score drop may be reflective of the absurdness of the ablated input rather than the importance of the feature.\n* Second, when features interact then ablating individual features may not be enough to measure their importance. For instance, if two feature interact disjunctively then ablating either one would not lead to a drop in the prediction score.\n\nLocalization: In object recognition networks (such as Inception), where the prediction can be localized to a small region of the image, the accuracy of an attribution map can be measured based on the amount of attribution falling on the corresponding region---larger the attribution the better. Such an analysis can be carried out using human-drawn bounding-box labels, which are available for the ImageNet dataset. Unfortunately, this evaluation also has its own set of flaws.\n* First, simply measuring the total attribution falling on the object does not tell how effectively the attribution distinguishes various features of the object. \n* Second, while the object may be localized to a region of the image, the context around the object would certainly contribute to its prediction. \nFor instance, in this image https://github.com/ankurtaly/Attributions/blob/master/Visualizations/IntegratedGradients/1bd6987fa9219dec.jpg, the attribution from the gradients at the image is more localized to the object (\u201ccabbage butterfly\u201d) than the attribution from the interior gradients. Yet to a human, the  attribution from the interior gradients appears qualitatively better as it focuses sharply on features of the butterfly and also shows parts of the context that seem relevant to the prediction."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Gradients of Counterfactuals", "abstract": "Gradients have been used to quantify feature importance in machine learning models. Unfortunately, in nonlinear deep networks, not only individual neurons but also the whole network can saturate, and as a result an important input feature can have a tiny gradient. We study various networks, and observe that this phenomena is indeed widespread, across many inputs.\n\nWe propose to examine interior gradients, which are gradients of counterfactual inputs constructed by scaling down the original input. We apply our method to the GoogleNet architecture for object recognition in images, as well as a ligand-based virtual screening network with categorical features and an LSTM based language model for the Penn Treebank dataset. We visualize how interior gradients better capture feature importance. Furthermore, interior gradients are applicable to a wide variety of deep networks, and have the attribution property that the feature importance scores sum to the the prediction score. \n\nBest of all, interior gradients can be computed just as easily as gradients. In contrast, previous methods are complex to implement, which hinders practical adoption.", "pdf": "/pdf/95894e6fa8b21d5e355bb0167096107df64f71d5.pdf", "TL;DR": "A method for identifying feature importance in deep networks using gradients of counterfactual inputs", "paperhash": "sundararajan|gradients_of_counterfactuals", "conflicts": ["google.com"], "keywords": ["Deep learning", "Computer vision", "Theory"], "authors": ["Mukund Sundararajan", "Ankur Taly", "Qiqi Yan"], "authorids": ["mukunds@google.com", "ataly@google.com", "qiqiyan@google.com"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287725585, "id": "ICLR.cc/2017/conference/-/paper106/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "rJzaDdYxx", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper106/reviewers", "ICLR.cc/2017/conference/paper106/areachairs"], "cdate": 1485287725585}}}, {"tddate": null, "tmdate": 1482104288360, "tcdate": 1482104288360, "number": 3, "id": "BJ_JRc4Nl", "invitation": "ICLR.cc/2017/conference/-/paper106/official/review", "forum": "rJzaDdYxx", "replyto": "rJzaDdYxx", "signatures": ["ICLR.cc/2017/conference/paper106/AnonReviewer2"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/conference/paper106/AnonReviewer2"], "content": {"title": "review: lacking experimental comparison to prior work", "rating": "3: Clear rejection", "review": "This paper proposes a new method, interior gradients, for analysing feature importance in deep neural networks.  The interior gradient is the gradient measured on a scaled version of the input.  The integrated gradient is the integral of interior gradients over all scaling factors.  Visualizations comparing integrated gradients with standard gradients on real images input to the Inception CNN show that integrated gradients correspond to an intuitive notion of feature importance.\n\nWhile motivation and qualitative examples are appealing, the paper lacks both qualitative and quantitative comparison to prior work.  Only the baseline (simply the standard gradient) is presented as reference for qualitative comparison.  Yet, the paper cites numerous other works (DeepLift, layer-wise relevance propagation, guided backpropagation) that all attack the same problem of feature importance.  Lack of comparison to any of these methods is a major weakness of the paper.  I do not believe it is fit for publication without such comparisons.  My pre-review question articulated this same concern and has not been answered.\n", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Gradients of Counterfactuals", "abstract": "Gradients have been used to quantify feature importance in machine learning models. Unfortunately, in nonlinear deep networks, not only individual neurons but also the whole network can saturate, and as a result an important input feature can have a tiny gradient. We study various networks, and observe that this phenomena is indeed widespread, across many inputs.\n\nWe propose to examine interior gradients, which are gradients of counterfactual inputs constructed by scaling down the original input. We apply our method to the GoogleNet architecture for object recognition in images, as well as a ligand-based virtual screening network with categorical features and an LSTM based language model for the Penn Treebank dataset. We visualize how interior gradients better capture feature importance. Furthermore, interior gradients are applicable to a wide variety of deep networks, and have the attribution property that the feature importance scores sum to the the prediction score. \n\nBest of all, interior gradients can be computed just as easily as gradients. In contrast, previous methods are complex to implement, which hinders practical adoption.", "pdf": "/pdf/95894e6fa8b21d5e355bb0167096107df64f71d5.pdf", "TL;DR": "A method for identifying feature importance in deep networks using gradients of counterfactual inputs", "paperhash": "sundararajan|gradients_of_counterfactuals", "conflicts": ["google.com"], "keywords": ["Deep learning", "Computer vision", "Theory"], "authors": ["Mukund Sundararajan", "Ankur Taly", "Qiqi Yan"], "authorids": ["mukunds@google.com", "ataly@google.com", "qiqiyan@google.com"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1481932799000, "tmdate": 1482512695260, "id": "ICLR.cc/2017/conference/-/paper106/official/review", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/conference/paper106/reviewers"], "noninvitees": ["ICLR.cc/2017/conference/paper106/AnonReviewer1", "ICLR.cc/2017/conference/paper106/AnonReviewer3", "ICLR.cc/2017/conference/paper106/AnonReviewer2"], "reply": {"forum": "rJzaDdYxx", "replyto": "rJzaDdYxx", "writers": {"values-regex": "ICLR.cc/2017/conference/paper106/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/conference/paper106/AnonReviewer[0-9]+"}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "value-regex": "[\\S\\s]{1,20000}"}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1489708799000, "cdate": 1482512695260}}}, {"tddate": null, "tmdate": 1481934458399, "tcdate": 1481934458399, "number": 2, "id": "rkGtUbzEl", "invitation": "ICLR.cc/2017/conference/-/paper106/official/review", "forum": "rJzaDdYxx", "replyto": "rJzaDdYxx", "signatures": ["ICLR.cc/2017/conference/paper106/AnonReviewer3"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/conference/paper106/AnonReviewer3"], "content": {"title": "review", "rating": "3: Clear rejection", "review": "The authors propose to measure \u201cfeature importance\u201d, or specifically, which pixels contribute most to a network\u2019s classification of an image. A simple (albeit not particularly effective) heuristic for measuring feature importance is to measure the gradients of the predicted class wrt each pixel in an input image I. This assigns a score to each pixel in I (that ranks how much the output prediction would change if a given pixel were to change). In this paper, the authors build on this and propose to measure feature importance by computing gradients of the output wrt scaled version of the input image, alpha*I, where alpha is a scalar between 0 and 1, then summing across all values of alpha to obtain their feature importance score. Here the scaling is simply linear scaling of the pixel values (alpha=0 is all black image, alpha=1 is original image). The authors call these scaled images \u201ccounterfactuals\u201d which seems like quite an unnecessarily grandiose name for literally, a scaled image. \n\nThe authors show a number of visualizations that indicate that the proposed feature importance score is more reasonable than just looking at gradients only with respect to the original image. They also show some quantitative evidence that the pixels highlighted by the proposed measure are more likely to fall on the objects rather than spurious parts of the image (in particular, see figure 5). The method is also applied to other types of networks. The quantitative evidence is quite limited and most of the paper is spent on qualitative results.\n\nWhile the goal of understanding deep networks is of key importance, it is not clear whether this paper really help elucidate much. The main interesting observation in this paper is that scaling an image by a small alpha (i.e. creating a faint image) places more \u201cimportance\u201d on pixels on the object related to the correct class prediction. Beyond that, the paper builds a bit on this, but no deeper insight is gained. The authors propose some hand-wavy explanation of why using small alpha (faint image) may force the network to focus on the object, but the argument is not convincing. It would have been interesting to try to probe a bit deeper here, but that may not be easy.\n\nUltimately, it is not clear how the proposed scheme for feature importance ranking is useful. First, it is still quite noisy and does not truly help understand what a deep net is doing on a particular image. Performing a single gradient descent step on an image (or on the collection of scaled versions of the image) hardly begins to probe the internal workings of a network. Moreover, as the authors admit, the scheme makes the assumption that each pixel is independent, which is clearly false.\n\nConsidering the paper presents a very simple idea, it is far too long. The main paper is 14 pages, up to 19 with references and appendix. In general the writing is long-winded and overly verbose. It detracted substantially from the paper. The authors also define unnecessary terminology. \u201cGradients of Coutnerfactuals\u201d sounds quite fancy, but is not very related to the ideas explored in the writing. I would encourage the authors to tighten up the writing and figures down to a more readable page length, and to more clearly spell out the ideas explored early on.", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Gradients of Counterfactuals", "abstract": "Gradients have been used to quantify feature importance in machine learning models. Unfortunately, in nonlinear deep networks, not only individual neurons but also the whole network can saturate, and as a result an important input feature can have a tiny gradient. We study various networks, and observe that this phenomena is indeed widespread, across many inputs.\n\nWe propose to examine interior gradients, which are gradients of counterfactual inputs constructed by scaling down the original input. We apply our method to the GoogleNet architecture for object recognition in images, as well as a ligand-based virtual screening network with categorical features and an LSTM based language model for the Penn Treebank dataset. We visualize how interior gradients better capture feature importance. Furthermore, interior gradients are applicable to a wide variety of deep networks, and have the attribution property that the feature importance scores sum to the the prediction score. \n\nBest of all, interior gradients can be computed just as easily as gradients. In contrast, previous methods are complex to implement, which hinders practical adoption.", "pdf": "/pdf/95894e6fa8b21d5e355bb0167096107df64f71d5.pdf", "TL;DR": "A method for identifying feature importance in deep networks using gradients of counterfactual inputs", "paperhash": "sundararajan|gradients_of_counterfactuals", "conflicts": ["google.com"], "keywords": ["Deep learning", "Computer vision", "Theory"], "authors": ["Mukund Sundararajan", "Ankur Taly", "Qiqi Yan"], "authorids": ["mukunds@google.com", "ataly@google.com", "qiqiyan@google.com"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1481932799000, "tmdate": 1482512695260, "id": "ICLR.cc/2017/conference/-/paper106/official/review", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/conference/paper106/reviewers"], "noninvitees": ["ICLR.cc/2017/conference/paper106/AnonReviewer1", "ICLR.cc/2017/conference/paper106/AnonReviewer3", "ICLR.cc/2017/conference/paper106/AnonReviewer2"], "reply": {"forum": "rJzaDdYxx", "replyto": "rJzaDdYxx", "writers": {"values-regex": "ICLR.cc/2017/conference/paper106/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/conference/paper106/AnonReviewer[0-9]+"}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "value-regex": "[\\S\\s]{1,20000}"}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1489708799000, "cdate": 1482512695260}}}, {"tddate": null, "tmdate": 1481848129675, "tcdate": 1481848129669, "number": 1, "id": "B1qHBhx4x", "invitation": "ICLR.cc/2017/conference/-/paper106/official/review", "forum": "rJzaDdYxx", "replyto": "rJzaDdYxx", "signatures": ["ICLR.cc/2017/conference/paper106/AnonReviewer1"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/conference/paper106/AnonReviewer1"], "content": {"title": "Scaling input samples.", "rating": "5: Marginally below acceptance threshold", "review": "This work proposes to use visualization of gradients to further understand the importance of features (i.e. pixels) for visual classification. Overall, this presented visualizations are interesting, however, the approach is very ad hoc. The authors do not explain why visualizing regular gradients isn't correlated with the importance of features relevant to the given visual category and proceed to the interior gradient approach. \n\nOne particular question with regular gradients at features that form the spatial support of the visual class. Is it the case that the gradients of the features that are confident of the prediction remain low, while those with high uncertainty will have strong gradients?\n\nWith regards to the interior gradients, it is unclear how the scaling parameter \\alpha affects the feature importance and how it is related to attention.\n\nFinally, does this model use batch normalization?", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Gradients of Counterfactuals", "abstract": "Gradients have been used to quantify feature importance in machine learning models. Unfortunately, in nonlinear deep networks, not only individual neurons but also the whole network can saturate, and as a result an important input feature can have a tiny gradient. We study various networks, and observe that this phenomena is indeed widespread, across many inputs.\n\nWe propose to examine interior gradients, which are gradients of counterfactual inputs constructed by scaling down the original input. We apply our method to the GoogleNet architecture for object recognition in images, as well as a ligand-based virtual screening network with categorical features and an LSTM based language model for the Penn Treebank dataset. We visualize how interior gradients better capture feature importance. Furthermore, interior gradients are applicable to a wide variety of deep networks, and have the attribution property that the feature importance scores sum to the the prediction score. \n\nBest of all, interior gradients can be computed just as easily as gradients. In contrast, previous methods are complex to implement, which hinders practical adoption.", "pdf": "/pdf/95894e6fa8b21d5e355bb0167096107df64f71d5.pdf", "TL;DR": "A method for identifying feature importance in deep networks using gradients of counterfactual inputs", "paperhash": "sundararajan|gradients_of_counterfactuals", "conflicts": ["google.com"], "keywords": ["Deep learning", "Computer vision", "Theory"], "authors": ["Mukund Sundararajan", "Ankur Taly", "Qiqi Yan"], "authorids": ["mukunds@google.com", "ataly@google.com", "qiqiyan@google.com"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1481932799000, "tmdate": 1482512695260, "id": "ICLR.cc/2017/conference/-/paper106/official/review", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/conference/paper106/reviewers"], "noninvitees": ["ICLR.cc/2017/conference/paper106/AnonReviewer1", "ICLR.cc/2017/conference/paper106/AnonReviewer3", "ICLR.cc/2017/conference/paper106/AnonReviewer2"], "reply": {"forum": "rJzaDdYxx", "replyto": "rJzaDdYxx", "writers": {"values-regex": "ICLR.cc/2017/conference/paper106/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/conference/paper106/AnonReviewer[0-9]+"}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "value-regex": "[\\S\\s]{1,20000}"}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1489708799000, "cdate": 1482512695260}}}, {"tddate": null, "tmdate": 1481158872512, "tcdate": 1481158872504, "number": 1, "id": "r1x1ZNUQe", "invitation": "ICLR.cc/2017/conference/-/paper106/pre-review/question", "forum": "rJzaDdYxx", "replyto": "rJzaDdYxx", "signatures": ["ICLR.cc/2017/conference/paper106/AnonReviewer2"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/conference/paper106/AnonReviewer2"], "content": {"title": "comparison to prior work", "question": "Could you provide quantitative or qualitative comparison to one or more of the prior methods mentioned in the discussion on score back-propagation based methods (eg guided back-propagation)?  As there is significant prior work here, it would be appropriate to include it in the experimental comparison rather than simply arguing against it in the text.  The simplest option (gradients at image) is dismissed more easily than these alternatives, yet serves as the only experimental reference."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Gradients of Counterfactuals", "abstract": "Gradients have been used to quantify feature importance in machine learning models. Unfortunately, in nonlinear deep networks, not only individual neurons but also the whole network can saturate, and as a result an important input feature can have a tiny gradient. We study various networks, and observe that this phenomena is indeed widespread, across many inputs.\n\nWe propose to examine interior gradients, which are gradients of counterfactual inputs constructed by scaling down the original input. We apply our method to the GoogleNet architecture for object recognition in images, as well as a ligand-based virtual screening network with categorical features and an LSTM based language model for the Penn Treebank dataset. We visualize how interior gradients better capture feature importance. Furthermore, interior gradients are applicable to a wide variety of deep networks, and have the attribution property that the feature importance scores sum to the the prediction score. \n\nBest of all, interior gradients can be computed just as easily as gradients. In contrast, previous methods are complex to implement, which hinders practical adoption.", "pdf": "/pdf/95894e6fa8b21d5e355bb0167096107df64f71d5.pdf", "TL;DR": "A method for identifying feature importance in deep networks using gradients of counterfactual inputs", "paperhash": "sundararajan|gradients_of_counterfactuals", "conflicts": ["google.com"], "keywords": ["Deep learning", "Computer vision", "Theory"], "authors": ["Mukund Sundararajan", "Ankur Taly", "Qiqi Yan"], "authorids": ["mukunds@google.com", "ataly@google.com", "qiqiyan@google.com"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1480741199000, "tmdate": 1481158873100, "id": "ICLR.cc/2017/conference/-/paper106/pre-review/question", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/conference/paper106/reviewers"], "noninvitees": ["ICLR.cc/2017/conference/paper106/AnonReviewer2"], "reply": {"forum": "rJzaDdYxx", "replyto": "rJzaDdYxx", "writers": {"values-regex": "ICLR.cc/2017/conference/paper106/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/conference/paper106/AnonReviewer[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your question.", "value-regex": ".{1,500}"}, "question": {"order": 2, "description": "Your question", "value-regex": "[\\S\\s]{1,5000}"}}}, "nonreaders": [], "expdate": 1488517199000, "cdate": 1481158873100}}}], "count": 10}