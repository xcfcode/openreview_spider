{"notes": [{"id": "BkeWw6VFwr", "original": "B1l5nEcPDr", "number": 585, "cdate": 1569439064721, "ddate": null, "tcdate": 1569439064721, "tmdate": 1583912050780, "tddate": null, "forum": "BkeWw6VFwr", "replyto": null, "invitation": "ICLR.cc/2020/Conference/-/Blind_Submission", "content": {"title": "Certified Robustness for Top-k Predictions against Adversarial Perturbations via Randomized Smoothing", "authors": ["Jinyuan Jia", "Xiaoyu Cao", "Binghui Wang", "Neil Zhenqiang Gong"], "authorids": ["jinyuan.jia@duke.edu", "xiaoyu.cao@duke.edu", "binghui.wang@duke.edu", "neil.gong@duke.edu"], "keywords": ["Certified Adversarial Robustness", "Randomized Smoothing", "Adversarial Examples"], "TL;DR": "We study the certified robustness for top-k predictions via randomized smoothing under Gaussian noise and derive a tight robustness bound in L_2 norm.", "abstract": "It is well-known that  classifiers are vulnerable to adversarial perturbations. To defend against adversarial perturbations, various certified robustness results have been derived. However, existing certified robustnesses are limited to top-1 predictions. In many real-world applications, top-$k$ predictions are more relevant. In this work, we aim to derive certified robustness for top-$k$ predictions. In particular, our certified robustness is based on randomized smoothing, which turns any classifier to a new classifier via adding noise to an input example. We adopt randomized smoothing because it is scalable to large-scale neural networks and applicable to any classifier. We derive a tight robustness in $\\ell_2$ norm for top-$k$ predictions  when using randomized smoothing with Gaussian noise. We find that generalizing the certified robustness  from top-1 to top-$k$ predictions faces significant technical challenges. We also empirically evaluate our method on CIFAR10 and ImageNet. For example, our method can obtain an ImageNet classifier with a certified top-5 accuracy of 62.8\\% when the $\\ell_2$-norms of the adversarial perturbations are less than 0.5 (=127/255). Our code is publicly available at: \\url{https://github.com/jjy1994/Certify_Topk}. ", "pdf": "/pdf/993579d504d60a321258536f640b344729e5aea3.pdf", "paperhash": "jia|certified_robustness_for_topk_predictions_against_adversarial_perturbations_via_randomized_smoothing", "code": "https://github.com/jjy1994/Certify_Topk", "_bibtex": "@inproceedings{\njia2020certified,\ntitle={Certified Robustness for Top-k Predictions against Adversarial Perturbations via Randomized Smoothing},\nauthor={Jinyuan Jia and Xiaoyu Cao and Binghui Wang and Neil Zhenqiang Gong},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=BkeWw6VFwr}\n}", "full_presentation_video": "", "original_pdf": "/attachment/e090f8f14f0da0dec936b5e08ae78744f80d6ce0.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "signatures": ["ICLR.cc/2020/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference"], "details": {"replyCount": 9, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"reply": {"readers": {"values-regex": ".*"}, "writers": {"values": ["ICLR.cc/2020/Conference"]}, "signatures": {"values": ["ICLR.cc/2020/Conference"]}, "content": {"spotlight_video": {"value-regex": ".*"}, "full_presentation_video": {"value-regex": ".*"}, "original_pdf": {"required": false, "description": "Upload a PDF file that ends with .pdf", "value-regex": ".*"}, "appendix": {"value-regex": ".*"}, "authorids": {"values-regex": ".*"}, "poster": {"value-regex": ".*"}, "authors": {"values": ["Anonymous"]}, "slides": {"value-regex": ".*"}}}, "final": [], "signatures": ["ICLR.cc/2020/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference"], "noninvitees": [], "tcdate": 1569271260237, "tmdate": 1593459412141, "id": "ICLR.cc/2020/Conference/-/Blind_Submission"}}, "tauthor": "OpenReview.net"}, {"id": "LhX3XGIQVL", "original": null, "number": 1, "cdate": 1576798700497, "ddate": null, "tcdate": 1576798700497, "tmdate": 1576800935435, "tddate": null, "forum": "BkeWw6VFwr", "replyto": "BkeWw6VFwr", "invitation": "ICLR.cc/2020/Conference/Paper585/-/Decision", "content": {"decision": "Accept (Poster)", "comment": "The paper extends the work on randomized smoothing for certifiably robust classifiers developed in prior work to a weaker specification requiring that the set of top-k predictions remain unchanged under adversarial perturbations of the input (rather than just the top-1). This enables the authors to achieve stronger results on robustness of classifiers on CIFAR10 and ImageNet (where the authors report the top-5 accuracy).\n\nThis is an interesting extension of certified defenses that is likely to be relevant for complex prediction tasks with several classes (ImageNet and beyond), where top-1 robustness may be difficult and unrealistic to achieve.\n\nThe reviewers were in consensus on acceptance and minor concerns were alleviated during the rebuttal phase.\n\nI therefore recommend acceptance.", "title": "Paper Decision"}, "signatures": ["ICLR.cc/2020/Conference/Program_Chairs"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Program_Chairs"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Certified Robustness for Top-k Predictions against Adversarial Perturbations via Randomized Smoothing", "authors": ["Jinyuan Jia", "Xiaoyu Cao", "Binghui Wang", "Neil Zhenqiang Gong"], "authorids": ["jinyuan.jia@duke.edu", "xiaoyu.cao@duke.edu", "binghui.wang@duke.edu", "neil.gong@duke.edu"], "keywords": ["Certified Adversarial Robustness", "Randomized Smoothing", "Adversarial Examples"], "TL;DR": "We study the certified robustness for top-k predictions via randomized smoothing under Gaussian noise and derive a tight robustness bound in L_2 norm.", "abstract": "It is well-known that  classifiers are vulnerable to adversarial perturbations. To defend against adversarial perturbations, various certified robustness results have been derived. However, existing certified robustnesses are limited to top-1 predictions. In many real-world applications, top-$k$ predictions are more relevant. In this work, we aim to derive certified robustness for top-$k$ predictions. In particular, our certified robustness is based on randomized smoothing, which turns any classifier to a new classifier via adding noise to an input example. We adopt randomized smoothing because it is scalable to large-scale neural networks and applicable to any classifier. We derive a tight robustness in $\\ell_2$ norm for top-$k$ predictions  when using randomized smoothing with Gaussian noise. We find that generalizing the certified robustness  from top-1 to top-$k$ predictions faces significant technical challenges. We also empirically evaluate our method on CIFAR10 and ImageNet. For example, our method can obtain an ImageNet classifier with a certified top-5 accuracy of 62.8\\% when the $\\ell_2$-norms of the adversarial perturbations are less than 0.5 (=127/255). Our code is publicly available at: \\url{https://github.com/jjy1994/Certify_Topk}. ", "pdf": "/pdf/993579d504d60a321258536f640b344729e5aea3.pdf", "paperhash": "jia|certified_robustness_for_topk_predictions_against_adversarial_perturbations_via_randomized_smoothing", "code": "https://github.com/jjy1994/Certify_Topk", "_bibtex": "@inproceedings{\njia2020certified,\ntitle={Certified Robustness for Top-k Predictions against Adversarial Perturbations via Randomized Smoothing},\nauthor={Jinyuan Jia and Xiaoyu Cao and Binghui Wang and Neil Zhenqiang Gong},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=BkeWw6VFwr}\n}", "full_presentation_video": "", "original_pdf": "/attachment/e090f8f14f0da0dec936b5e08ae78744f80d6ce0.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "tags": [], "invitation": {"reply": {"writers": {"description": "How your identity will be displayed.", "values-regex": ["ICLR.cc/2020/Conference/Program_Chairs"]}, "signatures": {"values": ["ICLR.cc/2020/Conference/Program_Chairs"], "description": "How your identity will be displayed."}, "content": {"decision": {"value-radio": ["Accept (Spotlight)", "Accept (Talk)", "Accept (Poster)", "Reject"], "description": "Decision", "required": true, "order": 2}, "title": {"value": "Paper Decision", "required": true, "order": 1}, "comment": {"value-regex": "[\\S\\s]{0,5000}", "description": "", "required": false, "order": 3}}, "forum": "BkeWw6VFwr", "replyto": "BkeWw6VFwr", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}}, "expdate": 1576854540000, "duedate": 1576853940000, "multiReply": false, "readers": ["everyone"], "invitees": ["ICLR.cc/2020/Conference/Program_Chairs"], "tcdate": 1576795724281, "tmdate": 1576800275900, "super": "ICLR.cc/2020/Conference/-/Decision", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper585/-/Decision"}}}, {"id": "r1lZzDODsH", "original": null, "number": 5, "cdate": 1573517065337, "ddate": null, "tcdate": 1573517065337, "tmdate": 1573517065337, "tddate": null, "forum": "BkeWw6VFwr", "replyto": "SyeQ3xEPir", "invitation": "ICLR.cc/2020/Conference/Paper585/-/Official_Comment", "content": {"title": "Thank the reviewer for the comments", "comment": "We thank the reviewer for the insightful comments and carefully reading of our responses. "}, "signatures": ["ICLR.cc/2020/Conference/Paper585/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper585/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Certified Robustness for Top-k Predictions against Adversarial Perturbations via Randomized Smoothing", "authors": ["Jinyuan Jia", "Xiaoyu Cao", "Binghui Wang", "Neil Zhenqiang Gong"], "authorids": ["jinyuan.jia@duke.edu", "xiaoyu.cao@duke.edu", "binghui.wang@duke.edu", "neil.gong@duke.edu"], "keywords": ["Certified Adversarial Robustness", "Randomized Smoothing", "Adversarial Examples"], "TL;DR": "We study the certified robustness for top-k predictions via randomized smoothing under Gaussian noise and derive a tight robustness bound in L_2 norm.", "abstract": "It is well-known that  classifiers are vulnerable to adversarial perturbations. To defend against adversarial perturbations, various certified robustness results have been derived. However, existing certified robustnesses are limited to top-1 predictions. In many real-world applications, top-$k$ predictions are more relevant. In this work, we aim to derive certified robustness for top-$k$ predictions. In particular, our certified robustness is based on randomized smoothing, which turns any classifier to a new classifier via adding noise to an input example. We adopt randomized smoothing because it is scalable to large-scale neural networks and applicable to any classifier. We derive a tight robustness in $\\ell_2$ norm for top-$k$ predictions  when using randomized smoothing with Gaussian noise. We find that generalizing the certified robustness  from top-1 to top-$k$ predictions faces significant technical challenges. We also empirically evaluate our method on CIFAR10 and ImageNet. For example, our method can obtain an ImageNet classifier with a certified top-5 accuracy of 62.8\\% when the $\\ell_2$-norms of the adversarial perturbations are less than 0.5 (=127/255). Our code is publicly available at: \\url{https://github.com/jjy1994/Certify_Topk}. ", "pdf": "/pdf/993579d504d60a321258536f640b344729e5aea3.pdf", "paperhash": "jia|certified_robustness_for_topk_predictions_against_adversarial_perturbations_via_randomized_smoothing", "code": "https://github.com/jjy1994/Certify_Topk", "_bibtex": "@inproceedings{\njia2020certified,\ntitle={Certified Robustness for Top-k Predictions against Adversarial Perturbations via Randomized Smoothing},\nauthor={Jinyuan Jia and Xiaoyu Cao and Binghui Wang and Neil Zhenqiang Gong},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=BkeWw6VFwr}\n}", "full_presentation_video": "", "original_pdf": "/attachment/e090f8f14f0da0dec936b5e08ae78744f80d6ce0.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "BkeWw6VFwr", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper585/Authors", "ICLR.cc/2020/Conference/Paper585/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper585/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper585/Reviewers", "ICLR.cc/2020/Conference/Paper585/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper585/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper585/Authors|ICLR.cc/2020/Conference/Paper585/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504169253, "tmdate": 1576860528407, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper585/Authors", "ICLR.cc/2020/Conference/Paper585/Reviewers", "ICLR.cc/2020/Conference/Paper585/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper585/-/Official_Comment"}}}, {"id": "SkgZDld6Yr", "original": null, "number": 2, "cdate": 1571811417169, "ddate": null, "tcdate": 1571811417169, "tmdate": 1573499072707, "tddate": null, "forum": "BkeWw6VFwr", "replyto": "BkeWw6VFwr", "invitation": "ICLR.cc/2020/Conference/Paper585/-/Official_Review", "content": {"experience_assessment": "I have published in this field for several years.", "rating": "6: Weak Accept", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "title": "Official Blind Review #1", "review": "This paper builds upon the random smoothing technique for top-1 prediction proposed by Cohen et al. for certifying top-k predictions with probabilistic guarantees, which enjoys good scalability to large neural networks and in principle can be applied to any classifier. \n\n- Contributions:\n1. The authors aim to provide (probabilistic) certification on top-k predictions, which to my knowledge is the first work to consider this setup. Many applications such as recommendation systems indeed use top-k predictions as a performance measure. The problem setup is new and important in the research of robustness certification.\n\n2. In terms of technical contributions, the authors identify the difficulty of extending top-1 prediction to top-k prediction, due to the requirement of simultaneous confidence interval estimation of the bounds on the actual class predictions. To cope with this difficulty, the authors proposed simultaneous confidence interval estimation based on Clopper-Pearson method and Bonferroni correction. However, I am not sure the difficulty is caused by the necessity of estimating multiple probability bounds, or simply the limitation of the proposed algorithm. I hope the authors can address my concerns in the Questions below. \n\n3. Experimental results on Cifar-10 and ImageNet showed improved lower bound on certified L2-norm radius when increasing k. The authors also performed an ablation study of different parameters in the proposed algorithm.\n\n- Questions:\n1. Intuitively, when extending top-1 certification to top-k certification, one would expect using ordered statistics of the prediction outputs from the randomly perturbed inputs. As long as the original label's prediction probability is in the top-k label set, the smoothed classifier is directly certified. Instead of ordered statistics, the authors tackle this problem by considering estimating upper and lower bounds of each class prediction probability. Therefore, the problem becomes more difficult as k increases, since this indirect approach needs to simultaneous estimate those probability bounds. I wonder the current approach will be suboptimal when compared to the ordered statistics approach. I would like to know the authors thoughts on this regard. That is, is the claimed difficulty an outcome when using the proposed indirect bound estimation for certification, or it's provably more difficult?\n\n2. The discussion on Fig.3 says \"We observe that \u001b \\sigma controls a trade-off between normal accuracy under no attacks and robustness. Specifically, when \u001b is larger, the accuracy under no attacks (i.e., the accuracy when radius is 0) is larger, but the certified top-k accuracy drops more quickly as the radius increases.\" However, it seems that larger \\sigma actually gives lower accuracy under no attacks in Figure 3. Please clarify.\n\nOverall, this paper brings some new insights and results in robustness certification, but some claims and statements need to be further justified. I am happy to increase my rating if my concerns are addressed. \n", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory."}, "signatures": ["ICLR.cc/2020/Conference/Paper585/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper585/AnonReviewer1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Certified Robustness for Top-k Predictions against Adversarial Perturbations via Randomized Smoothing", "authors": ["Jinyuan Jia", "Xiaoyu Cao", "Binghui Wang", "Neil Zhenqiang Gong"], "authorids": ["jinyuan.jia@duke.edu", "xiaoyu.cao@duke.edu", "binghui.wang@duke.edu", "neil.gong@duke.edu"], "keywords": ["Certified Adversarial Robustness", "Randomized Smoothing", "Adversarial Examples"], "TL;DR": "We study the certified robustness for top-k predictions via randomized smoothing under Gaussian noise and derive a tight robustness bound in L_2 norm.", "abstract": "It is well-known that  classifiers are vulnerable to adversarial perturbations. To defend against adversarial perturbations, various certified robustness results have been derived. However, existing certified robustnesses are limited to top-1 predictions. In many real-world applications, top-$k$ predictions are more relevant. In this work, we aim to derive certified robustness for top-$k$ predictions. In particular, our certified robustness is based on randomized smoothing, which turns any classifier to a new classifier via adding noise to an input example. We adopt randomized smoothing because it is scalable to large-scale neural networks and applicable to any classifier. We derive a tight robustness in $\\ell_2$ norm for top-$k$ predictions  when using randomized smoothing with Gaussian noise. We find that generalizing the certified robustness  from top-1 to top-$k$ predictions faces significant technical challenges. We also empirically evaluate our method on CIFAR10 and ImageNet. For example, our method can obtain an ImageNet classifier with a certified top-5 accuracy of 62.8\\% when the $\\ell_2$-norms of the adversarial perturbations are less than 0.5 (=127/255). Our code is publicly available at: \\url{https://github.com/jjy1994/Certify_Topk}. ", "pdf": "/pdf/993579d504d60a321258536f640b344729e5aea3.pdf", "paperhash": "jia|certified_robustness_for_topk_predictions_against_adversarial_perturbations_via_randomized_smoothing", "code": "https://github.com/jjy1994/Certify_Topk", "_bibtex": "@inproceedings{\njia2020certified,\ntitle={Certified Robustness for Top-k Predictions against Adversarial Perturbations via Randomized Smoothing},\nauthor={Jinyuan Jia and Xiaoyu Cao and Binghui Wang and Neil Zhenqiang Gong},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=BkeWw6VFwr}\n}", "full_presentation_video": "", "original_pdf": "/attachment/e090f8f14f0da0dec936b5e08ae78744f80d6ce0.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "BkeWw6VFwr", "replyto": "BkeWw6VFwr", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper585/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper585/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1575488928252, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper585/Reviewers"], "noninvitees": [], "tcdate": 1570237750018, "tmdate": 1575488928264, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper585/-/Official_Review"}}}, {"id": "SyeQ3xEPir", "original": null, "number": 4, "cdate": 1573499050556, "ddate": null, "tcdate": 1573499050556, "tmdate": 1573499050556, "tddate": null, "forum": "BkeWw6VFwr", "replyto": "rylPsDceiH", "invitation": "ICLR.cc/2020/Conference/Paper585/-/Official_Comment", "content": {"title": "Thank the authors for the response", "comment": "I thank the authors for the response, which clearly addresses my concerns. I will increase my rating. "}, "signatures": ["ICLR.cc/2020/Conference/Paper585/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper585/AnonReviewer1", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Certified Robustness for Top-k Predictions against Adversarial Perturbations via Randomized Smoothing", "authors": ["Jinyuan Jia", "Xiaoyu Cao", "Binghui Wang", "Neil Zhenqiang Gong"], "authorids": ["jinyuan.jia@duke.edu", "xiaoyu.cao@duke.edu", "binghui.wang@duke.edu", "neil.gong@duke.edu"], "keywords": ["Certified Adversarial Robustness", "Randomized Smoothing", "Adversarial Examples"], "TL;DR": "We study the certified robustness for top-k predictions via randomized smoothing under Gaussian noise and derive a tight robustness bound in L_2 norm.", "abstract": "It is well-known that  classifiers are vulnerable to adversarial perturbations. To defend against adversarial perturbations, various certified robustness results have been derived. However, existing certified robustnesses are limited to top-1 predictions. In many real-world applications, top-$k$ predictions are more relevant. In this work, we aim to derive certified robustness for top-$k$ predictions. In particular, our certified robustness is based on randomized smoothing, which turns any classifier to a new classifier via adding noise to an input example. We adopt randomized smoothing because it is scalable to large-scale neural networks and applicable to any classifier. We derive a tight robustness in $\\ell_2$ norm for top-$k$ predictions  when using randomized smoothing with Gaussian noise. We find that generalizing the certified robustness  from top-1 to top-$k$ predictions faces significant technical challenges. We also empirically evaluate our method on CIFAR10 and ImageNet. For example, our method can obtain an ImageNet classifier with a certified top-5 accuracy of 62.8\\% when the $\\ell_2$-norms of the adversarial perturbations are less than 0.5 (=127/255). Our code is publicly available at: \\url{https://github.com/jjy1994/Certify_Topk}. ", "pdf": "/pdf/993579d504d60a321258536f640b344729e5aea3.pdf", "paperhash": "jia|certified_robustness_for_topk_predictions_against_adversarial_perturbations_via_randomized_smoothing", "code": "https://github.com/jjy1994/Certify_Topk", "_bibtex": "@inproceedings{\njia2020certified,\ntitle={Certified Robustness for Top-k Predictions against Adversarial Perturbations via Randomized Smoothing},\nauthor={Jinyuan Jia and Xiaoyu Cao and Binghui Wang and Neil Zhenqiang Gong},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=BkeWw6VFwr}\n}", "full_presentation_video": "", "original_pdf": "/attachment/e090f8f14f0da0dec936b5e08ae78744f80d6ce0.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "BkeWw6VFwr", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper585/Authors", "ICLR.cc/2020/Conference/Paper585/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper585/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper585/Reviewers", "ICLR.cc/2020/Conference/Paper585/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper585/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper585/Authors|ICLR.cc/2020/Conference/Paper585/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504169253, "tmdate": 1576860528407, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper585/Authors", "ICLR.cc/2020/Conference/Paper585/Reviewers", "ICLR.cc/2020/Conference/Paper585/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper585/-/Official_Comment"}}}, {"id": "rygi0v5liS", "original": null, "number": 3, "cdate": 1573066706588, "ddate": null, "tcdate": 1573066706588, "tmdate": 1573066706588, "tddate": null, "forum": "BkeWw6VFwr", "replyto": "Hkxarun2tB", "invitation": "ICLR.cc/2020/Conference/Paper585/-/Official_Comment", "content": {"title": "Author response", "comment": "Thanks for the reviews. Our responses to the comments are as follows:\n\nResponse 1: Given k, we can estimate the lower and upper bounds of the output probabilities only for the top-k labels with the largest frequencies among the random samples. Therefore, a larger k leads to estimation of probability bounds for more labels. However, such computational overhead is negligible. For instance, even if we compute the probability bounds for all labels, the time spent on estimating the probability bounds is less than 1% of the overall computation time. \n\nResponse 2: radius=0 corresponds to the accuracy under no attack, which decreases as \\sigma increases. The reason is that we add larger noise during training and testing when \\sigma is larger, which decreases the accuracy under no attack. \n\nResponse 3: Sorry for the confusion. It was a typo in our description. The description should be \u201cwhen \\sigma is smaller...\u201d. We modified the sentence in the paper to be \u201cSpecifically, when \\sigma  is smaller, the accuracy under no attacks (i.e., the accuracy when radius is 0) is larger, but the certified top-k accuracy drops more quickly as the radius increases.\u201d. \n\nResponse 4: Thanks for the suggestion! However, we found that the time for finding the solution to the certified accuracy is negligible, compared to the overall computation time of randomized smoothing. Specifically, the major computation time is for the base classifier to predict labels for the randomly perturbed inputs. \n\nResponse 5: We have updated all L_2 to \\ell_2 in the paper. "}, "signatures": ["ICLR.cc/2020/Conference/Paper585/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper585/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Certified Robustness for Top-k Predictions against Adversarial Perturbations via Randomized Smoothing", "authors": ["Jinyuan Jia", "Xiaoyu Cao", "Binghui Wang", "Neil Zhenqiang Gong"], "authorids": ["jinyuan.jia@duke.edu", "xiaoyu.cao@duke.edu", "binghui.wang@duke.edu", "neil.gong@duke.edu"], "keywords": ["Certified Adversarial Robustness", "Randomized Smoothing", "Adversarial Examples"], "TL;DR": "We study the certified robustness for top-k predictions via randomized smoothing under Gaussian noise and derive a tight robustness bound in L_2 norm.", "abstract": "It is well-known that  classifiers are vulnerable to adversarial perturbations. To defend against adversarial perturbations, various certified robustness results have been derived. However, existing certified robustnesses are limited to top-1 predictions. In many real-world applications, top-$k$ predictions are more relevant. In this work, we aim to derive certified robustness for top-$k$ predictions. In particular, our certified robustness is based on randomized smoothing, which turns any classifier to a new classifier via adding noise to an input example. We adopt randomized smoothing because it is scalable to large-scale neural networks and applicable to any classifier. We derive a tight robustness in $\\ell_2$ norm for top-$k$ predictions  when using randomized smoothing with Gaussian noise. We find that generalizing the certified robustness  from top-1 to top-$k$ predictions faces significant technical challenges. We also empirically evaluate our method on CIFAR10 and ImageNet. For example, our method can obtain an ImageNet classifier with a certified top-5 accuracy of 62.8\\% when the $\\ell_2$-norms of the adversarial perturbations are less than 0.5 (=127/255). Our code is publicly available at: \\url{https://github.com/jjy1994/Certify_Topk}. ", "pdf": "/pdf/993579d504d60a321258536f640b344729e5aea3.pdf", "paperhash": "jia|certified_robustness_for_topk_predictions_against_adversarial_perturbations_via_randomized_smoothing", "code": "https://github.com/jjy1994/Certify_Topk", "_bibtex": "@inproceedings{\njia2020certified,\ntitle={Certified Robustness for Top-k Predictions against Adversarial Perturbations via Randomized Smoothing},\nauthor={Jinyuan Jia and Xiaoyu Cao and Binghui Wang and Neil Zhenqiang Gong},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=BkeWw6VFwr}\n}", "full_presentation_video": "", "original_pdf": "/attachment/e090f8f14f0da0dec936b5e08ae78744f80d6ce0.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "BkeWw6VFwr", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper585/Authors", "ICLR.cc/2020/Conference/Paper585/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper585/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper585/Reviewers", "ICLR.cc/2020/Conference/Paper585/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper585/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper585/Authors|ICLR.cc/2020/Conference/Paper585/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504169253, "tmdate": 1576860528407, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper585/Authors", "ICLR.cc/2020/Conference/Paper585/Reviewers", "ICLR.cc/2020/Conference/Paper585/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper585/-/Official_Comment"}}}, {"id": "rylPsDceiH", "original": null, "number": 2, "cdate": 1573066655349, "ddate": null, "tcdate": 1573066655349, "tmdate": 1573066655349, "tddate": null, "forum": "BkeWw6VFwr", "replyto": "SkgZDld6Yr", "invitation": "ICLR.cc/2020/Conference/Paper585/-/Official_Comment", "content": {"title": "Author response", "comment": "Thanks for the reviews. Our responses to the comments are as follows:\n\nResponse 1: The challenge for ordered statistics is how to derive the certified radius. Given an example and some randomly sampled noise, ordered statistics can probabilistically estimate whether a label is among the top-k labels predicted by the smoothed classifier. Ordered statistics can be used to estimate the top-k labels predicted by the smoothed classifier for an example with probabilistic guarantees. However, it is challenging for ordered statistics to derive the certified radius. Specifically, it is challenging to determine the upper bound of the adversarial perturbation (i.e., certified radius), with which a label is still among the top-k predicted labels. We believe it is an interesting future work to study how to leverage ordered statistics to derive certified radius.  \n\nResponse 2: Sorry for the confusion. It was a typo in our description. The description should be \u201cwhen \\sigma is smaller...\u201d. We modified the sentence to be \u201cSpecifically, when \\sigma  is smaller, the accuracy under no attacks (i.e., the accuracy when radius is 0) is larger, but the certified top-k accuracy drops more quickly as the radius increases.\u201d  "}, "signatures": ["ICLR.cc/2020/Conference/Paper585/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper585/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Certified Robustness for Top-k Predictions against Adversarial Perturbations via Randomized Smoothing", "authors": ["Jinyuan Jia", "Xiaoyu Cao", "Binghui Wang", "Neil Zhenqiang Gong"], "authorids": ["jinyuan.jia@duke.edu", "xiaoyu.cao@duke.edu", "binghui.wang@duke.edu", "neil.gong@duke.edu"], "keywords": ["Certified Adversarial Robustness", "Randomized Smoothing", "Adversarial Examples"], "TL;DR": "We study the certified robustness for top-k predictions via randomized smoothing under Gaussian noise and derive a tight robustness bound in L_2 norm.", "abstract": "It is well-known that  classifiers are vulnerable to adversarial perturbations. To defend against adversarial perturbations, various certified robustness results have been derived. However, existing certified robustnesses are limited to top-1 predictions. In many real-world applications, top-$k$ predictions are more relevant. In this work, we aim to derive certified robustness for top-$k$ predictions. In particular, our certified robustness is based on randomized smoothing, which turns any classifier to a new classifier via adding noise to an input example. We adopt randomized smoothing because it is scalable to large-scale neural networks and applicable to any classifier. We derive a tight robustness in $\\ell_2$ norm for top-$k$ predictions  when using randomized smoothing with Gaussian noise. We find that generalizing the certified robustness  from top-1 to top-$k$ predictions faces significant technical challenges. We also empirically evaluate our method on CIFAR10 and ImageNet. For example, our method can obtain an ImageNet classifier with a certified top-5 accuracy of 62.8\\% when the $\\ell_2$-norms of the adversarial perturbations are less than 0.5 (=127/255). Our code is publicly available at: \\url{https://github.com/jjy1994/Certify_Topk}. ", "pdf": "/pdf/993579d504d60a321258536f640b344729e5aea3.pdf", "paperhash": "jia|certified_robustness_for_topk_predictions_against_adversarial_perturbations_via_randomized_smoothing", "code": "https://github.com/jjy1994/Certify_Topk", "_bibtex": "@inproceedings{\njia2020certified,\ntitle={Certified Robustness for Top-k Predictions against Adversarial Perturbations via Randomized Smoothing},\nauthor={Jinyuan Jia and Xiaoyu Cao and Binghui Wang and Neil Zhenqiang Gong},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=BkeWw6VFwr}\n}", "full_presentation_video": "", "original_pdf": "/attachment/e090f8f14f0da0dec936b5e08ae78744f80d6ce0.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "BkeWw6VFwr", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper585/Authors", "ICLR.cc/2020/Conference/Paper585/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper585/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper585/Reviewers", "ICLR.cc/2020/Conference/Paper585/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper585/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper585/Authors|ICLR.cc/2020/Conference/Paper585/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504169253, "tmdate": 1576860528407, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper585/Authors", "ICLR.cc/2020/Conference/Paper585/Reviewers", "ICLR.cc/2020/Conference/Paper585/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper585/-/Official_Comment"}}}, {"id": "SJxN8wqesH", "original": null, "number": 1, "cdate": 1573066572289, "ddate": null, "tcdate": 1573066572289, "tmdate": 1573066572289, "tddate": null, "forum": "BkeWw6VFwr", "replyto": "Hyxynw6pFS", "invitation": "ICLR.cc/2020/Conference/Paper585/-/Official_Comment", "content": {"title": "Author response", "comment": "Thanks for the reviews. Our responses to the comments are as follows:\n\nResponse 1: On CIFAR10, the gaps between the certified top-k accuracy for different k are smaller than those between the top-k accuracy under no attacks (i.e., top-k-clean-accuracy), and they become smaller as the radius increases. On ImageNet, the gaps between the certified top-k accuracy for different k remain similar to those between the top-k accuracy under no attacks as the radius increases. Please refer to Figure 1. We added the analysis to Section 4.2.\n\nResponse 2: k is 3 in these two figures. We modified the captions of Figure 3 and Figure 4 to indicate the value of k. "}, "signatures": ["ICLR.cc/2020/Conference/Paper585/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper585/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Certified Robustness for Top-k Predictions against Adversarial Perturbations via Randomized Smoothing", "authors": ["Jinyuan Jia", "Xiaoyu Cao", "Binghui Wang", "Neil Zhenqiang Gong"], "authorids": ["jinyuan.jia@duke.edu", "xiaoyu.cao@duke.edu", "binghui.wang@duke.edu", "neil.gong@duke.edu"], "keywords": ["Certified Adversarial Robustness", "Randomized Smoothing", "Adversarial Examples"], "TL;DR": "We study the certified robustness for top-k predictions via randomized smoothing under Gaussian noise and derive a tight robustness bound in L_2 norm.", "abstract": "It is well-known that  classifiers are vulnerable to adversarial perturbations. To defend against adversarial perturbations, various certified robustness results have been derived. However, existing certified robustnesses are limited to top-1 predictions. In many real-world applications, top-$k$ predictions are more relevant. In this work, we aim to derive certified robustness for top-$k$ predictions. In particular, our certified robustness is based on randomized smoothing, which turns any classifier to a new classifier via adding noise to an input example. We adopt randomized smoothing because it is scalable to large-scale neural networks and applicable to any classifier. We derive a tight robustness in $\\ell_2$ norm for top-$k$ predictions  when using randomized smoothing with Gaussian noise. We find that generalizing the certified robustness  from top-1 to top-$k$ predictions faces significant technical challenges. We also empirically evaluate our method on CIFAR10 and ImageNet. For example, our method can obtain an ImageNet classifier with a certified top-5 accuracy of 62.8\\% when the $\\ell_2$-norms of the adversarial perturbations are less than 0.5 (=127/255). Our code is publicly available at: \\url{https://github.com/jjy1994/Certify_Topk}. ", "pdf": "/pdf/993579d504d60a321258536f640b344729e5aea3.pdf", "paperhash": "jia|certified_robustness_for_topk_predictions_against_adversarial_perturbations_via_randomized_smoothing", "code": "https://github.com/jjy1994/Certify_Topk", "_bibtex": "@inproceedings{\njia2020certified,\ntitle={Certified Robustness for Top-k Predictions against Adversarial Perturbations via Randomized Smoothing},\nauthor={Jinyuan Jia and Xiaoyu Cao and Binghui Wang and Neil Zhenqiang Gong},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=BkeWw6VFwr}\n}", "full_presentation_video": "", "original_pdf": "/attachment/e090f8f14f0da0dec936b5e08ae78744f80d6ce0.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "BkeWw6VFwr", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper585/Authors", "ICLR.cc/2020/Conference/Paper585/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper585/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper585/Reviewers", "ICLR.cc/2020/Conference/Paper585/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper585/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper585/Authors|ICLR.cc/2020/Conference/Paper585/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504169253, "tmdate": 1576860528407, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper585/Authors", "ICLR.cc/2020/Conference/Paper585/Reviewers", "ICLR.cc/2020/Conference/Paper585/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper585/-/Official_Comment"}}}, {"id": "Hkxarun2tB", "original": null, "number": 1, "cdate": 1571764293310, "ddate": null, "tcdate": 1571764293310, "tmdate": 1572972577115, "tddate": null, "forum": "BkeWw6VFwr", "replyto": "BkeWw6VFwr", "invitation": "ICLR.cc/2020/Conference/Paper585/-/Official_Review", "content": {"experience_assessment": "I have published one or two papers in this area.", "rating": "6: Weak Accept", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #3", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "Summary.\nThe paper proposes an extension to the work of Cohen et al. where a certified radius is deduced using a randomized smoothing approach. In particular, the authors show the radius at which a smoothed classifier g at under Gaussian perturbations is certified for the top k predictions. That is to say that the prediction will remain within the top k predictions of g. Setting k=1, one recovers Cohen et al. results. The authors show that the derived radius is tight.\n\nComments.\n\nI generally find the work interesting and I do not have any major criticism. The paper is also easy to read. I did not go through the tightness proof but I skimmed through proof of the certified radius and I find that the argument follows in a similar fashion to previous works using NP lemma.\n\nMay the authors comment on the following.\n\na) How does the method scale with k? - speedwise particularly when estimating the lower and upper bounds of the output probabilities.\n\nb) I do not understand Figure 3. Can the authors comment why for the radius = 0 the certified accuracy of the larger sigma (1.0) is actually worse than the smaller sigma? At least when k=1, increasing sigma increases the certified radius in which I expect to see that most of the samples to be actually within the radius and it should perform much better than lower sigma {0.25,0.5}. \n\nc) Based on the previous comment, I find the performance in Figure 3 in not consistent with the authors' discussion in page 7 \"when sigma is larger, the accuracy under no attacks (i.e. the accuracy when radius is 9) is larger .. \".\n\nd) Authors use bisection to find the solution to the certified accuracy for every t. Bisection is known to only enjoy linear convergence rate. Have the authors considered using algorithms that are much faster such as the sueprlinear secant method?\n\ne) Page 3 bullet point 3. \"it is impossible to certify a L_2 radius\" >> \"it is impossible to certify an \\ell_2 radius\". Consider changing all L_2 to \\ell_2."}, "signatures": ["ICLR.cc/2020/Conference/Paper585/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper585/AnonReviewer3"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Certified Robustness for Top-k Predictions against Adversarial Perturbations via Randomized Smoothing", "authors": ["Jinyuan Jia", "Xiaoyu Cao", "Binghui Wang", "Neil Zhenqiang Gong"], "authorids": ["jinyuan.jia@duke.edu", "xiaoyu.cao@duke.edu", "binghui.wang@duke.edu", "neil.gong@duke.edu"], "keywords": ["Certified Adversarial Robustness", "Randomized Smoothing", "Adversarial Examples"], "TL;DR": "We study the certified robustness for top-k predictions via randomized smoothing under Gaussian noise and derive a tight robustness bound in L_2 norm.", "abstract": "It is well-known that  classifiers are vulnerable to adversarial perturbations. To defend against adversarial perturbations, various certified robustness results have been derived. However, existing certified robustnesses are limited to top-1 predictions. In many real-world applications, top-$k$ predictions are more relevant. In this work, we aim to derive certified robustness for top-$k$ predictions. In particular, our certified robustness is based on randomized smoothing, which turns any classifier to a new classifier via adding noise to an input example. We adopt randomized smoothing because it is scalable to large-scale neural networks and applicable to any classifier. We derive a tight robustness in $\\ell_2$ norm for top-$k$ predictions  when using randomized smoothing with Gaussian noise. We find that generalizing the certified robustness  from top-1 to top-$k$ predictions faces significant technical challenges. We also empirically evaluate our method on CIFAR10 and ImageNet. For example, our method can obtain an ImageNet classifier with a certified top-5 accuracy of 62.8\\% when the $\\ell_2$-norms of the adversarial perturbations are less than 0.5 (=127/255). Our code is publicly available at: \\url{https://github.com/jjy1994/Certify_Topk}. ", "pdf": "/pdf/993579d504d60a321258536f640b344729e5aea3.pdf", "paperhash": "jia|certified_robustness_for_topk_predictions_against_adversarial_perturbations_via_randomized_smoothing", "code": "https://github.com/jjy1994/Certify_Topk", "_bibtex": "@inproceedings{\njia2020certified,\ntitle={Certified Robustness for Top-k Predictions against Adversarial Perturbations via Randomized Smoothing},\nauthor={Jinyuan Jia and Xiaoyu Cao and Binghui Wang and Neil Zhenqiang Gong},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=BkeWw6VFwr}\n}", "full_presentation_video": "", "original_pdf": "/attachment/e090f8f14f0da0dec936b5e08ae78744f80d6ce0.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "BkeWw6VFwr", "replyto": "BkeWw6VFwr", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper585/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper585/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1575488928252, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper585/Reviewers"], "noninvitees": [], "tcdate": 1570237750018, "tmdate": 1575488928264, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper585/-/Official_Review"}}}, {"id": "Hyxynw6pFS", "original": null, "number": 3, "cdate": 1571833767128, "ddate": null, "tcdate": 1571833767128, "tmdate": 1572972577030, "tddate": null, "forum": "BkeWw6VFwr", "replyto": "BkeWw6VFwr", "invitation": "ICLR.cc/2020/Conference/Paper585/-/Official_Review", "content": {"experience_assessment": "I have read many papers in this area.", "rating": "6: Weak Accept", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #2", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "Summary:\n\nThis paper studies the certifiable bounds for adversarial perturbations in \\ell_2 radius for top-k predictions instead of top-1 predictions.  The paper obtains a certifiable radius of \\ell_2 perturbations in the case of top-k predictions (Theorem 1) and shows that the bounds are tight (Theorem 2). The result thus generalizes the results obtained in Cohen et al. (2019) by setting k=1.\nSince Theorem 1 requires lower and upper bounds, the paper proposes two methods for calculating the bounds on multinomial probabilities. Experimental evidence suggests that one indeed obtains a better certifiable radius for the top-k radius vs. the top-1 radius.\n\nMy evaluation of the paper is positive: The theoretical results (Theorem 1 and 2) are new and study practical use cases of these models. The experimental results (Figure 1) support the claim that there is a non-trivial difference between the certified radii of top-1 and top-k predictions.  \nHowever, the level of technical novelty is relatively low. The proof of Theorem 1 follows the similar procedure for top-1 predictions and the methods proposed for estimating probabilities (BinoCP and SinuEM) are standard procedures.  \n\nOther comments:\n\n1. What is the trend of top-k-clean-accuracy and top-k-adversarial-accuracy as a function of k? Is this trend similar across different radii? \n\n2. What is the value of k in Figure 3 and Figure 4?"}, "signatures": ["ICLR.cc/2020/Conference/Paper585/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper585/AnonReviewer2"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Certified Robustness for Top-k Predictions against Adversarial Perturbations via Randomized Smoothing", "authors": ["Jinyuan Jia", "Xiaoyu Cao", "Binghui Wang", "Neil Zhenqiang Gong"], "authorids": ["jinyuan.jia@duke.edu", "xiaoyu.cao@duke.edu", "binghui.wang@duke.edu", "neil.gong@duke.edu"], "keywords": ["Certified Adversarial Robustness", "Randomized Smoothing", "Adversarial Examples"], "TL;DR": "We study the certified robustness for top-k predictions via randomized smoothing under Gaussian noise and derive a tight robustness bound in L_2 norm.", "abstract": "It is well-known that  classifiers are vulnerable to adversarial perturbations. To defend against adversarial perturbations, various certified robustness results have been derived. However, existing certified robustnesses are limited to top-1 predictions. In many real-world applications, top-$k$ predictions are more relevant. In this work, we aim to derive certified robustness for top-$k$ predictions. In particular, our certified robustness is based on randomized smoothing, which turns any classifier to a new classifier via adding noise to an input example. We adopt randomized smoothing because it is scalable to large-scale neural networks and applicable to any classifier. We derive a tight robustness in $\\ell_2$ norm for top-$k$ predictions  when using randomized smoothing with Gaussian noise. We find that generalizing the certified robustness  from top-1 to top-$k$ predictions faces significant technical challenges. We also empirically evaluate our method on CIFAR10 and ImageNet. For example, our method can obtain an ImageNet classifier with a certified top-5 accuracy of 62.8\\% when the $\\ell_2$-norms of the adversarial perturbations are less than 0.5 (=127/255). Our code is publicly available at: \\url{https://github.com/jjy1994/Certify_Topk}. ", "pdf": "/pdf/993579d504d60a321258536f640b344729e5aea3.pdf", "paperhash": "jia|certified_robustness_for_topk_predictions_against_adversarial_perturbations_via_randomized_smoothing", "code": "https://github.com/jjy1994/Certify_Topk", "_bibtex": "@inproceedings{\njia2020certified,\ntitle={Certified Robustness for Top-k Predictions against Adversarial Perturbations via Randomized Smoothing},\nauthor={Jinyuan Jia and Xiaoyu Cao and Binghui Wang and Neil Zhenqiang Gong},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=BkeWw6VFwr}\n}", "full_presentation_video": "", "original_pdf": "/attachment/e090f8f14f0da0dec936b5e08ae78744f80d6ce0.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "BkeWw6VFwr", "replyto": "BkeWw6VFwr", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper585/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper585/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1575488928252, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper585/Reviewers"], "noninvitees": [], "tcdate": 1570237750018, "tmdate": 1575488928264, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper585/-/Official_Review"}}}], "count": 10}