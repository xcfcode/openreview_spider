{"notes": [{"tddate": null, "ddate": null, "cdate": null, "tmdate": 1486396606327, "tcdate": 1486396606327, "number": 1, "id": "S1IT2zUue", "invitation": "ICLR.cc/2017/conference/-/paper476/acceptance", "forum": "Hy0L4t5el", "replyto": "Hy0L4t5el", "signatures": ["ICLR.cc/2017/pcs"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/pcs"], "content": {"decision": "Reject", "title": "ICLR committee final decision", "comment": "This paper is clearly written, but the method isn't demonstrated to solve any problem much better than simpler approaches. To quote one reviewer, \"the work may well be significant in the future, but is currently somewhat preliminary, lacks motivation, chooses a tree structured encoder without particular motivation, and is lacking in wider comparisons.\""}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"TL;DR": "", "title": "Tree-Structured Variational Autoencoder", "abstract": "Many kinds of variable-sized data we would like to model contain an internal hierarchical structure in the form of a tree, including source code, formal logical statements, and natural language sentences with parse trees. For such data it is natural to consider a model with matching computational structure. In this work, we introduce a variational autoencoder-based generative model for tree-structured data. We evaluate our model on a synthetic dataset, and a dataset with applications to automated theorem proving. By learning a latent representation over trees, our model can achieve similar test log likelihood to a standard autoregressive decoder, but with the number of sequentially dependent computations proportional to the depth of the tree instead of the number of nodes in the tree.", "pdf": "/pdf/29f62a14085790233f2c2036e86a2b2425898ae5.pdf", "paperhash": "shin|treestructured_variational_autoencoder", "keywords": [], "conflicts": ["berkeley.edu", "google.com"], "authors": ["Richard Shin", "Alexander A. Alemi", "Geoffrey Irving", "Oriol Vinyals"], "authorids": ["ricshin@cs.berkeley.edu", "alemi@google.com", "geoffreyi@google.com", "vinyals@google.com"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1486396607195, "id": "ICLR.cc/2017/conference/-/paper476/acceptance", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/pcs"], "noninvitees": ["ICLR.cc/2017/pcs"], "reply": {"forum": "Hy0L4t5el", "replyto": "Hy0L4t5el", "writers": {"values-regex": "ICLR.cc/2017/pcs"}, "signatures": {"values-regex": "ICLR.cc/2017/pcs", "description": "Your displayed identity associated with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your decision.", "value": "ICLR committee final decision"}, "comment": {"required": true, "order": 2, "description": "Decision comments.", "value-regex": "[\\S\\s]{1,5000}"}, "decision": {"required": true, "order": 3, "value-radio": ["Accept (Oral)", "Accept (Poster)", "Reject", "Invite to Workshop Track"]}}}, "nonreaders": [], "cdate": 1486396607195}}}, {"tddate": null, "tmdate": 1481941948101, "tcdate": 1481941948101, "number": 3, "id": "rk4TQQf4g", "invitation": "ICLR.cc/2017/conference/-/paper476/official/review", "forum": "Hy0L4t5el", "replyto": "Hy0L4t5el", "signatures": ["ICLR.cc/2017/conference/paper476/AnonReviewer3"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/conference/paper476/AnonReviewer3"], "content": {"title": "", "rating": "3: Clear rejection", "review": "The method overall seems to be a very interesting structural approach to variational autoencoders, however it seems to lack motivation as well as the application areas sufficient to prove its effectiveness.\n\nI see the attractiveness of using structural information in this context and I find it more intuitive than using a flat sequence representation, especially when there is a clear structure in the data. However experimental results seem to fail to be convincing in that regard.\n\nOne issue is the lack of a variety of applications in general, the experiments seem to be very limited in that regard, considering that the paper itself speaks about natural language applications. It would be interesting to use the latent representations learned with the model for some other end task and see how much it impacts the success of that end task compared to various baselines.\n\nIn my opinion, the paper has a potentially strong idea however in needs stronger results (and possibly in a wider variety of applications) as a proof of concept.", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"TL;DR": "", "title": "Tree-Structured Variational Autoencoder", "abstract": "Many kinds of variable-sized data we would like to model contain an internal hierarchical structure in the form of a tree, including source code, formal logical statements, and natural language sentences with parse trees. For such data it is natural to consider a model with matching computational structure. In this work, we introduce a variational autoencoder-based generative model for tree-structured data. We evaluate our model on a synthetic dataset, and a dataset with applications to automated theorem proving. By learning a latent representation over trees, our model can achieve similar test log likelihood to a standard autoregressive decoder, but with the number of sequentially dependent computations proportional to the depth of the tree instead of the number of nodes in the tree.", "pdf": "/pdf/29f62a14085790233f2c2036e86a2b2425898ae5.pdf", "paperhash": "shin|treestructured_variational_autoencoder", "keywords": [], "conflicts": ["berkeley.edu", "google.com"], "authors": ["Richard Shin", "Alexander A. Alemi", "Geoffrey Irving", "Oriol Vinyals"], "authorids": ["ricshin@cs.berkeley.edu", "alemi@google.com", "geoffreyi@google.com", "vinyals@google.com"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1481932799000, "tmdate": 1482512573406, "id": "ICLR.cc/2017/conference/-/paper476/official/review", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/conference/paper476/reviewers"], "noninvitees": ["ICLR.cc/2017/conference/paper476/AnonReviewer1", "ICLR.cc/2017/conference/paper476/AnonReviewer4", "ICLR.cc/2017/conference/paper476/AnonReviewer3"], "reply": {"forum": "Hy0L4t5el", "replyto": "Hy0L4t5el", "writers": {"values-regex": "ICLR.cc/2017/conference/paper476/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/conference/paper476/AnonReviewer[0-9]+"}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "value-regex": "[\\S\\s]{1,20000}"}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1489708799000, "cdate": 1482512573406}}}, {"tddate": null, "tmdate": 1481923145697, "tcdate": 1481923145697, "number": 2, "id": "rJzUcCbNe", "invitation": "ICLR.cc/2017/conference/-/paper476/official/review", "forum": "Hy0L4t5el", "replyto": "Hy0L4t5el", "signatures": ["ICLR.cc/2017/conference/paper476/AnonReviewer4"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/conference/paper476/AnonReviewer4"], "content": {"title": "a preliminary look at tree based variational inference", "rating": "3: Clear rejection", "review": "The authors propose a variational autoencoder for a specific form of tree-generating model.\n\nThe generative model for trees seems reasonable but is not fully motivated. If no previous references suggest this tree specification, then clear motivation for e.g. the extension beyond CFG should be given beyond the one sentence provided.\n\nGiven the tree model it may be natural to specify a tree model encoder, but the posterior distribution does not respect the structure of the prior (as the posterior distribution couples tree-distant variables), so there is in fact no good reason for this form, and a more general network could be compared with.\n\nThe approach provides sensible differentiable functions for encoding the network. The tests are indicative, but the results are very similar to the tested approaches, and it is not clear what the best evaluation metric ought to be.\n\nSignificance: the work may well be significant in the future, but is currently somewhat preliminary, lacks motivation, chooses a tree structured encoder without particular motivation, and is lacking in wider comparisons. There is also some lack of current motivation for the model, and no comparison with tractable models that do not need a variational autoencoder.\n\nOriginality: original, but at the moment it is not clear such originality is necessary.\n\nClarity: Good.\n\nExperiments: Sensible, but not extensive or conclusive.", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"TL;DR": "", "title": "Tree-Structured Variational Autoencoder", "abstract": "Many kinds of variable-sized data we would like to model contain an internal hierarchical structure in the form of a tree, including source code, formal logical statements, and natural language sentences with parse trees. For such data it is natural to consider a model with matching computational structure. In this work, we introduce a variational autoencoder-based generative model for tree-structured data. We evaluate our model on a synthetic dataset, and a dataset with applications to automated theorem proving. By learning a latent representation over trees, our model can achieve similar test log likelihood to a standard autoregressive decoder, but with the number of sequentially dependent computations proportional to the depth of the tree instead of the number of nodes in the tree.", "pdf": "/pdf/29f62a14085790233f2c2036e86a2b2425898ae5.pdf", "paperhash": "shin|treestructured_variational_autoencoder", "keywords": [], "conflicts": ["berkeley.edu", "google.com"], "authors": ["Richard Shin", "Alexander A. Alemi", "Geoffrey Irving", "Oriol Vinyals"], "authorids": ["ricshin@cs.berkeley.edu", "alemi@google.com", "geoffreyi@google.com", "vinyals@google.com"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1481932799000, "tmdate": 1482512573406, "id": "ICLR.cc/2017/conference/-/paper476/official/review", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/conference/paper476/reviewers"], "noninvitees": ["ICLR.cc/2017/conference/paper476/AnonReviewer1", "ICLR.cc/2017/conference/paper476/AnonReviewer4", "ICLR.cc/2017/conference/paper476/AnonReviewer3"], "reply": {"forum": "Hy0L4t5el", "replyto": "Hy0L4t5el", "writers": {"values-regex": "ICLR.cc/2017/conference/paper476/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/conference/paper476/AnonReviewer[0-9]+"}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "value-regex": "[\\S\\s]{1,20000}"}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1489708799000, "cdate": 1482512573406}}}, {"tddate": null, "tmdate": 1481921815714, "tcdate": 1481921815714, "number": 3, "id": "SJgXBAb4x", "invitation": "ICLR.cc/2017/conference/-/paper476/pre-review/question", "forum": "Hy0L4t5el", "replyto": "Hy0L4t5el", "signatures": ["ICLR.cc/2017/conference/paper476/AnonReviewer4"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/conference/paper476/AnonReviewer4"], "content": {"title": "Practicality", "question": "The approaches here do not currently seem practical for interesting problems. Is that the case, and if so is there reason to believe there will be obvious developments that will make it more practical?"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"TL;DR": "", "title": "Tree-Structured Variational Autoencoder", "abstract": "Many kinds of variable-sized data we would like to model contain an internal hierarchical structure in the form of a tree, including source code, formal logical statements, and natural language sentences with parse trees. For such data it is natural to consider a model with matching computational structure. In this work, we introduce a variational autoencoder-based generative model for tree-structured data. We evaluate our model on a synthetic dataset, and a dataset with applications to automated theorem proving. By learning a latent representation over trees, our model can achieve similar test log likelihood to a standard autoregressive decoder, but with the number of sequentially dependent computations proportional to the depth of the tree instead of the number of nodes in the tree.", "pdf": "/pdf/29f62a14085790233f2c2036e86a2b2425898ae5.pdf", "paperhash": "shin|treestructured_variational_autoencoder", "keywords": [], "conflicts": ["berkeley.edu", "google.com"], "authors": ["Richard Shin", "Alexander A. Alemi", "Geoffrey Irving", "Oriol Vinyals"], "authorids": ["ricshin@cs.berkeley.edu", "alemi@google.com", "geoffreyi@google.com", "vinyals@google.com"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1480741199000, "tmdate": 1481921816182, "id": "ICLR.cc/2017/conference/-/paper476/pre-review/question", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/conference/paper476/reviewers"], "noninvitees": ["ICLR.cc/2017/conference/paper476/AnonReviewer3", "ICLR.cc/2017/conference/paper476/AnonReviewer1", "ICLR.cc/2017/conference/paper476/AnonReviewer4"], "reply": {"forum": "Hy0L4t5el", "replyto": "Hy0L4t5el", "writers": {"values-regex": "ICLR.cc/2017/conference/paper476/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/conference/paper476/AnonReviewer[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your question.", "value-regex": ".{1,500}"}, "question": {"order": 2, "description": "Your question", "value-regex": "[\\S\\s]{1,5000}"}}}, "nonreaders": [], "expdate": 1488517199000, "cdate": 1481921816182}}}, {"tddate": null, "tmdate": 1481905554367, "tcdate": 1481905554367, "number": 1, "id": "Byq5r5bNl", "invitation": "ICLR.cc/2017/conference/-/paper476/official/review", "forum": "Hy0L4t5el", "replyto": "Hy0L4t5el", "signatures": ["ICLR.cc/2017/conference/paper476/AnonReviewer1"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/conference/paper476/AnonReviewer1"], "content": {"title": "Review", "rating": "4: Ok but not good enough - rejection", "review": "This paper introduces a novel extension of the variational autoencoder to arbitrary tree-structured outputs. Experiments are conducted on a synthetic arithmetic expression dataset and a first-order logic proof clause dataset in order to evaluate its density modeling performance.\n\nPros:\n+ The paper is clear and well-written.\n+ The tree-structure definition is sufficiently complete to capture a wide variety of tree types found in real-world situations.\n+ The tree generation and encoding procedure is elegant and well-articulated.\n+ The experiments, though limited in scope, are relatively thorough. The use of IWAE to obtain a better estimate of log likelihoods is a particularly nice touch.\n\nCons:\n- The performance gain over a baseline sequential model is marginal.\n- The experiments are limited in scope, both in the datasets considered and in the evaluation metrics used to compare the model with other approaches. Specifically: (a) there is only one set of results on a real-world dataset and in that case the proposed model performs worse than the baseline, and (b) there is no evaluation of the learned latent representation with respect to other tasks such as classification.\n- The ability of the model to generate trees in time proportional to the depth of the tree is proposed as a benefit of the approach, though this is not empirically validated in the experiments.\n\nThe procedures to generate and encode trees are clever in their repeated use of common operations. The weight sharing and gating operations seem important for this model to perform well but it is difficult to assess their utility without an ablation (in Table 1 and 2 these modifications are not evaluated side-by-side). Experiments in another domain (such as modeling source code, or parse trees conditioned on a sentence) would help in demonstrating the utility of this model. Overall the model seems promising and applicable to a variety of data but the lack of breadth in the experiments is a concern.\n\n* Section 3.1: \"We distinguish three types\" => two\n* Section 3.6: The exposition of the variable-sized latent state is slightly confusing because the issue of how many z's to generate is not discussed.\n* Section 4.2-4.3: When generating the datasets, did you verify that the test set is disjoint from the training set?\n* Table 1: Is there a particular reason why the variable latent results are missing for the depth 11 trees?", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"TL;DR": "", "title": "Tree-Structured Variational Autoencoder", "abstract": "Many kinds of variable-sized data we would like to model contain an internal hierarchical structure in the form of a tree, including source code, formal logical statements, and natural language sentences with parse trees. For such data it is natural to consider a model with matching computational structure. In this work, we introduce a variational autoencoder-based generative model for tree-structured data. We evaluate our model on a synthetic dataset, and a dataset with applications to automated theorem proving. By learning a latent representation over trees, our model can achieve similar test log likelihood to a standard autoregressive decoder, but with the number of sequentially dependent computations proportional to the depth of the tree instead of the number of nodes in the tree.", "pdf": "/pdf/29f62a14085790233f2c2036e86a2b2425898ae5.pdf", "paperhash": "shin|treestructured_variational_autoencoder", "keywords": [], "conflicts": ["berkeley.edu", "google.com"], "authors": ["Richard Shin", "Alexander A. Alemi", "Geoffrey Irving", "Oriol Vinyals"], "authorids": ["ricshin@cs.berkeley.edu", "alemi@google.com", "geoffreyi@google.com", "vinyals@google.com"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1481932799000, "tmdate": 1482512573406, "id": "ICLR.cc/2017/conference/-/paper476/official/review", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/conference/paper476/reviewers"], "noninvitees": ["ICLR.cc/2017/conference/paper476/AnonReviewer1", "ICLR.cc/2017/conference/paper476/AnonReviewer4", "ICLR.cc/2017/conference/paper476/AnonReviewer3"], "reply": {"forum": "Hy0L4t5el", "replyto": "Hy0L4t5el", "writers": {"values-regex": "ICLR.cc/2017/conference/paper476/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/conference/paper476/AnonReviewer[0-9]+"}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "value-regex": "[\\S\\s]{1,20000}"}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1489708799000, "cdate": 1482512573406}}}, {"tddate": null, "tmdate": 1480797720975, "tcdate": 1480797720970, "number": 2, "id": "HJb70jxXg", "invitation": "ICLR.cc/2017/conference/-/paper476/pre-review/question", "forum": "Hy0L4t5el", "replyto": "Hy0L4t5el", "signatures": ["ICLR.cc/2017/conference/paper476/AnonReviewer1"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/conference/paper476/AnonReviewer1"], "content": {"title": "Pre-review questions", "question": "\n1. Regarding the variable-sized latent VAE, how was the prior distribution over the number of latent variables specified? And during generation, how did you ensure that the resulting tree structure had the desired number of nodes? Did you generate the tree structure as described in 3.2 and simply draw z_{n_i} as necessary?\n2. Could you provide some more detail regarding the proof dataset? What sorts of functions and predicates did you use? How many types were there in the grammar? A simple example would also be helpful, perhaps showing a low-depth ground truth tree and a sample from the trained VAE."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"TL;DR": "", "title": "Tree-Structured Variational Autoencoder", "abstract": "Many kinds of variable-sized data we would like to model contain an internal hierarchical structure in the form of a tree, including source code, formal logical statements, and natural language sentences with parse trees. For such data it is natural to consider a model with matching computational structure. In this work, we introduce a variational autoencoder-based generative model for tree-structured data. We evaluate our model on a synthetic dataset, and a dataset with applications to automated theorem proving. By learning a latent representation over trees, our model can achieve similar test log likelihood to a standard autoregressive decoder, but with the number of sequentially dependent computations proportional to the depth of the tree instead of the number of nodes in the tree.", "pdf": "/pdf/29f62a14085790233f2c2036e86a2b2425898ae5.pdf", "paperhash": "shin|treestructured_variational_autoencoder", "keywords": [], "conflicts": ["berkeley.edu", "google.com"], "authors": ["Richard Shin", "Alexander A. Alemi", "Geoffrey Irving", "Oriol Vinyals"], "authorids": ["ricshin@cs.berkeley.edu", "alemi@google.com", "geoffreyi@google.com", "vinyals@google.com"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1480741199000, "tmdate": 1481921816182, "id": "ICLR.cc/2017/conference/-/paper476/pre-review/question", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/conference/paper476/reviewers"], "noninvitees": ["ICLR.cc/2017/conference/paper476/AnonReviewer3", "ICLR.cc/2017/conference/paper476/AnonReviewer1", "ICLR.cc/2017/conference/paper476/AnonReviewer4"], "reply": {"forum": "Hy0L4t5el", "replyto": "Hy0L4t5el", "writers": {"values-regex": "ICLR.cc/2017/conference/paper476/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/conference/paper476/AnonReviewer[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your question.", "value-regex": ".{1,500}"}, "question": {"order": 2, "description": "Your question", "value-regex": "[\\S\\s]{1,5000}"}}}, "nonreaders": [], "expdate": 1488517199000, "cdate": 1481921816182}}}, {"tddate": null, "tmdate": 1480615490413, "tcdate": 1480615490410, "number": 1, "id": "rkcrLJAfe", "invitation": "ICLR.cc/2017/conference/-/paper476/pre-review/question", "forum": "Hy0L4t5el", "replyto": "Hy0L4t5el", "signatures": ["ICLR.cc/2017/conference/paper476/AnonReviewer3"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/conference/paper476/AnonReviewer3"], "content": {"title": "Applications to language", "question": "Did the authors try the model on tree representations of natural language sentences? I'm curious about possible applications to dependency or constituency trees. "}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"TL;DR": "", "title": "Tree-Structured Variational Autoencoder", "abstract": "Many kinds of variable-sized data we would like to model contain an internal hierarchical structure in the form of a tree, including source code, formal logical statements, and natural language sentences with parse trees. For such data it is natural to consider a model with matching computational structure. In this work, we introduce a variational autoencoder-based generative model for tree-structured data. We evaluate our model on a synthetic dataset, and a dataset with applications to automated theorem proving. By learning a latent representation over trees, our model can achieve similar test log likelihood to a standard autoregressive decoder, but with the number of sequentially dependent computations proportional to the depth of the tree instead of the number of nodes in the tree.", "pdf": "/pdf/29f62a14085790233f2c2036e86a2b2425898ae5.pdf", "paperhash": "shin|treestructured_variational_autoencoder", "keywords": [], "conflicts": ["berkeley.edu", "google.com"], "authors": ["Richard Shin", "Alexander A. Alemi", "Geoffrey Irving", "Oriol Vinyals"], "authorids": ["ricshin@cs.berkeley.edu", "alemi@google.com", "geoffreyi@google.com", "vinyals@google.com"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1480741199000, "tmdate": 1481921816182, "id": "ICLR.cc/2017/conference/-/paper476/pre-review/question", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/conference/paper476/reviewers"], "noninvitees": ["ICLR.cc/2017/conference/paper476/AnonReviewer3", "ICLR.cc/2017/conference/paper476/AnonReviewer1", "ICLR.cc/2017/conference/paper476/AnonReviewer4"], "reply": {"forum": "Hy0L4t5el", "replyto": "Hy0L4t5el", "writers": {"values-regex": "ICLR.cc/2017/conference/paper476/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/conference/paper476/AnonReviewer[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your question.", "value-regex": ".{1,500}"}, "question": {"order": 2, "description": "Your question", "value-regex": "[\\S\\s]{1,5000}"}}}, "nonreaders": [], "expdate": 1488517199000, "cdate": 1481921816182}}}, {"tddate": null, "replyto": null, "ddate": null, "tmdate": 1478296663564, "tcdate": 1478296662368, "number": 476, "id": "Hy0L4t5el", "invitation": "ICLR.cc/2017/conference/-/submission", "forum": "Hy0L4t5el", "signatures": ["~Richard_Shin1"], "readers": ["everyone"], "content": {"TL;DR": "", "title": "Tree-Structured Variational Autoencoder", "abstract": "Many kinds of variable-sized data we would like to model contain an internal hierarchical structure in the form of a tree, including source code, formal logical statements, and natural language sentences with parse trees. For such data it is natural to consider a model with matching computational structure. In this work, we introduce a variational autoencoder-based generative model for tree-structured data. We evaluate our model on a synthetic dataset, and a dataset with applications to automated theorem proving. By learning a latent representation over trees, our model can achieve similar test log likelihood to a standard autoregressive decoder, but with the number of sequentially dependent computations proportional to the depth of the tree instead of the number of nodes in the tree.", "pdf": "/pdf/29f62a14085790233f2c2036e86a2b2425898ae5.pdf", "paperhash": "shin|treestructured_variational_autoencoder", "keywords": [], "conflicts": ["berkeley.edu", "google.com"], "authors": ["Richard Shin", "Alexander A. Alemi", "Geoffrey Irving", "Oriol Vinyals"], "authorids": ["ricshin@cs.berkeley.edu", "alemi@google.com", "geoffreyi@google.com", "vinyals@google.com"]}, "writers": [], "nonreaders": [], "details": {"replyCount": 7, "writable": false, "overwriting": [], "revisions": false, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1475686800000, "tmdate": 1478287705855, "id": "ICLR.cc/2017/conference/-/submission", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/pcs"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": null, "replyto": null, "writers": {"values-regex": "~.*"}, "signatures": {"values-regex": "~.*", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"pdf": {"required": true, "order": 5, "description": "Either upload a PDF file or provide a direct link to your PDF on ArXiv (link must begin with http(s) and end with .pdf)", "value-regex": "upload|(http|https):\\/\\/.+\\.pdf"}, "title": {"required": true, "order": 1, "description": "Title of paper.", "value-regex": ".{1,250}"}, "abstract": {"required": true, "order": 4, "description": "Abstract of paper.", "value-regex": "[\\S\\s]{1,5000}"}, "authors": {"required": true, "order": 2, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of author names, as they appear in the paper."}, "conflicts": {"required": true, "order": 100, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of email domains of people who would have a conflict of interest in reviewing this paper, (e.g., cs.umass.edu;google.com, etc.)."}, "keywords": {"order": 6, "description": "Comma separated list of keywords.", "values-dropdown": ["Theory", "Computer vision", "Speech", "Natural language processing", "Deep learning", "Unsupervised Learning", "Supervised Learning", "Semi-Supervised Learning", "Reinforcement Learning", "Transfer Learning", "Multi-modal learning", "Applications", "Optimization", "Structured prediction", "Games"]}, "TL;DR": {"required": false, "order": 3, "description": "\"Too Long; Didn't Read\": a short sentence describing your paper", "value-regex": "[^\\n]{0,250}"}, "authorids": {"required": true, "order": 3, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of author email addresses, in the same order as above."}}}, "nonreaders": [], "noninvitees": [], "expdate": 1483462800000, "cdate": 1478287705855}}}], "count": 8}