{"notes": [{"id": "HylthC4twr", "original": "BklF75Y_DS", "number": 1364, "cdate": 1569439408936, "ddate": null, "tcdate": 1569439408936, "tmdate": 1577168255537, "tddate": null, "forum": "HylthC4twr", "replyto": null, "invitation": "ICLR.cc/2020/Conference/-/Blind_Submission", "content": {"title": "Frequency Analysis for Graph Convolution Network", "authors": ["Hoang NT", "Takanori Maehara"], "authorids": ["hoang.nguyen.rh@riken.jp", "takanori.maehara@riken.jp"], "keywords": ["graph signal processing", "frequency analysis", "graph convolution neural network", "simplified convolution network", "semi-supervised vertex classification"], "TL;DR": "We study the filtering effect of GCN and SGC on benchmark datasets, find that all datasets are low-frequency and state-of-the-art models do not work in high-frequency settings.", "abstract": "In this work, we develop quantitative results to the learnablity of a two-layers Graph Convolutional Network (GCN). Instead of analyzing GCN under some classes of functions, our approach provides a quantitative gap between a two-layers GCN and a two-layers MLP model. Our analysis is based on the graph signal processing (GSP) approach, which can provide much more useful insights than the message-passing computational model. Interestingly, based on our analysis, we have been able to empirically demonstrate a few case when GCN and other state-of-the-art models cannot learn even when true vertex features are extremely low-dimensional. To demonstrate our theoretical findings and propose a solution to the aforementioned adversarial cases, we build a proof of concept graph neural network model with stacked filters named Graph Filters Neural Network (gfNN).\n", "pdf": "/pdf/7b77beae2b58e112aa72ed0dc311abc693ea9a51.pdf", "code": "https://gofile.io/?c=JrE62o ", "paperhash": "nt|frequency_analysis_for_graph_convolution_network", "original_pdf": "/attachment/6cb31ba54733adc8c8f92f4776a770ec8c177c88.pdf", "_bibtex": "@misc{\nnt2020frequency,\ntitle={Frequency Analysis for Graph Convolution Network},\nauthor={Hoang NT and Takanori Maehara},\nyear={2020},\nurl={https://openreview.net/forum?id=HylthC4twr}\n}"}, "signatures": ["ICLR.cc/2020/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference"], "details": {"replyCount": 11, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"reply": {"readers": {"values-regex": ".*"}, "writers": {"values": ["ICLR.cc/2020/Conference"]}, "signatures": {"values": ["ICLR.cc/2020/Conference"]}, "content": {"spotlight_video": {"value-regex": ".*"}, "full_presentation_video": {"value-regex": ".*"}, "original_pdf": {"required": false, "description": "Upload a PDF file that ends with .pdf", "value-regex": ".*"}, "appendix": {"value-regex": ".*"}, "authorids": {"values-regex": ".*"}, "poster": {"value-regex": ".*"}, "authors": {"values": ["Anonymous"]}, "slides": {"value-regex": ".*"}}}, "final": [], "signatures": ["ICLR.cc/2020/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference"], "noninvitees": [], "tcdate": 1569271260237, "tmdate": 1593459412141, "id": "ICLR.cc/2020/Conference/-/Blind_Submission"}}, "tauthor": "OpenReview.net"}, {"id": "I-3H8Eii5Q", "original": null, "number": 1, "cdate": 1576798721555, "ddate": null, "tcdate": 1576798721555, "tmdate": 1576800915023, "tddate": null, "forum": "HylthC4twr", "replyto": "HylthC4twr", "invitation": "ICLR.cc/2020/Conference/Paper1364/-/Decision", "content": {"decision": "Reject", "comment": "This paper studies two-layer graph convolutional networks and two-layer multi-layer perceptions and develops quantitative results of their effect in signal processing settings. The paper received 3 reviews by experts working in this area. R1 recommends Weak Accept, indicating that the paper provides some useful insight (e.g. into when graph neural networks are or are not appropriate for particular problems) and poses some specific technical questions. In follow up discussions after the author response, R1 and authors agree that there are some over claims in the paper but that these could be addressed with some toning down of claims and additional discussion. R2 recommends Weak Accept but raises several concerns about the technical contribution of the paper, indicating that some of the conclusions were already known or are unsurprising. R2 concludes \"I vote for weak accept, but I am fine if it is rejected.\" R3 recommends Reject, also questioning the significance of the technical contribution and whether some of the conclusions are well-supported by experiments, as well as some minor concerns about clarity of writing. In their thoughtful responses, authors acknowledge these concerns.  Given the split decision, the AC also read the paper. While it is clear it has significant merit, the concerns about significance of the contribution and support for conclusions (as acknowledged by authors) are important, and the AC feels a revision of the paper and another round of peer review is really needed to flesh these issues out. ", "title": "Paper Decision"}, "signatures": ["ICLR.cc/2020/Conference/Program_Chairs"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Program_Chairs"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Frequency Analysis for Graph Convolution Network", "authors": ["Hoang NT", "Takanori Maehara"], "authorids": ["hoang.nguyen.rh@riken.jp", "takanori.maehara@riken.jp"], "keywords": ["graph signal processing", "frequency analysis", "graph convolution neural network", "simplified convolution network", "semi-supervised vertex classification"], "TL;DR": "We study the filtering effect of GCN and SGC on benchmark datasets, find that all datasets are low-frequency and state-of-the-art models do not work in high-frequency settings.", "abstract": "In this work, we develop quantitative results to the learnablity of a two-layers Graph Convolutional Network (GCN). Instead of analyzing GCN under some classes of functions, our approach provides a quantitative gap between a two-layers GCN and a two-layers MLP model. Our analysis is based on the graph signal processing (GSP) approach, which can provide much more useful insights than the message-passing computational model. Interestingly, based on our analysis, we have been able to empirically demonstrate a few case when GCN and other state-of-the-art models cannot learn even when true vertex features are extremely low-dimensional. To demonstrate our theoretical findings and propose a solution to the aforementioned adversarial cases, we build a proof of concept graph neural network model with stacked filters named Graph Filters Neural Network (gfNN).\n", "pdf": "/pdf/7b77beae2b58e112aa72ed0dc311abc693ea9a51.pdf", "code": "https://gofile.io/?c=JrE62o ", "paperhash": "nt|frequency_analysis_for_graph_convolution_network", "original_pdf": "/attachment/6cb31ba54733adc8c8f92f4776a770ec8c177c88.pdf", "_bibtex": "@misc{\nnt2020frequency,\ntitle={Frequency Analysis for Graph Convolution Network},\nauthor={Hoang NT and Takanori Maehara},\nyear={2020},\nurl={https://openreview.net/forum?id=HylthC4twr}\n}"}, "tags": [], "invitation": {"reply": {"writers": {"description": "How your identity will be displayed.", "values-regex": ["ICLR.cc/2020/Conference/Program_Chairs"]}, "signatures": {"values": ["ICLR.cc/2020/Conference/Program_Chairs"], "description": "How your identity will be displayed."}, "content": {"decision": {"value-radio": ["Accept (Spotlight)", "Accept (Talk)", "Accept (Poster)", "Reject"], "description": "Decision", "required": true, "order": 2}, "title": {"value": "Paper Decision", "required": true, "order": 1}, "comment": {"value-regex": "[\\S\\s]{0,5000}", "description": "", "required": false, "order": 3}}, "forum": "HylthC4twr", "replyto": "HylthC4twr", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}}, "expdate": 1576854540000, "duedate": 1576853940000, "multiReply": false, "readers": ["everyone"], "invitees": ["ICLR.cc/2020/Conference/Program_Chairs"], "tcdate": 1576795716276, "tmdate": 1576800266379, "super": "ICLR.cc/2020/Conference/-/Decision", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper1364/-/Decision"}}}, {"id": "HJl80xU5jr", "original": null, "number": 13, "cdate": 1573703885784, "ddate": null, "tcdate": 1573703885784, "tmdate": 1573707025099, "tddate": null, "forum": "HylthC4twr", "replyto": "Syl_Dy8cjS", "invitation": "ICLR.cc/2020/Conference/Paper1364/-/Official_Comment", "content": {"title": "Thank you!", "comment": "Update: We add a footnote to the paragraph and extra information of the three datasets in Table 2 (appendix).\n\nIndeed, we will update our manuscript with this point. Thank you again for pointing this out!"}, "signatures": ["ICLR.cc/2020/Conference/Paper1364/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1364/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Frequency Analysis for Graph Convolution Network", "authors": ["Hoang NT", "Takanori Maehara"], "authorids": ["hoang.nguyen.rh@riken.jp", "takanori.maehara@riken.jp"], "keywords": ["graph signal processing", "frequency analysis", "graph convolution neural network", "simplified convolution network", "semi-supervised vertex classification"], "TL;DR": "We study the filtering effect of GCN and SGC on benchmark datasets, find that all datasets are low-frequency and state-of-the-art models do not work in high-frequency settings.", "abstract": "In this work, we develop quantitative results to the learnablity of a two-layers Graph Convolutional Network (GCN). Instead of analyzing GCN under some classes of functions, our approach provides a quantitative gap between a two-layers GCN and a two-layers MLP model. Our analysis is based on the graph signal processing (GSP) approach, which can provide much more useful insights than the message-passing computational model. Interestingly, based on our analysis, we have been able to empirically demonstrate a few case when GCN and other state-of-the-art models cannot learn even when true vertex features are extremely low-dimensional. To demonstrate our theoretical findings and propose a solution to the aforementioned adversarial cases, we build a proof of concept graph neural network model with stacked filters named Graph Filters Neural Network (gfNN).\n", "pdf": "/pdf/7b77beae2b58e112aa72ed0dc311abc693ea9a51.pdf", "code": "https://gofile.io/?c=JrE62o ", "paperhash": "nt|frequency_analysis_for_graph_convolution_network", "original_pdf": "/attachment/6cb31ba54733adc8c8f92f4776a770ec8c177c88.pdf", "_bibtex": "@misc{\nnt2020frequency,\ntitle={Frequency Analysis for Graph Convolution Network},\nauthor={Hoang NT and Takanori Maehara},\nyear={2020},\nurl={https://openreview.net/forum?id=HylthC4twr}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "HylthC4twr", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper1364/Authors", "ICLR.cc/2020/Conference/Paper1364/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper1364/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper1364/Reviewers", "ICLR.cc/2020/Conference/Paper1364/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper1364/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper1364/Authors|ICLR.cc/2020/Conference/Paper1364/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504157117, "tmdate": 1576860545122, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper1364/Authors", "ICLR.cc/2020/Conference/Paper1364/Reviewers", "ICLR.cc/2020/Conference/Paper1364/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper1364/-/Official_Comment"}}}, {"id": "Syl_Dy8cjS", "original": null, "number": 12, "cdate": 1573703519941, "ddate": null, "tcdate": 1573703519941, "tmdate": 1573703519941, "tddate": null, "forum": "HylthC4twr", "replyto": "rklf4em5oH", "invitation": "ICLR.cc/2020/Conference/Paper1364/-/Official_Comment", "content": {"title": "Thank you for clarification", "comment": "I thank the authors for considering my comment seriously and for providing additional information for clarification.\n\nI think the statistics of the datasets is informative for interpreting the noise level $\\sigma=0.01, 0.05$. Although it is up to the authors, I recommend to add the discussion in the previous comment to the paper."}, "signatures": ["ICLR.cc/2020/Conference/Paper1364/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1364/AnonReviewer1", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Frequency Analysis for Graph Convolution Network", "authors": ["Hoang NT", "Takanori Maehara"], "authorids": ["hoang.nguyen.rh@riken.jp", "takanori.maehara@riken.jp"], "keywords": ["graph signal processing", "frequency analysis", "graph convolution neural network", "simplified convolution network", "semi-supervised vertex classification"], "TL;DR": "We study the filtering effect of GCN and SGC on benchmark datasets, find that all datasets are low-frequency and state-of-the-art models do not work in high-frequency settings.", "abstract": "In this work, we develop quantitative results to the learnablity of a two-layers Graph Convolutional Network (GCN). Instead of analyzing GCN under some classes of functions, our approach provides a quantitative gap between a two-layers GCN and a two-layers MLP model. Our analysis is based on the graph signal processing (GSP) approach, which can provide much more useful insights than the message-passing computational model. Interestingly, based on our analysis, we have been able to empirically demonstrate a few case when GCN and other state-of-the-art models cannot learn even when true vertex features are extremely low-dimensional. To demonstrate our theoretical findings and propose a solution to the aforementioned adversarial cases, we build a proof of concept graph neural network model with stacked filters named Graph Filters Neural Network (gfNN).\n", "pdf": "/pdf/7b77beae2b58e112aa72ed0dc311abc693ea9a51.pdf", "code": "https://gofile.io/?c=JrE62o ", "paperhash": "nt|frequency_analysis_for_graph_convolution_network", "original_pdf": "/attachment/6cb31ba54733adc8c8f92f4776a770ec8c177c88.pdf", "_bibtex": "@misc{\nnt2020frequency,\ntitle={Frequency Analysis for Graph Convolution Network},\nauthor={Hoang NT and Takanori Maehara},\nyear={2020},\nurl={https://openreview.net/forum?id=HylthC4twr}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "HylthC4twr", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper1364/Authors", "ICLR.cc/2020/Conference/Paper1364/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper1364/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper1364/Reviewers", "ICLR.cc/2020/Conference/Paper1364/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper1364/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper1364/Authors|ICLR.cc/2020/Conference/Paper1364/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504157117, "tmdate": 1576860545122, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper1364/Authors", "ICLR.cc/2020/Conference/Paper1364/Reviewers", "ICLR.cc/2020/Conference/Paper1364/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper1364/-/Official_Comment"}}}, {"id": "rklf4em5oH", "original": null, "number": 11, "cdate": 1573691433795, "ddate": null, "tcdate": 1573691433795, "tmdate": 1573691433795, "tddate": null, "forum": "HylthC4twr", "replyto": "HJg8vTjKor", "invitation": "ICLR.cc/2020/Conference/Paper1364/-/Official_Comment", "content": {"title": "About Figure 3", "comment": "Hi, \n\nThank you for clarifying your comment to us! It is clear now.\n\nWe think you have a point here. It is indeed a large dip even within the low frequency domain for all datasets at $\\sigma = 0.05$. From your comment, we agree that our claim for \"strong denoising\" might be too aggressive. We can say there is a denoising effect and provide some more perspective.\n\nTo put in perspective, here are the standard deviation and mean of the signal $X$ for each dataset (across all channels):\n- Cora: $\\mu_X = 0.0007$; $\\sigma_X = 0.0071$ \n- Citeseer: $\\mu_X = 0.0003$; $\\sigma_X = 0.0029$ \n- Pubmed: $\\mu_X = 0.002$; $\\sigma_X = 0.0087$ \nIf we consider only the non-zero entries:\n- Cora: $\\mu_X = 0.0311$; $\\sigma_X = 0.05$ \n- Citeseer: $\\mu_X = 0.03$; $\\sigma_X = 0.0065$ \n- Pubmed: $\\mu_X = 0.02$; $\\sigma_X = 0.02$ \n\nAs you can see, noise level $\\sigma = 0.01$ and $\\sigma = 0.05$ is extremely large here. The reason for us to choose such large noise level is to support for the \"strong denoising\" argument. Nonetheless, we will make the argument clearer and more exact.\n\nThank you very much for your time and your valuable comment!"}, "signatures": ["ICLR.cc/2020/Conference/Paper1364/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1364/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Frequency Analysis for Graph Convolution Network", "authors": ["Hoang NT", "Takanori Maehara"], "authorids": ["hoang.nguyen.rh@riken.jp", "takanori.maehara@riken.jp"], "keywords": ["graph signal processing", "frequency analysis", "graph convolution neural network", "simplified convolution network", "semi-supervised vertex classification"], "TL;DR": "We study the filtering effect of GCN and SGC on benchmark datasets, find that all datasets are low-frequency and state-of-the-art models do not work in high-frequency settings.", "abstract": "In this work, we develop quantitative results to the learnablity of a two-layers Graph Convolutional Network (GCN). Instead of analyzing GCN under some classes of functions, our approach provides a quantitative gap between a two-layers GCN and a two-layers MLP model. Our analysis is based on the graph signal processing (GSP) approach, which can provide much more useful insights than the message-passing computational model. Interestingly, based on our analysis, we have been able to empirically demonstrate a few case when GCN and other state-of-the-art models cannot learn even when true vertex features are extremely low-dimensional. To demonstrate our theoretical findings and propose a solution to the aforementioned adversarial cases, we build a proof of concept graph neural network model with stacked filters named Graph Filters Neural Network (gfNN).\n", "pdf": "/pdf/7b77beae2b58e112aa72ed0dc311abc693ea9a51.pdf", "code": "https://gofile.io/?c=JrE62o ", "paperhash": "nt|frequency_analysis_for_graph_convolution_network", "original_pdf": "/attachment/6cb31ba54733adc8c8f92f4776a770ec8c177c88.pdf", "_bibtex": "@misc{\nnt2020frequency,\ntitle={Frequency Analysis for Graph Convolution Network},\nauthor={Hoang NT and Takanori Maehara},\nyear={2020},\nurl={https://openreview.net/forum?id=HylthC4twr}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "HylthC4twr", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper1364/Authors", "ICLR.cc/2020/Conference/Paper1364/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper1364/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper1364/Reviewers", "ICLR.cc/2020/Conference/Paper1364/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper1364/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper1364/Authors|ICLR.cc/2020/Conference/Paper1364/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504157117, "tmdate": 1576860545122, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper1364/Authors", "ICLR.cc/2020/Conference/Paper1364/Reviewers", "ICLR.cc/2020/Conference/Paper1364/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper1364/-/Official_Comment"}}}, {"id": "HJg8vTjKor", "original": null, "number": 10, "cdate": 1573662046505, "ddate": null, "tcdate": 1573662046505, "tmdate": 1573662074862, "tddate": null, "forum": "HylthC4twr", "replyto": "BJxKT2hvjS", "invitation": "ICLR.cc/2020/Conference/Paper1364/-/Official_Comment", "content": {"title": "Explanation about my comment on Figure 3", "comment": ">> Can we ask are you referring to Figure 5 (Section 7) instead of Figure 3 (Section 3)?\n\nI meant Figure 3. I did not agree with the following sentence:\n\n> By adding artificial Gaussian noise, we observe that the performance at low-frequency regions is relatively robust, which implies a strong denoising effect.\n\nTake the case where we use approximately 1000 frequency components in the PubMed dataset. I thought that the difference in performance between the $\\sigma=0$ case and the $\\sigma=0.05$ case is large. We can say the same thing in the case of approximately 400 frequency components in Cora and 500 frequency components in CiteSeer.\nI understand that the performance drops in these situations are certainly relatively smaller than the situations in which we use all frequency components. However, I was not sure we could safely say that this observation has justified Assumption 2.\n\nI would appreciate if authors let me know if my explanation is still unclear.\n"}, "signatures": ["ICLR.cc/2020/Conference/Paper1364/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1364/AnonReviewer1", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Frequency Analysis for Graph Convolution Network", "authors": ["Hoang NT", "Takanori Maehara"], "authorids": ["hoang.nguyen.rh@riken.jp", "takanori.maehara@riken.jp"], "keywords": ["graph signal processing", "frequency analysis", "graph convolution neural network", "simplified convolution network", "semi-supervised vertex classification"], "TL;DR": "We study the filtering effect of GCN and SGC on benchmark datasets, find that all datasets are low-frequency and state-of-the-art models do not work in high-frequency settings.", "abstract": "In this work, we develop quantitative results to the learnablity of a two-layers Graph Convolutional Network (GCN). Instead of analyzing GCN under some classes of functions, our approach provides a quantitative gap between a two-layers GCN and a two-layers MLP model. Our analysis is based on the graph signal processing (GSP) approach, which can provide much more useful insights than the message-passing computational model. Interestingly, based on our analysis, we have been able to empirically demonstrate a few case when GCN and other state-of-the-art models cannot learn even when true vertex features are extremely low-dimensional. To demonstrate our theoretical findings and propose a solution to the aforementioned adversarial cases, we build a proof of concept graph neural network model with stacked filters named Graph Filters Neural Network (gfNN).\n", "pdf": "/pdf/7b77beae2b58e112aa72ed0dc311abc693ea9a51.pdf", "code": "https://gofile.io/?c=JrE62o ", "paperhash": "nt|frequency_analysis_for_graph_convolution_network", "original_pdf": "/attachment/6cb31ba54733adc8c8f92f4776a770ec8c177c88.pdf", "_bibtex": "@misc{\nnt2020frequency,\ntitle={Frequency Analysis for Graph Convolution Network},\nauthor={Hoang NT and Takanori Maehara},\nyear={2020},\nurl={https://openreview.net/forum?id=HylthC4twr}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "HylthC4twr", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper1364/Authors", "ICLR.cc/2020/Conference/Paper1364/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper1364/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper1364/Reviewers", "ICLR.cc/2020/Conference/Paper1364/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper1364/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper1364/Authors|ICLR.cc/2020/Conference/Paper1364/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504157117, "tmdate": 1576860545122, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper1364/Authors", "ICLR.cc/2020/Conference/Paper1364/Reviewers", "ICLR.cc/2020/Conference/Paper1364/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper1364/-/Official_Comment"}}}, {"id": "SJlsqBjJjS", "original": null, "number": 8, "cdate": 1573004690642, "ddate": null, "tcdate": 1573004690642, "tmdate": 1573535135615, "tddate": null, "forum": "HylthC4twr", "replyto": "B1xVuu6aKr", "invitation": "ICLR.cc/2020/Conference/Paper1364/-/Official_Comment", "content": {"title": "We apologize about the code link and we made some update following your comments", "comment": "Hi,\n\nUpdate: We updated our manuscript according to your comment (4) and (5). Thank you very much! \n\nThank you for reading our paper. Please let us address the \"cons\" part of your comment.\n\n(1) You are right. The novelty of gfNN itself is trivial. However we find gfNN is a very useful analysis tool. Originally (not in the paper), this model comes from our analysis of how important features are to GCN. When we asked the question: what if the features are not linearly separable, we found that GCN can still work, but SGC failed. Wanting to preserve the simplicity of SGC while dealing with complex feature, we come up with gfNN. Further investigation of SGC and GCN nature lead to this manuscript. We also want to point out our paper did the exact analysis on frequency component in Fig 3, 4, and 6, which is useful for addressing the dataset and design adaptive filters.\n\n(2) It is indeed a very small incremental step in research. \n\n(3) On Cora, the performance gap is up to ~10 percent (noisy setting). It is true that same phenomenon is not so clear on other dataset like Citeseer and Pubmed. However, SGC-like method shows better noise resistance to GCN, which we think interesting enough for further study on our claim.\n\n(4) and (5) We apologize for such negligent. We will make the clean version of the code available after this reviewing process. The Colab link to run experiment was harder to make anonymous that we initially thought. We should have provided a zipfile link (included datasets): https://gofile.io/?c=JrE62o. After install dependencies (networkx, pytorch==1.0), run 'python citation.py --model gfnn --dataset cora'.\n\nThanks again for giving comments to our paper."}, "signatures": ["ICLR.cc/2020/Conference/Paper1364/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1364/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Frequency Analysis for Graph Convolution Network", "authors": ["Hoang NT", "Takanori Maehara"], "authorids": ["hoang.nguyen.rh@riken.jp", "takanori.maehara@riken.jp"], "keywords": ["graph signal processing", "frequency analysis", "graph convolution neural network", "simplified convolution network", "semi-supervised vertex classification"], "TL;DR": "We study the filtering effect of GCN and SGC on benchmark datasets, find that all datasets are low-frequency and state-of-the-art models do not work in high-frequency settings.", "abstract": "In this work, we develop quantitative results to the learnablity of a two-layers Graph Convolutional Network (GCN). Instead of analyzing GCN under some classes of functions, our approach provides a quantitative gap between a two-layers GCN and a two-layers MLP model. Our analysis is based on the graph signal processing (GSP) approach, which can provide much more useful insights than the message-passing computational model. Interestingly, based on our analysis, we have been able to empirically demonstrate a few case when GCN and other state-of-the-art models cannot learn even when true vertex features are extremely low-dimensional. To demonstrate our theoretical findings and propose a solution to the aforementioned adversarial cases, we build a proof of concept graph neural network model with stacked filters named Graph Filters Neural Network (gfNN).\n", "pdf": "/pdf/7b77beae2b58e112aa72ed0dc311abc693ea9a51.pdf", "code": "https://gofile.io/?c=JrE62o ", "paperhash": "nt|frequency_analysis_for_graph_convolution_network", "original_pdf": "/attachment/6cb31ba54733adc8c8f92f4776a770ec8c177c88.pdf", "_bibtex": "@misc{\nnt2020frequency,\ntitle={Frequency Analysis for Graph Convolution Network},\nauthor={Hoang NT and Takanori Maehara},\nyear={2020},\nurl={https://openreview.net/forum?id=HylthC4twr}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "HylthC4twr", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper1364/Authors", "ICLR.cc/2020/Conference/Paper1364/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper1364/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper1364/Reviewers", "ICLR.cc/2020/Conference/Paper1364/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper1364/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper1364/Authors|ICLR.cc/2020/Conference/Paper1364/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504157117, "tmdate": 1576860545122, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper1364/Authors", "ICLR.cc/2020/Conference/Paper1364/Reviewers", "ICLR.cc/2020/Conference/Paper1364/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper1364/-/Official_Comment"}}}, {"id": "BJxKT2hvjS", "original": null, "number": 9, "cdate": 1573534912968, "ddate": null, "tcdate": 1573534912968, "tmdate": 1573534912968, "tddate": null, "forum": "HylthC4twr", "replyto": "rklob41CKr", "invitation": "ICLR.cc/2020/Conference/Paper1364/-/Official_Comment", "content": {"title": "We made some minor updates to our manuscript following your comments ", "comment": "Hi,\n\nThank you very much for your comments and questions! \n\n> Firstly, we do plan to have the code available, you can find the core models (including SGC, GCN and noisy settings plus synthetic data) which we use for all experiments here:  https://gofile.io/?c=JrE62o \n\n> Suggestion regarding Theorem 8 (we updated the appendix explaining it in a bit detailed). \nTo recap here, the reason for the term $\\epsilon^{1/4}$ is from the square root  of Lemma 10 which bounds the D-norm of difference between an activated signal $\\sigma(X)$ and a band-limited signal $Y$. This lemma is meant to prepare for Theorem 8, where $\\sigma(X)$ is the activation of the *true* noiseless sigmal and $Y$ is the filtered version of the observed signal.\n\n> Question about the value k in Section 6. \nThe $k$ under analysis here is 2 as we stated from the beginning. We have to assume $k^*$ is 2 and furthermore we assume this value comes from Corollary 6. Since GCN couples the number of MLP layers and k, we find it unfair to analyze some other values for k in case of SGC and gfNN. We plan to improve this argument in later version of our manuscript. \n\n> Question about frequency component experiments in Section 3 (Figure 3). \nCan we ask are you referring to Figure 5 (Section 7) instead of Figure 3 (Section 3)? We think our Figure 3 clearly shows our Assumption 2 (low-frequency assumption) experimentally across all data set. Even at 0.01, when we use all frequency components, all datasets show more than 10% decrease in performance. Please let us know if you meant something else.\n\n> Suggestion about the title of Sections 4 and 5.\nThank you very much. We will consider to change accordingly to make it clearer to reader.\n\nThank you again for your time and your comments!"}, "signatures": ["ICLR.cc/2020/Conference/Paper1364/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1364/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Frequency Analysis for Graph Convolution Network", "authors": ["Hoang NT", "Takanori Maehara"], "authorids": ["hoang.nguyen.rh@riken.jp", "takanori.maehara@riken.jp"], "keywords": ["graph signal processing", "frequency analysis", "graph convolution neural network", "simplified convolution network", "semi-supervised vertex classification"], "TL;DR": "We study the filtering effect of GCN and SGC on benchmark datasets, find that all datasets are low-frequency and state-of-the-art models do not work in high-frequency settings.", "abstract": "In this work, we develop quantitative results to the learnablity of a two-layers Graph Convolutional Network (GCN). Instead of analyzing GCN under some classes of functions, our approach provides a quantitative gap between a two-layers GCN and a two-layers MLP model. Our analysis is based on the graph signal processing (GSP) approach, which can provide much more useful insights than the message-passing computational model. Interestingly, based on our analysis, we have been able to empirically demonstrate a few case when GCN and other state-of-the-art models cannot learn even when true vertex features are extremely low-dimensional. To demonstrate our theoretical findings and propose a solution to the aforementioned adversarial cases, we build a proof of concept graph neural network model with stacked filters named Graph Filters Neural Network (gfNN).\n", "pdf": "/pdf/7b77beae2b58e112aa72ed0dc311abc693ea9a51.pdf", "code": "https://gofile.io/?c=JrE62o ", "paperhash": "nt|frequency_analysis_for_graph_convolution_network", "original_pdf": "/attachment/6cb31ba54733adc8c8f92f4776a770ec8c177c88.pdf", "_bibtex": "@misc{\nnt2020frequency,\ntitle={Frequency Analysis for Graph Convolution Network},\nauthor={Hoang NT and Takanori Maehara},\nyear={2020},\nurl={https://openreview.net/forum?id=HylthC4twr}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "HylthC4twr", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper1364/Authors", "ICLR.cc/2020/Conference/Paper1364/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper1364/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper1364/Reviewers", "ICLR.cc/2020/Conference/Paper1364/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper1364/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper1364/Authors|ICLR.cc/2020/Conference/Paper1364/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504157117, "tmdate": 1576860545122, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper1364/Authors", "ICLR.cc/2020/Conference/Paper1364/Reviewers", "ICLR.cc/2020/Conference/Paper1364/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper1364/-/Official_Comment"}}}, {"id": "Hkx7hw9JoB", "original": null, "number": 7, "cdate": 1573001131470, "ddate": null, "tcdate": 1573001131470, "tmdate": 1573001397062, "tddate": null, "forum": "HylthC4twr", "replyto": "SJxiGab2tS", "invitation": "ICLR.cc/2020/Conference/Paper1364/-/Official_Comment", "content": {"title": "The data itself has low frequency.", "comment": "Hi,\n\nThank you very much for spending your time with our paper. \n\n(1) As in our paper, we addressed the previous observation and stated that our proof for \"low-pass filtering\" has the same results as in SGC, but using a different technique. In addition, our paper suggests why low-pass filtering works by looking at the Rayleigh quotient of the data itself, which would be helpful to analyze a dataset before using GCN/SGC (graph filtering techniques).\n\n(2) Yes, if the frequency of the label vectors are higher, low-pass technique wouldn't work. We show that in Figure 6. However, to be honest, we couldn't find a real-world dataset that exhibit this high frequency nature so we have to generate a synthetic experiment. As you can see in our Fig 6 (also fig 9), even if the features are very \"informative\", applying low-pass filtering technique will make the problem harder. Surprisingly, we found that even more complex methods do not work in this \"high-frequency\" case.\n\n(3) We agree that our contribution of gfNN is trivial, but we wrote this paper because we think the implication in analysis would be interesting and helpful and gfNN is a tool to do that empirically. Fig 7 shows how problem might arise when we use SGC. We wanted to say that the low-frequency nature of data influence the design of Graph Neural Nets, hence we need to look more carefully in to the graph structure (might be represented by filter frequency) and the convexity of the node features themselves.\n\nThank you again for your time! "}, "signatures": ["ICLR.cc/2020/Conference/Paper1364/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1364/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Frequency Analysis for Graph Convolution Network", "authors": ["Hoang NT", "Takanori Maehara"], "authorids": ["hoang.nguyen.rh@riken.jp", "takanori.maehara@riken.jp"], "keywords": ["graph signal processing", "frequency analysis", "graph convolution neural network", "simplified convolution network", "semi-supervised vertex classification"], "TL;DR": "We study the filtering effect of GCN and SGC on benchmark datasets, find that all datasets are low-frequency and state-of-the-art models do not work in high-frequency settings.", "abstract": "In this work, we develop quantitative results to the learnablity of a two-layers Graph Convolutional Network (GCN). Instead of analyzing GCN under some classes of functions, our approach provides a quantitative gap between a two-layers GCN and a two-layers MLP model. Our analysis is based on the graph signal processing (GSP) approach, which can provide much more useful insights than the message-passing computational model. Interestingly, based on our analysis, we have been able to empirically demonstrate a few case when GCN and other state-of-the-art models cannot learn even when true vertex features are extremely low-dimensional. To demonstrate our theoretical findings and propose a solution to the aforementioned adversarial cases, we build a proof of concept graph neural network model with stacked filters named Graph Filters Neural Network (gfNN).\n", "pdf": "/pdf/7b77beae2b58e112aa72ed0dc311abc693ea9a51.pdf", "code": "https://gofile.io/?c=JrE62o ", "paperhash": "nt|frequency_analysis_for_graph_convolution_network", "original_pdf": "/attachment/6cb31ba54733adc8c8f92f4776a770ec8c177c88.pdf", "_bibtex": "@misc{\nnt2020frequency,\ntitle={Frequency Analysis for Graph Convolution Network},\nauthor={Hoang NT and Takanori Maehara},\nyear={2020},\nurl={https://openreview.net/forum?id=HylthC4twr}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "HylthC4twr", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper1364/Authors", "ICLR.cc/2020/Conference/Paper1364/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper1364/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper1364/Reviewers", "ICLR.cc/2020/Conference/Paper1364/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper1364/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper1364/Authors|ICLR.cc/2020/Conference/Paper1364/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504157117, "tmdate": 1576860545122, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper1364/Authors", "ICLR.cc/2020/Conference/Paper1364/Reviewers", "ICLR.cc/2020/Conference/Paper1364/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper1364/-/Official_Comment"}}}, {"id": "SJxiGab2tS", "original": null, "number": 1, "cdate": 1571720467039, "ddate": null, "tcdate": 1571720467039, "tmdate": 1572972478519, "tddate": null, "forum": "HylthC4twr", "replyto": "HylthC4twr", "invitation": "ICLR.cc/2020/Conference/Paper1364/-/Official_Review", "content": {"rating": "6: Weak Accept", "experience_assessment": "I have published one or two papers in this area.", "review_assessment:_checking_correctness_of_derivations_and_theory": "I carefully checked the derivations and theory.", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #2", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review": "The paper shows the graph signal convolution in GCN-based models is typically a low-pass filter. Besides, the authors propose a simplified GCN-framework named gfNN, which is demonstrated on various benchmark datasets.  To be honest, the paper is well-motivated, well-written. And,  I enjoyed reading through the paper. \n\nHowever, I have some concerns regarding the technical contributions of this paper.\n(1) \"GNN is a low-pass filter\" is not a new observation. Various works (SGC, [Shuman, et al., 2013]) have studied this observation before. \n(2) If the frequency of the label vector is higher than the threshold of the low-pass filter (e.g., gfNN), will the model be problematic? \n(3) It seems the only difference between SGC and gfNN is that gfNN is equipped with one more hidden layer. The authors claim that gfNN perform better than SGC is because \"the true features are non-linearly separable\". If it is the case, then the technical contribution of gfNN is trivial. \n\nOverall, I still like this paper due to its interesting point of the presentation. I vote for weak accept, but I am fine if it is rejected. "}, "signatures": ["ICLR.cc/2020/Conference/Paper1364/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1364/AnonReviewer2"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Frequency Analysis for Graph Convolution Network", "authors": ["Hoang NT", "Takanori Maehara"], "authorids": ["hoang.nguyen.rh@riken.jp", "takanori.maehara@riken.jp"], "keywords": ["graph signal processing", "frequency analysis", "graph convolution neural network", "simplified convolution network", "semi-supervised vertex classification"], "TL;DR": "We study the filtering effect of GCN and SGC on benchmark datasets, find that all datasets are low-frequency and state-of-the-art models do not work in high-frequency settings.", "abstract": "In this work, we develop quantitative results to the learnablity of a two-layers Graph Convolutional Network (GCN). Instead of analyzing GCN under some classes of functions, our approach provides a quantitative gap between a two-layers GCN and a two-layers MLP model. Our analysis is based on the graph signal processing (GSP) approach, which can provide much more useful insights than the message-passing computational model. Interestingly, based on our analysis, we have been able to empirically demonstrate a few case when GCN and other state-of-the-art models cannot learn even when true vertex features are extremely low-dimensional. To demonstrate our theoretical findings and propose a solution to the aforementioned adversarial cases, we build a proof of concept graph neural network model with stacked filters named Graph Filters Neural Network (gfNN).\n", "pdf": "/pdf/7b77beae2b58e112aa72ed0dc311abc693ea9a51.pdf", "code": "https://gofile.io/?c=JrE62o ", "paperhash": "nt|frequency_analysis_for_graph_convolution_network", "original_pdf": "/attachment/6cb31ba54733adc8c8f92f4776a770ec8c177c88.pdf", "_bibtex": "@misc{\nnt2020frequency,\ntitle={Frequency Analysis for Graph Convolution Network},\nauthor={Hoang NT and Takanori Maehara},\nyear={2020},\nurl={https://openreview.net/forum?id=HylthC4twr}\n}"}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "HylthC4twr", "replyto": "HylthC4twr", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper1364/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper1364/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1575911193351, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper1364/Reviewers"], "noninvitees": [], "tcdate": 1570237738454, "tmdate": 1575911193367, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper1364/-/Official_Review"}}}, {"id": "B1xVuu6aKr", "original": null, "number": 2, "cdate": 1571833963696, "ddate": null, "tcdate": 1571833963696, "tmdate": 1572972478481, "tddate": null, "forum": "HylthC4twr", "replyto": "HylthC4twr", "invitation": "ICLR.cc/2020/Conference/Paper1364/-/Official_Review", "content": {"experience_assessment": "I have published one or two papers in this area.", "rating": "1: Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #3", "review_assessment:_checking_correctness_of_derivations_and_theory": "I carefully checked the derivations and theory.", "review": "The authors extend the existing work SGC [1] to a nonlinear version, which addresses the limitations of dealing with nonlinear feature. It further extends the theoretical\u00a0finding in [1] about the low-pass filtering functionality\u00a0of graph convolutional networks and shows its advantage in dealing with graph signal processing problem. Evaluation of the proposed method is performed on 7 datasets for node classification task.\nPros:\n1. This work goes into detail of the theoretical finding of SGC.\n2. Authors conduct extensive experiments on multiple datasets.\nCons:\n1. The proposed graph neural network mode is an extension of the existing model SGC, which address the limitation of SGC to model the node feature nonlinearity. It is a good extension, but the novelty is limited.\n2. Authors further extend the theoretical finding in [1] and verify the fact that low-pass filtering\u00a0functionality of graph neural network provide better noise robustness\u00a0than two layer MLP. It has some novelty, but the novelty is incremental.\n3. In the experiment, the performance gap between SGC and gfNN is very small on noise robustness study and traditional node classification. The performance gap between GCN and gfNN is also small on noise robustness study is also small, which can not\u00a0support the conclusion \"GCN has a risk of overfitting to the noise\"\n4. The paper has the problem of notation missing, e.g on page 2, Fig1 is never mentioned; on page 7, the notation of \"LG\" is missed in Fig 5.\n5. The code link is given but no code is missing.\n[1]Wu, Tianyi Zhang, Amauri Holanda de Souza Jr., Christopher Fifty, Tao Yu, and Kilian Q.Weinberger. Simplifying graph convolutional networks. ICML2019\n"}, "signatures": ["ICLR.cc/2020/Conference/Paper1364/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1364/AnonReviewer3"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Frequency Analysis for Graph Convolution Network", "authors": ["Hoang NT", "Takanori Maehara"], "authorids": ["hoang.nguyen.rh@riken.jp", "takanori.maehara@riken.jp"], "keywords": ["graph signal processing", "frequency analysis", "graph convolution neural network", "simplified convolution network", "semi-supervised vertex classification"], "TL;DR": "We study the filtering effect of GCN and SGC on benchmark datasets, find that all datasets are low-frequency and state-of-the-art models do not work in high-frequency settings.", "abstract": "In this work, we develop quantitative results to the learnablity of a two-layers Graph Convolutional Network (GCN). Instead of analyzing GCN under some classes of functions, our approach provides a quantitative gap between a two-layers GCN and a two-layers MLP model. Our analysis is based on the graph signal processing (GSP) approach, which can provide much more useful insights than the message-passing computational model. Interestingly, based on our analysis, we have been able to empirically demonstrate a few case when GCN and other state-of-the-art models cannot learn even when true vertex features are extremely low-dimensional. To demonstrate our theoretical findings and propose a solution to the aforementioned adversarial cases, we build a proof of concept graph neural network model with stacked filters named Graph Filters Neural Network (gfNN).\n", "pdf": "/pdf/7b77beae2b58e112aa72ed0dc311abc693ea9a51.pdf", "code": "https://gofile.io/?c=JrE62o ", "paperhash": "nt|frequency_analysis_for_graph_convolution_network", "original_pdf": "/attachment/6cb31ba54733adc8c8f92f4776a770ec8c177c88.pdf", "_bibtex": "@misc{\nnt2020frequency,\ntitle={Frequency Analysis for Graph Convolution Network},\nauthor={Hoang NT and Takanori Maehara},\nyear={2020},\nurl={https://openreview.net/forum?id=HylthC4twr}\n}"}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "HylthC4twr", "replyto": "HylthC4twr", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper1364/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper1364/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1575911193351, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper1364/Reviewers"], "noninvitees": [], "tcdate": 1570237738454, "tmdate": 1575911193367, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper1364/-/Official_Review"}}}, {"id": "rklob41CKr", "original": null, "number": 3, "cdate": 1571841026551, "ddate": null, "tcdate": 1571841026551, "tmdate": 1572972478437, "tddate": null, "forum": "HylthC4twr", "replyto": "HylthC4twr", "invitation": "ICLR.cc/2020/Conference/Paper1364/-/Official_Review", "content": {"experience_assessment": "I have published one or two papers in this area.", "rating": "6: Weak Accept", "review_assessment:_thoroughness_in_paper_reading": "I made a quick assessment of this paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #1", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "Summary\n\nSeveral theoretical analyses have been conducted on MPNN-type NNs. On the other hand, although many graph neural network models take the approach of graph filtering, there is little theoretical analysis on graph NNs that take the filtering approach. This paper analyzed the learnability of filtering type graph NNs.\nFirst, the authors hypothesized that the data used practical tasks consisted of true low-frequency information and high-frequency noise (Assumption 2), and verified the correctness of the assumption.\nNext, the authors quantitatively evaluated the difference between the case where we feed noisy data to a graph NN and the case where we feed noiseless data to an MLP. The authors showed that a two-layer GCN approximately behaves as a noise-filtering + a two-layered MLP (Theorem 8). Based on this observation, the authors proposed gfNN, which directly models the latter architecture. We can interpret gfNN as an SGC whose final linear transformation is replaced with an MLP.\nFinally, the authors empirically showed that gfNN achieved the same level of accuracy as existing GNNs in the citation network tasks. Furthermore, the authors created a dataset that has meaningful information in the high-frequency area (BA-High). It was shown that the existing GNN, including gfNN, did not perform well, while a GNN designed to pass high frequency (gfNN-high) can predict accurately.\n\n\nDecision\n\nI judge that this paper contributes to deepning the understanding of graph NNs and is worth to be accepted based on the following three points.\nFirst, it enabled us to understand what causes the oversmoothing phenomena. Several studies have shown that Laplacian-type graph convolution works as a low pass filter. However, most of them considered a linear setting and did not explain how the graph convolution behaves when a graph NN has non-linear activation functions. Compared to them, their result admits non-linearity.\nSecond, by showing that we can approximate a GCN by a noise filter followed by an MLP, this paper has made the relationship between a GCN and an SGC clearer.\nFinally, the authors experimentally showed that existing graph NNs do not have predictive power when useful information is in high-frequency domains. It gives insights on what graph NNs can and cannot solve.\nFor these reasons, I think this paper has contributed to a deeper understanding of graph NNs and sufficiently significant.\n\n\nSuggestions\n\n- If I understand correctly, the title of Section 4 reflects the content of Lemma 5 in Section 5 rather than the content of Theorem 3 and (5). I recommend the authors to reconsider the titles of Sections 4 and 5.\n- Could you add more explanations to the proof of Theorem 8 in Appendix A. Especially, I could not understand how the term $\\tilde{O}(\\epsilon^{1/4})$ is derived.\n\n\nQuestions\n\n- I could not find implementations of graph NNs in the notebook to the code (I only found the ls result of dataset directories). Do you plan to release the experiment code?\n- At the beginning of Section 6, the authors wrote that they set $k$ to $2$ (hence two-layered GNNs are in consideration). But Theorems 7 and 8 considered the optimal $k^\\ast$ in Corollary 6. Which is correct?\n- In Section 3, the authors claimed that the performance of MLPs is relatively more robust to the Gaussian noise in the low-frequency regime compared to the high-frequency regime. Certainly, the decrease in performance at $\\sigma = 0.01$ is massive in the high-frequency setting for the CiteSeer dataset. However, it is hard to see this trend in Cora and Pubmed. Therefore, I think it is a little too aggressive to conclude that claim."}, "signatures": ["ICLR.cc/2020/Conference/Paper1364/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1364/AnonReviewer1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Frequency Analysis for Graph Convolution Network", "authors": ["Hoang NT", "Takanori Maehara"], "authorids": ["hoang.nguyen.rh@riken.jp", "takanori.maehara@riken.jp"], "keywords": ["graph signal processing", "frequency analysis", "graph convolution neural network", "simplified convolution network", "semi-supervised vertex classification"], "TL;DR": "We study the filtering effect of GCN and SGC on benchmark datasets, find that all datasets are low-frequency and state-of-the-art models do not work in high-frequency settings.", "abstract": "In this work, we develop quantitative results to the learnablity of a two-layers Graph Convolutional Network (GCN). Instead of analyzing GCN under some classes of functions, our approach provides a quantitative gap between a two-layers GCN and a two-layers MLP model. Our analysis is based on the graph signal processing (GSP) approach, which can provide much more useful insights than the message-passing computational model. Interestingly, based on our analysis, we have been able to empirically demonstrate a few case when GCN and other state-of-the-art models cannot learn even when true vertex features are extremely low-dimensional. To demonstrate our theoretical findings and propose a solution to the aforementioned adversarial cases, we build a proof of concept graph neural network model with stacked filters named Graph Filters Neural Network (gfNN).\n", "pdf": "/pdf/7b77beae2b58e112aa72ed0dc311abc693ea9a51.pdf", "code": "https://gofile.io/?c=JrE62o ", "paperhash": "nt|frequency_analysis_for_graph_convolution_network", "original_pdf": "/attachment/6cb31ba54733adc8c8f92f4776a770ec8c177c88.pdf", "_bibtex": "@misc{\nnt2020frequency,\ntitle={Frequency Analysis for Graph Convolution Network},\nauthor={Hoang NT and Takanori Maehara},\nyear={2020},\nurl={https://openreview.net/forum?id=HylthC4twr}\n}"}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "HylthC4twr", "replyto": "HylthC4twr", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper1364/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper1364/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1575911193351, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper1364/Reviewers"], "noninvitees": [], "tcdate": 1570237738454, "tmdate": 1575911193367, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper1364/-/Official_Review"}}}], "count": 12}