{"notes": [{"id": "ObkQpUsR-x", "original": "X_c-x6sN17", "number": 27, "cdate": 1582750159476, "ddate": null, "tcdate": 1582750159476, "tmdate": 1587925109962, "tddate": null, "forum": "ObkQpUsR-x", "replyto": null, "invitation": "ICLR.cc/2020/Workshop/DeepDiffEq/-/Blind_Submission", "content": {"title": "A Free-Energy Principle for Representation Learning", "authors": ["Yansong Gao", "Pratik Chaudhari"], "authorids": ["gaoyans@sas.upenn.edu", "pratikac@seas.upenn.edu"], "keywords": ["information theory", "thermodynamics", "rate-distortion theory", "transfer learning", "information bottleneck"], "TL;DR": "We use ideas from thermodynamics and information theory to design stochastic processes to keep the classification loss constant as the model is transferred from the source task to the target task.", "abstract": "We employ a formal connection of machine learning with thermodynamics to characterize the quality of learnt representations for transfer learning. We discuss how information-theoretic functionals such as rate, distortion and classification loss of a model lie on a convex, so-called equilibrium surface. We prescribe dynamical processes to traverse this surface under constraints, e.g., an iso-classification process that trades off rate and distortion to keep the classification loss unchanged. We demonstrate how this process can be used for transferring representations from a source dataset to a target dataset while keeping the classification loss constant. Experimental validation of the theoretical results is provided on standard image-classification datasets.\n", "pdf": "/pdf/0744e148ad3515a5b20ef45d48c17af250aeeac1.pdf", "paperhash": "gao|a_freeenergy_principle_for_representation_learning", "_bibtex": "@inproceedings{\ngao2020a,\ntitle={A Free-Energy Principle for Representation Learning},\nauthor={Yansong Gao and Pratik Chaudhari},\nbooktitle={ICLR 2020 Workshop on Integration of Deep Neural Models and Differential Equations},\nyear={2020},\nurl={https://openreview.net/forum?id=ObkQpUsR-x}\n}"}, "signatures": ["ICLR.cc/2020/Workshop/DeepDiffEq"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Workshop/DeepDiffEq"], "details": {"replyCount": 1, "writable": false, "overwriting": [], "revisions": false, "tags": [], "invitation": {"reply": {"readers": {"values-regex": ".*"}, "writers": {"values": ["ICLR.cc/2020/Workshop/DeepDiffEq"]}, "signatures": {"values": ["ICLR.cc/2020/Workshop/DeepDiffEq"]}, "content": {"authors": {"values": ["Anonymous"]}, "authorids": {"values-regex": ".*"}}}, "signatures": ["ICLR.cc/2020/Workshop/DeepDiffEq"], "readers": ["everyone"], "writers": ["ICLR.cc/2020/Workshop/DeepDiffEq"], "invitees": ["~"], "tcdate": 1582750147213, "tmdate": 1587924718420, "id": "ICLR.cc/2020/Workshop/DeepDiffEq/-/Blind_Submission"}}, "tauthor": "OpenReview.net"}, {"id": "NmItt0upF8", "original": null, "number": 1, "cdate": 1582774665218, "ddate": null, "tcdate": 1582774665218, "tmdate": 1582774665218, "tddate": null, "forum": "ObkQpUsR-x", "replyto": "ObkQpUsR-x", "invitation": "ICLR.cc/2020/Workshop/DeepDiffEq/Paper27/-/Decision", "content": {"decision": "Accept (Poster)", "title": "Paper Decision"}, "signatures": ["ICLR.cc/2020/Workshop/DeepDiffEq/Program_Chairs"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Workshop/DeepDiffEq/Program_Chairs"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "A Free-Energy Principle for Representation Learning", "authors": ["Yansong Gao", "Pratik Chaudhari"], "authorids": ["gaoyans@sas.upenn.edu", "pratikac@seas.upenn.edu"], "keywords": ["information theory", "thermodynamics", "rate-distortion theory", "transfer learning", "information bottleneck"], "TL;DR": "We use ideas from thermodynamics and information theory to design stochastic processes to keep the classification loss constant as the model is transferred from the source task to the target task.", "abstract": "We employ a formal connection of machine learning with thermodynamics to characterize the quality of learnt representations for transfer learning. We discuss how information-theoretic functionals such as rate, distortion and classification loss of a model lie on a convex, so-called equilibrium surface. We prescribe dynamical processes to traverse this surface under constraints, e.g., an iso-classification process that trades off rate and distortion to keep the classification loss unchanged. We demonstrate how this process can be used for transferring representations from a source dataset to a target dataset while keeping the classification loss constant. Experimental validation of the theoretical results is provided on standard image-classification datasets.\n", "pdf": "/pdf/0744e148ad3515a5b20ef45d48c17af250aeeac1.pdf", "paperhash": "gao|a_freeenergy_principle_for_representation_learning", "_bibtex": "@inproceedings{\ngao2020a,\ntitle={A Free-Energy Principle for Representation Learning},\nauthor={Yansong Gao and Pratik Chaudhari},\nbooktitle={ICLR 2020 Workshop on Integration of Deep Neural Models and Differential Equations},\nyear={2020},\nurl={https://openreview.net/forum?id=ObkQpUsR-x}\n}"}, "tags": [], "invitation": {"reply": {"writers": {"values": ["ICLR.cc/2020/Workshop/DeepDiffEq/Program_Chairs"], "description": "How your identity will be displayed."}, "signatures": {"values": ["ICLR.cc/2020/Workshop/DeepDiffEq/Program_Chairs"], "description": "How your identity will be displayed."}, "content": {"title": {"order": 1, "required": true, "value": "Paper Decision"}, "decision": {"order": 2, "required": true, "value-radio": ["Accept (Oral)", "Accept (Poster)", "Reject"], "description": "Decision"}, "comment": {"order": 3, "required": false, "value-regex": "[\\S\\s]{0,5000}", "description": ""}}, "forum": "ObkQpUsR-x", "replyto": "ObkQpUsR-x", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}}, "cdate": 1582156800000, "expdate": 1589155200000, "duedate": 1588291200000, "multiReply": false, "readers": ["everyone"], "invitees": ["ICLR.cc/2020/Workshop/DeepDiffEq/Program_Chairs"], "tcdate": 1582771074158, "tmdate": 1587925017559, "super": "ICLR.cc/2020/Workshop/DeepDiffEq/-/Decision", "signatures": ["ICLR.cc/2020/Workshop/DeepDiffEq"], "writers": ["ICLR.cc/2020/Workshop/DeepDiffEq"], "id": "ICLR.cc/2020/Workshop/DeepDiffEq/Paper27/-/Decision"}}}], "count": 2}