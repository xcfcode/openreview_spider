{"notes": [{"id": "Sye2s2VtDr", "original": "HyxPefzWvS", "number": 166, "cdate": 1569438883712, "ddate": null, "tcdate": 1569438883712, "tmdate": 1577168227245, "tddate": null, "forum": "Sye2s2VtDr", "replyto": null, "invitation": "ICLR.cc/2020/Conference/-/Blind_Submission", "content": {"title": "Automatically Learning Feature Crossing from Model Interpretation for Tabular Data", "authors": ["Zhaocheng Liu", "Qiang Liu", "Haoli Zhang"], "authorids": ["zhaocheng.liu@realai.ai", "qiang.liu@realai.ai", "haoli.zhang@realai.ai"], "keywords": ["AutoML", "feature crossing", "interpretation"], "TL;DR": "We propose a novel method called CrossGO, which automatically and efficiently selects useful cross features according to the interpretation inconsistency computed in deep neural networks.", "abstract": "Automatically feature generation is a major topic of automated machine learning. Among various feature generation approaches, feature crossing, which takes cross-product of sparse features, is a promising way to effectively capture the interactions among categorical features in tabular data. Previous works on feature crossing try to search in the set of all the possible cross feature fields. This is obviously not efficient when the size of original feature fields is large. Meanwhile, some deep learning-based methods combines deep neural networks and various interaction components. However, due to the existing of Deep Neural Networks (DNN), only a few cross features can be explicitly generated by the interaction components. Recently, piece-wise interpretation of DNN has been widely studied, and the piece-wise interpretations are usually inconsistent in different samples. Inspired by this, we give a definition of interpretation inconsistency in DNN, and propose a novel method called CrossGO, which selects useful cross features according to the interpretation inconsistency. The whole process of learning feature crossing can be done via simply training a DNN model and a logistic regression (LR) model. CrossGO can generate compact candidate set of cross feature fields, and promote the efficiency of searching. Extensive experiments have been conducted on several real-world datasets. Cross features generated by CrossGO can empower a simple LR model achieving approximate or even better performances comparing with complex DNN models.", "pdf": "/pdf/c39b15440e8a22dfb2c8ffd1b37118d17d498950.pdf", "paperhash": "liu|automatically_learning_feature_crossing_from_model_interpretation_for_tabular_data", "original_pdf": "/attachment/12eb9cf9f863af97bf98ef55cace2014a9e15e8a.pdf", "_bibtex": "@misc{\nliu2020automatically,\ntitle={Automatically Learning Feature Crossing from Model Interpretation for Tabular Data},\nauthor={Zhaocheng Liu and Qiang Liu and Haoli Zhang},\nyear={2020},\nurl={https://openreview.net/forum?id=Sye2s2VtDr}\n}"}, "signatures": ["ICLR.cc/2020/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference"], "details": {"replyCount": 22, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"reply": {"readers": {"values-regex": ".*"}, "writers": {"values": ["ICLR.cc/2020/Conference"]}, "signatures": {"values": ["ICLR.cc/2020/Conference"]}, "content": {"spotlight_video": {"value-regex": ".*"}, "full_presentation_video": {"value-regex": ".*"}, "original_pdf": {"required": false, "description": "Upload a PDF file that ends with .pdf", "value-regex": ".*"}, "appendix": {"value-regex": ".*"}, "authorids": {"values-regex": ".*"}, "poster": {"value-regex": ".*"}, "authors": {"values": ["Anonymous"]}, "slides": {"value-regex": ".*"}}}, "final": [], "signatures": ["ICLR.cc/2020/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference"], "noninvitees": [], "tcdate": 1569271260237, "tmdate": 1593459412141, "id": "ICLR.cc/2020/Conference/-/Blind_Submission"}}, "tauthor": "OpenReview.net"}, {"id": "dYr0Gp9aYo", "original": null, "number": 1, "cdate": 1576798689148, "ddate": null, "tcdate": 1576798689148, "tmdate": 1576800945973, "tddate": null, "forum": "Sye2s2VtDr", "replyto": "Sye2s2VtDr", "invitation": "ICLR.cc/2020/Conference/Paper166/-/Decision", "content": {"decision": "Reject", "comment": "The authors propose a simple but effective method for feature crossing using interpretation inconsistency (as defined by the authors).\n\nI think this is a good work and the authors as well as the reviewers participated well in the discussions. However, there is still disagreement about the positioning of the paper. In particular, all the reviewers  felt that additional baselines should be tried. While the authors have strongly rebutted the necessity of these baselines the reviewers are not convinced about it. Given the strong reservations of the all the 3 reviewers at this point I cannot recommend the acceptance of this paper. I strongly suggest that in subsequent submissions the authors should position their work better and perhaps compare with some of the related works recommended by the reviewers.", "title": "Paper Decision"}, "signatures": ["ICLR.cc/2020/Conference/Program_Chairs"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Program_Chairs"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Automatically Learning Feature Crossing from Model Interpretation for Tabular Data", "authors": ["Zhaocheng Liu", "Qiang Liu", "Haoli Zhang"], "authorids": ["zhaocheng.liu@realai.ai", "qiang.liu@realai.ai", "haoli.zhang@realai.ai"], "keywords": ["AutoML", "feature crossing", "interpretation"], "TL;DR": "We propose a novel method called CrossGO, which automatically and efficiently selects useful cross features according to the interpretation inconsistency computed in deep neural networks.", "abstract": "Automatically feature generation is a major topic of automated machine learning. Among various feature generation approaches, feature crossing, which takes cross-product of sparse features, is a promising way to effectively capture the interactions among categorical features in tabular data. Previous works on feature crossing try to search in the set of all the possible cross feature fields. This is obviously not efficient when the size of original feature fields is large. Meanwhile, some deep learning-based methods combines deep neural networks and various interaction components. However, due to the existing of Deep Neural Networks (DNN), only a few cross features can be explicitly generated by the interaction components. Recently, piece-wise interpretation of DNN has been widely studied, and the piece-wise interpretations are usually inconsistent in different samples. Inspired by this, we give a definition of interpretation inconsistency in DNN, and propose a novel method called CrossGO, which selects useful cross features according to the interpretation inconsistency. The whole process of learning feature crossing can be done via simply training a DNN model and a logistic regression (LR) model. CrossGO can generate compact candidate set of cross feature fields, and promote the efficiency of searching. Extensive experiments have been conducted on several real-world datasets. Cross features generated by CrossGO can empower a simple LR model achieving approximate or even better performances comparing with complex DNN models.", "pdf": "/pdf/c39b15440e8a22dfb2c8ffd1b37118d17d498950.pdf", "paperhash": "liu|automatically_learning_feature_crossing_from_model_interpretation_for_tabular_data", "original_pdf": "/attachment/12eb9cf9f863af97bf98ef55cace2014a9e15e8a.pdf", "_bibtex": "@misc{\nliu2020automatically,\ntitle={Automatically Learning Feature Crossing from Model Interpretation for Tabular Data},\nauthor={Zhaocheng Liu and Qiang Liu and Haoli Zhang},\nyear={2020},\nurl={https://openreview.net/forum?id=Sye2s2VtDr}\n}"}, "tags": [], "invitation": {"reply": {"writers": {"description": "How your identity will be displayed.", "values-regex": ["ICLR.cc/2020/Conference/Program_Chairs"]}, "signatures": {"values": ["ICLR.cc/2020/Conference/Program_Chairs"], "description": "How your identity will be displayed."}, "content": {"decision": {"value-radio": ["Accept (Spotlight)", "Accept (Talk)", "Accept (Poster)", "Reject"], "description": "Decision", "required": true, "order": 2}, "title": {"value": "Paper Decision", "required": true, "order": 1}, "comment": {"value-regex": "[\\S\\s]{0,5000}", "description": "", "required": false, "order": 3}}, "forum": "Sye2s2VtDr", "replyto": "Sye2s2VtDr", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}}, "expdate": 1576854540000, "duedate": 1576853940000, "multiReply": false, "readers": ["everyone"], "invitees": ["ICLR.cc/2020/Conference/Program_Chairs"], "tcdate": 1576795718872, "tmdate": 1576800269416, "super": "ICLR.cc/2020/Conference/-/Decision", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper166/-/Decision"}}}, {"id": "H1eu0MZ2tS", "original": null, "number": 3, "cdate": 1571717840124, "ddate": null, "tcdate": 1571717840124, "tmdate": 1574256298711, "tddate": null, "forum": "Sye2s2VtDr", "replyto": "Sye2s2VtDr", "invitation": "ICLR.cc/2020/Conference/Paper166/-/Official_Review", "content": {"experience_assessment": "I have read many papers in this area.", "rating": "3: Weak Reject", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "review_assessment:_thoroughness_in_paper_reading": "I made a quick assessment of this paper.", "title": "Official Blind Review #3", "review": "In the paper, the authors proposed CrossGO, an algorithm for finding crossing features useful for prediction.\nIn CrossGO, one trains a neural network that captures feature crossing implicitly.\nThen, possible crossing features are estimated using the gradient-based saliency.\nThe idea here is that, if a feature has a crossing with some other features, its contribution in the saliency can vary across different inputs.\nThus, by looking at the variation of the saliency, one can find candidates features for feature crossing.\nCrossGO greedily selects candidate crossings based on the idea above.\nIn the last step, a simple logistic regression is trained using the candidate crossings, and the effective crossings are selected using a forward greedy feature selection.\n\nI found the paper well-written and the idea is easy to follow.\nMy concern, however, is the lack of Factorization Machines (FM) in the experiments.\nIn Introduction, the authors mention to the deep version of FM and stated \"(deep FMs are) not able to generate interpretable cross features\".\nBut, as the authors are aware of, non-deep FMs are able to handle feature crossings in a interpretable way.\nThus, it would be essential to adopt non-deep FMs as the baseline in the experiments.\nBecause the important baseline is missing, I found the results are not convincing enough to claim the effectiveness of the proposed method.\n\n\n### Updated after author response ###\nThe authors have partially addressed my concern by adding FM/HOFMs as the experiment baselines, which I greatly appreciate.\nHowever, I found the current paper misses some other possible baselines for high-order interaction models [Ref1,2].\nAs the authors mentioned in the response, FMs find the feature crossing as a kind of embedded representations, which may not be suitable for modeling sparse interactions.\nThus, the sparse interaction models need to be taken into consideration as well.\n\n[Ref1] Safe Feature Pruning for Sparse High-Order Interaction Models\n[Ref2] Selective Inference for Sparse High-Order Interaction Models", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory."}, "signatures": ["ICLR.cc/2020/Conference/Paper166/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper166/AnonReviewer3"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Automatically Learning Feature Crossing from Model Interpretation for Tabular Data", "authors": ["Zhaocheng Liu", "Qiang Liu", "Haoli Zhang"], "authorids": ["zhaocheng.liu@realai.ai", "qiang.liu@realai.ai", "haoli.zhang@realai.ai"], "keywords": ["AutoML", "feature crossing", "interpretation"], "TL;DR": "We propose a novel method called CrossGO, which automatically and efficiently selects useful cross features according to the interpretation inconsistency computed in deep neural networks.", "abstract": "Automatically feature generation is a major topic of automated machine learning. Among various feature generation approaches, feature crossing, which takes cross-product of sparse features, is a promising way to effectively capture the interactions among categorical features in tabular data. Previous works on feature crossing try to search in the set of all the possible cross feature fields. This is obviously not efficient when the size of original feature fields is large. Meanwhile, some deep learning-based methods combines deep neural networks and various interaction components. However, due to the existing of Deep Neural Networks (DNN), only a few cross features can be explicitly generated by the interaction components. Recently, piece-wise interpretation of DNN has been widely studied, and the piece-wise interpretations are usually inconsistent in different samples. Inspired by this, we give a definition of interpretation inconsistency in DNN, and propose a novel method called CrossGO, which selects useful cross features according to the interpretation inconsistency. The whole process of learning feature crossing can be done via simply training a DNN model and a logistic regression (LR) model. CrossGO can generate compact candidate set of cross feature fields, and promote the efficiency of searching. Extensive experiments have been conducted on several real-world datasets. Cross features generated by CrossGO can empower a simple LR model achieving approximate or even better performances comparing with complex DNN models.", "pdf": "/pdf/c39b15440e8a22dfb2c8ffd1b37118d17d498950.pdf", "paperhash": "liu|automatically_learning_feature_crossing_from_model_interpretation_for_tabular_data", "original_pdf": "/attachment/12eb9cf9f863af97bf98ef55cace2014a9e15e8a.pdf", "_bibtex": "@misc{\nliu2020automatically,\ntitle={Automatically Learning Feature Crossing from Model Interpretation for Tabular Data},\nauthor={Zhaocheng Liu and Qiang Liu and Haoli Zhang},\nyear={2020},\nurl={https://openreview.net/forum?id=Sye2s2VtDr}\n}"}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "Sye2s2VtDr", "replyto": "Sye2s2VtDr", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper166/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper166/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1576037928502, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper166/Reviewers"], "noninvitees": [], "tcdate": 1570237756058, "tmdate": 1576037928518, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper166/-/Official_Review"}}}, {"id": "BkxGEFUsir", "original": null, "number": 15, "cdate": 1573771561895, "ddate": null, "tcdate": 1573771561895, "tmdate": 1573771561895, "tddate": null, "forum": "Sye2s2VtDr", "replyto": "rylMxaALsr", "invitation": "ICLR.cc/2020/Conference/Paper166/-/Official_Comment", "content": {"title": "Thank you for your response (2)", "comment": "Re(1)\n\nThank you for the response. \n\n\nRe (2) \n\nDo the authors have any reference that supports the claim that DNN is the \"most\npowerful model for tabular data\"? It would be very helpful to me. Kaggle\ncompetition winning solutions almost always contain intricate featurizations\nwith a gradient boosting model for tabular data and very occasionally utilize\nneural network models. Neural networks are definitely the state of the art for\nimages, text and such but it is not as clear for tabular data.\n\n\nRe (3)\n\nThank you for clarification. The results in the current paper do not contain any\nerror bars so it is hard to understand the stability of the proposed scheme as\nis. \n"}, "signatures": ["ICLR.cc/2020/Conference/Paper166/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper166/AnonReviewer1", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Automatically Learning Feature Crossing from Model Interpretation for Tabular Data", "authors": ["Zhaocheng Liu", "Qiang Liu", "Haoli Zhang"], "authorids": ["zhaocheng.liu@realai.ai", "qiang.liu@realai.ai", "haoli.zhang@realai.ai"], "keywords": ["AutoML", "feature crossing", "interpretation"], "TL;DR": "We propose a novel method called CrossGO, which automatically and efficiently selects useful cross features according to the interpretation inconsistency computed in deep neural networks.", "abstract": "Automatically feature generation is a major topic of automated machine learning. Among various feature generation approaches, feature crossing, which takes cross-product of sparse features, is a promising way to effectively capture the interactions among categorical features in tabular data. Previous works on feature crossing try to search in the set of all the possible cross feature fields. This is obviously not efficient when the size of original feature fields is large. Meanwhile, some deep learning-based methods combines deep neural networks and various interaction components. However, due to the existing of Deep Neural Networks (DNN), only a few cross features can be explicitly generated by the interaction components. Recently, piece-wise interpretation of DNN has been widely studied, and the piece-wise interpretations are usually inconsistent in different samples. Inspired by this, we give a definition of interpretation inconsistency in DNN, and propose a novel method called CrossGO, which selects useful cross features according to the interpretation inconsistency. The whole process of learning feature crossing can be done via simply training a DNN model and a logistic regression (LR) model. CrossGO can generate compact candidate set of cross feature fields, and promote the efficiency of searching. Extensive experiments have been conducted on several real-world datasets. Cross features generated by CrossGO can empower a simple LR model achieving approximate or even better performances comparing with complex DNN models.", "pdf": "/pdf/c39b15440e8a22dfb2c8ffd1b37118d17d498950.pdf", "paperhash": "liu|automatically_learning_feature_crossing_from_model_interpretation_for_tabular_data", "original_pdf": "/attachment/12eb9cf9f863af97bf98ef55cace2014a9e15e8a.pdf", "_bibtex": "@misc{\nliu2020automatically,\ntitle={Automatically Learning Feature Crossing from Model Interpretation for Tabular Data},\nauthor={Zhaocheng Liu and Qiang Liu and Haoli Zhang},\nyear={2020},\nurl={https://openreview.net/forum?id=Sye2s2VtDr}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "Sye2s2VtDr", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper166/Authors", "ICLR.cc/2020/Conference/Paper166/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper166/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper166/Reviewers", "ICLR.cc/2020/Conference/Paper166/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper166/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper166/Authors|ICLR.cc/2020/Conference/Paper166/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504175370, "tmdate": 1576860556362, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper166/Authors", "ICLR.cc/2020/Conference/Paper166/Reviewers", "ICLR.cc/2020/Conference/Paper166/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper166/-/Official_Comment"}}}, {"id": "SJg3bP8jir", "original": null, "number": 14, "cdate": 1573771012062, "ddate": null, "tcdate": 1573771012062, "tmdate": 1573771012062, "tddate": null, "forum": "Sye2s2VtDr", "replyto": "SylUA2RIoS", "invitation": "ICLR.cc/2020/Conference/Paper166/-/Official_Comment", "content": {"title": "Thank you for your response (1)", "comment": "Re (1)\nThe reason for referring to these papers is that these papers are fairly recent\n(3/4 are published at a top AI/ML conference within the year) and I think, as\nreviewers, we are supposed to judge the novelty of the proposed scheme against\nexisting work (to the best of our knowledge). As I mentioned in the reviews, it\nwould be good to position the proposed scheme against these recent existing\nprior art. Whether empirical evaluation is required depends on the\nconnection. However, if the authors argue that there is no connection, that is\nnot completely clear to be in the author response.\n\nRe(2) \nI am not sure if the authors have properly read and understood the references I\npointed them to. For example, [4] can work with any target model -- it is\ndesigned to automatically generate new features (by combining/crossing existing\nones) that improve the performance of the base model. If XGBoost/DNN is the\n\"state of the art\" base model, it would improve their performance. If the base\nmodel is LR, it would generate features to improve LR. [3] generates feature\ncombinations for GLM (LR is a special case of GLM) so it is not clear how the\nauthors claim that [3] \"cannot be used to empower LR\". Moreover, the whole goal\nof this line of research is to generate interpretable models (hence using LR) by\nutilizing interpretable feature combinations. I would argue that [2,3] are doing\nexactly that so it would be good to understand clearly why these are not useful\nbaselines for interpretable models with binary data. \n\nRe(3)\nGiven [3,4], I feel that the claim that \"AutoCross [5] is the first work that\ncan enpower LR\" seems to lack justification. It would be helpful if the authors\ncould further explain their reasons to dismiss these (possibly) related prior\nart. Especially since AutoCross itself does not discuss [2,3,4].\n\n\nAgain, my goal is not to ask the authors to cite every paper out there but\nrather to clearly differentiate against recent related work (or at least explain\nto me why it is not related). Otherwise, it does not appear that the current\nmanuscript is well positioned with respect to the current state of the field."}, "signatures": ["ICLR.cc/2020/Conference/Paper166/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper166/AnonReviewer1", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Automatically Learning Feature Crossing from Model Interpretation for Tabular Data", "authors": ["Zhaocheng Liu", "Qiang Liu", "Haoli Zhang"], "authorids": ["zhaocheng.liu@realai.ai", "qiang.liu@realai.ai", "haoli.zhang@realai.ai"], "keywords": ["AutoML", "feature crossing", "interpretation"], "TL;DR": "We propose a novel method called CrossGO, which automatically and efficiently selects useful cross features according to the interpretation inconsistency computed in deep neural networks.", "abstract": "Automatically feature generation is a major topic of automated machine learning. Among various feature generation approaches, feature crossing, which takes cross-product of sparse features, is a promising way to effectively capture the interactions among categorical features in tabular data. Previous works on feature crossing try to search in the set of all the possible cross feature fields. This is obviously not efficient when the size of original feature fields is large. Meanwhile, some deep learning-based methods combines deep neural networks and various interaction components. However, due to the existing of Deep Neural Networks (DNN), only a few cross features can be explicitly generated by the interaction components. Recently, piece-wise interpretation of DNN has been widely studied, and the piece-wise interpretations are usually inconsistent in different samples. Inspired by this, we give a definition of interpretation inconsistency in DNN, and propose a novel method called CrossGO, which selects useful cross features according to the interpretation inconsistency. The whole process of learning feature crossing can be done via simply training a DNN model and a logistic regression (LR) model. CrossGO can generate compact candidate set of cross feature fields, and promote the efficiency of searching. Extensive experiments have been conducted on several real-world datasets. Cross features generated by CrossGO can empower a simple LR model achieving approximate or even better performances comparing with complex DNN models.", "pdf": "/pdf/c39b15440e8a22dfb2c8ffd1b37118d17d498950.pdf", "paperhash": "liu|automatically_learning_feature_crossing_from_model_interpretation_for_tabular_data", "original_pdf": "/attachment/12eb9cf9f863af97bf98ef55cace2014a9e15e8a.pdf", "_bibtex": "@misc{\nliu2020automatically,\ntitle={Automatically Learning Feature Crossing from Model Interpretation for Tabular Data},\nauthor={Zhaocheng Liu and Qiang Liu and Haoli Zhang},\nyear={2020},\nurl={https://openreview.net/forum?id=Sye2s2VtDr}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "Sye2s2VtDr", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper166/Authors", "ICLR.cc/2020/Conference/Paper166/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper166/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper166/Reviewers", "ICLR.cc/2020/Conference/Paper166/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper166/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper166/Authors|ICLR.cc/2020/Conference/Paper166/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504175370, "tmdate": 1576860556362, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper166/Authors", "ICLR.cc/2020/Conference/Paper166/Reviewers", "ICLR.cc/2020/Conference/Paper166/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper166/-/Official_Comment"}}}, {"id": "BJg9a68tjB", "original": null, "number": 13, "cdate": 1573641666273, "ddate": null, "tcdate": 1573641666273, "tmdate": 1573641666273, "tddate": null, "forum": "Sye2s2VtDr", "replyto": "Byg60oZKsH", "invitation": "ICLR.cc/2020/Conference/Paper166/-/Official_Comment", "content": {"title": "Higher-order FMs involved.", "comment": "Thanks for your advice.\n\nConventional FM only focuses on second-order interactions, and is extended to HOFM for high-order interactions. We have talked about this in section 2.1. Actually, the main problem of FM-based models is not the order of interactions, but the fact that interactions modeled by FM are somehow similarity between embeddings, which can not well capture all kinds of possible interactions.\n\nFortunately, we have done the experiments of HOFM when we began our work on feature interaction. FM and HOFM are the most natural methods for feature interaction. So, we have tried both of them at very first, and found them both not competitive with DNN.\n\nHere, we list the results of HOFM:\n\t   employee\tAdult\tCritio\tAllstate\tPrudential\tMovielens\tAnon1\tAnon2\nHOFM\t86.96\t91.67\t79.82\t86.48\t84.85\t         86.18\t         72.78\t90.38\n\nIt is clear that both CrossGO and DNN outperform HOFM. And on some datasets, the advantages are very large.\n\nIn summary, model with only interaction components while without deep components can not achieve competitive performances as DNN. So, all the deep learning-based methods must include both interaction components and deep components, to obtain satisfactory results."}, "signatures": ["ICLR.cc/2020/Conference/Paper166/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper166/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Automatically Learning Feature Crossing from Model Interpretation for Tabular Data", "authors": ["Zhaocheng Liu", "Qiang Liu", "Haoli Zhang"], "authorids": ["zhaocheng.liu@realai.ai", "qiang.liu@realai.ai", "haoli.zhang@realai.ai"], "keywords": ["AutoML", "feature crossing", "interpretation"], "TL;DR": "We propose a novel method called CrossGO, which automatically and efficiently selects useful cross features according to the interpretation inconsistency computed in deep neural networks.", "abstract": "Automatically feature generation is a major topic of automated machine learning. Among various feature generation approaches, feature crossing, which takes cross-product of sparse features, is a promising way to effectively capture the interactions among categorical features in tabular data. Previous works on feature crossing try to search in the set of all the possible cross feature fields. This is obviously not efficient when the size of original feature fields is large. Meanwhile, some deep learning-based methods combines deep neural networks and various interaction components. However, due to the existing of Deep Neural Networks (DNN), only a few cross features can be explicitly generated by the interaction components. Recently, piece-wise interpretation of DNN has been widely studied, and the piece-wise interpretations are usually inconsistent in different samples. Inspired by this, we give a definition of interpretation inconsistency in DNN, and propose a novel method called CrossGO, which selects useful cross features according to the interpretation inconsistency. The whole process of learning feature crossing can be done via simply training a DNN model and a logistic regression (LR) model. CrossGO can generate compact candidate set of cross feature fields, and promote the efficiency of searching. Extensive experiments have been conducted on several real-world datasets. Cross features generated by CrossGO can empower a simple LR model achieving approximate or even better performances comparing with complex DNN models.", "pdf": "/pdf/c39b15440e8a22dfb2c8ffd1b37118d17d498950.pdf", "paperhash": "liu|automatically_learning_feature_crossing_from_model_interpretation_for_tabular_data", "original_pdf": "/attachment/12eb9cf9f863af97bf98ef55cace2014a9e15e8a.pdf", "_bibtex": "@misc{\nliu2020automatically,\ntitle={Automatically Learning Feature Crossing from Model Interpretation for Tabular Data},\nauthor={Zhaocheng Liu and Qiang Liu and Haoli Zhang},\nyear={2020},\nurl={https://openreview.net/forum?id=Sye2s2VtDr}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "Sye2s2VtDr", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper166/Authors", "ICLR.cc/2020/Conference/Paper166/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper166/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper166/Reviewers", "ICLR.cc/2020/Conference/Paper166/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper166/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper166/Authors|ICLR.cc/2020/Conference/Paper166/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504175370, "tmdate": 1576860556362, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper166/Authors", "ICLR.cc/2020/Conference/Paper166/Reviewers", "ICLR.cc/2020/Conference/Paper166/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper166/-/Official_Comment"}}}, {"id": "Byg60oZKsH", "original": null, "number": 12, "cdate": 1573620693493, "ddate": null, "tcdate": 1573620693493, "tmdate": 1573620693493, "tddate": null, "forum": "Sye2s2VtDr", "replyto": "HJevRwU_sB", "invitation": "ICLR.cc/2020/Conference/Paper166/-/Official_Comment", "content": {"title": "Higher-order FMs", "comment": "First of all, I would like to thank the authors for an additional experiment on FM.\nHowever, there still remains a small concern.\nUnfortunately, the replay \"FM can only model second-order interaction\" is not true.\nOne of the reference [Ref1] in the paper provides a way to model higher-order interactions using FM, and I expect to see if including higher-order interaction is helpful or not.\n[Ref2] also provides a way to extend FM to higher-order interactions.\n\n[Ref1] Mathieu Blondel, Akinori Fujino, Naonori Ueda, and Masakazu Ishihata. Higher-order factorization\nmachines. In Advances in Neural Information Processing Systems, pp. 3351\u20133359, 2016.\n[Ref2] Exponential Machines https://arxiv.org/abs/1605.03795"}, "signatures": ["ICLR.cc/2020/Conference/Paper166/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper166/AnonReviewer3", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Automatically Learning Feature Crossing from Model Interpretation for Tabular Data", "authors": ["Zhaocheng Liu", "Qiang Liu", "Haoli Zhang"], "authorids": ["zhaocheng.liu@realai.ai", "qiang.liu@realai.ai", "haoli.zhang@realai.ai"], "keywords": ["AutoML", "feature crossing", "interpretation"], "TL;DR": "We propose a novel method called CrossGO, which automatically and efficiently selects useful cross features according to the interpretation inconsistency computed in deep neural networks.", "abstract": "Automatically feature generation is a major topic of automated machine learning. Among various feature generation approaches, feature crossing, which takes cross-product of sparse features, is a promising way to effectively capture the interactions among categorical features in tabular data. Previous works on feature crossing try to search in the set of all the possible cross feature fields. This is obviously not efficient when the size of original feature fields is large. Meanwhile, some deep learning-based methods combines deep neural networks and various interaction components. However, due to the existing of Deep Neural Networks (DNN), only a few cross features can be explicitly generated by the interaction components. Recently, piece-wise interpretation of DNN has been widely studied, and the piece-wise interpretations are usually inconsistent in different samples. Inspired by this, we give a definition of interpretation inconsistency in DNN, and propose a novel method called CrossGO, which selects useful cross features according to the interpretation inconsistency. The whole process of learning feature crossing can be done via simply training a DNN model and a logistic regression (LR) model. CrossGO can generate compact candidate set of cross feature fields, and promote the efficiency of searching. Extensive experiments have been conducted on several real-world datasets. Cross features generated by CrossGO can empower a simple LR model achieving approximate or even better performances comparing with complex DNN models.", "pdf": "/pdf/c39b15440e8a22dfb2c8ffd1b37118d17d498950.pdf", "paperhash": "liu|automatically_learning_feature_crossing_from_model_interpretation_for_tabular_data", "original_pdf": "/attachment/12eb9cf9f863af97bf98ef55cace2014a9e15e8a.pdf", "_bibtex": "@misc{\nliu2020automatically,\ntitle={Automatically Learning Feature Crossing from Model Interpretation for Tabular Data},\nauthor={Zhaocheng Liu and Qiang Liu and Haoli Zhang},\nyear={2020},\nurl={https://openreview.net/forum?id=Sye2s2VtDr}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "Sye2s2VtDr", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper166/Authors", "ICLR.cc/2020/Conference/Paper166/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper166/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper166/Reviewers", "ICLR.cc/2020/Conference/Paper166/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper166/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper166/Authors|ICLR.cc/2020/Conference/Paper166/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504175370, "tmdate": 1576860556362, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper166/Authors", "ICLR.cc/2020/Conference/Paper166/Reviewers", "ICLR.cc/2020/Conference/Paper166/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper166/-/Official_Comment"}}}, {"id": "HJevRwU_sB", "original": null, "number": 8, "cdate": 1573574607512, "ddate": null, "tcdate": 1573574607512, "tmdate": 1573613535636, "tddate": null, "forum": "Sye2s2VtDr", "replyto": "H1eu0MZ2tS", "invitation": "ICLR.cc/2020/Conference/Paper166/-/Official_Comment", "content": {"title": "Response to the question.", "comment": "Thanks for your comments.\n\nWe agree that FM is an important baseline for feature interaction. However, FM can only model second-order interaction. And interactions modeled by FM are somehow similarity between embeddings, which can not well capture all kinds of possible interactions. Moreover, we have actually tried FM, and found it is not competitive with DNN. Thus, we didn\u2019t involve it as a baseline in our manuscript.\n\nThanks for your advice, and we also believe it would be better to involve FM as a baseline to claim the effectiveness of CrossGO. So, we updated our manuscript, and involved FM as a baseline, as shown in table (3) and (4). According to the experimental results, both DNN and our proposed CrossGO outperform FM. Now, I believe the effectiveness of CrossGO is well demonstrated.\n"}, "signatures": ["ICLR.cc/2020/Conference/Paper166/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper166/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Automatically Learning Feature Crossing from Model Interpretation for Tabular Data", "authors": ["Zhaocheng Liu", "Qiang Liu", "Haoli Zhang"], "authorids": ["zhaocheng.liu@realai.ai", "qiang.liu@realai.ai", "haoli.zhang@realai.ai"], "keywords": ["AutoML", "feature crossing", "interpretation"], "TL;DR": "We propose a novel method called CrossGO, which automatically and efficiently selects useful cross features according to the interpretation inconsistency computed in deep neural networks.", "abstract": "Automatically feature generation is a major topic of automated machine learning. Among various feature generation approaches, feature crossing, which takes cross-product of sparse features, is a promising way to effectively capture the interactions among categorical features in tabular data. Previous works on feature crossing try to search in the set of all the possible cross feature fields. This is obviously not efficient when the size of original feature fields is large. Meanwhile, some deep learning-based methods combines deep neural networks and various interaction components. However, due to the existing of Deep Neural Networks (DNN), only a few cross features can be explicitly generated by the interaction components. Recently, piece-wise interpretation of DNN has been widely studied, and the piece-wise interpretations are usually inconsistent in different samples. Inspired by this, we give a definition of interpretation inconsistency in DNN, and propose a novel method called CrossGO, which selects useful cross features according to the interpretation inconsistency. The whole process of learning feature crossing can be done via simply training a DNN model and a logistic regression (LR) model. CrossGO can generate compact candidate set of cross feature fields, and promote the efficiency of searching. Extensive experiments have been conducted on several real-world datasets. Cross features generated by CrossGO can empower a simple LR model achieving approximate or even better performances comparing with complex DNN models.", "pdf": "/pdf/c39b15440e8a22dfb2c8ffd1b37118d17d498950.pdf", "paperhash": "liu|automatically_learning_feature_crossing_from_model_interpretation_for_tabular_data", "original_pdf": "/attachment/12eb9cf9f863af97bf98ef55cace2014a9e15e8a.pdf", "_bibtex": "@misc{\nliu2020automatically,\ntitle={Automatically Learning Feature Crossing from Model Interpretation for Tabular Data},\nauthor={Zhaocheng Liu and Qiang Liu and Haoli Zhang},\nyear={2020},\nurl={https://openreview.net/forum?id=Sye2s2VtDr}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "Sye2s2VtDr", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper166/Authors", "ICLR.cc/2020/Conference/Paper166/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper166/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper166/Reviewers", "ICLR.cc/2020/Conference/Paper166/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper166/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper166/Authors|ICLR.cc/2020/Conference/Paper166/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504175370, "tmdate": 1576860556362, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper166/Authors", "ICLR.cc/2020/Conference/Paper166/Reviewers", "ICLR.cc/2020/Conference/Paper166/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper166/-/Official_Comment"}}}, {"id": "HklzxQvuoS", "original": null, "number": 11, "cdate": 1573577449970, "ddate": null, "tcdate": 1573577449970, "tmdate": 1573577465824, "tddate": null, "forum": "Sye2s2VtDr", "replyto": "ByltxKWzYr", "invitation": "ICLR.cc/2020/Conference/Paper166/-/Official_Comment", "content": {"title": "Response to question (3).", "comment": "Thanks for your valuable advice.\n\nWe have updated our manuscript, and showed the comparison of cross feature field number between CrossGO and AutoCross, in table (6).\n\nAccording to the results, on narrow datasets, the numbers of the two methods are similar. While on wide datsets, CrossGO can generate more useful cross feature fields, and this results in the performance improvement in table (4)."}, "signatures": ["ICLR.cc/2020/Conference/Paper166/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper166/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Automatically Learning Feature Crossing from Model Interpretation for Tabular Data", "authors": ["Zhaocheng Liu", "Qiang Liu", "Haoli Zhang"], "authorids": ["zhaocheng.liu@realai.ai", "qiang.liu@realai.ai", "haoli.zhang@realai.ai"], "keywords": ["AutoML", "feature crossing", "interpretation"], "TL;DR": "We propose a novel method called CrossGO, which automatically and efficiently selects useful cross features according to the interpretation inconsistency computed in deep neural networks.", "abstract": "Automatically feature generation is a major topic of automated machine learning. Among various feature generation approaches, feature crossing, which takes cross-product of sparse features, is a promising way to effectively capture the interactions among categorical features in tabular data. Previous works on feature crossing try to search in the set of all the possible cross feature fields. This is obviously not efficient when the size of original feature fields is large. Meanwhile, some deep learning-based methods combines deep neural networks and various interaction components. However, due to the existing of Deep Neural Networks (DNN), only a few cross features can be explicitly generated by the interaction components. Recently, piece-wise interpretation of DNN has been widely studied, and the piece-wise interpretations are usually inconsistent in different samples. Inspired by this, we give a definition of interpretation inconsistency in DNN, and propose a novel method called CrossGO, which selects useful cross features according to the interpretation inconsistency. The whole process of learning feature crossing can be done via simply training a DNN model and a logistic regression (LR) model. CrossGO can generate compact candidate set of cross feature fields, and promote the efficiency of searching. Extensive experiments have been conducted on several real-world datasets. Cross features generated by CrossGO can empower a simple LR model achieving approximate or even better performances comparing with complex DNN models.", "pdf": "/pdf/c39b15440e8a22dfb2c8ffd1b37118d17d498950.pdf", "paperhash": "liu|automatically_learning_feature_crossing_from_model_interpretation_for_tabular_data", "original_pdf": "/attachment/12eb9cf9f863af97bf98ef55cace2014a9e15e8a.pdf", "_bibtex": "@misc{\nliu2020automatically,\ntitle={Automatically Learning Feature Crossing from Model Interpretation for Tabular Data},\nauthor={Zhaocheng Liu and Qiang Liu and Haoli Zhang},\nyear={2020},\nurl={https://openreview.net/forum?id=Sye2s2VtDr}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "Sye2s2VtDr", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper166/Authors", "ICLR.cc/2020/Conference/Paper166/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper166/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper166/Reviewers", "ICLR.cc/2020/Conference/Paper166/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper166/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper166/Authors|ICLR.cc/2020/Conference/Paper166/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504175370, "tmdate": 1576860556362, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper166/Authors", "ICLR.cc/2020/Conference/Paper166/Reviewers", "ICLR.cc/2020/Conference/Paper166/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper166/-/Official_Comment"}}}, {"id": "Hkl-QfvOiS", "original": null, "number": 10, "cdate": 1573577240522, "ddate": null, "tcdate": 1573577240522, "tmdate": 1573577240522, "tddate": null, "forum": "Sye2s2VtDr", "replyto": "ByltxKWzYr", "invitation": "ICLR.cc/2020/Conference/Paper166/-/Official_Comment", "content": {"title": "Response to question (2).", "comment": "Thanks for your valuable advice.\n\nAfter the submission of original manuscript, we have reproduced AutoCross on the wide datasets. We revised our manuscript, and compared AutoCross on both narrow and wide datasets in table (3)(4), and illustrated the comparision of running time in table(5).\n\nAccording to Table (4), CrossGO can significantly outperform AutoCross. This is because, on the wide datasets, the candidate set of cross features is inevitable to be extremely large, and samples for evaluating each candidate cross feature field are too little. So, the feature genration of AcutoCross on wide datasets is with great randomness and not reliable.\n\nAccording to table (5), our CrossGO is much faster than AutoCross. And the wider the dataset, the lager the advantage of CrossGO."}, "signatures": ["ICLR.cc/2020/Conference/Paper166/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper166/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Automatically Learning Feature Crossing from Model Interpretation for Tabular Data", "authors": ["Zhaocheng Liu", "Qiang Liu", "Haoli Zhang"], "authorids": ["zhaocheng.liu@realai.ai", "qiang.liu@realai.ai", "haoli.zhang@realai.ai"], "keywords": ["AutoML", "feature crossing", "interpretation"], "TL;DR": "We propose a novel method called CrossGO, which automatically and efficiently selects useful cross features according to the interpretation inconsistency computed in deep neural networks.", "abstract": "Automatically feature generation is a major topic of automated machine learning. Among various feature generation approaches, feature crossing, which takes cross-product of sparse features, is a promising way to effectively capture the interactions among categorical features in tabular data. Previous works on feature crossing try to search in the set of all the possible cross feature fields. This is obviously not efficient when the size of original feature fields is large. Meanwhile, some deep learning-based methods combines deep neural networks and various interaction components. However, due to the existing of Deep Neural Networks (DNN), only a few cross features can be explicitly generated by the interaction components. Recently, piece-wise interpretation of DNN has been widely studied, and the piece-wise interpretations are usually inconsistent in different samples. Inspired by this, we give a definition of interpretation inconsistency in DNN, and propose a novel method called CrossGO, which selects useful cross features according to the interpretation inconsistency. The whole process of learning feature crossing can be done via simply training a DNN model and a logistic regression (LR) model. CrossGO can generate compact candidate set of cross feature fields, and promote the efficiency of searching. Extensive experiments have been conducted on several real-world datasets. Cross features generated by CrossGO can empower a simple LR model achieving approximate or even better performances comparing with complex DNN models.", "pdf": "/pdf/c39b15440e8a22dfb2c8ffd1b37118d17d498950.pdf", "paperhash": "liu|automatically_learning_feature_crossing_from_model_interpretation_for_tabular_data", "original_pdf": "/attachment/12eb9cf9f863af97bf98ef55cace2014a9e15e8a.pdf", "_bibtex": "@misc{\nliu2020automatically,\ntitle={Automatically Learning Feature Crossing from Model Interpretation for Tabular Data},\nauthor={Zhaocheng Liu and Qiang Liu and Haoli Zhang},\nyear={2020},\nurl={https://openreview.net/forum?id=Sye2s2VtDr}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "Sye2s2VtDr", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper166/Authors", "ICLR.cc/2020/Conference/Paper166/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper166/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper166/Reviewers", "ICLR.cc/2020/Conference/Paper166/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper166/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper166/Authors|ICLR.cc/2020/Conference/Paper166/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504175370, "tmdate": 1576860556362, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper166/Authors", "ICLR.cc/2020/Conference/Paper166/Reviewers", "ICLR.cc/2020/Conference/Paper166/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper166/-/Official_Comment"}}}, {"id": "HJe48C8OjS", "original": null, "number": 9, "cdate": 1573576267760, "ddate": null, "tcdate": 1573576267760, "tmdate": 1573576267760, "tddate": null, "forum": "Sye2s2VtDr", "replyto": "ByltxKWzYr", "invitation": "ICLR.cc/2020/Conference/Paper166/-/Official_Comment", "content": {"title": "Response to question (1).", "comment": "Thanks for your comments. We are sorry that the parameter setting causes misunderstanding.\n\nActually, the parameters for filtering cross feature fields are with great physical meaning:\n\n$ \\eta$ is the threshold of interpretation inconsistency. It means the inconsistency of the contribution of a feature to the final prediction (lies in [0,1]). According to table (1), $ \\eta=0.01$ is reasonable.\n\n$\\delta$ is the maximum order of cross features. Extremely high-order (larger than 4th-order) cross features are rarely useful. So, for simplicity, it is reasonable to set $\\delta=4$. And the same setting is used in AutoCross.\n\n$\\varepsilon$ refers to the ratio of a cross feature field occurs in the samples. The setting of $\\varepsilon$ is to eliminate the sparsity of the filtering procedure, and accelerate the generation. The occurrence ratio of useful cross feature fields is usually much large than $0.01$. So, it is fun to set $\\varepsilon=0.01$.\n\n$\\gamma$ means the size of candidate size of cross feature fields. For the efficient searching in section 3.2, we set $\\gamma=2N$. Larger $\\gamma$ may slightly improve the effectiveness, but severely harm the efficiency. And according to table (6), $2N$ is totally enough, because of our accurate generation of candidate cross feature fields.\n\nAccording to the experiments on several datasets of different application domains, the default parameters achieve great performances.\n"}, "signatures": ["ICLR.cc/2020/Conference/Paper166/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper166/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Automatically Learning Feature Crossing from Model Interpretation for Tabular Data", "authors": ["Zhaocheng Liu", "Qiang Liu", "Haoli Zhang"], "authorids": ["zhaocheng.liu@realai.ai", "qiang.liu@realai.ai", "haoli.zhang@realai.ai"], "keywords": ["AutoML", "feature crossing", "interpretation"], "TL;DR": "We propose a novel method called CrossGO, which automatically and efficiently selects useful cross features according to the interpretation inconsistency computed in deep neural networks.", "abstract": "Automatically feature generation is a major topic of automated machine learning. Among various feature generation approaches, feature crossing, which takes cross-product of sparse features, is a promising way to effectively capture the interactions among categorical features in tabular data. Previous works on feature crossing try to search in the set of all the possible cross feature fields. This is obviously not efficient when the size of original feature fields is large. Meanwhile, some deep learning-based methods combines deep neural networks and various interaction components. However, due to the existing of Deep Neural Networks (DNN), only a few cross features can be explicitly generated by the interaction components. Recently, piece-wise interpretation of DNN has been widely studied, and the piece-wise interpretations are usually inconsistent in different samples. Inspired by this, we give a definition of interpretation inconsistency in DNN, and propose a novel method called CrossGO, which selects useful cross features according to the interpretation inconsistency. The whole process of learning feature crossing can be done via simply training a DNN model and a logistic regression (LR) model. CrossGO can generate compact candidate set of cross feature fields, and promote the efficiency of searching. Extensive experiments have been conducted on several real-world datasets. Cross features generated by CrossGO can empower a simple LR model achieving approximate or even better performances comparing with complex DNN models.", "pdf": "/pdf/c39b15440e8a22dfb2c8ffd1b37118d17d498950.pdf", "paperhash": "liu|automatically_learning_feature_crossing_from_model_interpretation_for_tabular_data", "original_pdf": "/attachment/12eb9cf9f863af97bf98ef55cace2014a9e15e8a.pdf", "_bibtex": "@misc{\nliu2020automatically,\ntitle={Automatically Learning Feature Crossing from Model Interpretation for Tabular Data},\nauthor={Zhaocheng Liu and Qiang Liu and Haoli Zhang},\nyear={2020},\nurl={https://openreview.net/forum?id=Sye2s2VtDr}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "Sye2s2VtDr", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper166/Authors", "ICLR.cc/2020/Conference/Paper166/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper166/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper166/Reviewers", "ICLR.cc/2020/Conference/Paper166/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper166/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper166/Authors|ICLR.cc/2020/Conference/Paper166/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504175370, "tmdate": 1576860556362, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper166/Authors", "ICLR.cc/2020/Conference/Paper166/Reviewers", "ICLR.cc/2020/Conference/Paper166/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper166/-/Official_Comment"}}}, {"id": "SylUA2RIoS", "original": null, "number": 6, "cdate": 1573477581667, "ddate": null, "tcdate": 1573477581667, "tmdate": 1573480036200, "tddate": null, "forum": "Sye2s2VtDr", "replyto": "ByejreosKS", "invitation": "ICLR.cc/2020/Conference/Paper166/-/Official_Comment", "content": {"title": "Reply to question (1)", "comment": "Thanks for your comments, but we don\u2019t think these methods should be compared. Here are the reasons:\n\n(1)\tConsidering there are so many works published every year, I don\u2019t think it is reasonable to ask author \u201cyou need to add some methods into your comparison\u201d when finding some literatures might be somehow related. If we do this, such questions can be endless.\n\n(2)\tWe have read the mentioned works, and found none of them show they can achieve competitive performances comparing with powerful models such as DNN and xgBoost, according to the reported results in the literatures. So, we don\u2019t think these methods worth to give a try. Moreover, [1][4] focus on numerical features. And in [2][3], the authors generate tree-structure rules, which can not be used to empower LR.\n\n(3)\tAutoCross [5] is the first work that can empower LR to achieve competitive performances comparing with DNN on several datasets. It is the state-of-the-art method in feature crossing. The paper of AutoCross is published in Aug 2019, and our paper is submitted in Sep 2019. So, it is enough to compare AutoCross and some representative methods in [5].\n\n\n[5] Yuanfei L, Mengshuo W, Hao Z, et al. AutoCross: Automatic Feature Crossing for Tabular Data in Real-World Applications. KDD, 2019.\n"}, "signatures": ["ICLR.cc/2020/Conference/Paper166/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper166/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Automatically Learning Feature Crossing from Model Interpretation for Tabular Data", "authors": ["Zhaocheng Liu", "Qiang Liu", "Haoli Zhang"], "authorids": ["zhaocheng.liu@realai.ai", "qiang.liu@realai.ai", "haoli.zhang@realai.ai"], "keywords": ["AutoML", "feature crossing", "interpretation"], "TL;DR": "We propose a novel method called CrossGO, which automatically and efficiently selects useful cross features according to the interpretation inconsistency computed in deep neural networks.", "abstract": "Automatically feature generation is a major topic of automated machine learning. Among various feature generation approaches, feature crossing, which takes cross-product of sparse features, is a promising way to effectively capture the interactions among categorical features in tabular data. Previous works on feature crossing try to search in the set of all the possible cross feature fields. This is obviously not efficient when the size of original feature fields is large. Meanwhile, some deep learning-based methods combines deep neural networks and various interaction components. However, due to the existing of Deep Neural Networks (DNN), only a few cross features can be explicitly generated by the interaction components. Recently, piece-wise interpretation of DNN has been widely studied, and the piece-wise interpretations are usually inconsistent in different samples. Inspired by this, we give a definition of interpretation inconsistency in DNN, and propose a novel method called CrossGO, which selects useful cross features according to the interpretation inconsistency. The whole process of learning feature crossing can be done via simply training a DNN model and a logistic regression (LR) model. CrossGO can generate compact candidate set of cross feature fields, and promote the efficiency of searching. Extensive experiments have been conducted on several real-world datasets. Cross features generated by CrossGO can empower a simple LR model achieving approximate or even better performances comparing with complex DNN models.", "pdf": "/pdf/c39b15440e8a22dfb2c8ffd1b37118d17d498950.pdf", "paperhash": "liu|automatically_learning_feature_crossing_from_model_interpretation_for_tabular_data", "original_pdf": "/attachment/12eb9cf9f863af97bf98ef55cace2014a9e15e8a.pdf", "_bibtex": "@misc{\nliu2020automatically,\ntitle={Automatically Learning Feature Crossing from Model Interpretation for Tabular Data},\nauthor={Zhaocheng Liu and Qiang Liu and Haoli Zhang},\nyear={2020},\nurl={https://openreview.net/forum?id=Sye2s2VtDr}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "Sye2s2VtDr", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper166/Authors", "ICLR.cc/2020/Conference/Paper166/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper166/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper166/Reviewers", "ICLR.cc/2020/Conference/Paper166/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper166/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper166/Authors|ICLR.cc/2020/Conference/Paper166/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504175370, "tmdate": 1576860556362, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper166/Authors", "ICLR.cc/2020/Conference/Paper166/Reviewers", "ICLR.cc/2020/Conference/Paper166/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper166/-/Official_Comment"}}}, {"id": "rylMxaALsr", "original": null, "number": 7, "cdate": 1573477609738, "ddate": null, "tcdate": 1573477609738, "tmdate": 1573477609738, "tddate": null, "forum": "Sye2s2VtDr", "replyto": "ByejreosKS", "invitation": "ICLR.cc/2020/Conference/Paper166/-/Official_Comment", "content": {"title": "Reply to question (2)", "comment": "Thanks for your comments. Actually, we don\u2019t need to question about the stability of CrossGO. Here are the reasons:\n\n(1)\tOur aim is to find what features are crossed in DNN and empower LR to achieve competitive performances in real-world applications. According to our results, this is satisfied. \tThe cross features in CrossGO are all learned from DNN. So, if CrossGO is too unstable to be applied, DNN will also be too unstable to be applied. However, DNN is well applied in real-world applications.\n\n(2)\tThe reason our model is tied with DNN is that, DNN is the most powerful model for tabular data. Finding what features are crossed in DNN can help us to achieve best performances. \n\n(3)\tActually, we have ran CrossGO 10 times, and reported the averaged AUC in the paper. The variances of AUC are relatively small, and even smaller than those of DNN, because of the searching process. And due to the existing of the searching process, difference between the set of final cross feature fields during each running is extremely small (on those datasets with little number of cross features, there is no difference). Thus, our CrossGO is actually more stable than DNN.\n\nIn summary, we don\u2019t need to question about the stability of CrossGO. It can been well used in various real-world applications.\n"}, "signatures": ["ICLR.cc/2020/Conference/Paper166/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper166/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Automatically Learning Feature Crossing from Model Interpretation for Tabular Data", "authors": ["Zhaocheng Liu", "Qiang Liu", "Haoli Zhang"], "authorids": ["zhaocheng.liu@realai.ai", "qiang.liu@realai.ai", "haoli.zhang@realai.ai"], "keywords": ["AutoML", "feature crossing", "interpretation"], "TL;DR": "We propose a novel method called CrossGO, which automatically and efficiently selects useful cross features according to the interpretation inconsistency computed in deep neural networks.", "abstract": "Automatically feature generation is a major topic of automated machine learning. Among various feature generation approaches, feature crossing, which takes cross-product of sparse features, is a promising way to effectively capture the interactions among categorical features in tabular data. Previous works on feature crossing try to search in the set of all the possible cross feature fields. This is obviously not efficient when the size of original feature fields is large. Meanwhile, some deep learning-based methods combines deep neural networks and various interaction components. However, due to the existing of Deep Neural Networks (DNN), only a few cross features can be explicitly generated by the interaction components. Recently, piece-wise interpretation of DNN has been widely studied, and the piece-wise interpretations are usually inconsistent in different samples. Inspired by this, we give a definition of interpretation inconsistency in DNN, and propose a novel method called CrossGO, which selects useful cross features according to the interpretation inconsistency. The whole process of learning feature crossing can be done via simply training a DNN model and a logistic regression (LR) model. CrossGO can generate compact candidate set of cross feature fields, and promote the efficiency of searching. Extensive experiments have been conducted on several real-world datasets. Cross features generated by CrossGO can empower a simple LR model achieving approximate or even better performances comparing with complex DNN models.", "pdf": "/pdf/c39b15440e8a22dfb2c8ffd1b37118d17d498950.pdf", "paperhash": "liu|automatically_learning_feature_crossing_from_model_interpretation_for_tabular_data", "original_pdf": "/attachment/12eb9cf9f863af97bf98ef55cace2014a9e15e8a.pdf", "_bibtex": "@misc{\nliu2020automatically,\ntitle={Automatically Learning Feature Crossing from Model Interpretation for Tabular Data},\nauthor={Zhaocheng Liu and Qiang Liu and Haoli Zhang},\nyear={2020},\nurl={https://openreview.net/forum?id=Sye2s2VtDr}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "Sye2s2VtDr", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper166/Authors", "ICLR.cc/2020/Conference/Paper166/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper166/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper166/Reviewers", "ICLR.cc/2020/Conference/Paper166/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper166/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper166/Authors|ICLR.cc/2020/Conference/Paper166/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504175370, "tmdate": 1576860556362, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper166/Authors", "ICLR.cc/2020/Conference/Paper166/Reviewers", "ICLR.cc/2020/Conference/Paper166/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper166/-/Official_Comment"}}}, {"id": "ByltxKWzYr", "original": null, "number": 1, "cdate": 1571064049398, "ddate": null, "tcdate": 1571064049398, "tmdate": 1572972630369, "tddate": null, "forum": "Sye2s2VtDr", "replyto": "Sye2s2VtDr", "invitation": "ICLR.cc/2020/Conference/Paper166/-/Official_Review", "content": {"rating": "3: Weak Reject", "experience_assessment": "I have read many papers in this area.", "review_assessment:_checking_correctness_of_derivations_and_theory": "I carefully checked the derivations and theory.", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #2", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review": "This paper attempts to solve the cross feature generation problem efficiently. The state-of-the-art method AutoCross cannot control the size of the searching set of the candidates of cross feature fields. To narrow down this set, the authors provides a measurement called Interpretation Inconsistency. With an easy toy experiment, the authors conjecture that features with large Interpretation Inconsistency tend to interact with other features in the hidden layers of DNN. Therefore, based on this conjecture, the authors design an effective algorithm to discard those cross features with small Interpretation Inconsistency value, which finally narrows the set of cross features. With this narrowed set, the whole procedure can be accelerated largely. \n\nPros:\nThis work can be regarded as an accelerated version of AutoCross. By incorporating Interpretation Inconsistency, the set of cross features can be effectively narrowed. Although this is an incremental work, this idea is relatively novel. \n\nCons:\n1.\tThe setting of the threshold for filtering feature fields is somewhat heuristic. The authors should provide some explanations on its setting. If not, we cannot trust it and doubt that it may cause some unexpected results and thus will not be robust.\n2.\tThe experiments are somewhat not convincing. The main contribution is to accelerate AutoCross. Thus, I expect to see the time complexity comparison between them. However, I do not find it in this paper. Although the authors mention that on wide datasets, AutoCross simply cannot work, on narrow datasets, a time complexity comparison should be provided.\n3.\tIn Table 5, only the numbers of cross feature fields of the proposed method are provided. A comparison with baseline methods on the number would be better to show the advantage of the proposed method.\n\nMinor: In Section 2.1, the double quotation marks should be revised."}, "signatures": ["ICLR.cc/2020/Conference/Paper166/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper166/AnonReviewer2"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Automatically Learning Feature Crossing from Model Interpretation for Tabular Data", "authors": ["Zhaocheng Liu", "Qiang Liu", "Haoli Zhang"], "authorids": ["zhaocheng.liu@realai.ai", "qiang.liu@realai.ai", "haoli.zhang@realai.ai"], "keywords": ["AutoML", "feature crossing", "interpretation"], "TL;DR": "We propose a novel method called CrossGO, which automatically and efficiently selects useful cross features according to the interpretation inconsistency computed in deep neural networks.", "abstract": "Automatically feature generation is a major topic of automated machine learning. Among various feature generation approaches, feature crossing, which takes cross-product of sparse features, is a promising way to effectively capture the interactions among categorical features in tabular data. Previous works on feature crossing try to search in the set of all the possible cross feature fields. This is obviously not efficient when the size of original feature fields is large. Meanwhile, some deep learning-based methods combines deep neural networks and various interaction components. However, due to the existing of Deep Neural Networks (DNN), only a few cross features can be explicitly generated by the interaction components. Recently, piece-wise interpretation of DNN has been widely studied, and the piece-wise interpretations are usually inconsistent in different samples. Inspired by this, we give a definition of interpretation inconsistency in DNN, and propose a novel method called CrossGO, which selects useful cross features according to the interpretation inconsistency. The whole process of learning feature crossing can be done via simply training a DNN model and a logistic regression (LR) model. CrossGO can generate compact candidate set of cross feature fields, and promote the efficiency of searching. Extensive experiments have been conducted on several real-world datasets. Cross features generated by CrossGO can empower a simple LR model achieving approximate or even better performances comparing with complex DNN models.", "pdf": "/pdf/c39b15440e8a22dfb2c8ffd1b37118d17d498950.pdf", "paperhash": "liu|automatically_learning_feature_crossing_from_model_interpretation_for_tabular_data", "original_pdf": "/attachment/12eb9cf9f863af97bf98ef55cace2014a9e15e8a.pdf", "_bibtex": "@misc{\nliu2020automatically,\ntitle={Automatically Learning Feature Crossing from Model Interpretation for Tabular Data},\nauthor={Zhaocheng Liu and Qiang Liu and Haoli Zhang},\nyear={2020},\nurl={https://openreview.net/forum?id=Sye2s2VtDr}\n}"}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "Sye2s2VtDr", "replyto": "Sye2s2VtDr", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper166/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper166/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1576037928502, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper166/Reviewers"], "noninvitees": [], "tcdate": 1570237756058, "tmdate": 1576037928518, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper166/-/Official_Review"}}}, {"id": "ByejreosKS", "original": null, "number": 2, "cdate": 1571692610790, "ddate": null, "tcdate": 1571692610790, "tmdate": 1572972630334, "tddate": null, "forum": "Sye2s2VtDr", "replyto": "Sye2s2VtDr", "invitation": "ICLR.cc/2020/Conference/Paper166/-/Official_Review", "content": {"rating": "3: Weak Reject", "experience_assessment": "I have published one or two papers in this area.", "review_assessment:_checking_correctness_of_derivations_and_theory": "N/A", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #1", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review": "\nThe paper presents a scheme to generate new features as cross-product\nof binary features to improve the performance of linear models while\nobtaining interpretable models. The candidate set of cross-features\ncan be exponential and is handled by the proposed scheme by utilizing\nthe gradient-based importances of the features in a (deep) neural\nnetwork. Features with large discrepancies in their local and global\ninterpretations are used as the seed set of candidate features for\ngenerating new cross-features, and the final step performs a feature\nselection to further reduce the final set of cross-features. The\nempirical evaluation demonstrates the utility of the proposed scheme\non 8 datasets. \n\nWhile the proposed scheme does present a way to improve the accuracy\nof interpretable models, I am currently recommending a reject for the\nfollowing reasons (given the higher standard recommended for papers\nover 8 pages):\n\n- While this paper does consider some baselines, it seems to be\n  missing some crucial baselines that address the same (or very\n  similar) problem. There are some papers [2,3] that learn boolean\n  conjunctions (that can be seen as cross-features) to generate\n  accurate interpretable models. Moreover, there are some search based\n  feature generation schemes [1,4] that significantly improve upon the\n  exhaustive feature generation scheme of Kanter & Veeramacheneni,\n  2015. This technique can easily be applicable in learning boolean\n  cross features with binary features. At the very least, it is important to \n  understand where this proposed scheme is positioned relative to the \n  aforementioned literature and why a comparison is not required.\n- It is very unintuitive (at least to me) to tie the candidate\n  generation scheme to a neural network especially given the\n  sensitivity of neural network training to different initializations\n  and other factors. For the same data and neural network, the local\n  vs. global discrepancies can change significantly, thereby changing\n  the candidate set of cross features. This can potentially make the\n  proposed feature generation scheme somewhat unstable, and the\n  interpretations from the subsequent models might not be as\n  interpretable as they seem. It would be good to understand what I am\n  missing here and why being tied to a neural network model is\n  essential and not an issue here. \n\n\nClarification:\n\n- Lines 8-10 in Algorithm 1 is not clearly explained.\n- The experiment to motivate Assumption 1 needs to be better\n  explained.\n\n\nMinor:\n\n- The notation in equation (1) needs to be clarified better.\n\n\n[1] Khurana, Udayan, et al. \"Cognito: Automated feature engineering\nfor supervised learning.\" 2016 IEEE 16th International Conference on\nData Mining Workshops (ICDMW). IEEE, 2016. \n[2] Dash, Sanjeeb, Oktay Gunluk, and Dennis Wei. \"Boolean decision\nrules via column generation.\" Advances in Neural Information\nProcessing Systems. 2018. \n[3] Wei, Dennis, et al. \"Generalized Linear Rule Models.\" Proceedings\nof the 36th International Conference on Machine Learning. 2019.\n[4] Khurana, Udayan, Horst Samulowitz, and Deepak Turaga. \"Feature\nengineering for predictive modeling using reinforcement learning.\"\nThirty-Second AAAI Conference on Artificial Intelligence. 2018. \n"}, "signatures": ["ICLR.cc/2020/Conference/Paper166/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper166/AnonReviewer1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Automatically Learning Feature Crossing from Model Interpretation for Tabular Data", "authors": ["Zhaocheng Liu", "Qiang Liu", "Haoli Zhang"], "authorids": ["zhaocheng.liu@realai.ai", "qiang.liu@realai.ai", "haoli.zhang@realai.ai"], "keywords": ["AutoML", "feature crossing", "interpretation"], "TL;DR": "We propose a novel method called CrossGO, which automatically and efficiently selects useful cross features according to the interpretation inconsistency computed in deep neural networks.", "abstract": "Automatically feature generation is a major topic of automated machine learning. Among various feature generation approaches, feature crossing, which takes cross-product of sparse features, is a promising way to effectively capture the interactions among categorical features in tabular data. Previous works on feature crossing try to search in the set of all the possible cross feature fields. This is obviously not efficient when the size of original feature fields is large. Meanwhile, some deep learning-based methods combines deep neural networks and various interaction components. However, due to the existing of Deep Neural Networks (DNN), only a few cross features can be explicitly generated by the interaction components. Recently, piece-wise interpretation of DNN has been widely studied, and the piece-wise interpretations are usually inconsistent in different samples. Inspired by this, we give a definition of interpretation inconsistency in DNN, and propose a novel method called CrossGO, which selects useful cross features according to the interpretation inconsistency. The whole process of learning feature crossing can be done via simply training a DNN model and a logistic regression (LR) model. CrossGO can generate compact candidate set of cross feature fields, and promote the efficiency of searching. Extensive experiments have been conducted on several real-world datasets. Cross features generated by CrossGO can empower a simple LR model achieving approximate or even better performances comparing with complex DNN models.", "pdf": "/pdf/c39b15440e8a22dfb2c8ffd1b37118d17d498950.pdf", "paperhash": "liu|automatically_learning_feature_crossing_from_model_interpretation_for_tabular_data", "original_pdf": "/attachment/12eb9cf9f863af97bf98ef55cace2014a9e15e8a.pdf", "_bibtex": "@misc{\nliu2020automatically,\ntitle={Automatically Learning Feature Crossing from Model Interpretation for Tabular Data},\nauthor={Zhaocheng Liu and Qiang Liu and Haoli Zhang},\nyear={2020},\nurl={https://openreview.net/forum?id=Sye2s2VtDr}\n}"}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "Sye2s2VtDr", "replyto": "Sye2s2VtDr", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper166/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper166/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1576037928502, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper166/Reviewers"], "noninvitees": [], "tcdate": 1570237756058, "tmdate": 1576037928518, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper166/-/Official_Review"}}}, {"id": "H1xvyQfwFH", "original": null, "number": 4, "cdate": 1571394271360, "ddate": null, "tcdate": 1571394271360, "tmdate": 1571971647096, "tddate": null, "forum": "Sye2s2VtDr", "replyto": "Sye2s2VtDr", "invitation": "ICLR.cc/2020/Conference/Paper166/-/Public_Comment", "content": {"title": "Comparison with existing methods.", "comment": "The model is interesting.\n\nAccording to the results on Criteo, CrossGO performs similarly with existing CTR prediction methods. So, what is the advantage of CrossGO, comparing with methods such as DeepFM, PNN and DCN?\n\nWhat is the correlation with the interaction part in AutoInt[1]. I notice that, AutoInt also has similar performances on Criteo.\n\n[1] AutoInt: Automatic Feature Interaction Learning via Self-Attentive Neural Networks.\n"}, "signatures": ["~John_Ryan3"], "readers": ["everyone"], "nonreaders": [], "writers": ["~John_Ryan3", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Automatically Learning Feature Crossing from Model Interpretation for Tabular Data", "authors": ["Zhaocheng Liu", "Qiang Liu", "Haoli Zhang"], "authorids": ["zhaocheng.liu@realai.ai", "qiang.liu@realai.ai", "haoli.zhang@realai.ai"], "keywords": ["AutoML", "feature crossing", "interpretation"], "TL;DR": "We propose a novel method called CrossGO, which automatically and efficiently selects useful cross features according to the interpretation inconsistency computed in deep neural networks.", "abstract": "Automatically feature generation is a major topic of automated machine learning. Among various feature generation approaches, feature crossing, which takes cross-product of sparse features, is a promising way to effectively capture the interactions among categorical features in tabular data. Previous works on feature crossing try to search in the set of all the possible cross feature fields. This is obviously not efficient when the size of original feature fields is large. Meanwhile, some deep learning-based methods combines deep neural networks and various interaction components. However, due to the existing of Deep Neural Networks (DNN), only a few cross features can be explicitly generated by the interaction components. Recently, piece-wise interpretation of DNN has been widely studied, and the piece-wise interpretations are usually inconsistent in different samples. Inspired by this, we give a definition of interpretation inconsistency in DNN, and propose a novel method called CrossGO, which selects useful cross features according to the interpretation inconsistency. The whole process of learning feature crossing can be done via simply training a DNN model and a logistic regression (LR) model. CrossGO can generate compact candidate set of cross feature fields, and promote the efficiency of searching. Extensive experiments have been conducted on several real-world datasets. Cross features generated by CrossGO can empower a simple LR model achieving approximate or even better performances comparing with complex DNN models.", "pdf": "/pdf/c39b15440e8a22dfb2c8ffd1b37118d17d498950.pdf", "paperhash": "liu|automatically_learning_feature_crossing_from_model_interpretation_for_tabular_data", "original_pdf": "/attachment/12eb9cf9f863af97bf98ef55cace2014a9e15e8a.pdf", "_bibtex": "@misc{\nliu2020automatically,\ntitle={Automatically Learning Feature Crossing from Model Interpretation for Tabular Data},\nauthor={Zhaocheng Liu and Qiang Liu and Haoli Zhang},\nyear={2020},\nurl={https://openreview.net/forum?id=Sye2s2VtDr}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "Sye2s2VtDr", "readers": {"values": ["everyone"], "description": "User groups that will be able to read this comment."}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "~.*"}}, "readers": ["everyone"], "tcdate": 1569504213012, "tmdate": 1576860589506, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["everyone"], "noninvitees": ["ICLR.cc/2020/Conference/Paper166/Authors", "ICLR.cc/2020/Conference/Paper166/Reviewers", "ICLR.cc/2020/Conference/Paper166/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper166/-/Public_Comment"}}}, {"id": "HJlvhVq9FH", "original": null, "number": 5, "cdate": 1571624110867, "ddate": null, "tcdate": 1571624110867, "tmdate": 1571624136822, "tddate": null, "forum": "Sye2s2VtDr", "replyto": "r1l85X2_tS", "invitation": "ICLR.cc/2020/Conference/Paper166/-/Public_Comment", "content": {"comment": "Thanks for your immediate reply.\nOk, I can get it now. This seems promising.", "title": "Thanks for your immediate reply."}, "signatures": ["~John_Ryan3"], "readers": ["everyone"], "nonreaders": [], "writers": ["~John_Ryan3", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Automatically Learning Feature Crossing from Model Interpretation for Tabular Data", "authors": ["Zhaocheng Liu", "Qiang Liu", "Haoli Zhang"], "authorids": ["zhaocheng.liu@realai.ai", "qiang.liu@realai.ai", "haoli.zhang@realai.ai"], "keywords": ["AutoML", "feature crossing", "interpretation"], "TL;DR": "We propose a novel method called CrossGO, which automatically and efficiently selects useful cross features according to the interpretation inconsistency computed in deep neural networks.", "abstract": "Automatically feature generation is a major topic of automated machine learning. Among various feature generation approaches, feature crossing, which takes cross-product of sparse features, is a promising way to effectively capture the interactions among categorical features in tabular data. Previous works on feature crossing try to search in the set of all the possible cross feature fields. This is obviously not efficient when the size of original feature fields is large. Meanwhile, some deep learning-based methods combines deep neural networks and various interaction components. However, due to the existing of Deep Neural Networks (DNN), only a few cross features can be explicitly generated by the interaction components. Recently, piece-wise interpretation of DNN has been widely studied, and the piece-wise interpretations are usually inconsistent in different samples. Inspired by this, we give a definition of interpretation inconsistency in DNN, and propose a novel method called CrossGO, which selects useful cross features according to the interpretation inconsistency. The whole process of learning feature crossing can be done via simply training a DNN model and a logistic regression (LR) model. CrossGO can generate compact candidate set of cross feature fields, and promote the efficiency of searching. Extensive experiments have been conducted on several real-world datasets. Cross features generated by CrossGO can empower a simple LR model achieving approximate or even better performances comparing with complex DNN models.", "pdf": "/pdf/c39b15440e8a22dfb2c8ffd1b37118d17d498950.pdf", "paperhash": "liu|automatically_learning_feature_crossing_from_model_interpretation_for_tabular_data", "original_pdf": "/attachment/12eb9cf9f863af97bf98ef55cace2014a9e15e8a.pdf", "_bibtex": "@misc{\nliu2020automatically,\ntitle={Automatically Learning Feature Crossing from Model Interpretation for Tabular Data},\nauthor={Zhaocheng Liu and Qiang Liu and Haoli Zhang},\nyear={2020},\nurl={https://openreview.net/forum?id=Sye2s2VtDr}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "Sye2s2VtDr", "readers": {"values": ["everyone"], "description": "User groups that will be able to read this comment."}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "~.*"}}, "readers": ["everyone"], "tcdate": 1569504213012, "tmdate": 1576860589506, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["everyone"], "noninvitees": ["ICLR.cc/2020/Conference/Paper166/Authors", "ICLR.cc/2020/Conference/Paper166/Reviewers", "ICLR.cc/2020/Conference/Paper166/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper166/-/Public_Comment"}}}, {"id": "r1l85X2_tS", "original": null, "number": 5, "cdate": 1571500942458, "ddate": null, "tcdate": 1571500942458, "tmdate": 1571500942458, "tddate": null, "forum": "Sye2s2VtDr", "replyto": "H1xvyQfwFH", "invitation": "ICLR.cc/2020/Conference/Paper166/-/Official_Comment", "content": {"comment": "Thanks for your interest in our work.\n\nComplex deep neural networks have high performances, and can implicitly capture some feature interactions in their hidden layers, but can not be explicitly interpreted. Simple linear models, e.g., LR, have relatively low performances, but can be fully interpreted, and all the prediction made by LR can be easily explained. Thus, in this work, we aim to combine the advantages of DNN and LR, and extract useful cross feature to empower simple LR models to achieve similar performances comparing with DNN. Chasing for the SOTA performances, which might be slightly higher than DNN, is not the purpose of this work. Moreover, in real applications, simple LR models are flexible, and easy to implement.\n\nOn the other hand, deep learning-based CTR models can explicitly capture only part of feature interactions. For example, DeepFM can do this via its FM module, and DCN can achieve this through the cross net. However, due to the existing of DNN in these methods, most feature interactions are capture by the hidden layers, and only a few feature interactions can be explicitly explained, as we discussed in section 2.1. Thus, these deep learning-based CTR models are partially interpretable, while LR empowered by CrossGO is fully interpretable.\n\nAutoInt applies self-attention to find feature interactions. This is one way to find cross features, like FM in DeepFM and cross net in DCN. According to the original paper of AutoInt, combining Eq. (8) and (9), we can obviously find a DNN structure with input of the original features. Thus, as explained before, only a few cross features can be explicitly captured by the self-attention module.\n\nActually, about one year ago, we have tried similar architecture with AutoInt, with self-attention to find cross features. If we only apply self-attention, without DNN-like architectures, e.g., residual in AutoInt, we can not obtain competitive performances. If we involve DNN in the model, the performances are similar with or slightly over DNN, but not enough cross features can be extracted and explained. Thus, the self-attention module is not enough powerful for crossing features, and can not meet our purpose.\n", "title": "Thanks for your interest."}, "signatures": ["ICLR.cc/2020/Conference/Paper166/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper166/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Automatically Learning Feature Crossing from Model Interpretation for Tabular Data", "authors": ["Zhaocheng Liu", "Qiang Liu", "Haoli Zhang"], "authorids": ["zhaocheng.liu@realai.ai", "qiang.liu@realai.ai", "haoli.zhang@realai.ai"], "keywords": ["AutoML", "feature crossing", "interpretation"], "TL;DR": "We propose a novel method called CrossGO, which automatically and efficiently selects useful cross features according to the interpretation inconsistency computed in deep neural networks.", "abstract": "Automatically feature generation is a major topic of automated machine learning. Among various feature generation approaches, feature crossing, which takes cross-product of sparse features, is a promising way to effectively capture the interactions among categorical features in tabular data. Previous works on feature crossing try to search in the set of all the possible cross feature fields. This is obviously not efficient when the size of original feature fields is large. Meanwhile, some deep learning-based methods combines deep neural networks and various interaction components. However, due to the existing of Deep Neural Networks (DNN), only a few cross features can be explicitly generated by the interaction components. Recently, piece-wise interpretation of DNN has been widely studied, and the piece-wise interpretations are usually inconsistent in different samples. Inspired by this, we give a definition of interpretation inconsistency in DNN, and propose a novel method called CrossGO, which selects useful cross features according to the interpretation inconsistency. The whole process of learning feature crossing can be done via simply training a DNN model and a logistic regression (LR) model. CrossGO can generate compact candidate set of cross feature fields, and promote the efficiency of searching. Extensive experiments have been conducted on several real-world datasets. Cross features generated by CrossGO can empower a simple LR model achieving approximate or even better performances comparing with complex DNN models.", "pdf": "/pdf/c39b15440e8a22dfb2c8ffd1b37118d17d498950.pdf", "paperhash": "liu|automatically_learning_feature_crossing_from_model_interpretation_for_tabular_data", "original_pdf": "/attachment/12eb9cf9f863af97bf98ef55cace2014a9e15e8a.pdf", "_bibtex": "@misc{\nliu2020automatically,\ntitle={Automatically Learning Feature Crossing from Model Interpretation for Tabular Data},\nauthor={Zhaocheng Liu and Qiang Liu and Haoli Zhang},\nyear={2020},\nurl={https://openreview.net/forum?id=Sye2s2VtDr}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "Sye2s2VtDr", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper166/Authors", "ICLR.cc/2020/Conference/Paper166/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper166/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper166/Reviewers", "ICLR.cc/2020/Conference/Paper166/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper166/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper166/Authors|ICLR.cc/2020/Conference/Paper166/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504175370, "tmdate": 1576860556362, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper166/Authors", "ICLR.cc/2020/Conference/Paper166/Reviewers", "ICLR.cc/2020/Conference/Paper166/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper166/-/Official_Comment"}}}, {"id": "HJgTxp58tH", "original": null, "number": 4, "cdate": 1571364085498, "ddate": null, "tcdate": 1571364085498, "tmdate": 1571364085498, "tddate": null, "forum": "Sye2s2VtDr", "replyto": "BkePA3fEtr", "invitation": "ICLR.cc/2020/Conference/Paper166/-/Official_Comment", "content": {"comment": "Thanks for your affirmation of our work, but I don't know much about the application field you mentioned. Good luck!\n\n1) We now have a distributed implementation for commercial use, involving many our own modules, so it is not available for releasing. We are working on implementing our CrossGO model based on open-source modules. \n\n2) We think that the ideal model should be fully interpretable. Logistic regression (LR) is a linear model, which is fully interpretable, but it needs manual feature engineering to improve performance. CrossGO can automatically generate cross features, which empower a simple LR model to always achieve better performance comparing with deep neural networks (DNNs). As mentioned in section 2.1, wide & deep is a deep learning-based method, which is not fully interpretable. Thus, CrossGO+LR is the best choice.  \n\n3) Thanks for your correction.", "title": "Thanks for your reply."}, "signatures": ["ICLR.cc/2020/Conference/Paper166/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper166/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Automatically Learning Feature Crossing from Model Interpretation for Tabular Data", "authors": ["Zhaocheng Liu", "Qiang Liu", "Haoli Zhang"], "authorids": ["zhaocheng.liu@realai.ai", "qiang.liu@realai.ai", "haoli.zhang@realai.ai"], "keywords": ["AutoML", "feature crossing", "interpretation"], "TL;DR": "We propose a novel method called CrossGO, which automatically and efficiently selects useful cross features according to the interpretation inconsistency computed in deep neural networks.", "abstract": "Automatically feature generation is a major topic of automated machine learning. Among various feature generation approaches, feature crossing, which takes cross-product of sparse features, is a promising way to effectively capture the interactions among categorical features in tabular data. Previous works on feature crossing try to search in the set of all the possible cross feature fields. This is obviously not efficient when the size of original feature fields is large. Meanwhile, some deep learning-based methods combines deep neural networks and various interaction components. However, due to the existing of Deep Neural Networks (DNN), only a few cross features can be explicitly generated by the interaction components. Recently, piece-wise interpretation of DNN has been widely studied, and the piece-wise interpretations are usually inconsistent in different samples. Inspired by this, we give a definition of interpretation inconsistency in DNN, and propose a novel method called CrossGO, which selects useful cross features according to the interpretation inconsistency. The whole process of learning feature crossing can be done via simply training a DNN model and a logistic regression (LR) model. CrossGO can generate compact candidate set of cross feature fields, and promote the efficiency of searching. Extensive experiments have been conducted on several real-world datasets. Cross features generated by CrossGO can empower a simple LR model achieving approximate or even better performances comparing with complex DNN models.", "pdf": "/pdf/c39b15440e8a22dfb2c8ffd1b37118d17d498950.pdf", "paperhash": "liu|automatically_learning_feature_crossing_from_model_interpretation_for_tabular_data", "original_pdf": "/attachment/12eb9cf9f863af97bf98ef55cace2014a9e15e8a.pdf", "_bibtex": "@misc{\nliu2020automatically,\ntitle={Automatically Learning Feature Crossing from Model Interpretation for Tabular Data},\nauthor={Zhaocheng Liu and Qiang Liu and Haoli Zhang},\nyear={2020},\nurl={https://openreview.net/forum?id=Sye2s2VtDr}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "Sye2s2VtDr", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper166/Authors", "ICLR.cc/2020/Conference/Paper166/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper166/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper166/Reviewers", "ICLR.cc/2020/Conference/Paper166/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper166/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper166/Authors|ICLR.cc/2020/Conference/Paper166/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504175370, "tmdate": 1576860556362, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper166/Authors", "ICLR.cc/2020/Conference/Paper166/Reviewers", "ICLR.cc/2020/Conference/Paper166/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper166/-/Official_Comment"}}}, {"id": "Bkx_BOE4Fr", "original": null, "number": 3, "cdate": 1571207232074, "ddate": null, "tcdate": 1571207232074, "tmdate": 1571207232074, "tddate": null, "forum": "Sye2s2VtDr", "replyto": "Sye2s2VtDr", "invitation": "ICLR.cc/2020/Conference/Paper166/-/Official_Comment", "content": {"comment": "We have a typo in the example in Fig. (1). The first cross feature field should be {$f_1$,$f_3$}, instead of {$f_1$,$f_2$}.\nSorry if this caused misunderstanding.", "title": "Correction in Fig. (1)."}, "signatures": ["ICLR.cc/2020/Conference/Paper166/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper166/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Automatically Learning Feature Crossing from Model Interpretation for Tabular Data", "authors": ["Zhaocheng Liu", "Qiang Liu", "Haoli Zhang"], "authorids": ["zhaocheng.liu@realai.ai", "qiang.liu@realai.ai", "haoli.zhang@realai.ai"], "keywords": ["AutoML", "feature crossing", "interpretation"], "TL;DR": "We propose a novel method called CrossGO, which automatically and efficiently selects useful cross features according to the interpretation inconsistency computed in deep neural networks.", "abstract": "Automatically feature generation is a major topic of automated machine learning. Among various feature generation approaches, feature crossing, which takes cross-product of sparse features, is a promising way to effectively capture the interactions among categorical features in tabular data. Previous works on feature crossing try to search in the set of all the possible cross feature fields. This is obviously not efficient when the size of original feature fields is large. Meanwhile, some deep learning-based methods combines deep neural networks and various interaction components. However, due to the existing of Deep Neural Networks (DNN), only a few cross features can be explicitly generated by the interaction components. Recently, piece-wise interpretation of DNN has been widely studied, and the piece-wise interpretations are usually inconsistent in different samples. Inspired by this, we give a definition of interpretation inconsistency in DNN, and propose a novel method called CrossGO, which selects useful cross features according to the interpretation inconsistency. The whole process of learning feature crossing can be done via simply training a DNN model and a logistic regression (LR) model. CrossGO can generate compact candidate set of cross feature fields, and promote the efficiency of searching. Extensive experiments have been conducted on several real-world datasets. Cross features generated by CrossGO can empower a simple LR model achieving approximate or even better performances comparing with complex DNN models.", "pdf": "/pdf/c39b15440e8a22dfb2c8ffd1b37118d17d498950.pdf", "paperhash": "liu|automatically_learning_feature_crossing_from_model_interpretation_for_tabular_data", "original_pdf": "/attachment/12eb9cf9f863af97bf98ef55cace2014a9e15e8a.pdf", "_bibtex": "@misc{\nliu2020automatically,\ntitle={Automatically Learning Feature Crossing from Model Interpretation for Tabular Data},\nauthor={Zhaocheng Liu and Qiang Liu and Haoli Zhang},\nyear={2020},\nurl={https://openreview.net/forum?id=Sye2s2VtDr}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "Sye2s2VtDr", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper166/Authors", "ICLR.cc/2020/Conference/Paper166/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper166/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper166/Reviewers", "ICLR.cc/2020/Conference/Paper166/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper166/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper166/Authors|ICLR.cc/2020/Conference/Paper166/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504175370, "tmdate": 1576860556362, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper166/Authors", "ICLR.cc/2020/Conference/Paper166/Reviewers", "ICLR.cc/2020/Conference/Paper166/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper166/-/Official_Comment"}}}, {"id": "BkePA3fEtr", "original": null, "number": 3, "cdate": 1571200207153, "ddate": null, "tcdate": 1571200207153, "tmdate": 1571200207153, "tddate": null, "forum": "Sye2s2VtDr", "replyto": "Sye2s2VtDr", "invitation": "ICLR.cc/2020/Conference/Paper166/-/Public_Comment", "content": {"comment": "This article proposed an exciting model, and I can envision the use of CrossGo in many fields. For many practical applications, feature engineering is significant to improve the model's performance. Therefore, neural networks show better results in many problems (neural networks can automatically generate new features). However, the neural network lacks interpretability. It is difficult to understand what new variables are generated in the neural network, and it is almost impossible to analyze and interpret the new variables based on physical mechanisms. However, CrossGo has the potential to solve this problem.\n\nThe CrossGo not only helps to quickly perform feature engineering, but also helps to improve the interpretability of the model. More importantly, we can try to explain the new variables generated by CrossGo from the physical meaning, and it is possible to find the physical mechanisms and control factors that have not been discovered before. I plan to apply this method to the field of petroleum engineering and analyze the relationship between well logs based on the synthetic well log generation model. I believe that I can get some interesting results from the perspective of physical mechanism.\n\nI also have some questions about this paper:\n\n1.\tIs the code of this study available online?\n2.\tWhy do you add the generated cross feature to the LR model? Why not use a wide & deep architecture to add the generated cross feature to the wide section? This eliminates the need to manually generate features for the wide section of the models.\n3.\tIn the pseudocode Algorithm 2, the final set of cross feature fields in line 6 should be shown as the uppercase S instead of lowercase s.\n", "title": "Great work and meaningful to knowledge discovery"}, "signatures": ["~Yuntian_Chen1"], "readers": ["everyone"], "nonreaders": [], "writers": ["~Yuntian_Chen1", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Automatically Learning Feature Crossing from Model Interpretation for Tabular Data", "authors": ["Zhaocheng Liu", "Qiang Liu", "Haoli Zhang"], "authorids": ["zhaocheng.liu@realai.ai", "qiang.liu@realai.ai", "haoli.zhang@realai.ai"], "keywords": ["AutoML", "feature crossing", "interpretation"], "TL;DR": "We propose a novel method called CrossGO, which automatically and efficiently selects useful cross features according to the interpretation inconsistency computed in deep neural networks.", "abstract": "Automatically feature generation is a major topic of automated machine learning. Among various feature generation approaches, feature crossing, which takes cross-product of sparse features, is a promising way to effectively capture the interactions among categorical features in tabular data. Previous works on feature crossing try to search in the set of all the possible cross feature fields. This is obviously not efficient when the size of original feature fields is large. Meanwhile, some deep learning-based methods combines deep neural networks and various interaction components. However, due to the existing of Deep Neural Networks (DNN), only a few cross features can be explicitly generated by the interaction components. Recently, piece-wise interpretation of DNN has been widely studied, and the piece-wise interpretations are usually inconsistent in different samples. Inspired by this, we give a definition of interpretation inconsistency in DNN, and propose a novel method called CrossGO, which selects useful cross features according to the interpretation inconsistency. The whole process of learning feature crossing can be done via simply training a DNN model and a logistic regression (LR) model. CrossGO can generate compact candidate set of cross feature fields, and promote the efficiency of searching. Extensive experiments have been conducted on several real-world datasets. Cross features generated by CrossGO can empower a simple LR model achieving approximate or even better performances comparing with complex DNN models.", "pdf": "/pdf/c39b15440e8a22dfb2c8ffd1b37118d17d498950.pdf", "paperhash": "liu|automatically_learning_feature_crossing_from_model_interpretation_for_tabular_data", "original_pdf": "/attachment/12eb9cf9f863af97bf98ef55cace2014a9e15e8a.pdf", "_bibtex": "@misc{\nliu2020automatically,\ntitle={Automatically Learning Feature Crossing from Model Interpretation for Tabular Data},\nauthor={Zhaocheng Liu and Qiang Liu and Haoli Zhang},\nyear={2020},\nurl={https://openreview.net/forum?id=Sye2s2VtDr}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "Sye2s2VtDr", "readers": {"values": ["everyone"], "description": "User groups that will be able to read this comment."}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "~.*"}}, "readers": ["everyone"], "tcdate": 1569504213012, "tmdate": 1576860589506, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["everyone"], "noninvitees": ["ICLR.cc/2020/Conference/Paper166/Authors", "ICLR.cc/2020/Conference/Paper166/Reviewers", "ICLR.cc/2020/Conference/Paper166/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper166/-/Public_Comment"}}}, {"id": "B1gM3VC9ur", "original": null, "number": 2, "cdate": 1570591913555, "ddate": null, "tcdate": 1570591913555, "tmdate": 1570591913555, "tddate": null, "forum": "Sye2s2VtDr", "replyto": "Bye7oD0Y_H", "invitation": "ICLR.cc/2020/Conference/Paper166/-/Official_Comment", "content": {"comment": "Thanks for your reply.\n\n(1) There are no other features exist outside those selected fields.\n\n(2) No, we do not need this. The selected cross featre fields work for the whole set of samples. If we have different fields for different samples, the online inference process is hard to be efficiently done.\n\n(3) Auctually, in a sparse LR, embeddings of features are used, where dimensionality is one. Other than this, learning embeddings is not necessary.", "title": "Thanks for the reply. "}, "signatures": ["ICLR.cc/2020/Conference/Paper166/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper166/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Automatically Learning Feature Crossing from Model Interpretation for Tabular Data", "authors": ["Zhaocheng Liu", "Qiang Liu", "Haoli Zhang"], "authorids": ["zhaocheng.liu@realai.ai", "qiang.liu@realai.ai", "haoli.zhang@realai.ai"], "keywords": ["AutoML", "feature crossing", "interpretation"], "TL;DR": "We propose a novel method called CrossGO, which automatically and efficiently selects useful cross features according to the interpretation inconsistency computed in deep neural networks.", "abstract": "Automatically feature generation is a major topic of automated machine learning. Among various feature generation approaches, feature crossing, which takes cross-product of sparse features, is a promising way to effectively capture the interactions among categorical features in tabular data. Previous works on feature crossing try to search in the set of all the possible cross feature fields. This is obviously not efficient when the size of original feature fields is large. Meanwhile, some deep learning-based methods combines deep neural networks and various interaction components. However, due to the existing of Deep Neural Networks (DNN), only a few cross features can be explicitly generated by the interaction components. Recently, piece-wise interpretation of DNN has been widely studied, and the piece-wise interpretations are usually inconsistent in different samples. Inspired by this, we give a definition of interpretation inconsistency in DNN, and propose a novel method called CrossGO, which selects useful cross features according to the interpretation inconsistency. The whole process of learning feature crossing can be done via simply training a DNN model and a logistic regression (LR) model. CrossGO can generate compact candidate set of cross feature fields, and promote the efficiency of searching. Extensive experiments have been conducted on several real-world datasets. Cross features generated by CrossGO can empower a simple LR model achieving approximate or even better performances comparing with complex DNN models.", "pdf": "/pdf/c39b15440e8a22dfb2c8ffd1b37118d17d498950.pdf", "paperhash": "liu|automatically_learning_feature_crossing_from_model_interpretation_for_tabular_data", "original_pdf": "/attachment/12eb9cf9f863af97bf98ef55cace2014a9e15e8a.pdf", "_bibtex": "@misc{\nliu2020automatically,\ntitle={Automatically Learning Feature Crossing from Model Interpretation for Tabular Data},\nauthor={Zhaocheng Liu and Qiang Liu and Haoli Zhang},\nyear={2020},\nurl={https://openreview.net/forum?id=Sye2s2VtDr}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "Sye2s2VtDr", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper166/Authors", "ICLR.cc/2020/Conference/Paper166/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper166/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper166/Reviewers", "ICLR.cc/2020/Conference/Paper166/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper166/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper166/Authors|ICLR.cc/2020/Conference/Paper166/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504175370, "tmdate": 1576860556362, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper166/Authors", "ICLR.cc/2020/Conference/Paper166/Reviewers", "ICLR.cc/2020/Conference/Paper166/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper166/-/Official_Comment"}}}, {"id": "Bye7oD0Y_H", "original": null, "number": 2, "cdate": 1570527130709, "ddate": null, "tcdate": 1570527130709, "tmdate": 1570527130709, "tddate": null, "forum": "Sye2s2VtDr", "replyto": "Sye2s2VtDr", "invitation": "ICLR.cc/2020/Conference/Paper166/-/Public_Comment", "content": {"comment": "This work propose an effective way to generate features.\n\nSome discussions or suggestions :\n1. The work first selects feature fields and then generate features from the selected fields. Does other features exist outside those the selected fields\uff1f\n2. The selected fields are fixed for all samples in this work. Do we need different fields for different samples?\n3. Is it necessary to learn embeddings for generated features?", "title": "Efficient for Feature generation"}, "signatures": ["~Claude_Shannon1"], "readers": ["everyone"], "nonreaders": [], "writers": ["~Claude_Shannon1", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Automatically Learning Feature Crossing from Model Interpretation for Tabular Data", "authors": ["Zhaocheng Liu", "Qiang Liu", "Haoli Zhang"], "authorids": ["zhaocheng.liu@realai.ai", "qiang.liu@realai.ai", "haoli.zhang@realai.ai"], "keywords": ["AutoML", "feature crossing", "interpretation"], "TL;DR": "We propose a novel method called CrossGO, which automatically and efficiently selects useful cross features according to the interpretation inconsistency computed in deep neural networks.", "abstract": "Automatically feature generation is a major topic of automated machine learning. Among various feature generation approaches, feature crossing, which takes cross-product of sparse features, is a promising way to effectively capture the interactions among categorical features in tabular data. Previous works on feature crossing try to search in the set of all the possible cross feature fields. This is obviously not efficient when the size of original feature fields is large. Meanwhile, some deep learning-based methods combines deep neural networks and various interaction components. However, due to the existing of Deep Neural Networks (DNN), only a few cross features can be explicitly generated by the interaction components. Recently, piece-wise interpretation of DNN has been widely studied, and the piece-wise interpretations are usually inconsistent in different samples. Inspired by this, we give a definition of interpretation inconsistency in DNN, and propose a novel method called CrossGO, which selects useful cross features according to the interpretation inconsistency. The whole process of learning feature crossing can be done via simply training a DNN model and a logistic regression (LR) model. CrossGO can generate compact candidate set of cross feature fields, and promote the efficiency of searching. Extensive experiments have been conducted on several real-world datasets. Cross features generated by CrossGO can empower a simple LR model achieving approximate or even better performances comparing with complex DNN models.", "pdf": "/pdf/c39b15440e8a22dfb2c8ffd1b37118d17d498950.pdf", "paperhash": "liu|automatically_learning_feature_crossing_from_model_interpretation_for_tabular_data", "original_pdf": "/attachment/12eb9cf9f863af97bf98ef55cace2014a9e15e8a.pdf", "_bibtex": "@misc{\nliu2020automatically,\ntitle={Automatically Learning Feature Crossing from Model Interpretation for Tabular Data},\nauthor={Zhaocheng Liu and Qiang Liu and Haoli Zhang},\nyear={2020},\nurl={https://openreview.net/forum?id=Sye2s2VtDr}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "Sye2s2VtDr", "readers": {"values": ["everyone"], "description": "User groups that will be able to read this comment."}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "~.*"}}, "readers": ["everyone"], "tcdate": 1569504213012, "tmdate": 1576860589506, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["everyone"], "noninvitees": ["ICLR.cc/2020/Conference/Paper166/Authors", "ICLR.cc/2020/Conference/Paper166/Reviewers", "ICLR.cc/2020/Conference/Paper166/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper166/-/Public_Comment"}}}], "count": 23}