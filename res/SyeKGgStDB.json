{"notes": [{"id": "SyeKGgStDB", "original": "rygsszxtvS", "number": 2181, "cdate": 1569439760943, "ddate": null, "tcdate": 1569439760943, "tmdate": 1577168267863, "tddate": null, "forum": "SyeKGgStDB", "replyto": null, "invitation": "ICLR.cc/2020/Conference/-/Blind_Submission", "content": {"authorids": ["biao@cs.umd.edu", "jbrandt@adobe.com", "rmech@adobe.com", "nxu@adobe.com", "bmkim@adobe.com", "dm@cs.umd.edu"], "title": "Training a Constrained Natural Media Painting Agent using Reinforcement Learning ", "authors": ["Biao Jia", "Jonathan Brandt", "Radomir Mech", "Ning Xu", "Byungmoon Kim", "Dinesh Manocha"], "pdf": "/pdf/afa890445030c115fa0f638977e7a1915a4355fd.pdf", "TL;DR": "We train a natural media painting agent using environment model. Based on our painting agent, we present a novel approach to train a constrained painting agent that follows the command encoded in the observation.", "abstract": "We present a novel approach to train a natural media painting using reinforcement learning. Given a reference image,  our formulation is based on stroke-based rendering that  imitates human drawing and can be learned from scratch without supervision. Our painting agent computes a sequence of actions that represent the primitive painting strokes. In order to ensure that the generated policy is predictable and controllable, we use a constrained learning method and train the painting agent  using the environment model and follows the commands encoded in an observation. We have applied our approach on many benchmarks and our results demonstrate that our constrained agent can handle different painting media and different constraints in the action space to collaborate with humans or other agents.\n", "keywords": [], "paperhash": "jia|training_a_constrained_natural_media_painting_agent_using_reinforcement_learning", "original_pdf": "/attachment/afa890445030c115fa0f638977e7a1915a4355fd.pdf", "_bibtex": "@misc{\njia2020training,\ntitle={Training a Constrained Natural Media Painting Agent using Reinforcement Learning },\nauthor={Biao Jia and Jonathan Brandt and Radomir Mech and Ning Xu and Byungmoon Kim and Dinesh Manocha},\nyear={2020},\nurl={https://openreview.net/forum?id=SyeKGgStDB}\n}"}, "signatures": ["ICLR.cc/2020/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference"], "details": {"replyCount": 5, "writable": false, "overwriting": [], "revisions": false, "tags": [], "invitation": {"reply": {"readers": {"values-regex": ".*"}, "writers": {"values": ["ICLR.cc/2020/Conference"]}, "signatures": {"values": ["ICLR.cc/2020/Conference"]}, "content": {"spotlight_video": {"value-regex": ".*"}, "full_presentation_video": {"value-regex": ".*"}, "original_pdf": {"required": false, "description": "Upload a PDF file that ends with .pdf", "value-regex": ".*"}, "appendix": {"value-regex": ".*"}, "authorids": {"values-regex": ".*"}, "poster": {"value-regex": ".*"}, "authors": {"values": ["Anonymous"]}, "slides": {"value-regex": ".*"}}}, "final": [], "signatures": ["ICLR.cc/2020/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference"], "noninvitees": [], "tcdate": 1569271260237, "tmdate": 1593459412141, "id": "ICLR.cc/2020/Conference/-/Blind_Submission"}}, "tauthor": "OpenReview.net"}, {"id": "LyXwrtrXM2", "original": null, "number": 1, "cdate": 1576798742575, "ddate": null, "tcdate": 1576798742575, "tmdate": 1576800893653, "tddate": null, "forum": "SyeKGgStDB", "replyto": "SyeKGgStDB", "invitation": "ICLR.cc/2020/Conference/Paper2181/-/Decision", "content": {"decision": "Reject", "comment": "Paper is withdrawn by authors.", "title": "Paper Decision"}, "signatures": ["ICLR.cc/2020/Conference/Program_Chairs"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Program_Chairs"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["biao@cs.umd.edu", "jbrandt@adobe.com", "rmech@adobe.com", "nxu@adobe.com", "bmkim@adobe.com", "dm@cs.umd.edu"], "title": "Training a Constrained Natural Media Painting Agent using Reinforcement Learning ", "authors": ["Biao Jia", "Jonathan Brandt", "Radomir Mech", "Ning Xu", "Byungmoon Kim", "Dinesh Manocha"], "pdf": "/pdf/afa890445030c115fa0f638977e7a1915a4355fd.pdf", "TL;DR": "We train a natural media painting agent using environment model. Based on our painting agent, we present a novel approach to train a constrained painting agent that follows the command encoded in the observation.", "abstract": "We present a novel approach to train a natural media painting using reinforcement learning. Given a reference image,  our formulation is based on stroke-based rendering that  imitates human drawing and can be learned from scratch without supervision. Our painting agent computes a sequence of actions that represent the primitive painting strokes. In order to ensure that the generated policy is predictable and controllable, we use a constrained learning method and train the painting agent  using the environment model and follows the commands encoded in an observation. We have applied our approach on many benchmarks and our results demonstrate that our constrained agent can handle different painting media and different constraints in the action space to collaborate with humans or other agents.\n", "keywords": [], "paperhash": "jia|training_a_constrained_natural_media_painting_agent_using_reinforcement_learning", "original_pdf": "/attachment/afa890445030c115fa0f638977e7a1915a4355fd.pdf", "_bibtex": "@misc{\njia2020training,\ntitle={Training a Constrained Natural Media Painting Agent using Reinforcement Learning },\nauthor={Biao Jia and Jonathan Brandt and Radomir Mech and Ning Xu and Byungmoon Kim and Dinesh Manocha},\nyear={2020},\nurl={https://openreview.net/forum?id=SyeKGgStDB}\n}"}, "tags": [], "invitation": {"reply": {"writers": {"description": "How your identity will be displayed.", "values-regex": ["ICLR.cc/2020/Conference/Program_Chairs"]}, "signatures": {"values": ["ICLR.cc/2020/Conference/Program_Chairs"], "description": "How your identity will be displayed."}, "content": {"decision": {"value-radio": ["Accept (Spotlight)", "Accept (Talk)", "Accept (Poster)", "Reject"], "description": "Decision", "required": true, "order": 2}, "title": {"value": "Paper Decision", "required": true, "order": 1}, "comment": {"value-regex": "[\\S\\s]{0,5000}", "description": "", "required": false, "order": 3}}, "forum": "SyeKGgStDB", "replyto": "SyeKGgStDB", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}}, "expdate": 1576854540000, "duedate": 1576853940000, "multiReply": false, "readers": ["everyone"], "invitees": ["ICLR.cc/2020/Conference/Program_Chairs"], "tcdate": 1576795725355, "tmdate": 1576800277222, "super": "ICLR.cc/2020/Conference/-/Decision", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper2181/-/Decision"}}}, {"id": "rylc8Z7QaB", "original": null, "number": 1, "cdate": 1575330130042, "ddate": null, "tcdate": 1575330130042, "tmdate": 1575330130042, "tddate": null, "forum": "SyeKGgStDB", "replyto": "SyeKGgStDB", "invitation": "ICLR.cc/2020/Conference/Paper2181/-/Withdraw", "content": {"title": "Submission Withdrawn by the Authors", "withdrawal confirmation": "I have read and agree with the venue's withdrawal policy on behalf of myself and my co-authors."}, "signatures": ["ICLR.cc/2020/Conference/Paper2181/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper2181/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["biao@cs.umd.edu", "jbrandt@adobe.com", "rmech@adobe.com", "nxu@adobe.com", "bmkim@adobe.com", "dm@cs.umd.edu"], "title": "Training a Constrained Natural Media Painting Agent using Reinforcement Learning ", "authors": ["Biao Jia", "Jonathan Brandt", "Radomir Mech", "Ning Xu", "Byungmoon Kim", "Dinesh Manocha"], "pdf": "/pdf/afa890445030c115fa0f638977e7a1915a4355fd.pdf", "TL;DR": "We train a natural media painting agent using environment model. Based on our painting agent, we present a novel approach to train a constrained painting agent that follows the command encoded in the observation.", "abstract": "We present a novel approach to train a natural media painting using reinforcement learning. Given a reference image,  our formulation is based on stroke-based rendering that  imitates human drawing and can be learned from scratch without supervision. Our painting agent computes a sequence of actions that represent the primitive painting strokes. In order to ensure that the generated policy is predictable and controllable, we use a constrained learning method and train the painting agent  using the environment model and follows the commands encoded in an observation. We have applied our approach on many benchmarks and our results demonstrate that our constrained agent can handle different painting media and different constraints in the action space to collaborate with humans or other agents.\n", "keywords": [], "paperhash": "jia|training_a_constrained_natural_media_painting_agent_using_reinforcement_learning", "original_pdf": "/attachment/afa890445030c115fa0f638977e7a1915a4355fd.pdf", "_bibtex": "@misc{\njia2020training,\ntitle={Training a Constrained Natural Media Painting Agent using Reinforcement Learning },\nauthor={Biao Jia and Jonathan Brandt and Radomir Mech and Ning Xu and Byungmoon Kim and Dinesh Manocha},\nyear={2020},\nurl={https://openreview.net/forum?id=SyeKGgStDB}\n}"}, "tags": [], "invitation": {"reply": {"forum": "SyeKGgStDB", "replyto": "SyeKGgStDB", "readers": {"description": "User groups that will be able to read this withdraw note.", "values": ["everyone"]}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper2181/Authors"}, "content": {"title": {"order": 1, "value": "Submission Withdrawn by the Authors"}, "withdrawal confirmation": {"order": 2, "description": "Please confirm to withdraw.", "required": true, "value-radio": ["I have read and agree with the venue's withdrawal policy on behalf of myself and my co-authors."]}}}, "cdate": 1569423540000, "expdate": 1576803281000, "duedate": 1576335540000, "multiReply": false, "signatures": ["~Super_User1"], "readers": ["everyone"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper2181/Authors"], "tcdate": 1569529004657, "tmdate": 1576804099379, "id": "ICLR.cc/2020/Conference/Paper2181/-/Withdraw"}}}, {"id": "Byes_E3hYr", "original": null, "number": 1, "cdate": 1571763315236, "ddate": null, "tcdate": 1571763315236, "tmdate": 1572972372528, "tddate": null, "forum": "SyeKGgStDB", "replyto": "SyeKGgStDB", "invitation": "ICLR.cc/2020/Conference/Paper2181/-/Official_Review", "content": {"experience_assessment": "I have read many papers in this area.", "rating": "3: Weak Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #3", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "The authors present the results of training a natural media painting agent using reinforcement learning for different types of strokes. The agent seems to be capable of learning how to pain under different types of constraints and produce visually interesting images.\n\nComments:\n\n- Given that the authors give an implementation of the constrained RL agent as one of the key contributions of the paper, there is a glaring absence of mentioning related work on constrained reinforcement learning and reviewing the existing approaches in literature, in order to compare and contrast what the authors propose in this paper. This makes it hard for the readers to assess the novelty of the contribution.\n\n- Similarly, the authors should discuss in more detail the limitations on the types of constraints that are possible to easily express in this framework, given the simplicity of the constraints that are shown in the experiments\n\n- The readability of the paper seems like it could be improved. Apart from typos, there seem to be many long enumerations of approaches that other researchers have taken in this space, but for a reader it is not immediately obvious how these come together and relate to the work that is being presented.\n\n- With the above in mind, one thing that was conceptually unclear to me is that one of the main advantages of the proposed approach, according to the authors, when compared to some of the cited related work, is that this approach can generate intermediate representations and not just the final output with most resemblance to the reference picture. There is a mention of this opening up new artistic possibilities. Yet, this particular use case is not given central stage in evaluation. The authors should provide more examples of why this particular capability is relevant and how it leads to interesting outcomes.\n\n- The authors say: \u201cwe use 5 strokes to reproduce hand-written digits images, 20 strokes to reproduce character images, 100 strokes to reproduce face and object images\u201d - which does seem reasonable, but the actual numbers (5, 20, 100) are not well motivated. After all, why not (10, 50, 200) or (5, 40, 100) or (5, 40, 200)? It would be good to show experimentally (for one of these) that the choice is justified. I\u2019m not familiar with KanjiVG - but there do exist kanji characters with more than 50 strokes. I\u2019m guessing they are not present in this dataset?\n\n- The authors should provide more details on the specifics of the model architecture and the hyperparameters that have been used / explored.\n\n- In the results/discussion of the paper, the authors should compare to prior work and highlight their novel contributions. Given that multiple papers out there that have had at first glance similar-looking results, it is hard to otherwise qualitatively judge whether what is proposed in this paper is better, without any form of side-by-side comparison.\n"}, "signatures": ["ICLR.cc/2020/Conference/Paper2181/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper2181/AnonReviewer3"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["biao@cs.umd.edu", "jbrandt@adobe.com", "rmech@adobe.com", "nxu@adobe.com", "bmkim@adobe.com", "dm@cs.umd.edu"], "title": "Training a Constrained Natural Media Painting Agent using Reinforcement Learning ", "authors": ["Biao Jia", "Jonathan Brandt", "Radomir Mech", "Ning Xu", "Byungmoon Kim", "Dinesh Manocha"], "pdf": "/pdf/afa890445030c115fa0f638977e7a1915a4355fd.pdf", "TL;DR": "We train a natural media painting agent using environment model. Based on our painting agent, we present a novel approach to train a constrained painting agent that follows the command encoded in the observation.", "abstract": "We present a novel approach to train a natural media painting using reinforcement learning. Given a reference image,  our formulation is based on stroke-based rendering that  imitates human drawing and can be learned from scratch without supervision. Our painting agent computes a sequence of actions that represent the primitive painting strokes. In order to ensure that the generated policy is predictable and controllable, we use a constrained learning method and train the painting agent  using the environment model and follows the commands encoded in an observation. We have applied our approach on many benchmarks and our results demonstrate that our constrained agent can handle different painting media and different constraints in the action space to collaborate with humans or other agents.\n", "keywords": [], "paperhash": "jia|training_a_constrained_natural_media_painting_agent_using_reinforcement_learning", "original_pdf": "/attachment/afa890445030c115fa0f638977e7a1915a4355fd.pdf", "_bibtex": "@misc{\njia2020training,\ntitle={Training a Constrained Natural Media Painting Agent using Reinforcement Learning },\nauthor={Biao Jia and Jonathan Brandt and Radomir Mech and Ning Xu and Byungmoon Kim and Dinesh Manocha},\nyear={2020},\nurl={https://openreview.net/forum?id=SyeKGgStDB}\n}"}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "SyeKGgStDB", "replyto": "SyeKGgStDB", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper2181/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper2181/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1575910709499, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper2181/Reviewers"], "noninvitees": [], "tcdate": 1570237726540, "tmdate": 1575910709511, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper2181/-/Official_Review"}}}, {"id": "Hyl4lLkRKr", "original": null, "number": 2, "cdate": 1571841516145, "ddate": null, "tcdate": 1571841516145, "tmdate": 1572972372481, "tddate": null, "forum": "SyeKGgStDB", "replyto": "SyeKGgStDB", "invitation": "ICLR.cc/2020/Conference/Paper2181/-/Official_Review", "content": {"experience_assessment": "I have published one or two papers in this area.", "rating": "1: Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #2", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "This paper presents a reinforcement learning agent trained to interact with a painting environment in order to reproduce target images. The novel aspect of this work seems to be a version of the agent producing partial actions (i.e., portion of the action tuple is clamped to pre-specified values). This new agent receives the clamped components of the action as an additional conditioning input.\n\nPros:\n+ In some cases, images produced by the system look appealing.\n\nCons:\n- The writing of the manuscript could be significantly improved. I had a hard time understanding certain parts of the paper (e.g., what \u201cconstrained\u201d means in the context of the present work). I got an impression that there was an effort to make things look more complex than they really are.\n- The proposed model lacks novelty \u2013 there seems to be only one non-trivial contribution and I\u2019m not entirely sure how useful it is. The authors never compare their system against a simple baseline when one just overrides the actions of the agent.\n- In general, the evaluation section of the paper leaves a lot to be desired. The authors report some numbers (most of which are not even for the proposed model) but I\u2019m struggling to make anything out of that information. Why should I care about them? What interesting conclusions can I draw from them? The paper never discusses this. On top of that, there are no baselines.\n\nNotes/questions:\n* At test time, the policy receives renders from a real environment. Could that create problems since it has only been trained on images synthesized by a neural surrogate?\n* Abstract: \u201con many benchmarks\u201d -> \u201con several benchmarks\u201d\n* Section 1: \u201cwe use a constraint representation along with \u2026\u201d \u2013 this sentence needs to be rewritten.\n* Section 2: Missing reference \u2013 Neural Painters (Nakano, 19). Considers a neural surrogate of the libmypaint environment.\n* Section 2, last paragraph:  \u201cboth methods can work on either a small action space or a small observation space\u201d \u2013 how is the present model different? The action space is very similar (albeit continuous) to the existing approaches (i.e., relies on Bezier curves much like in (Ganin et al., 18)).\n* Section 2, last paragraph: The last sentence needs to be rewritten (\u201cuncontrollable agent\u201d looks a bit strange)\n* Section 3, first paragraph: \u201cWe highlight all \u2026\u201d -> \u201cWe describe all \u2026\u201d\n* Section 4.1, first paragraph: The first sentence needs to be rewritten (\u201cthe corresponding canvas by the given action\u201d).\n* Section 4.1, first paragraph: \u201cUnlike the previous \u2026\u201d \u2013 not true. (Ganin et al., 18) proposes to use this environment and (Nakano, 19) trains a neural surrogate for it.\n* Section 4.4: \u201cWGAN loss (Huang et al., 19)\u201d \u2013 this WGAN loss was introduced in (Ganin et al., 18).\n* Section 5: I feel like the paper could do a better job at explaining what \u201cconstraining\u201d really means and justifying why it\u2019s an interesting problem to solve. In my opinion, Eq. (3), for example, obscures rather than clarifies the notion of \u201cconstraints\u201d.\n* Section 5, paragraph 2: \u201cFor each different\u201d -> \u201cFor each\u201d\n* Section 5.1, paragraph 4: \u201cpi\u201d -> \u201c\\pi\u201d\n* Figure 5: The caption almost overlaps with the text below.\n* Section 6.3, paragraph 2: \u201cl2\u201d -> \u201cl_2\u201d\n* Section 7, paragraph 2: \u201cdiffering\u201d -> \u201cdifferent\u201d\n\nI feel like the authors should perform a major re-writing of the manuscript before it\u2019s ready for publication. Moreover, I failed to see any significantly novel aspects of the proposed system (maybe due to the poor presentation) and therefore I wouldn\u2019t recommend the paper for acceptance."}, "signatures": ["ICLR.cc/2020/Conference/Paper2181/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper2181/AnonReviewer2"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["biao@cs.umd.edu", "jbrandt@adobe.com", "rmech@adobe.com", "nxu@adobe.com", "bmkim@adobe.com", "dm@cs.umd.edu"], "title": "Training a Constrained Natural Media Painting Agent using Reinforcement Learning ", "authors": ["Biao Jia", "Jonathan Brandt", "Radomir Mech", "Ning Xu", "Byungmoon Kim", "Dinesh Manocha"], "pdf": "/pdf/afa890445030c115fa0f638977e7a1915a4355fd.pdf", "TL;DR": "We train a natural media painting agent using environment model. Based on our painting agent, we present a novel approach to train a constrained painting agent that follows the command encoded in the observation.", "abstract": "We present a novel approach to train a natural media painting using reinforcement learning. Given a reference image,  our formulation is based on stroke-based rendering that  imitates human drawing and can be learned from scratch without supervision. Our painting agent computes a sequence of actions that represent the primitive painting strokes. In order to ensure that the generated policy is predictable and controllable, we use a constrained learning method and train the painting agent  using the environment model and follows the commands encoded in an observation. We have applied our approach on many benchmarks and our results demonstrate that our constrained agent can handle different painting media and different constraints in the action space to collaborate with humans or other agents.\n", "keywords": [], "paperhash": "jia|training_a_constrained_natural_media_painting_agent_using_reinforcement_learning", "original_pdf": "/attachment/afa890445030c115fa0f638977e7a1915a4355fd.pdf", "_bibtex": "@misc{\njia2020training,\ntitle={Training a Constrained Natural Media Painting Agent using Reinforcement Learning },\nauthor={Biao Jia and Jonathan Brandt and Radomir Mech and Ning Xu and Byungmoon Kim and Dinesh Manocha},\nyear={2020},\nurl={https://openreview.net/forum?id=SyeKGgStDB}\n}"}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "SyeKGgStDB", "replyto": "SyeKGgStDB", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper2181/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper2181/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1575910709499, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper2181/Reviewers"], "noninvitees": [], "tcdate": 1570237726540, "tmdate": 1575910709511, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper2181/-/Official_Review"}}}, {"id": "HkehXzoP9H", "original": null, "number": 3, "cdate": 1572479523764, "ddate": null, "tcdate": 1572479523764, "tmdate": 1572972372437, "tddate": null, "forum": "SyeKGgStDB", "replyto": "SyeKGgStDB", "invitation": "ICLR.cc/2020/Conference/Paper2181/-/Official_Review", "content": {"rating": "1: Reject", "experience_assessment": "I have published in this field for several years.", "review_assessment:_checking_correctness_of_derivations_and_theory": "I did not assess the derivations or theory.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #4", "review_assessment:_thoroughness_in_paper_reading": "I made a quick assessment of this paper.", "review": "This paper proposes an RL agent for generating a painting from a photograph by optimizing a sequence of brush strokes to match the target image.\n\nI believe the paper should be rejected because it does not have significant technical novelty for a first-tier conference, and the results do not show much aesthetic or technical advance. In terms of technical novelty, the paper seems to be applying a standard RL agent to an existing problem space, to optimize existing losses. The addition of constraints is technically very simple. The paper itself fails to articulate a compelling statement of novelty, for example, in discussing Huang 2019, the paper just says that a limitation of that method is that it uses OpenCV and that it doesn\u2019t provide a system for control. Removing OpenCV is not a publishable contribution and shouldn\u2019t even be mentioned; the control mechanism is not particularly novel.\n\nSome of the results do look nice, but it\u2019s hard to say that the method has improved over the past 20 years of stroke-based rendering, e.g., many of the results look worse than those in Hertzmann 1998. The paper doesn\u2019t offer any meaningful comparisons to the previous work, such as fair side-by-side comparisons on the same images, comparing computation times and aesthetics. The paper doesn\u2019t articulate any aesthetic goals or state any meaningful standard by which the images might have improved over previous work. The control mechanism is not tested in any meaningful way (e.g., user studies), and the changes it makes to the results seem fairly trivial (e.g., contrast can be added to an image just as well via a post-process).\n\nI\u2019m not sure what ICLR\u2019s policy on citing previous unrefereed work is, but one paper that seems to have much more interesting results in a similar context is: https://arxiv.org/abs/1904.08410 . Reiichiro Nakano, Neural Painters: A learned differentiable constraint for generating brushstroke paintings."}, "signatures": ["ICLR.cc/2020/Conference/Paper2181/AnonReviewer4"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper2181/AnonReviewer4"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["biao@cs.umd.edu", "jbrandt@adobe.com", "rmech@adobe.com", "nxu@adobe.com", "bmkim@adobe.com", "dm@cs.umd.edu"], "title": "Training a Constrained Natural Media Painting Agent using Reinforcement Learning ", "authors": ["Biao Jia", "Jonathan Brandt", "Radomir Mech", "Ning Xu", "Byungmoon Kim", "Dinesh Manocha"], "pdf": "/pdf/afa890445030c115fa0f638977e7a1915a4355fd.pdf", "TL;DR": "We train a natural media painting agent using environment model. Based on our painting agent, we present a novel approach to train a constrained painting agent that follows the command encoded in the observation.", "abstract": "We present a novel approach to train a natural media painting using reinforcement learning. Given a reference image,  our formulation is based on stroke-based rendering that  imitates human drawing and can be learned from scratch without supervision. Our painting agent computes a sequence of actions that represent the primitive painting strokes. In order to ensure that the generated policy is predictable and controllable, we use a constrained learning method and train the painting agent  using the environment model and follows the commands encoded in an observation. We have applied our approach on many benchmarks and our results demonstrate that our constrained agent can handle different painting media and different constraints in the action space to collaborate with humans or other agents.\n", "keywords": [], "paperhash": "jia|training_a_constrained_natural_media_painting_agent_using_reinforcement_learning", "original_pdf": "/attachment/afa890445030c115fa0f638977e7a1915a4355fd.pdf", "_bibtex": "@misc{\njia2020training,\ntitle={Training a Constrained Natural Media Painting Agent using Reinforcement Learning },\nauthor={Biao Jia and Jonathan Brandt and Radomir Mech and Ning Xu and Byungmoon Kim and Dinesh Manocha},\nyear={2020},\nurl={https://openreview.net/forum?id=SyeKGgStDB}\n}"}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "SyeKGgStDB", "replyto": "SyeKGgStDB", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper2181/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper2181/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1575910709499, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper2181/Reviewers"], "noninvitees": [], "tcdate": 1570237726540, "tmdate": 1575910709511, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper2181/-/Official_Review"}}}], "count": 6}