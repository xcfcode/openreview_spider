{"notes": [{"id": "H1glKiCqtm", "original": "rJl_CWc9t7", "number": 412, "cdate": 1538087799770, "ddate": null, "tcdate": 1538087799770, "tmdate": 1545355408476, "tddate": null, "forum": "H1glKiCqtm", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "The Effectiveness of Pre-Trained Code Embeddings", "abstract": "Word embeddings are widely used in machine learning based natural language processing systems. It is common to use pre-trained word embeddings which provide benefits such as reduced training time and improved overall performance. There has been a recent interest in applying natural language processing techniques to programming languages. However, none of this recent work uses pre-trained embeddings on code tokens. Using extreme summarization as the downstream task, we show that using pre-trained embeddings on code tokens provides the same benefits as it does to natural languages, achieving: over 1.9x speedup, 5\\% improvement in test loss, 4\\% improvement in F1 scores, and resistance to over-fitting. We also show that the choice of language used for the embeddings does not have to match that of the task to achieve these benefits and that even embeddings pre-trained on human languages provide these benefits to programming languages.   ", "keywords": ["machine learning", "deep learning", "summarization", "embeddings", "word embeddings", "source code", "programming languages", "programming language processing"], "authorids": ["bbt1@hw.ac.uk", "n.k.taylor@hw.ac.uk", "d.s.reay@hw.ac.uk"], "authors": ["Ben Trevett", "Donald Reay", "N. K. Taylor"], "TL;DR": "Researchers exploring natural language processing techniques applied to source code are not using any form of pre-trained embeddings, we show that they should be.", "pdf": "/pdf/81d477207e4c2ddafbd1919eff239fcbe6cb539d.pdf", "paperhash": "trevett|the_effectiveness_of_pretrained_code_embeddings", "_bibtex": "@misc{\ntrevett2019the,\ntitle={The Effectiveness of Pre-Trained Code Embeddings},\nauthor={Ben Trevett and Donald Reay and N. K. Taylor},\nyear={2019},\nurl={https://openreview.net/forum?id=H1glKiCqtm},\n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"replyCount": 9, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Blind_Submission", "rdate": null, "ddate": null, "expdate": null, "duedate": 1538085600000, "tmdate": 1538142958393, "tddate": null, "super": null, "final": null, "reply": {"signatures": {"values": ["ICLR.cc/2019/Conference"]}, "forum": null, "readers": {"values": ["everyone"]}, "replyto": null, "content": {"authorids": {"values-regex": ".*"}, "authors": {"values": ["Anonymous"]}}, "writers": {"values": ["ICLR.cc/2019/Conference"]}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["~"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": null, "taskCompletionCount": null, "transform": null, "cdate": 1538142958393}}, "tauthor": "OpenReview.net"}, {"id": "rklBp7SkeE", "original": null, "number": 1, "cdate": 1544668093414, "ddate": null, "tcdate": 1544668093414, "tmdate": 1545354505513, "tddate": null, "forum": "H1glKiCqtm", "replyto": "H1glKiCqtm", "invitation": "ICLR.cc/2019/Conference/-/Paper412/Meta_Review", "content": {"metareview": "All three reviewers agree that the research question\u2014should pretrained embeddings be used in code understanding tasks\u2014is a reasonable one. However, there were some early issues with the way in which the paper reported results (involving both metrics and baselines). After some discussion with the reviewers, it seems that the paper now presents a clear picture of the results, but that these results are not sufficiently strong to warrant acceptance. \n\nI'm wary to turn down a paper over what are basically negative results, but for results like this to be useful to the community, they'd have to come from a very thorough experiment, and they'd have to be accompanied by a frank and detailed discussion. Neither of the two more confident authors are convinced that this paper meets that bar.", "confidence": "3: The area chair is somewhat confident", "recommendation": "Reject", "title": "Reasonable experiments, but limited contributions"}, "signatures": ["ICLR.cc/2019/Conference/Paper412/Area_Chair1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference/Paper412/Area_Chair1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "The Effectiveness of Pre-Trained Code Embeddings", "abstract": "Word embeddings are widely used in machine learning based natural language processing systems. It is common to use pre-trained word embeddings which provide benefits such as reduced training time and improved overall performance. There has been a recent interest in applying natural language processing techniques to programming languages. However, none of this recent work uses pre-trained embeddings on code tokens. Using extreme summarization as the downstream task, we show that using pre-trained embeddings on code tokens provides the same benefits as it does to natural languages, achieving: over 1.9x speedup, 5\\% improvement in test loss, 4\\% improvement in F1 scores, and resistance to over-fitting. We also show that the choice of language used for the embeddings does not have to match that of the task to achieve these benefits and that even embeddings pre-trained on human languages provide these benefits to programming languages.   ", "keywords": ["machine learning", "deep learning", "summarization", "embeddings", "word embeddings", "source code", "programming languages", "programming language processing"], "authorids": ["bbt1@hw.ac.uk", "n.k.taylor@hw.ac.uk", "d.s.reay@hw.ac.uk"], "authors": ["Ben Trevett", "Donald Reay", "N. K. Taylor"], "TL;DR": "Researchers exploring natural language processing techniques applied to source code are not using any form of pre-trained embeddings, we show that they should be.", "pdf": "/pdf/81d477207e4c2ddafbd1919eff239fcbe6cb539d.pdf", "paperhash": "trevett|the_effectiveness_of_pretrained_code_embeddings", "_bibtex": "@misc{\ntrevett2019the,\ntitle={The Effectiveness of Pre-Trained Code Embeddings},\nauthor={Ben Trevett and Donald Reay and N. K. Taylor},\nyear={2019},\nurl={https://openreview.net/forum?id=H1glKiCqtm},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper412/Meta_Review", "rdate": null, "ddate": null, "expdate": null, "duedate": 1541548800000, "tmdate": 1545353225395, "tddate": null, "super": null, "final": null, "reply": {"forum": "H1glKiCqtm", "replyto": "H1glKiCqtm", "readers": {"description": "Select all user groups that should be able to read this comment. Selecting 'All Users' will allow paper authors, reviewers, area chairs, and program chairs to view this comment.", "values": ["everyone"]}, "signatures": {"description": "How your identity will be displayed with the above content.", "values-regex": "ICLR.cc/2019/Conference/Paper412/Area_Chair[0-9]+"}, "writers": {"description": "Users that may modify this record.", "values-regex": "ICLR.cc/2019/Conference/Paper412/Area_Chair[0-9]+"}, "content": {"title": {"order": 1, "value-regex": ".{1,500}", "description": "Brief summary of your review.", "required": true}, "metareview": {"order": 2, "value-regex": "[\\S\\s]{1,5000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "required": true}, "recommendation": {"order": 3, "value-dropdown": ["Accept (Oral)", "Accept (Poster)", "Reject"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The area chair is absolutely certain", "4: The area chair is confident but not absolutely certain", "3: The area chair is somewhat confident", "2: The area chair is not sure", "1: The area chair's evaluation is an educated guess"], "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper412/Area_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": false, "taskCompletionCount": null, "transform": null, "cdate": 1545353225395}}}, {"id": "HJxUz-QtAm", "original": null, "number": 9, "cdate": 1543217421899, "ddate": null, "tcdate": 1543217421899, "tmdate": 1543217452932, "tddate": null, "forum": "H1glKiCqtm", "replyto": "ryeueXCIpQ", "invitation": "ICLR.cc/2019/Conference/-/Paper412/Official_Comment", "content": {"title": "Thank you for your additional work", "comment": "Thank you especially for doing such a nice job of supplying additional experiments that show a comparison to pre-trained English embeddings. The results appear to be in keeping with your observations about syntax vs. semantics as well as my expectations. I'm slightly disappointed that they did show that pre-trained code embeddings are not any more effective than pre-trained English embeddings, but it is interesting that with comparable data, some programming languages are providing pre-trained embeddings as useful as those trained on English."}, "signatures": ["ICLR.cc/2019/Conference/Paper412/AnonReviewer1"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper412/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper412/AnonReviewer1", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "The Effectiveness of Pre-Trained Code Embeddings", "abstract": "Word embeddings are widely used in machine learning based natural language processing systems. It is common to use pre-trained word embeddings which provide benefits such as reduced training time and improved overall performance. There has been a recent interest in applying natural language processing techniques to programming languages. However, none of this recent work uses pre-trained embeddings on code tokens. Using extreme summarization as the downstream task, we show that using pre-trained embeddings on code tokens provides the same benefits as it does to natural languages, achieving: over 1.9x speedup, 5\\% improvement in test loss, 4\\% improvement in F1 scores, and resistance to over-fitting. We also show that the choice of language used for the embeddings does not have to match that of the task to achieve these benefits and that even embeddings pre-trained on human languages provide these benefits to programming languages.   ", "keywords": ["machine learning", "deep learning", "summarization", "embeddings", "word embeddings", "source code", "programming languages", "programming language processing"], "authorids": ["bbt1@hw.ac.uk", "n.k.taylor@hw.ac.uk", "d.s.reay@hw.ac.uk"], "authors": ["Ben Trevett", "Donald Reay", "N. K. Taylor"], "TL;DR": "Researchers exploring natural language processing techniques applied to source code are not using any form of pre-trained embeddings, we show that they should be.", "pdf": "/pdf/81d477207e4c2ddafbd1919eff239fcbe6cb539d.pdf", "paperhash": "trevett|the_effectiveness_of_pretrained_code_embeddings", "_bibtex": "@misc{\ntrevett2019the,\ntitle={The Effectiveness of Pre-Trained Code Embeddings},\nauthor={Ben Trevett and Donald Reay and N. K. Taylor},\nyear={2019},\nurl={https://openreview.net/forum?id=H1glKiCqtm},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper412/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621621204, "tddate": null, "super": null, "final": null, "reply": {"forum": "H1glKiCqtm", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper412/Authors", "ICLR.cc/2019/Conference/Paper412/Reviewers", "ICLR.cc/2019/Conference/Paper412/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper412/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper412/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper412/Authors|ICLR.cc/2019/Conference/Paper412/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper412/Reviewers", "ICLR.cc/2019/Conference/Paper412/Authors", "ICLR.cc/2019/Conference/Paper412/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621621204}}}, {"id": "ryeueXCIpQ", "original": null, "number": 4, "cdate": 1542017776025, "ddate": null, "tcdate": 1542017776025, "tmdate": 1542017776025, "tddate": null, "forum": "H1glKiCqtm", "replyto": "rJebNL4c27", "invitation": "ICLR.cc/2019/Conference/-/Paper412/Official_Comment", "content": {"title": "Reviewer 1 response", "comment": "Thank you for the comments and feedback.\n\t\n1. We have added the number of tokens and lines of code within the embedding datasets to section 3.1. We agree with your assumption that more data for pre-training would most likely be beneficial, however we believe this is outside the scope of this work as we have aimed to present an initial exploration into the effectiveness of pre-trained code embeddings. Now we have shown that embeddings do provide several benefits, further work can be done on exploring how best to create these embeddings, e.g. more data, which algorithms to use, etc.\n\t\n2. Thank you for your comment suggesting the use of embeddings pre-trained on natural languages. It encouraged us to explore this, and we have obtained results using embeddings created from the WikiText-103 dataset, using the same AWD-LSTM-LM model. We used this dataset as it is of comparable size to the programming language data. Additionally, we believed that using GloVe (or other) pre-trained embeddings would raise questions of whether the larger amount of data the GloVe embeddings have been trained on is responsible for the results. We have included this within our paper, which now indicates that the natural language (English) embeddings show comparable results to the programming language embeddings, thus reinforcing our view that the semantics are more important than the syntax for this task (see also our response to AnonReviewer2).\n\t\n3. We initially stated that the \"improvement\" metric was in terms of validation loss. This was a mistake and should have said test loss. The paper has been updated to fix this and \"test loss improvement\" has now been explicitly stated throughout.\n\t\n4. We have now updated our paper to include mentions of rank 1 F1 scores throughout the paper and have added a table of F1 scores. We can now see that a 4\\% test loss improvement corresponds to a 5\\% rank 1 F1 improvement."}, "signatures": ["ICLR.cc/2019/Conference/Paper412/Authors"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper412/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper412/Authors", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "The Effectiveness of Pre-Trained Code Embeddings", "abstract": "Word embeddings are widely used in machine learning based natural language processing systems. It is common to use pre-trained word embeddings which provide benefits such as reduced training time and improved overall performance. There has been a recent interest in applying natural language processing techniques to programming languages. However, none of this recent work uses pre-trained embeddings on code tokens. Using extreme summarization as the downstream task, we show that using pre-trained embeddings on code tokens provides the same benefits as it does to natural languages, achieving: over 1.9x speedup, 5\\% improvement in test loss, 4\\% improvement in F1 scores, and resistance to over-fitting. We also show that the choice of language used for the embeddings does not have to match that of the task to achieve these benefits and that even embeddings pre-trained on human languages provide these benefits to programming languages.   ", "keywords": ["machine learning", "deep learning", "summarization", "embeddings", "word embeddings", "source code", "programming languages", "programming language processing"], "authorids": ["bbt1@hw.ac.uk", "n.k.taylor@hw.ac.uk", "d.s.reay@hw.ac.uk"], "authors": ["Ben Trevett", "Donald Reay", "N. K. Taylor"], "TL;DR": "Researchers exploring natural language processing techniques applied to source code are not using any form of pre-trained embeddings, we show that they should be.", "pdf": "/pdf/81d477207e4c2ddafbd1919eff239fcbe6cb539d.pdf", "paperhash": "trevett|the_effectiveness_of_pretrained_code_embeddings", "_bibtex": "@misc{\ntrevett2019the,\ntitle={The Effectiveness of Pre-Trained Code Embeddings},\nauthor={Ben Trevett and Donald Reay and N. K. Taylor},\nyear={2019},\nurl={https://openreview.net/forum?id=H1glKiCqtm},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper412/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621621204, "tddate": null, "super": null, "final": null, "reply": {"forum": "H1glKiCqtm", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper412/Authors", "ICLR.cc/2019/Conference/Paper412/Reviewers", "ICLR.cc/2019/Conference/Paper412/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper412/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper412/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper412/Authors|ICLR.cc/2019/Conference/Paper412/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper412/Reviewers", "ICLR.cc/2019/Conference/Paper412/Authors", "ICLR.cc/2019/Conference/Paper412/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621621204}}}, {"id": "BkxIAGALaX", "original": null, "number": 3, "cdate": 1542017741762, "ddate": null, "tcdate": 1542017741762, "tmdate": 1542017741762, "tddate": null, "forum": "H1glKiCqtm", "replyto": "BJgeZaFq2X", "invitation": "ICLR.cc/2019/Conference/-/Paper412/Official_Comment", "content": {"title": "Reviewer 2 response", "comment": "Thank you for the comments and feedback.\n\t\n1. We have added details about the size of the datasets for the language modeling. More details about the model are available in the papers by Merity et al., which is referenced in our paper.\n\t\n2. You are correct in that speedup refers to the increase in training speed. This is detailed in the results section where we mention how speedup, S, is calculated as the number of epochs taken by the random embeddings to reach its best validation loss, N\\_r, divided by the number of epochs taken by a non-random embedding to reach that same validation loss, N\\_e. \n\t\n3. The downstream task in this experiment is the extreme summarization task. We have clarified this in the abstract \\& introduction.\n\t\n4. The performance improvement is for the test loss (using the parameters achieved from the lowest validation loss). The paper previously incorrectly stated that improvement was calculated via the validation loss and this has now been corrected. We have also added a table of results for the rank 1 F1 scores and made sure to explicitly mention the performance improvements (both for F1 scores and test loss) in the results section.\n\t\n5. We agree that syntactic information is useful and you are correct in that the model is not explicitly fed the syntactic information. However, the model does implicitly use syntactic information as the syntax does exist within the sequence of tokens. Furthermore, as per AnonReviewer1's comments, we have added results obtained from using embeddings trained on a natural language (English), and have shown they achieve comparable results to each of the programming languages used. As all 4 of these embeddings achieve similar results - with the main difference between them being the syntax - we would argue that this supports the view that the syntax is less important - although admittedly still useful - than the semantic information provided by sensible variable names for this task. We do think the usefulness of syntactic information for the extreme summarization task is an interesting area of research and requires further investigation, but we believe it is outside the scope of this work. \n\t\n6. Thank you for spotting the error with RQ6, this has now been corrected. "}, "signatures": ["ICLR.cc/2019/Conference/Paper412/Authors"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper412/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper412/Authors", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "The Effectiveness of Pre-Trained Code Embeddings", "abstract": "Word embeddings are widely used in machine learning based natural language processing systems. It is common to use pre-trained word embeddings which provide benefits such as reduced training time and improved overall performance. There has been a recent interest in applying natural language processing techniques to programming languages. However, none of this recent work uses pre-trained embeddings on code tokens. Using extreme summarization as the downstream task, we show that using pre-trained embeddings on code tokens provides the same benefits as it does to natural languages, achieving: over 1.9x speedup, 5\\% improvement in test loss, 4\\% improvement in F1 scores, and resistance to over-fitting. We also show that the choice of language used for the embeddings does not have to match that of the task to achieve these benefits and that even embeddings pre-trained on human languages provide these benefits to programming languages.   ", "keywords": ["machine learning", "deep learning", "summarization", "embeddings", "word embeddings", "source code", "programming languages", "programming language processing"], "authorids": ["bbt1@hw.ac.uk", "n.k.taylor@hw.ac.uk", "d.s.reay@hw.ac.uk"], "authors": ["Ben Trevett", "Donald Reay", "N. K. Taylor"], "TL;DR": "Researchers exploring natural language processing techniques applied to source code are not using any form of pre-trained embeddings, we show that they should be.", "pdf": "/pdf/81d477207e4c2ddafbd1919eff239fcbe6cb539d.pdf", "paperhash": "trevett|the_effectiveness_of_pretrained_code_embeddings", "_bibtex": "@misc{\ntrevett2019the,\ntitle={The Effectiveness of Pre-Trained Code Embeddings},\nauthor={Ben Trevett and Donald Reay and N. K. Taylor},\nyear={2019},\nurl={https://openreview.net/forum?id=H1glKiCqtm},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper412/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621621204, "tddate": null, "super": null, "final": null, "reply": {"forum": "H1glKiCqtm", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper412/Authors", "ICLR.cc/2019/Conference/Paper412/Reviewers", "ICLR.cc/2019/Conference/Paper412/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper412/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper412/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper412/Authors|ICLR.cc/2019/Conference/Paper412/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper412/Reviewers", "ICLR.cc/2019/Conference/Paper412/Authors", "ICLR.cc/2019/Conference/Paper412/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621621204}}}, {"id": "SkehizCLa7", "original": null, "number": 2, "cdate": 1542017700246, "ddate": null, "tcdate": 1542017700246, "tmdate": 1542017700246, "tddate": null, "forum": "H1glKiCqtm", "replyto": "HJxg8bip37", "invitation": "ICLR.cc/2019/Conference/-/Paper412/Official_Comment", "content": {"title": "Reviewer 3 response", "comment": "Thank you for the comments and feedback.\n\t\n1. To clarify, the working assumptions is that pre-trained embeddings do increase performance. This is mentioned in the abstract - ''which provide benefits such as reduced training time and overall performance\" - and in the fourth paragraph of the introduction, with a reference to (Kim, 2014).\n\t\n2. We have now fixed the reference, thank you for spotting that."}, "signatures": ["ICLR.cc/2019/Conference/Paper412/Authors"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper412/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper412/Authors", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "The Effectiveness of Pre-Trained Code Embeddings", "abstract": "Word embeddings are widely used in machine learning based natural language processing systems. It is common to use pre-trained word embeddings which provide benefits such as reduced training time and improved overall performance. There has been a recent interest in applying natural language processing techniques to programming languages. However, none of this recent work uses pre-trained embeddings on code tokens. Using extreme summarization as the downstream task, we show that using pre-trained embeddings on code tokens provides the same benefits as it does to natural languages, achieving: over 1.9x speedup, 5\\% improvement in test loss, 4\\% improvement in F1 scores, and resistance to over-fitting. We also show that the choice of language used for the embeddings does not have to match that of the task to achieve these benefits and that even embeddings pre-trained on human languages provide these benefits to programming languages.   ", "keywords": ["machine learning", "deep learning", "summarization", "embeddings", "word embeddings", "source code", "programming languages", "programming language processing"], "authorids": ["bbt1@hw.ac.uk", "n.k.taylor@hw.ac.uk", "d.s.reay@hw.ac.uk"], "authors": ["Ben Trevett", "Donald Reay", "N. K. Taylor"], "TL;DR": "Researchers exploring natural language processing techniques applied to source code are not using any form of pre-trained embeddings, we show that they should be.", "pdf": "/pdf/81d477207e4c2ddafbd1919eff239fcbe6cb539d.pdf", "paperhash": "trevett|the_effectiveness_of_pretrained_code_embeddings", "_bibtex": "@misc{\ntrevett2019the,\ntitle={The Effectiveness of Pre-Trained Code Embeddings},\nauthor={Ben Trevett and Donald Reay and N. K. Taylor},\nyear={2019},\nurl={https://openreview.net/forum?id=H1glKiCqtm},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper412/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621621204, "tddate": null, "super": null, "final": null, "reply": {"forum": "H1glKiCqtm", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper412/Authors", "ICLR.cc/2019/Conference/Paper412/Reviewers", "ICLR.cc/2019/Conference/Paper412/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper412/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper412/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper412/Authors|ICLR.cc/2019/Conference/Paper412/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper412/Reviewers", "ICLR.cc/2019/Conference/Paper412/Authors", "ICLR.cc/2019/Conference/Paper412/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621621204}}}, {"id": "HkxhFfRLT7", "original": null, "number": 1, "cdate": 1542017668029, "ddate": null, "tcdate": 1542017668029, "tmdate": 1542017668029, "tddate": null, "forum": "H1glKiCqtm", "replyto": "H1glKiCqtm", "invitation": "ICLR.cc/2019/Conference/-/Paper412/Official_Comment", "content": {"title": "Revisions", "comment": "We would like to thank all reviewers for their thoughtful comments.\n\t\nWe have made the following revisions to the paper:\n\n1. Clarified that extreme summarization is the downstream task\n2. Added results obtained from comparing natural language (English) embeddings to the programming language embeddings\n3. Added information about the size of the embedding data\n4. Added rank 1 F1 score results\n5. Fixed where the improvement metric was incorrectly stated to have been calculated from the validation loss\n6. Fixed a handful of typographical errors\n7. Fixed a reference"}, "signatures": ["ICLR.cc/2019/Conference/Paper412/Authors"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper412/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper412/Authors", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "The Effectiveness of Pre-Trained Code Embeddings", "abstract": "Word embeddings are widely used in machine learning based natural language processing systems. It is common to use pre-trained word embeddings which provide benefits such as reduced training time and improved overall performance. There has been a recent interest in applying natural language processing techniques to programming languages. However, none of this recent work uses pre-trained embeddings on code tokens. Using extreme summarization as the downstream task, we show that using pre-trained embeddings on code tokens provides the same benefits as it does to natural languages, achieving: over 1.9x speedup, 5\\% improvement in test loss, 4\\% improvement in F1 scores, and resistance to over-fitting. We also show that the choice of language used for the embeddings does not have to match that of the task to achieve these benefits and that even embeddings pre-trained on human languages provide these benefits to programming languages.   ", "keywords": ["machine learning", "deep learning", "summarization", "embeddings", "word embeddings", "source code", "programming languages", "programming language processing"], "authorids": ["bbt1@hw.ac.uk", "n.k.taylor@hw.ac.uk", "d.s.reay@hw.ac.uk"], "authors": ["Ben Trevett", "Donald Reay", "N. K. Taylor"], "TL;DR": "Researchers exploring natural language processing techniques applied to source code are not using any form of pre-trained embeddings, we show that they should be.", "pdf": "/pdf/81d477207e4c2ddafbd1919eff239fcbe6cb539d.pdf", "paperhash": "trevett|the_effectiveness_of_pretrained_code_embeddings", "_bibtex": "@misc{\ntrevett2019the,\ntitle={The Effectiveness of Pre-Trained Code Embeddings},\nauthor={Ben Trevett and Donald Reay and N. K. Taylor},\nyear={2019},\nurl={https://openreview.net/forum?id=H1glKiCqtm},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper412/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621621204, "tddate": null, "super": null, "final": null, "reply": {"forum": "H1glKiCqtm", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper412/Authors", "ICLR.cc/2019/Conference/Paper412/Reviewers", "ICLR.cc/2019/Conference/Paper412/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper412/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper412/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper412/Authors|ICLR.cc/2019/Conference/Paper412/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper412/Reviewers", "ICLR.cc/2019/Conference/Paper412/Authors", "ICLR.cc/2019/Conference/Paper412/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621621204}}}, {"id": "HJxg8bip37", "original": null, "number": 3, "cdate": 1541415239590, "ddate": null, "tcdate": 1541415239590, "tmdate": 1541534017481, "tddate": null, "forum": "H1glKiCqtm", "replyto": "H1glKiCqtm", "invitation": "ICLR.cc/2019/Conference/-/Paper412/Official_Review", "content": {"title": "Incremental empirical study", "review": "The paper presents some experiments using pre-trained code embeddings on the task of predicting a method name from the code of method body. The paper is well written and the motivations and the design of empirical study are clear.\n\nThe empirical results of validation loss in Figure 1 is reporting the behaviour of random initialization of embedding. From the plots of 10 projects we may derive a couple of claim: (i) the validation loss of random initialization after 10 epochs may increase and get unstable, (ii) random initialization after 5-10 epochs may reach the same loss as pre-trained embeddings. The working assumption is that pre-trained embedding should speed-up the learning process. The empirical results show that it is not just a matter of reducing the training time but also of performance. The discussion is neglecting to comment this behaviour that looks not compliant with the working assumptions. \n\nMinor comment. The reference [Allamanis et al., 2016] is pointing to arxiv.org despite the fact that the work is published as Proceedings of the 33 rd International Conference on Machine Learning, New York, NY, USA, 2016. JMLR: W&CP volume 48.\n", "rating": "6: Marginally above acceptance threshold", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "signatures": ["ICLR.cc/2019/Conference/Paper412/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "The Effectiveness of Pre-Trained Code Embeddings", "abstract": "Word embeddings are widely used in machine learning based natural language processing systems. It is common to use pre-trained word embeddings which provide benefits such as reduced training time and improved overall performance. There has been a recent interest in applying natural language processing techniques to programming languages. However, none of this recent work uses pre-trained embeddings on code tokens. Using extreme summarization as the downstream task, we show that using pre-trained embeddings on code tokens provides the same benefits as it does to natural languages, achieving: over 1.9x speedup, 5\\% improvement in test loss, 4\\% improvement in F1 scores, and resistance to over-fitting. We also show that the choice of language used for the embeddings does not have to match that of the task to achieve these benefits and that even embeddings pre-trained on human languages provide these benefits to programming languages.   ", "keywords": ["machine learning", "deep learning", "summarization", "embeddings", "word embeddings", "source code", "programming languages", "programming language processing"], "authorids": ["bbt1@hw.ac.uk", "n.k.taylor@hw.ac.uk", "d.s.reay@hw.ac.uk"], "authors": ["Ben Trevett", "Donald Reay", "N. K. Taylor"], "TL;DR": "Researchers exploring natural language processing techniques applied to source code are not using any form of pre-trained embeddings, we show that they should be.", "pdf": "/pdf/81d477207e4c2ddafbd1919eff239fcbe6cb539d.pdf", "paperhash": "trevett|the_effectiveness_of_pretrained_code_embeddings", "_bibtex": "@misc{\ntrevett2019the,\ntitle={The Effectiveness of Pre-Trained Code Embeddings},\nauthor={Ben Trevett and Donald Reay and N. K. Taylor},\nyear={2019},\nurl={https://openreview.net/forum?id=H1glKiCqtm},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper412/Official_Review", "cdate": 1542234467200, "expdate": 1552335264000, "duedate": 1541196000000, "reply": {"forum": "H1glKiCqtm", "replyto": "H1glKiCqtm", "readers": {"description": "The users who will be allowed to read the reply content.", "values": ["everyone"]}, "nonreaders": {"values": []}, "signatures": {"description": "How your identity will be displayed with the above content.", "values-regex": "ICLR.cc/2019/Conference/Paper412/AnonReviewer[0-9]+"}, "writers": {"description": "Users that may modify this record.", "values": ["ICLR.cc/2019/Conference"]}, "content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "required": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}}, "multiReply": false, "tcdate": 1552335718427, "tmdate": 1552335718427, "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "invitees": ["ICLR.cc/2019/Conference/Paper412/Reviewers"], "noninvitees": [], "signatures": ["ICLR.cc/2019/Conference"]}}}, {"id": "BJgeZaFq2X", "original": null, "number": 2, "cdate": 1541213432203, "ddate": null, "tcdate": 1541213432203, "tmdate": 1541534017268, "tddate": null, "forum": "H1glKiCqtm", "replyto": "H1glKiCqtm", "invitation": "ICLR.cc/2019/Conference/-/Paper412/Official_Review", "content": {"title": "Interesting and important research questions, unconvincing results", "review": "This paper sets to understand whether pretraining word embeddings for\nprogramming language code by using NLP-like language models has an\nimpact on extreme code summarization task (i.e., generate/predict the\nname of a function based on its body).\n\nI think the paper asks some important questions, however the execution\nof the research and the results presented are not convincing.\n\nI think the area is relevant and the research questions are worth\npursuing; however the work as it is presented in the paper needs\nimprovement to be accepted for publication.\n\nPros:\n* The study of language models for programming language code\n* Pretraining is performed for 3 different languages (C, Java, Python) - target task is in Python\n\nCons:\n* Strange claims of speedup and performance improvement\n* Inconclusive results\n\nSome suggestions for improvement:\n\n* The section on language models pretraining is very sparse, more\n  details are needed.\n\n* The claims of speedup and improvement are strange. Speedup refers to\n  the training speed, I suppose. The performance of the downstream\n  task is never discussed. Only the validation loss is shown and all\n  the performance \"improvement\" is discussed on these graphs, which I\n  found strange. Also, the graphs have their y-axes starting at\n  non-zero values. I personally prefer graphs that start at zero and\n  if there is a need to \"zoom-in\" find a way to \"zoom-in\" to the part\n  of the graph that is important.\n\n* In general the paper writing and reporting on the experiments sounds\n  ad-hoc and not well thought-out.\n\n* I don't agree with many of the explanations in the paper. For\n  example (page 6), it's not true that the extreme summarization task\n  does not require much of the syntactic information (there are\n  submission at the current ICLR'19 that show exactly the opposite,\n  encoding based on syntactic information is useful). The model\n  studied in the paper does NOT use any syntactic information, it\n  treats the code like a sequence of tokens.\n\n* The last question in Section 6 is not a Yes/No question, the answer\n  is phrased as a Yes/No question.\n\nI encourage the authors to pursue the research questions, however in a\nmore systematic and with better methodology.", "rating": "4: Ok but not good enough - rejection", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["ICLR.cc/2019/Conference/Paper412/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "The Effectiveness of Pre-Trained Code Embeddings", "abstract": "Word embeddings are widely used in machine learning based natural language processing systems. It is common to use pre-trained word embeddings which provide benefits such as reduced training time and improved overall performance. There has been a recent interest in applying natural language processing techniques to programming languages. However, none of this recent work uses pre-trained embeddings on code tokens. Using extreme summarization as the downstream task, we show that using pre-trained embeddings on code tokens provides the same benefits as it does to natural languages, achieving: over 1.9x speedup, 5\\% improvement in test loss, 4\\% improvement in F1 scores, and resistance to over-fitting. We also show that the choice of language used for the embeddings does not have to match that of the task to achieve these benefits and that even embeddings pre-trained on human languages provide these benefits to programming languages.   ", "keywords": ["machine learning", "deep learning", "summarization", "embeddings", "word embeddings", "source code", "programming languages", "programming language processing"], "authorids": ["bbt1@hw.ac.uk", "n.k.taylor@hw.ac.uk", "d.s.reay@hw.ac.uk"], "authors": ["Ben Trevett", "Donald Reay", "N. K. Taylor"], "TL;DR": "Researchers exploring natural language processing techniques applied to source code are not using any form of pre-trained embeddings, we show that they should be.", "pdf": "/pdf/81d477207e4c2ddafbd1919eff239fcbe6cb539d.pdf", "paperhash": "trevett|the_effectiveness_of_pretrained_code_embeddings", "_bibtex": "@misc{\ntrevett2019the,\ntitle={The Effectiveness of Pre-Trained Code Embeddings},\nauthor={Ben Trevett and Donald Reay and N. K. Taylor},\nyear={2019},\nurl={https://openreview.net/forum?id=H1glKiCqtm},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper412/Official_Review", "cdate": 1542234467200, "expdate": 1552335264000, "duedate": 1541196000000, "reply": {"forum": "H1glKiCqtm", "replyto": "H1glKiCqtm", "readers": {"description": "The users who will be allowed to read the reply content.", "values": ["everyone"]}, "nonreaders": {"values": []}, "signatures": {"description": "How your identity will be displayed with the above content.", "values-regex": "ICLR.cc/2019/Conference/Paper412/AnonReviewer[0-9]+"}, "writers": {"description": "Users that may modify this record.", "values": ["ICLR.cc/2019/Conference"]}, "content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "required": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}}, "multiReply": false, "tcdate": 1552335718427, "tmdate": 1552335718427, "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "invitees": ["ICLR.cc/2019/Conference/Paper412/Reviewers"], "noninvitees": [], "signatures": ["ICLR.cc/2019/Conference"]}}}, {"id": "rJebNL4c27", "original": null, "number": 1, "cdate": 1541191208561, "ddate": null, "tcdate": 1541191208561, "tmdate": 1541534017061, "tddate": null, "forum": "H1glKiCqtm", "replyto": "H1glKiCqtm", "invitation": "ICLR.cc/2019/Conference/-/Paper412/Official_Review", "content": {"title": "Are pre-trained code embeddings more effective than pre-trained natural language embeddings?", "review": "THE EFFECTIVENESS OF PRE-TRAINED CODE EMBEDDINGS\n\nSummary:\n\nThis work shows how pre-training word vectors using corpuses of code leads to representations that are more suitable than randomly initialized (and trained) representations for function/method name prediction (here called extreme summarization). This paper applies a standard language model to several collected corpuses of code written in different programming languages in order to pretrain the embeddings. It then uses a standard model for the extreme summarization task that takes pre-trained language model embeddings. This leads to speedups in training, improvements in validation loss, and less overfitting. I worry that these results didn't really need much proving given that we have already seen the exact same methods work with natural languages. It would actually be more surprising if they didn't work for programming languages, which suggests that the real question is whether code embeddings are actually more effective than natural language embeddings for this problem given that the authors show syntax of the code is far less important than the semantics of the words in the vocabulary. It is not clear that embeddings pre-trained with much more data on natural languages wouldn't work just as well.\n\nPros:\n\nThis paper takes the time to clearly explain the effectiveness of pre-training words vectors in a new setting. It is easy to follow and understand thanks to the clear organization and exposition.\n\nSpeedup and validation loss improvements are demonstrated for a variety of programming languages despite the final evaluation being only in Java, which is quite surprising. \n\nThe authors discover that overlap in actual programming language syntax is less important than overlap in semantic representation. \n\nBecause the models are out-of-the-box, it is easy to focus on the actual contributions of this paper related to pre-training.\n\nDoes seem to clearly demonstrate that pre-trained embeddings of some form should be used for this extreme summarization task.\n\n\nCons:\n\nIt is not clear how big the collected corpus is. This is important because the work that this paper cites on pre-trained embeddings (Mikolov et al 2013, Pennington et al 2014, McCann et al 2017, Peters et al 2018) typically use fairly large datasets for pre-training. All of these results might be watered down by insufficient pre-training data for the language model when in fact the results could be much stronger with more data. It would be nice to show the effects of pre-training dataset size as is done in the aforementioned previous works. Without this comparison, it is hard to tell whether the paper sufficiently explores this idea.\n\nThe models are both standard, out-of-the-box models. There is no novelty on the modeling side of this paper.\n\nThe pre-training methods are also not novel. They are methods that have already been shown to work applied in a slightly different setting.\n\nIt is not clear that the setting is actually different enough to require this pre-training. Comparing to randomly initialized embeddings is fine, but I would also like to see a comparison to other pre-trained embeddings like GloVe, GloVe+CoVe, or ELMo (Pennington et al 2014, McCann et al 2017, Peters et al 2018). Since the authors find that it is the semantics of the words that matter more than the syntax of any particular programming language, then perhaps it would actually be better to use pre-trained embeddings that tap into much larger amounts of data. At the very least, it seems it would make sense to perhaps supplement a standard pre-trained embedding with those suggested by the authors since so many of the words in the code must be English words. If this is too farfetch'd, then I would suggest that the authors provide some statistics showing why GloVe, GloVe+CoVe, and ELMo are not appropriate starting points for comparison, but the overlap from the pre-training corpuses is already so low that it seems supplementing with standard pre-trained embeddings should only help.\n\nThe evaluation dataset detailed in Allamanis et al 2016 uses two metrics: an F1 metric and an exact match metric. This paper only compares on validation loss. What's more, it reports everything in relative terms so that the raw improvement is masked until Figure 1 makes it somewhat possible to deduce. The problem here is that we don't know how a 0.0-0.5 raw improvement in validation loss translates to the metrics established for the dataset by Allamanis et al 2016. If those are no longer the standard metrics, the authors should explain how validation loss came to supplant the original metrics proposed by Allamanis et al 2016.\n\nWhat's more, there is no context for how well models typically do on this evaluation task. Without any comparisons it is impossible to tell whether any of the experiments are using models in a reasonable realm of performance on this task.\n\nOverall:\n\nAll these effects have already been shown for pre-trained embeddings in the past, and the experiments involve running standard methods on newly collected datasets. This means there is no novelty in the pre-training method or the extreme summarization method. Little is known about the newly collected datasets, it is not clear how to interpret the relative improvements in validation loss compared to the original metrics of Allamanis et al 2016, and the paper lacks necessary comparisons to othef pre-trained embeddings, so though the overall claim that pre-trained embeddings should be used for this task seems to hold up, it is not clear that this is a complete argument for the method chosen by the authors.", "rating": "5: Marginally below acceptance threshold", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["ICLR.cc/2019/Conference/Paper412/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "The Effectiveness of Pre-Trained Code Embeddings", "abstract": "Word embeddings are widely used in machine learning based natural language processing systems. It is common to use pre-trained word embeddings which provide benefits such as reduced training time and improved overall performance. There has been a recent interest in applying natural language processing techniques to programming languages. However, none of this recent work uses pre-trained embeddings on code tokens. Using extreme summarization as the downstream task, we show that using pre-trained embeddings on code tokens provides the same benefits as it does to natural languages, achieving: over 1.9x speedup, 5\\% improvement in test loss, 4\\% improvement in F1 scores, and resistance to over-fitting. We also show that the choice of language used for the embeddings does not have to match that of the task to achieve these benefits and that even embeddings pre-trained on human languages provide these benefits to programming languages.   ", "keywords": ["machine learning", "deep learning", "summarization", "embeddings", "word embeddings", "source code", "programming languages", "programming language processing"], "authorids": ["bbt1@hw.ac.uk", "n.k.taylor@hw.ac.uk", "d.s.reay@hw.ac.uk"], "authors": ["Ben Trevett", "Donald Reay", "N. K. Taylor"], "TL;DR": "Researchers exploring natural language processing techniques applied to source code are not using any form of pre-trained embeddings, we show that they should be.", "pdf": "/pdf/81d477207e4c2ddafbd1919eff239fcbe6cb539d.pdf", "paperhash": "trevett|the_effectiveness_of_pretrained_code_embeddings", "_bibtex": "@misc{\ntrevett2019the,\ntitle={The Effectiveness of Pre-Trained Code Embeddings},\nauthor={Ben Trevett and Donald Reay and N. K. Taylor},\nyear={2019},\nurl={https://openreview.net/forum?id=H1glKiCqtm},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper412/Official_Review", "cdate": 1542234467200, "expdate": 1552335264000, "duedate": 1541196000000, "reply": {"forum": "H1glKiCqtm", "replyto": "H1glKiCqtm", "readers": {"description": "The users who will be allowed to read the reply content.", "values": ["everyone"]}, "nonreaders": {"values": []}, "signatures": {"description": "How your identity will be displayed with the above content.", "values-regex": "ICLR.cc/2019/Conference/Paper412/AnonReviewer[0-9]+"}, "writers": {"description": "Users that may modify this record.", "values": ["ICLR.cc/2019/Conference"]}, "content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "required": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}}, "multiReply": false, "tcdate": 1552335718427, "tmdate": 1552335718427, "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "invitees": ["ICLR.cc/2019/Conference/Paper412/Reviewers"], "noninvitees": [], "signatures": ["ICLR.cc/2019/Conference"]}}}], "count": 10}