{"notes": [{"tddate": null, "ddate": null, "cdate": null, "original": null, "tmdate": 1490028614769, "tcdate": 1490028614769, "number": 1, "id": "Sk1LdtTsx", "invitation": "ICLR.cc/2017/workshop/-/paper125/acceptance", "forum": "rydQ6CEKl", "replyto": "rydQ6CEKl", "signatures": ["ICLR.cc/2017/pcs"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/pcs"], "content": {"decision": "Reject", "title": "ICLR committee final decision"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "A Note on Deep Variational Models for Unsupervised Clustering", "abstract": "Recently, the Gaussian Mixture Variational Autoencoder (GMVAE) has been introduced to handle unsupervised clustering (Dilokthanakul et al., 2016). However, the existing formulation requires the introduction of the free bits term into the objective function in order to overcome the effects of the uniform prior imposed on the latent categorical variable. By considering our choice of generative and inference models, we propose a simple variation on the GMVAE that performs well empirically without modifying the variational objective function.\n", "pdf": "/pdf/7a0323fa4043f45be40c37101dab65f3cea329bc.pdf", "TL;DR": "We make small changes to the generative and inference models and show huge impact on clustering/classification.", "paperhash": "shu|a_note_on_deep_variational_models_for_unsupervised_clustering", "keywords": ["Deep learning", "Unsupervised Learning"], "conflicts": ["stanford.edu", "mitre.org"], "authors": ["Rui Shu", "James Brofos", "Curtis Langlotz"], "authorids": ["ruishu@stanford.edu", "james@brofos.org", "langlotz@stanford.edu"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "tmdate": 1490028615369, "id": "ICLR.cc/2017/workshop/-/paper125/acceptance", "writers": ["ICLR.cc/2017/workshop"], "signatures": ["ICLR.cc/2017/workshop"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/pcs"], "noninvitees": ["ICLR.cc/2017/pcs"], "reply": {"forum": "rydQ6CEKl", "replyto": "rydQ6CEKl", "writers": {"values-regex": "ICLR.cc/2017/pcs"}, "signatures": {"values-regex": "ICLR.cc/2017/pcs", "description": "Your displayed identity associated with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your decision.", "value": "ICLR committee final decision"}, "decision": {"required": true, "order": 3, "value-radio": ["Accept", "Reject"]}}}, "nonreaders": [], "cdate": 1490028615369}}}, {"tddate": null, "nonreaders": null, "tmdate": 1489208097234, "tcdate": 1489208030678, "number": 2, "id": "BJv1QWbol", "invitation": "ICLR.cc/2017/workshop/-/paper125/official/review", "forum": "rydQ6CEKl", "replyto": "rydQ6CEKl", "signatures": ["ICLR.cc/2017/workshop/paper125/AnonReviewer2"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/workshop/paper125/AnonReviewer2"], "content": {"title": "Review: A Note on Deep Variational Models for Unsupervised Clustering", "rating": "4: Ok but not good enough - rejection", "review": "The authors seek to analyze (deep) discrete latent variable models\nwith variational inference---with specific focus on \"unsupervised\nclustering\". However, the work lacks attribution to related work in\nthis problem, offer a nonstandard baseline, and do not discuss\nscalability concerns of their proposal.\n\nThere is no discussion of any relevant work about (deep) discrete\nlatent variable models for clustering. This makes it difficult to\nunderstand what insights to glean from the paper. For example,\nRanganath et al.  (2015) have applied deep exponential families with\nvariational inference for learning mixed memberships in text\ncorpora. Johnson et al. (2016) have studied Gaussian mixture models\nwith neural networks. There are other works in the area of topic\nmodels and deep learning (e.g., Chien and Lee, 2017)---which get at\neven more complicated (mixed membership) structures than the single\nassignment in Gaussian mixtures. It would be useful to mention, if not\ncompare to, at least one model/inference that has been applied to this\ndomain.\n\nFollowing the above, the authors analyze a flaw in a model no one has\nactually used for unsupervised clustering leveraging neural nets.\nComparing to, e.g., Ranganath et al. (2015), would be more sensible if\nthe aim is to better understand the differences in models. Comparing\nto, e.g., Johnson et al. (2016), would be more sensible if the aim is\nto better understand the differences in inference.\n\nRegarding the algorithm itself, the authors don't mention the scalability\nissues present in the original GMVAE paper\u2014as also described by the\nreviewers (https://openreview.net/forum?id=SJx7Jrtgl&noteId=SJx7Jrtgl).\n\nMinor remarks\n\n+ I would recommend against the use of \"variational models\" in the\n  title. This work analyzes specific extensions of the variational\n  auto-encoder. It is not an interchangeable term with variational\n  models, which are about rich posterior approximations (e.g., Tran et\n  al., 2016).\n\nReferences\n\nChien, Jen-Tzung, and Chao-Hsi Lee. \"Deep Unfolding for Topic Models.\" IEEE Transactions on Pattern Analysis and Machine Intelligence (2017).\n\nJohnson, M. J., Duvenaud, D., Wiltschko, A. B., Datta, S. R., & Adams, R. P. (2016). Composing graphical models with neural networks for structured representations and fast inference. In Neural Information Processing Systems.\n\nRanganath, R., Tang, L., Charlin, L., & Blei, D. M. (2015). Deep Exponential Families. In Artificial Intelligence and Statistics.\n\nTran, D., Ranganath, R., & Blei, D. M. (2016). The Variational Gaussian Process. In International Conference on Learning Representations.", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "A Note on Deep Variational Models for Unsupervised Clustering", "abstract": "Recently, the Gaussian Mixture Variational Autoencoder (GMVAE) has been introduced to handle unsupervised clustering (Dilokthanakul et al., 2016). However, the existing formulation requires the introduction of the free bits term into the objective function in order to overcome the effects of the uniform prior imposed on the latent categorical variable. By considering our choice of generative and inference models, we propose a simple variation on the GMVAE that performs well empirically without modifying the variational objective function.\n", "pdf": "/pdf/7a0323fa4043f45be40c37101dab65f3cea329bc.pdf", "TL;DR": "We make small changes to the generative and inference models and show huge impact on clustering/classification.", "paperhash": "shu|a_note_on_deep_variational_models_for_unsupervised_clustering", "keywords": ["Deep learning", "Unsupervised Learning"], "conflicts": ["stanford.edu", "mitre.org"], "authors": ["Rui Shu", "James Brofos", "Curtis Langlotz"], "authorids": ["ruishu@stanford.edu", "james@brofos.org", "langlotz@stanford.edu"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1489183200000, "tmdate": 1489208031397, "id": "ICLR.cc/2017/workshop/-/paper125/official/review", "writers": ["ICLR.cc/2017/workshop"], "signatures": ["ICLR.cc/2017/workshop"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/workshop/paper125/reviewers"], "noninvitees": ["ICLR.cc/2017/workshop/paper125/AnonReviewer1", "ICLR.cc/2017/workshop/paper125/AnonReviewer2"], "reply": {"forum": "rydQ6CEKl", "replyto": "rydQ6CEKl", "writers": {"values-regex": "ICLR.cc/2017/workshop/paper125/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/workshop/paper125/AnonReviewer[0-9]+"}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "value-regex": "[\\S\\s]{1,5000}"}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1496959200000, "cdate": 1489208031397}}}, {"tddate": null, "tmdate": 1489168849806, "tcdate": 1489168849806, "number": 1, "id": "HJcCFwloe", "invitation": "ICLR.cc/2017/workshop/-/paper125/official/review", "forum": "rydQ6CEKl", "replyto": "rydQ6CEKl", "signatures": ["ICLR.cc/2017/workshop/paper125/AnonReviewer1"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/workshop/paper125/AnonReviewer1"], "content": {"title": "The authors expose an intriguing aspect of the behavior of (GM)VAEs", "rating": "5: Marginally below acceptance threshold", "review": "This paper provides an analysis of different VAE architectures with both Gaussian and categorical latent variables from the perspective of unsupervised clustering.\nThe authors propose a simple modification of the GMVAE model which removes the need of fiddling with the ELBO in order to make the model use the discrete latent variables.\nThe authors demonstrate empirically (on MNIST) that small differences in the model's architecture can have a substantial impact on how the discrete latent variables are used as measured by classification accuracy and conditional entropy.\n\nNovelty\n\nThe contribution of this paper is in noticing that a relatively small change to the architecture of the GMVAE model allows it to more efficiently use the discrete latent variables while retaining a principled loss function.\n\nClarity\n\nThe different architectures explored, the experiment performed on MNIST and the experimental results are clearly explained. \nThe analysis/discussion of model properties lacks some clarity. In particular, the analysis in section 3 offers little insight into the problem.\n\nSignificance\n\nWhile the authors expose an intriguing aspect of the behavior of (GM)VAEs with discrete latent variables, the effect of these properties in semi-supervised learning is only conjectural at this point as no experiments were performed to analyse that.\nMore experiments are needed to assess the relevance of the observations made in this work.\nAlso note that, while having an interesting effect on how the model interacts with the discrete latent variables, the resulting ELBO of the proposed GMVAE is worse than that of M2.\n\nQuality\n\nThe paper is ok overall. The text could be improved by focusing on the experimental results and on less speculative analysis of the model properties.\nThe strength of this paper would substantially improve if the authors had performed semi-supervised classification experiments.", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "A Note on Deep Variational Models for Unsupervised Clustering", "abstract": "Recently, the Gaussian Mixture Variational Autoencoder (GMVAE) has been introduced to handle unsupervised clustering (Dilokthanakul et al., 2016). However, the existing formulation requires the introduction of the free bits term into the objective function in order to overcome the effects of the uniform prior imposed on the latent categorical variable. By considering our choice of generative and inference models, we propose a simple variation on the GMVAE that performs well empirically without modifying the variational objective function.\n", "pdf": "/pdf/7a0323fa4043f45be40c37101dab65f3cea329bc.pdf", "TL;DR": "We make small changes to the generative and inference models and show huge impact on clustering/classification.", "paperhash": "shu|a_note_on_deep_variational_models_for_unsupervised_clustering", "keywords": ["Deep learning", "Unsupervised Learning"], "conflicts": ["stanford.edu", "mitre.org"], "authors": ["Rui Shu", "James Brofos", "Curtis Langlotz"], "authorids": ["ruishu@stanford.edu", "james@brofos.org", "langlotz@stanford.edu"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1489183200000, "tmdate": 1489208031397, "id": "ICLR.cc/2017/workshop/-/paper125/official/review", "writers": ["ICLR.cc/2017/workshop"], "signatures": ["ICLR.cc/2017/workshop"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/workshop/paper125/reviewers"], "noninvitees": ["ICLR.cc/2017/workshop/paper125/AnonReviewer1", "ICLR.cc/2017/workshop/paper125/AnonReviewer2"], "reply": {"forum": "rydQ6CEKl", "replyto": "rydQ6CEKl", "writers": {"values-regex": "ICLR.cc/2017/workshop/paper125/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/workshop/paper125/AnonReviewer[0-9]+"}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "value-regex": "[\\S\\s]{1,5000}"}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1496959200000, "cdate": 1489208031397}}}, {"tddate": null, "replyto": null, "ddate": null, "tmdate": 1487701337878, "tcdate": 1487363359589, "number": 125, "id": "rydQ6CEKl", "invitation": "ICLR.cc/2017/workshop/-/submission", "forum": "rydQ6CEKl", "signatures": ["~Rui_Shu1"], "readers": ["everyone"], "content": {"title": "A Note on Deep Variational Models for Unsupervised Clustering", "abstract": "Recently, the Gaussian Mixture Variational Autoencoder (GMVAE) has been introduced to handle unsupervised clustering (Dilokthanakul et al., 2016). However, the existing formulation requires the introduction of the free bits term into the objective function in order to overcome the effects of the uniform prior imposed on the latent categorical variable. By considering our choice of generative and inference models, we propose a simple variation on the GMVAE that performs well empirically without modifying the variational objective function.\n", "pdf": "/pdf/7a0323fa4043f45be40c37101dab65f3cea329bc.pdf", "TL;DR": "We make small changes to the generative and inference models and show huge impact on clustering/classification.", "paperhash": "shu|a_note_on_deep_variational_models_for_unsupervised_clustering", "keywords": ["Deep learning", "Unsupervised Learning"], "conflicts": ["stanford.edu", "mitre.org"], "authors": ["Rui Shu", "James Brofos", "Curtis Langlotz"], "authorids": ["ruishu@stanford.edu", "james@brofos.org", "langlotz@stanford.edu"]}, "writers": [], "nonreaders": [], "details": {"replyCount": 3, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1487690420000, "tmdate": 1484242559574, "id": "ICLR.cc/2017/workshop/-/submission", "writers": ["ICLR.cc/2017/workshop"], "signatures": ["ICLR.cc/2017/pcs"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": null, "replyto": null, "writers": {"values-regex": "~.*"}, "signatures": {"values-regex": "~.*", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"pdf": {"required": true, "order": 5, "description": "Either upload a PDF file or provide a direct link to your PDF on ArXiv (link must begin with http(s) and end with .pdf)", "value-regex": "upload|(http|https):\\/\\/.+\\.pdf"}, "title": {"required": true, "order": 1, "description": "Title of paper.", "value-regex": ".{1,250}"}, "abstract": {"required": true, "order": 4, "description": "Abstract of paper.", "value-regex": "[\\S\\s]{1,5000}"}, "authors": {"required": true, "order": 2, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of author names, as they appear in the paper."}, "conflicts": {"required": true, "order": 100, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of email domains of people who would have a conflict of interest in reviewing this paper, (e.g., cs.umass.edu;google.com, etc.)."}, "keywords": {"order": 6, "description": "Comma separated list of keywords.", "values-dropdown": ["Theory", "Computer vision", "Speech", "Natural language processing", "Deep learning", "Unsupervised Learning", "Supervised Learning", "Semi-Supervised Learning", "Reinforcement Learning", "Transfer Learning", "Multi-modal learning", "Applications", "Optimization", "Structured prediction", "Games"]}, "TL;DR": {"required": false, "order": 3, "description": "\"Too Long; Didn't Read\": a short sentence describing your paper", "value-regex": "[^\\n]{0,250}"}, "authorids": {"required": true, "order": 3, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of author email addresses, in the same order as above."}}}, "nonreaders": [], "noninvitees": [], "expdate": 1495466420000, "cdate": 1484242559574}}}], "count": 4}