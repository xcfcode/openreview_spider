{"notes": [{"id": "ZqB2GD-Ixn", "original": "Jhm1JuQs2ZN", "number": 343, "cdate": 1601308045894, "ddate": null, "tcdate": 1601308045894, "tmdate": 1614985731791, "tddate": null, "forum": "ZqB2GD-Ixn", "replyto": null, "invitation": "ICLR.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Accounting for Unobserved Confounding in Domain Generalization", "authorids": ["~Alexis_Bellot1", "~Mihaela_van_der_Schaar2"], "authors": ["Alexis Bellot", "Mihaela van der Schaar"], "keywords": ["Causality", "Robust Optimization", "Domain Generalization"], "abstract": "The ability to extrapolate, or generalize, from observed to new related environments is central to any form of reliable machine learning, yet most methods fail when moving beyond i.i.d data. In some cases, the reason lies in a misappreciation of the causal structure that governs the data, and in particular as a consequence of the influence of unobserved confounders that drive changes in observed distributions and distort correlations. In this paper, we argue for defining generalization with respect to a broader class of distribution shifts (defined as arising from interventions in the underlying causal model), including changes in observed, unobserved and target variable distributions. We propose a new robust learning principle that may be paired with any gradient-based learning algorithm. This learning principle has explicit generalization guarantees, and relates robustness with certain invariances in the causal model, clarifying why, in some cases, test performance lags training performance. We demonstrate the empirical performance of our approach on healthcare data from different modalities, including image and speech data.", "pdf": "/pdf/a71069c98bc6b909da9beec1e2af2daa62539042.pdf", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "bellot|accounting_for_unobserved_confounding_in_domain_generalization", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=srRTjYNgq", "_bibtex": "@misc{\nbellot2021accounting,\ntitle={Accounting for Unobserved Confounding in Domain Generalization},\nauthor={Alexis Bellot and Mihaela van der Schaar},\nyear={2021},\nurl={https://openreview.net/forum?id=ZqB2GD-Ixn}\n}"}, "signatures": ["ICLR.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference"], "details": {"replyCount": 10, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"reply": {"readers": {"values-regex": ".*"}, "writers": {"values": ["ICLR.cc/2021/Conference"]}, "signatures": {"values": ["ICLR.cc/2021/Conference"]}, "content": {"authors": {"values": ["Anonymous"]}, "authorids": {"values-regex": ".*"}, "reviewed_version_(pdf)": {"required": false, "description": "Upload a PDF file that ends with .pdf", "value-regex": ".*"}}}, "signatures": ["ICLR.cc/2021/Conference"], "readers": ["everyone"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["~", "OpenReview.net/Support"], "tcdate": 1601308008205, "tmdate": 1614984599368, "id": "ICLR.cc/2021/Conference/-/Blind_Submission"}}, "tauthor": "OpenReview.net"}, {"id": "38xYJdWcURv", "original": null, "number": 1, "cdate": 1610040407643, "ddate": null, "tcdate": 1610040407643, "tmdate": 1610474004539, "tddate": null, "forum": "ZqB2GD-Ixn", "replyto": "ZqB2GD-Ixn", "invitation": "ICLR.cc/2021/Conference/Paper343/-/Decision", "content": {"title": "Final Decision", "decision": "Reject", "comment": "This paper deals with domain generalization with causal modeling. Specifically, it considers a broader class of distribution shifts, arising from the system intervention perspective, and proposes some robust learning principle to achieve domain generalization. The paper is well written and has some interesting ideas. However, as pointed by Reviewers #1 and #4, the exact problem setting should be made more explicit, the theory and algorithm should be more consistent, and some very relevant contributions in the literature should be discussed or compared with. "}, "signatures": ["ICLR.cc/2021/Conference/Program_Chairs"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference/Program_Chairs"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Accounting for Unobserved Confounding in Domain Generalization", "authorids": ["~Alexis_Bellot1", "~Mihaela_van_der_Schaar2"], "authors": ["Alexis Bellot", "Mihaela van der Schaar"], "keywords": ["Causality", "Robust Optimization", "Domain Generalization"], "abstract": "The ability to extrapolate, or generalize, from observed to new related environments is central to any form of reliable machine learning, yet most methods fail when moving beyond i.i.d data. In some cases, the reason lies in a misappreciation of the causal structure that governs the data, and in particular as a consequence of the influence of unobserved confounders that drive changes in observed distributions and distort correlations. In this paper, we argue for defining generalization with respect to a broader class of distribution shifts (defined as arising from interventions in the underlying causal model), including changes in observed, unobserved and target variable distributions. We propose a new robust learning principle that may be paired with any gradient-based learning algorithm. This learning principle has explicit generalization guarantees, and relates robustness with certain invariances in the causal model, clarifying why, in some cases, test performance lags training performance. We demonstrate the empirical performance of our approach on healthcare data from different modalities, including image and speech data.", "pdf": "/pdf/a71069c98bc6b909da9beec1e2af2daa62539042.pdf", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "bellot|accounting_for_unobserved_confounding_in_domain_generalization", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=srRTjYNgq", "_bibtex": "@misc{\nbellot2021accounting,\ntitle={Accounting for Unobserved Confounding in Domain Generalization},\nauthor={Alexis Bellot and Mihaela van der Schaar},\nyear={2021},\nurl={https://openreview.net/forum?id=ZqB2GD-Ixn}\n}"}, "tags": [], "invitation": {"reply": {"forum": "ZqB2GD-Ixn", "replyto": "ZqB2GD-Ixn", "readers": {"values": ["everyone"]}, "writers": {"values": ["ICLR.cc/2021/Conference/Program_Chairs"]}, "signatures": {"values": ["ICLR.cc/2021/Conference/Program_Chairs"]}, "content": {"title": {"value": "Final Decision"}, "decision": {"value-radio": ["Accept (Oral)", "Accept (Spotlight)", "Accept (Poster)", "Reject"]}, "comment": {"value-regex": "[\\S\\s]{0,50000}", "markdown": true}}}, "multiReply": false, "signatures": ["ICLR.cc/2021/Conference"], "readers": ["everyone"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Program_Chairs"], "tcdate": 1610040407629, "tmdate": 1610474004523, "id": "ICLR.cc/2021/Conference/Paper343/-/Decision"}}}, {"id": "KBe24KZKuCr", "original": null, "number": 3, "cdate": 1603989940391, "ddate": null, "tcdate": 1603989940391, "tmdate": 1606751293015, "tddate": null, "forum": "ZqB2GD-Ixn", "replyto": "ZqB2GD-Ixn", "invitation": "ICLR.cc/2021/Conference/Paper343/-/Official_Review", "content": {"title": "Excellent paper with a few clarity issues", "review": "--- Update after discussion ---\n\nAfter looking at the concerns raised by the other reviewers and the author responses, I have the following comments:\n\n1. I think the that authors have more than adequately addressed the concerns raised by reviewer 4. With that said, I agree with reviewer 4 in that the link between theorem 1 and the proposed objective and its approximation is not made sufficiently clear in the text. \n\n2. I whole-heartedly agree with reviewer 1 that a clear and concise list of the assumptions made would improve the paper.\n\nOverall, however, I think the paper should still be accepted and will keep my original rating.\n\n--- Original review ---\n\nOverall, I found this to be an excellent paper. The topic of generalizing to new environments is clearly important and the authors do a good job motivating this problem. I found the paper well written and clear, with many intuitive examples. I found the method compelling and the theory appears correct. The experiments were well designed and convincing. Insofar as I have concerns with the paper, they relate to clearly communicating the specific setting considered by the authors and contrasting their work with others (details below).\n\n--- Comments --- \n\n1. One piece that was unclear to me was why if was necessary to assume that $\\mathbb{F}$ remains fixed. Shifts in $\\mathbb{F}$ are certainly possible in real applications (e.g., consider a change in a treatment policy relating observed lab measurements to observed treatments at a particular hospital). Is this a constraint on the method? That is, if the observed environments contain shifts in $\\mathbb{F}$, would the proposed method fail to produce a model that is robust to those shifts?\n\n2. More generally, I didn't think the assumptions were clearly communicated. I think paragraph 2 of A.3.1 should probably be moved into the main paper.\n\n3. I found the example in the intro a bit unclear. I would try to communicate earlier what you are hoping to show with the example. Additionally, at this point in the paper, it is not really clear what a \"causal solution\" is or how it differs from the proposed solution. \n\n4. I thought the remarks following Equation (5) were very helpful and would recommend adding a similar high-level discussion after Theorem 1. Something like: The first term on the RHS is the expected loss and the second term is zero if the constraints discussed above are satisfied, thus by minimizing the constrained expected loss, we are minimizing an upper bound on the LHS.\n\n5. By the time I got to Equation (6) I found myself wondering why *this* robust objective is better than all the others. This was then addressed, in part, by the last parts of 3.1 and 3.3, but I would consider including a more explicit contrast between these various objectives earlier in the paper. I think something like Section 2 of Kreuger et al. (2020) would help contextualize your contribution a bit better.\n\n6. Links to Equation (9) should be swapped for Equation (1) (e.g., page 1, par 2).\n\n7. I would recommend swapping $\\alpha$ for another symbol since $\\alpha_e$ is also used.", "rating": "9: Top 15% of accepted papers, strong accept", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["ICLR.cc/2021/Conference/Paper343/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper343/AnonReviewer2"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Accounting for Unobserved Confounding in Domain Generalization", "authorids": ["~Alexis_Bellot1", "~Mihaela_van_der_Schaar2"], "authors": ["Alexis Bellot", "Mihaela van der Schaar"], "keywords": ["Causality", "Robust Optimization", "Domain Generalization"], "abstract": "The ability to extrapolate, or generalize, from observed to new related environments is central to any form of reliable machine learning, yet most methods fail when moving beyond i.i.d data. In some cases, the reason lies in a misappreciation of the causal structure that governs the data, and in particular as a consequence of the influence of unobserved confounders that drive changes in observed distributions and distort correlations. In this paper, we argue for defining generalization with respect to a broader class of distribution shifts (defined as arising from interventions in the underlying causal model), including changes in observed, unobserved and target variable distributions. We propose a new robust learning principle that may be paired with any gradient-based learning algorithm. This learning principle has explicit generalization guarantees, and relates robustness with certain invariances in the causal model, clarifying why, in some cases, test performance lags training performance. We demonstrate the empirical performance of our approach on healthcare data from different modalities, including image and speech data.", "pdf": "/pdf/a71069c98bc6b909da9beec1e2af2daa62539042.pdf", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "bellot|accounting_for_unobserved_confounding_in_domain_generalization", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=srRTjYNgq", "_bibtex": "@misc{\nbellot2021accounting,\ntitle={Accounting for Unobserved Confounding in Domain Generalization},\nauthor={Alexis Bellot and Mihaela van der Schaar},\nyear={2021},\nurl={https://openreview.net/forum?id=ZqB2GD-Ixn}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq . ***Please remember to file the Code-of-Ethics report. Once you submitted the review, a link to the report will be visible in the bottom right corner of your review.***", "required": true, "markdown": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}, "forum": "ZqB2GD-Ixn", "replyto": "ZqB2GD-Ixn", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"], "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper343/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1607428800000, "duedate": 1606752000000, "multiReply": false, "readers": ["everyone"], "tcdate": 1602538145257, "tmdate": 1606915774755, "super": "ICLR.cc/2021/Conference/-/Official_Review", "signatures": ["OpenReview.net"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Paper343/Reviewers", "OpenReview.net/Support"], "id": "ICLR.cc/2021/Conference/Paper343/-/Official_Review"}}}, {"id": "jl4khaMy6NZ", "original": null, "number": 4, "cdate": 1604026067538, "ddate": null, "tcdate": 1604026067538, "tmdate": 1606121365224, "tddate": null, "forum": "ZqB2GD-Ixn", "replyto": "ZqB2GD-Ixn", "invitation": "ICLR.cc/2021/Conference/Paper343/-/Official_Review", "content": {"title": "Accounting for Unobserved Confounding in Domain Generalization", "review": "Summary: This paper proposes a new regularizer that can be plugged in gradient-based learning algorithms, which aims at solving the problems induced by unobserved confounders. And the authors provide the upper bound for one specific kind of distributionally robust optimization problem, whose uncertainty set is defined as the affine combinations of training distributions. And based on this the algorithm is proposed to deal with the problem of unobserved confounders. Experiments on three medical datasets validate the effectiveness of the method. \n\nStrengths: \n1.\tThe authors provide the upper bound of a group-DRO-like problem whose uncertainty set is the affine combination of training environments. \n2.\tThe authors provide the moment conditions for each pair of environments under linear settings with unobserved confounders and show that the gradients should not be forced to be zero. \n3.\tThree medical experiments validate the effectiveness of the proposed method. \n\n\nWeaknesses:\nIn spite of the strengths mentioned above, there are a few questions that are confusing. \n1.\tAs for the simulated experiment: What is the purpose of the third figure in Figure 1? It shows that the perfect causal model performs bad under unobserved, while the other three methods performs almost the same. Further, the performance of the proposed DIRM and DRO is quite similar in this setting, which does not account for the effectiveness of the method. Besides, the result of IRM for this experiment is missed. \n2.\tAs for the theoretical analysis: \na)\tFor Theorem 1, the right hand equation uses L_2 norm of a function of beta. I read the prove and I think this norm is defined as an integral which has nothing do with beta any more. Therefore, I wonder what does the regularizer proposed in equation(6) means since beta has already been integrated. \nb)\tFor Theorem 1, the core assumption is \u2018the expected loss function as a function of beta belongs to a Sobolev space\u2019, which is confusing. Could you provide some explanations of this assumption or give some examples of it?\nc)\tTheorem 1 provides an upper bound for one specific kind of DRO problem whose uncertainty set is formulated as an affine combination of training distributions. However, in this article, the authors do not state what is the definition of the invariance here and why solve such DRO problem could achieve the invariance. \n3.\tAs for the proposed objective function:\na)\tAs mentioned above, the L_2 norm is taken over a function of beta, which I think is not the Euclidean norm of the vector. Beta has already been integrated and this regularizer has nothing do with beta. I wonder how to compute this when optimizing?\nb)\tI wonder how this objective function can be optimized efficiently? The first concern is mentioned above as the computation of L_2 norm. The second concern is how to optimize the variance which is non-convex and hard to optimize. Namkoong et al. [1] convert the optimization of a variance-regularized problem to a f-divergence DRO for better optimization, while in this paper the authors take the opposite way. I wonder is there any theoretical guarantee of the optimization of the objective function(6). \n4.\tAs for the experiments:\na)\tThe experimental results on the last two datasets are not convincing enough to validate the effectiveness of the proposed method, since the performance is similar to IRM, which I wonder if it is caused by the problems mentioned above(in 3).\n\n[1] Duchi, J. , & Namkoong, H. . (2016). Variance-based regularization with convex objectives.", "rating": "3: Clear rejection", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}, "signatures": ["ICLR.cc/2021/Conference/Paper343/AnonReviewer4"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper343/AnonReviewer4"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Accounting for Unobserved Confounding in Domain Generalization", "authorids": ["~Alexis_Bellot1", "~Mihaela_van_der_Schaar2"], "authors": ["Alexis Bellot", "Mihaela van der Schaar"], "keywords": ["Causality", "Robust Optimization", "Domain Generalization"], "abstract": "The ability to extrapolate, or generalize, from observed to new related environments is central to any form of reliable machine learning, yet most methods fail when moving beyond i.i.d data. In some cases, the reason lies in a misappreciation of the causal structure that governs the data, and in particular as a consequence of the influence of unobserved confounders that drive changes in observed distributions and distort correlations. In this paper, we argue for defining generalization with respect to a broader class of distribution shifts (defined as arising from interventions in the underlying causal model), including changes in observed, unobserved and target variable distributions. We propose a new robust learning principle that may be paired with any gradient-based learning algorithm. This learning principle has explicit generalization guarantees, and relates robustness with certain invariances in the causal model, clarifying why, in some cases, test performance lags training performance. We demonstrate the empirical performance of our approach on healthcare data from different modalities, including image and speech data.", "pdf": "/pdf/a71069c98bc6b909da9beec1e2af2daa62539042.pdf", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "bellot|accounting_for_unobserved_confounding_in_domain_generalization", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=srRTjYNgq", "_bibtex": "@misc{\nbellot2021accounting,\ntitle={Accounting for Unobserved Confounding in Domain Generalization},\nauthor={Alexis Bellot and Mihaela van der Schaar},\nyear={2021},\nurl={https://openreview.net/forum?id=ZqB2GD-Ixn}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq . ***Please remember to file the Code-of-Ethics report. Once you submitted the review, a link to the report will be visible in the bottom right corner of your review.***", "required": true, "markdown": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}, "forum": "ZqB2GD-Ixn", "replyto": "ZqB2GD-Ixn", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"], "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper343/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1607428800000, "duedate": 1606752000000, "multiReply": false, "readers": ["everyone"], "tcdate": 1602538145257, "tmdate": 1606915774755, "super": "ICLR.cc/2021/Conference/-/Official_Review", "signatures": ["OpenReview.net"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Paper343/Reviewers", "OpenReview.net/Support"], "id": "ICLR.cc/2021/Conference/Paper343/-/Official_Review"}}}, {"id": "fSCn4pJoeO", "original": null, "number": 3, "cdate": 1605286368359, "ddate": null, "tcdate": 1605286368359, "tmdate": 1605694071433, "tddate": null, "forum": "ZqB2GD-Ixn", "replyto": "jl4khaMy6NZ", "invitation": "ICLR.cc/2021/Conference/Paper343/-/Official_Comment", "content": {"title": "Updated response including changes made to the revised manuscript", "comment": "Thank you very much for your comments. Please see below an updated response, highlighting the changes we have made in the revised manuscript to address your concerns and include your suggestions.\n\n**Purpose of the third panel in Figure 1.**\n- The third panel of Figure 1 illustrates that causal solutions, while robust to shifts in the distribution of observed variables, underperform with shifts in unobserved confounders since by definition causal solutions do not capture any of the observed correlation due to these variables. In the presence of unobserved confounders, Figure 1 shows that there is a general trade-off in performance: causal solutions outperform with large shifts on observed variables while correlation-based methods (OLS) outperform with moderate shifts in observed variables and with shifts in unobserved variables. In this context, one interpretation of DIRM is as an interpolation between causal and correlation-based solutions. DRO (using convex combinations of environments) also proposes such an interpolation and can be interpreted as a special case of DIRM for a certain hyperparameter $\\alpha$ (this has been changed to $\\eta$ in the revised manuscript). To show more contrast with DRO we have update Figure 3 in the Appendix to include DRO.\n\n*Changes in the manuscript*: The discussion of Figure 1 has been improved to emphasize two things: 1) Causal and correlation-based solutions are optimal under different perturbation regimes \u2013 no single approach outperforms, and the difference in performance depends on which variables are intervened on in test data. 2) DIRM is designed to interpolate between causal and correlation-based solutions, a fact that is also shown in Figure 3 of the Appendix which includes comparisons with DRO. \n\n**On the regularizer of the objective and implementation.**\n- The variance term controls the regularity of the prediction function and its purpose is to encourage representations $\\phi$ that lead to predictors with similar derivatives in all training environments (as described by Reviewer 2). Most of the optimization thus involves $\\phi$, though $\\beta$ still plays a role in the first term of the objective. The regularizer in practice is approximated by the (squared) vector norm of the derivative, evaluated at the current estimate of $\\beta$ on a batch of training examples of each environment before taking the variance between norms (chosen as a proxy for the maximum deviation between environments because of its smoother gradient vector field).\n- The reason for defining the expected loss function to live in a Sobolev space is to ensure its partial derivatives have well-defined L_2 norms but is not otherwise constraining.\n- As to the question related to invariances, the DRO problem in Theorem 1 does not immediately achieve invariances. This is our interpretation upon seeing the resemblance between the last terms on the RHS of Theorem 1 and the moment conditions discussed in section 2.2. By analogy to causality as a DRO problem (i.e. where the uncertainty set contains arbitrary interventions on observed variables), taking $\\lambda\\rightarrow\\infty$ (which corresponds to uncertainty sets with increasing perturbation magnitude) Theorem 1 shows that causal predictors are intrinsically linked with predictors that achieve some form of invariance between environments. This is discussed in Section 3.2, where we also note that the DRO problem as defined in Theorem 1 is more general than simply a proxy for causality. If the available environments span interventions on unobserved or target variables, then it shows that some form of invariance will be satisfied to arbitrary shifts in those variables. We observe this to hold approximately in Figure 2, albeit with a toy experiment.\n- DIRM is sensitive to initialization and to the choice of hyperparameters \u2013 specifically its optimization schedule. In our experiments, we found best performance by increasing the penalty term weight $\\lambda$ after a fixed number of iterations. Since this choice must be made a priori, this could be a significant limitation for its use in practice, even though reasonable guesses can be made with held-out test sets which lead to good performance. This fact, however, applies to also to most out-of-sample generalization algorithms with tuning parameters, including IRM, REx and others.\n\n*Changes to the manuscript*: This discussion, as well as pseudo-code for DIRM, has been included in Appendix A.3. To further investigate the sensitivity of DIRM (as well as IRM and REx) to the optimization schedule we included also an additional experiment that shows test accuracy as a function of the iteration at which penalty term weight is increased. This can also be found in section A.3.\n"}, "signatures": ["ICLR.cc/2021/Conference/Paper343/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper343/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Accounting for Unobserved Confounding in Domain Generalization", "authorids": ["~Alexis_Bellot1", "~Mihaela_van_der_Schaar2"], "authors": ["Alexis Bellot", "Mihaela van der Schaar"], "keywords": ["Causality", "Robust Optimization", "Domain Generalization"], "abstract": "The ability to extrapolate, or generalize, from observed to new related environments is central to any form of reliable machine learning, yet most methods fail when moving beyond i.i.d data. In some cases, the reason lies in a misappreciation of the causal structure that governs the data, and in particular as a consequence of the influence of unobserved confounders that drive changes in observed distributions and distort correlations. In this paper, we argue for defining generalization with respect to a broader class of distribution shifts (defined as arising from interventions in the underlying causal model), including changes in observed, unobserved and target variable distributions. We propose a new robust learning principle that may be paired with any gradient-based learning algorithm. This learning principle has explicit generalization guarantees, and relates robustness with certain invariances in the causal model, clarifying why, in some cases, test performance lags training performance. We demonstrate the empirical performance of our approach on healthcare data from different modalities, including image and speech data.", "pdf": "/pdf/a71069c98bc6b909da9beec1e2af2daa62539042.pdf", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "bellot|accounting_for_unobserved_confounding_in_domain_generalization", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=srRTjYNgq", "_bibtex": "@misc{\nbellot2021accounting,\ntitle={Accounting for Unobserved Confounding in Domain Generalization},\nauthor={Alexis Bellot and Mihaela van der Schaar},\nyear={2021},\nurl={https://openreview.net/forum?id=ZqB2GD-Ixn}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "ZqB2GD-Ixn", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper343/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper343/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper343/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper343/Authors|ICLR.cc/2021/Conference/Paper343/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper343/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923871997, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper343/-/Official_Comment"}}}, {"id": "jnNgHjXsiyv", "original": null, "number": 5, "cdate": 1605692601964, "ddate": null, "tcdate": 1605692601964, "tmdate": 1605693905879, "tddate": null, "forum": "ZqB2GD-Ixn", "replyto": "KBe24KZKuCr", "invitation": "ICLR.cc/2021/Conference/Paper343/-/Official_Comment", "content": {"title": "Thank you for your comments and many suggestions", "comment": "Thank you very much for your comments and many suggestions. Apologies for the slow reply. Please find below our answers to some of your questions, and the corresponding changes we have made to the revised manuscript.\n\n**Clarifications.**\n- The requirement that $\\mathbb F$ be fixed is not necessary for generalization guarantees. As long as new data distributions can be represented as affine combinations of training distributions, we can expect performance to be as least as good as that observed for the robust objective. It is, however, necessary that $\\mathbb F$ be fixed to interpret the DIRM solution causally. \n\n*Changes to the manuscript*: \n- The observation above has been emphasized before section 3.1 in the revised manuscript. \n- We have also revised our discussion of the introductory example, more clearly communicating the objective of Figure 1 which is two-fold: first, highlighting that generalization performance depends on the nature of the shift occurring in test data and that different methods behave very differently for different shifts. And second, highlighting that DIRM can be understood as interpolating between causal and correlation-based solutions in this example. \n- We have clarified the meaning of each term in Theorem 1. \n- Some of the equations were mislabelled which has been corrected, and $\\alpha$ has been changed for $\\eta$ for clarity.\n- In the revised manuscript, we now refer more explicitly to the Appendix to expand on the assumptions needed for causality in section 2.2. We chose not to expand on this further in the main body of the paper since these assumptions are not necessary for the subsequent results in section 3.\n"}, "signatures": ["ICLR.cc/2021/Conference/Paper343/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper343/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Accounting for Unobserved Confounding in Domain Generalization", "authorids": ["~Alexis_Bellot1", "~Mihaela_van_der_Schaar2"], "authors": ["Alexis Bellot", "Mihaela van der Schaar"], "keywords": ["Causality", "Robust Optimization", "Domain Generalization"], "abstract": "The ability to extrapolate, or generalize, from observed to new related environments is central to any form of reliable machine learning, yet most methods fail when moving beyond i.i.d data. In some cases, the reason lies in a misappreciation of the causal structure that governs the data, and in particular as a consequence of the influence of unobserved confounders that drive changes in observed distributions and distort correlations. In this paper, we argue for defining generalization with respect to a broader class of distribution shifts (defined as arising from interventions in the underlying causal model), including changes in observed, unobserved and target variable distributions. We propose a new robust learning principle that may be paired with any gradient-based learning algorithm. This learning principle has explicit generalization guarantees, and relates robustness with certain invariances in the causal model, clarifying why, in some cases, test performance lags training performance. We demonstrate the empirical performance of our approach on healthcare data from different modalities, including image and speech data.", "pdf": "/pdf/a71069c98bc6b909da9beec1e2af2daa62539042.pdf", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "bellot|accounting_for_unobserved_confounding_in_domain_generalization", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=srRTjYNgq", "_bibtex": "@misc{\nbellot2021accounting,\ntitle={Accounting for Unobserved Confounding in Domain Generalization},\nauthor={Alexis Bellot and Mihaela van der Schaar},\nyear={2021},\nurl={https://openreview.net/forum?id=ZqB2GD-Ixn}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "ZqB2GD-Ixn", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper343/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper343/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper343/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper343/Authors|ICLR.cc/2021/Conference/Paper343/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper343/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923871997, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper343/-/Official_Comment"}}}, {"id": "V4OaNlHuFl3", "original": null, "number": 6, "cdate": 1605693783193, "ddate": null, "tcdate": 1605693783193, "tmdate": 1605693783193, "tddate": null, "forum": "ZqB2GD-Ixn", "replyto": "wYVk6lmaT_h", "invitation": "ICLR.cc/2021/Conference/Paper343/-/Official_Comment", "content": {"title": "Thank you for your comments, and especially for highlighting the missing discussion on the limitations of DIRM", "comment": "Thank you for your comments and for pointing out typos which have been corrected in the revised manuscript. Sorry for the slow reply. Please find below our answer to your questions and details on the corresponding changes we have in the revised manuscript.\n\n- The supremum can be understood as a maximum since our set of distributions is finite, suprema are generally used for these statements because they are well-defined even on infinite sets as long as they are upper-bounded.\n- We have included a paragraph in the conclusion that highlights what performance guarantees can and cannot be expected in practice. Specifically, we must have observed a certain shift between two training environments to be able to extrapolate to arbitrary shifts in that direction. We cannot for instance guarantee prediction performance in \u201cblack swan events\u201d due to a shift that has not been observed before.\n"}, "signatures": ["ICLR.cc/2021/Conference/Paper343/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper343/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Accounting for Unobserved Confounding in Domain Generalization", "authorids": ["~Alexis_Bellot1", "~Mihaela_van_der_Schaar2"], "authors": ["Alexis Bellot", "Mihaela van der Schaar"], "keywords": ["Causality", "Robust Optimization", "Domain Generalization"], "abstract": "The ability to extrapolate, or generalize, from observed to new related environments is central to any form of reliable machine learning, yet most methods fail when moving beyond i.i.d data. In some cases, the reason lies in a misappreciation of the causal structure that governs the data, and in particular as a consequence of the influence of unobserved confounders that drive changes in observed distributions and distort correlations. In this paper, we argue for defining generalization with respect to a broader class of distribution shifts (defined as arising from interventions in the underlying causal model), including changes in observed, unobserved and target variable distributions. We propose a new robust learning principle that may be paired with any gradient-based learning algorithm. This learning principle has explicit generalization guarantees, and relates robustness with certain invariances in the causal model, clarifying why, in some cases, test performance lags training performance. We demonstrate the empirical performance of our approach on healthcare data from different modalities, including image and speech data.", "pdf": "/pdf/a71069c98bc6b909da9beec1e2af2daa62539042.pdf", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "bellot|accounting_for_unobserved_confounding_in_domain_generalization", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=srRTjYNgq", "_bibtex": "@misc{\nbellot2021accounting,\ntitle={Accounting for Unobserved Confounding in Domain Generalization},\nauthor={Alexis Bellot and Mihaela van der Schaar},\nyear={2021},\nurl={https://openreview.net/forum?id=ZqB2GD-Ixn}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "ZqB2GD-Ixn", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper343/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper343/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper343/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper343/Authors|ICLR.cc/2021/Conference/Paper343/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper343/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923871997, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper343/-/Official_Comment"}}}, {"id": "41f7__SbAs", "original": null, "number": 4, "cdate": 1605288514297, "ddate": null, "tcdate": 1605288514297, "tmdate": 1605693521470, "tddate": null, "forum": "ZqB2GD-Ixn", "replyto": "pnH-awcXILV", "invitation": "ICLR.cc/2021/Conference/Paper343/-/Official_Comment", "content": {"title": "Update to the response and details on the changes made in the revised manuscript.", "comment": "Thank you very much for your comments. Please find below a slightly updated review and changes made in the revised manuscript based on your suggestions.\n\n**On assumptions for causality.**\n- The comment of the distribution family of environments relates to causal inference and the moment conditions proposed in section 2.2. The assumptions there parallel those of Invariant Causal Prediction [1] (which also form the basis for IRM) but importantly relaxes that of causal sufficiency, i.e. invariances hold even if not all causes of Y are observed, including confounders (influencing two or more variables). This is a significant change with respect to IRM, the latter explicitly shown to be inadequate in the presence of unobserved confounders (and shown empirically in experiments given in Appendix A.1). Our derivation however does require additive noises and interventions on all observed variables, which we agree is still restrictive.\n- Part of our contribution is to acknowledge this fact (mentioned in the last bullet point of section 2.2) and propose an objective that leverages these invariances to achieve more general robustness guarantees. Specifically, with the objective we propose, even if not all conditions for causality hold, invariances are still useful to regularize prediction algorithms, in the sense that solutions can be expected to be robust to certain shifts in the data distribution.\n\n*Changes to the manuscript*: We have included pseudo-code in Appendix A.3 and described therein more details on our implementation. REx has been implemented with a similar optimization schedule as IRM and DIRM, and our results in the updated Table 1 show performance close to IRM, and competitive but below DIRM for all experiments. Thank you for pointing out the typo which will be corrected in the revised manuscript. Further validation of DIRM on domain generalization benchmark datasets is an important task, but we chose to defer it to future work because these datasets do not highlight bias due to unobserved confounding explicitly which is the characteristic of data we study in this work.\n\n[1] Peters, Jonas, Peter Buhlmann, and Nicolai Meinshausen. \"Causal inference by using invariant prediction: identification and confidence intervals\u201d. Series B Statistical methodology. (2016).\n\n"}, "signatures": ["ICLR.cc/2021/Conference/Paper343/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper343/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Accounting for Unobserved Confounding in Domain Generalization", "authorids": ["~Alexis_Bellot1", "~Mihaela_van_der_Schaar2"], "authors": ["Alexis Bellot", "Mihaela van der Schaar"], "keywords": ["Causality", "Robust Optimization", "Domain Generalization"], "abstract": "The ability to extrapolate, or generalize, from observed to new related environments is central to any form of reliable machine learning, yet most methods fail when moving beyond i.i.d data. In some cases, the reason lies in a misappreciation of the causal structure that governs the data, and in particular as a consequence of the influence of unobserved confounders that drive changes in observed distributions and distort correlations. In this paper, we argue for defining generalization with respect to a broader class of distribution shifts (defined as arising from interventions in the underlying causal model), including changes in observed, unobserved and target variable distributions. We propose a new robust learning principle that may be paired with any gradient-based learning algorithm. This learning principle has explicit generalization guarantees, and relates robustness with certain invariances in the causal model, clarifying why, in some cases, test performance lags training performance. We demonstrate the empirical performance of our approach on healthcare data from different modalities, including image and speech data.", "pdf": "/pdf/a71069c98bc6b909da9beec1e2af2daa62539042.pdf", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "bellot|accounting_for_unobserved_confounding_in_domain_generalization", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=srRTjYNgq", "_bibtex": "@misc{\nbellot2021accounting,\ntitle={Accounting for Unobserved Confounding in Domain Generalization},\nauthor={Alexis Bellot and Mihaela van der Schaar},\nyear={2021},\nurl={https://openreview.net/forum?id=ZqB2GD-Ixn}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "ZqB2GD-Ixn", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper343/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper343/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper343/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper343/Authors|ICLR.cc/2021/Conference/Paper343/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper343/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923871997, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper343/-/Official_Comment"}}}, {"id": "zmTgfegYZ_Z", "original": null, "number": 2, "cdate": 1605112615764, "ddate": null, "tcdate": 1605112615764, "tmdate": 1605112615764, "tddate": null, "forum": "ZqB2GD-Ixn", "replyto": "jl4khaMy6NZ", "invitation": "ICLR.cc/2021/Conference/Paper343/-/Official_Comment", "content": {"title": "RE: the dependence of the regularizer on $\\beta$ (weakness 2a)", "comment": "I understood this as trying to find a representation $\\phi$ such that the optimal predictor given that representation is domain invariant. That is, it is ok that the regularizer does not depend on $\\beta$ since it is attempting to constrain $\\phi$, though I could certainly be wrong in this understanding."}, "signatures": ["ICLR.cc/2021/Conference/Paper343/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper343/AnonReviewer2"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Accounting for Unobserved Confounding in Domain Generalization", "authorids": ["~Alexis_Bellot1", "~Mihaela_van_der_Schaar2"], "authors": ["Alexis Bellot", "Mihaela van der Schaar"], "keywords": ["Causality", "Robust Optimization", "Domain Generalization"], "abstract": "The ability to extrapolate, or generalize, from observed to new related environments is central to any form of reliable machine learning, yet most methods fail when moving beyond i.i.d data. In some cases, the reason lies in a misappreciation of the causal structure that governs the data, and in particular as a consequence of the influence of unobserved confounders that drive changes in observed distributions and distort correlations. In this paper, we argue for defining generalization with respect to a broader class of distribution shifts (defined as arising from interventions in the underlying causal model), including changes in observed, unobserved and target variable distributions. We propose a new robust learning principle that may be paired with any gradient-based learning algorithm. This learning principle has explicit generalization guarantees, and relates robustness with certain invariances in the causal model, clarifying why, in some cases, test performance lags training performance. We demonstrate the empirical performance of our approach on healthcare data from different modalities, including image and speech data.", "pdf": "/pdf/a71069c98bc6b909da9beec1e2af2daa62539042.pdf", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "bellot|accounting_for_unobserved_confounding_in_domain_generalization", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=srRTjYNgq", "_bibtex": "@misc{\nbellot2021accounting,\ntitle={Accounting for Unobserved Confounding in Domain Generalization},\nauthor={Alexis Bellot and Mihaela van der Schaar},\nyear={2021},\nurl={https://openreview.net/forum?id=ZqB2GD-Ixn}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "ZqB2GD-Ixn", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper343/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper343/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper343/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper343/Authors|ICLR.cc/2021/Conference/Paper343/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper343/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923871997, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper343/-/Official_Comment"}}}, {"id": "wYVk6lmaT_h", "original": null, "number": 1, "cdate": 1603797661433, "ddate": null, "tcdate": 1603797661433, "tmdate": 1605024710649, "tddate": null, "forum": "ZqB2GD-Ixn", "replyto": "ZqB2GD-Ixn", "invitation": "ICLR.cc/2021/Conference/Paper343/-/Official_Review", "content": {"title": "A new objective for out-of-sample generalization via causal invariances.", "review": "The authors propose an optimization objective for out-of-sample generalization that aims to exploit statistical structure that emerges from underlying causal mechanisms and is hence transferable across domains. Effectiveness of the approach is demonstrated on several real-world datasets.\nThe problem is thoroughly motivated and relevant literature reviewed. Experiments support the authors claims, although real-world examples seems somewhat contrived.\nThe paper lacks an investigation of where and how the proposed methodology fails. It would have been helpful to provide more intuition around the formal explanations in section 2 and 3.\n\n\n## Detailed Comments\n- \"new or related data\" -> what does \"related data\" mean?\n- \"Doing so is difficult however, some form of uncertainty about the distribution of new data is unavoidable.\" -> Please check grammar\n- (eq1): why are we taking the *supremum* of the expected loss over distributions?\n- \"to problem (9)\" -> I think you mean (1). Prolly the eqs (1) and (9) have the same latex equation label.\n- acronym DRO is not defined in text (only in figure caption)\n\n", "rating": "7: Good paper, accept", "confidence": "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper"}, "signatures": ["ICLR.cc/2021/Conference/Paper343/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper343/AnonReviewer3"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Accounting for Unobserved Confounding in Domain Generalization", "authorids": ["~Alexis_Bellot1", "~Mihaela_van_der_Schaar2"], "authors": ["Alexis Bellot", "Mihaela van der Schaar"], "keywords": ["Causality", "Robust Optimization", "Domain Generalization"], "abstract": "The ability to extrapolate, or generalize, from observed to new related environments is central to any form of reliable machine learning, yet most methods fail when moving beyond i.i.d data. In some cases, the reason lies in a misappreciation of the causal structure that governs the data, and in particular as a consequence of the influence of unobserved confounders that drive changes in observed distributions and distort correlations. In this paper, we argue for defining generalization with respect to a broader class of distribution shifts (defined as arising from interventions in the underlying causal model), including changes in observed, unobserved and target variable distributions. We propose a new robust learning principle that may be paired with any gradient-based learning algorithm. This learning principle has explicit generalization guarantees, and relates robustness with certain invariances in the causal model, clarifying why, in some cases, test performance lags training performance. We demonstrate the empirical performance of our approach on healthcare data from different modalities, including image and speech data.", "pdf": "/pdf/a71069c98bc6b909da9beec1e2af2daa62539042.pdf", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "bellot|accounting_for_unobserved_confounding_in_domain_generalization", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=srRTjYNgq", "_bibtex": "@misc{\nbellot2021accounting,\ntitle={Accounting for Unobserved Confounding in Domain Generalization},\nauthor={Alexis Bellot and Mihaela van der Schaar},\nyear={2021},\nurl={https://openreview.net/forum?id=ZqB2GD-Ixn}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq . ***Please remember to file the Code-of-Ethics report. Once you submitted the review, a link to the report will be visible in the bottom right corner of your review.***", "required": true, "markdown": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}, "forum": "ZqB2GD-Ixn", "replyto": "ZqB2GD-Ixn", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"], "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper343/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1607428800000, "duedate": 1606752000000, "multiReply": false, "readers": ["everyone"], "tcdate": 1602538145257, "tmdate": 1606915774755, "super": "ICLR.cc/2021/Conference/-/Official_Review", "signatures": ["OpenReview.net"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Paper343/Reviewers", "OpenReview.net/Support"], "id": "ICLR.cc/2021/Conference/Paper343/-/Official_Review"}}}, {"id": "pnH-awcXILV", "original": null, "number": 2, "cdate": 1603878287491, "ddate": null, "tcdate": 1603878287491, "tmdate": 1605024710589, "tddate": null, "forum": "ZqB2GD-Ixn", "replyto": "ZqB2GD-Ixn", "invitation": "ICLR.cc/2021/Conference/Paper343/-/Official_Review", "content": {"title": "tackle the unobserved confounding to address cross-domain generalization", "review": "summary:\nThis paper proposes a new domain generalization (DG) method, which enjoys certain statistical invariance property in the presence of unobserved confounders. The method is motivated by causal understanding of the underlying generating distribution and it assumes that the distribution generating the unseen data is obtained by manipulating the distribution of exogenous variables in the causal model.\n\n\npros:\n- this work views the distribution family of training data as generated from manipulating a causal model $M$, which is novel in DG methods and of pracitical significance.\n\n- the idea is well motivated (section 2) and clearly presented (section 3)\n\n- related works are properly mentioned and discussed\n\n\ncons:\n- the considered distribution family seems a bit restrictive as it requires manipulation only on exogeneous variables in additive structural equations.\n\n- the algorithm is not available in both the main text and appendix.\n\n- the proposed DG method is not empirically studied on widely used benchmark data sets. \n\n\ndetailed comments:\n- It seems the method can only handle confounder of two variables with an additive structureal euqation relating them. If that is the case, it would be better to elaborate corresponding requirements in numbered assumptions.\n\n- The derivation of the last inequality in the proof of theorem 1 is not very straightforward. It would be better to elaborate its derivation in the appendix.\n\n- Since the analysis throughout the main text assumes a given $\\phi(x)$ but one has to learn both $f$ and $\\phi$ in practice, it would be better to give the algorithm used in experimental section in the main text.\n\n- Experiments on popular DG data sets (e.g., VLCS) are missing in this work. It would be better to show the performance of the proposed method on benchmark data set. If possible, it would  be great to also consider comparing with REx [1].\n\nminor:\n- typo under Eq. (5), *indeces*\n\n[1] David Krueger, Ethan Caballero, Joern-Henrik Jacobsen, Amy Zhang, Jonathan Binas, Remi Le Priol, and Aaron Courville. Out", "rating": "5: Marginally below acceptance threshold", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["ICLR.cc/2021/Conference/Paper343/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper343/AnonReviewer1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Accounting for Unobserved Confounding in Domain Generalization", "authorids": ["~Alexis_Bellot1", "~Mihaela_van_der_Schaar2"], "authors": ["Alexis Bellot", "Mihaela van der Schaar"], "keywords": ["Causality", "Robust Optimization", "Domain Generalization"], "abstract": "The ability to extrapolate, or generalize, from observed to new related environments is central to any form of reliable machine learning, yet most methods fail when moving beyond i.i.d data. In some cases, the reason lies in a misappreciation of the causal structure that governs the data, and in particular as a consequence of the influence of unobserved confounders that drive changes in observed distributions and distort correlations. In this paper, we argue for defining generalization with respect to a broader class of distribution shifts (defined as arising from interventions in the underlying causal model), including changes in observed, unobserved and target variable distributions. We propose a new robust learning principle that may be paired with any gradient-based learning algorithm. This learning principle has explicit generalization guarantees, and relates robustness with certain invariances in the causal model, clarifying why, in some cases, test performance lags training performance. We demonstrate the empirical performance of our approach on healthcare data from different modalities, including image and speech data.", "pdf": "/pdf/a71069c98bc6b909da9beec1e2af2daa62539042.pdf", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "bellot|accounting_for_unobserved_confounding_in_domain_generalization", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=srRTjYNgq", "_bibtex": "@misc{\nbellot2021accounting,\ntitle={Accounting for Unobserved Confounding in Domain Generalization},\nauthor={Alexis Bellot and Mihaela van der Schaar},\nyear={2021},\nurl={https://openreview.net/forum?id=ZqB2GD-Ixn}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq . ***Please remember to file the Code-of-Ethics report. Once you submitted the review, a link to the report will be visible in the bottom right corner of your review.***", "required": true, "markdown": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}, "forum": "ZqB2GD-Ixn", "replyto": "ZqB2GD-Ixn", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"], "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper343/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1607428800000, "duedate": 1606752000000, "multiReply": false, "readers": ["everyone"], "tcdate": 1602538145257, "tmdate": 1606915774755, "super": "ICLR.cc/2021/Conference/-/Official_Review", "signatures": ["OpenReview.net"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Paper343/Reviewers", "OpenReview.net/Support"], "id": "ICLR.cc/2021/Conference/Paper343/-/Official_Review"}}}], "count": 11}