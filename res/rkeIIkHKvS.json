{"notes": [{"id": "rkeIIkHKvS", "original": "SkgU1P6dwH", "number": 1730, "cdate": 1569439566057, "ddate": null, "tcdate": 1569439566057, "tmdate": 1583912044406, "tddate": null, "forum": "rkeIIkHKvS", "replyto": null, "invitation": "ICLR.cc/2020/Conference/-/Blind_Submission", "content": {"authorids": ["yfhou@cse.cuhk.edu.hk", "jzhang@cse.cuhk.edu.hk", "jcheng@cse.cuhk.edu.hk", "klma@cse.cuhk.edu.hk", "tbma@comp.nus.edu.sg", "hzchen@cse.cuhk.edu.hk", "mcyang@cse.cuhk.edu.hk"], "title": "Measuring and Improving the Use of Graph Information in Graph Neural Networks", "authors": ["Yifan Hou", "Jian Zhang", "James Cheng", "Kaili Ma", "Richard T. B. Ma", "Hongzhi Chen", "Ming-Chang Yang"], "pdf": "/pdf/3ff628aed23920c95386567ad7acc7885d49b122.pdf", "abstract": "Graph neural networks (GNNs) have been widely used for representation learning on graph data. However, there is limited understanding on how much performance GNNs actually gain from graph data. This paper introduces a context-surrounding GNN framework and proposes two smoothness metrics to measure the quantity and quality of information obtained from graph data. A new, improved GNN model, called CS-GNN, is then devised to improve the use of graph information based on the smoothness values of a graph. CS-GNN is shown to achieve better performance than existing methods in different types of real graphs. ", "keywords": [], "paperhash": "hou|measuring_and_improving_the_use_of_graph_information_in_graph_neural_networks", "code": "https://github.com/yifan-h/CS-GNN", "_bibtex": "@inproceedings{\nHou2020Measuring,\ntitle={Measuring and Improving the Use of Graph Information in Graph Neural Networks},\nauthor={Yifan Hou and Jian Zhang and James Cheng and Kaili Ma and Richard T. B. Ma and Hongzhi Chen and Ming-Chang Yang},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=rkeIIkHKvS}\n}", "full_presentation_video": "", "original_pdf": "/attachment/cf368b35da9df17ac5dabfa78e42dfb550d73e50.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "signatures": ["ICLR.cc/2020/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference"], "details": {"replyCount": 9, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"reply": {"readers": {"values-regex": ".*"}, "writers": {"values": ["ICLR.cc/2020/Conference"]}, "signatures": {"values": ["ICLR.cc/2020/Conference"]}, "content": {"spotlight_video": {"value-regex": ".*"}, "full_presentation_video": {"value-regex": ".*"}, "original_pdf": {"required": false, "description": "Upload a PDF file that ends with .pdf", "value-regex": ".*"}, "appendix": {"value-regex": ".*"}, "authorids": {"values-regex": ".*"}, "poster": {"value-regex": ".*"}, "authors": {"values": ["Anonymous"]}, "slides": {"value-regex": ".*"}}}, "final": [], "signatures": ["ICLR.cc/2020/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference"], "noninvitees": [], "tcdate": 1569271260237, "tmdate": 1593459412141, "id": "ICLR.cc/2020/Conference/-/Blind_Submission"}}, "tauthor": "ICLR.cc/2020/Conference"}, {"id": "FFSNqtyup1", "original": null, "number": 1, "cdate": 1576798730992, "ddate": null, "tcdate": 1576798730992, "tmdate": 1576800905488, "tddate": null, "forum": "rkeIIkHKvS", "replyto": "rkeIIkHKvS", "invitation": "ICLR.cc/2020/Conference/Paper1730/-/Decision", "content": {"decision": "Accept (Poster)", "comment": "Two reviewers are positive about this paper while the other reviewer is negative. The low-scoring reviewer did not respond to discussions. I also read the paper and found it interesting. Thus an accept is recommended.", "title": "Paper Decision"}, "signatures": ["ICLR.cc/2020/Conference/Program_Chairs"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Program_Chairs"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["yfhou@cse.cuhk.edu.hk", "jzhang@cse.cuhk.edu.hk", "jcheng@cse.cuhk.edu.hk", "klma@cse.cuhk.edu.hk", "tbma@comp.nus.edu.sg", "hzchen@cse.cuhk.edu.hk", "mcyang@cse.cuhk.edu.hk"], "title": "Measuring and Improving the Use of Graph Information in Graph Neural Networks", "authors": ["Yifan Hou", "Jian Zhang", "James Cheng", "Kaili Ma", "Richard T. B. Ma", "Hongzhi Chen", "Ming-Chang Yang"], "pdf": "/pdf/3ff628aed23920c95386567ad7acc7885d49b122.pdf", "abstract": "Graph neural networks (GNNs) have been widely used for representation learning on graph data. However, there is limited understanding on how much performance GNNs actually gain from graph data. This paper introduces a context-surrounding GNN framework and proposes two smoothness metrics to measure the quantity and quality of information obtained from graph data. A new, improved GNN model, called CS-GNN, is then devised to improve the use of graph information based on the smoothness values of a graph. CS-GNN is shown to achieve better performance than existing methods in different types of real graphs. ", "keywords": [], "paperhash": "hou|measuring_and_improving_the_use_of_graph_information_in_graph_neural_networks", "code": "https://github.com/yifan-h/CS-GNN", "_bibtex": "@inproceedings{\nHou2020Measuring,\ntitle={Measuring and Improving the Use of Graph Information in Graph Neural Networks},\nauthor={Yifan Hou and Jian Zhang and James Cheng and Kaili Ma and Richard T. B. Ma and Hongzhi Chen and Ming-Chang Yang},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=rkeIIkHKvS}\n}", "full_presentation_video": "", "original_pdf": "/attachment/cf368b35da9df17ac5dabfa78e42dfb550d73e50.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "tags": [], "invitation": {"reply": {"writers": {"description": "How your identity will be displayed.", "values-regex": ["ICLR.cc/2020/Conference/Program_Chairs"]}, "signatures": {"values": ["ICLR.cc/2020/Conference/Program_Chairs"], "description": "How your identity will be displayed."}, "content": {"decision": {"value-radio": ["Accept (Spotlight)", "Accept (Talk)", "Accept (Poster)", "Reject"], "description": "Decision", "required": true, "order": 2}, "title": {"value": "Paper Decision", "required": true, "order": 1}, "comment": {"value-regex": "[\\S\\s]{0,5000}", "description": "", "required": false, "order": 3}}, "forum": "rkeIIkHKvS", "replyto": "rkeIIkHKvS", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}}, "expdate": 1576854540000, "duedate": 1576853940000, "multiReply": false, "readers": ["everyone"], "invitees": ["ICLR.cc/2020/Conference/Program_Chairs"], "tcdate": 1576795723154, "tmdate": 1576800274590, "super": "ICLR.cc/2020/Conference/-/Decision", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper1730/-/Decision"}}}, {"id": "BJxsAEBNor", "original": null, "number": 2, "cdate": 1573307603436, "ddate": null, "tcdate": 1573307603436, "tmdate": 1573486500770, "tddate": null, "forum": "rkeIIkHKvS", "replyto": "ryxJ4-ExqH", "invitation": "ICLR.cc/2020/Conference/Paper1730/-/Official_Comment", "content": {"title": "[Part 1] Response to the reviewer's concern on the similarity with GAT", "comment": "Thank you for your comments and the detailed suggestions. We try to address your main concerns below and hopefully this will make the contributions of our paper clearer.\n\nFirst, we would like to discuss your concern that our method is close to GAT.  While our GNN model, i.e., CS-GNN, is also an attention-based method like GAT, we remark that our contributions are not just a new GNN model itself. In addition to CS-GNN, another main contribution of our work is the use of the two smoothness metrics to help researchers understand what and how much graph information can benefit an existing GNN model (not just our model). For example, we found that existing GNNs, e.g., GAT, achieve good performance for graphs with large feature smoothness and small label smoothness. However, they do not perform well for graphs with small feature smoothness or large label smoothness because they fail to obtain sufficient useful information or obtain too much negative information from neighboring nodes. \n\nSuch understanding is very important as until now there is limited knowledge about why and in what situations GNNs can outperform other methods. For example, we show in Table 3 that GAT outperforms MLP in some cases, but GAT has significantly worse results than MLP for processing graphs with small feature smoothness or large label smoothness. Also, label propagation can have similar or even better performance than GNN methods such as GCN and GraphSAGE for processing some graphs. \n\nIn our paper, we used the two smoothness measures to explain the performance of different methods on different graph datasets. And we believe the insights obtained in our study are valuable to researchers, as they can also use the smoothness measures to better understand the performance of different GNNs on different graphs (e.g., designing better models, building benchmarks). As currently there is a lack of metrics to measure the quantity and quality of information a GNN obtains from graph data, our smoothness metrics may also inspire other researchers to develop better measures to gain more comprehensive understanding. \n\nOur second contribution is the CS-GNN model, which improves the use of graph information using the smoothness values. Although CS-GNN is also an attention-based method, there are some key differences between CS-GNN and GAT as we will explain in our response to Suggestion 2 below. In addition, CS-GNN actually achieves quite significant performance improvements over GAT as we will explain in our next response.\n\nWe admit that we did not make our contributions clear in the paper, and this has obscured the primary purpose of the smoothness metrics. We have now stated in the 2nd paragraph of Section 1 the two main contributions of the paper. We hope the reviewer would find this clearer now. Thank you for raising this concern.\n"}, "signatures": ["ICLR.cc/2020/Conference/Paper1730/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1730/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["yfhou@cse.cuhk.edu.hk", "jzhang@cse.cuhk.edu.hk", "jcheng@cse.cuhk.edu.hk", "klma@cse.cuhk.edu.hk", "tbma@comp.nus.edu.sg", "hzchen@cse.cuhk.edu.hk", "mcyang@cse.cuhk.edu.hk"], "title": "Measuring and Improving the Use of Graph Information in Graph Neural Networks", "authors": ["Yifan Hou", "Jian Zhang", "James Cheng", "Kaili Ma", "Richard T. B. Ma", "Hongzhi Chen", "Ming-Chang Yang"], "pdf": "/pdf/3ff628aed23920c95386567ad7acc7885d49b122.pdf", "abstract": "Graph neural networks (GNNs) have been widely used for representation learning on graph data. However, there is limited understanding on how much performance GNNs actually gain from graph data. This paper introduces a context-surrounding GNN framework and proposes two smoothness metrics to measure the quantity and quality of information obtained from graph data. A new, improved GNN model, called CS-GNN, is then devised to improve the use of graph information based on the smoothness values of a graph. CS-GNN is shown to achieve better performance than existing methods in different types of real graphs. ", "keywords": [], "paperhash": "hou|measuring_and_improving_the_use_of_graph_information_in_graph_neural_networks", "code": "https://github.com/yifan-h/CS-GNN", "_bibtex": "@inproceedings{\nHou2020Measuring,\ntitle={Measuring and Improving the Use of Graph Information in Graph Neural Networks},\nauthor={Yifan Hou and Jian Zhang and James Cheng and Kaili Ma and Richard T. B. Ma and Hongzhi Chen and Ming-Chang Yang},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=rkeIIkHKvS}\n}", "full_presentation_video": "", "original_pdf": "/attachment/cf368b35da9df17ac5dabfa78e42dfb550d73e50.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "rkeIIkHKvS", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper1730/Authors", "ICLR.cc/2020/Conference/Paper1730/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper1730/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper1730/Reviewers", "ICLR.cc/2020/Conference/Paper1730/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper1730/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper1730/Authors|ICLR.cc/2020/Conference/Paper1730/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504151720, "tmdate": 1576860554059, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper1730/Authors", "ICLR.cc/2020/Conference/Paper1730/Reviewers", "ICLR.cc/2020/Conference/Paper1730/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper1730/-/Official_Comment"}}}, {"id": "r1x6NrBEsH", "original": null, "number": 3, "cdate": 1573307701428, "ddate": null, "tcdate": 1573307701428, "tmdate": 1573486483382, "tddate": null, "forum": "rkeIIkHKvS", "replyto": "ryxJ4-ExqH", "invitation": "ICLR.cc/2020/Conference/Paper1730/-/Official_Comment", "content": {"title": "[Part 2] Response to the reviewer's concern on the marginal performance improvements", "comment": "Next, we would like to address your concern that our experimental results show marginal improvement over existing GNN methods. Actually we believe the improvements made by CS-GNN is quite significant, but maybe the numbers are buried in the table as we squeezed many things in Table 2, which has now been divided into 3 tables. CS-GNN outperforms GAT by 9.65% and 17.14% on the PubMed and BGP graphs. CS-GNN outperforms GraphSAGE by 8.98%, 9.15% and 6.32% on the Citeseer, Cora and BGP graphs. CS-GNN outperforms GCN by 6.23%, 12.78%, 11.45% and 26.26% on the Citeseer, Cora, PubMed and BGP graphs. Although in some other cases the performance may seem to be marginal, there is still improvement in every case and we would like to remark that such marginal improvements are actually considered \u201cacceptable\u201d in related work. For example, Velickovic et al. (2018) reported that GAT improves over GCN only for 2.26%, 1.97% and 0.00% on Citeseer, Cora and PubMed. But this is understandable as it is very challenging for a method to outperform other methods by a large margin in every case. Thus, while some of our improvements may be marginal, we would like to highlight that there are actually quite a number of other cases that CS-GNN does obtain significant improvements over existing methods. We understand these numbers could have been buried in the big table in the previous version, and we hope that by breaking the table into three smaller tables, the results are clearer now. \n\n"}, "signatures": ["ICLR.cc/2020/Conference/Paper1730/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1730/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["yfhou@cse.cuhk.edu.hk", "jzhang@cse.cuhk.edu.hk", "jcheng@cse.cuhk.edu.hk", "klma@cse.cuhk.edu.hk", "tbma@comp.nus.edu.sg", "hzchen@cse.cuhk.edu.hk", "mcyang@cse.cuhk.edu.hk"], "title": "Measuring and Improving the Use of Graph Information in Graph Neural Networks", "authors": ["Yifan Hou", "Jian Zhang", "James Cheng", "Kaili Ma", "Richard T. B. Ma", "Hongzhi Chen", "Ming-Chang Yang"], "pdf": "/pdf/3ff628aed23920c95386567ad7acc7885d49b122.pdf", "abstract": "Graph neural networks (GNNs) have been widely used for representation learning on graph data. However, there is limited understanding on how much performance GNNs actually gain from graph data. This paper introduces a context-surrounding GNN framework and proposes two smoothness metrics to measure the quantity and quality of information obtained from graph data. A new, improved GNN model, called CS-GNN, is then devised to improve the use of graph information based on the smoothness values of a graph. CS-GNN is shown to achieve better performance than existing methods in different types of real graphs. ", "keywords": [], "paperhash": "hou|measuring_and_improving_the_use_of_graph_information_in_graph_neural_networks", "code": "https://github.com/yifan-h/CS-GNN", "_bibtex": "@inproceedings{\nHou2020Measuring,\ntitle={Measuring and Improving the Use of Graph Information in Graph Neural Networks},\nauthor={Yifan Hou and Jian Zhang and James Cheng and Kaili Ma and Richard T. B. Ma and Hongzhi Chen and Ming-Chang Yang},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=rkeIIkHKvS}\n}", "full_presentation_video": "", "original_pdf": "/attachment/cf368b35da9df17ac5dabfa78e42dfb550d73e50.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "rkeIIkHKvS", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper1730/Authors", "ICLR.cc/2020/Conference/Paper1730/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper1730/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper1730/Reviewers", "ICLR.cc/2020/Conference/Paper1730/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper1730/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper1730/Authors|ICLR.cc/2020/Conference/Paper1730/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504151720, "tmdate": 1576860554059, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper1730/Authors", "ICLR.cc/2020/Conference/Paper1730/Reviewers", "ICLR.cc/2020/Conference/Paper1730/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper1730/-/Official_Comment"}}}, {"id": "B1lwIIHVjr", "original": null, "number": 4, "cdate": 1573307983264, "ddate": null, "tcdate": 1573307983264, "tmdate": 1573486463802, "tddate": null, "forum": "rkeIIkHKvS", "replyto": "ryxJ4-ExqH", "invitation": "ICLR.cc/2020/Conference/Paper1730/-/Official_Comment", "content": {"title": "[Part 3] Responses to the reviewer's three suggestions", "comment": "Response to Suggestion 1: Thank you for your suggestion. We believe one of the main problems is that we did not clearly highlight our two main contributions, and thus the first contribution, i.e., the smoothness metrics are proposed primarily to understand how the use of graph information may (or may not) benefit GNNs (as detailed in our response to the first concern above), was not clear to readers. To address your concern, we have revised our paper to clearly state the purposes of proposing the smoothness metrics, which should have strengthened the motivation for the smoothness metrics. \n\nIn addition, we have also added another comparison result, CS-GNN (no topology), so that the difference between CS-GNN (no topology) and GAT is mainly in the use of the smoothness metrics in CS-GNN\u2019s attention mechanism. The results reported in Table 3 show that CS-GNN (no topology) still achieves significant improvements over GAT on the PubMed and BGP graphs. The improvements are mainly because the use of smoothness enables CS-GNN to increase the gain of positive information and reduce negative noisy information from these two graphs. \n\n\n\nResponse to Suggestion 2: Thank you for your suggestion. We did not include CS-GNN in Table 1 because Section 2.1 only introduces the background and we do not find it easy to include CS-GNN there without introducing some details of our method first, and thus this may make readers even more confused. Instead, we now list the key differences between CS-GNN and GAT clearly in Section 3.3 of the revised paper. First, the attention mechanism of CS-GNN is similar to the multiplicative attention mechanism, while GAT is similar to the additive attention mechanism. Compared with the traditional multiplicative attention mechanism, we introduced two weight matrices instead of one to compute the attention coefficients. Second, we consider the smoothness metrics in our attention mechanism, which is unique in CS-GNN and leads to significant performance improvements over existing GNNs (e.g., GAT) for processing graphs such as PubMed and BGP. Third, we also include the use of nodes\u2019 local topology features in computing the attention coefficients to further improve the performance. (Remark: if the reviewer does not think the last point is significant enough, we may consider to remove it. Please also see our response to Suggestion 3 below.)\n\n\n\nResponse to Suggestion 3: We have conducted experiments on CS-GNN without using local topology features (LTF), denoted as CS-GNN (w/o LTF). The results are presented in Table 3 in the revised paper, which shows that using LTF does improve the performance of CS-GNN, but not significantly. However, the results do reveal the effectiveness of the smoothness metrics in CS-GNN, because the difference between CS-GNN (w/o LTF) and GAT is mainly in the use of the smoothness metrics in CS-GNN\u2019s attention mechanism. As shown in Table 3, CS-GNN (w/o LTF) still achieves significant improvements over GAT on the PubMed and BGP graphs. \n\nWe also found that the use of LTF in other GNNs also only leads to marginal performance improvement, e.g., using LTF in GCN even has worse performance in a few cases. If the reviewer does not feel the improvements obtained using LTF very significant, we would consider not to put the use of side information as a subsection in Section 3.2, but only briefly discuss it at the end of Section 3.1. Thank you for suggesting the ablation experiments that helped us see the effects of LTF!\n"}, "signatures": ["ICLR.cc/2020/Conference/Paper1730/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1730/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["yfhou@cse.cuhk.edu.hk", "jzhang@cse.cuhk.edu.hk", "jcheng@cse.cuhk.edu.hk", "klma@cse.cuhk.edu.hk", "tbma@comp.nus.edu.sg", "hzchen@cse.cuhk.edu.hk", "mcyang@cse.cuhk.edu.hk"], "title": "Measuring and Improving the Use of Graph Information in Graph Neural Networks", "authors": ["Yifan Hou", "Jian Zhang", "James Cheng", "Kaili Ma", "Richard T. B. Ma", "Hongzhi Chen", "Ming-Chang Yang"], "pdf": "/pdf/3ff628aed23920c95386567ad7acc7885d49b122.pdf", "abstract": "Graph neural networks (GNNs) have been widely used for representation learning on graph data. However, there is limited understanding on how much performance GNNs actually gain from graph data. This paper introduces a context-surrounding GNN framework and proposes two smoothness metrics to measure the quantity and quality of information obtained from graph data. A new, improved GNN model, called CS-GNN, is then devised to improve the use of graph information based on the smoothness values of a graph. CS-GNN is shown to achieve better performance than existing methods in different types of real graphs. ", "keywords": [], "paperhash": "hou|measuring_and_improving_the_use_of_graph_information_in_graph_neural_networks", "code": "https://github.com/yifan-h/CS-GNN", "_bibtex": "@inproceedings{\nHou2020Measuring,\ntitle={Measuring and Improving the Use of Graph Information in Graph Neural Networks},\nauthor={Yifan Hou and Jian Zhang and James Cheng and Kaili Ma and Richard T. B. Ma and Hongzhi Chen and Ming-Chang Yang},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=rkeIIkHKvS}\n}", "full_presentation_video": "", "original_pdf": "/attachment/cf368b35da9df17ac5dabfa78e42dfb550d73e50.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "rkeIIkHKvS", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper1730/Authors", "ICLR.cc/2020/Conference/Paper1730/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper1730/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper1730/Reviewers", "ICLR.cc/2020/Conference/Paper1730/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper1730/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper1730/Authors|ICLR.cc/2020/Conference/Paper1730/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504151720, "tmdate": 1576860554059, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper1730/Authors", "ICLR.cc/2020/Conference/Paper1730/Reviewers", "ICLR.cc/2020/Conference/Paper1730/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper1730/-/Official_Comment"}}}, {"id": "B1eu28SVsB", "original": null, "number": 5, "cdate": 1573308080078, "ddate": null, "tcdate": 1573308080078, "tmdate": 1573308080078, "tddate": null, "forum": "rkeIIkHKvS", "replyto": "SJlJQTncFH", "invitation": "ICLR.cc/2020/Conference/Paper1730/-/Official_Comment", "content": {"title": "Reporting Lambda f and Lambda l values in the main paper", "comment": "Thank you for your positive feedbacks and the suggestion. We have now included a separate table (Table 2) in the main paper to report and discuss Lambda f and Lambda l values of the datasets. Indeed, this should make the analysis in Section 4.2 easier to follow as the two smoothness metrics are one of our key contributions to measure and understand the use of graph information in GNNs. \n\n"}, "signatures": ["ICLR.cc/2020/Conference/Paper1730/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1730/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["yfhou@cse.cuhk.edu.hk", "jzhang@cse.cuhk.edu.hk", "jcheng@cse.cuhk.edu.hk", "klma@cse.cuhk.edu.hk", "tbma@comp.nus.edu.sg", "hzchen@cse.cuhk.edu.hk", "mcyang@cse.cuhk.edu.hk"], "title": "Measuring and Improving the Use of Graph Information in Graph Neural Networks", "authors": ["Yifan Hou", "Jian Zhang", "James Cheng", "Kaili Ma", "Richard T. B. Ma", "Hongzhi Chen", "Ming-Chang Yang"], "pdf": "/pdf/3ff628aed23920c95386567ad7acc7885d49b122.pdf", "abstract": "Graph neural networks (GNNs) have been widely used for representation learning on graph data. However, there is limited understanding on how much performance GNNs actually gain from graph data. This paper introduces a context-surrounding GNN framework and proposes two smoothness metrics to measure the quantity and quality of information obtained from graph data. A new, improved GNN model, called CS-GNN, is then devised to improve the use of graph information based on the smoothness values of a graph. CS-GNN is shown to achieve better performance than existing methods in different types of real graphs. ", "keywords": [], "paperhash": "hou|measuring_and_improving_the_use_of_graph_information_in_graph_neural_networks", "code": "https://github.com/yifan-h/CS-GNN", "_bibtex": "@inproceedings{\nHou2020Measuring,\ntitle={Measuring and Improving the Use of Graph Information in Graph Neural Networks},\nauthor={Yifan Hou and Jian Zhang and James Cheng and Kaili Ma and Richard T. B. Ma and Hongzhi Chen and Ming-Chang Yang},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=rkeIIkHKvS}\n}", "full_presentation_video": "", "original_pdf": "/attachment/cf368b35da9df17ac5dabfa78e42dfb550d73e50.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "rkeIIkHKvS", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper1730/Authors", "ICLR.cc/2020/Conference/Paper1730/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper1730/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper1730/Reviewers", "ICLR.cc/2020/Conference/Paper1730/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper1730/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper1730/Authors|ICLR.cc/2020/Conference/Paper1730/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504151720, "tmdate": 1576860554059, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper1730/Authors", "ICLR.cc/2020/Conference/Paper1730/Reviewers", "ICLR.cc/2020/Conference/Paper1730/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper1730/-/Official_Comment"}}}, {"id": "ryl-NEH4jS", "original": null, "number": 1, "cdate": 1573307433283, "ddate": null, "tcdate": 1573307433283, "tmdate": 1573307433283, "tddate": null, "forum": "rkeIIkHKvS", "replyto": "H1ep9tkO9H", "invitation": "ICLR.cc/2020/Conference/Paper1730/-/Official_Comment", "content": {"title": "Revisions according to the reviewer's suggestions", "comment": "Thank you for your positive feedbacks and all your suggestions. We have made the following changes to our paper according to your suggestions:\n\n1. Rephrased all long sentences in the paper.\n\n2. Re-organized some subsections and tables. We separated Section 2.2 into two subsections and changed the title of Section 2.2. But we didn\u2019t move paragraph 3 of Section 2.1 to Section 3.3 because paragraph 3 only discusses the background of existing GNNs listed in Table 1. Instead, we rewrote Section 3.3 to mainly discuss the key differences between existing GNNs and CS-GNN. \n\n3. Added a new section in Appendix G to discuss the differences between the KLD and mutual information (also see our answer to your question below).\n\n\nAnswers to other questions are given as follows.\n\nQ1: Is there a particular reason for using the KLD instead of mutual information?\n\nA1: We use the KLD instead of MI because of the following reason. In an information diagram, mutual information I(X; Y) can be seen as the overlap of two correlated variables X and Y, which is a symmetric measure. In contrast, KLD(X||Y) can be seen as the extra part brought by X to Y, which is a measure of the non-symmetric difference between two probability distributions. Considering the node classification task, the information contributed by neighbors and the information contributed to neighbors are different (i.e., non-symmetric). Thus, we use the KLD instead of MI.\n\nWe remark that, although some existing GNN works [1, 2] use MI in their models, their purposes are different from our work. MI can be written as I(X, Y) = D_{KL}(P(X,Y)||P(X) \\times P(Y)), where P(X,Y) is the joint distribution of X and Y, and P(X), P(Y) are marginal distributions of X and Y. From this perspective, we can explain the mutual information of X and Y as the information loss when the joint distribution is used to approximate the marginal distributions. However, this is not our purpose in node classification.\n\nWe included the above discussion in Appendix G of the revised paper as some readers may be interested to know.\n\nQ2: In 2nd sentence of section 2.2, what does \u201cnode\u2019s own information\u201d mean? If it is the individual node\u2019s features then why it naturally the representation vector h_v (which is aggregated with neighboring nodes?)\n\nA2: The \u201cnode\u2019s own information\u201d here refers to the node\u2019s information before the aggregation with neighboring nodes takes place. That is, here h_v = h_v^{(0)} = x_v, i.e., the initial value of h_v or the feature vector x_v of v. To avoid confusion, we have modified the sentence as: We consider the context c_v of a node v as the node\u2019s own information, which is initialized as the feature vector x_v of v. \n\nThank you again for your suggestions, which have helped make the paper flow clearer and highlight our contributions.\n\n[1] Petar Velickovic, William Fedus, William L. Hamilton, Pietro Li{\\`{o}}, Yoshua Bengio and R. Devon Hjelm. Deep Graph Infomax. In ICLR 2019.\n\n[2] Anonymous Authors. Utilizing Edge Features in Graph Neural Networks via Variational Information Maximization. Submitted to ICLR 2020.\n"}, "signatures": ["ICLR.cc/2020/Conference/Paper1730/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1730/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["yfhou@cse.cuhk.edu.hk", "jzhang@cse.cuhk.edu.hk", "jcheng@cse.cuhk.edu.hk", "klma@cse.cuhk.edu.hk", "tbma@comp.nus.edu.sg", "hzchen@cse.cuhk.edu.hk", "mcyang@cse.cuhk.edu.hk"], "title": "Measuring and Improving the Use of Graph Information in Graph Neural Networks", "authors": ["Yifan Hou", "Jian Zhang", "James Cheng", "Kaili Ma", "Richard T. B. Ma", "Hongzhi Chen", "Ming-Chang Yang"], "pdf": "/pdf/3ff628aed23920c95386567ad7acc7885d49b122.pdf", "abstract": "Graph neural networks (GNNs) have been widely used for representation learning on graph data. However, there is limited understanding on how much performance GNNs actually gain from graph data. This paper introduces a context-surrounding GNN framework and proposes two smoothness metrics to measure the quantity and quality of information obtained from graph data. A new, improved GNN model, called CS-GNN, is then devised to improve the use of graph information based on the smoothness values of a graph. CS-GNN is shown to achieve better performance than existing methods in different types of real graphs. ", "keywords": [], "paperhash": "hou|measuring_and_improving_the_use_of_graph_information_in_graph_neural_networks", "code": "https://github.com/yifan-h/CS-GNN", "_bibtex": "@inproceedings{\nHou2020Measuring,\ntitle={Measuring and Improving the Use of Graph Information in Graph Neural Networks},\nauthor={Yifan Hou and Jian Zhang and James Cheng and Kaili Ma and Richard T. B. Ma and Hongzhi Chen and Ming-Chang Yang},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=rkeIIkHKvS}\n}", "full_presentation_video": "", "original_pdf": "/attachment/cf368b35da9df17ac5dabfa78e42dfb550d73e50.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "rkeIIkHKvS", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper1730/Authors", "ICLR.cc/2020/Conference/Paper1730/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper1730/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper1730/Reviewers", "ICLR.cc/2020/Conference/Paper1730/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper1730/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper1730/Authors|ICLR.cc/2020/Conference/Paper1730/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504151720, "tmdate": 1576860554059, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper1730/Authors", "ICLR.cc/2020/Conference/Paper1730/Reviewers", "ICLR.cc/2020/Conference/Paper1730/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper1730/-/Official_Comment"}}}, {"id": "SJlJQTncFH", "original": null, "number": 1, "cdate": 1571634454545, "ddate": null, "tcdate": 1571634454545, "tmdate": 1572972430930, "tddate": null, "forum": "rkeIIkHKvS", "replyto": "rkeIIkHKvS", "invitation": "ICLR.cc/2020/Conference/Paper1730/-/Official_Review", "content": {"rating": "8: Accept", "experience_assessment": "I have read many papers in this area.", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #3", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review": "The authors study how neighbor information on graphs can be used in Graph Neural Networks. It proposes measures on whether the data in neighboring nodes are useful in terms of labels or features. It also provides a new Graph Neural Network algorithm that is a modification of attention-based models incorporating the derived label and feature smoothness measures. The paper demonstrates the usefulness of these measures and algorithms with several different baselines from different families. The writing is mostly smooth, and the authors seem to provide enough detail of the experiments performed.\n\nThe proposed measures look simple but effective (as demonstrated in Table 2). The paper compares different techniques and shows that when neighboring labels are not smooth, techniques such as label propagation does not help. I do recommend Table 4 Lambda f and Lambda l values to be included in the main paper (though text mentions). When incorporated into the attention-based GNNs, Figure 1 also shows that smoothness parameters of the techniques also improve. "}, "signatures": ["ICLR.cc/2020/Conference/Paper1730/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1730/AnonReviewer3"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["yfhou@cse.cuhk.edu.hk", "jzhang@cse.cuhk.edu.hk", "jcheng@cse.cuhk.edu.hk", "klma@cse.cuhk.edu.hk", "tbma@comp.nus.edu.sg", "hzchen@cse.cuhk.edu.hk", "mcyang@cse.cuhk.edu.hk"], "title": "Measuring and Improving the Use of Graph Information in Graph Neural Networks", "authors": ["Yifan Hou", "Jian Zhang", "James Cheng", "Kaili Ma", "Richard T. B. Ma", "Hongzhi Chen", "Ming-Chang Yang"], "pdf": "/pdf/3ff628aed23920c95386567ad7acc7885d49b122.pdf", "abstract": "Graph neural networks (GNNs) have been widely used for representation learning on graph data. However, there is limited understanding on how much performance GNNs actually gain from graph data. This paper introduces a context-surrounding GNN framework and proposes two smoothness metrics to measure the quantity and quality of information obtained from graph data. A new, improved GNN model, called CS-GNN, is then devised to improve the use of graph information based on the smoothness values of a graph. CS-GNN is shown to achieve better performance than existing methods in different types of real graphs. ", "keywords": [], "paperhash": "hou|measuring_and_improving_the_use_of_graph_information_in_graph_neural_networks", "code": "https://github.com/yifan-h/CS-GNN", "_bibtex": "@inproceedings{\nHou2020Measuring,\ntitle={Measuring and Improving the Use of Graph Information in Graph Neural Networks},\nauthor={Yifan Hou and Jian Zhang and James Cheng and Kaili Ma and Richard T. B. Ma and Hongzhi Chen and Ming-Chang Yang},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=rkeIIkHKvS}\n}", "full_presentation_video": "", "original_pdf": "/attachment/cf368b35da9df17ac5dabfa78e42dfb550d73e50.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "rkeIIkHKvS", "replyto": "rkeIIkHKvS", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper1730/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper1730/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1575088720944, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper1730/Reviewers"], "noninvitees": [], "tcdate": 1570237733135, "tmdate": 1575088720959, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper1730/-/Official_Review"}}}, {"id": "ryxJ4-ExqH", "original": null, "number": 2, "cdate": 1571991846870, "ddate": null, "tcdate": 1571991846870, "tmdate": 1572972430891, "tddate": null, "forum": "rkeIIkHKvS", "replyto": "rkeIIkHKvS", "invitation": "ICLR.cc/2020/Conference/Paper1730/-/Official_Review", "content": {"experience_assessment": "I have published one or two papers in this area.", "rating": "3: Weak Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #2", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "This paper proposes two smoothness metrics to measure the quantity and quality of the graph information that GNNs employ in the model. With the smoothness measures, this paper proposes a new GNN model to improve the use of graph information. Overall, the paper is well-organized and clearly written. The main concern is the novelty, since the proposed method is pretty close to the graph attention network (GAT), except using the two smoothness metrics and a slightly different way to compute the attention coefficients. Experimental results show marginal improvement over existing GNN methods on the node classification task. Given these aspects, it is not that convincing that the introduced smoothness metrics are necessary. I would like to recommend a weak reject for this paper.\n\n\nSuggestions to improve the paper:\n\n1) It would be better to provide more convincing evidence and motivation for the smoothness metrics, either in theory or empirical analysis.\n\n2) When describing the proposed method, organize the key differences in a more clear way. For example, add the proposed method directly in Table 1 and summarize the key differences in bullet points. Currently, this important part is deferred to Section 3.3, which may cause confusion for the readers to understand the paper.\n\n3) In Section 3.2, this paper claims that the proposed method can easily include side information on graphs to improve performance, by using the topology feature in the last fully connected layer for class prediction. However, this technique can also be used in existing GNN models, and it is not clear why this is described as something unique for the proposed method. Also, there is no corresponding ablation experiments to compare the performance of the proposed method with and without using local topology features."}, "signatures": ["ICLR.cc/2020/Conference/Paper1730/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1730/AnonReviewer2"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["yfhou@cse.cuhk.edu.hk", "jzhang@cse.cuhk.edu.hk", "jcheng@cse.cuhk.edu.hk", "klma@cse.cuhk.edu.hk", "tbma@comp.nus.edu.sg", "hzchen@cse.cuhk.edu.hk", "mcyang@cse.cuhk.edu.hk"], "title": "Measuring and Improving the Use of Graph Information in Graph Neural Networks", "authors": ["Yifan Hou", "Jian Zhang", "James Cheng", "Kaili Ma", "Richard T. B. Ma", "Hongzhi Chen", "Ming-Chang Yang"], "pdf": "/pdf/3ff628aed23920c95386567ad7acc7885d49b122.pdf", "abstract": "Graph neural networks (GNNs) have been widely used for representation learning on graph data. However, there is limited understanding on how much performance GNNs actually gain from graph data. This paper introduces a context-surrounding GNN framework and proposes two smoothness metrics to measure the quantity and quality of information obtained from graph data. A new, improved GNN model, called CS-GNN, is then devised to improve the use of graph information based on the smoothness values of a graph. CS-GNN is shown to achieve better performance than existing methods in different types of real graphs. ", "keywords": [], "paperhash": "hou|measuring_and_improving_the_use_of_graph_information_in_graph_neural_networks", "code": "https://github.com/yifan-h/CS-GNN", "_bibtex": "@inproceedings{\nHou2020Measuring,\ntitle={Measuring and Improving the Use of Graph Information in Graph Neural Networks},\nauthor={Yifan Hou and Jian Zhang and James Cheng and Kaili Ma and Richard T. B. Ma and Hongzhi Chen and Ming-Chang Yang},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=rkeIIkHKvS}\n}", "full_presentation_video": "", "original_pdf": "/attachment/cf368b35da9df17ac5dabfa78e42dfb550d73e50.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "rkeIIkHKvS", "replyto": "rkeIIkHKvS", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper1730/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper1730/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1575088720944, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper1730/Reviewers"], "noninvitees": [], "tcdate": 1570237733135, "tmdate": 1575088720959, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper1730/-/Official_Review"}}}, {"id": "H1ep9tkO9H", "original": null, "number": 3, "cdate": 1572497812992, "ddate": null, "tcdate": 1572497812992, "tmdate": 1572972430845, "tddate": null, "forum": "rkeIIkHKvS", "replyto": "rkeIIkHKvS", "invitation": "ICLR.cc/2020/Conference/Paper1730/-/Official_Review", "content": {"rating": "8: Accept", "experience_assessment": "I have read many papers in this area.", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #1", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review": "Summary\n\nThe paper proposes two graph smoothness metrics for measuring the usefulness of graph information. The feature smoothness indicates how much information can be gained by aggregating neighboring nodes while the label smoothness assesses the quality of this information. The authors show that Graph Neural Networks (GNNs) work best for tasks with high features smoothness and low label smoothness by utilizing information from surrounding nodes which also tends to have the same label. Based on these two metrics, the authors introduce a framework, called Context-Surrounding Graph Neural Network (CS-GNN), that utilizes important information from neighboring nodes of the same label while reduce the disturbance from neighboring nodes from different classes. The results demonstrate considerable improvement across 5 different tasks. \n\nStrength\n\nThe authors advocate for better understanding of the use of graph information in learning, which is both an important and interesting problem. Two graph smoothness metrics appears to be intuitive and reflect common situations in graph-based data (1) features from neighboring nodes contribute differently to target node representation (2) neighboring nodes information sometimes causing disturbance if node with different labels tend to be connected. The paper provides some theoretical analysis that supports this claim and thorough experiments that show the correlation between the two proposed metrics with the performance of GNNs. \n\nWeakness\n\nWhile the paper is reasonably readable, there is certainly room for improvements in the clarity of the paper. First, I would suggest the authors to avoid too much word repetition as well as long, obscure sentences. For example, the first sentence of section 2.2 can  be rewritten as \u201cGNNs usually contains an aggregation step to collect neighboring information and a combination step that merges this information with node features.\u201d The flow of the paper is also hard to follow and need some rearrangement. For instance, paragraph 3 of section 2.1 can be pushed until section 3.3. Another suggestion about the flow is to separate section 2.2 into two subsections for features smoothness and label smoothness (also the title of this section need to be refined). Finally, the results would be more clear if separated into different tables or subsections/paragraphs.\n\nQuestions\n\n* Is there a particular reason for using the KLD instead of mutual information?\n* In 2nd sentence of section 2.2, what does \u201cnode\u2019s own information\u201d mean? If it is the individual node\u2019s features then why it naturally the representation vector h_v (which is aggregated with neighboring nodes?)"}, "signatures": ["ICLR.cc/2020/Conference/Paper1730/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1730/AnonReviewer1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["yfhou@cse.cuhk.edu.hk", "jzhang@cse.cuhk.edu.hk", "jcheng@cse.cuhk.edu.hk", "klma@cse.cuhk.edu.hk", "tbma@comp.nus.edu.sg", "hzchen@cse.cuhk.edu.hk", "mcyang@cse.cuhk.edu.hk"], "title": "Measuring and Improving the Use of Graph Information in Graph Neural Networks", "authors": ["Yifan Hou", "Jian Zhang", "James Cheng", "Kaili Ma", "Richard T. B. Ma", "Hongzhi Chen", "Ming-Chang Yang"], "pdf": "/pdf/3ff628aed23920c95386567ad7acc7885d49b122.pdf", "abstract": "Graph neural networks (GNNs) have been widely used for representation learning on graph data. However, there is limited understanding on how much performance GNNs actually gain from graph data. This paper introduces a context-surrounding GNN framework and proposes two smoothness metrics to measure the quantity and quality of information obtained from graph data. A new, improved GNN model, called CS-GNN, is then devised to improve the use of graph information based on the smoothness values of a graph. CS-GNN is shown to achieve better performance than existing methods in different types of real graphs. ", "keywords": [], "paperhash": "hou|measuring_and_improving_the_use_of_graph_information_in_graph_neural_networks", "code": "https://github.com/yifan-h/CS-GNN", "_bibtex": "@inproceedings{\nHou2020Measuring,\ntitle={Measuring and Improving the Use of Graph Information in Graph Neural Networks},\nauthor={Yifan Hou and Jian Zhang and James Cheng and Kaili Ma and Richard T. B. Ma and Hongzhi Chen and Ming-Chang Yang},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=rkeIIkHKvS}\n}", "full_presentation_video": "", "original_pdf": "/attachment/cf368b35da9df17ac5dabfa78e42dfb550d73e50.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "rkeIIkHKvS", "replyto": "rkeIIkHKvS", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper1730/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper1730/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1575088720944, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper1730/Reviewers"], "noninvitees": [], "tcdate": 1570237733135, "tmdate": 1575088720959, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper1730/-/Official_Review"}}}], "count": 10}