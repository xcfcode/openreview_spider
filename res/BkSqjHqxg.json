{"notes": [{"tddate": null, "ddate": null, "cdate": null, "tmdate": 1486396471030, "tcdate": 1486396471030, "number": 1, "id": "r11H3GL_x", "invitation": "ICLR.cc/2017/conference/-/paper268/acceptance", "forum": "BkSqjHqxg", "replyto": "BkSqjHqxg", "signatures": ["ICLR.cc/2017/pcs"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/pcs"], "content": {"decision": "Reject", "title": "ICLR committee final decision", "comment": "The idea of applying skip-graphs to this graph domain to learn embeddings is good. The results demonstrate that this approach is competitive, but do not show a clear advantage. This is difficult, as the variety of approaches in this area is rapidly increasing. But comparisons to other methods could be improved, notably deep graph kernels."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Skip-graph: Learning graph embeddings with an encoder-decoder model", "abstract": "In this work, we study the problem of feature representation learning for graph-structured data. Many of the existing work in the area are task-specific and based on supervised techniques. We study a method for obtaining a generic feature representation for a graph using an unsupervised approach. The neural encoder-decoder model is a method that has been used in the natural language processing domain to learn feature representations of sentences. In our proposed approach, we train the encoder-decoder model to predict the random walk sequence of neighboring regions in a graph given a random walk along a particular region. The goal is to map subgraphs \u2014 as represented by their random walks \u2014 that are structurally and functionally similar to nearby locations in feature space. We evaluate the learned graph vectors using several real-world datasets on the graph classification task. The proposed model is able to achieve good results against state-of- the-art techniques.", "pdf": "/pdf/954ddff2afa7d65560f37fe0b0e1b08b0a75a739.pdf", "TL;DR": "An unsupervised method for generating graph feature representations based on the encoder-decoder model.", "paperhash": "lee|skipgraph_learning_graph_embeddings_with_an_encoderdecoder_model", "conflicts": ["cs.wpi.edu"], "authors": ["John Boaz Lee", "Xiangnan Kong"], "authorids": ["jtlee@wpi.edu", "xkong@wpi.edu"], "keywords": ["Unsupervised Learning", "Deep learning"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1486396471518, "id": "ICLR.cc/2017/conference/-/paper268/acceptance", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/pcs"], "noninvitees": ["ICLR.cc/2017/pcs"], "reply": {"forum": "BkSqjHqxg", "replyto": "BkSqjHqxg", "writers": {"values-regex": "ICLR.cc/2017/pcs"}, "signatures": {"values-regex": "ICLR.cc/2017/pcs", "description": "Your displayed identity associated with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your decision.", "value": "ICLR committee final decision"}, "comment": {"required": true, "order": 2, "description": "Decision comments.", "value-regex": "[\\S\\s]{1,5000}"}, "decision": {"required": true, "order": 3, "value-radio": ["Accept (Oral)", "Accept (Poster)", "Reject", "Invite to Workshop Track"]}}}, "nonreaders": [], "cdate": 1486396471518}}}, {"tddate": null, "tmdate": 1484579178028, "tcdate": 1484579178028, "number": 3, "id": "ByfubwcIe", "invitation": "ICLR.cc/2017/conference/-/paper268/official/comment", "forum": "BkSqjHqxg", "replyto": "H1Q8Ckz4l", "signatures": ["ICLR.cc/2017/conference/paper268/AnonReviewer2"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/conference/paper268/AnonReviewer2"], "content": {"title": "Comment on DeepWalk experiments", "comment": "I would like to thank the authors for following my suggestion and trying the averaged DeepWalk embeddings. Unfortunately, the results seem to show that the proposed method outperforms DeepWalk only of two datasets out of four. Hence, I can not increase the score that I gave to the paper. Arguably, DeepWalk method is much simpler, and the complexity of the proposed method has to be backed up by a strong experimental advantage. Alternatively, an additional analysis of the representation could be done. "}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Skip-graph: Learning graph embeddings with an encoder-decoder model", "abstract": "In this work, we study the problem of feature representation learning for graph-structured data. Many of the existing work in the area are task-specific and based on supervised techniques. We study a method for obtaining a generic feature representation for a graph using an unsupervised approach. The neural encoder-decoder model is a method that has been used in the natural language processing domain to learn feature representations of sentences. In our proposed approach, we train the encoder-decoder model to predict the random walk sequence of neighboring regions in a graph given a random walk along a particular region. The goal is to map subgraphs \u2014 as represented by their random walks \u2014 that are structurally and functionally similar to nearby locations in feature space. We evaluate the learned graph vectors using several real-world datasets on the graph classification task. The proposed model is able to achieve good results against state-of- the-art techniques.", "pdf": "/pdf/954ddff2afa7d65560f37fe0b0e1b08b0a75a739.pdf", "TL;DR": "An unsupervised method for generating graph feature representations based on the encoder-decoder model.", "paperhash": "lee|skipgraph_learning_graph_embeddings_with_an_encoderdecoder_model", "conflicts": ["cs.wpi.edu"], "authors": ["John Boaz Lee", "Xiangnan Kong"], "authorids": ["jtlee@wpi.edu", "xkong@wpi.edu"], "keywords": ["Unsupervised Learning", "Deep learning"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287657357, "id": "ICLR.cc/2017/conference/-/paper268/official/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "reply": {"forum": "BkSqjHqxg", "writers": {"values-regex": "ICLR.cc/2017/conference/paper268/(AnonReviewer|areachair)[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/conference/paper268/(AnonReviewer|areachair)[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": [], "invitees": ["ICLR.cc/2017/conference/paper268/reviewers", "ICLR.cc/2017/conference/paper268/areachairs"], "cdate": 1485287657357}}}, {"tddate": null, "tmdate": 1484104713870, "tcdate": 1484104713870, "number": 9, "id": "HyzM47X8l", "invitation": "ICLR.cc/2017/conference/-/paper268/public/comment", "forum": "BkSqjHqxg", "replyto": "BkSqjHqxg", "signatures": ["~John_Boaz_Lee1"], "readers": ["everyone"], "writers": ["~John_Boaz_Lee1"], "content": {"title": "Summary of changes", "comment": "Dear reviewers, thank you very much for all the insightful comments and suggestions. Please find below a summary of our response to each of the points that were raised. Please note that we have paraphrased some of the comments and combined similar ones.\n\nAnonymous Reviewer 2:\n\nComment 1. Use the same classifier for all the compared methods.\n\nWe have updated the results in our paper to reflect the changes from using a common classifier for all the compared methods. The changes can be found in section 3.2.\n\nComment 2. Use mean- or max-pooling to aggregate the embeddings learned by methods such as DeepWalk or node2vec and include this as a baseline.\n\nThe paper has been updated to include results from Deepwalk which was added as an additional baseline. Changes were made to sections 3.2 and 3.3.\n\nAnonymous Reviewer 3:\n\nComment 3. Provide more information about the exact values of the parameters that were used in the grid search.\n\nThe information have been added to the paper. This can be found in section 3.2.\n\nAnonymous Reviewer 1:\n\nComment 4. Need more experiment to demonstrate the power of their feature extraction methods. (Clustering, Search, Prediction etc.). Only comparing the classification accuracy by using the proposed method is not enough.\n\nWe plan to extend the experiments by using the embedding for graph clustering and graph search tasks in future works/journal extension. Due to the suggested page limit of ICLR, it is not easy to add these additional experiments without deleting some existing results in the paper. In the existing results, we have demonstrated the power of the embedding through prediction tasks and visualization of the embedding.\n\nComment 5. Presentation of the paper is weak. There are lots of typos and unclear statements. \n\nThe latest version of the paper has been proofread by several individuals and to the best of our knowledge we have removed the major typos and/or unclear statements. \n\nComment 6. What is the difference from graph kernel methods? The comparison with graph kernel is missing. \n\nWe agree that the problem studied in the deep graph kernel paper seems to be very similar, or even the same, to the one we are studying. However, the underlying approach is slightly different and we argue that that in itself is a good motivation for the work as there has not been too many work published in the area. We use an encoder-decoder model which has not been used, and for one we can identify functionally similar subgraphs. \n\nRegrettably, due to time constraints we are unable to add a comparison with Deep Graph Kernels. However, we have tested against methods that have been shown to achieve good results on the type of graphs we used (ECFP and NeuralFPS) and we have also tested against DeepWalk. The introduction section has been updated to include some discussion on this.\n\nAnonymous Reviewer 4:\n\nComment 7. Comparisons with recent work like LINE and node2vec are missing. You can compare them easily by applying the same aggregation strategy to their node embeddings.\n\nWe have already addressed the comment of a previous reviewer and have included DeepWalk as a baseline. We did not add comparisons against node2vec and LINE as these, in general, belong to the same family of methods.\n\nComment 8. As the current datasets are small (e.g., the average number of nodes per graph is around 30), it would be great to explore larger graph datasets to further investigate the method. \n\nTo compensate in a way, we tested the method on four different molecular graph datasets. Regrettably, we are unable to add experiments on more datasets at the moment.\n\nComment 9. The description about how to split the random walk sequence into 3 sub-sequences is missing. Also, the line \u201cl_min >= (n_k - 1), \u2026 >= l_max\u201d in section 2.2.2 is a mistake.\n\nSection 2.2.2 has been updated to correct this. Thank you very much for pointing this out.\n\n"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Skip-graph: Learning graph embeddings with an encoder-decoder model", "abstract": "In this work, we study the problem of feature representation learning for graph-structured data. Many of the existing work in the area are task-specific and based on supervised techniques. We study a method for obtaining a generic feature representation for a graph using an unsupervised approach. The neural encoder-decoder model is a method that has been used in the natural language processing domain to learn feature representations of sentences. In our proposed approach, we train the encoder-decoder model to predict the random walk sequence of neighboring regions in a graph given a random walk along a particular region. The goal is to map subgraphs \u2014 as represented by their random walks \u2014 that are structurally and functionally similar to nearby locations in feature space. We evaluate the learned graph vectors using several real-world datasets on the graph classification task. The proposed model is able to achieve good results against state-of- the-art techniques.", "pdf": "/pdf/954ddff2afa7d65560f37fe0b0e1b08b0a75a739.pdf", "TL;DR": "An unsupervised method for generating graph feature representations based on the encoder-decoder model.", "paperhash": "lee|skipgraph_learning_graph_embeddings_with_an_encoderdecoder_model", "conflicts": ["cs.wpi.edu"], "authors": ["John Boaz Lee", "Xiangnan Kong"], "authorids": ["jtlee@wpi.edu", "xkong@wpi.edu"], "keywords": ["Unsupervised Learning", "Deep learning"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287657491, "id": "ICLR.cc/2017/conference/-/paper268/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "BkSqjHqxg", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper268/reviewers", "ICLR.cc/2017/conference/paper268/areachairs"], "cdate": 1485287657491}}}, {"tddate": null, "replyto": null, "ddate": null, "tmdate": 1484104179320, "tcdate": 1478282124971, "number": 268, "id": "BkSqjHqxg", "invitation": "ICLR.cc/2017/conference/-/submission", "forum": "BkSqjHqxg", "signatures": ["~John_Boaz_Lee1"], "readers": ["everyone"], "content": {"title": "Skip-graph: Learning graph embeddings with an encoder-decoder model", "abstract": "In this work, we study the problem of feature representation learning for graph-structured data. Many of the existing work in the area are task-specific and based on supervised techniques. We study a method for obtaining a generic feature representation for a graph using an unsupervised approach. The neural encoder-decoder model is a method that has been used in the natural language processing domain to learn feature representations of sentences. In our proposed approach, we train the encoder-decoder model to predict the random walk sequence of neighboring regions in a graph given a random walk along a particular region. The goal is to map subgraphs \u2014 as represented by their random walks \u2014 that are structurally and functionally similar to nearby locations in feature space. We evaluate the learned graph vectors using several real-world datasets on the graph classification task. The proposed model is able to achieve good results against state-of- the-art techniques.", "pdf": "/pdf/954ddff2afa7d65560f37fe0b0e1b08b0a75a739.pdf", "TL;DR": "An unsupervised method for generating graph feature representations based on the encoder-decoder model.", "paperhash": "lee|skipgraph_learning_graph_embeddings_with_an_encoderdecoder_model", "conflicts": ["cs.wpi.edu"], "authors": ["John Boaz Lee", "Xiangnan Kong"], "authorids": ["jtlee@wpi.edu", "xkong@wpi.edu"], "keywords": ["Unsupervised Learning", "Deep learning"]}, "writers": [], "nonreaders": [], "details": {"replyCount": 18, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1475686800000, "tmdate": 1478287705855, "id": "ICLR.cc/2017/conference/-/submission", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/pcs"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": null, "replyto": null, "writers": {"values-regex": "~.*"}, "signatures": {"values-regex": "~.*", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"pdf": {"required": true, "order": 5, "description": "Either upload a PDF file or provide a direct link to your PDF on ArXiv (link must begin with http(s) and end with .pdf)", "value-regex": "upload|(http|https):\\/\\/.+\\.pdf"}, "title": {"required": true, "order": 1, "description": "Title of paper.", "value-regex": ".{1,250}"}, "abstract": {"required": true, "order": 4, "description": "Abstract of paper.", "value-regex": "[\\S\\s]{1,5000}"}, "authors": {"required": true, "order": 2, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of author names, as they appear in the paper."}, "conflicts": {"required": true, "order": 100, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of email domains of people who would have a conflict of interest in reviewing this paper, (e.g., cs.umass.edu;google.com, etc.)."}, "keywords": {"order": 6, "description": "Comma separated list of keywords.", "values-dropdown": ["Theory", "Computer vision", "Speech", "Natural language processing", "Deep learning", "Unsupervised Learning", "Supervised Learning", "Semi-Supervised Learning", "Reinforcement Learning", "Transfer Learning", "Multi-modal learning", "Applications", "Optimization", "Structured prediction", "Games"]}, "TL;DR": {"required": false, "order": 3, "description": "\"Too Long; Didn't Read\": a short sentence describing your paper", "value-regex": "[^\\n]{0,250}"}, "authorids": {"required": true, "order": 3, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of author email addresses, in the same order as above."}}}, "nonreaders": [], "noninvitees": [], "expdate": 1483462800000, "cdate": 1478287705855}}}, {"tddate": null, "tmdate": 1483331265351, "tcdate": 1483331265351, "number": 1, "id": "S1FT8Uvrl", "invitation": "ICLR.cc/2017/conference/-/paper268/public/review", "forum": "BkSqjHqxg", "replyto": "BkSqjHqxg", "signatures": ["(anonymous)"], "readers": ["everyone"], "writers": ["(anonymous)"], "content": {"title": "Experiments Are Incomplete", "rating": "5: Marginally below acceptance threshold", "review": "This paper proposes an unsupervised graph embedding learning method based on random walk and skip-thought model. They show promising results compared to several competitors on four chemical compound datasets.\n\nStrength:\n1, The idea of learning the graph embedding by applying skip-thought model to random walk sequences is interesting. \n2, The paper is well organized.\n\nWeakness:\n1, As the current datasets are small (e.g., the average number of nodes per graph is around 30), it would be great to explore larger graph datasets to further investigate the method. \n2, Comparisons with recent work like LINE and node2vec are missing. You can compare them easily by applying the same aggregation strategy to their node embeddings.\n\nDetailed Questions:\n1, The description about how to split the random walk sequence into 3 sub-sequences is missing. Also, the line \u201cl_min >= (n_k - 1), \u2026 >= l_max\u201d in section 2.2.2 is a mistake.\n2, Can you provide the standard deviations of the 5-fold cross validation in Table 2? I\u2019m curious about how stable the algorithm is.", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Skip-graph: Learning graph embeddings with an encoder-decoder model", "abstract": "In this work, we study the problem of feature representation learning for graph-structured data. Many of the existing work in the area are task-specific and based on supervised techniques. We study a method for obtaining a generic feature representation for a graph using an unsupervised approach. The neural encoder-decoder model is a method that has been used in the natural language processing domain to learn feature representations of sentences. In our proposed approach, we train the encoder-decoder model to predict the random walk sequence of neighboring regions in a graph given a random walk along a particular region. The goal is to map subgraphs \u2014 as represented by their random walks \u2014 that are structurally and functionally similar to nearby locations in feature space. We evaluate the learned graph vectors using several real-world datasets on the graph classification task. The proposed model is able to achieve good results against state-of- the-art techniques.", "pdf": "/pdf/954ddff2afa7d65560f37fe0b0e1b08b0a75a739.pdf", "TL;DR": "An unsupervised method for generating graph feature representations based on the encoder-decoder model.", "paperhash": "lee|skipgraph_learning_graph_embeddings_with_an_encoderdecoder_model", "conflicts": ["cs.wpi.edu"], "authors": ["John Boaz Lee", "Xiangnan Kong"], "authorids": ["jtlee@wpi.edu", "xkong@wpi.edu"], "keywords": ["Unsupervised Learning", "Deep learning"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1483331265934, "id": "ICLR.cc/2017/conference/-/paper268/public/review", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "BkSqjHqxg", "replyto": "BkSqjHqxg", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)"}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "value-regex": "[\\S\\s]{1,20000}"}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "noninvitees": ["jtlee@wpi.edu", "xkong@wpi.edu", "ICLR.cc/2017/conference/paper268/reviewers", "ICLR.cc/2017/conference/paper268/areachairs", "(anonymous)"], "cdate": 1483331265934}}}, {"tddate": null, "tmdate": 1483047099265, "tcdate": 1483047099265, "number": 2, "id": "ByQax-7Bl", "invitation": "ICLR.cc/2017/conference/-/paper268/official/comment", "forum": "BkSqjHqxg", "replyto": "HkpJUpfHx", "signatures": ["ICLR.cc/2017/conference/paper268/AnonReviewer1"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/conference/paper268/AnonReviewer1"], "content": {"title": "Dee Graph Kernel?", "comment": "Learning an embedding is equivalent to learning a kernel. See literature on metric embeddings. I am not sure if this is the first method for learning embeddings of graphs. See the Deep Graph Kernel paper \nhttp://dl.acm.org/citation.cfm?id=2783417"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Skip-graph: Learning graph embeddings with an encoder-decoder model", "abstract": "In this work, we study the problem of feature representation learning for graph-structured data. Many of the existing work in the area are task-specific and based on supervised techniques. We study a method for obtaining a generic feature representation for a graph using an unsupervised approach. The neural encoder-decoder model is a method that has been used in the natural language processing domain to learn feature representations of sentences. In our proposed approach, we train the encoder-decoder model to predict the random walk sequence of neighboring regions in a graph given a random walk along a particular region. The goal is to map subgraphs \u2014 as represented by their random walks \u2014 that are structurally and functionally similar to nearby locations in feature space. We evaluate the learned graph vectors using several real-world datasets on the graph classification task. The proposed model is able to achieve good results against state-of- the-art techniques.", "pdf": "/pdf/954ddff2afa7d65560f37fe0b0e1b08b0a75a739.pdf", "TL;DR": "An unsupervised method for generating graph feature representations based on the encoder-decoder model.", "paperhash": "lee|skipgraph_learning_graph_embeddings_with_an_encoderdecoder_model", "conflicts": ["cs.wpi.edu"], "authors": ["John Boaz Lee", "Xiangnan Kong"], "authorids": ["jtlee@wpi.edu", "xkong@wpi.edu"], "keywords": ["Unsupervised Learning", "Deep learning"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287657357, "id": "ICLR.cc/2017/conference/-/paper268/official/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "reply": {"forum": "BkSqjHqxg", "writers": {"values-regex": "ICLR.cc/2017/conference/paper268/(AnonReviewer|areachair)[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/conference/paper268/(AnonReviewer|areachair)[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": [], "invitees": ["ICLR.cc/2017/conference/paper268/reviewers", "ICLR.cc/2017/conference/paper268/areachairs"], "cdate": 1485287657357}}}, {"tddate": null, "tmdate": 1483032036733, "tcdate": 1483032036733, "number": 8, "id": "HkpJUpfHx", "invitation": "ICLR.cc/2017/conference/-/paper268/public/comment", "forum": "BkSqjHqxg", "replyto": "HJctDnzSe", "signatures": ["~Xiangnan_Kong1"], "readers": ["everyone"], "writers": ["~Xiangnan_Kong1"], "content": {"title": "Re: Comparison with Graph kernels Missing", "comment": "Thanks a lot for the invaluable comment. As suggested by reviewer2, we have added a comparison with DeepWalk (the embedding method) in Table 2.\n\n= Response to Comments 1, 2 and 5: (difference between this paper and graph kernel) =\nI would like to clarify the major differences between our work and graph kernel methods. Although recent methods on graph kernels achieved great performances on graph data, but they are actually focused on graph kernel problems, instead of the graph embedding problem. Graph kernel methods are focused on learning a kernel/similarity function between a Pair of graph objects.  Our method is learning a feature embedding for each graph object. For example, in figure 4, we showed a graph embedding result, which cannot be obtained through graph kernel methods. This paper is the first deep learning approach to graph embedding problem.  Although our graph embedding can potentially be fed into a kernel/similarity function in order to construct a graph kernel and to compare with graph kernel methods, that would be slightly beyond the scope of graph embedding problem of this paper. But we would be happy to add this comparison if this is crucial. \n\n= Response to Comment 3: (more experiments on clustering, search, prediction etc. tasks) =\nWe plan to extend the experiments by using the embedding for graph clustering and graph search tasks in future works/journal extension.  Due to the page limit of ICLR, it is not easy to add these additional experiments without deleting some existing results in the paper. In the existing results, we have demonstrated the power of the embedding through Prediction tasks and visualization of the embedding.\n\n= Response to Comment 4: (typo and unclear statements) =\nWe regret if there is any typo or unclear statement in the paper, and we will proof-read again and correct them quickly in the next revision."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Skip-graph: Learning graph embeddings with an encoder-decoder model", "abstract": "In this work, we study the problem of feature representation learning for graph-structured data. Many of the existing work in the area are task-specific and based on supervised techniques. We study a method for obtaining a generic feature representation for a graph using an unsupervised approach. The neural encoder-decoder model is a method that has been used in the natural language processing domain to learn feature representations of sentences. In our proposed approach, we train the encoder-decoder model to predict the random walk sequence of neighboring regions in a graph given a random walk along a particular region. The goal is to map subgraphs \u2014 as represented by their random walks \u2014 that are structurally and functionally similar to nearby locations in feature space. We evaluate the learned graph vectors using several real-world datasets on the graph classification task. The proposed model is able to achieve good results against state-of- the-art techniques.", "pdf": "/pdf/954ddff2afa7d65560f37fe0b0e1b08b0a75a739.pdf", "TL;DR": "An unsupervised method for generating graph feature representations based on the encoder-decoder model.", "paperhash": "lee|skipgraph_learning_graph_embeddings_with_an_encoderdecoder_model", "conflicts": ["cs.wpi.edu"], "authors": ["John Boaz Lee", "Xiangnan Kong"], "authorids": ["jtlee@wpi.edu", "xkong@wpi.edu"], "keywords": ["Unsupervised Learning", "Deep learning"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287657491, "id": "ICLR.cc/2017/conference/-/paper268/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "BkSqjHqxg", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper268/reviewers", "ICLR.cc/2017/conference/paper268/areachairs"], "cdate": 1485287657491}}}, {"tddate": null, "tmdate": 1483028353978, "tcdate": 1483028353978, "number": 3, "id": "HJctDnzSe", "invitation": "ICLR.cc/2017/conference/-/paper268/official/review", "forum": "BkSqjHqxg", "replyto": "BkSqjHqxg", "signatures": ["ICLR.cc/2017/conference/paper268/AnonReviewer1"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/conference/paper268/AnonReviewer1"], "content": {"title": "Comparison with Graph kernels Missing", "rating": "5: Marginally below acceptance threshold", "review": "This paper studies the graph embedding problem by using the encoder-decoder method. The experimental study on real network data sets show the features extracted by the proposed model is good for classification.\n\nStrong points of this paper:\n  1. The idea of using the methods from natural language processing to graph mining is quite interesting.\n  2. The organization of the paper is clear\n\nWeak points of this paper:\n  1. Comparisons with state-of-art methods (Graph Kernels) is missing. \n  2. The problem is not well motivated, are there any application of this. What is the different from the graph kernel methods? The comparison with graph kernel is missing. \n  3. Need more experiment to demonstrate the power of their feature extraction methods. (Clustering, Search, Prediction etc.)\n  4. Presentation of the paper is weak. There are lots of typos and unclear statements. \n  5. The author mentioned about the graph kernel things, but in the experiment they didn't compare them. Also, only compare the classification accuracy by using the proposed method is not enough.", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Skip-graph: Learning graph embeddings with an encoder-decoder model", "abstract": "In this work, we study the problem of feature representation learning for graph-structured data. Many of the existing work in the area are task-specific and based on supervised techniques. We study a method for obtaining a generic feature representation for a graph using an unsupervised approach. The neural encoder-decoder model is a method that has been used in the natural language processing domain to learn feature representations of sentences. In our proposed approach, we train the encoder-decoder model to predict the random walk sequence of neighboring regions in a graph given a random walk along a particular region. The goal is to map subgraphs \u2014 as represented by their random walks \u2014 that are structurally and functionally similar to nearby locations in feature space. We evaluate the learned graph vectors using several real-world datasets on the graph classification task. The proposed model is able to achieve good results against state-of- the-art techniques.", "pdf": "/pdf/954ddff2afa7d65560f37fe0b0e1b08b0a75a739.pdf", "TL;DR": "An unsupervised method for generating graph feature representations based on the encoder-decoder model.", "paperhash": "lee|skipgraph_learning_graph_embeddings_with_an_encoderdecoder_model", "conflicts": ["cs.wpi.edu"], "authors": ["John Boaz Lee", "Xiangnan Kong"], "authorids": ["jtlee@wpi.edu", "xkong@wpi.edu"], "keywords": ["Unsupervised Learning", "Deep learning"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1481932799000, "tmdate": 1483028354555, "id": "ICLR.cc/2017/conference/-/paper268/official/review", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/conference/paper268/reviewers"], "noninvitees": ["ICLR.cc/2017/conference/paper268/AnonReviewer2", "ICLR.cc/2017/conference/paper268/AnonReviewer3", "ICLR.cc/2017/conference/paper268/AnonReviewer1"], "reply": {"forum": "BkSqjHqxg", "replyto": "BkSqjHqxg", "writers": {"values-regex": "ICLR.cc/2017/conference/paper268/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/conference/paper268/AnonReviewer[0-9]+"}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "value-regex": "[\\S\\s]{1,20000}"}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1489708799000, "cdate": 1483028354555}}}, {"tddate": null, "tmdate": 1482788977770, "tcdate": 1482202311290, "number": 7, "id": "SyJR3M8Nl", "invitation": "ICLR.cc/2017/conference/-/paper268/public/comment", "forum": "BkSqjHqxg", "replyto": "ByHWhGUVg", "signatures": ["~John_Boaz_Lee1"], "readers": ["everyone"], "writers": ["~John_Boaz_Lee1"], "content": {"title": "Response", "comment": "Thank you for your response, we have updated the paper to include information about the parameters we tested. This can be found in sec. 3.2."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Skip-graph: Learning graph embeddings with an encoder-decoder model", "abstract": "In this work, we study the problem of feature representation learning for graph-structured data. Many of the existing work in the area are task-specific and based on supervised techniques. We study a method for obtaining a generic feature representation for a graph using an unsupervised approach. The neural encoder-decoder model is a method that has been used in the natural language processing domain to learn feature representations of sentences. In our proposed approach, we train the encoder-decoder model to predict the random walk sequence of neighboring regions in a graph given a random walk along a particular region. The goal is to map subgraphs \u2014 as represented by their random walks \u2014 that are structurally and functionally similar to nearby locations in feature space. We evaluate the learned graph vectors using several real-world datasets on the graph classification task. The proposed model is able to achieve good results against state-of- the-art techniques.", "pdf": "/pdf/954ddff2afa7d65560f37fe0b0e1b08b0a75a739.pdf", "TL;DR": "An unsupervised method for generating graph feature representations based on the encoder-decoder model.", "paperhash": "lee|skipgraph_learning_graph_embeddings_with_an_encoderdecoder_model", "conflicts": ["cs.wpi.edu"], "authors": ["John Boaz Lee", "Xiangnan Kong"], "authorids": ["jtlee@wpi.edu", "xkong@wpi.edu"], "keywords": ["Unsupervised Learning", "Deep learning"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287657491, "id": "ICLR.cc/2017/conference/-/paper268/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "BkSqjHqxg", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper268/reviewers", "ICLR.cc/2017/conference/paper268/areachairs"], "cdate": 1485287657491}}}, {"tddate": null, "tmdate": 1482788798096, "tcdate": 1481565633127, "number": 3, "id": "SJFpSv37e", "invitation": "ICLR.cc/2017/conference/-/paper268/public/comment", "forum": "BkSqjHqxg", "replyto": "Sy52xMJXe", "signatures": ["~John_Boaz_Lee1"], "readers": ["everyone"], "writers": ["~John_Boaz_Lee1"], "content": {"title": "Summary of changes in response to comment", "comment": "Thank you for your comments and suggestions. We have updated our paper. In particular we added the following things:\n\n(a) short discussion on how the method can be used with unlabeled graphs (sec. 2.2.1)\n(b) short discussion and figure of visualization of the embeddings for one of the datasets (sec. 3.5, figure 4)\n(c) experiments were rerun to use a common classifier (neural network) for all tested methods (sec. 3.2)\n\nFurthermore, in response to your suggestion in the review, we have included DeepWalk as an additional baseline method which we tested against. The additional information is included in sec. 3.2 and sec. 3.3."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Skip-graph: Learning graph embeddings with an encoder-decoder model", "abstract": "In this work, we study the problem of feature representation learning for graph-structured data. Many of the existing work in the area are task-specific and based on supervised techniques. We study a method for obtaining a generic feature representation for a graph using an unsupervised approach. The neural encoder-decoder model is a method that has been used in the natural language processing domain to learn feature representations of sentences. In our proposed approach, we train the encoder-decoder model to predict the random walk sequence of neighboring regions in a graph given a random walk along a particular region. The goal is to map subgraphs \u2014 as represented by their random walks \u2014 that are structurally and functionally similar to nearby locations in feature space. We evaluate the learned graph vectors using several real-world datasets on the graph classification task. The proposed model is able to achieve good results against state-of- the-art techniques.", "pdf": "/pdf/954ddff2afa7d65560f37fe0b0e1b08b0a75a739.pdf", "TL;DR": "An unsupervised method for generating graph feature representations based on the encoder-decoder model.", "paperhash": "lee|skipgraph_learning_graph_embeddings_with_an_encoderdecoder_model", "conflicts": ["cs.wpi.edu"], "authors": ["John Boaz Lee", "Xiangnan Kong"], "authorids": ["jtlee@wpi.edu", "xkong@wpi.edu"], "keywords": ["Unsupervised Learning", "Deep learning"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287657491, "id": "ICLR.cc/2017/conference/-/paper268/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "BkSqjHqxg", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper268/reviewers", "ICLR.cc/2017/conference/paper268/areachairs"], "cdate": 1485287657491}}}, {"tddate": null, "tmdate": 1482202179856, "tcdate": 1482202179856, "number": 6, "id": "rJ3HnzIVl", "invitation": "ICLR.cc/2017/conference/-/paper268/public/comment", "forum": "BkSqjHqxg", "replyto": "HJLfcyL4x", "signatures": ["~John_Boaz_Lee1"], "readers": ["everyone"], "writers": ["~John_Boaz_Lee1"], "content": {"title": "Response", "comment": "Thank you for your comments. Discussion about the classifier we used can be found in section 3.2 of our paper. We used a neural network classifier. The same classifier, optimized over the same set of parameters, was used to evaluated all the compared methods. \n\nWe do not claim that the method achieves absolute best performance on the tested datasets. However, we compared our approach against methods that have been shown to achieve state-of-the-art results on the type of graphs (molecular) that we used for evaluation. The results show that the method is competitive against these methods. "}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Skip-graph: Learning graph embeddings with an encoder-decoder model", "abstract": "In this work, we study the problem of feature representation learning for graph-structured data. Many of the existing work in the area are task-specific and based on supervised techniques. We study a method for obtaining a generic feature representation for a graph using an unsupervised approach. The neural encoder-decoder model is a method that has been used in the natural language processing domain to learn feature representations of sentences. In our proposed approach, we train the encoder-decoder model to predict the random walk sequence of neighboring regions in a graph given a random walk along a particular region. The goal is to map subgraphs \u2014 as represented by their random walks \u2014 that are structurally and functionally similar to nearby locations in feature space. We evaluate the learned graph vectors using several real-world datasets on the graph classification task. The proposed model is able to achieve good results against state-of- the-art techniques.", "pdf": "/pdf/954ddff2afa7d65560f37fe0b0e1b08b0a75a739.pdf", "TL;DR": "An unsupervised method for generating graph feature representations based on the encoder-decoder model.", "paperhash": "lee|skipgraph_learning_graph_embeddings_with_an_encoderdecoder_model", "conflicts": ["cs.wpi.edu"], "authors": ["John Boaz Lee", "Xiangnan Kong"], "authorids": ["jtlee@wpi.edu", "xkong@wpi.edu"], "keywords": ["Unsupervised Learning", "Deep learning"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287657491, "id": "ICLR.cc/2017/conference/-/paper268/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "BkSqjHqxg", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper268/reviewers", "ICLR.cc/2017/conference/paper268/areachairs"], "cdate": 1485287657491}}}, {"tddate": null, "tmdate": 1482202108951, "tcdate": 1482202108951, "number": 1, "id": "ByHWhGUVg", "invitation": "ICLR.cc/2017/conference/-/paper268/official/comment", "forum": "BkSqjHqxg", "replyto": "BJr0cMIEe", "signatures": ["ICLR.cc/2017/conference/paper268/AnonReviewer3"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/conference/paper268/AnonReviewer3"], "content": {"title": "more information on classifier", "comment": "For someone to reproduce your experiment it would be helpful to give more details -- how big was the network (how many units in each layer), which parameters was the grid search used for."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Skip-graph: Learning graph embeddings with an encoder-decoder model", "abstract": "In this work, we study the problem of feature representation learning for graph-structured data. Many of the existing work in the area are task-specific and based on supervised techniques. We study a method for obtaining a generic feature representation for a graph using an unsupervised approach. The neural encoder-decoder model is a method that has been used in the natural language processing domain to learn feature representations of sentences. In our proposed approach, we train the encoder-decoder model to predict the random walk sequence of neighboring regions in a graph given a random walk along a particular region. The goal is to map subgraphs \u2014 as represented by their random walks \u2014 that are structurally and functionally similar to nearby locations in feature space. We evaluate the learned graph vectors using several real-world datasets on the graph classification task. The proposed model is able to achieve good results against state-of- the-art techniques.", "pdf": "/pdf/954ddff2afa7d65560f37fe0b0e1b08b0a75a739.pdf", "TL;DR": "An unsupervised method for generating graph feature representations based on the encoder-decoder model.", "paperhash": "lee|skipgraph_learning_graph_embeddings_with_an_encoderdecoder_model", "conflicts": ["cs.wpi.edu"], "authors": ["John Boaz Lee", "Xiangnan Kong"], "authorids": ["jtlee@wpi.edu", "xkong@wpi.edu"], "keywords": ["Unsupervised Learning", "Deep learning"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287657357, "id": "ICLR.cc/2017/conference/-/paper268/official/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "reply": {"forum": "BkSqjHqxg", "writers": {"values-regex": "ICLR.cc/2017/conference/paper268/(AnonReviewer|areachair)[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/conference/paper268/(AnonReviewer|areachair)[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": [], "invitees": ["ICLR.cc/2017/conference/paper268/reviewers", "ICLR.cc/2017/conference/paper268/areachairs"], "cdate": 1485287657357}}}, {"tddate": null, "tmdate": 1482201804888, "tcdate": 1482201804888, "number": 5, "id": "BJr0cMIEe", "invitation": "ICLR.cc/2017/conference/-/paper268/public/comment", "forum": "BkSqjHqxg", "replyto": "S1LDYyIVx", "signatures": ["~John_Boaz_Lee1"], "readers": ["everyone"], "writers": ["~John_Boaz_Lee1"], "content": {"title": "Response", "comment": "Hello, we used a neural network in our experiments. The same classifier (using the same set of parameters) was used with all the evaluated methods. This information can be found in the latter part of section 3.2 of the paper."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Skip-graph: Learning graph embeddings with an encoder-decoder model", "abstract": "In this work, we study the problem of feature representation learning for graph-structured data. Many of the existing work in the area are task-specific and based on supervised techniques. We study a method for obtaining a generic feature representation for a graph using an unsupervised approach. The neural encoder-decoder model is a method that has been used in the natural language processing domain to learn feature representations of sentences. In our proposed approach, we train the encoder-decoder model to predict the random walk sequence of neighboring regions in a graph given a random walk along a particular region. The goal is to map subgraphs \u2014 as represented by their random walks \u2014 that are structurally and functionally similar to nearby locations in feature space. We evaluate the learned graph vectors using several real-world datasets on the graph classification task. The proposed model is able to achieve good results against state-of- the-art techniques.", "pdf": "/pdf/954ddff2afa7d65560f37fe0b0e1b08b0a75a739.pdf", "TL;DR": "An unsupervised method for generating graph feature representations based on the encoder-decoder model.", "paperhash": "lee|skipgraph_learning_graph_embeddings_with_an_encoderdecoder_model", "conflicts": ["cs.wpi.edu"], "authors": ["John Boaz Lee", "Xiangnan Kong"], "authorids": ["jtlee@wpi.edu", "xkong@wpi.edu"], "keywords": ["Unsupervised Learning", "Deep learning"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287657491, "id": "ICLR.cc/2017/conference/-/paper268/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "BkSqjHqxg", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper268/reviewers", "ICLR.cc/2017/conference/paper268/areachairs"], "cdate": 1485287657491}}}, {"tddate": null, "tmdate": 1482189373668, "tcdate": 1482189325897, "number": 2, "id": "HJLfcyL4x", "invitation": "ICLR.cc/2017/conference/-/paper268/official/review", "forum": "BkSqjHqxg", "replyto": "BkSqjHqxg", "signatures": ["ICLR.cc/2017/conference/paper268/AnonReviewer3"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/conference/paper268/AnonReviewer3"], "content": {"title": "An extension of skip-graph architecture to classifying similar molecular graphs ", "rating": "6: Marginally above acceptance threshold", "review": "Authors take the skip-graph architecture (Kiros 2015) and apply it to classifying labeled graphs (molecular graphs). They do it by creating many sentences by walking the graph randomly, and asking the model to predict previous part and next part from the middle part. Activations of the decoder part of this model on a walk generated from a new graph are used as features for a binary classifier use to predict whether the molecule has anti-cancer properties.\n\nPaper is well written, except that evaluation section is missing details of how the embedding is used for actual classification (ie, what classifier is used)\n\nUnfortunately I'm not familiar with the dataset and how hard it is to achieve the results they demonstrate, that would be the important factor to weight on the papers acceptance.", "confidence": "1: The reviewer's evaluation is an educated guess"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Skip-graph: Learning graph embeddings with an encoder-decoder model", "abstract": "In this work, we study the problem of feature representation learning for graph-structured data. Many of the existing work in the area are task-specific and based on supervised techniques. We study a method for obtaining a generic feature representation for a graph using an unsupervised approach. The neural encoder-decoder model is a method that has been used in the natural language processing domain to learn feature representations of sentences. In our proposed approach, we train the encoder-decoder model to predict the random walk sequence of neighboring regions in a graph given a random walk along a particular region. The goal is to map subgraphs \u2014 as represented by their random walks \u2014 that are structurally and functionally similar to nearby locations in feature space. We evaluate the learned graph vectors using several real-world datasets on the graph classification task. The proposed model is able to achieve good results against state-of- the-art techniques.", "pdf": "/pdf/954ddff2afa7d65560f37fe0b0e1b08b0a75a739.pdf", "TL;DR": "An unsupervised method for generating graph feature representations based on the encoder-decoder model.", "paperhash": "lee|skipgraph_learning_graph_embeddings_with_an_encoderdecoder_model", "conflicts": ["cs.wpi.edu"], "authors": ["John Boaz Lee", "Xiangnan Kong"], "authorids": ["jtlee@wpi.edu", "xkong@wpi.edu"], "keywords": ["Unsupervised Learning", "Deep learning"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1481932799000, "tmdate": 1483028354555, "id": "ICLR.cc/2017/conference/-/paper268/official/review", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/conference/paper268/reviewers"], "noninvitees": ["ICLR.cc/2017/conference/paper268/AnonReviewer2", "ICLR.cc/2017/conference/paper268/AnonReviewer3", "ICLR.cc/2017/conference/paper268/AnonReviewer1"], "reply": {"forum": "BkSqjHqxg", "replyto": "BkSqjHqxg", "writers": {"values-regex": "ICLR.cc/2017/conference/paper268/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/conference/paper268/AnonReviewer[0-9]+"}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "value-regex": "[\\S\\s]{1,20000}"}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1489708799000, "cdate": 1483028354555}}}, {"tddate": null, "tmdate": 1482189149576, "tcdate": 1482189149576, "number": 2, "id": "S1LDYyIVx", "invitation": "ICLR.cc/2017/conference/-/paper268/pre-review/question", "forum": "BkSqjHqxg", "replyto": "BkSqjHqxg", "signatures": ["ICLR.cc/2017/conference/paper268/AnonReviewer3"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/conference/paper268/AnonReviewer3"], "content": {"title": "How do you go from embedding to final classification?", "question": "You say that any off the shelf classifier can be used to make the prediction based on embedding, what are the actual classifiers you used in your experiments?"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Skip-graph: Learning graph embeddings with an encoder-decoder model", "abstract": "In this work, we study the problem of feature representation learning for graph-structured data. Many of the existing work in the area are task-specific and based on supervised techniques. We study a method for obtaining a generic feature representation for a graph using an unsupervised approach. The neural encoder-decoder model is a method that has been used in the natural language processing domain to learn feature representations of sentences. In our proposed approach, we train the encoder-decoder model to predict the random walk sequence of neighboring regions in a graph given a random walk along a particular region. The goal is to map subgraphs \u2014 as represented by their random walks \u2014 that are structurally and functionally similar to nearby locations in feature space. We evaluate the learned graph vectors using several real-world datasets on the graph classification task. The proposed model is able to achieve good results against state-of- the-art techniques.", "pdf": "/pdf/954ddff2afa7d65560f37fe0b0e1b08b0a75a739.pdf", "TL;DR": "An unsupervised method for generating graph feature representations based on the encoder-decoder model.", "paperhash": "lee|skipgraph_learning_graph_embeddings_with_an_encoderdecoder_model", "conflicts": ["cs.wpi.edu"], "authors": ["John Boaz Lee", "Xiangnan Kong"], "authorids": ["jtlee@wpi.edu", "xkong@wpi.edu"], "keywords": ["Unsupervised Learning", "Deep learning"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1480741199000, "tmdate": 1482189150100, "id": "ICLR.cc/2017/conference/-/paper268/pre-review/question", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/conference/paper268/reviewers"], "noninvitees": ["ICLR.cc/2017/conference/paper268/AnonReviewer2", "ICLR.cc/2017/conference/paper268/AnonReviewer3"], "reply": {"forum": "BkSqjHqxg", "replyto": "BkSqjHqxg", "writers": {"values-regex": "ICLR.cc/2017/conference/paper268/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/conference/paper268/AnonReviewer[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your question.", "value-regex": ".{1,500}"}, "question": {"order": 2, "description": "Your question", "value-regex": "[\\S\\s]{1,5000}"}}}, "nonreaders": [], "expdate": 1488517199000, "cdate": 1482189150100}}}, {"tddate": null, "tmdate": 1481928267011, "tcdate": 1481928267011, "number": 1, "id": "H1Q8Ckz4l", "invitation": "ICLR.cc/2017/conference/-/paper268/official/review", "forum": "BkSqjHqxg", "replyto": "BkSqjHqxg", "signatures": ["ICLR.cc/2017/conference/paper268/AnonReviewer2"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/conference/paper268/AnonReviewer2"], "content": {"title": "Good paper", "rating": "7: Good paper, accept", "review": "The paper presents a method to learn graph embeddings in a unsupervised way using random walks. It is well written and the execution appears quite accurate. The area of learning whole graph representations does not seem to be very well explored in general, and the proposed approach enjoys having very few competitors.\n\nIn a nutshell, the idea is to linearize the graph using random walks and to compute the embedding of the central segment of each walk using the skip-thought criterion. Being not an expert in biology, I can not comment whether or not this makes sense, but the gains reported in Table 2 are quite significant. \n\nAn anonymous public comment compared this work to a number of others in which the problem of learning representations of nodes is considered. While this is arguably a different goal, one natural baseline would be to pool these representations using mean- or max- pooling. It would very interesting to do such a comparison, especially given that the considered approach heavily relies on pooling (see Figure 3(c))\n\nTo sum up, I think it is a nice paper, and with more baselines I would be ready to further increase the numerical score.  \n", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Skip-graph: Learning graph embeddings with an encoder-decoder model", "abstract": "In this work, we study the problem of feature representation learning for graph-structured data. Many of the existing work in the area are task-specific and based on supervised techniques. We study a method for obtaining a generic feature representation for a graph using an unsupervised approach. The neural encoder-decoder model is a method that has been used in the natural language processing domain to learn feature representations of sentences. In our proposed approach, we train the encoder-decoder model to predict the random walk sequence of neighboring regions in a graph given a random walk along a particular region. The goal is to map subgraphs \u2014 as represented by their random walks \u2014 that are structurally and functionally similar to nearby locations in feature space. We evaluate the learned graph vectors using several real-world datasets on the graph classification task. The proposed model is able to achieve good results against state-of- the-art techniques.", "pdf": "/pdf/954ddff2afa7d65560f37fe0b0e1b08b0a75a739.pdf", "TL;DR": "An unsupervised method for generating graph feature representations based on the encoder-decoder model.", "paperhash": "lee|skipgraph_learning_graph_embeddings_with_an_encoderdecoder_model", "conflicts": ["cs.wpi.edu"], "authors": ["John Boaz Lee", "Xiangnan Kong"], "authorids": ["jtlee@wpi.edu", "xkong@wpi.edu"], "keywords": ["Unsupervised Learning", "Deep learning"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1481932799000, "tmdate": 1483028354555, "id": "ICLR.cc/2017/conference/-/paper268/official/review", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/conference/paper268/reviewers"], "noninvitees": ["ICLR.cc/2017/conference/paper268/AnonReviewer2", "ICLR.cc/2017/conference/paper268/AnonReviewer3", "ICLR.cc/2017/conference/paper268/AnonReviewer1"], "reply": {"forum": "BkSqjHqxg", "replyto": "BkSqjHqxg", "writers": {"values-regex": "ICLR.cc/2017/conference/paper268/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/conference/paper268/AnonReviewer[0-9]+"}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "value-regex": "[\\S\\s]{1,20000}"}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1489708799000, "cdate": 1483028354555}}}, {"tddate": null, "tmdate": 1480710353368, "tcdate": 1480691889645, "number": 1, "id": "Sy52xMJXe", "invitation": "ICLR.cc/2017/conference/-/paper268/pre-review/question", "forum": "BkSqjHqxg", "replyto": "BkSqjHqxg", "signatures": ["ICLR.cc/2017/conference/paper268/AnonReviewer2"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/conference/paper268/AnonReviewer2"], "content": {"title": "Classifier for ECFP", "question": "What is the classifier that you used for ECFP? In the text you only say that you used a library from a prior work. I think that for a correct comparison you should  use the same classifier for ECFP and skip-graph embeddings, because your dataset is very small and skewed, and the choice of regularization might be very important."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Skip-graph: Learning graph embeddings with an encoder-decoder model", "abstract": "In this work, we study the problem of feature representation learning for graph-structured data. Many of the existing work in the area are task-specific and based on supervised techniques. We study a method for obtaining a generic feature representation for a graph using an unsupervised approach. The neural encoder-decoder model is a method that has been used in the natural language processing domain to learn feature representations of sentences. In our proposed approach, we train the encoder-decoder model to predict the random walk sequence of neighboring regions in a graph given a random walk along a particular region. The goal is to map subgraphs \u2014 as represented by their random walks \u2014 that are structurally and functionally similar to nearby locations in feature space. We evaluate the learned graph vectors using several real-world datasets on the graph classification task. The proposed model is able to achieve good results against state-of- the-art techniques.", "pdf": "/pdf/954ddff2afa7d65560f37fe0b0e1b08b0a75a739.pdf", "TL;DR": "An unsupervised method for generating graph feature representations based on the encoder-decoder model.", "paperhash": "lee|skipgraph_learning_graph_embeddings_with_an_encoderdecoder_model", "conflicts": ["cs.wpi.edu"], "authors": ["John Boaz Lee", "Xiangnan Kong"], "authorids": ["jtlee@wpi.edu", "xkong@wpi.edu"], "keywords": ["Unsupervised Learning", "Deep learning"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1480741199000, "tmdate": 1482189150100, "id": "ICLR.cc/2017/conference/-/paper268/pre-review/question", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/conference/paper268/reviewers"], "noninvitees": ["ICLR.cc/2017/conference/paper268/AnonReviewer2", "ICLR.cc/2017/conference/paper268/AnonReviewer3"], "reply": {"forum": "BkSqjHqxg", "replyto": "BkSqjHqxg", "writers": {"values-regex": "ICLR.cc/2017/conference/paper268/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/conference/paper268/AnonReviewer[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your question.", "value-regex": ".{1,500}"}, "question": {"order": 2, "description": "Your question", "value-regex": "[\\S\\s]{1,5000}"}}}, "nonreaders": [], "expdate": 1488517199000, "cdate": 1482189150100}}}, {"tddate": null, "tmdate": 1478351078077, "tcdate": 1478351078018, "number": 2, "id": "SkA1KUjgl", "invitation": "ICLR.cc/2017/conference/-/paper268/public/comment", "forum": "BkSqjHqxg", "replyto": "HyFIVpclx", "signatures": ["~Xiangnan_Kong1"], "readers": ["everyone"], "writers": ["~Xiangnan_Kong1"], "content": {"title": "Baseline comparisons", "comment": "Thanks a lot for the comment.\nI would like to clarify the major differences between our work and previous work. Although the recent works (LINE, DeepWalk, node2vec) are indeed unsupervised, but they are actually focused on the node embedding problem, instead of the graph embedding problem. LINE, DeepWalk and node2vec are learning an embedding for each node in a graph or an information network.  Our method is learning an embedding for each graph object in a collection of graphs. In the example of molecular graph, our method is trying to learning representation for a molecule, while LINE, DeepWalk, node2vec are learning representation for an atom within the molecule."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Skip-graph: Learning graph embeddings with an encoder-decoder model", "abstract": "In this work, we study the problem of feature representation learning for graph-structured data. Many of the existing work in the area are task-specific and based on supervised techniques. We study a method for obtaining a generic feature representation for a graph using an unsupervised approach. The neural encoder-decoder model is a method that has been used in the natural language processing domain to learn feature representations of sentences. In our proposed approach, we train the encoder-decoder model to predict the random walk sequence of neighboring regions in a graph given a random walk along a particular region. The goal is to map subgraphs \u2014 as represented by their random walks \u2014 that are structurally and functionally similar to nearby locations in feature space. We evaluate the learned graph vectors using several real-world datasets on the graph classification task. The proposed model is able to achieve good results against state-of- the-art techniques.", "pdf": "/pdf/954ddff2afa7d65560f37fe0b0e1b08b0a75a739.pdf", "TL;DR": "An unsupervised method for generating graph feature representations based on the encoder-decoder model.", "paperhash": "lee|skipgraph_learning_graph_embeddings_with_an_encoderdecoder_model", "conflicts": ["cs.wpi.edu"], "authors": ["John Boaz Lee", "Xiangnan Kong"], "authorids": ["jtlee@wpi.edu", "xkong@wpi.edu"], "keywords": ["Unsupervised Learning", "Deep learning"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287657491, "id": "ICLR.cc/2017/conference/-/paper268/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "BkSqjHqxg", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper268/reviewers", "ICLR.cc/2017/conference/paper268/areachairs"], "cdate": 1485287657491}}}, {"tddate": null, "tmdate": 1478313108883, "tcdate": 1478313040871, "number": 1, "id": "HyFIVpclx", "invitation": "ICLR.cc/2017/conference/-/paper268/public/comment", "forum": "BkSqjHqxg", "replyto": "BkSqjHqxg", "signatures": ["(anonymous)"], "readers": ["everyone"], "writers": ["(anonymous)"], "content": {"title": "Baseline comparisons", "comment": "Hi,\n\nIn the abstract you have mentioned, \"Many of the existing work in the area are task-specific and based on supervised techniques\". I don't think this is a valid statement, since lot of recent work in graph embeddings is based on unsupervised methods. Like LINE and DeepWalk. \n\nAnd is there any particular reason you didn't compare your method with DeepWalk and LINE, considering the fact that they are state-of-the art methods in representation learning for graphs?\n\nRegards,"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Skip-graph: Learning graph embeddings with an encoder-decoder model", "abstract": "In this work, we study the problem of feature representation learning for graph-structured data. Many of the existing work in the area are task-specific and based on supervised techniques. We study a method for obtaining a generic feature representation for a graph using an unsupervised approach. The neural encoder-decoder model is a method that has been used in the natural language processing domain to learn feature representations of sentences. In our proposed approach, we train the encoder-decoder model to predict the random walk sequence of neighboring regions in a graph given a random walk along a particular region. The goal is to map subgraphs \u2014 as represented by their random walks \u2014 that are structurally and functionally similar to nearby locations in feature space. We evaluate the learned graph vectors using several real-world datasets on the graph classification task. The proposed model is able to achieve good results against state-of- the-art techniques.", "pdf": "/pdf/954ddff2afa7d65560f37fe0b0e1b08b0a75a739.pdf", "TL;DR": "An unsupervised method for generating graph feature representations based on the encoder-decoder model.", "paperhash": "lee|skipgraph_learning_graph_embeddings_with_an_encoderdecoder_model", "conflicts": ["cs.wpi.edu"], "authors": ["John Boaz Lee", "Xiangnan Kong"], "authorids": ["jtlee@wpi.edu", "xkong@wpi.edu"], "keywords": ["Unsupervised Learning", "Deep learning"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287657491, "id": "ICLR.cc/2017/conference/-/paper268/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "BkSqjHqxg", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper268/reviewers", "ICLR.cc/2017/conference/paper268/areachairs"], "cdate": 1485287657491}}}], "count": 19}