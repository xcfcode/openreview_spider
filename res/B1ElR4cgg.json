{"notes": [{"tddate": null, "replyto": null, "ddate": null, "tmdate": 1487693389326, "tcdate": 1478278635792, "number": 222, "id": "B1ElR4cgg", "invitation": "ICLR.cc/2017/conference/-/submission", "forum": "B1ElR4cgg", "signatures": ["~Mohamed_Ishmael_Belghazi1"], "readers": ["everyone"], "content": {"title": "Adversarially Learned Inference", "abstract": "We introduce the adversarially learned inference (ALI) model, which jointly\nlearns a generation network and an inference network using an adversarial\nprocess. The generation network maps samples from stochastic latent variables to\nthe data space while the inference network maps training examples in data space\nto the space of latent variables. An adversarial game is cast between these two\nnetworks and a discriminative network that is trained to distinguish between\njoint latent/data-space samples from the generative network and joint samples\nfrom the inference network.  We illustrate the ability of the model to learn\nmutually coherent inference and generation networks through the inspections of\nmodel samples and reconstructions and confirm the usefulness of the learned\nrepresentations by obtaining a performance competitive with other recent\napproaches on the semi-supervised SVHN task.", "pdf": "/pdf/7a3fa67c5f7f97e5095d822afd76a76eaf6b9551.pdf", "TL;DR": "We present and adverserially trained generative model with an inference network. Samples quality is high. Competitive semi-supervised results are achieved.", "paperhash": "dumoulin|adversarially_learned_inference", "conflicts": ["umontreal.ca"], "keywords": ["Computer vision", "Deep learning", "Unsupervised Learning", "Semi-Supervised Learning"], "authors": ["Vincent Dumoulin", "Ishmael Belghazi", "Ben Poole", "Alex Lamb", "Martin Arjovsky", "Olivier Mastropietro", "Aaron Courville"], "authorids": ["vincent.dumoulin@umontreal.ca", "ishmael.belghazi@gmail.com", "poole@cs.stanford.edu", "alex6200@gmail.com", "martinarjovsky@gmail.com", "oli.mastro@gmail.com", "aaron.courville@gmail.com"]}, "writers": [], "nonreaders": [], "details": {"replyCount": 16, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1475686800000, "tmdate": 1478287705855, "id": "ICLR.cc/2017/conference/-/submission", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/pcs"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": null, "replyto": null, "writers": {"values-regex": "~.*"}, "signatures": {"values-regex": "~.*", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"pdf": {"required": true, "order": 5, "description": "Either upload a PDF file or provide a direct link to your PDF on ArXiv (link must begin with http(s) and end with .pdf)", "value-regex": "upload|(http|https):\\/\\/.+\\.pdf"}, "title": {"required": true, "order": 1, "description": "Title of paper.", "value-regex": ".{1,250}"}, "abstract": {"required": true, "order": 4, "description": "Abstract of paper.", "value-regex": "[\\S\\s]{1,5000}"}, "authors": {"required": true, "order": 2, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of author names, as they appear in the paper."}, "conflicts": {"required": true, "order": 100, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of email domains of people who would have a conflict of interest in reviewing this paper, (e.g., cs.umass.edu;google.com, etc.)."}, "keywords": {"order": 6, "description": "Comma separated list of keywords.", "values-dropdown": ["Theory", "Computer vision", "Speech", "Natural language processing", "Deep learning", "Unsupervised Learning", "Supervised Learning", "Semi-Supervised Learning", "Reinforcement Learning", "Transfer Learning", "Multi-modal learning", "Applications", "Optimization", "Structured prediction", "Games"]}, "TL;DR": {"required": false, "order": 3, "description": "\"Too Long; Didn't Read\": a short sentence describing your paper", "value-regex": "[^\\n]{0,250}"}, "authorids": {"required": true, "order": 3, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of author email addresses, in the same order as above."}}}, "nonreaders": [], "noninvitees": [], "expdate": 1483462800000, "cdate": 1478287705855}}}, {"tddate": null, "ddate": null, "cdate": null, "tmdate": 1486396442958, "tcdate": 1486396442958, "number": 1, "id": "Sy7Qhz8_x", "invitation": "ICLR.cc/2017/conference/-/paper222/acceptance", "forum": "B1ElR4cgg", "replyto": "B1ElR4cgg", "signatures": ["ICLR.cc/2017/pcs"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/pcs"], "content": {"title": "ICLR committee final decision", "comment": "The reviewers were positive about this paper and agree that it will make a contribution to the community.", "decision": "Accept (Poster)"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Adversarially Learned Inference", "abstract": "We introduce the adversarially learned inference (ALI) model, which jointly\nlearns a generation network and an inference network using an adversarial\nprocess. The generation network maps samples from stochastic latent variables to\nthe data space while the inference network maps training examples in data space\nto the space of latent variables. An adversarial game is cast between these two\nnetworks and a discriminative network that is trained to distinguish between\njoint latent/data-space samples from the generative network and joint samples\nfrom the inference network.  We illustrate the ability of the model to learn\nmutually coherent inference and generation networks through the inspections of\nmodel samples and reconstructions and confirm the usefulness of the learned\nrepresentations by obtaining a performance competitive with other recent\napproaches on the semi-supervised SVHN task.", "pdf": "/pdf/7a3fa67c5f7f97e5095d822afd76a76eaf6b9551.pdf", "TL;DR": "We present and adverserially trained generative model with an inference network. Samples quality is high. Competitive semi-supervised results are achieved.", "paperhash": "dumoulin|adversarially_learned_inference", "conflicts": ["umontreal.ca"], "keywords": ["Computer vision", "Deep learning", "Unsupervised Learning", "Semi-Supervised Learning"], "authors": ["Vincent Dumoulin", "Ishmael Belghazi", "Ben Poole", "Alex Lamb", "Martin Arjovsky", "Olivier Mastropietro", "Aaron Courville"], "authorids": ["vincent.dumoulin@umontreal.ca", "ishmael.belghazi@gmail.com", "poole@cs.stanford.edu", "alex6200@gmail.com", "martinarjovsky@gmail.com", "oli.mastro@gmail.com", "aaron.courville@gmail.com"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1486396443507, "id": "ICLR.cc/2017/conference/-/paper222/acceptance", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/pcs"], "noninvitees": ["ICLR.cc/2017/pcs"], "reply": {"forum": "B1ElR4cgg", "replyto": "B1ElR4cgg", "writers": {"values-regex": "ICLR.cc/2017/pcs"}, "signatures": {"values-regex": "ICLR.cc/2017/pcs", "description": "Your displayed identity associated with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your decision.", "value": "ICLR committee final decision"}, "comment": {"required": true, "order": 2, "description": "Decision comments.", "value-regex": "[\\S\\s]{1,5000}"}, "decision": {"required": true, "order": 3, "value-radio": ["Accept (Oral)", "Accept (Poster)", "Reject", "Invite to Workshop Track"]}}}, "nonreaders": [], "cdate": 1486396443507}}}, {"tddate": null, "tmdate": 1484940962917, "tcdate": 1482186556422, "number": 2, "id": "SJ4HkJ8Vl", "invitation": "ICLR.cc/2017/conference/-/paper222/official/review", "forum": "B1ElR4cgg", "replyto": "B1ElR4cgg", "signatures": ["ICLR.cc/2017/conference/paper222/AnonReviewer1"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/conference/paper222/AnonReviewer1"], "content": {"title": "official review", "rating": "7: Good paper, accept", "review": "After reading the rebuttal, I decided to increase my score. I think ALI somehow stabilizes the GAN training as demonstrated in Fig. 8 and learns a reasonable inference network.\n\n---------------\nInitial Review:\n\nThis paper proposes a new method for learning an inference network in the GAN framework. ALI's objective is to match the joint distribution of hidden and visible units imposed by an encoder and decoder network. ALI is trained on multiple datasets, and it seems to have a good reconstruction even though it does not have an explicit reconstruction term in the cost function. This shows it is learning a decent inference network for GAN.\n\nThere are currently many ways to learn an inference network for GANs: One can learn an inference network after training the GAN by sampling from the GAN and learning a separate network to map X to Z. There is also the infoGAN approach (not cited) which trains the inference network at the same time with the generative path. I think this paper should have an extensive comparison with these other methods and have a discussion for why ALI's inference network is superior to previous works.\n\nSince ALI's inference network is stochastic, it would be great if different reconstructions of a same image is included. I believe the inference network of the BiGAN paper is deterministic which is the main difference with this work. So maybe it is worth highlighting this difference.\n\nThe quality of samples is very good, but there is no quantitative experiment to compare ALI's samples with other GAN variants. So I am not sure if learning an inference network has contributed to better generative samples. Maybe including an inception score for comparison can help.\n\nThere are two sets of semi-supervised results: \nThe first one concatenate the hidden layers of the inference network and uses an L2-SVM afterwards. Ideally, concatenating feature maps is not the best way for semi-supervised learning and one would want to train the semi-supervised path at the same time with the generative path. It would have been much more interesting if part of the hidden code was a categorical distribution and another part of it was a continuous distribution like Gaussian, and the inference network on the categorical latent variable was used directly for classification (like semi-supervised VAE). In this case, the inference network would be trained at the same time with the generative path. Also if the authors can show that ALI can disentangle factors of variations with a discrete latent variable like infoGAN, it will significantly improve the quality of the paper.\n\nThe second semi-supervised learning results show that ALI can match the state-of-the-art. But my impression is that the significant gain is mainly coming from the adaptation of Salimans et al. (2016) in which the discriminator is used for classification. It is unclear to me why learning an inference network help the discriminator do a better job in classification. How do we know the proposed method is improving the stability of the GAN? My understanding is that one of the main points of learning an inference network is to learn a mapping from the image to the high-level features such as class labels. So it would have been more interesting if the inference path was directly used for semi-supervised learning as I explained above.", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Adversarially Learned Inference", "abstract": "We introduce the adversarially learned inference (ALI) model, which jointly\nlearns a generation network and an inference network using an adversarial\nprocess. The generation network maps samples from stochastic latent variables to\nthe data space while the inference network maps training examples in data space\nto the space of latent variables. An adversarial game is cast between these two\nnetworks and a discriminative network that is trained to distinguish between\njoint latent/data-space samples from the generative network and joint samples\nfrom the inference network.  We illustrate the ability of the model to learn\nmutually coherent inference and generation networks through the inspections of\nmodel samples and reconstructions and confirm the usefulness of the learned\nrepresentations by obtaining a performance competitive with other recent\napproaches on the semi-supervised SVHN task.", "pdf": "/pdf/7a3fa67c5f7f97e5095d822afd76a76eaf6b9551.pdf", "TL;DR": "We present and adverserially trained generative model with an inference network. Samples quality is high. Competitive semi-supervised results are achieved.", "paperhash": "dumoulin|adversarially_learned_inference", "conflicts": ["umontreal.ca"], "keywords": ["Computer vision", "Deep learning", "Unsupervised Learning", "Semi-Supervised Learning"], "authors": ["Vincent Dumoulin", "Ishmael Belghazi", "Ben Poole", "Alex Lamb", "Martin Arjovsky", "Olivier Mastropietro", "Aaron Courville"], "authorids": ["vincent.dumoulin@umontreal.ca", "ishmael.belghazi@gmail.com", "poole@cs.stanford.edu", "alex6200@gmail.com", "martinarjovsky@gmail.com", "oli.mastro@gmail.com", "aaron.courville@gmail.com"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1481932799000, "tmdate": 1482512658098, "id": "ICLR.cc/2017/conference/-/paper222/official/review", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/conference/paper222/reviewers"], "noninvitees": ["ICLR.cc/2017/conference/paper222/AnonReviewer3", "ICLR.cc/2017/conference/paper222/AnonReviewer1", "ICLR.cc/2017/conference/paper222/AnonReviewer2"], "reply": {"forum": "B1ElR4cgg", "replyto": "B1ElR4cgg", "writers": {"values-regex": "ICLR.cc/2017/conference/paper222/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/conference/paper222/AnonReviewer[0-9]+"}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "value-regex": "[\\S\\s]{1,20000}"}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1489708799000, "cdate": 1482512658098}}}, {"tddate": null, "tmdate": 1484590866235, "tcdate": 1484590866235, "number": 10, "id": "Sk5zkq5Ul", "invitation": "ICLR.cc/2017/conference/-/paper222/public/comment", "forum": "B1ElR4cgg", "replyto": "B1ElR4cgg", "signatures": ["~Vincent_Dumoulin1"], "readers": ["everyone"], "writers": ["~Vincent_Dumoulin1"], "content": {"title": "Submission updated", "comment": "We recently updated the submission taking the reviewers' comments into account. The main change is the addition of a section discussing alternative approaches to feedforward inference in GANs and section with a toy experiment comparing ALI's behaviour with those approaches."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Adversarially Learned Inference", "abstract": "We introduce the adversarially learned inference (ALI) model, which jointly\nlearns a generation network and an inference network using an adversarial\nprocess. The generation network maps samples from stochastic latent variables to\nthe data space while the inference network maps training examples in data space\nto the space of latent variables. An adversarial game is cast between these two\nnetworks and a discriminative network that is trained to distinguish between\njoint latent/data-space samples from the generative network and joint samples\nfrom the inference network.  We illustrate the ability of the model to learn\nmutually coherent inference and generation networks through the inspections of\nmodel samples and reconstructions and confirm the usefulness of the learned\nrepresentations by obtaining a performance competitive with other recent\napproaches on the semi-supervised SVHN task.", "pdf": "/pdf/7a3fa67c5f7f97e5095d822afd76a76eaf6b9551.pdf", "TL;DR": "We present and adverserially trained generative model with an inference network. Samples quality is high. Competitive semi-supervised results are achieved.", "paperhash": "dumoulin|adversarially_learned_inference", "conflicts": ["umontreal.ca"], "keywords": ["Computer vision", "Deep learning", "Unsupervised Learning", "Semi-Supervised Learning"], "authors": ["Vincent Dumoulin", "Ishmael Belghazi", "Ben Poole", "Alex Lamb", "Martin Arjovsky", "Olivier Mastropietro", "Aaron Courville"], "authorids": ["vincent.dumoulin@umontreal.ca", "ishmael.belghazi@gmail.com", "poole@cs.stanford.edu", "alex6200@gmail.com", "martinarjovsky@gmail.com", "oli.mastro@gmail.com", "aaron.courville@gmail.com"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287677630, "id": "ICLR.cc/2017/conference/-/paper222/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "B1ElR4cgg", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper222/reviewers", "ICLR.cc/2017/conference/paper222/areachairs"], "cdate": 1485287677630}}}, {"tddate": null, "tmdate": 1484328752141, "tcdate": 1484328752141, "number": 9, "id": "rJ_4JqL8x", "invitation": "ICLR.cc/2017/conference/-/paper222/public/comment", "forum": "B1ElR4cgg", "replyto": "r1zt4GhNx", "signatures": ["~Olivier_Mastropietro1"], "readers": ["everyone"], "writers": ["~Olivier_Mastropietro1"], "content": {"title": "Response to (anonymous)", "comment": "Good point! It might not be clearly specified, but the architectures in the appendix were not used for semi-supervised learning. For comparison with Salisman et al. model, we used an architecture very close to theirs. The differences are that we need to accomodate the encoder. This results in a ConvNet which has exactly the same structure (reversed order of feature maps, nonlinearities, etc) as their generator and with convolution instead of deconvolution. There is also a very small amount of extra parameters added into their discriminator to take this into account. Also, we did stop training at 1200 epochs and the 6475 mentionned in the appendix is for the samples in the purely unsupervised setting."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Adversarially Learned Inference", "abstract": "We introduce the adversarially learned inference (ALI) model, which jointly\nlearns a generation network and an inference network using an adversarial\nprocess. The generation network maps samples from stochastic latent variables to\nthe data space while the inference network maps training examples in data space\nto the space of latent variables. An adversarial game is cast between these two\nnetworks and a discriminative network that is trained to distinguish between\njoint latent/data-space samples from the generative network and joint samples\nfrom the inference network.  We illustrate the ability of the model to learn\nmutually coherent inference and generation networks through the inspections of\nmodel samples and reconstructions and confirm the usefulness of the learned\nrepresentations by obtaining a performance competitive with other recent\napproaches on the semi-supervised SVHN task.", "pdf": "/pdf/7a3fa67c5f7f97e5095d822afd76a76eaf6b9551.pdf", "TL;DR": "We present and adverserially trained generative model with an inference network. Samples quality is high. Competitive semi-supervised results are achieved.", "paperhash": "dumoulin|adversarially_learned_inference", "conflicts": ["umontreal.ca"], "keywords": ["Computer vision", "Deep learning", "Unsupervised Learning", "Semi-Supervised Learning"], "authors": ["Vincent Dumoulin", "Ishmael Belghazi", "Ben Poole", "Alex Lamb", "Martin Arjovsky", "Olivier Mastropietro", "Aaron Courville"], "authorids": ["vincent.dumoulin@umontreal.ca", "ishmael.belghazi@gmail.com", "poole@cs.stanford.edu", "alex6200@gmail.com", "martinarjovsky@gmail.com", "oli.mastro@gmail.com", "aaron.courville@gmail.com"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287677630, "id": "ICLR.cc/2017/conference/-/paper222/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "B1ElR4cgg", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper222/reviewers", "ICLR.cc/2017/conference/paper222/areachairs"], "cdate": 1485287677630}}}, {"tddate": null, "tmdate": 1482593401856, "tcdate": 1482593401856, "number": 8, "id": "r1zt4GhNx", "invitation": "ICLR.cc/2017/conference/-/paper222/public/comment", "forum": "B1ElR4cgg", "replyto": "H1d32I-Ee", "signatures": ["(anonymous)"], "readers": ["everyone"], "writers": ["(anonymous)"], "content": {"title": "Comparison with Salismans et al.", "comment": "Great paper! I really enjoyed reading it. \nThe comparison with Salismans et al. might be a little unfair. ALI [1] was trained for 6475 epochs (which is a pretty large number I believe) whereas the Salisman et al. model [2] was trained for 1200 epochs only. \n\nI'm curious about how much of the improvement in the sample quality for cifar10 is because of the model being better and how much of it is due to the longer training regime.\n\nWould it be possible for the authors to share a graph of the Discriminator and Generator losses versus training progress? It would probably help us understand how important it was to run the training procedure for 6475 epochs (which seems like a rather large number). \n\n[1]: https://github.com/IshmaelBelghazi/ALI/blob/master/experiments/ali_cifar10.py#L28\n[2]: https://github.com/openai/improved-gan/blob/master/mnist_svhn_cifar10/train_cifar_feature_matching.py#L130"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Adversarially Learned Inference", "abstract": "We introduce the adversarially learned inference (ALI) model, which jointly\nlearns a generation network and an inference network using an adversarial\nprocess. The generation network maps samples from stochastic latent variables to\nthe data space while the inference network maps training examples in data space\nto the space of latent variables. An adversarial game is cast between these two\nnetworks and a discriminative network that is trained to distinguish between\njoint latent/data-space samples from the generative network and joint samples\nfrom the inference network.  We illustrate the ability of the model to learn\nmutually coherent inference and generation networks through the inspections of\nmodel samples and reconstructions and confirm the usefulness of the learned\nrepresentations by obtaining a performance competitive with other recent\napproaches on the semi-supervised SVHN task.", "pdf": "/pdf/7a3fa67c5f7f97e5095d822afd76a76eaf6b9551.pdf", "TL;DR": "We present and adverserially trained generative model with an inference network. Samples quality is high. Competitive semi-supervised results are achieved.", "paperhash": "dumoulin|adversarially_learned_inference", "conflicts": ["umontreal.ca"], "keywords": ["Computer vision", "Deep learning", "Unsupervised Learning", "Semi-Supervised Learning"], "authors": ["Vincent Dumoulin", "Ishmael Belghazi", "Ben Poole", "Alex Lamb", "Martin Arjovsky", "Olivier Mastropietro", "Aaron Courville"], "authorids": ["vincent.dumoulin@umontreal.ca", "ishmael.belghazi@gmail.com", "poole@cs.stanford.edu", "alex6200@gmail.com", "martinarjovsky@gmail.com", "oli.mastro@gmail.com", "aaron.courville@gmail.com"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287677630, "id": "ICLR.cc/2017/conference/-/paper222/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "B1ElR4cgg", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper222/reviewers", "ICLR.cc/2017/conference/paper222/areachairs"], "cdate": 1485287677630}}}, {"tddate": null, "tmdate": 1482523741806, "tcdate": 1482523741806, "number": 7, "id": "rkLwVWjEx", "invitation": "ICLR.cc/2017/conference/-/paper222/public/comment", "forum": "B1ElR4cgg", "replyto": "SJ4HkJ8Vl", "signatures": ["~Vincent_Dumoulin1"], "readers": ["everyone"], "writers": ["~Vincent_Dumoulin1"], "content": {"title": "Response to AnonReviewer1", "comment": "We thank you for you feedback.\n\nREVIEWER POINT\n\n\u201cI think this paper should have an extensive comparison with these other methods and have a discussion for why ALI's inference network is superior to previous works.\u201d\n\nRESPONSE\n\nThe reviewer raises an important and salient point that, while we have shown that ALI does learn to do inference reasonably well, the paper doesn\u2019t do enough to directly compare with alternative ways of doing feedforward inference in a GAN setting. To address these concerns, we will shortly add two new sections to the paper: (1) a review of alternative approaches and (2) a new experiment to highlight the role of the inference network during learning. These additions are summarized below.\n\nHere is a list of alternative approaches and why they may or may not be fit for comparison with ALI:\n\n* Learning the inverse mapping from GAN samples: This corresponds to learning an encoder to reconstruct Z, i.e. encode(decode(Z ~ p(Z))) ~= Z. We are not aware of any work that reports results for this approach. Could you point out to such work if it exists?\n\n* InfoGAN: While InfoGAN should be cited as related work, InfoGAN actually does not do inference, it only estimates the discrete latent code which describes specific aspects of the image.  This is why the InfoGAN paper doesn\u2019t show any reconstructions, rather it shows generated samples where they vary the latent code. Additionally, InfoGAN uses a fixed reconstruction cost for the latent code C and requires a tractable approximate posterior, q(C|X), that can be sampled from and evaluated. ALI only requires that inference networks can be sampled from, allowing it to represent arbitrarily complex posterior distributions. Combining InfoGAN and ALI could be an exciting area for future work.\n\n* Post-hoc learned inference: As verification that learning inference jointly with generation is beneficial, one can first train a GAN and then freeze the decoder and learn the encoder using the procedure proposed by ALI. In this setting, the encoder and the decoder cannot interact together during training and the encoder must work with whatever the decoder has learned during GAN training.\n\nTo address this point we performed an experiment on a toy dataset for which q(X) is a 2D gaussian mixture with 25 mixture components laid out on a grid. The covariance matrices and centroids have been chosen such that the distribution exhibits lots of modes separated by large low-probability regions, which makes it a decently hard task despite the 2D nature of the dataset.\nWe trained ALI and GAN on 100,000 q(X) samples. The decoder and discriminator architectures are identical between ALI and GAN. Each model was trained 10 times using Adam with random learning rate and beta_1 values, and the weights were initialized by drawing from a gaussian distribution with a random standard deviation.\n\nWe measured the extent to which the trained models covered all 25 modes by drawing 10,000 samples from their p(X) distribution and assigning each sample to a q(X) mixture component according to the mixture responsibilities. We defined a dropped mode as one that wasn\u2019t assigned to *any* sample (which is a generous definition). Using this definition, we found that ALI models covered 13.4 \u00b1 5.8 modes on average (min: 8, max: 25) while GAN models covered 10.4 \u00b1 9.2 modes on average (min: 1, max: 22).\n\nWe then selected the best-covering ALI and GAN models, and the GAN model was augmented with the following inference mechanisms:\n\n* Learned inverse mapping\n\n* Post-hoc learned inference\n\nThe encoders learned for GAN inference have the same architecture as ALI\u2019s encoder. We then compared each model\u2019s inference capabilities by reconstructing 10,000 held-out samples from q(X).\n\nA figure summarizing the experiment can be found at https://raw.githubusercontent.com/IshmaelBelghazi/ALI/master/paper/mixture_plot.png.\n\nThe three columns correspond to the three different strategies for learning inference:\n\n1. ALI (our proposed strategy).\n\n2. Learning an inverse mapping from GAN samples.\n\n3. Post-hoc learned inference\n\nThe five rows correspond to:\n\n1. X ~ q(X) samples, i.e. test set examples, colour-coded by mixture component. They're the same for all three columns.\n\n2. Z_hat ~ q(Z | X) samples, i.e. the latent codes, also colour-coded.\n\n3. X_hat ~ p(X | Z = Z_hat) samples, i.e. the reconstructions, also colour-coded.\n\n4. Z ~ p(Z) samples, i.e. prior samples. They're the same for all three columns.\n\n5. X_tilde ~ p(X | Z) samples, i.e. generator samples.\n\nHere is what we observe:\n\n* The ALI encoder models a marginal distribution q(Z) that matches p(Z) fairly well (row 2, column 1). The learned representation does a decent job at clustering and organizing the different mixture components.\n\n* The GAN generator (row 5, columns 2-3) has more trouble reaching all the modes than the ALI generator (row 5, column 1), even over 10 runs of hyperparameter search.\n\n* Learning an inverse mapping from GAN samples does not work very well: the encoder has trouble covering the prior marginally and the way it clusters mixture components is not very well organized (row 2, column 2).\n\n* Learning inference post-hoc doesn't work as well as training the encoder and the decoder jointly. As had been discussed above, it appears that adversarial training benefits from learning inference at training time in terms of mode coverage. This also negatively impacts how the latent space is organized (row 2, column 3). However, it appears to be better at matching q(Z) and p(Z) than when inference is learned through inverse mapping from GAN samples.\n\nTo summarize, this experiment provides evidence that adversarial training benefits from learning an inference mechanism jointly with the decoder. Furthermore, it shows that our proposed approach for learning inference in an adversarial setting is superior to the other approaches investigated.\n\nWe will update the manuscript shortly to incorporate these additional results and cite the appropriate relevant work.\n\nREVIEWER POINT\n\n\u201cSince ALI's inference network is stochastic, it would be great if different reconstructions of a same image is included. I believe the inference network of the BiGAN paper is deterministic which is the main difference with this work. So maybe it is worth highlighting this difference.\u201d\n\nRESPONSE\n\nOur experience is that the added stochasticity does not make much of a difference: at the end of training, very little noise ends up being injected at the encoder\u2019s output. This falls in line with the invertibility results derived by Donahue et al. (2016).\n \nWe agree that left unexplained, this difference may confuse readers and we will update the manuscript to address this question.\n\nREVIEWER POINT\n\n\u201cThe quality of samples is very good, but there is no quantitative experiment to compare ALI's samples with other GAN variants. So I am not sure if learning an inference network has contributed to better generative samples. Maybe including an inception score for comparison can help.\u201d\n\nRESPONSE\n\nWe do not claim that learning an inference network contributes to better generative samples, simply that doing so does not come at the expense of sample quality. However, as explained above, experiments on a toy dataset suggest that ALI is better at mode coverage than GAN.\n\nRegarding the use of the Inception score, we are hesitant to use it, as Odena et al. (2016) [1] found that \u201c[the] Inception accuracy can not measure whether a model has collapsed. A model that simply memorized one example from each ImageNet class would do very well by this metric.\u201d\n\nREVIEWER POINT\n\n\u201cThere are two sets of semi-supervised results [...]\u201d\n\nRESPONSE\n\nThe point which we try to make with the semi-supervised results is that: \n\n* In the first method, one can train a shallow classifier using learned features from an unsupervised model.  We used the *exact same* procedure as DCGAN to build an L2-SVM on top of existing features, with the exception that the features were taken from the inference network\u2019s high-level representation as opposed to the discriminator.  In this case ALI outperformed the results reported in the DCGAN paper, which suggests that for this procedure the inference network buys us something over the discriminator. To ensure that the comparison is fair, we are currently running an experiment in which DCGAN and ALI share the same architecture. We will update the manuscript when it is complete.\n\n* In the second method, one co-trains the discriminator for label classification. With this procedure ALI matches the more recent \u201cImproved methods for training GANs\u201d results while using a simpler architecture (no feature matching). In this setting, the inference network *is* used, as it provides one of the two inputs which the discriminator uses to produce its prediction.\n\nWhile an inference network on categorical variables like in semi-supervised VAEs does sound elegant and straightforward, it is not directly applicable to ALI. Like GANs, ALI requires that the conditional distributions p(x | z) and q(z | x) can be sampled from in a way that allows gradient backpropagation, which cannot be achieved in a straightforward manner using discrete random variables.\n\n[1] Odena, A., Olah, C., & Shlens, J. (2016). Conditional Image Synthesis With Auxiliary Classifier GANs. arXiv preprint arXiv:1610.09585."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Adversarially Learned Inference", "abstract": "We introduce the adversarially learned inference (ALI) model, which jointly\nlearns a generation network and an inference network using an adversarial\nprocess. The generation network maps samples from stochastic latent variables to\nthe data space while the inference network maps training examples in data space\nto the space of latent variables. An adversarial game is cast between these two\nnetworks and a discriminative network that is trained to distinguish between\njoint latent/data-space samples from the generative network and joint samples\nfrom the inference network.  We illustrate the ability of the model to learn\nmutually coherent inference and generation networks through the inspections of\nmodel samples and reconstructions and confirm the usefulness of the learned\nrepresentations by obtaining a performance competitive with other recent\napproaches on the semi-supervised SVHN task.", "pdf": "/pdf/7a3fa67c5f7f97e5095d822afd76a76eaf6b9551.pdf", "TL;DR": "We present and adverserially trained generative model with an inference network. Samples quality is high. Competitive semi-supervised results are achieved.", "paperhash": "dumoulin|adversarially_learned_inference", "conflicts": ["umontreal.ca"], "keywords": ["Computer vision", "Deep learning", "Unsupervised Learning", "Semi-Supervised Learning"], "authors": ["Vincent Dumoulin", "Ishmael Belghazi", "Ben Poole", "Alex Lamb", "Martin Arjovsky", "Olivier Mastropietro", "Aaron Courville"], "authorids": ["vincent.dumoulin@umontreal.ca", "ishmael.belghazi@gmail.com", "poole@cs.stanford.edu", "alex6200@gmail.com", "martinarjovsky@gmail.com", "oli.mastro@gmail.com", "aaron.courville@gmail.com"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287677630, "id": "ICLR.cc/2017/conference/-/paper222/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "B1ElR4cgg", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper222/reviewers", "ICLR.cc/2017/conference/paper222/areachairs"], "cdate": 1485287677630}}}, {"tddate": null, "tmdate": 1482521818452, "tcdate": 1482521818452, "number": 6, "id": "BkfkpgoNe", "invitation": "ICLR.cc/2017/conference/-/paper222/public/comment", "forum": "B1ElR4cgg", "replyto": "H1d32I-Ee", "signatures": ["~Vincent_Dumoulin1"], "readers": ["everyone"], "writers": ["~Vincent_Dumoulin1"], "content": {"title": "Response to AnonReviewer3", "comment": "We thank you for your feedback."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Adversarially Learned Inference", "abstract": "We introduce the adversarially learned inference (ALI) model, which jointly\nlearns a generation network and an inference network using an adversarial\nprocess. The generation network maps samples from stochastic latent variables to\nthe data space while the inference network maps training examples in data space\nto the space of latent variables. An adversarial game is cast between these two\nnetworks and a discriminative network that is trained to distinguish between\njoint latent/data-space samples from the generative network and joint samples\nfrom the inference network.  We illustrate the ability of the model to learn\nmutually coherent inference and generation networks through the inspections of\nmodel samples and reconstructions and confirm the usefulness of the learned\nrepresentations by obtaining a performance competitive with other recent\napproaches on the semi-supervised SVHN task.", "pdf": "/pdf/7a3fa67c5f7f97e5095d822afd76a76eaf6b9551.pdf", "TL;DR": "We present and adverserially trained generative model with an inference network. Samples quality is high. Competitive semi-supervised results are achieved.", "paperhash": "dumoulin|adversarially_learned_inference", "conflicts": ["umontreal.ca"], "keywords": ["Computer vision", "Deep learning", "Unsupervised Learning", "Semi-Supervised Learning"], "authors": ["Vincent Dumoulin", "Ishmael Belghazi", "Ben Poole", "Alex Lamb", "Martin Arjovsky", "Olivier Mastropietro", "Aaron Courville"], "authorids": ["vincent.dumoulin@umontreal.ca", "ishmael.belghazi@gmail.com", "poole@cs.stanford.edu", "alex6200@gmail.com", "martinarjovsky@gmail.com", "oli.mastro@gmail.com", "aaron.courville@gmail.com"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287677630, "id": "ICLR.cc/2017/conference/-/paper222/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "B1ElR4cgg", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper222/reviewers", "ICLR.cc/2017/conference/paper222/areachairs"], "cdate": 1485287677630}}}, {"tddate": null, "tmdate": 1482521769049, "tcdate": 1482521769049, "number": 5, "id": "Bk-h2liEl", "invitation": "ICLR.cc/2017/conference/-/paper222/public/comment", "forum": "B1ElR4cgg", "replyto": "HJpxUk8Eg", "signatures": ["~Vincent_Dumoulin1"], "readers": ["everyone"], "writers": ["~Vincent_Dumoulin1"], "content": {"title": "Response to AnonReviewer2", "comment": "We thank you for your review."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Adversarially Learned Inference", "abstract": "We introduce the adversarially learned inference (ALI) model, which jointly\nlearns a generation network and an inference network using an adversarial\nprocess. The generation network maps samples from stochastic latent variables to\nthe data space while the inference network maps training examples in data space\nto the space of latent variables. An adversarial game is cast between these two\nnetworks and a discriminative network that is trained to distinguish between\njoint latent/data-space samples from the generative network and joint samples\nfrom the inference network.  We illustrate the ability of the model to learn\nmutually coherent inference and generation networks through the inspections of\nmodel samples and reconstructions and confirm the usefulness of the learned\nrepresentations by obtaining a performance competitive with other recent\napproaches on the semi-supervised SVHN task.", "pdf": "/pdf/7a3fa67c5f7f97e5095d822afd76a76eaf6b9551.pdf", "TL;DR": "We present and adverserially trained generative model with an inference network. Samples quality is high. Competitive semi-supervised results are achieved.", "paperhash": "dumoulin|adversarially_learned_inference", "conflicts": ["umontreal.ca"], "keywords": ["Computer vision", "Deep learning", "Unsupervised Learning", "Semi-Supervised Learning"], "authors": ["Vincent Dumoulin", "Ishmael Belghazi", "Ben Poole", "Alex Lamb", "Martin Arjovsky", "Olivier Mastropietro", "Aaron Courville"], "authorids": ["vincent.dumoulin@umontreal.ca", "ishmael.belghazi@gmail.com", "poole@cs.stanford.edu", "alex6200@gmail.com", "martinarjovsky@gmail.com", "oli.mastro@gmail.com", "aaron.courville@gmail.com"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287677630, "id": "ICLR.cc/2017/conference/-/paper222/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "B1ElR4cgg", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper222/reviewers", "ICLR.cc/2017/conference/paper222/areachairs"], "cdate": 1485287677630}}}, {"tddate": null, "tmdate": 1482188276734, "tcdate": 1482188276734, "number": 3, "id": "HJpxUk8Eg", "invitation": "ICLR.cc/2017/conference/-/paper222/official/review", "forum": "B1ElR4cgg", "replyto": "B1ElR4cgg", "signatures": ["ICLR.cc/2017/conference/paper222/AnonReviewer2"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/conference/paper222/AnonReviewer2"], "content": {"title": "", "rating": "7: Good paper, accept", "review": "This is a parallel work with BiGAN.  The idea is using auto encoder to provide extra information for discriminator. This approach seems is promising from reported result.", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Adversarially Learned Inference", "abstract": "We introduce the adversarially learned inference (ALI) model, which jointly\nlearns a generation network and an inference network using an adversarial\nprocess. The generation network maps samples from stochastic latent variables to\nthe data space while the inference network maps training examples in data space\nto the space of latent variables. An adversarial game is cast between these two\nnetworks and a discriminative network that is trained to distinguish between\njoint latent/data-space samples from the generative network and joint samples\nfrom the inference network.  We illustrate the ability of the model to learn\nmutually coherent inference and generation networks through the inspections of\nmodel samples and reconstructions and confirm the usefulness of the learned\nrepresentations by obtaining a performance competitive with other recent\napproaches on the semi-supervised SVHN task.", "pdf": "/pdf/7a3fa67c5f7f97e5095d822afd76a76eaf6b9551.pdf", "TL;DR": "We present and adverserially trained generative model with an inference network. Samples quality is high. Competitive semi-supervised results are achieved.", "paperhash": "dumoulin|adversarially_learned_inference", "conflicts": ["umontreal.ca"], "keywords": ["Computer vision", "Deep learning", "Unsupervised Learning", "Semi-Supervised Learning"], "authors": ["Vincent Dumoulin", "Ishmael Belghazi", "Ben Poole", "Alex Lamb", "Martin Arjovsky", "Olivier Mastropietro", "Aaron Courville"], "authorids": ["vincent.dumoulin@umontreal.ca", "ishmael.belghazi@gmail.com", "poole@cs.stanford.edu", "alex6200@gmail.com", "martinarjovsky@gmail.com", "oli.mastro@gmail.com", "aaron.courville@gmail.com"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1481932799000, "tmdate": 1482512658098, "id": "ICLR.cc/2017/conference/-/paper222/official/review", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/conference/paper222/reviewers"], "noninvitees": ["ICLR.cc/2017/conference/paper222/AnonReviewer3", "ICLR.cc/2017/conference/paper222/AnonReviewer1", "ICLR.cc/2017/conference/paper222/AnonReviewer2"], "reply": {"forum": "B1ElR4cgg", "replyto": "B1ElR4cgg", "writers": {"values-regex": "ICLR.cc/2017/conference/paper222/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/conference/paper222/AnonReviewer[0-9]+"}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "value-regex": "[\\S\\s]{1,20000}"}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1489708799000, "cdate": 1482512658098}}}, {"tddate": null, "tmdate": 1481890992184, "tcdate": 1481890992184, "number": 1, "id": "H1d32I-Ee", "invitation": "ICLR.cc/2017/conference/-/paper222/official/review", "forum": "B1ElR4cgg", "replyto": "B1ElR4cgg", "signatures": ["ICLR.cc/2017/conference/paper222/AnonReviewer3"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/conference/paper222/AnonReviewer3"], "content": {"title": "interesting extension of GANs, promising results", "rating": "8: Top 50% of accepted papers, clear accept", "review": "This paper extends the GAN framework to allow for latent variables. The observed data set is expanded by drawing latent variables z from a conditional distribution q(z|x). The joint distribution on x,z is then modeled using a joint generator model p(x,z)=p(z)p(x|z).  Both q and p are then trained by trying to fool a discriminator. This constitutes a worthwhile extension of GANs: giving GANs the ability to do inference opens up many applications that could previously only be addressed by e.g. VAEs.\n\nThe results are very promising. The CIFAR-10 samples are the best I've seen so far (not counting methods that use class labels). Matching the semi-supervised results from Salimans et al. without feature matching also indicates the proposed method may improve the stability of training GANs.", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Adversarially Learned Inference", "abstract": "We introduce the adversarially learned inference (ALI) model, which jointly\nlearns a generation network and an inference network using an adversarial\nprocess. The generation network maps samples from stochastic latent variables to\nthe data space while the inference network maps training examples in data space\nto the space of latent variables. An adversarial game is cast between these two\nnetworks and a discriminative network that is trained to distinguish between\njoint latent/data-space samples from the generative network and joint samples\nfrom the inference network.  We illustrate the ability of the model to learn\nmutually coherent inference and generation networks through the inspections of\nmodel samples and reconstructions and confirm the usefulness of the learned\nrepresentations by obtaining a performance competitive with other recent\napproaches on the semi-supervised SVHN task.", "pdf": "/pdf/7a3fa67c5f7f97e5095d822afd76a76eaf6b9551.pdf", "TL;DR": "We present and adverserially trained generative model with an inference network. Samples quality is high. Competitive semi-supervised results are achieved.", "paperhash": "dumoulin|adversarially_learned_inference", "conflicts": ["umontreal.ca"], "keywords": ["Computer vision", "Deep learning", "Unsupervised Learning", "Semi-Supervised Learning"], "authors": ["Vincent Dumoulin", "Ishmael Belghazi", "Ben Poole", "Alex Lamb", "Martin Arjovsky", "Olivier Mastropietro", "Aaron Courville"], "authorids": ["vincent.dumoulin@umontreal.ca", "ishmael.belghazi@gmail.com", "poole@cs.stanford.edu", "alex6200@gmail.com", "martinarjovsky@gmail.com", "oli.mastro@gmail.com", "aaron.courville@gmail.com"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1481932799000, "tmdate": 1482512658098, "id": "ICLR.cc/2017/conference/-/paper222/official/review", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/conference/paper222/reviewers"], "noninvitees": ["ICLR.cc/2017/conference/paper222/AnonReviewer3", "ICLR.cc/2017/conference/paper222/AnonReviewer1", "ICLR.cc/2017/conference/paper222/AnonReviewer2"], "reply": {"forum": "B1ElR4cgg", "replyto": "B1ElR4cgg", "writers": {"values-regex": "ICLR.cc/2017/conference/paper222/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/conference/paper222/AnonReviewer[0-9]+"}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "value-regex": "[\\S\\s]{1,20000}"}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1489708799000, "cdate": 1482512658098}}}, {"tddate": null, "tmdate": 1481658254737, "tcdate": 1481658254732, "number": 4, "id": "BkwcJR6mx", "invitation": "ICLR.cc/2017/conference/-/paper222/public/comment", "forum": "B1ElR4cgg", "replyto": "SJZmHKuQe", "signatures": ["~Vincent_Dumoulin1"], "readers": ["everyone"], "writers": ["~Vincent_Dumoulin1"], "content": {"title": "Clarifications", "comment": "Thank you for your questions.\n\n1) The adaptation of the Salimans et al. (2016) method is what is responsible for the misclassification rate reduction. Note that the semi-supervised method used in the first version of the ALI arXiv paper differs from the one used in this submission in one key aspect. In the former, semi-supervised learning is done after ALI has been trained. In the latter, semi-supervised learning is integrated into ALI's training procedure. In that sense, it is unsurprising that the Salimans et al. (2016) method performs better than a linear SVM trained on features extracted from ALI's encoder.\n\n2) The inference network is used for both methods mentioned in 1). In the first version of the arXiv paper, the encoder is used after unsupervised training as a feature extractor. We show that it outperforms the Radford et al. (2015) semi-supervised result with GANs. In this submission, the discriminator adapted for the semi-supervised learning task receives the encoder's output as input. We show that doing so allows us to match the Salimans et al. (2016) semi-supervised results without having to do feature matching.\n\n3) This paper does not claim that the conditional image generation results are better than previous work. The results are presented to support the claim that ALI is also amenable to class-conditional generative modeling.\n\nWe updated the submission to highlight and clarify the difference between the semi-supervised learning results presented in the first arXiv version of the paper and this version."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Adversarially Learned Inference", "abstract": "We introduce the adversarially learned inference (ALI) model, which jointly\nlearns a generation network and an inference network using an adversarial\nprocess. The generation network maps samples from stochastic latent variables to\nthe data space while the inference network maps training examples in data space\nto the space of latent variables. An adversarial game is cast between these two\nnetworks and a discriminative network that is trained to distinguish between\njoint latent/data-space samples from the generative network and joint samples\nfrom the inference network.  We illustrate the ability of the model to learn\nmutually coherent inference and generation networks through the inspections of\nmodel samples and reconstructions and confirm the usefulness of the learned\nrepresentations by obtaining a performance competitive with other recent\napproaches on the semi-supervised SVHN task.", "pdf": "/pdf/7a3fa67c5f7f97e5095d822afd76a76eaf6b9551.pdf", "TL;DR": "We present and adverserially trained generative model with an inference network. Samples quality is high. Competitive semi-supervised results are achieved.", "paperhash": "dumoulin|adversarially_learned_inference", "conflicts": ["umontreal.ca"], "keywords": ["Computer vision", "Deep learning", "Unsupervised Learning", "Semi-Supervised Learning"], "authors": ["Vincent Dumoulin", "Ishmael Belghazi", "Ben Poole", "Alex Lamb", "Martin Arjovsky", "Olivier Mastropietro", "Aaron Courville"], "authorids": ["vincent.dumoulin@umontreal.ca", "ishmael.belghazi@gmail.com", "poole@cs.stanford.edu", "alex6200@gmail.com", "martinarjovsky@gmail.com", "oli.mastro@gmail.com", "aaron.courville@gmail.com"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287677630, "id": "ICLR.cc/2017/conference/-/paper222/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "B1ElR4cgg", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper222/reviewers", "ICLR.cc/2017/conference/paper222/areachairs"], "cdate": 1485287677630}}}, {"tddate": null, "tmdate": 1481311512664, "tcdate": 1481311512659, "number": 2, "id": "SJZmHKuQe", "invitation": "ICLR.cc/2017/conference/-/paper222/pre-review/question", "forum": "B1ElR4cgg", "replyto": "B1ElR4cgg", "signatures": ["ICLR.cc/2017/conference/paper222/AnonReviewer1"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/conference/paper222/AnonReviewer1"], "content": {"title": "few questions", "question": "I think the idea of matching the joint distributions in order to learn an inference network for GANs is interesting.\n\nI have a few questions from the authors:\n \n1) I had read the previous version of the paper in which the classification rate on SVHN was 19.14% which is good, but not outstanding. What exactly has changed in the new paper which achieves 7.3% classification rate. Is it only the adaptation of Salimans et al. (2016), better hyper-parameters or something else?\n\n2) I think the main contribution of this paper is proposing a new way to learn an inference network for GANs. So may I ask if the authors have tried to use this inference network for semi-supervised learning rather than using the GAN discriminative network as done in this paper, in Radford et al. (2015) and Salimans et al. (2016).\n\n3) The conditional generation is interesting, but I have seen similar experiments in papers such as \"Autoencoding beyond pixels using a learned similarity metric\". Does this paper claim that the image generation results is better than the previous works. If so why?"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Adversarially Learned Inference", "abstract": "We introduce the adversarially learned inference (ALI) model, which jointly\nlearns a generation network and an inference network using an adversarial\nprocess. The generation network maps samples from stochastic latent variables to\nthe data space while the inference network maps training examples in data space\nto the space of latent variables. An adversarial game is cast between these two\nnetworks and a discriminative network that is trained to distinguish between\njoint latent/data-space samples from the generative network and joint samples\nfrom the inference network.  We illustrate the ability of the model to learn\nmutually coherent inference and generation networks through the inspections of\nmodel samples and reconstructions and confirm the usefulness of the learned\nrepresentations by obtaining a performance competitive with other recent\napproaches on the semi-supervised SVHN task.", "pdf": "/pdf/7a3fa67c5f7f97e5095d822afd76a76eaf6b9551.pdf", "TL;DR": "We present and adverserially trained generative model with an inference network. Samples quality is high. Competitive semi-supervised results are achieved.", "paperhash": "dumoulin|adversarially_learned_inference", "conflicts": ["umontreal.ca"], "keywords": ["Computer vision", "Deep learning", "Unsupervised Learning", "Semi-Supervised Learning"], "authors": ["Vincent Dumoulin", "Ishmael Belghazi", "Ben Poole", "Alex Lamb", "Martin Arjovsky", "Olivier Mastropietro", "Aaron Courville"], "authorids": ["vincent.dumoulin@umontreal.ca", "ishmael.belghazi@gmail.com", "poole@cs.stanford.edu", "alex6200@gmail.com", "martinarjovsky@gmail.com", "oli.mastro@gmail.com", "aaron.courville@gmail.com"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1480741199000, "tmdate": 1481311513225, "id": "ICLR.cc/2017/conference/-/paper222/pre-review/question", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/conference/paper222/reviewers"], "noninvitees": ["ICLR.cc/2017/conference/paper222/AnonReviewer2", "ICLR.cc/2017/conference/paper222/AnonReviewer1"], "reply": {"forum": "B1ElR4cgg", "replyto": "B1ElR4cgg", "writers": {"values-regex": "ICLR.cc/2017/conference/paper222/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/conference/paper222/AnonReviewer[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your question.", "value-regex": ".{1,500}"}, "question": {"order": 2, "description": "Your question", "value-regex": "[\\S\\s]{1,5000}"}}}, "nonreaders": [], "expdate": 1488517199000, "cdate": 1481311513225}}}, {"tddate": null, "tmdate": 1480794273047, "tcdate": 1480794273041, "number": 3, "id": "rktjgoeXl", "invitation": "ICLR.cc/2017/conference/-/paper222/public/comment", "forum": "B1ElR4cgg", "replyto": "HkjImAJ7e", "signatures": ["~Alex_Lamb1"], "readers": ["everyone"], "writers": ["~Alex_Lamb1"], "content": {"title": "Connection to BiGAN", "comment": "Both methods were developed independently and published at roughly the same time (BiGAN released May 31 2016, ALI released 2 days later on June 2 2016).  Both papers acknowledge that the methods were developed independently and are very similar.  \n\nThere are differences in the experiments and ALI considered stochastic encoders, but the two proposed models are essentially the same.  "}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Adversarially Learned Inference", "abstract": "We introduce the adversarially learned inference (ALI) model, which jointly\nlearns a generation network and an inference network using an adversarial\nprocess. The generation network maps samples from stochastic latent variables to\nthe data space while the inference network maps training examples in data space\nto the space of latent variables. An adversarial game is cast between these two\nnetworks and a discriminative network that is trained to distinguish between\njoint latent/data-space samples from the generative network and joint samples\nfrom the inference network.  We illustrate the ability of the model to learn\nmutually coherent inference and generation networks through the inspections of\nmodel samples and reconstructions and confirm the usefulness of the learned\nrepresentations by obtaining a performance competitive with other recent\napproaches on the semi-supervised SVHN task.", "pdf": "/pdf/7a3fa67c5f7f97e5095d822afd76a76eaf6b9551.pdf", "TL;DR": "We present and adverserially trained generative model with an inference network. Samples quality is high. Competitive semi-supervised results are achieved.", "paperhash": "dumoulin|adversarially_learned_inference", "conflicts": ["umontreal.ca"], "keywords": ["Computer vision", "Deep learning", "Unsupervised Learning", "Semi-Supervised Learning"], "authors": ["Vincent Dumoulin", "Ishmael Belghazi", "Ben Poole", "Alex Lamb", "Martin Arjovsky", "Olivier Mastropietro", "Aaron Courville"], "authorids": ["vincent.dumoulin@umontreal.ca", "ishmael.belghazi@gmail.com", "poole@cs.stanford.edu", "alex6200@gmail.com", "martinarjovsky@gmail.com", "oli.mastro@gmail.com", "aaron.courville@gmail.com"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287677630, "id": "ICLR.cc/2017/conference/-/paper222/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "B1ElR4cgg", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper222/reviewers", "ICLR.cc/2017/conference/paper222/areachairs"], "cdate": 1485287677630}}}, {"tddate": null, "tmdate": 1480741714835, "tcdate": 1480741714830, "number": 1, "id": "HkjImAJ7e", "invitation": "ICLR.cc/2017/conference/-/paper222/pre-review/question", "forum": "B1ElR4cgg", "replyto": "B1ElR4cgg", "signatures": ["ICLR.cc/2017/conference/paper222/AnonReviewer2"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/conference/paper222/AnonReviewer2"], "content": {"title": "Pre-review question", "question": "What is the difference of the ALI model to BiGAN (https://arxiv.org/abs/1605.09782) ?"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Adversarially Learned Inference", "abstract": "We introduce the adversarially learned inference (ALI) model, which jointly\nlearns a generation network and an inference network using an adversarial\nprocess. The generation network maps samples from stochastic latent variables to\nthe data space while the inference network maps training examples in data space\nto the space of latent variables. An adversarial game is cast between these two\nnetworks and a discriminative network that is trained to distinguish between\njoint latent/data-space samples from the generative network and joint samples\nfrom the inference network.  We illustrate the ability of the model to learn\nmutually coherent inference and generation networks through the inspections of\nmodel samples and reconstructions and confirm the usefulness of the learned\nrepresentations by obtaining a performance competitive with other recent\napproaches on the semi-supervised SVHN task.", "pdf": "/pdf/7a3fa67c5f7f97e5095d822afd76a76eaf6b9551.pdf", "TL;DR": "We present and adverserially trained generative model with an inference network. Samples quality is high. Competitive semi-supervised results are achieved.", "paperhash": "dumoulin|adversarially_learned_inference", "conflicts": ["umontreal.ca"], "keywords": ["Computer vision", "Deep learning", "Unsupervised Learning", "Semi-Supervised Learning"], "authors": ["Vincent Dumoulin", "Ishmael Belghazi", "Ben Poole", "Alex Lamb", "Martin Arjovsky", "Olivier Mastropietro", "Aaron Courville"], "authorids": ["vincent.dumoulin@umontreal.ca", "ishmael.belghazi@gmail.com", "poole@cs.stanford.edu", "alex6200@gmail.com", "martinarjovsky@gmail.com", "oli.mastro@gmail.com", "aaron.courville@gmail.com"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1480741199000, "tmdate": 1481311513225, "id": "ICLR.cc/2017/conference/-/paper222/pre-review/question", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/conference/paper222/reviewers"], "noninvitees": ["ICLR.cc/2017/conference/paper222/AnonReviewer2", "ICLR.cc/2017/conference/paper222/AnonReviewer1"], "reply": {"forum": "B1ElR4cgg", "replyto": "B1ElR4cgg", "writers": {"values-regex": "ICLR.cc/2017/conference/paper222/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/conference/paper222/AnonReviewer[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your question.", "value-regex": ".{1,500}"}, "question": {"order": 2, "description": "Your question", "value-regex": "[\\S\\s]{1,5000}"}}}, "nonreaders": [], "expdate": 1488517199000, "cdate": 1481311513225}}}, {"tddate": null, "tmdate": 1480526292993, "tcdate": 1480526292987, "number": 2, "id": "BkaCFtnGe", "invitation": "ICLR.cc/2017/conference/-/paper222/public/comment", "forum": "B1ElR4cgg", "replyto": "HkD8tKxfe", "signatures": ["~Mohamed_Ishmael_Belghazi1"], "readers": ["everyone"], "writers": ["~Mohamed_Ishmael_Belghazi1"], "content": {"title": "Reply to details of semi-supervised learning experiments comment by Anonymous", "comment": "In the OpenReview version, we incorporate semi-supervised learning into the training of ALI by following Salimans et al.'s setup of having the discriminator output a distribution over K + 1 labels. The first K labels correspond \nto the classes found in the labeled dataset. The K + 1th label is that of the samples. Given this output distribution, the discriminator's value function can be broken down into supervised and unsupervised parts. The supervised part receives labeled data and their encodings. The unsupervised part receives unlabeled data and samples as well as their respective encodings. \n\nThe main difference between our setup and Salimans et al.'s is that the latter does not have encodings to be fed to the discriminator."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Adversarially Learned Inference", "abstract": "We introduce the adversarially learned inference (ALI) model, which jointly\nlearns a generation network and an inference network using an adversarial\nprocess. The generation network maps samples from stochastic latent variables to\nthe data space while the inference network maps training examples in data space\nto the space of latent variables. An adversarial game is cast between these two\nnetworks and a discriminative network that is trained to distinguish between\njoint latent/data-space samples from the generative network and joint samples\nfrom the inference network.  We illustrate the ability of the model to learn\nmutually coherent inference and generation networks through the inspections of\nmodel samples and reconstructions and confirm the usefulness of the learned\nrepresentations by obtaining a performance competitive with other recent\napproaches on the semi-supervised SVHN task.", "pdf": "/pdf/7a3fa67c5f7f97e5095d822afd76a76eaf6b9551.pdf", "TL;DR": "We present and adverserially trained generative model with an inference network. Samples quality is high. Competitive semi-supervised results are achieved.", "paperhash": "dumoulin|adversarially_learned_inference", "conflicts": ["umontreal.ca"], "keywords": ["Computer vision", "Deep learning", "Unsupervised Learning", "Semi-Supervised Learning"], "authors": ["Vincent Dumoulin", "Ishmael Belghazi", "Ben Poole", "Alex Lamb", "Martin Arjovsky", "Olivier Mastropietro", "Aaron Courville"], "authorids": ["vincent.dumoulin@umontreal.ca", "ishmael.belghazi@gmail.com", "poole@cs.stanford.edu", "alex6200@gmail.com", "martinarjovsky@gmail.com", "oli.mastro@gmail.com", "aaron.courville@gmail.com"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287677630, "id": "ICLR.cc/2017/conference/-/paper222/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "B1ElR4cgg", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper222/reviewers", "ICLR.cc/2017/conference/paper222/areachairs"], "cdate": 1485287677630}}}, {"tddate": null, "tmdate": 1479739726765, "tcdate": 1479739726758, "number": 1, "id": "HkD8tKxfe", "invitation": "ICLR.cc/2017/conference/-/paper222/public/comment", "forum": "B1ElR4cgg", "replyto": "B1ElR4cgg", "signatures": ["(anonymous)"], "readers": ["everyone"], "writers": ["(anonymous)"], "content": {"title": "details of semi-supervised learning experiments", "comment": "What is the specific setting of the semi-supervised learning experiments? Do you use the feature from encoder or from the discriminator? And how do you add label information to the training process? In the arXiv version it is said that a L2-SVM is trained on the last few layers of the encoder, but the performance is much worse than reported in openreview version of the paper. "}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Adversarially Learned Inference", "abstract": "We introduce the adversarially learned inference (ALI) model, which jointly\nlearns a generation network and an inference network using an adversarial\nprocess. The generation network maps samples from stochastic latent variables to\nthe data space while the inference network maps training examples in data space\nto the space of latent variables. An adversarial game is cast between these two\nnetworks and a discriminative network that is trained to distinguish between\njoint latent/data-space samples from the generative network and joint samples\nfrom the inference network.  We illustrate the ability of the model to learn\nmutually coherent inference and generation networks through the inspections of\nmodel samples and reconstructions and confirm the usefulness of the learned\nrepresentations by obtaining a performance competitive with other recent\napproaches on the semi-supervised SVHN task.", "pdf": "/pdf/7a3fa67c5f7f97e5095d822afd76a76eaf6b9551.pdf", "TL;DR": "We present and adverserially trained generative model with an inference network. Samples quality is high. Competitive semi-supervised results are achieved.", "paperhash": "dumoulin|adversarially_learned_inference", "conflicts": ["umontreal.ca"], "keywords": ["Computer vision", "Deep learning", "Unsupervised Learning", "Semi-Supervised Learning"], "authors": ["Vincent Dumoulin", "Ishmael Belghazi", "Ben Poole", "Alex Lamb", "Martin Arjovsky", "Olivier Mastropietro", "Aaron Courville"], "authorids": ["vincent.dumoulin@umontreal.ca", "ishmael.belghazi@gmail.com", "poole@cs.stanford.edu", "alex6200@gmail.com", "martinarjovsky@gmail.com", "oli.mastro@gmail.com", "aaron.courville@gmail.com"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287677630, "id": "ICLR.cc/2017/conference/-/paper222/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "B1ElR4cgg", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper222/reviewers", "ICLR.cc/2017/conference/paper222/areachairs"], "cdate": 1485287677630}}}], "count": 17}