{"notes": [{"id": "H1lKNp4Fvr", "original": "SkxdQw7wvS", "number": 494, "cdate": 1569439025051, "ddate": null, "tcdate": 1569439025051, "tmdate": 1577168263203, "tddate": null, "forum": "H1lKNp4Fvr", "replyto": null, "invitation": "ICLR.cc/2020/Conference/-/Blind_Submission", "content": {"title": "A shallow feature extraction network with a large receptive field for stereo matching tasks", "authors": ["Jianguo Liu", "Yunjian Feng", "Guo Ji", "Fuwu Yan"], "authorids": ["ljg424@163.com", "1029515027@whut.edu.cn", "18754806756@163.com", "yanfw@whut.edu.cn"], "keywords": ["stereo matching", "feature extraction network", "convolution neural network", "receptive field"], "TL;DR": "We introduced a shallow featrue extraction network with a large receptive field for stereo matching tasks, which uses a simple structure to get better performance.", "abstract": "Stereo matching is one of the important basic tasks in the computer vision field. In recent years, stereo matching algorithms based on deep learning have achieved excellent performance and become the mainstream research direction. Existing algorithms generally use deep convolutional neural networks (DCNNs) to extract more abstract semantic information, but we believe that the detailed information of the spatial structure is more important for stereo matching tasks. Based on this point of view, this paper proposes a shallow feature extraction network with a large receptive field. The network consists of three parts: a primary feature extraction module, an atrous spatial pyramid pooling (ASPP) module and a feature fusion module. The primary feature extraction network contains only three convolution layers. This network utilizes the basic feature extraction ability of the shallow network to extract and retain the detailed information of the spatial structure. In this paper, the dilated convolution and atrous spatial pyramid pooling (ASPP) module is introduced to increase the size of receptive field. In addition, a feature fusion module is designed, which integrates the feature maps with multiscale receptive fields and mutually complements the feature information of different scales. We replaced the feature extraction part of the existing stereo matching algorithms with our shallow feature extraction network, and achieved state-of-the-art performance on the KITTI 2015 dataset. Compared with the reference network, the number of parameters is reduced by 42%, and the matching accuracy is improved by 1.9%.", "pdf": "/pdf/c93569943e445c32d160418adc1d4b8484adb78a.pdf", "paperhash": "liu|a_shallow_feature_extraction_network_with_a_large_receptive_field_for_stereo_matching_tasks", "original_pdf": "/attachment/c93569943e445c32d160418adc1d4b8484adb78a.pdf", "_bibtex": "@misc{\nliu2020a,\ntitle={A shallow feature extraction network with a large receptive field for stereo matching tasks},\nauthor={Jianguo Liu and Yunjian Feng and Guo Ji and Fuwu Yan},\nyear={2020},\nurl={https://openreview.net/forum?id=H1lKNp4Fvr}\n}"}, "signatures": ["ICLR.cc/2020/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference"], "details": {"replyCount": 4, "writable": false, "overwriting": [], "revisions": false, "tags": [], "invitation": {"reply": {"readers": {"values-regex": ".*"}, "writers": {"values": ["ICLR.cc/2020/Conference"]}, "signatures": {"values": ["ICLR.cc/2020/Conference"]}, "content": {"spotlight_video": {"value-regex": ".*"}, "full_presentation_video": {"value-regex": ".*"}, "original_pdf": {"required": false, "description": "Upload a PDF file that ends with .pdf", "value-regex": ".*"}, "appendix": {"value-regex": ".*"}, "authorids": {"values-regex": ".*"}, "poster": {"value-regex": ".*"}, "authors": {"values": ["Anonymous"]}, "slides": {"value-regex": ".*"}}}, "final": [], "signatures": ["ICLR.cc/2020/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference"], "noninvitees": [], "tcdate": 1569271260237, "tmdate": 1593459412141, "id": "ICLR.cc/2020/Conference/-/Blind_Submission"}}, "tauthor": "OpenReview.net"}, {"id": "vrhf8or8S8", "original": null, "number": 1, "cdate": 1576798698084, "ddate": null, "tcdate": 1576798698084, "tmdate": 1576800937734, "tddate": null, "forum": "H1lKNp4Fvr", "replyto": "H1lKNp4Fvr", "invitation": "ICLR.cc/2020/Conference/Paper494/-/Decision", "content": {"decision": "Reject", "comment": "The paper proposed the use of a shallow layers with large receptive fields for feature extraction to be used in stereo matching tasks. It showed on the KITTI2015 dataset this method leads to large model size reducetion while maintaining a comparable performance.\n\nThe main conern on this paper is the lack of technical contributions:\n* The task of stereo matching is very specialized one, simply presenting the model size reduction and performance is not interesting to general readers. Adding more analysis that help understanding why the proposed method helps in this particular task and for what kind of tasks a shallow feature instead a deeper one is perferred. In that way, the paper would be addressing much wider audiences. \n* The discussions on related work is not thorough enough, lacking of analysis of pros and cons between different methods.", "title": "Paper Decision"}, "signatures": ["ICLR.cc/2020/Conference/Program_Chairs"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Program_Chairs"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "A shallow feature extraction network with a large receptive field for stereo matching tasks", "authors": ["Jianguo Liu", "Yunjian Feng", "Guo Ji", "Fuwu Yan"], "authorids": ["ljg424@163.com", "1029515027@whut.edu.cn", "18754806756@163.com", "yanfw@whut.edu.cn"], "keywords": ["stereo matching", "feature extraction network", "convolution neural network", "receptive field"], "TL;DR": "We introduced a shallow featrue extraction network with a large receptive field for stereo matching tasks, which uses a simple structure to get better performance.", "abstract": "Stereo matching is one of the important basic tasks in the computer vision field. In recent years, stereo matching algorithms based on deep learning have achieved excellent performance and become the mainstream research direction. Existing algorithms generally use deep convolutional neural networks (DCNNs) to extract more abstract semantic information, but we believe that the detailed information of the spatial structure is more important for stereo matching tasks. Based on this point of view, this paper proposes a shallow feature extraction network with a large receptive field. The network consists of three parts: a primary feature extraction module, an atrous spatial pyramid pooling (ASPP) module and a feature fusion module. The primary feature extraction network contains only three convolution layers. This network utilizes the basic feature extraction ability of the shallow network to extract and retain the detailed information of the spatial structure. In this paper, the dilated convolution and atrous spatial pyramid pooling (ASPP) module is introduced to increase the size of receptive field. In addition, a feature fusion module is designed, which integrates the feature maps with multiscale receptive fields and mutually complements the feature information of different scales. We replaced the feature extraction part of the existing stereo matching algorithms with our shallow feature extraction network, and achieved state-of-the-art performance on the KITTI 2015 dataset. Compared with the reference network, the number of parameters is reduced by 42%, and the matching accuracy is improved by 1.9%.", "pdf": "/pdf/c93569943e445c32d160418adc1d4b8484adb78a.pdf", "paperhash": "liu|a_shallow_feature_extraction_network_with_a_large_receptive_field_for_stereo_matching_tasks", "original_pdf": "/attachment/c93569943e445c32d160418adc1d4b8484adb78a.pdf", "_bibtex": "@misc{\nliu2020a,\ntitle={A shallow feature extraction network with a large receptive field for stereo matching tasks},\nauthor={Jianguo Liu and Yunjian Feng and Guo Ji and Fuwu Yan},\nyear={2020},\nurl={https://openreview.net/forum?id=H1lKNp4Fvr}\n}"}, "tags": [], "invitation": {"reply": {"writers": {"description": "How your identity will be displayed.", "values-regex": ["ICLR.cc/2020/Conference/Program_Chairs"]}, "signatures": {"values": ["ICLR.cc/2020/Conference/Program_Chairs"], "description": "How your identity will be displayed."}, "content": {"decision": {"value-radio": ["Accept (Spotlight)", "Accept (Talk)", "Accept (Poster)", "Reject"], "description": "Decision", "required": true, "order": 2}, "title": {"value": "Paper Decision", "required": true, "order": 1}, "comment": {"value-regex": "[\\S\\s]{0,5000}", "description": "", "required": false, "order": 3}}, "forum": "H1lKNp4Fvr", "replyto": "H1lKNp4Fvr", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}}, "expdate": 1576854540000, "duedate": 1576853940000, "multiReply": false, "readers": ["everyone"], "invitees": ["ICLR.cc/2020/Conference/Program_Chairs"], "tcdate": 1576795729423, "tmdate": 1576800282008, "super": "ICLR.cc/2020/Conference/-/Decision", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper494/-/Decision"}}}, {"id": "SklXNK5Jqr", "original": null, "number": 2, "cdate": 1571952939056, "ddate": null, "tcdate": 1571952939056, "tmdate": 1572972588459, "tddate": null, "forum": "H1lKNp4Fvr", "replyto": "H1lKNp4Fvr", "invitation": "ICLR.cc/2020/Conference/Paper494/-/Official_Review", "content": {"experience_assessment": "I have read many papers in this area.", "rating": "3: Weak Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #3", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "This paper presents an algorithm for stereo image matching that attempts to capture improved representations of detailed spatial structure information, in particular, by increasing the size of the receptive field.  The paper shows that this leads to a major reduction in the number of model parameters (42% in one case) with comparable performance on the KITTI2015 data set.\n\nI like the driving principle of the authors' approach (that stereo image matching relies more heavily on low-level features, and that higher level \"semantic\" features are not as critical) compelling.  I would have really like to have seen the authors do some analysis of the features that they do extract, so that the reader can get a deeper insight into why their method works. The paper could be improved by providing more this kind of analysis and by adding more motivate for why low-level features are more important for stereo matching.  \n\nI'm concerned that the paper only present results on one, small (200+200 images) data set.  The paper would be much stronger if the authors tested on more, and varied data sets.\n\nIs it simply a network complexity issues or is there something else?\n\nThe related work section appears to be just a laundry list of methods.  The paper would be stronger if the authors provided more interpretation of the strengths and weaknesses of these methods, some insight into why they work, and why the proposed method is better.\n\nThe authors' method claims to use a 1x1 convolution layer.  Is that correct?  Sounds like simple multiplication.  Explain what it different.\n\nThe authors' reporting of their results appears muddled.  They claim the error rate was \"reduced 3.4% and 1.9%\" in Table 5.  I could not figure out which numbers they were talking about.  In most cases, the authors' method was not the best.\n\nMinor point:  The authors say \"conclusion\" when I think they mean \"oclusion\"."}, "signatures": ["ICLR.cc/2020/Conference/Paper494/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper494/AnonReviewer3"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "A shallow feature extraction network with a large receptive field for stereo matching tasks", "authors": ["Jianguo Liu", "Yunjian Feng", "Guo Ji", "Fuwu Yan"], "authorids": ["ljg424@163.com", "1029515027@whut.edu.cn", "18754806756@163.com", "yanfw@whut.edu.cn"], "keywords": ["stereo matching", "feature extraction network", "convolution neural network", "receptive field"], "TL;DR": "We introduced a shallow featrue extraction network with a large receptive field for stereo matching tasks, which uses a simple structure to get better performance.", "abstract": "Stereo matching is one of the important basic tasks in the computer vision field. In recent years, stereo matching algorithms based on deep learning have achieved excellent performance and become the mainstream research direction. Existing algorithms generally use deep convolutional neural networks (DCNNs) to extract more abstract semantic information, but we believe that the detailed information of the spatial structure is more important for stereo matching tasks. Based on this point of view, this paper proposes a shallow feature extraction network with a large receptive field. The network consists of three parts: a primary feature extraction module, an atrous spatial pyramid pooling (ASPP) module and a feature fusion module. The primary feature extraction network contains only three convolution layers. This network utilizes the basic feature extraction ability of the shallow network to extract and retain the detailed information of the spatial structure. In this paper, the dilated convolution and atrous spatial pyramid pooling (ASPP) module is introduced to increase the size of receptive field. In addition, a feature fusion module is designed, which integrates the feature maps with multiscale receptive fields and mutually complements the feature information of different scales. We replaced the feature extraction part of the existing stereo matching algorithms with our shallow feature extraction network, and achieved state-of-the-art performance on the KITTI 2015 dataset. Compared with the reference network, the number of parameters is reduced by 42%, and the matching accuracy is improved by 1.9%.", "pdf": "/pdf/c93569943e445c32d160418adc1d4b8484adb78a.pdf", "paperhash": "liu|a_shallow_feature_extraction_network_with_a_large_receptive_field_for_stereo_matching_tasks", "original_pdf": "/attachment/c93569943e445c32d160418adc1d4b8484adb78a.pdf", "_bibtex": "@misc{\nliu2020a,\ntitle={A shallow feature extraction network with a large receptive field for stereo matching tasks},\nauthor={Jianguo Liu and Yunjian Feng and Guo Ji and Fuwu Yan},\nyear={2020},\nurl={https://openreview.net/forum?id=H1lKNp4Fvr}\n}"}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "H1lKNp4Fvr", "replyto": "H1lKNp4Fvr", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper494/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper494/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1574809396346, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper494/Reviewers"], "noninvitees": [], "tcdate": 1570237751319, "tmdate": 1574809396359, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper494/-/Official_Review"}}}, {"id": "SyencAbAtr", "original": null, "number": 1, "cdate": 1571851923551, "ddate": null, "tcdate": 1571851923551, "tmdate": 1572972588415, "tddate": null, "forum": "H1lKNp4Fvr", "replyto": "H1lKNp4Fvr", "invitation": "ICLR.cc/2020/Conference/Paper494/-/Official_Review", "content": {"experience_assessment": "I have read many papers in this area.", "rating": "1: Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #1", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "The paper at hand argues that shallow feature extraction networks should be favored for the computer vision task of stereo matching, rather than the commonly used deep ResNet backbones. To that end, a model is proposed consisting of three convolutional feature extraction layers only. As this makes it impossible to capture global context, dilated convolutions with varying dilations are applied to the extracted features in parallel and concatenated. Finally, a fusion module implemented via channel attention is applied.\n\nI found this paper lacking in terms of contributions. While the motivation for retaining detailed feature information makes sense for the task in question, it is not clear why it requires replacing the ResNet feature extraction with a very shallow network; an alternative would be to add skip-connections originating from lower levels. Both dilated convolutions and the fusion module are not novel. The paper addresses the need for a fusion module in great detail. However, the insight that a large dilation on top of features computed from a limited receptive field will result in a non-continuous receptive field is a rather trivial one. Hence I don't see the need for section 4.3.1 and 4.3.2, as well as the somewhat complicated deduction in appendix A. The individual modules are ablated, but what about the number of layers for feature extraction? Why settle for 3 rather than 1, 2, or 4?\n\nThe paper does compare against other methods for stereo matching, but I was wondering why the KTTI leader-board excerpt does not include the better results from http://www.cvlibs.net/datasets/kitti/eval_scene_flow.php?benchmark=stereo ? The result tables are also hard to parse as bold numbers do not correspond to best performance. The conclusion claims that the proposed shallow architecture exhibits \"lower training difficulty\" but I did not see any support for this in the experiments.\n\nOverall, I think that this paper should be rejected on the basis of insufficient contributions."}, "signatures": ["ICLR.cc/2020/Conference/Paper494/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper494/AnonReviewer1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "A shallow feature extraction network with a large receptive field for stereo matching tasks", "authors": ["Jianguo Liu", "Yunjian Feng", "Guo Ji", "Fuwu Yan"], "authorids": ["ljg424@163.com", "1029515027@whut.edu.cn", "18754806756@163.com", "yanfw@whut.edu.cn"], "keywords": ["stereo matching", "feature extraction network", "convolution neural network", "receptive field"], "TL;DR": "We introduced a shallow featrue extraction network with a large receptive field for stereo matching tasks, which uses a simple structure to get better performance.", "abstract": "Stereo matching is one of the important basic tasks in the computer vision field. In recent years, stereo matching algorithms based on deep learning have achieved excellent performance and become the mainstream research direction. Existing algorithms generally use deep convolutional neural networks (DCNNs) to extract more abstract semantic information, but we believe that the detailed information of the spatial structure is more important for stereo matching tasks. Based on this point of view, this paper proposes a shallow feature extraction network with a large receptive field. The network consists of three parts: a primary feature extraction module, an atrous spatial pyramid pooling (ASPP) module and a feature fusion module. The primary feature extraction network contains only three convolution layers. This network utilizes the basic feature extraction ability of the shallow network to extract and retain the detailed information of the spatial structure. In this paper, the dilated convolution and atrous spatial pyramid pooling (ASPP) module is introduced to increase the size of receptive field. In addition, a feature fusion module is designed, which integrates the feature maps with multiscale receptive fields and mutually complements the feature information of different scales. We replaced the feature extraction part of the existing stereo matching algorithms with our shallow feature extraction network, and achieved state-of-the-art performance on the KITTI 2015 dataset. Compared with the reference network, the number of parameters is reduced by 42%, and the matching accuracy is improved by 1.9%.", "pdf": "/pdf/c93569943e445c32d160418adc1d4b8484adb78a.pdf", "paperhash": "liu|a_shallow_feature_extraction_network_with_a_large_receptive_field_for_stereo_matching_tasks", "original_pdf": "/attachment/c93569943e445c32d160418adc1d4b8484adb78a.pdf", "_bibtex": "@misc{\nliu2020a,\ntitle={A shallow feature extraction network with a large receptive field for stereo matching tasks},\nauthor={Jianguo Liu and Yunjian Feng and Guo Ji and Fuwu Yan},\nyear={2020},\nurl={https://openreview.net/forum?id=H1lKNp4Fvr}\n}"}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "H1lKNp4Fvr", "replyto": "H1lKNp4Fvr", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper494/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper494/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1574809396346, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper494/Reviewers"], "noninvitees": [], "tcdate": 1570237751319, "tmdate": 1574809396359, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper494/-/Official_Review"}}}, {"id": "SygdNBqM5H", "original": null, "number": 3, "cdate": 1572148527992, "ddate": null, "tcdate": 1572148527992, "tmdate": 1572972588373, "tddate": null, "forum": "H1lKNp4Fvr", "replyto": "H1lKNp4Fvr", "invitation": "ICLR.cc/2020/Conference/Paper494/-/Official_Review", "content": {"experience_assessment": "I do not know much about this area.", "rating": "6: Weak Accept", "review_assessment:_thoroughness_in_paper_reading": "I made a quick assessment of this paper.", "review_assessment:_checking_correctness_of_experiments": "I did not assess the experiments.", "title": "Official Blind Review #4", "review_assessment:_checking_correctness_of_derivations_and_theory": "I did not assess the derivations or theory.", "review": "This is a paper about a rather specialized area of computer vision (stereo matching),\nand it's not really a theoretical paper; it's about an improved network topology for\na very specific task.\nMy feeling is that this belongs in a computer vision conference, where people would be better\nable to appreciate it.\nIt does relate specifically to learning representations, though, so perhaps it has a chance in ICLR?\nI'm putting \"weak accept\" but take this as with weak confidence as I am not really a computer vision person."}, "signatures": ["ICLR.cc/2020/Conference/Paper494/AnonReviewer4"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper494/AnonReviewer4"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "A shallow feature extraction network with a large receptive field for stereo matching tasks", "authors": ["Jianguo Liu", "Yunjian Feng", "Guo Ji", "Fuwu Yan"], "authorids": ["ljg424@163.com", "1029515027@whut.edu.cn", "18754806756@163.com", "yanfw@whut.edu.cn"], "keywords": ["stereo matching", "feature extraction network", "convolution neural network", "receptive field"], "TL;DR": "We introduced a shallow featrue extraction network with a large receptive field for stereo matching tasks, which uses a simple structure to get better performance.", "abstract": "Stereo matching is one of the important basic tasks in the computer vision field. In recent years, stereo matching algorithms based on deep learning have achieved excellent performance and become the mainstream research direction. Existing algorithms generally use deep convolutional neural networks (DCNNs) to extract more abstract semantic information, but we believe that the detailed information of the spatial structure is more important for stereo matching tasks. Based on this point of view, this paper proposes a shallow feature extraction network with a large receptive field. The network consists of three parts: a primary feature extraction module, an atrous spatial pyramid pooling (ASPP) module and a feature fusion module. The primary feature extraction network contains only three convolution layers. This network utilizes the basic feature extraction ability of the shallow network to extract and retain the detailed information of the spatial structure. In this paper, the dilated convolution and atrous spatial pyramid pooling (ASPP) module is introduced to increase the size of receptive field. In addition, a feature fusion module is designed, which integrates the feature maps with multiscale receptive fields and mutually complements the feature information of different scales. We replaced the feature extraction part of the existing stereo matching algorithms with our shallow feature extraction network, and achieved state-of-the-art performance on the KITTI 2015 dataset. Compared with the reference network, the number of parameters is reduced by 42%, and the matching accuracy is improved by 1.9%.", "pdf": "/pdf/c93569943e445c32d160418adc1d4b8484adb78a.pdf", "paperhash": "liu|a_shallow_feature_extraction_network_with_a_large_receptive_field_for_stereo_matching_tasks", "original_pdf": "/attachment/c93569943e445c32d160418adc1d4b8484adb78a.pdf", "_bibtex": "@misc{\nliu2020a,\ntitle={A shallow feature extraction network with a large receptive field for stereo matching tasks},\nauthor={Jianguo Liu and Yunjian Feng and Guo Ji and Fuwu Yan},\nyear={2020},\nurl={https://openreview.net/forum?id=H1lKNp4Fvr}\n}"}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "H1lKNp4Fvr", "replyto": "H1lKNp4Fvr", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper494/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper494/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1574809396346, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper494/Reviewers"], "noninvitees": [], "tcdate": 1570237751319, "tmdate": 1574809396359, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper494/-/Official_Review"}}}], "count": 5}