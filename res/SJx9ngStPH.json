{"notes": [{"id": "SJx9ngStPH", "original": "r1eKux-YDS", "number": 2547, "cdate": 1569439921944, "ddate": null, "tcdate": 1569439921944, "tmdate": 1583912024226, "tddate": null, "forum": "SJx9ngStPH", "replyto": null, "invitation": "ICLR.cc/2020/Conference/-/Blind_Submission", "content": {"authorids": ["zelaa@cs.uni-freiburg.de", "siemsj@cs.uni-freiburg.de", "fh@cs.uni-freiburg.de"], "title": "NAS-Bench-1Shot1: Benchmarking and Dissecting One-shot Neural Architecture Search", "authors": ["Arber Zela", "Julien Siems", "Frank Hutter"], "pdf": "/pdf/629de63a76318d4dba0710a49082db53188ddd27.pdf", "abstract": "One-shot neural architecture search (NAS) has played a crucial role in making\nNAS methods computationally feasible in practice. Nevertheless, there is still a\nlack of understanding on how these weight-sharing algorithms exactly work due\nto the many factors controlling the dynamics of the process. In order to allow\na scientific study of these components, we introduce a general framework for\none-shot NAS that can be instantiated to many recently-introduced variants and\nintroduce a general benchmarking framework that draws on the recent large-scale\ntabular benchmark NAS-Bench-101 for cheap anytime evaluations of one-shot\nNAS methods. To showcase the framework, we compare several state-of-the-art\none-shot NAS methods, examine how sensitive they are to their hyperparameters\nand how they can be improved by tuning their hyperparameters, and compare their\nperformance to that of blackbox optimizers for NAS-Bench-101.", "code": "https://github.com/automl/nasbench-1shot1", "keywords": ["Neural Architecture Search", "Deep Learning", "Computer Vision"], "paperhash": "zela|nasbench1shot1_benchmarking_and_dissecting_oneshot_neural_architecture_search", "_bibtex": "@inproceedings{\nZela2020NAS-Bench-1Shot1:,\ntitle={NAS-Bench-1Shot1: Benchmarking and Dissecting One-shot Neural Architecture Search},\nauthor={Arber Zela and Julien Siems and Frank Hutter},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=SJx9ngStPH}\n}", "full_presentation_video": "", "original_pdf": "/attachment/f33f4aa80d5c9e7e2758b5e94f9ebcbce1954a56.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "signatures": ["ICLR.cc/2020/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference"], "details": {"replyCount": 9, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"reply": {"readers": {"values-regex": ".*"}, "writers": {"values": ["ICLR.cc/2020/Conference"]}, "signatures": {"values": ["ICLR.cc/2020/Conference"]}, "content": {"spotlight_video": {"value-regex": ".*"}, "full_presentation_video": {"value-regex": ".*"}, "original_pdf": {"required": false, "description": "Upload a PDF file that ends with .pdf", "value-regex": ".*"}, "appendix": {"value-regex": ".*"}, "authorids": {"values-regex": ".*"}, "poster": {"value-regex": ".*"}, "authors": {"values": ["Anonymous"]}, "slides": {"value-regex": ".*"}}}, "final": [], "signatures": ["ICLR.cc/2020/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference"], "noninvitees": [], "tcdate": 1569271260237, "tmdate": 1593459412141, "id": "ICLR.cc/2020/Conference/-/Blind_Submission"}}, "tauthor": "ICLR.cc/2020/Conference"}, {"id": "fhaP5EbL15", "original": null, "number": 1, "cdate": 1576798751784, "ddate": null, "tcdate": 1576798751784, "tmdate": 1576800883866, "tddate": null, "forum": "SJx9ngStPH", "replyto": "SJx9ngStPH", "invitation": "ICLR.cc/2020/Conference/Paper2547/-/Decision", "content": {"decision": "Accept (Poster)", "comment": "The authors present a new benchmark for architecture search. Reviews were somewhat mixed, but also with mixed confidence scores. I recommend acceptance as poster - and encourage the authors to also cite https://openreview.net/forum?id=HJxyZkBKDr", "title": "Paper Decision"}, "signatures": ["ICLR.cc/2020/Conference/Program_Chairs"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Program_Chairs"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["zelaa@cs.uni-freiburg.de", "siemsj@cs.uni-freiburg.de", "fh@cs.uni-freiburg.de"], "title": "NAS-Bench-1Shot1: Benchmarking and Dissecting One-shot Neural Architecture Search", "authors": ["Arber Zela", "Julien Siems", "Frank Hutter"], "pdf": "/pdf/629de63a76318d4dba0710a49082db53188ddd27.pdf", "abstract": "One-shot neural architecture search (NAS) has played a crucial role in making\nNAS methods computationally feasible in practice. Nevertheless, there is still a\nlack of understanding on how these weight-sharing algorithms exactly work due\nto the many factors controlling the dynamics of the process. In order to allow\na scientific study of these components, we introduce a general framework for\none-shot NAS that can be instantiated to many recently-introduced variants and\nintroduce a general benchmarking framework that draws on the recent large-scale\ntabular benchmark NAS-Bench-101 for cheap anytime evaluations of one-shot\nNAS methods. To showcase the framework, we compare several state-of-the-art\none-shot NAS methods, examine how sensitive they are to their hyperparameters\nand how they can be improved by tuning their hyperparameters, and compare their\nperformance to that of blackbox optimizers for NAS-Bench-101.", "code": "https://github.com/automl/nasbench-1shot1", "keywords": ["Neural Architecture Search", "Deep Learning", "Computer Vision"], "paperhash": "zela|nasbench1shot1_benchmarking_and_dissecting_oneshot_neural_architecture_search", "_bibtex": "@inproceedings{\nZela2020NAS-Bench-1Shot1:,\ntitle={NAS-Bench-1Shot1: Benchmarking and Dissecting One-shot Neural Architecture Search},\nauthor={Arber Zela and Julien Siems and Frank Hutter},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=SJx9ngStPH}\n}", "full_presentation_video": "", "original_pdf": "/attachment/f33f4aa80d5c9e7e2758b5e94f9ebcbce1954a56.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "tags": [], "invitation": {"reply": {"writers": {"description": "How your identity will be displayed.", "values-regex": ["ICLR.cc/2020/Conference/Program_Chairs"]}, "signatures": {"values": ["ICLR.cc/2020/Conference/Program_Chairs"], "description": "How your identity will be displayed."}, "content": {"decision": {"value-radio": ["Accept (Spotlight)", "Accept (Talk)", "Accept (Poster)", "Reject"], "description": "Decision", "required": true, "order": 2}, "title": {"value": "Paper Decision", "required": true, "order": 1}, "comment": {"value-regex": "[\\S\\s]{0,5000}", "description": "", "required": false, "order": 3}}, "forum": "SJx9ngStPH", "replyto": "SJx9ngStPH", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}}, "expdate": 1576854540000, "duedate": 1576853940000, "multiReply": false, "readers": ["everyone"], "invitees": ["ICLR.cc/2020/Conference/Program_Chairs"], "tcdate": 1576795717633, "tmdate": 1576800267974, "super": "ICLR.cc/2020/Conference/-/Decision", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper2547/-/Decision"}}}, {"id": "BJgfr4RFoS", "original": null, "number": 6, "cdate": 1573671994162, "ddate": null, "tcdate": 1573671994162, "tmdate": 1573672053916, "tddate": null, "forum": "SJx9ngStPH", "replyto": "BkeNfNCFjB", "invitation": "ICLR.cc/2020/Conference/Paper2547/-/Official_Comment", "content": {"title": "Response to Reviewer #1 (2/2)", "comment": "-- References --\n[1] Chris Ying, Aaron Klein, Esteban Real, Eric Christiansen, Kevin Murphy, Frank Hutter, NAS-Bench-101: Towards Reproducible Neural Architecture Search, ICML 2019\n[2] Hieu Pham, Melody Y. Guan, Barret Zoph, Quoc V. Le, Jeff Dean, Efficient Neural Architecture Search via Parameter Sharing, ICML 2018\n[3] Hanxiao Liu, Karen Simonyan, Yiming Yang, DARTS: Differentiable Architecture Search, ICLR 2019\n[4] LIAM LI, AMEET TALWALKAR. Random Search and Reproducibility for Neural Architecture Search, ArXiv 2019\n[5] Han Cai, Ligeng Zhu, Song Han, ProxylessNAS: Direct Neural Architecture Search on Target Task and Hardware, ICLR 2019\n[6] Sirui Xie, Hehui Zheng, Chunxiao Liu, Liang Lin, SNAS: Stochastic Neural Architecture Search, ICLR 2019\n[7] Lisha Li, Kevin Jamieson, Giulia DeSalvo, Afshin Rostamizadeh, Ameet Talwalkar, Hyperband: A Novel Bandit-Based Approach to Hyperparameter Optimization, JMLR 2018\n[8] Stefan Falkner, Aaron Klein, Frank Hutter, BOHB: Robust and Efficient Hyperparameter Optimization at Scale, ICML 2018"}, "signatures": ["ICLR.cc/2020/Conference/Paper2547/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper2547/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["zelaa@cs.uni-freiburg.de", "siemsj@cs.uni-freiburg.de", "fh@cs.uni-freiburg.de"], "title": "NAS-Bench-1Shot1: Benchmarking and Dissecting One-shot Neural Architecture Search", "authors": ["Arber Zela", "Julien Siems", "Frank Hutter"], "pdf": "/pdf/629de63a76318d4dba0710a49082db53188ddd27.pdf", "abstract": "One-shot neural architecture search (NAS) has played a crucial role in making\nNAS methods computationally feasible in practice. Nevertheless, there is still a\nlack of understanding on how these weight-sharing algorithms exactly work due\nto the many factors controlling the dynamics of the process. In order to allow\na scientific study of these components, we introduce a general framework for\none-shot NAS that can be instantiated to many recently-introduced variants and\nintroduce a general benchmarking framework that draws on the recent large-scale\ntabular benchmark NAS-Bench-101 for cheap anytime evaluations of one-shot\nNAS methods. To showcase the framework, we compare several state-of-the-art\none-shot NAS methods, examine how sensitive they are to their hyperparameters\nand how they can be improved by tuning their hyperparameters, and compare their\nperformance to that of blackbox optimizers for NAS-Bench-101.", "code": "https://github.com/automl/nasbench-1shot1", "keywords": ["Neural Architecture Search", "Deep Learning", "Computer Vision"], "paperhash": "zela|nasbench1shot1_benchmarking_and_dissecting_oneshot_neural_architecture_search", "_bibtex": "@inproceedings{\nZela2020NAS-Bench-1Shot1:,\ntitle={NAS-Bench-1Shot1: Benchmarking and Dissecting One-shot Neural Architecture Search},\nauthor={Arber Zela and Julien Siems and Frank Hutter},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=SJx9ngStPH}\n}", "full_presentation_video": "", "original_pdf": "/attachment/f33f4aa80d5c9e7e2758b5e94f9ebcbce1954a56.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "SJx9ngStPH", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper2547/Authors", "ICLR.cc/2020/Conference/Paper2547/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper2547/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper2547/Reviewers", "ICLR.cc/2020/Conference/Paper2547/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper2547/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper2547/Authors|ICLR.cc/2020/Conference/Paper2547/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504139694, "tmdate": 1576860545933, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper2547/Authors", "ICLR.cc/2020/Conference/Paper2547/Reviewers", "ICLR.cc/2020/Conference/Paper2547/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper2547/-/Official_Comment"}}}, {"id": "BkeNfNCFjB", "original": null, "number": 5, "cdate": 1573671947575, "ddate": null, "tcdate": 1573671947575, "tmdate": 1573672008327, "tddate": null, "forum": "SJx9ngStPH", "replyto": "SkljhB5ndB", "invitation": "ICLR.cc/2020/Conference/Paper2547/-/Official_Comment", "content": {"title": "Response to Reviewer #1 (1/2)", "comment": "We would like to thank the reviewer for his/her feedback. We address the concerns raised by the reviewer in the following paragraphs:\n\n> The main contribution of this submission is the benchmark NAS-Bench-1Shot1, which can benefit future research for one-shot NAS. However, this benchmark is based on NAS-Bench-101 [1], and the difference is that NAS-Bench-101 only contains discrete architecture, while the presented NAS-Bench-1Shot1 has a component to discretize architectures and then match to NAS-Bench-101. The novelty may not be enough. \n\nWe agree with the reviewer that NAS-Bench-101 is not new, but we argue that our paper is nevertheless novel, because:\n- Finding a way to reuse NAS-Bench-101 is one of the strengths of our approach, since the immense computational resources required to generate NAS-Bench-101 (120 TPU years!) can be efficiently reused this way. We believe this is indeed *more* novel than to simply create another benchmark, and it is far more environmentally friendly since it comes with zero additional computational burden. As we demonstrate in our paper our benchmark allows for a quick and thorough analysis of different NAS methods, which would otherwise be too time consuming. \n\n- The mapping between different search space representations is novel to the best of our knowledge. Most previous work in NAS represents the architecture search space as a directed acyclic graph, however they differ by where the operation choices are encoded in the graph -- either nodes (e.g. ENAS [2]) or edges (e.g. DARTS [3]). By introducing a framework that allows us to create search spaces that automatically satisfy all the constraints in NAS-Bench-101, one can clearly investigate the contribution that each specific algorithm has on the achieved performance, without adding a confounding factor due to a different search space.\n\n- A correlation analysis between the stand-alone architectures evaluated with the one-shot weights and retrained from scratch has not been done before for all the architectures in such a large search space (more than 360k architectures).\n\n- As the reviewer already pointed out, the tunability of one-shot NAS optimizers has not been addressed before.\n\n> The authors claim that they introduce a general framework for one-shot NAS methods. Personally, I think this is over-claimed. There are several variants of DARTS, and the authors just implement these variants and DARTS itself in a unified code base. It would be a true general framework if it can also work with other one-shot NAS methods such as ENAS and the rest ones.\n\nWe acknowledge that at the time of submission we had focused on implementing various NAS methods based on DARTS, due to the interest which it has created in the community. However, while the code base of Random NAS with weight sharing [4] is based on DARTS, its search method differs and already demonstrates that similar sampling-based search methods can also fit into our framework. (Indeed, our framework allows to give further clues on why the results of RandomWS were subpar, by demonstrating the weak correlation between one-shot model and final architecture performance.) We have now integrated ENAS (Algorithm 5 in the paper) in our framework and updated the figures in the paper accordingly. Thanks for this suggestion! We are currently working on integrating other methods, such as ProxylessNAS [5] or SNAS [6].\n\nNote that our claim that NAS-Bench-1Shot1 is a general framework for one-shot NAS methods (and not only; also for NAS methods using black-box optimizers) is also due to our novel unification between different graph representations in existing NAS papers.\n\nOne other advantage of using the NAS-Bench-101 benchmark is the evaluation of all the architectures using different budgets. This allows evaluating the sensitivity of NAS algorithms during search with respect to the number of epochs used to train individual architectures for estimating the validation error returned to the NAS optimizer (e.g., one can expect a different behavior of ENAS if the sampled architectures from the controller would be evaluated using the lowest or the highest training budget in NAS-Bench-101). This also allows running multi-fidelity black-box optimizers, such as Hyperband [7] or BOHB [8], in our framework.\n\n> One interesting thing is that the authors try to use HPO method such as BOHB to tune the hyperparameter of NAS methods.\n\nThanks! We also updated the results with more HPO runs. \n\nWe hope that with this response we addressed all your concerns and that you will consider updating your assessment, particularly seeing that we have now demonstrated that our framework also encompasses ENAS. Thank you for your time and effort."}, "signatures": ["ICLR.cc/2020/Conference/Paper2547/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper2547/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["zelaa@cs.uni-freiburg.de", "siemsj@cs.uni-freiburg.de", "fh@cs.uni-freiburg.de"], "title": "NAS-Bench-1Shot1: Benchmarking and Dissecting One-shot Neural Architecture Search", "authors": ["Arber Zela", "Julien Siems", "Frank Hutter"], "pdf": "/pdf/629de63a76318d4dba0710a49082db53188ddd27.pdf", "abstract": "One-shot neural architecture search (NAS) has played a crucial role in making\nNAS methods computationally feasible in practice. Nevertheless, there is still a\nlack of understanding on how these weight-sharing algorithms exactly work due\nto the many factors controlling the dynamics of the process. In order to allow\na scientific study of these components, we introduce a general framework for\none-shot NAS that can be instantiated to many recently-introduced variants and\nintroduce a general benchmarking framework that draws on the recent large-scale\ntabular benchmark NAS-Bench-101 for cheap anytime evaluations of one-shot\nNAS methods. To showcase the framework, we compare several state-of-the-art\none-shot NAS methods, examine how sensitive they are to their hyperparameters\nand how they can be improved by tuning their hyperparameters, and compare their\nperformance to that of blackbox optimizers for NAS-Bench-101.", "code": "https://github.com/automl/nasbench-1shot1", "keywords": ["Neural Architecture Search", "Deep Learning", "Computer Vision"], "paperhash": "zela|nasbench1shot1_benchmarking_and_dissecting_oneshot_neural_architecture_search", "_bibtex": "@inproceedings{\nZela2020NAS-Bench-1Shot1:,\ntitle={NAS-Bench-1Shot1: Benchmarking and Dissecting One-shot Neural Architecture Search},\nauthor={Arber Zela and Julien Siems and Frank Hutter},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=SJx9ngStPH}\n}", "full_presentation_video": "", "original_pdf": "/attachment/f33f4aa80d5c9e7e2758b5e94f9ebcbce1954a56.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "SJx9ngStPH", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper2547/Authors", "ICLR.cc/2020/Conference/Paper2547/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper2547/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper2547/Reviewers", "ICLR.cc/2020/Conference/Paper2547/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper2547/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper2547/Authors|ICLR.cc/2020/Conference/Paper2547/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504139694, "tmdate": 1576860545933, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper2547/Authors", "ICLR.cc/2020/Conference/Paper2547/Reviewers", "ICLR.cc/2020/Conference/Paper2547/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper2547/-/Official_Comment"}}}, {"id": "HyxD2ZRFjH", "original": null, "number": 4, "cdate": 1573671342949, "ddate": null, "tcdate": 1573671342949, "tmdate": 1573671342949, "tddate": null, "forum": "SJx9ngStPH", "replyto": "BkeRiU01qB", "invitation": "ICLR.cc/2020/Conference/Paper2547/-/Official_Comment", "content": {"title": "Response to Reviewer #2", "comment": "We greatly appreciate the reviewer's effort and the very positive review. We share the reviewer\u2019s hope that NAS-Bench-1Shot1 will serve the community to prototype and benchmark NAS algorithms without confounding factors."}, "signatures": ["ICLR.cc/2020/Conference/Paper2547/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper2547/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["zelaa@cs.uni-freiburg.de", "siemsj@cs.uni-freiburg.de", "fh@cs.uni-freiburg.de"], "title": "NAS-Bench-1Shot1: Benchmarking and Dissecting One-shot Neural Architecture Search", "authors": ["Arber Zela", "Julien Siems", "Frank Hutter"], "pdf": "/pdf/629de63a76318d4dba0710a49082db53188ddd27.pdf", "abstract": "One-shot neural architecture search (NAS) has played a crucial role in making\nNAS methods computationally feasible in practice. Nevertheless, there is still a\nlack of understanding on how these weight-sharing algorithms exactly work due\nto the many factors controlling the dynamics of the process. In order to allow\na scientific study of these components, we introduce a general framework for\none-shot NAS that can be instantiated to many recently-introduced variants and\nintroduce a general benchmarking framework that draws on the recent large-scale\ntabular benchmark NAS-Bench-101 for cheap anytime evaluations of one-shot\nNAS methods. To showcase the framework, we compare several state-of-the-art\none-shot NAS methods, examine how sensitive they are to their hyperparameters\nand how they can be improved by tuning their hyperparameters, and compare their\nperformance to that of blackbox optimizers for NAS-Bench-101.", "code": "https://github.com/automl/nasbench-1shot1", "keywords": ["Neural Architecture Search", "Deep Learning", "Computer Vision"], "paperhash": "zela|nasbench1shot1_benchmarking_and_dissecting_oneshot_neural_architecture_search", "_bibtex": "@inproceedings{\nZela2020NAS-Bench-1Shot1:,\ntitle={NAS-Bench-1Shot1: Benchmarking and Dissecting One-shot Neural Architecture Search},\nauthor={Arber Zela and Julien Siems and Frank Hutter},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=SJx9ngStPH}\n}", "full_presentation_video": "", "original_pdf": "/attachment/f33f4aa80d5c9e7e2758b5e94f9ebcbce1954a56.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "SJx9ngStPH", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper2547/Authors", "ICLR.cc/2020/Conference/Paper2547/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper2547/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper2547/Reviewers", "ICLR.cc/2020/Conference/Paper2547/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper2547/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper2547/Authors|ICLR.cc/2020/Conference/Paper2547/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504139694, "tmdate": 1576860545933, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper2547/Authors", "ICLR.cc/2020/Conference/Paper2547/Reviewers", "ICLR.cc/2020/Conference/Paper2547/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper2547/-/Official_Comment"}}}, {"id": "BJgaF-RFsr", "original": null, "number": 3, "cdate": 1573671300919, "ddate": null, "tcdate": 1573671300919, "tmdate": 1573671300919, "tddate": null, "forum": "SJx9ngStPH", "replyto": "Byxt3MX9qH", "invitation": "ICLR.cc/2020/Conference/Paper2547/-/Official_Comment", "content": {"title": "Response to Reviewer #4", "comment": "We thank the reviewer for reading our paper thoroughly and for the very positive feedback. \n\n> the background section might be improved\nBased on the reviewer\u2019s suggestion we updated Section 2 in the paper and added some more details for each respective NAS method we used throughout the paper in Appendix B. We hope that now the concepts will be easier to understand, also for a reader not familiar with the different NAS paradigms, and without going through the literature in detail."}, "signatures": ["ICLR.cc/2020/Conference/Paper2547/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper2547/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["zelaa@cs.uni-freiburg.de", "siemsj@cs.uni-freiburg.de", "fh@cs.uni-freiburg.de"], "title": "NAS-Bench-1Shot1: Benchmarking and Dissecting One-shot Neural Architecture Search", "authors": ["Arber Zela", "Julien Siems", "Frank Hutter"], "pdf": "/pdf/629de63a76318d4dba0710a49082db53188ddd27.pdf", "abstract": "One-shot neural architecture search (NAS) has played a crucial role in making\nNAS methods computationally feasible in practice. Nevertheless, there is still a\nlack of understanding on how these weight-sharing algorithms exactly work due\nto the many factors controlling the dynamics of the process. In order to allow\na scientific study of these components, we introduce a general framework for\none-shot NAS that can be instantiated to many recently-introduced variants and\nintroduce a general benchmarking framework that draws on the recent large-scale\ntabular benchmark NAS-Bench-101 for cheap anytime evaluations of one-shot\nNAS methods. To showcase the framework, we compare several state-of-the-art\none-shot NAS methods, examine how sensitive they are to their hyperparameters\nand how they can be improved by tuning their hyperparameters, and compare their\nperformance to that of blackbox optimizers for NAS-Bench-101.", "code": "https://github.com/automl/nasbench-1shot1", "keywords": ["Neural Architecture Search", "Deep Learning", "Computer Vision"], "paperhash": "zela|nasbench1shot1_benchmarking_and_dissecting_oneshot_neural_architecture_search", "_bibtex": "@inproceedings{\nZela2020NAS-Bench-1Shot1:,\ntitle={NAS-Bench-1Shot1: Benchmarking and Dissecting One-shot Neural Architecture Search},\nauthor={Arber Zela and Julien Siems and Frank Hutter},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=SJx9ngStPH}\n}", "full_presentation_video": "", "original_pdf": "/attachment/f33f4aa80d5c9e7e2758b5e94f9ebcbce1954a56.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "SJx9ngStPH", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper2547/Authors", "ICLR.cc/2020/Conference/Paper2547/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper2547/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper2547/Reviewers", "ICLR.cc/2020/Conference/Paper2547/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper2547/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper2547/Authors|ICLR.cc/2020/Conference/Paper2547/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504139694, "tmdate": 1576860545933, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper2547/Authors", "ICLR.cc/2020/Conference/Paper2547/Reviewers", "ICLR.cc/2020/Conference/Paper2547/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper2547/-/Official_Comment"}}}, {"id": "SyxkV1RtsH", "original": null, "number": 1, "cdate": 1573670694599, "ddate": null, "tcdate": 1573670694599, "tmdate": 1573670883044, "tddate": null, "forum": "SJx9ngStPH", "replyto": "SJx9ngStPH", "invitation": "ICLR.cc/2020/Conference/Paper2547/-/Official_Comment", "content": {"title": "General comment to the AC and to reviewers", "comment": "We thank the reviewers for reading our paper thoroughly and for their feedback. We updated the paper as follows:\n- More independent runs for each method in all the experiments in the paper.\n- Added ENAS [1] (Algorithm 5 in the paper) to the codebase and benchmarked it in all our search spaces. The results for this optimizer are shown in Figure 2 and Figure 7 in the paper.\n- Added more detailed information to the background section.\n- Fixed a small bug in the codebase and updated the plots with the new results. The paper\u2019s analysis and conclusions of course remain unchanged. In order to make the results reproducible, we provide all the seeds and settings with the code release.\n\nWe would like to note that there was a parallel concurrent work submitted to ICLR 2020 named: \u201cAn Algorithm-Agnostic NAS Benchmark\u201d. We believe this is also a very valuable benchmark, and it also received very positive scores (8,8,6); the reason we point this out here is that we believe the reviewers\u2019 arguments for giving high scores also apply to our paper. In particular, they emphasize the importance of good benchmarks like these for one-shot NAS algorithms in the reproducibility crisis. The main differences between the two benchmarks are as follows:\n\n- They use extensive computation to create a *new* benchmark (with 15.625 architectures), while we devise a novel reformulation to reuse the even much more extensive computation of the NAS-Bench-101 dataset (~120 TPU years) to create three new one-shot search spaces with 6240, 29.160, and 363.648 architectures each. \n- We believe that our reuse of the extreme computation of NAS-Bench-101 is environmentally friendly, since it provides similar value as a new benchmark at zero computational cost.\n- We show that (contrary to their claim), it *is* possible to reuse the graph representation in NAS-Bench-101 to run one-shot NAS methods; this requires changes to the one-shot search space, but allows a mapping which can be used for architecture evaluation. \n- They evaluate their search space on 3 image classification datasets, while we introduce 3 different search spaces (as sub-spaces of NAS-Bench-101) with growing complexity.\n- Our paper does not only serve as a benchmark, but also provides additional insights into the NAS optimization process, such as:\n      1. Investigating the correlation between the stand-alone models evaluated with the one-shot weights vs. retrained from scratch (to the best of our knowledge, the first time this is done for a large search space (more than 360k architectures).\n      2. Analyzing the anytime performance of one-shot NAS algorithms\n      3. Tuning the hyperparameters these optimizers such that they perform comparable with black-box NAS optimizers with the same number of function evaluations.\n\nWe thank the reviewers and the AC for their time and effort for ICLR.\n\n-- References --\n[1] Hieu Pham, Melody Y. Guan, Barret Zoph, Quoc V. Le, Jeff Dean, Efficient Neural Architecture Search via Parameter Sharing, ICML 2018"}, "signatures": ["ICLR.cc/2020/Conference/Paper2547/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper2547/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["zelaa@cs.uni-freiburg.de", "siemsj@cs.uni-freiburg.de", "fh@cs.uni-freiburg.de"], "title": "NAS-Bench-1Shot1: Benchmarking and Dissecting One-shot Neural Architecture Search", "authors": ["Arber Zela", "Julien Siems", "Frank Hutter"], "pdf": "/pdf/629de63a76318d4dba0710a49082db53188ddd27.pdf", "abstract": "One-shot neural architecture search (NAS) has played a crucial role in making\nNAS methods computationally feasible in practice. Nevertheless, there is still a\nlack of understanding on how these weight-sharing algorithms exactly work due\nto the many factors controlling the dynamics of the process. In order to allow\na scientific study of these components, we introduce a general framework for\none-shot NAS that can be instantiated to many recently-introduced variants and\nintroduce a general benchmarking framework that draws on the recent large-scale\ntabular benchmark NAS-Bench-101 for cheap anytime evaluations of one-shot\nNAS methods. To showcase the framework, we compare several state-of-the-art\none-shot NAS methods, examine how sensitive they are to their hyperparameters\nand how they can be improved by tuning their hyperparameters, and compare their\nperformance to that of blackbox optimizers for NAS-Bench-101.", "code": "https://github.com/automl/nasbench-1shot1", "keywords": ["Neural Architecture Search", "Deep Learning", "Computer Vision"], "paperhash": "zela|nasbench1shot1_benchmarking_and_dissecting_oneshot_neural_architecture_search", "_bibtex": "@inproceedings{\nZela2020NAS-Bench-1Shot1:,\ntitle={NAS-Bench-1Shot1: Benchmarking and Dissecting One-shot Neural Architecture Search},\nauthor={Arber Zela and Julien Siems and Frank Hutter},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=SJx9ngStPH}\n}", "full_presentation_video": "", "original_pdf": "/attachment/f33f4aa80d5c9e7e2758b5e94f9ebcbce1954a56.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "SJx9ngStPH", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper2547/Authors", "ICLR.cc/2020/Conference/Paper2547/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper2547/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper2547/Reviewers", "ICLR.cc/2020/Conference/Paper2547/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper2547/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper2547/Authors|ICLR.cc/2020/Conference/Paper2547/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504139694, "tmdate": 1576860545933, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper2547/Authors", "ICLR.cc/2020/Conference/Paper2547/Reviewers", "ICLR.cc/2020/Conference/Paper2547/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper2547/-/Official_Comment"}}}, {"id": "SkljhB5ndB", "original": null, "number": 1, "cdate": 1570706866639, "ddate": null, "tcdate": 1570706866639, "tmdate": 1572972324163, "tddate": null, "forum": "SJx9ngStPH", "replyto": "SJx9ngStPH", "invitation": "ICLR.cc/2020/Conference/Paper2547/-/Official_Review", "content": {"rating": "1: Reject", "experience_assessment": "I have read many papers in this area.", "review_assessment:_checking_correctness_of_derivations_and_theory": "N/A", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #1", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review": "In this submission, the authors present a benchmark NAS-Bench-1Shot1 for one-shot Network Architecture Search. The presented benchmark reuses the existing NAS-Bench-101 that only contains discrete architectures, and the authors give a method to discretize architectures to match NAS-Bench-101. Also, the authors claim that they introduce a general framework for one-shot NAS methods.\n\nOverall speaking, the technique contribution and novelty of this submission requires further improvement, and I suggest to rejecting this submission. The reasons are detailed as follows:\n\n1) The main contribution of this submission is the benchmark NAS-Bench-1Shot1, which can benefit future research for one-shot NAS. However, this benchmark is based on NAS-Bench-101, and the difference is that NAS-Bench-101 only contains discrete architecture, while the presented NAS-Bench-1Shot1 has a component to discretize architectures and then match to NAS-Bench-101. The novelty may not be enough.\n\n2) The authors claim that they introduce a general framework for one-shot NAS methods. Personally, I think this is over-claimed. There are several variants of DARTS, and the authors just implement these variants and DARTS itself in a unified code base. It would be a true general framework if it can also work with other one-shot NAS methods such as ENAS and the rest ones.\n\nGiven these, this submission requires further improvement, especially in terms of technique contribution and novelty. \n\nOne interesting thing is that the authors try to use HPO method such as BOHB to tune the hyperparameter of NAS methods."}, "signatures": ["ICLR.cc/2020/Conference/Paper2547/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper2547/AnonReviewer1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["zelaa@cs.uni-freiburg.de", "siemsj@cs.uni-freiburg.de", "fh@cs.uni-freiburg.de"], "title": "NAS-Bench-1Shot1: Benchmarking and Dissecting One-shot Neural Architecture Search", "authors": ["Arber Zela", "Julien Siems", "Frank Hutter"], "pdf": "/pdf/629de63a76318d4dba0710a49082db53188ddd27.pdf", "abstract": "One-shot neural architecture search (NAS) has played a crucial role in making\nNAS methods computationally feasible in practice. Nevertheless, there is still a\nlack of understanding on how these weight-sharing algorithms exactly work due\nto the many factors controlling the dynamics of the process. In order to allow\na scientific study of these components, we introduce a general framework for\none-shot NAS that can be instantiated to many recently-introduced variants and\nintroduce a general benchmarking framework that draws on the recent large-scale\ntabular benchmark NAS-Bench-101 for cheap anytime evaluations of one-shot\nNAS methods. To showcase the framework, we compare several state-of-the-art\none-shot NAS methods, examine how sensitive they are to their hyperparameters\nand how they can be improved by tuning their hyperparameters, and compare their\nperformance to that of blackbox optimizers for NAS-Bench-101.", "code": "https://github.com/automl/nasbench-1shot1", "keywords": ["Neural Architecture Search", "Deep Learning", "Computer Vision"], "paperhash": "zela|nasbench1shot1_benchmarking_and_dissecting_oneshot_neural_architecture_search", "_bibtex": "@inproceedings{\nZela2020NAS-Bench-1Shot1:,\ntitle={NAS-Bench-1Shot1: Benchmarking and Dissecting One-shot Neural Architecture Search},\nauthor={Arber Zela and Julien Siems and Frank Hutter},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=SJx9ngStPH}\n}", "full_presentation_video": "", "original_pdf": "/attachment/f33f4aa80d5c9e7e2758b5e94f9ebcbce1954a56.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "SJx9ngStPH", "replyto": "SJx9ngStPH", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper2547/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper2547/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1575547573208, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper2547/Reviewers"], "noninvitees": [], "tcdate": 1570237721292, "tmdate": 1575547573227, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper2547/-/Official_Review"}}}, {"id": "BkeRiU01qB", "original": null, "number": 2, "cdate": 1571968678452, "ddate": null, "tcdate": 1571968678452, "tmdate": 1572972324127, "tddate": null, "forum": "SJx9ngStPH", "replyto": "SJx9ngStPH", "invitation": "ICLR.cc/2020/Conference/Paper2547/-/Official_Review", "content": {"experience_assessment": "I have read many papers in this area.", "rating": "8: Accept", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #2", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "\nThis paper proposes a benchmark dataset for evaluating One-Short Neural Architecture Search models. It extends on the idea of the NASBench-101 (Ying et. al., 2019) into One-Shot models. \n\nI think this is important work. With all the development of neural archictecture search methods, reproducible research is paramount. This is even more timely considering the fact that these problems are computationally expensive, so it is even more computationally difficult than usual to run exhaustive comparisons among proposed methods. \n\nThe paper is well-written and the design decisions are clearly explained. The comparison of NAS methods is also interesting to read. In general, I think this is a worthy publication. \n"}, "signatures": ["ICLR.cc/2020/Conference/Paper2547/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper2547/AnonReviewer2"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["zelaa@cs.uni-freiburg.de", "siemsj@cs.uni-freiburg.de", "fh@cs.uni-freiburg.de"], "title": "NAS-Bench-1Shot1: Benchmarking and Dissecting One-shot Neural Architecture Search", "authors": ["Arber Zela", "Julien Siems", "Frank Hutter"], "pdf": "/pdf/629de63a76318d4dba0710a49082db53188ddd27.pdf", "abstract": "One-shot neural architecture search (NAS) has played a crucial role in making\nNAS methods computationally feasible in practice. Nevertheless, there is still a\nlack of understanding on how these weight-sharing algorithms exactly work due\nto the many factors controlling the dynamics of the process. In order to allow\na scientific study of these components, we introduce a general framework for\none-shot NAS that can be instantiated to many recently-introduced variants and\nintroduce a general benchmarking framework that draws on the recent large-scale\ntabular benchmark NAS-Bench-101 for cheap anytime evaluations of one-shot\nNAS methods. To showcase the framework, we compare several state-of-the-art\none-shot NAS methods, examine how sensitive they are to their hyperparameters\nand how they can be improved by tuning their hyperparameters, and compare their\nperformance to that of blackbox optimizers for NAS-Bench-101.", "code": "https://github.com/automl/nasbench-1shot1", "keywords": ["Neural Architecture Search", "Deep Learning", "Computer Vision"], "paperhash": "zela|nasbench1shot1_benchmarking_and_dissecting_oneshot_neural_architecture_search", "_bibtex": "@inproceedings{\nZela2020NAS-Bench-1Shot1:,\ntitle={NAS-Bench-1Shot1: Benchmarking and Dissecting One-shot Neural Architecture Search},\nauthor={Arber Zela and Julien Siems and Frank Hutter},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=SJx9ngStPH}\n}", "full_presentation_video": "", "original_pdf": "/attachment/f33f4aa80d5c9e7e2758b5e94f9ebcbce1954a56.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "SJx9ngStPH", "replyto": "SJx9ngStPH", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper2547/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper2547/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1575547573208, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper2547/Reviewers"], "noninvitees": [], "tcdate": 1570237721292, "tmdate": 1575547573227, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper2547/-/Official_Review"}}}, {"id": "Byxt3MX9qH", "original": null, "number": 3, "cdate": 1572643504862, "ddate": null, "tcdate": 1572643504862, "tmdate": 1572972324078, "tddate": null, "forum": "SJx9ngStPH", "replyto": "SJx9ngStPH", "invitation": "ICLR.cc/2020/Conference/Paper2547/-/Official_Review", "content": {"rating": "8: Accept", "experience_assessment": "I do not know much about this area.", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #4", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review": "This paper introduces a benchmarking framework to evaluate a class of one-shot NAS methods by exploiting the NAS-Bench-101 database. In order to do so, the authors apply techniques from Bender et al. (2018) to match the search spaces in NAS-Bench to one-shot scenarios and weight edges in the search graph allowing for a variable number of edges per cell. These weights are then used to query a larger, discrete architecture from NAS-Bench for the corresponding evaluation errors. The authors motivate the soundness of a unique framework by showing minimal differences between three NAS optimizers. \nIn their analysis, they also corroborate the findings of Sciuto et al. (2019) on a larger scale, showing little generalization of the ranking from one-shot validation to the final architecture. Finally, the authors also use this framework to show that a fine-tuned baseline compares favorably to SOTA methods, and that large regularization factors lead to more robust configurations.\n\nThe paper is well-written and introduces a framework to cheaply compare one-shot NAS optimizers based on expensive computations behind the NAS-Bench-101 benchmark. In addition, the authors provide empirical analyses that reflect generalization and regularization issues with current methods and that could lead towards designing more robust algorithms. \n\nIn my opinion, the the background section might be improved by presenting higher level notions that would lead to an easier understanding by a wider audience. Also, although comprehensible due to the nature of this study, readers not familiar with a variety of previous work might find difficult to parse the paper as many concepts are just referenced."}, "signatures": ["ICLR.cc/2020/Conference/Paper2547/AnonReviewer4"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper2547/AnonReviewer4"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["zelaa@cs.uni-freiburg.de", "siemsj@cs.uni-freiburg.de", "fh@cs.uni-freiburg.de"], "title": "NAS-Bench-1Shot1: Benchmarking and Dissecting One-shot Neural Architecture Search", "authors": ["Arber Zela", "Julien Siems", "Frank Hutter"], "pdf": "/pdf/629de63a76318d4dba0710a49082db53188ddd27.pdf", "abstract": "One-shot neural architecture search (NAS) has played a crucial role in making\nNAS methods computationally feasible in practice. Nevertheless, there is still a\nlack of understanding on how these weight-sharing algorithms exactly work due\nto the many factors controlling the dynamics of the process. In order to allow\na scientific study of these components, we introduce a general framework for\none-shot NAS that can be instantiated to many recently-introduced variants and\nintroduce a general benchmarking framework that draws on the recent large-scale\ntabular benchmark NAS-Bench-101 for cheap anytime evaluations of one-shot\nNAS methods. To showcase the framework, we compare several state-of-the-art\none-shot NAS methods, examine how sensitive they are to their hyperparameters\nand how they can be improved by tuning their hyperparameters, and compare their\nperformance to that of blackbox optimizers for NAS-Bench-101.", "code": "https://github.com/automl/nasbench-1shot1", "keywords": ["Neural Architecture Search", "Deep Learning", "Computer Vision"], "paperhash": "zela|nasbench1shot1_benchmarking_and_dissecting_oneshot_neural_architecture_search", "_bibtex": "@inproceedings{\nZela2020NAS-Bench-1Shot1:,\ntitle={NAS-Bench-1Shot1: Benchmarking and Dissecting One-shot Neural Architecture Search},\nauthor={Arber Zela and Julien Siems and Frank Hutter},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=SJx9ngStPH}\n}", "full_presentation_video": "", "original_pdf": "/attachment/f33f4aa80d5c9e7e2758b5e94f9ebcbce1954a56.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "SJx9ngStPH", "replyto": "SJx9ngStPH", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper2547/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper2547/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1575547573208, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper2547/Reviewers"], "noninvitees": [], "tcdate": 1570237721292, "tmdate": 1575547573227, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper2547/-/Official_Review"}}}], "count": 10}