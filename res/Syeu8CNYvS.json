{"notes": [{"id": "Syeu8CNYvS", "original": "S1ezsZwuPB", "number": 1143, "cdate": 1569439311522, "ddate": null, "tcdate": 1569439311522, "tmdate": 1577168253240, "tddate": null, "forum": "Syeu8CNYvS", "replyto": null, "invitation": "ICLR.cc/2020/Conference/-/Blind_Submission", "content": {"title": "MODELLING   BIOLOGICAL   ASSAYS   WITH ADAPTIVE DEEP KERNEL LEARNING", "authors": ["Prudencio Tossou", "Basile Dura", "Daniel Cohen", "Mario Marchand", "Fran\u00e7ois Laviolette", "Alexandre Lacoste"], "authorids": ["tossouprudencio@gmail.com", "basile@invivoai.ca", "daniel@invivoai.ca", "mario.marchand@ift.ulaval.ca", "francois.laviolette@ift.ulaval.ca", "allac@elementai.com"], "keywords": ["few-shot learning", "few-shot regression", "deep kernel learning", "biological assay modelling", "drug discovery"], "TL;DR": "We investigate the modelling of biological assays using deep kernel learning in few-shot settings.", "abstract": "Due to the significant costs of data generation, many prediction tasks within drug discovery are by nature few-shot regression (FSR) problems, including accurate modelling of biological assays.  Although a number of few-shot classification and reinforcement learning methods exist for similar applications, we find relatively few FSR methods meeting the performance standards required for such tasks under real-world constraints. Inspired by deep kernel learning, we develop a novel FSR algorithm that is better suited to these settings. Our algorithm consists of learning a deep network in combination with a kernel function and a differentiable kernel algorithm. As the choice of the kernel is critical, our algorithm learns to find the appropriate one for each task during inference. It thus performs more effectively with complex task distributions, outperforming current state-of-the-art algorithms on both toy and novel, real-world benchmarks that we introduce herein. By introducing novel benchmarks derived from biological assays, we hope that the community will progress towards the development of FSR algorithms suitable for use in noisy and uncertain environments such as drug discovery.", "pdf": "/pdf/c0c794d29ce86c937dcb0760e85a8d2557597764.pdf", "paperhash": "tossou|modelling_biological_assays_with_adaptive_deep_kernel_learning", "original_pdf": "/attachment/169ccbd6d9cda53fa854a14e36a066f19d913657.pdf", "_bibtex": "@misc{\ntossou2020modelling,\ntitle={{\\{}MODELLING{\\}}   {\\{}BIOLOGICAL{\\}}   {\\{}ASSAYS{\\}}   {\\{}WITH{\\}} {\\{}ADAPTIVE{\\}} {\\{}DEEP{\\}} {\\{}KERNEL{\\}} {\\{}LEARNING{\\}}},\nauthor={Prudencio Tossou and Basile Dura and Daniel Cohen and Mario Marchand and Fran{\\c{c}}ois Laviolette and Alexandre Lacoste},\nyear={2020},\nurl={https://openreview.net/forum?id=Syeu8CNYvS}\n}"}, "signatures": ["ICLR.cc/2020/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference"], "details": {"replyCount": 17, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"reply": {"readers": {"values-regex": ".*"}, "writers": {"values": ["ICLR.cc/2020/Conference"]}, "signatures": {"values": ["ICLR.cc/2020/Conference"]}, "content": {"spotlight_video": {"value-regex": ".*"}, "full_presentation_video": {"value-regex": ".*"}, "original_pdf": {"required": false, "description": "Upload a PDF file that ends with .pdf", "value-regex": ".*"}, "appendix": {"value-regex": ".*"}, "authorids": {"values-regex": ".*"}, "poster": {"value-regex": ".*"}, "authors": {"values": ["Anonymous"]}, "slides": {"value-regex": ".*"}}}, "final": [], "signatures": ["ICLR.cc/2020/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference"], "noninvitees": [], "tcdate": 1569271260237, "tmdate": 1593459412141, "id": "ICLR.cc/2020/Conference/-/Blind_Submission"}}, "tauthor": "OpenReview.net"}, {"id": "rLBkW3BIh5", "original": null, "number": 1, "cdate": 1576798715610, "ddate": null, "tcdate": 1576798715610, "tmdate": 1576800920924, "tddate": null, "forum": "Syeu8CNYvS", "replyto": "Syeu8CNYvS", "invitation": "ICLR.cc/2020/Conference/Paper1143/-/Decision", "content": {"decision": "Reject", "comment": "This work applies deep kernel learning to the problem of few shot regression for modeling biological assays. To deal with sparse data on new tasks, the authors propose to adapt the learned kernel to each task. Reviews were mixed about the method and experiments, some reviewers were satisfied with the author rebuttal while others did not support acceptance during the discussion period. Some reviewers ultimately felt that the experimental results were too weak to warrant publication. On the binding task the method is comparable with simpler baselines, and some felt that the gains on antibacterial were unconvincing. \nOther reviewers felt that there remained simpler baselines to compare with, for example ablating the affects of learning the kernel with simple hand picking one. While authors commented they tried this, there were no details given on the results or what exactly they tried. \n\nBased on the reviewer discussion, the work feels too preliminary in its current form to warrant publication in ICLR. However, given that there are clearly some interesting ideas proposed in this work, I recommend resubmitting with stronger experimental evidence that the method helps over baselines.", "title": "Paper Decision"}, "signatures": ["ICLR.cc/2020/Conference/Program_Chairs"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Program_Chairs"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "MODELLING   BIOLOGICAL   ASSAYS   WITH ADAPTIVE DEEP KERNEL LEARNING", "authors": ["Prudencio Tossou", "Basile Dura", "Daniel Cohen", "Mario Marchand", "Fran\u00e7ois Laviolette", "Alexandre Lacoste"], "authorids": ["tossouprudencio@gmail.com", "basile@invivoai.ca", "daniel@invivoai.ca", "mario.marchand@ift.ulaval.ca", "francois.laviolette@ift.ulaval.ca", "allac@elementai.com"], "keywords": ["few-shot learning", "few-shot regression", "deep kernel learning", "biological assay modelling", "drug discovery"], "TL;DR": "We investigate the modelling of biological assays using deep kernel learning in few-shot settings.", "abstract": "Due to the significant costs of data generation, many prediction tasks within drug discovery are by nature few-shot regression (FSR) problems, including accurate modelling of biological assays.  Although a number of few-shot classification and reinforcement learning methods exist for similar applications, we find relatively few FSR methods meeting the performance standards required for such tasks under real-world constraints. Inspired by deep kernel learning, we develop a novel FSR algorithm that is better suited to these settings. Our algorithm consists of learning a deep network in combination with a kernel function and a differentiable kernel algorithm. As the choice of the kernel is critical, our algorithm learns to find the appropriate one for each task during inference. It thus performs more effectively with complex task distributions, outperforming current state-of-the-art algorithms on both toy and novel, real-world benchmarks that we introduce herein. By introducing novel benchmarks derived from biological assays, we hope that the community will progress towards the development of FSR algorithms suitable for use in noisy and uncertain environments such as drug discovery.", "pdf": "/pdf/c0c794d29ce86c937dcb0760e85a8d2557597764.pdf", "paperhash": "tossou|modelling_biological_assays_with_adaptive_deep_kernel_learning", "original_pdf": "/attachment/169ccbd6d9cda53fa854a14e36a066f19d913657.pdf", "_bibtex": "@misc{\ntossou2020modelling,\ntitle={{\\{}MODELLING{\\}}   {\\{}BIOLOGICAL{\\}}   {\\{}ASSAYS{\\}}   {\\{}WITH{\\}} {\\{}ADAPTIVE{\\}} {\\{}DEEP{\\}} {\\{}KERNEL{\\}} {\\{}LEARNING{\\}}},\nauthor={Prudencio Tossou and Basile Dura and Daniel Cohen and Mario Marchand and Fran{\\c{c}}ois Laviolette and Alexandre Lacoste},\nyear={2020},\nurl={https://openreview.net/forum?id=Syeu8CNYvS}\n}"}, "tags": [], "invitation": {"reply": {"writers": {"description": "How your identity will be displayed.", "values-regex": ["ICLR.cc/2020/Conference/Program_Chairs"]}, "signatures": {"values": ["ICLR.cc/2020/Conference/Program_Chairs"], "description": "How your identity will be displayed."}, "content": {"decision": {"value-radio": ["Accept (Spotlight)", "Accept (Talk)", "Accept (Poster)", "Reject"], "description": "Decision", "required": true, "order": 2}, "title": {"value": "Paper Decision", "required": true, "order": 1}, "comment": {"value-regex": "[\\S\\s]{0,5000}", "description": "", "required": false, "order": 3}}, "forum": "Syeu8CNYvS", "replyto": "Syeu8CNYvS", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}}, "expdate": 1576854540000, "duedate": 1576853940000, "multiReply": false, "readers": ["everyone"], "invitees": ["ICLR.cc/2020/Conference/Program_Chairs"], "tcdate": 1576795703851, "tmdate": 1576800251316, "super": "ICLR.cc/2020/Conference/-/Decision", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper1143/-/Decision"}}}, {"id": "BygUBEE3oH", "original": null, "number": 7, "cdate": 1573827645831, "ddate": null, "tcdate": 1573827645831, "tmdate": 1573849346306, "tddate": null, "forum": "Syeu8CNYvS", "replyto": "Syeu8CNYvS", "invitation": "ICLR.cc/2020/Conference/Paper1143/-/Official_Comment", "content": {"title": "To all reviewers", "comment": "We offer a sincere thank you to all reviewers for their insightful comments and suggestions to improve our paper. We have addressed the primary concerns of each reviewer by responding directly to your comments and have updated the manuscript accordingly. We have also taken special care to clarify any confusing sections in the paper to help with readability. With this global comment, we wish to summarize all major changes to facilitate your ongoing review process.\n\n1 - We have rewritten Section 3 of the paper after it was suggested that it was hard to follow. We hope that the changes will improve understanding of the methodological contribution of our work. \n\n2 - Second, we redid experiments related the molecular benchmarks to provide confidence intervals for the MSE. During these experiments, we changed the number of tasks in the meta-test from 500 to 1000 for each collection to have a better estimate of the meta-test performance of all methods. (Unfortunately, due to resource constraints, the results of ADKL-GP for the Binding collection will be missing for the moment. Thanks for understanding).  \n\n3 - We also included new models in the comparison process for these datasets. These methods are considered to be state-of-the-art in chemoinformatics and comparing against them is very insightful regarding how current meta-learning methods perform relative to existing methods for bioassay modelling.\n\n4 - We have added p-values of pairwise statistical tests that compared each algorithm to ADKL-GP and ADKL-KRR. More precisely, for any two algorithms, we did the Wilcoxon ranked test which compared the results of both algorithms for each task to determine if one is significantly better than the other. These p-values are provided in Tables 4-5.\n\n5 - Following the previous points, the analysis of the results has been slightly modified as well.\n"}, "signatures": ["ICLR.cc/2020/Conference/Paper1143/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1143/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "MODELLING   BIOLOGICAL   ASSAYS   WITH ADAPTIVE DEEP KERNEL LEARNING", "authors": ["Prudencio Tossou", "Basile Dura", "Daniel Cohen", "Mario Marchand", "Fran\u00e7ois Laviolette", "Alexandre Lacoste"], "authorids": ["tossouprudencio@gmail.com", "basile@invivoai.ca", "daniel@invivoai.ca", "mario.marchand@ift.ulaval.ca", "francois.laviolette@ift.ulaval.ca", "allac@elementai.com"], "keywords": ["few-shot learning", "few-shot regression", "deep kernel learning", "biological assay modelling", "drug discovery"], "TL;DR": "We investigate the modelling of biological assays using deep kernel learning in few-shot settings.", "abstract": "Due to the significant costs of data generation, many prediction tasks within drug discovery are by nature few-shot regression (FSR) problems, including accurate modelling of biological assays.  Although a number of few-shot classification and reinforcement learning methods exist for similar applications, we find relatively few FSR methods meeting the performance standards required for such tasks under real-world constraints. Inspired by deep kernel learning, we develop a novel FSR algorithm that is better suited to these settings. Our algorithm consists of learning a deep network in combination with a kernel function and a differentiable kernel algorithm. As the choice of the kernel is critical, our algorithm learns to find the appropriate one for each task during inference. It thus performs more effectively with complex task distributions, outperforming current state-of-the-art algorithms on both toy and novel, real-world benchmarks that we introduce herein. By introducing novel benchmarks derived from biological assays, we hope that the community will progress towards the development of FSR algorithms suitable for use in noisy and uncertain environments such as drug discovery.", "pdf": "/pdf/c0c794d29ce86c937dcb0760e85a8d2557597764.pdf", "paperhash": "tossou|modelling_biological_assays_with_adaptive_deep_kernel_learning", "original_pdf": "/attachment/169ccbd6d9cda53fa854a14e36a066f19d913657.pdf", "_bibtex": "@misc{\ntossou2020modelling,\ntitle={{\\{}MODELLING{\\}}   {\\{}BIOLOGICAL{\\}}   {\\{}ASSAYS{\\}}   {\\{}WITH{\\}} {\\{}ADAPTIVE{\\}} {\\{}DEEP{\\}} {\\{}KERNEL{\\}} {\\{}LEARNING{\\}}},\nauthor={Prudencio Tossou and Basile Dura and Daniel Cohen and Mario Marchand and Fran{\\c{c}}ois Laviolette and Alexandre Lacoste},\nyear={2020},\nurl={https://openreview.net/forum?id=Syeu8CNYvS}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "Syeu8CNYvS", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper1143/Authors", "ICLR.cc/2020/Conference/Paper1143/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper1143/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper1143/Reviewers", "ICLR.cc/2020/Conference/Paper1143/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper1143/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper1143/Authors|ICLR.cc/2020/Conference/Paper1143/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504160576, "tmdate": 1576860546055, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper1143/Authors", "ICLR.cc/2020/Conference/Paper1143/Reviewers", "ICLR.cc/2020/Conference/Paper1143/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper1143/-/Official_Comment"}}}, {"id": "H1luXI4nsS", "original": null, "number": 14, "cdate": 1573828128037, "ddate": null, "tcdate": 1573828128037, "tmdate": 1573828128037, "tddate": null, "forum": "Syeu8CNYvS", "replyto": "rJxWx_3O5S", "invitation": "ICLR.cc/2020/Conference/Paper1143/-/Official_Comment", "content": {"title": "response to #7", "comment": "Thank you for your thorough review. All comments and questions were very much appreciated and we hope this response addresses them in a way that is satisfactory.\n\nQ1 - The benchmarks in section 6.1 would benefit from confidence intervals. In my experience, few-shot algorithms can be quite noisy, so statistical tests are important to distinguish architectural improvements from noise. Repeated trials could be taken over the choice of random seed for the experiments to gauge robustness. Without error bars, and on a new dataset, it's not possible to gauge if ADKL really provides an improvement. \nR1 - You are absolutely right - without repeated trials the result bears little significance. We have repeated these experiments 3 times each (and apologize for not being able to do more due to time and computational resource constraints) and have updated the manuscript with the new results.\n\nQ2 - The experiments having to do with active learning in section 6.2 are interesting. Why is only CNP measured though? Do other methods not make sense with active learning? \nR2 - Only CNP and BMAML make sense for the active learning setting. However, we did not include  BMAML  because it only gives good results for large number of particles  and requires some monte carlo sampling to compute the variance. So we only used CNP due to computational resource limitations.\n\nQ3 - However, the work could still use a good bit of polish to really shine.\nR3 - You are absolutely right that some polishing was required to improve the paper. As mentioned in the comment addressed to all reviewers, we have performed new experiments and made changes to the text to improve both the technical content and the overall presentation of the paper.\n\nQ4 - It's not clear to me that the suggested ADKL framework really makes an improvement over past few shot regression methods. Adding some statistical significance tests would be useful. \nR4 - We have updated the experiment set performed on real-world dataset to make the meta-test include 1000 tasks, and added some statistical significance tests between all the models and ADKL-KRR. With these results we can see that ADKL-KRR is statistically superior to existing meta-learning methods and is competitive with the state of the art in chemoinformatic\n\nQ5 - It would also help if the authors benchmarked against datasets that were better known in this field, such as those from the moleculenet.ai suite. It's not easy to judge how easy/hard the new datasets the authors propose are, which makes it challenging to gauge the real improvement. \nR5 - Using Moleculenet.ai is certainly a great idea, but only 50 regression tasks are present in the suite and all of them contain large amounts of data (making them less representative of many real-life tasks encountered in bioassay modelling). Due to time constraints, we did not perform these experiments, but it is worth noting that since no previous work has used this suite in a few-shot learning setting, it would still be difficult to gauge the improvement of methods and the difficulty of the tasks. That said, we complemented Tables 2 and 3 with standard deviation of the MSE over multiple runs. We also added statistical tests showing how other  compared to ADKL. We also include in the benchmark the state of the art methods used in chemoinformatics to help gauge the difficulty of the task collection for meta-learning methods.\n\nQ6 - I'm also not sure that this paper is a clear fit for ICLR. I think there's a real contribution to the field of deep drug discovery by the adaptation of the DKL framework to few shot drug discovery, \nDue to the interdisciplinary nature of this work, it is hard to completely disagree with you. However, given that we are proposing a new few-shot learning algorithm, it may also be difficult for the drug discovery and chemoinformatics community to fully appreciate the technical contribution herein. We believe that the ICRL/machine learning community is better suited to appreciate the technical content of this paper, and we are planning to supplement the manuscript with additional materials such as blog posts to help better communicate these technical contribution to the drug discovery community.\n\nQ7 - but I'm not convinced that ADKL is superior to other DKL methods as a pure learning technique. \nR7 - In the updated manuscript, we have provided confidence intervals over the results and statistical test results to help assess whether ADKL is superior to other methods (including other DKL methods). Together, we hope that this information will help illustrate that ADKL is significantly different from compared to other meta-learning baseline including FS-DKL.\n\n"}, "signatures": ["ICLR.cc/2020/Conference/Paper1143/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1143/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "MODELLING   BIOLOGICAL   ASSAYS   WITH ADAPTIVE DEEP KERNEL LEARNING", "authors": ["Prudencio Tossou", "Basile Dura", "Daniel Cohen", "Mario Marchand", "Fran\u00e7ois Laviolette", "Alexandre Lacoste"], "authorids": ["tossouprudencio@gmail.com", "basile@invivoai.ca", "daniel@invivoai.ca", "mario.marchand@ift.ulaval.ca", "francois.laviolette@ift.ulaval.ca", "allac@elementai.com"], "keywords": ["few-shot learning", "few-shot regression", "deep kernel learning", "biological assay modelling", "drug discovery"], "TL;DR": "We investigate the modelling of biological assays using deep kernel learning in few-shot settings.", "abstract": "Due to the significant costs of data generation, many prediction tasks within drug discovery are by nature few-shot regression (FSR) problems, including accurate modelling of biological assays.  Although a number of few-shot classification and reinforcement learning methods exist for similar applications, we find relatively few FSR methods meeting the performance standards required for such tasks under real-world constraints. Inspired by deep kernel learning, we develop a novel FSR algorithm that is better suited to these settings. Our algorithm consists of learning a deep network in combination with a kernel function and a differentiable kernel algorithm. As the choice of the kernel is critical, our algorithm learns to find the appropriate one for each task during inference. It thus performs more effectively with complex task distributions, outperforming current state-of-the-art algorithms on both toy and novel, real-world benchmarks that we introduce herein. By introducing novel benchmarks derived from biological assays, we hope that the community will progress towards the development of FSR algorithms suitable for use in noisy and uncertain environments such as drug discovery.", "pdf": "/pdf/c0c794d29ce86c937dcb0760e85a8d2557597764.pdf", "paperhash": "tossou|modelling_biological_assays_with_adaptive_deep_kernel_learning", "original_pdf": "/attachment/169ccbd6d9cda53fa854a14e36a066f19d913657.pdf", "_bibtex": "@misc{\ntossou2020modelling,\ntitle={{\\{}MODELLING{\\}}   {\\{}BIOLOGICAL{\\}}   {\\{}ASSAYS{\\}}   {\\{}WITH{\\}} {\\{}ADAPTIVE{\\}} {\\{}DEEP{\\}} {\\{}KERNEL{\\}} {\\{}LEARNING{\\}}},\nauthor={Prudencio Tossou and Basile Dura and Daniel Cohen and Mario Marchand and Fran{\\c{c}}ois Laviolette and Alexandre Lacoste},\nyear={2020},\nurl={https://openreview.net/forum?id=Syeu8CNYvS}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "Syeu8CNYvS", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper1143/Authors", "ICLR.cc/2020/Conference/Paper1143/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper1143/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper1143/Reviewers", "ICLR.cc/2020/Conference/Paper1143/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper1143/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper1143/Authors|ICLR.cc/2020/Conference/Paper1143/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504160576, "tmdate": 1576860546055, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper1143/Authors", "ICLR.cc/2020/Conference/Paper1143/Reviewers", "ICLR.cc/2020/Conference/Paper1143/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper1143/-/Official_Comment"}}}, {"id": "S1e-gL4noB", "original": null, "number": 13, "cdate": 1573828072634, "ddate": null, "tcdate": 1573828072634, "tmdate": 1573828072634, "tddate": null, "forum": "Syeu8CNYvS", "replyto": "BJgdYgX9qr", "invitation": "ICLR.cc/2020/Conference/Paper1143/-/Official_Comment", "content": {"title": "response to #5 --part 2", "comment": "\nQ6 - How each meta-train episode is formed? Did they stochasticall sample a subset of molecules for each episode?\nR6 - As mentioned in the updated version of our manuscript, the episodes are formed as follows :\nBefore training, tasks are divided between meta-train and meta-test. Once that separation is done it will not change. Note that the tasks are divided the same way across the experiments (depending only on the seed) to ensure comparable results.\nAt train time, each training batch consists of a fixed number of randomly sampled tasks from the meta-training set. For each task, we build the episode by defining the support and the query sets, whose examples are randomly sampled (without replacement) from the original task dataset.\n\nThis sampling scheme means that any one task cannot be seen both in the meta-train and the meta-test sets. However, the same training example can be used in the support and the query set, although not during the same batch.\n\nQ7 - What is the total number of tasks in the meta-train and meta-test split respectively? Are there any overlapping between the two splits?\nR7 - We used 1000 tasks for testing for the molecular benchmarks and 1250 for the Sinusoids datasets. The remaining tasks for each collection are used for meta-training and validation. There is no overlap between meta-train, meta-valid, and meta-test.\n\nQ8 - Section 4 (line 201) \"DKL methods lie between neural networks and kernel methods\". To me, at high-level, DKL adds kernel learning as a differentiable layer in the end of a neural network. See how a similar model is categorized in Bertinetto et al. ICLR 2019 paper \"Meta-learning with differentiable closed-form solvers\":  \"The main idea is to teach a deep network to use standard machine learning tools, such as ridge regression,as part of its own internal model, enabling it to quickly adapt to novel data.\" The delta of the paper is adding 1) Gaussian Process and 2) task-specific adaptation. If Bertinetto et al. categorize their method as part of a deep network then I think so should this work.\nR8 - We did not mean that DKL methods were outside of the scope of deep neural networks but rather that they incorporated ideas from both neural networks as well as kernel methods. The method itself is indeed part of the neural network family.\n\nQ9 - Section 5 (line 272) \"Fig 2 highlights three aspects of the collections that make them better benchmarks for evaluating the readiness of FSR methods for real-world applications relative to toy collections.\" What is the other benchmarks the authors are comparing with? Are they generic benchmarks for all types few-shot regression tasks/applications beyond biological assays (e.g. computer vision tasks like: object detection). Maybe defining the proposed benchmark as \"complimentary\" and \"bio-assay application focused\" would be more appropriate. \nR9 - Our intent with this statement was simply to emphasize that most existing benchmarks (1D or 2D function regression tasks or image-related tasks) do not have the characteristics intrinsic to bioassay modelling tasks that we believe are shared by other real-world applications of few-shot regression (e.g. hyperparameter optimization, biomedical survival analysis, etc). However, you are correct in pointing out that the benchmarks we propose herein are complementary and bio-assay application focused (rather than better than existing benchmarks) and have modified the main text to reflect this.\n\nThank you for the additional feedback on the presentation. We have updated the manuscript to improve its clarity on all aspects referenced in your comments and hope that any confusion has been removed.\n"}, "signatures": ["ICLR.cc/2020/Conference/Paper1143/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1143/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "MODELLING   BIOLOGICAL   ASSAYS   WITH ADAPTIVE DEEP KERNEL LEARNING", "authors": ["Prudencio Tossou", "Basile Dura", "Daniel Cohen", "Mario Marchand", "Fran\u00e7ois Laviolette", "Alexandre Lacoste"], "authorids": ["tossouprudencio@gmail.com", "basile@invivoai.ca", "daniel@invivoai.ca", "mario.marchand@ift.ulaval.ca", "francois.laviolette@ift.ulaval.ca", "allac@elementai.com"], "keywords": ["few-shot learning", "few-shot regression", "deep kernel learning", "biological assay modelling", "drug discovery"], "TL;DR": "We investigate the modelling of biological assays using deep kernel learning in few-shot settings.", "abstract": "Due to the significant costs of data generation, many prediction tasks within drug discovery are by nature few-shot regression (FSR) problems, including accurate modelling of biological assays.  Although a number of few-shot classification and reinforcement learning methods exist for similar applications, we find relatively few FSR methods meeting the performance standards required for such tasks under real-world constraints. Inspired by deep kernel learning, we develop a novel FSR algorithm that is better suited to these settings. Our algorithm consists of learning a deep network in combination with a kernel function and a differentiable kernel algorithm. As the choice of the kernel is critical, our algorithm learns to find the appropriate one for each task during inference. It thus performs more effectively with complex task distributions, outperforming current state-of-the-art algorithms on both toy and novel, real-world benchmarks that we introduce herein. By introducing novel benchmarks derived from biological assays, we hope that the community will progress towards the development of FSR algorithms suitable for use in noisy and uncertain environments such as drug discovery.", "pdf": "/pdf/c0c794d29ce86c937dcb0760e85a8d2557597764.pdf", "paperhash": "tossou|modelling_biological_assays_with_adaptive_deep_kernel_learning", "original_pdf": "/attachment/169ccbd6d9cda53fa854a14e36a066f19d913657.pdf", "_bibtex": "@misc{\ntossou2020modelling,\ntitle={{\\{}MODELLING{\\}}   {\\{}BIOLOGICAL{\\}}   {\\{}ASSAYS{\\}}   {\\{}WITH{\\}} {\\{}ADAPTIVE{\\}} {\\{}DEEP{\\}} {\\{}KERNEL{\\}} {\\{}LEARNING{\\}}},\nauthor={Prudencio Tossou and Basile Dura and Daniel Cohen and Mario Marchand and Fran{\\c{c}}ois Laviolette and Alexandre Lacoste},\nyear={2020},\nurl={https://openreview.net/forum?id=Syeu8CNYvS}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "Syeu8CNYvS", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper1143/Authors", "ICLR.cc/2020/Conference/Paper1143/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper1143/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper1143/Reviewers", "ICLR.cc/2020/Conference/Paper1143/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper1143/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper1143/Authors|ICLR.cc/2020/Conference/Paper1143/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504160576, "tmdate": 1576860546055, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper1143/Authors", "ICLR.cc/2020/Conference/Paper1143/Reviewers", "ICLR.cc/2020/Conference/Paper1143/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper1143/-/Official_Comment"}}}, {"id": "rJemABVhjS", "original": null, "number": 12, "cdate": 1573828043455, "ddate": null, "tcdate": 1573828043455, "tmdate": 1573828043455, "tddate": null, "forum": "Syeu8CNYvS", "replyto": "BJgdYgX9qr", "invitation": "ICLR.cc/2020/Conference/Paper1143/-/Official_Comment", "content": {"title": "response to #5 -- part 1", "comment": "We sincerely thank you for your thorough review. It really helped us improve many aspects of the paper. We hope to answer all your comments in the remainder of this response.\n\nQ1 - Section 3.1 and 3.2 about \"Task Specific Kernel\" are very hard to follow.\nR1 - We have re-written these sections and hope that any misleading and confusing parts are now clarified.\n\nQ2 - (line 170) equation 12, What is the size of the MLP that is used as the kernel network \nR2 - We used a two layers MLP of 256 * 1 with ReLU activation in our experiments for the molecular datasets. And, 40* 1 with ReLU activation in our experiments for the Sinusoids. However these are part of the network architecture and as such must be selected by the experimenter. We have clarify these details in the experimental updated paper.\n\nQ3  -- Is there an ablation to show the contribution of using learnable kernel network vs hand-picked kernel for ADKL-GP and ADKL-KRR? \nR3 - Unfortunately there is no such experiments in the current version of the paper. However, during our experiment journey that , we tried to hand picked the kernel for ADKL-GP and ADKL-KRR and we did not have any success doing so.\n\nQ4  -- (line 181) \"where U is a set of unlabeled inputs\" Where does the unlabeled inputs come from?\nR4 - No, U is not a set of unlabeled inputs rather a set of pseudo-representations that we learned during the outer-loop of meta-learning. We are responsible for this confusing in our attempt to explain why U is important and where is comes from the version of the paper that you reviewed. But, now we have updated  the manuscript to make this clearer.\n\nQ5  -- Is there an ablation about |U|  <= 50 and its effect?\nR5 - Yes, we tried |U| = 0, 20 and 50 in our experiments and show the relative performance between of |U| = 20 and 50 compared to  |U| = 0 in Figure 4 - b and d. However, we did not extend beyond 50 as this increases the computation time and we could not afford this cost for our experiments due to resource constraints.\n\nQ5- The ProtoMAML code provided by the authors has only a few lines of code. And in the comment, it says: \"It turns out that ProtoMAML is the same as the light version of BMAML with one particle.\" Such implementation detail should be mentioned in the main paper.\nR5 - Thank you for bringing our attention to some of the more confusing details of our implementation. ProtoMAML was originally developed for classification. We modified it slightly for regression purposes by modifying the prototypical layer with a linear layer whose initialisation is learned during the outer training loop and adapted using gradient descent within the inner loop. As such, the name ProtoMAML might be somewhat improper (but we employed it in a natural way to generalise the algorithm to regression).\n\nThe correspondence between that particular variant of ProtoMAML and BMAML comes from the following fact: the memory-efficient version of BMAML is as a two-part network with a feature extractor, which is shared between tasks and updated in the outer loop of the meta-learning procedure and a final layer, which is updated during the fast-adaptation (inner loop) using an initialisation learned during the outer loop. When using multiple particles, there are multiple versions of the final layer that are learned and used to perform predictions but, when only one particle is used, this corresponds to the aforementioned ProtoMAML.\n\nHowever, having said this, we have removed this algorithm from the updated manuscript to avoid confusing the reader and also to avoid offending the authors of ProtoMAML with our overly simplistic generalization of their method to regression.\n\n"}, "signatures": ["ICLR.cc/2020/Conference/Paper1143/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1143/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "MODELLING   BIOLOGICAL   ASSAYS   WITH ADAPTIVE DEEP KERNEL LEARNING", "authors": ["Prudencio Tossou", "Basile Dura", "Daniel Cohen", "Mario Marchand", "Fran\u00e7ois Laviolette", "Alexandre Lacoste"], "authorids": ["tossouprudencio@gmail.com", "basile@invivoai.ca", "daniel@invivoai.ca", "mario.marchand@ift.ulaval.ca", "francois.laviolette@ift.ulaval.ca", "allac@elementai.com"], "keywords": ["few-shot learning", "few-shot regression", "deep kernel learning", "biological assay modelling", "drug discovery"], "TL;DR": "We investigate the modelling of biological assays using deep kernel learning in few-shot settings.", "abstract": "Due to the significant costs of data generation, many prediction tasks within drug discovery are by nature few-shot regression (FSR) problems, including accurate modelling of biological assays.  Although a number of few-shot classification and reinforcement learning methods exist for similar applications, we find relatively few FSR methods meeting the performance standards required for such tasks under real-world constraints. Inspired by deep kernel learning, we develop a novel FSR algorithm that is better suited to these settings. Our algorithm consists of learning a deep network in combination with a kernel function and a differentiable kernel algorithm. As the choice of the kernel is critical, our algorithm learns to find the appropriate one for each task during inference. It thus performs more effectively with complex task distributions, outperforming current state-of-the-art algorithms on both toy and novel, real-world benchmarks that we introduce herein. By introducing novel benchmarks derived from biological assays, we hope that the community will progress towards the development of FSR algorithms suitable for use in noisy and uncertain environments such as drug discovery.", "pdf": "/pdf/c0c794d29ce86c937dcb0760e85a8d2557597764.pdf", "paperhash": "tossou|modelling_biological_assays_with_adaptive_deep_kernel_learning", "original_pdf": "/attachment/169ccbd6d9cda53fa854a14e36a066f19d913657.pdf", "_bibtex": "@misc{\ntossou2020modelling,\ntitle={{\\{}MODELLING{\\}}   {\\{}BIOLOGICAL{\\}}   {\\{}ASSAYS{\\}}   {\\{}WITH{\\}} {\\{}ADAPTIVE{\\}} {\\{}DEEP{\\}} {\\{}KERNEL{\\}} {\\{}LEARNING{\\}}},\nauthor={Prudencio Tossou and Basile Dura and Daniel Cohen and Mario Marchand and Fran{\\c{c}}ois Laviolette and Alexandre Lacoste},\nyear={2020},\nurl={https://openreview.net/forum?id=Syeu8CNYvS}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "Syeu8CNYvS", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper1143/Authors", "ICLR.cc/2020/Conference/Paper1143/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper1143/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper1143/Reviewers", "ICLR.cc/2020/Conference/Paper1143/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper1143/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper1143/Authors|ICLR.cc/2020/Conference/Paper1143/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504160576, "tmdate": 1576860546055, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper1143/Authors", "ICLR.cc/2020/Conference/Paper1143/Reviewers", "ICLR.cc/2020/Conference/Paper1143/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper1143/-/Official_Comment"}}}, {"id": "r1eOtBE3jr", "original": null, "number": 11, "cdate": 1573827968228, "ddate": null, "tcdate": 1573827968228, "tmdate": 1573827968228, "tddate": null, "forum": "Syeu8CNYvS", "replyto": "Bkxkgp7qqr", "invitation": "ICLR.cc/2020/Conference/Paper1143/-/Official_Comment", "content": {"title": "response to #2 -- part 2", "comment": "\nQ4 - Given the tiny amount of data available, it seems surprising to me that the MSE is so low. From the brief description given, these problems appear significantly harder than the artificial Sinusoids task, yet the reported MSEs are orders of magnitude smaller.\nR4 - It can indeed be surprising that the MSE for molecular tasks is lower than the MSE for the Sinusoids tasks. However, as the MSE is scale dependant, it is expected to be so because the targets of the molecular tasks are pre-processed and rescaled to the [0-1] interval, but those for Sinusoids are from [0.1, 5] (range of amplitude). We did not preprocess the Sinusoids as this is the setup used by all previous papers.\n\nQ5 - How is molecule similarity measured in Figure 2c?\nR5 - The similarity measure used in Figure 2C is the Tanimoto similarity computed on the molecular fingerprint of the molecules (ECFP4, folded back to 4096 bits). (David Rogers and Mathew Hahn, 2010)\n\nQ6 - It would be useful for the authors to visualize performance for the Binding and Antibacterial tasks - for example, how different are the different protein targets? What are the molecular ligand structures in the train and test set in each case - could the authors provide some examples? \nR6 - As the intended audience for this paper is primarily the few-shot learning community, we feel that such a detailed analysis would make the paper harder to digest for most readers. However, as all the datasets and code to reproduce all our experiments will be publicly available, we invite any interested reader to carry out such experiments at their own accord.\n\nQ7 - Using random splits into train and test likely means that some test data points are very close to train data points - can the authors stratify their analysis to provide some insight into the performance beyond the average MSE? \nR7 - Indeed, randomly splitting each task into train and test could lead to some test data points being very close to other train data points. However, as shown by Figure 2 (left panel), most data points for any given bioassay are comparatively more similar than data points from different bioassays. This means that trying to stratify the internal train/test split for most tasks will not avoid the problem that you have pointed out. However, we understand that showing the performance beyond the average MSE will be insightful and have therefore provided the results of pairwise statistical analysis that compare ADKL to all other algorithms.\n\nOverall this paper makes a potentially interesting contribution, but it is not well situated within the drug discovery literature, and the results are not explained in enough detail to be understandable by experts in the drug discovery field.\nWe appreciate that the manuscript, in its current form, is not detailed enough to be understood by experts in drug discovery. However, as this paper was submitted to ICLR, we expect most readers to come from the few-shot learning and computational chemistry communities, and we have therefore intentionally limited drug discovery related details (and associated jargon) so the intended audience may more easily follow. Moreover, as we wish to bring the attention of the few-shot learning community to the applications available in drug discovery, as well as present a new few-shot modelling technique, we feel that this level of detail might discourage the community from taking further interest in these types of applications. \n"}, "signatures": ["ICLR.cc/2020/Conference/Paper1143/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1143/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "MODELLING   BIOLOGICAL   ASSAYS   WITH ADAPTIVE DEEP KERNEL LEARNING", "authors": ["Prudencio Tossou", "Basile Dura", "Daniel Cohen", "Mario Marchand", "Fran\u00e7ois Laviolette", "Alexandre Lacoste"], "authorids": ["tossouprudencio@gmail.com", "basile@invivoai.ca", "daniel@invivoai.ca", "mario.marchand@ift.ulaval.ca", "francois.laviolette@ift.ulaval.ca", "allac@elementai.com"], "keywords": ["few-shot learning", "few-shot regression", "deep kernel learning", "biological assay modelling", "drug discovery"], "TL;DR": "We investigate the modelling of biological assays using deep kernel learning in few-shot settings.", "abstract": "Due to the significant costs of data generation, many prediction tasks within drug discovery are by nature few-shot regression (FSR) problems, including accurate modelling of biological assays.  Although a number of few-shot classification and reinforcement learning methods exist for similar applications, we find relatively few FSR methods meeting the performance standards required for such tasks under real-world constraints. Inspired by deep kernel learning, we develop a novel FSR algorithm that is better suited to these settings. Our algorithm consists of learning a deep network in combination with a kernel function and a differentiable kernel algorithm. As the choice of the kernel is critical, our algorithm learns to find the appropriate one for each task during inference. It thus performs more effectively with complex task distributions, outperforming current state-of-the-art algorithms on both toy and novel, real-world benchmarks that we introduce herein. By introducing novel benchmarks derived from biological assays, we hope that the community will progress towards the development of FSR algorithms suitable for use in noisy and uncertain environments such as drug discovery.", "pdf": "/pdf/c0c794d29ce86c937dcb0760e85a8d2557597764.pdf", "paperhash": "tossou|modelling_biological_assays_with_adaptive_deep_kernel_learning", "original_pdf": "/attachment/169ccbd6d9cda53fa854a14e36a066f19d913657.pdf", "_bibtex": "@misc{\ntossou2020modelling,\ntitle={{\\{}MODELLING{\\}}   {\\{}BIOLOGICAL{\\}}   {\\{}ASSAYS{\\}}   {\\{}WITH{\\}} {\\{}ADAPTIVE{\\}} {\\{}DEEP{\\}} {\\{}KERNEL{\\}} {\\{}LEARNING{\\}}},\nauthor={Prudencio Tossou and Basile Dura and Daniel Cohen and Mario Marchand and Fran{\\c{c}}ois Laviolette and Alexandre Lacoste},\nyear={2020},\nurl={https://openreview.net/forum?id=Syeu8CNYvS}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "Syeu8CNYvS", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper1143/Authors", "ICLR.cc/2020/Conference/Paper1143/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper1143/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper1143/Reviewers", "ICLR.cc/2020/Conference/Paper1143/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper1143/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper1143/Authors|ICLR.cc/2020/Conference/Paper1143/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504160576, "tmdate": 1576860546055, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper1143/Authors", "ICLR.cc/2020/Conference/Paper1143/Reviewers", "ICLR.cc/2020/Conference/Paper1143/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper1143/-/Official_Comment"}}}, {"id": "SyefwSV3sr", "original": null, "number": 10, "cdate": 1573827929602, "ddate": null, "tcdate": 1573827929602, "tmdate": 1573827929602, "tddate": null, "forum": "Syeu8CNYvS", "replyto": "Bkxkgp7qqr", "invitation": "ICLR.cc/2020/Conference/Paper1143/-/Official_Comment", "content": {"title": "response to #2 --part 1", "comment": "First, we would like to say that we appreciate your thorough review, and all comments and questions regarding our manuscript. In the rest of this response, we try to address all questions and comments.\n\nQ1 - However, the paper as currently written is difficult to follow, and in particular it is hard to distinguish between places where existing methods are combined from novel contributions made by this paper. It would be helpful if the authors could explicitly delineate the novel contributions that they make. \nR1 - There were indeed certain sections that required polishing and we have now updated our manuscript to make the methodological contribution easier to follow and understand. We sincerely hope that the confusion has been alleviated, but we would nonetheless like to briefly clarify our technical contribution and its novelty. We begin the paper by observing that deep kernel learning is a simple yet effective method to learn from few samples. However, given that using the same hand-selected kernel for all tasks has certain limitations, we proposed ADKL to obtain the suitable kernel during inference. To do so, we learn task representations by maximizing an estimate of the mutual information between the support and query sets of a task (doing so is completely novel and ablation studies show that is critical to the model performances). We then use these representations to infer the adequate kernels for each task. This process involves learning a neural network and leveraging some pseudo-inputs that lie in the feature space on which this network operates (this also all novel). Finally, the proposed algorithm was applied to bioassay modelling, representing (to the best of our knowledge) the first application of few-shot learning methods to this domain, with results indicating that our approach is better than existing methods for such tasks.\n\nQ2 - Moreover, there is a large body of work in the drug discovery literature that uses sparse experimental data on the interactions of multiple target proteins and multiple ligands to build models that predict the outcome of biological assays for held out protein targets, where this problem is known as drug-target interaction prediction, but these papers are not referenced in this work (e.g. reviewed in Chen et al. Molecules 23(9):1-15, 2018, Ezzat et al. 2017, 2018, 2019). \nR2 - Our experimentations with BindingDB can indeed be viewed as an instance of a drug-target interaction (DTI) prediction problem. However, there are some noticeable differences between our application of meta-learning to BindingDB and the existing literature in DTI. First, in a classical DTI problem, the target protein is known and is used as part of the model construction. ADKL does not use this information and relies solely on the training set of molecules to build a model. Second, this work extends beyond the scope of DTI predictions given that the use of meta-learning allows us to deal with additional types of tasks. For example, our experiments with antibacterial assays involve only phenotypic assays (i.e. no specific protein target is known). Finally, this work focuses on learning when data is particularly scarce and, as such, we have developed a model can be applied across any bioassay modelling task for which data is limited. This is in contrast to many DTI methods, which tend to be used only to build screening tools to discover new potential ligands for a given protein or new targets for existing molecules.\n\nQ3 - In addition, it is hard to understand the results of the experiments that the authors carry out in this paper using data from BindingDB and PubChem. I don't understand the scaling that is applied to the MSE metric for the binding or antibacterial datasets. Why are the reported MSEs so low for all the methods? What does this metric mean? If the targets are first log2-scaled, then scaled linearly, then how different are they after this process?\nR3 - We first wish to clarify how the MSE is computed for all Tables 1-3: each task is partitioned into query and support sets, then the support set is used to generate a model which is evaluated on the query set to compute the MSE. This process is repeated 30 times per task and the average over the repetitions per task and over all tasks is the value shown in Tables 1-3.\nFor BindingDB and Antibacterial, the MSE metric is computed using the normalised version of the targets (first log2-scaled and then mapped to the [0-1] interval). This normalisation is done because the original target scale for each task goes from 10^-3 to 10^6. It is required to avoid the meta-training being biased towards a specific group of tasks which will have a larger MSE because of the scale of their targets. The values are low and expected to be so due to the scaling but, as we understand that this may lead to some confusion, we now report the RMSE for Antibacterial and BindingDB as well as for the toy dataset.\n\n"}, "signatures": ["ICLR.cc/2020/Conference/Paper1143/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1143/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "MODELLING   BIOLOGICAL   ASSAYS   WITH ADAPTIVE DEEP KERNEL LEARNING", "authors": ["Prudencio Tossou", "Basile Dura", "Daniel Cohen", "Mario Marchand", "Fran\u00e7ois Laviolette", "Alexandre Lacoste"], "authorids": ["tossouprudencio@gmail.com", "basile@invivoai.ca", "daniel@invivoai.ca", "mario.marchand@ift.ulaval.ca", "francois.laviolette@ift.ulaval.ca", "allac@elementai.com"], "keywords": ["few-shot learning", "few-shot regression", "deep kernel learning", "biological assay modelling", "drug discovery"], "TL;DR": "We investigate the modelling of biological assays using deep kernel learning in few-shot settings.", "abstract": "Due to the significant costs of data generation, many prediction tasks within drug discovery are by nature few-shot regression (FSR) problems, including accurate modelling of biological assays.  Although a number of few-shot classification and reinforcement learning methods exist for similar applications, we find relatively few FSR methods meeting the performance standards required for such tasks under real-world constraints. Inspired by deep kernel learning, we develop a novel FSR algorithm that is better suited to these settings. Our algorithm consists of learning a deep network in combination with a kernel function and a differentiable kernel algorithm. As the choice of the kernel is critical, our algorithm learns to find the appropriate one for each task during inference. It thus performs more effectively with complex task distributions, outperforming current state-of-the-art algorithms on both toy and novel, real-world benchmarks that we introduce herein. By introducing novel benchmarks derived from biological assays, we hope that the community will progress towards the development of FSR algorithms suitable for use in noisy and uncertain environments such as drug discovery.", "pdf": "/pdf/c0c794d29ce86c937dcb0760e85a8d2557597764.pdf", "paperhash": "tossou|modelling_biological_assays_with_adaptive_deep_kernel_learning", "original_pdf": "/attachment/169ccbd6d9cda53fa854a14e36a066f19d913657.pdf", "_bibtex": "@misc{\ntossou2020modelling,\ntitle={{\\{}MODELLING{\\}}   {\\{}BIOLOGICAL{\\}}   {\\{}ASSAYS{\\}}   {\\{}WITH{\\}} {\\{}ADAPTIVE{\\}} {\\{}DEEP{\\}} {\\{}KERNEL{\\}} {\\{}LEARNING{\\}}},\nauthor={Prudencio Tossou and Basile Dura and Daniel Cohen and Mario Marchand and Fran{\\c{c}}ois Laviolette and Alexandre Lacoste},\nyear={2020},\nurl={https://openreview.net/forum?id=Syeu8CNYvS}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "Syeu8CNYvS", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper1143/Authors", "ICLR.cc/2020/Conference/Paper1143/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper1143/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper1143/Reviewers", "ICLR.cc/2020/Conference/Paper1143/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper1143/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper1143/Authors|ICLR.cc/2020/Conference/Paper1143/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504160576, "tmdate": 1576860546055, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper1143/Authors", "ICLR.cc/2020/Conference/Paper1143/Reviewers", "ICLR.cc/2020/Conference/Paper1143/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper1143/-/Official_Comment"}}}, {"id": "HylKJH42sH", "original": null, "number": 9, "cdate": 1573827808988, "ddate": null, "tcdate": 1573827808988, "tmdate": 1573827808988, "tddate": null, "forum": "Syeu8CNYvS", "replyto": "BJltL5L55H", "invitation": "ICLR.cc/2020/Conference/Paper1143/-/Official_Comment", "content": {"title": "Response to #6", "comment": "First, we would like to thank you for your thorough review, your kind words regarding our manuscript, and the additional related work that you have pointed us towards. In the remainder of our response, we try to address all questions and comments.\n\nQ1  - The backpropagation through the kernel regressor (in order to train the parameters of the embedding function and other networks) seems unexpectedly straightforward. Is that only because there is a closed-form solution for the optimal regressor? \nWere the specific algorithms (KRR, GP) chosen because of that? Or could something like MetaOptNet (Meta-Learning with differentiable convex optimization, Lee et al., CVPR 2019) be used to relax that constraint?\nR1 - Yes, the straightforwardness of the backpropagation of the kernel regressors in ADKL is only due to the fact that we choose algorithms that admit closed form solutions (GP and KRR). The backpropagation is easily done in such cases using the chain-rule and the automatic differentiation algorithms that exist in popular frameworks such as Pytorch or Tensorflow. However, an algorithm that does not admit a closed form solution could be used as was the case in MetaOptNet and also in (Meta-learning with differentiable closed-form solvers, ICLR2019).  \n\nQ2  - What \"generalization guarantees of kernel-based models\" (l. 122) would be applicable here? Do they hold even when the kernel is applied on top of a learned embedding (), or even when it depends on a trained model itself ()?\nR2 - When the meta-training is over, using ADKL for get a  model is the same as using any other kernel function designed by hand or using a more sophisticated procedure and then perform  KRR. Thus, it is our view that Corollary 13.10 of [1]  is still applicable even if the kernel method is applied on top of a learned embedding function. It is worth recalling that this corollary bounds the true risk of a model obtained by minimizing Equation 1 (see paper) and can be applied to both KRR and GP. \n\n[1] Shalev-Shwartz, Shai, and Shai Ben-David. Understanding machine learning: From theory to algorithms. Cambridge university press, 2014.\n\nQ3  - What does \"correlations > 0.8\" mean exactly? (l. 258, 263)\nR3  - The correlation threshold was used to remove tasks that were too similar in order to avoid information leakage between training and testing. This is now clarified in the manuscript and we provide a summary of the process below.  For any tasks pair in a given collection that share a high proportion of molecules and has highly correlated targets, as measured by the Pearson correlation coefficient (PCC), we remove one of them. We used  a threshold of  0.8 to indicate a high correlation between tasks.\n\nQ4  - In the \"Binding\" dataset, is it possible that the same protein is used in different bio-assays? In that case, are the different experiments \"merged\" into the same task, or be considered different tasks? Could it be possible that tasks involving the same protein would be in different (meta-)splits, or has that been taken care of during the data collection?\nR4  - The same protein can indeed be present in different bio-assays. However, different assays featuring the same protein often involve different molecules, experimental setups or measures. Therefore, we did not perform any form of pre-processing to avoid having the same protein involved in the meta-training and the meta-testing set multiple times. Also, by filtering the highly correlated tasks as described above, we can ensure that if the same protein is involved in different tasks, they are sufficiently different so as not to bias the performance being measured in any way.\n\nQ5  - In the meta-test splits, how are examples split between the train/support and valid/query parts of each task?\nR5 - The meta-test set is randomly split by sampling K=5, 10, 20 examples for the train partition and using the remaining for the test partition. To obtain the performance of an algorithm for each task, we repeat this train/test split 30 times and report the average over all the splits. The results in Tables 1-3 are the average over all the tasks using this procedure.\n\nQ6  - How were the specific architectures of the different neural networks designed, or selected? Between , v, r, , the space of hyper-parameters seems huge, and the effects of these choices might be drastic.\nR6 - The choice of hyper-parameters is indeed a topic in itself. Herein, we first performed the ablation studies on the toy datasets to better understand the effects of each hyperparameter on the learning process and performance. The results obtained gave us some insight into the values of  hyper-parameters to try for the real world datasets.  The results were then obtained after a light hyper-parameter search (which was also carried out for other baseline algorithms to avoid biasing results in favour of our method).\n\nThank you for the additional feedback on the figures and notation. We have updated the manuscript  consequently"}, "signatures": ["ICLR.cc/2020/Conference/Paper1143/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1143/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "MODELLING   BIOLOGICAL   ASSAYS   WITH ADAPTIVE DEEP KERNEL LEARNING", "authors": ["Prudencio Tossou", "Basile Dura", "Daniel Cohen", "Mario Marchand", "Fran\u00e7ois Laviolette", "Alexandre Lacoste"], "authorids": ["tossouprudencio@gmail.com", "basile@invivoai.ca", "daniel@invivoai.ca", "mario.marchand@ift.ulaval.ca", "francois.laviolette@ift.ulaval.ca", "allac@elementai.com"], "keywords": ["few-shot learning", "few-shot regression", "deep kernel learning", "biological assay modelling", "drug discovery"], "TL;DR": "We investigate the modelling of biological assays using deep kernel learning in few-shot settings.", "abstract": "Due to the significant costs of data generation, many prediction tasks within drug discovery are by nature few-shot regression (FSR) problems, including accurate modelling of biological assays.  Although a number of few-shot classification and reinforcement learning methods exist for similar applications, we find relatively few FSR methods meeting the performance standards required for such tasks under real-world constraints. Inspired by deep kernel learning, we develop a novel FSR algorithm that is better suited to these settings. Our algorithm consists of learning a deep network in combination with a kernel function and a differentiable kernel algorithm. As the choice of the kernel is critical, our algorithm learns to find the appropriate one for each task during inference. It thus performs more effectively with complex task distributions, outperforming current state-of-the-art algorithms on both toy and novel, real-world benchmarks that we introduce herein. By introducing novel benchmarks derived from biological assays, we hope that the community will progress towards the development of FSR algorithms suitable for use in noisy and uncertain environments such as drug discovery.", "pdf": "/pdf/c0c794d29ce86c937dcb0760e85a8d2557597764.pdf", "paperhash": "tossou|modelling_biological_assays_with_adaptive_deep_kernel_learning", "original_pdf": "/attachment/169ccbd6d9cda53fa854a14e36a066f19d913657.pdf", "_bibtex": "@misc{\ntossou2020modelling,\ntitle={{\\{}MODELLING{\\}}   {\\{}BIOLOGICAL{\\}}   {\\{}ASSAYS{\\}}   {\\{}WITH{\\}} {\\{}ADAPTIVE{\\}} {\\{}DEEP{\\}} {\\{}KERNEL{\\}} {\\{}LEARNING{\\}}},\nauthor={Prudencio Tossou and Basile Dura and Daniel Cohen and Mario Marchand and Fran{\\c{c}}ois Laviolette and Alexandre Lacoste},\nyear={2020},\nurl={https://openreview.net/forum?id=Syeu8CNYvS}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "Syeu8CNYvS", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper1143/Authors", "ICLR.cc/2020/Conference/Paper1143/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper1143/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper1143/Reviewers", "ICLR.cc/2020/Conference/Paper1143/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper1143/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper1143/Authors|ICLR.cc/2020/Conference/Paper1143/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504160576, "tmdate": 1576860546055, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper1143/Authors", "ICLR.cc/2020/Conference/Paper1143/Reviewers", "ICLR.cc/2020/Conference/Paper1143/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper1143/-/Official_Comment"}}}, {"id": "SkeVO44noH", "original": null, "number": 8, "cdate": 1573827692502, "ddate": null, "tcdate": 1573827692502, "tmdate": 1573827692502, "tddate": null, "forum": "Syeu8CNYvS", "replyto": "B1l2o9Jp5B", "invitation": "ICLR.cc/2020/Conference/Paper1143/-/Official_Comment", "content": {"title": "respons to #4", "comment": "First, thank you for your thorough review and suggestions to improve the paper. In the remainder of our response, we try to address your main questions and comments.\n\nQ1: How well the proposed method performs against classical machine learning methods?\n\nR1: This is a great question as the ultimate goal is to improve not only upon meta-learning methods but also classical methods. To this end, we performed new experiments using two techniques considered to be state-of-the-art in chemoinformatics (1) the Random Forest algorithm with ECFP4 (Extended Connectivity FingerPrints of diameter 4) as molecular input representation [1], and (2) ECFP4 with kernel ridge regression and tanimoto similarity as a kernel function. Overall, new results in the updated Tables 2 and 3 show that ADKL performs better than classical methods on the Antibacterial collection and is competitive on the Binding collection. However, it is worth noting that other meta-learning technique fall significantly behind relative to these strong baselines. These results indicate that although ADKL is significatively superior to other meta-learning methods (as shown by the relative p-value to ADKL-KRR for pairwise comparison at the task level), there remains much room to develop improved meta-learning algorithms which are undoubtedly superior to classical methods in computational chemistry. Indeed, our hope in offering the proposed datasets is that the community can progress towards developing better meta-learning algorithms for regression problems.\n\nQ2: How was MSE in Tables 1-3 calculated? The experimental results in Tables 1-3 show only marginal improvement for real datasets. Also, it\u2019s not clear if the numbers in the Tables 1-3 are on the original scale or on the transformed scale.  \n\nR2: During meta-test, each task is partitioned into query and support sets, then the support set is used to generate a model which is evaluated on the query set to compute the MSE. This process is repeated 30 times per task and the average over the repetitions per task and over all tasks is the value shown in Tables 1-3.\nFor Table 1 (Sinusoids), the MSE is computed on the original target scale but for Table 2-3 (molecular datasets), we used the transformed scale (doing so it necessary to avoid  the averaging being dominated by tasks whose output domains are large: the original output domain goes from 10^-3 to 10^6).\n\nQ3: It would be useful to see the histogram of MSEs instead of just a single number.\nR3: Indeed, a single value does not give the whole picture when comparing meta-learning algorithms. However, for space limitation, we could not show the histograms in the main text (See appendix 6 please). In the updated version of the paper, we also provide a more detailed overview of the performance of each method (confidence intervals of the MSE after multiple runs, and p-values of pairwise statistical analyses at the task level for every method compared to ADKL-KRR), and we hope that is helpful in your analysis of the results.\n\n[1] Olier, Ivan, et al. \"Meta-QSAR: a large-scale application of meta-learning to drug design and discovery.\" Machine Learning 107.1 (2018): 285-311.\n"}, "signatures": ["ICLR.cc/2020/Conference/Paper1143/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1143/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "MODELLING   BIOLOGICAL   ASSAYS   WITH ADAPTIVE DEEP KERNEL LEARNING", "authors": ["Prudencio Tossou", "Basile Dura", "Daniel Cohen", "Mario Marchand", "Fran\u00e7ois Laviolette", "Alexandre Lacoste"], "authorids": ["tossouprudencio@gmail.com", "basile@invivoai.ca", "daniel@invivoai.ca", "mario.marchand@ift.ulaval.ca", "francois.laviolette@ift.ulaval.ca", "allac@elementai.com"], "keywords": ["few-shot learning", "few-shot regression", "deep kernel learning", "biological assay modelling", "drug discovery"], "TL;DR": "We investigate the modelling of biological assays using deep kernel learning in few-shot settings.", "abstract": "Due to the significant costs of data generation, many prediction tasks within drug discovery are by nature few-shot regression (FSR) problems, including accurate modelling of biological assays.  Although a number of few-shot classification and reinforcement learning methods exist for similar applications, we find relatively few FSR methods meeting the performance standards required for such tasks under real-world constraints. Inspired by deep kernel learning, we develop a novel FSR algorithm that is better suited to these settings. Our algorithm consists of learning a deep network in combination with a kernel function and a differentiable kernel algorithm. As the choice of the kernel is critical, our algorithm learns to find the appropriate one for each task during inference. It thus performs more effectively with complex task distributions, outperforming current state-of-the-art algorithms on both toy and novel, real-world benchmarks that we introduce herein. By introducing novel benchmarks derived from biological assays, we hope that the community will progress towards the development of FSR algorithms suitable for use in noisy and uncertain environments such as drug discovery.", "pdf": "/pdf/c0c794d29ce86c937dcb0760e85a8d2557597764.pdf", "paperhash": "tossou|modelling_biological_assays_with_adaptive_deep_kernel_learning", "original_pdf": "/attachment/169ccbd6d9cda53fa854a14e36a066f19d913657.pdf", "_bibtex": "@misc{\ntossou2020modelling,\ntitle={{\\{}MODELLING{\\}}   {\\{}BIOLOGICAL{\\}}   {\\{}ASSAYS{\\}}   {\\{}WITH{\\}} {\\{}ADAPTIVE{\\}} {\\{}DEEP{\\}} {\\{}KERNEL{\\}} {\\{}LEARNING{\\}}},\nauthor={Prudencio Tossou and Basile Dura and Daniel Cohen and Mario Marchand and Fran{\\c{c}}ois Laviolette and Alexandre Lacoste},\nyear={2020},\nurl={https://openreview.net/forum?id=Syeu8CNYvS}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "Syeu8CNYvS", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper1143/Authors", "ICLR.cc/2020/Conference/Paper1143/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper1143/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper1143/Reviewers", "ICLR.cc/2020/Conference/Paper1143/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper1143/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper1143/Authors|ICLR.cc/2020/Conference/Paper1143/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504160576, "tmdate": 1576860546055, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper1143/Authors", "ICLR.cc/2020/Conference/Paper1143/Reviewers", "ICLR.cc/2020/Conference/Paper1143/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper1143/-/Official_Comment"}}}, {"id": "rJxWx_3O5S", "original": null, "number": 2, "cdate": 1572550633236, "ddate": null, "tcdate": 1572550633236, "tmdate": 1572972507289, "tddate": null, "forum": "Syeu8CNYvS", "replyto": "Syeu8CNYvS", "invitation": "ICLR.cc/2020/Conference/Paper1143/-/Official_Review", "content": {"rating": "6: Weak Accept", "experience_assessment": "I have published in this field for several years.", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #7", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review": "The authors of this work are attempting to solve the problem of few shot regression for drug discovery problems. This is an important problem in the field of deep drug discovery, since low data issues are very common. While previous papers have addressed the challenges of low data drug classification, there hasn't been much progress made so far on low data regression thus far.\n\nThe authors propose formulating the problem at hand as a few shot deep kernel regression problem (FSDKL). This framework has some similarities to past work deep metric learning, which has been used previously for few shot classification problems in drug discovery. In particular, the authors propose a new method, adaptive deep kernel learning to help improve task specific learning. ADKL is claimed to improve over FSDKL since it helps learn a task specific kernel function. There are a number of interesting methodological adaptations here, such as the\u00a0use of an idea similar to DeepSets to encode order invariance in the training set (an important challenge when dealing with small \"support\" sets in training). The authors also incorporate some unlabeled data during training to improve on representation learning.\n\nTo test their contributions, the authors gather two new dataset collections, Binding and Antibacterial from publicly available sources. Some detail is provided about these collections, but a priori, it's not easy for me to judge the quality of these data sources since they haven't been benchmarked previously in the literature.\n\nIn the experimental section, the authors compare ADKL against a number of past low data learning methods. The benchmarks in section 6.1 would benefit from confidence intervals. In my experience, few-shot algorithms can be quite noisy, so statistical tests are important to distinguish architectural improvements from noise. Repeated trials could be taken over the choice of random seed for the experiments to gauge robustness. Without error bars, and on a new dataset, it's not possible to gauge if ADKL really provides an improvement.\u00a0\n\nThe experiments having to do with active learning in section 6.2 are interesting. Why is only CNP measured though? Do other methods not make sense with active learning?\u00a0\n\nIn conclusion, the authors consider an important problem for deep learning in drug discovery and offer a useful advance by adapting the framework of deep kernel learning to this space. However, the work could still use a good bit of polish to really shine. It's not clear to me that the suggested ADKL framework really makes an improvement over past few shot regression methods. Adding some statistical\u00a0significance tests would be useful. It would also help if the authors benchmarked against datasets that were better known in this field, such as those from the moleculenet.ai suite. It's not easy to judge how easy/hard the new datasets the authors propose are, which makes it challenging to gauge the real improvement. I'm also not sure that this paper is a clear fit for ICLR. I think there's a real contribution to the field of deep drug discovery by the adaptation of the DKL framework to few shot\u00a0drug discovery, but I'm not convinced that ADKL is superior to other DKL methods as a pure learning technique. \n\nAll that said, I'm comfortable marking the paper as a \"weak accept\" since I think there is a real scientific contribution here, but I encourage the authors to make a serious effort to improve their presentation and tighten-up their experiments.\n\nDetailed Suggestions:\n- Section 2 on Deep Kernel Learning and Section 4 on Related work should likely be merged together. Going back and forth between the literature and author contributions was a little confusing.\u00a0\n- There are a lot of acronyms in the paper; I found myself having to refer back and forth to all the methods considered. It might be worthwhile to make a cleanup pass to make the discussions a little easier to read.\u00a0\n- Figure 4 would benefit from a legend. At first glance, it wasn't clear what gamma_mine and gamma_pseudo mean here. The color plot is also a little difficult to make sense. Perhaps consider an alternative plot."}, "signatures": ["ICLR.cc/2020/Conference/Paper1143/AnonReviewer7"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1143/AnonReviewer7"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "MODELLING   BIOLOGICAL   ASSAYS   WITH ADAPTIVE DEEP KERNEL LEARNING", "authors": ["Prudencio Tossou", "Basile Dura", "Daniel Cohen", "Mario Marchand", "Fran\u00e7ois Laviolette", "Alexandre Lacoste"], "authorids": ["tossouprudencio@gmail.com", "basile@invivoai.ca", "daniel@invivoai.ca", "mario.marchand@ift.ulaval.ca", "francois.laviolette@ift.ulaval.ca", "allac@elementai.com"], "keywords": ["few-shot learning", "few-shot regression", "deep kernel learning", "biological assay modelling", "drug discovery"], "TL;DR": "We investigate the modelling of biological assays using deep kernel learning in few-shot settings.", "abstract": "Due to the significant costs of data generation, many prediction tasks within drug discovery are by nature few-shot regression (FSR) problems, including accurate modelling of biological assays.  Although a number of few-shot classification and reinforcement learning methods exist for similar applications, we find relatively few FSR methods meeting the performance standards required for such tasks under real-world constraints. Inspired by deep kernel learning, we develop a novel FSR algorithm that is better suited to these settings. Our algorithm consists of learning a deep network in combination with a kernel function and a differentiable kernel algorithm. As the choice of the kernel is critical, our algorithm learns to find the appropriate one for each task during inference. It thus performs more effectively with complex task distributions, outperforming current state-of-the-art algorithms on both toy and novel, real-world benchmarks that we introduce herein. By introducing novel benchmarks derived from biological assays, we hope that the community will progress towards the development of FSR algorithms suitable for use in noisy and uncertain environments such as drug discovery.", "pdf": "/pdf/c0c794d29ce86c937dcb0760e85a8d2557597764.pdf", "paperhash": "tossou|modelling_biological_assays_with_adaptive_deep_kernel_learning", "original_pdf": "/attachment/169ccbd6d9cda53fa854a14e36a066f19d913657.pdf", "_bibtex": "@misc{\ntossou2020modelling,\ntitle={{\\{}MODELLING{\\}}   {\\{}BIOLOGICAL{\\}}   {\\{}ASSAYS{\\}}   {\\{}WITH{\\}} {\\{}ADAPTIVE{\\}} {\\{}DEEP{\\}} {\\{}KERNEL{\\}} {\\{}LEARNING{\\}}},\nauthor={Prudencio Tossou and Basile Dura and Daniel Cohen and Mario Marchand and Fran{\\c{c}}ois Laviolette and Alexandre Lacoste},\nyear={2020},\nurl={https://openreview.net/forum?id=Syeu8CNYvS}\n}"}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "Syeu8CNYvS", "replyto": "Syeu8CNYvS", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper1143/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper1143/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1575499184529, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper1143/Reviewers"], "noninvitees": [], "tcdate": 1570237741731, "tmdate": 1575499184543, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper1143/-/Official_Review"}}}, {"id": "Bkxkgp7qqr", "original": null, "number": 4, "cdate": 1572646118617, "ddate": null, "tcdate": 1572646118617, "tmdate": 1572972507234, "tddate": null, "forum": "Syeu8CNYvS", "replyto": "Syeu8CNYvS", "invitation": "ICLR.cc/2020/Conference/Paper1143/-/Official_Review", "content": {"rating": "3: Weak Reject", "experience_assessment": "I have published one or two papers in this area.", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #2", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review": "This is an interesting paper that proposes the use of few shot regression to predict complicated experimental measurements such as protein-ligand binding affinity from very small, noisy real-world datasets. It is great that the authors make the effort to apply their approach to these important questions in drug-discovery. However, the paper as currently written is difficult to follow, and in particular it is hard to distinguish between places where existing methods are combined from novel contributions made by this paper. It would be helpful if the authors could explicitly delineate the novel contributions that they make. Moreover, there is a large body of work in the drug discovery literature that uses sparse experimental data on the interactions of multiple target proteins and multiple ligands to build models that predict the outcome of biological assays for held out protein targets, where this problem is known as drug-target interaction prediction, but these papers are not referenced in this work (e.g. reviewed in Chen et al. Molecules 23(9):1-15, 2018, Ezzat et al. 2017, 2018, 2019). \n\nIn addition, it is hard to understand the results of the experiments that the authors carry out in this paper using data from BindingDB and PubChem. I don't understand the scaling that is applied to the MSE metric for the binding or antibacterial datasets. Why are the reported MSEs so low for all the methods? What does this metric mean? If the targets are first log2-scaled, then scaled linearly, then how different are they after this process? Given the tiny amount of data available, it seems surprising to me that the MSE is so low. From the brief description given, these problems appear significantly harder than the artificial Sinusoids task, yet the reported MSEs are orders of magnitude smaller. How is molecule similarity measured in Figure 2c? It would be useful for the authors to visualize performance for the Binding and Antibacterial tasks - for example how different are the different protein targets? What are the molecular ligand structures in the train and test set in each case - could the authors provide some examples? Using random splits into train and test likely means that some test data points are very close to train data points - can the authors stratify their analysis to provide some insight into the performance beyond the average MSE? \n\nOverall this paper makes a potentially interesting contribution, but it is not well situated within the drug discovery literature, and the results are not explained in enough detail to be understandable by experts in the drug discovery field. \n"}, "signatures": ["ICLR.cc/2020/Conference/Paper1143/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1143/AnonReviewer2"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "MODELLING   BIOLOGICAL   ASSAYS   WITH ADAPTIVE DEEP KERNEL LEARNING", "authors": ["Prudencio Tossou", "Basile Dura", "Daniel Cohen", "Mario Marchand", "Fran\u00e7ois Laviolette", "Alexandre Lacoste"], "authorids": ["tossouprudencio@gmail.com", "basile@invivoai.ca", "daniel@invivoai.ca", "mario.marchand@ift.ulaval.ca", "francois.laviolette@ift.ulaval.ca", "allac@elementai.com"], "keywords": ["few-shot learning", "few-shot regression", "deep kernel learning", "biological assay modelling", "drug discovery"], "TL;DR": "We investigate the modelling of biological assays using deep kernel learning in few-shot settings.", "abstract": "Due to the significant costs of data generation, many prediction tasks within drug discovery are by nature few-shot regression (FSR) problems, including accurate modelling of biological assays.  Although a number of few-shot classification and reinforcement learning methods exist for similar applications, we find relatively few FSR methods meeting the performance standards required for such tasks under real-world constraints. Inspired by deep kernel learning, we develop a novel FSR algorithm that is better suited to these settings. Our algorithm consists of learning a deep network in combination with a kernel function and a differentiable kernel algorithm. As the choice of the kernel is critical, our algorithm learns to find the appropriate one for each task during inference. It thus performs more effectively with complex task distributions, outperforming current state-of-the-art algorithms on both toy and novel, real-world benchmarks that we introduce herein. By introducing novel benchmarks derived from biological assays, we hope that the community will progress towards the development of FSR algorithms suitable for use in noisy and uncertain environments such as drug discovery.", "pdf": "/pdf/c0c794d29ce86c937dcb0760e85a8d2557597764.pdf", "paperhash": "tossou|modelling_biological_assays_with_adaptive_deep_kernel_learning", "original_pdf": "/attachment/169ccbd6d9cda53fa854a14e36a066f19d913657.pdf", "_bibtex": "@misc{\ntossou2020modelling,\ntitle={{\\{}MODELLING{\\}}   {\\{}BIOLOGICAL{\\}}   {\\{}ASSAYS{\\}}   {\\{}WITH{\\}} {\\{}ADAPTIVE{\\}} {\\{}DEEP{\\}} {\\{}KERNEL{\\}} {\\{}LEARNING{\\}}},\nauthor={Prudencio Tossou and Basile Dura and Daniel Cohen and Mario Marchand and Fran{\\c{c}}ois Laviolette and Alexandre Lacoste},\nyear={2020},\nurl={https://openreview.net/forum?id=Syeu8CNYvS}\n}"}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "Syeu8CNYvS", "replyto": "Syeu8CNYvS", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper1143/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper1143/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1575499184529, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper1143/Reviewers"], "noninvitees": [], "tcdate": 1570237741731, "tmdate": 1575499184543, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper1143/-/Official_Review"}}}, {"id": "BJltL5L55H", "original": null, "number": 5, "cdate": 1572657745292, "ddate": null, "tcdate": 1572657745292, "tmdate": 1572972507188, "tddate": null, "forum": "Syeu8CNYvS", "replyto": "Syeu8CNYvS", "invitation": "ICLR.cc/2020/Conference/Paper1143/-/Official_Review", "content": {"rating": "8: Accept", "experience_assessment": "I have read many papers in this area.", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #6", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review": "The submission is at the intersection of few-shot learning, kernel regression methods, and computational biology.\nThe main contributions are:\n  - A few-shot learning algorithm combining several ideas and features:\n    - Combining metric learning (shared across tasks) and kernel regression within each task\n    - Learning a task representation by maximizing an estimate of the mutual information between the train (support) and valid (query) sets of a task\n    - The addition of learned, synthetic \"pseudo-examples\"\n  - Two datasets for few-shot regression, from real-life biological assays\nThe proposed algorithm outperforms (or is competitive with) mainstream few-shot learning methods on a synthetic 1D regression dataset, as well as the two proposed datasets.\n\nThis paper should be accepted, because it significantly expands the field of few-shot learning by proposing both a novel problem to tackle (few-shot regression from a high-dimensional, noisy input), with public datasets, and novel algorithm to solve it (combining several recent advances in different sub-fields of machine learning).\n\nOverview\nThe overall problem is clearly stated, as well as its main challenges: noisiness of the data, different behaviors of the same input across tasks.\nDespite the complexity of the proposed algorithm, its different pieces and their motivations are clearly motivated, introduced, and tested in ablation studies. I liked the clarity of section 2.\nThe \"related work\" section is clear and presents a good overall picture of the field. Additional papers that may be of interest:\n  - Learned hallucination (Low-shot learning from imaginary data, Wang et al., CVPR 2018) seems to relate to the \"pseudo-representations\"\n  - TADAM (Task dependent adaptive metric for improved few-shot learning, Oreshkin et al., NeurIPS 2018) is another example of task representation used in conjunction with metric learning (in the context of classification, not regression, though)\nThe proposed datasets are an interesting new benchmarking task, that naturally requires learning a task description, I hope it will get traction.\n\nQuestions:\n  - The backpropagation through the kernel regressor (in order to train the parameters of the embedding function and other networks) seems unexpectedly straightforward. Is that only because there is a closed-form solution for the optimal regressor? Were the specific algorithms (KRR, GP) chosen because of that? Or could something like MetaOptNet (Meta-Learning with differentiable convex optimization, Lee et al., CVPR 2019) be used to relax that constraint?\n  - What \"generalization guarantees of kernel-based models\" (l. 122) would be applicable here? Do they hold even when the kernel is applied on top of a learned embedding ($\\phi_\\theta$), or even when it depends on a trained model itself ($C_t$)?\n  - What does \"correlations > 0.8\" mean exactly? (l. 258, 263)\n  - In the \"Binding\" dataset, is it possible that the same protein is used in different bio-assays? In that case, are the different experiments \"merged\" into the same task, or be considered different tasks? Could it be possible that tasks involving the same protein would be in different (meta-)splits, or has that been taken care of during the data collection?\n  - In the meta-test splits, how are examples split between the train/support and valid/query parts of each task?\n  - How were the specific architectures of the different neural networks designed, or selected? Between $\\phi$, v, r, $MLP_\\rho$, the space of hyper-parameters seems huge, and the effects of these choices might be drastic.\n\nAdditional feedback\n  - The caption of Figure 1 could (re-)introduce a definition of the notation. U and C_t for instance have not been introduced yet.\n  - I'm not sure I agree that FSDKL only \"share[s] characteristics with the metric learning framework\", I see it more as being in that framework, but incorporating other elements as well (like other methods do, e.g., TADAM or RelationNet).\n  - The horizontal axis of Figure 4 (a) and (c) are not clear until we see Table 4 of the appendix, and suggest an ordering of the different configurations, rather than 10 different categories. I'm not sure how to improve it though, maybe letters instead of numbers?\n\nOn notation:\n  - On l. 155, is $\\phi$ the same as $\\phi_\\theta$, or a different embedding function for x?\n  - In Eq. 11, should $D^t_{trn}$ be $D^{t_j}_{trn}$ instead in both terms? Similarly, $D^{t_j}_{val}$ in the first term?\n  - In Eq. 12, and l. 173, $\\phi_x'$ suggests it is a different embedding $\\phi'$ of the same $x$, if we want to convey that there are two inputs x and x' instead, $\\phi_{x'}$ may be clearer.\n  - In Fig. 4 (a) and 5, the vertical axis is labeled $\\gamma_{mine}$ instead of (I assume) $\\gamma_{task}$."}, "signatures": ["ICLR.cc/2020/Conference/Paper1143/AnonReviewer6"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1143/AnonReviewer6"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "MODELLING   BIOLOGICAL   ASSAYS   WITH ADAPTIVE DEEP KERNEL LEARNING", "authors": ["Prudencio Tossou", "Basile Dura", "Daniel Cohen", "Mario Marchand", "Fran\u00e7ois Laviolette", "Alexandre Lacoste"], "authorids": ["tossouprudencio@gmail.com", "basile@invivoai.ca", "daniel@invivoai.ca", "mario.marchand@ift.ulaval.ca", "francois.laviolette@ift.ulaval.ca", "allac@elementai.com"], "keywords": ["few-shot learning", "few-shot regression", "deep kernel learning", "biological assay modelling", "drug discovery"], "TL;DR": "We investigate the modelling of biological assays using deep kernel learning in few-shot settings.", "abstract": "Due to the significant costs of data generation, many prediction tasks within drug discovery are by nature few-shot regression (FSR) problems, including accurate modelling of biological assays.  Although a number of few-shot classification and reinforcement learning methods exist for similar applications, we find relatively few FSR methods meeting the performance standards required for such tasks under real-world constraints. Inspired by deep kernel learning, we develop a novel FSR algorithm that is better suited to these settings. Our algorithm consists of learning a deep network in combination with a kernel function and a differentiable kernel algorithm. As the choice of the kernel is critical, our algorithm learns to find the appropriate one for each task during inference. It thus performs more effectively with complex task distributions, outperforming current state-of-the-art algorithms on both toy and novel, real-world benchmarks that we introduce herein. By introducing novel benchmarks derived from biological assays, we hope that the community will progress towards the development of FSR algorithms suitable for use in noisy and uncertain environments such as drug discovery.", "pdf": "/pdf/c0c794d29ce86c937dcb0760e85a8d2557597764.pdf", "paperhash": "tossou|modelling_biological_assays_with_adaptive_deep_kernel_learning", "original_pdf": "/attachment/169ccbd6d9cda53fa854a14e36a066f19d913657.pdf", "_bibtex": "@misc{\ntossou2020modelling,\ntitle={{\\{}MODELLING{\\}}   {\\{}BIOLOGICAL{\\}}   {\\{}ASSAYS{\\}}   {\\{}WITH{\\}} {\\{}ADAPTIVE{\\}} {\\{}DEEP{\\}} {\\{}KERNEL{\\}} {\\{}LEARNING{\\}}},\nauthor={Prudencio Tossou and Basile Dura and Daniel Cohen and Mario Marchand and Fran{\\c{c}}ois Laviolette and Alexandre Lacoste},\nyear={2020},\nurl={https://openreview.net/forum?id=Syeu8CNYvS}\n}"}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "Syeu8CNYvS", "replyto": "Syeu8CNYvS", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper1143/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper1143/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1575499184529, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper1143/Reviewers"], "noninvitees": [], "tcdate": 1570237741731, "tmdate": 1575499184543, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper1143/-/Official_Review"}}}, {"id": "BJgdYgX9qr", "original": null, "number": 3, "cdate": 1572642944004, "ddate": null, "tcdate": 1572642944004, "tmdate": 1572972507139, "tddate": null, "forum": "Syeu8CNYvS", "replyto": "Syeu8CNYvS", "invitation": "ICLR.cc/2020/Conference/Paper1143/-/Official_Review", "content": {"rating": "3: Weak Reject", "experience_assessment": "I have published one or two papers in this area.", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #5", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review": "To tackle data scarcity issue in biological assay modeling, this paper proposes a method to episodically train Deep Kernel Learning models such that at meta-test time the models requires less examples. \n\nThe proposed Adaptive Deep Kernel Learning extends Deep Kernel Learning (end-to-end train Gaussian Process/Kernel Ridge Regression using Neural Network's final layer embedding) by:\n\n1. using a learnable task-specific kernel generator network \n2. applying episodic few-shot/meta learning to train the system end-to-end\n\nHere are the major issues for rejecting:\n\nModel:\n- Section 3.1 and 3.2 about \"Task Specific Kernel\" are very hard to follow.\n  -- (line 170) equation 12, What is the size of the MLP that is used as the kernel network \n  -- Is there an ablation to show the contribution of using learnable kernel network vs hand-picked kernel for ADKL-GP and ADKL-KRR? \n  -- (line 181) \"where U is a set of unlabeled inputs\" Where does the unlabeled inputs come from?\n  -- Is there an ablation about |U|  <= 50 and its effect?\n\nExperiments and Datasets:\n\n- The ProtoMAML code provided by the authors has only a few lines of code. And in the comment, it says: \"It turns out that ProtoMAML is the same as the light version of BMAML with one particle.\" Such implementation detail should be mentioned in the main paper.\n\n- Section 5 lacks details. \n -- How each meta-train episode is formed? Did they stochasticall sample a subset of molecules for each episode?\n -- What is the total number of tasks in the meta-train and meta-test split respectively? Are there any overlapping between the two splits?\n\n\nPresentation Issues:\n- Section 2 (line 76) \"We extended it (Deep Kernel Learning) to few-shot learning and discuss its advantages over the metric learning framework\" This sounds like the author developed a brand new framework, while the rest of paper is about proposing a specific realization of few-shot learning: Few-shot Deep Kernel Learning, which meta-learn through a differentialble kernel learning process (with the task kernel adaptation network novelty). \n\n- Section 3 (Figure 1) \"The blue and orange colors show the procedure...\" However there are more than two colors (including different shades of blue and orange colors) in the figure, which makes the figure hard to parse .  \n\n- Section 4 (line 201) \"DKL methods lie between neural networks and kernel methods\". To me, at high-level, DKL adds kernel learning as a differentiable layer in the end of a neural network. See how a similar model is categorized in Bertinetto et al. ICLR 2019 paper \"Meta-learning with differentiable closed-form solvers\":  \"The main idea is to teach a deep network to use standard machine learning tools, such as ridge regression,as part of its own internal model, enabling it to quickly adapt to novel data.\" The delta of the paper is adding 1) Gaussian Process and 2) task-specific adaptation. If Bertinetto et al. categorize their method as part of a deep network then I think so should this work.\n\n- Section 4 (line 239) \"Our work goes beyond ... by proposing ADKL: a data-driven manner for computing the correct kernel for a task.\" This is probably a grammar mistake. \"a data driven manner for\" sounds odd. \n\n- Section 5 (line 272) \"Fig 2 highlights three aspects of the collections that make them better benchmarks for evaluating the readiness of FSR methods for real-world applications relative to toy collections.\" What is the other benchmarks the authors are comparing with? Are they generic benchmarks for all types few-shot regression tasks/applications beyond biological assays (e.g. computer vision tasks like: object detection). Maybe defining the proposed benchmark as \"complimentary\" and \"bio-assay application focused\" would be more appropriate. \n\n"}, "signatures": ["ICLR.cc/2020/Conference/Paper1143/AnonReviewer5"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1143/AnonReviewer5"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "MODELLING   BIOLOGICAL   ASSAYS   WITH ADAPTIVE DEEP KERNEL LEARNING", "authors": ["Prudencio Tossou", "Basile Dura", "Daniel Cohen", "Mario Marchand", "Fran\u00e7ois Laviolette", "Alexandre Lacoste"], "authorids": ["tossouprudencio@gmail.com", "basile@invivoai.ca", "daniel@invivoai.ca", "mario.marchand@ift.ulaval.ca", "francois.laviolette@ift.ulaval.ca", "allac@elementai.com"], "keywords": ["few-shot learning", "few-shot regression", "deep kernel learning", "biological assay modelling", "drug discovery"], "TL;DR": "We investigate the modelling of biological assays using deep kernel learning in few-shot settings.", "abstract": "Due to the significant costs of data generation, many prediction tasks within drug discovery are by nature few-shot regression (FSR) problems, including accurate modelling of biological assays.  Although a number of few-shot classification and reinforcement learning methods exist for similar applications, we find relatively few FSR methods meeting the performance standards required for such tasks under real-world constraints. Inspired by deep kernel learning, we develop a novel FSR algorithm that is better suited to these settings. Our algorithm consists of learning a deep network in combination with a kernel function and a differentiable kernel algorithm. As the choice of the kernel is critical, our algorithm learns to find the appropriate one for each task during inference. It thus performs more effectively with complex task distributions, outperforming current state-of-the-art algorithms on both toy and novel, real-world benchmarks that we introduce herein. By introducing novel benchmarks derived from biological assays, we hope that the community will progress towards the development of FSR algorithms suitable for use in noisy and uncertain environments such as drug discovery.", "pdf": "/pdf/c0c794d29ce86c937dcb0760e85a8d2557597764.pdf", "paperhash": "tossou|modelling_biological_assays_with_adaptive_deep_kernel_learning", "original_pdf": "/attachment/169ccbd6d9cda53fa854a14e36a066f19d913657.pdf", "_bibtex": "@misc{\ntossou2020modelling,\ntitle={{\\{}MODELLING{\\}}   {\\{}BIOLOGICAL{\\}}   {\\{}ASSAYS{\\}}   {\\{}WITH{\\}} {\\{}ADAPTIVE{\\}} {\\{}DEEP{\\}} {\\{}KERNEL{\\}} {\\{}LEARNING{\\}}},\nauthor={Prudencio Tossou and Basile Dura and Daniel Cohen and Mario Marchand and Fran{\\c{c}}ois Laviolette and Alexandre Lacoste},\nyear={2020},\nurl={https://openreview.net/forum?id=Syeu8CNYvS}\n}"}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "Syeu8CNYvS", "replyto": "Syeu8CNYvS", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper1143/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper1143/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1575499184529, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper1143/Reviewers"], "noninvitees": [], "tcdate": 1570237741731, "tmdate": 1575499184543, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper1143/-/Official_Review"}}}, {"id": "B1l2o9Jp5B", "original": null, "number": 6, "cdate": 1572825763952, "ddate": null, "tcdate": 1572825763952, "tmdate": 1572972507096, "tddate": null, "forum": "Syeu8CNYvS", "replyto": "Syeu8CNYvS", "invitation": "ICLR.cc/2020/Conference/Paper1143/-/Official_Review", "content": {"rating": "6: Weak Accept", "experience_assessment": "I have published one or two papers in this area.", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #4", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review": "This paper presents a new framework for solving few-shot regression problems. The proposed framework is based on deep kernel learning, which lies in the intersection of neural networks and kernel methods. The authors introduced adaptive deep kernel learning, which learns kernel for multiple task collection and computes the correct kernel for a task in a data-driven manner. The method is evaluated on three tasks collections \u2014 Sinusoids (synthetic dataset), Binding (real dataset of 5717 task where each task represents a binding affinity of small molecules against a given protein) and Antibacterial (real dataset of 3255 tasks where each task represents antimicrobial activity against given bacterium).\n\n\nPros:\n1. The proposed framework introduces a new adaptive method for few-shot drug discovery regression problems. \n2. The paper addressed the question of uncertainty estimation for drug discovery tasks.\n\n\nCons:\n1. The authors only evaluate the performance of the proposed method against other DKL-based methods. They do not consider a comparison with widely used in computational chemistry classical machine learning methods such as random forest, gradient boosting, SVM (which is also a kernel method), etc.\n2. The experimental results in Tables 1-3 show only marginal improvement for real datasets. Also, it\u2019s not clear if the numbers in the Tables 1-3 are on the original scale or on the transformed scale. To estimate how well the models perform it\u2019s useful to transform the targets back to the original scale. \n3. Overall the paper is written in a somehow confusing manner and some details in the description of the experiments important for understanding are omitted.\n\nQuestions:\n1. How well the proposed method performs against classical machine learning methods?\n2. How was MSE in Tables 1-3 calculated? \n3. It would be useful to see the histogram of MSEs instead of just a single number.\n"}, "signatures": ["ICLR.cc/2020/Conference/Paper1143/AnonReviewer4"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1143/AnonReviewer4"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "MODELLING   BIOLOGICAL   ASSAYS   WITH ADAPTIVE DEEP KERNEL LEARNING", "authors": ["Prudencio Tossou", "Basile Dura", "Daniel Cohen", "Mario Marchand", "Fran\u00e7ois Laviolette", "Alexandre Lacoste"], "authorids": ["tossouprudencio@gmail.com", "basile@invivoai.ca", "daniel@invivoai.ca", "mario.marchand@ift.ulaval.ca", "francois.laviolette@ift.ulaval.ca", "allac@elementai.com"], "keywords": ["few-shot learning", "few-shot regression", "deep kernel learning", "biological assay modelling", "drug discovery"], "TL;DR": "We investigate the modelling of biological assays using deep kernel learning in few-shot settings.", "abstract": "Due to the significant costs of data generation, many prediction tasks within drug discovery are by nature few-shot regression (FSR) problems, including accurate modelling of biological assays.  Although a number of few-shot classification and reinforcement learning methods exist for similar applications, we find relatively few FSR methods meeting the performance standards required for such tasks under real-world constraints. Inspired by deep kernel learning, we develop a novel FSR algorithm that is better suited to these settings. Our algorithm consists of learning a deep network in combination with a kernel function and a differentiable kernel algorithm. As the choice of the kernel is critical, our algorithm learns to find the appropriate one for each task during inference. It thus performs more effectively with complex task distributions, outperforming current state-of-the-art algorithms on both toy and novel, real-world benchmarks that we introduce herein. By introducing novel benchmarks derived from biological assays, we hope that the community will progress towards the development of FSR algorithms suitable for use in noisy and uncertain environments such as drug discovery.", "pdf": "/pdf/c0c794d29ce86c937dcb0760e85a8d2557597764.pdf", "paperhash": "tossou|modelling_biological_assays_with_adaptive_deep_kernel_learning", "original_pdf": "/attachment/169ccbd6d9cda53fa854a14e36a066f19d913657.pdf", "_bibtex": "@misc{\ntossou2020modelling,\ntitle={{\\{}MODELLING{\\}}   {\\{}BIOLOGICAL{\\}}   {\\{}ASSAYS{\\}}   {\\{}WITH{\\}} {\\{}ADAPTIVE{\\}} {\\{}DEEP{\\}} {\\{}KERNEL{\\}} {\\{}LEARNING{\\}}},\nauthor={Prudencio Tossou and Basile Dura and Daniel Cohen and Mario Marchand and Fran{\\c{c}}ois Laviolette and Alexandre Lacoste},\nyear={2020},\nurl={https://openreview.net/forum?id=Syeu8CNYvS}\n}"}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "Syeu8CNYvS", "replyto": "Syeu8CNYvS", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper1143/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper1143/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1575499184529, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper1143/Reviewers"], "noninvitees": [], "tcdate": 1570237741731, "tmdate": 1575499184543, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper1143/-/Official_Review"}}}, {"id": "rye5AH_E5H", "original": null, "number": 4, "cdate": 1572271570386, "ddate": null, "tcdate": 1572271570386, "tmdate": 1572271570386, "tddate": null, "forum": "Syeu8CNYvS", "replyto": "SygFo6h75H", "invitation": "ICLR.cc/2020/Conference/Paper1143/-/Official_Comment", "content": {"title": "Thanks", "comment": "Thank you for your comments. We are happy to try to clarify specific thoughts or ideas as needed."}, "signatures": ["ICLR.cc/2020/Conference/Paper1143/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1143/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "MODELLING   BIOLOGICAL   ASSAYS   WITH ADAPTIVE DEEP KERNEL LEARNING", "authors": ["Prudencio Tossou", "Basile Dura", "Daniel Cohen", "Mario Marchand", "Fran\u00e7ois Laviolette", "Alexandre Lacoste"], "authorids": ["tossouprudencio@gmail.com", "basile@invivoai.ca", "daniel@invivoai.ca", "mario.marchand@ift.ulaval.ca", "francois.laviolette@ift.ulaval.ca", "allac@elementai.com"], "keywords": ["few-shot learning", "few-shot regression", "deep kernel learning", "biological assay modelling", "drug discovery"], "TL;DR": "We investigate the modelling of biological assays using deep kernel learning in few-shot settings.", "abstract": "Due to the significant costs of data generation, many prediction tasks within drug discovery are by nature few-shot regression (FSR) problems, including accurate modelling of biological assays.  Although a number of few-shot classification and reinforcement learning methods exist for similar applications, we find relatively few FSR methods meeting the performance standards required for such tasks under real-world constraints. Inspired by deep kernel learning, we develop a novel FSR algorithm that is better suited to these settings. Our algorithm consists of learning a deep network in combination with a kernel function and a differentiable kernel algorithm. As the choice of the kernel is critical, our algorithm learns to find the appropriate one for each task during inference. It thus performs more effectively with complex task distributions, outperforming current state-of-the-art algorithms on both toy and novel, real-world benchmarks that we introduce herein. By introducing novel benchmarks derived from biological assays, we hope that the community will progress towards the development of FSR algorithms suitable for use in noisy and uncertain environments such as drug discovery.", "pdf": "/pdf/c0c794d29ce86c937dcb0760e85a8d2557597764.pdf", "paperhash": "tossou|modelling_biological_assays_with_adaptive_deep_kernel_learning", "original_pdf": "/attachment/169ccbd6d9cda53fa854a14e36a066f19d913657.pdf", "_bibtex": "@misc{\ntossou2020modelling,\ntitle={{\\{}MODELLING{\\}}   {\\{}BIOLOGICAL{\\}}   {\\{}ASSAYS{\\}}   {\\{}WITH{\\}} {\\{}ADAPTIVE{\\}} {\\{}DEEP{\\}} {\\{}KERNEL{\\}} {\\{}LEARNING{\\}}},\nauthor={Prudencio Tossou and Basile Dura and Daniel Cohen and Mario Marchand and Fran{\\c{c}}ois Laviolette and Alexandre Lacoste},\nyear={2020},\nurl={https://openreview.net/forum?id=Syeu8CNYvS}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "Syeu8CNYvS", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper1143/Authors", "ICLR.cc/2020/Conference/Paper1143/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper1143/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper1143/Reviewers", "ICLR.cc/2020/Conference/Paper1143/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper1143/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper1143/Authors|ICLR.cc/2020/Conference/Paper1143/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504160576, "tmdate": 1576860546055, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper1143/Authors", "ICLR.cc/2020/Conference/Paper1143/Reviewers", "ICLR.cc/2020/Conference/Paper1143/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper1143/-/Official_Comment"}}}, {"id": "SygFo6h75H", "original": null, "number": 3, "cdate": 1572224417062, "ddate": null, "tcdate": 1572224417062, "tmdate": 1572224417062, "tddate": null, "forum": "Syeu8CNYvS", "replyto": "HyeAZo-htH", "invitation": "ICLR.cc/2020/Conference/Paper1143/-/Official_Comment", "content": {"title": "Can't assess this line of work", "comment": "I unfortunately can't provide technical substance. But I do feel the presentation makes understanding unusually hard."}, "signatures": ["ICLR.cc/2020/Conference/Paper1143/AnonReviewer1"], "readers": ["everyone", "ICLR.cc/2020/Conference/Paper1143/Reviewers"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1143/AnonReviewer1", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "MODELLING   BIOLOGICAL   ASSAYS   WITH ADAPTIVE DEEP KERNEL LEARNING", "authors": ["Prudencio Tossou", "Basile Dura", "Daniel Cohen", "Mario Marchand", "Fran\u00e7ois Laviolette", "Alexandre Lacoste"], "authorids": ["tossouprudencio@gmail.com", "basile@invivoai.ca", "daniel@invivoai.ca", "mario.marchand@ift.ulaval.ca", "francois.laviolette@ift.ulaval.ca", "allac@elementai.com"], "keywords": ["few-shot learning", "few-shot regression", "deep kernel learning", "biological assay modelling", "drug discovery"], "TL;DR": "We investigate the modelling of biological assays using deep kernel learning in few-shot settings.", "abstract": "Due to the significant costs of data generation, many prediction tasks within drug discovery are by nature few-shot regression (FSR) problems, including accurate modelling of biological assays.  Although a number of few-shot classification and reinforcement learning methods exist for similar applications, we find relatively few FSR methods meeting the performance standards required for such tasks under real-world constraints. Inspired by deep kernel learning, we develop a novel FSR algorithm that is better suited to these settings. Our algorithm consists of learning a deep network in combination with a kernel function and a differentiable kernel algorithm. As the choice of the kernel is critical, our algorithm learns to find the appropriate one for each task during inference. It thus performs more effectively with complex task distributions, outperforming current state-of-the-art algorithms on both toy and novel, real-world benchmarks that we introduce herein. By introducing novel benchmarks derived from biological assays, we hope that the community will progress towards the development of FSR algorithms suitable for use in noisy and uncertain environments such as drug discovery.", "pdf": "/pdf/c0c794d29ce86c937dcb0760e85a8d2557597764.pdf", "paperhash": "tossou|modelling_biological_assays_with_adaptive_deep_kernel_learning", "original_pdf": "/attachment/169ccbd6d9cda53fa854a14e36a066f19d913657.pdf", "_bibtex": "@misc{\ntossou2020modelling,\ntitle={{\\{}MODELLING{\\}}   {\\{}BIOLOGICAL{\\}}   {\\{}ASSAYS{\\}}   {\\{}WITH{\\}} {\\{}ADAPTIVE{\\}} {\\{}DEEP{\\}} {\\{}KERNEL{\\}} {\\{}LEARNING{\\}}},\nauthor={Prudencio Tossou and Basile Dura and Daniel Cohen and Mario Marchand and Fran{\\c{c}}ois Laviolette and Alexandre Lacoste},\nyear={2020},\nurl={https://openreview.net/forum?id=Syeu8CNYvS}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "Syeu8CNYvS", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper1143/Authors", "ICLR.cc/2020/Conference/Paper1143/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper1143/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper1143/Reviewers", "ICLR.cc/2020/Conference/Paper1143/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper1143/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper1143/Authors|ICLR.cc/2020/Conference/Paper1143/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504160576, "tmdate": 1576860546055, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper1143/Authors", "ICLR.cc/2020/Conference/Paper1143/Reviewers", "ICLR.cc/2020/Conference/Paper1143/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper1143/-/Official_Comment"}}}, {"id": "HyeAZo-htH", "original": null, "number": 1, "cdate": 1571719941663, "ddate": null, "tcdate": 1571719941663, "tmdate": 1571719941663, "tddate": null, "forum": "Syeu8CNYvS", "replyto": "Syeu8CNYvS", "invitation": "ICLR.cc/2020/Conference/Paper1143/-/Official_Comment", "content": {"title": "I don't quite follow this line of work.", "comment": "I unfortunately can't provide technical substance. But I do feel the presentation makes understanding unusually hard."}, "signatures": ["ICLR.cc/2020/Conference/Paper1143/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1143/AnonReviewer1", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "MODELLING   BIOLOGICAL   ASSAYS   WITH ADAPTIVE DEEP KERNEL LEARNING", "authors": ["Prudencio Tossou", "Basile Dura", "Daniel Cohen", "Mario Marchand", "Fran\u00e7ois Laviolette", "Alexandre Lacoste"], "authorids": ["tossouprudencio@gmail.com", "basile@invivoai.ca", "daniel@invivoai.ca", "mario.marchand@ift.ulaval.ca", "francois.laviolette@ift.ulaval.ca", "allac@elementai.com"], "keywords": ["few-shot learning", "few-shot regression", "deep kernel learning", "biological assay modelling", "drug discovery"], "TL;DR": "We investigate the modelling of biological assays using deep kernel learning in few-shot settings.", "abstract": "Due to the significant costs of data generation, many prediction tasks within drug discovery are by nature few-shot regression (FSR) problems, including accurate modelling of biological assays.  Although a number of few-shot classification and reinforcement learning methods exist for similar applications, we find relatively few FSR methods meeting the performance standards required for such tasks under real-world constraints. Inspired by deep kernel learning, we develop a novel FSR algorithm that is better suited to these settings. Our algorithm consists of learning a deep network in combination with a kernel function and a differentiable kernel algorithm. As the choice of the kernel is critical, our algorithm learns to find the appropriate one for each task during inference. It thus performs more effectively with complex task distributions, outperforming current state-of-the-art algorithms on both toy and novel, real-world benchmarks that we introduce herein. By introducing novel benchmarks derived from biological assays, we hope that the community will progress towards the development of FSR algorithms suitable for use in noisy and uncertain environments such as drug discovery.", "pdf": "/pdf/c0c794d29ce86c937dcb0760e85a8d2557597764.pdf", "paperhash": "tossou|modelling_biological_assays_with_adaptive_deep_kernel_learning", "original_pdf": "/attachment/169ccbd6d9cda53fa854a14e36a066f19d913657.pdf", "_bibtex": "@misc{\ntossou2020modelling,\ntitle={{\\{}MODELLING{\\}}   {\\{}BIOLOGICAL{\\}}   {\\{}ASSAYS{\\}}   {\\{}WITH{\\}} {\\{}ADAPTIVE{\\}} {\\{}DEEP{\\}} {\\{}KERNEL{\\}} {\\{}LEARNING{\\}}},\nauthor={Prudencio Tossou and Basile Dura and Daniel Cohen and Mario Marchand and Fran{\\c{c}}ois Laviolette and Alexandre Lacoste},\nyear={2020},\nurl={https://openreview.net/forum?id=Syeu8CNYvS}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "Syeu8CNYvS", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper1143/Authors", "ICLR.cc/2020/Conference/Paper1143/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper1143/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper1143/Reviewers", "ICLR.cc/2020/Conference/Paper1143/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper1143/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper1143/Authors|ICLR.cc/2020/Conference/Paper1143/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504160576, "tmdate": 1576860546055, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper1143/Authors", "ICLR.cc/2020/Conference/Paper1143/Reviewers", "ICLR.cc/2020/Conference/Paper1143/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper1143/-/Official_Comment"}}}], "count": 18}