{"notes": [{"id": "SkxbDsR9Ym", "original": "S1eEW-w9Km", "number": 236, "cdate": 1538087768649, "ddate": null, "tcdate": 1538087768649, "tmdate": 1545355432129, "tddate": null, "forum": "SkxbDsR9Ym", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "RelWalk -- A Latent Variable Model Approach to Knowledge Graph Embedding", "abstract": "Knowledge Graph Embedding (KGE) is the task of jointly learning entity and relation embeddings for a given knowledge graph. Existing methods for learning KGEs can be seen as a two-stage process where (a) entities and relations in the knowledge graph are represented using some linear algebraic structures (embeddings), and (b) a scoring function is defined that evaluates the strength of a relation that holds between two entities using the corresponding relation and entity embeddings. Unfortunately, prior proposals for the scoring functions in the first step have been heuristically motivated, and it is unclear as to how the scoring functions in KGEs relate to the generation process of the underlying knowledge graph. To address this issue, we propose a generative account of the KGE learning task. Specifically, given a knowledge graph represented by a set of relational triples (h, R, t), where the semantic relation R holds between the two entities h (head) and t (tail), we extend the random walk model (Arora et al., 2016a) of word embeddings to KGE. We derive a theoretical relationship between the joint probability p(h, R, t) and the embeddings of h, R and t. Moreover, we show that marginal loss minimisation, a popular objective used by much prior work in KGE, follows naturally from the log-likelihood ratio maximisation under the probabilities estimated from the KGEs according to our theoretical relationship. We propose a learning objective motivated by the theoretical analysis to learn KGEs from a given knowledge graph. The KGEs learnt by our proposed method obtain state-of-the-art performance on FB15K237 and WN18RR benchmark datasets, providing empirical evidence in support of the theory.\n", "keywords": ["relation representations", "natural language processing", "theoretical analysis", "knowledge graphs"], "authorids": ["danushka@liverpool.ac.uk", "h.a.hakami@liverpool.ac.uk", "yyoshida@nii.ac.jp", "k_keniti@nii.ac.jp"], "authors": ["Danushka Bollegala", "Huda Hakami", "Yuichi Yoshida", "Ken-ichi Kawarabayashi"], "TL;DR": "We present a theoretically proven generative model of knowledge graph embedding. ", "pdf": "/pdf/d70821e9867c967f02ed7b2eb093b95ef3fa0e3d.pdf", "paperhash": "bollegala|relwalk_a_latent_variable_model_approach_to_knowledge_graph_embedding", "_bibtex": "@misc{\nbollegala2019relwalk,\ntitle={RelWalk -- A Latent Variable Model Approach to Knowledge Graph Embedding},\nauthor={Danushka Bollegala and Huda Hakami and Yuichi Yoshida and Ken-ichi Kawarabayashi},\nyear={2019},\nurl={https://openreview.net/forum?id=SkxbDsR9Ym},\n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"replyCount": 19, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Blind_Submission", "rdate": null, "ddate": null, "expdate": null, "duedate": 1538085600000, "tmdate": 1538142958393, "tddate": null, "super": null, "final": null, "reply": {"signatures": {"values": ["ICLR.cc/2019/Conference"]}, "forum": null, "readers": {"values": ["everyone"]}, "replyto": null, "content": {"authorids": {"values-regex": ".*"}, "authors": {"values": ["Anonymous"]}}, "writers": {"values": ["ICLR.cc/2019/Conference"]}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["~"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": null, "taskCompletionCount": null, "transform": null, "cdate": 1538142958393}}, "tauthor": "OpenReview.net"}, {"id": "BJlzMYa4lE", "original": null, "number": 1, "cdate": 1545029898005, "ddate": null, "tcdate": 1545029898005, "tmdate": 1545354484231, "tddate": null, "forum": "SkxbDsR9Ym", "replyto": "SkxbDsR9Ym", "invitation": "ICLR.cc/2019/Conference/-/Paper236/Meta_Review", "content": {"metareview": "This paper proposes a new scoring function for link prediction model that is based on a generative model for the knowledge graph, based on a random-walk model previously used for word embeddings. The new scoring function, as it is accompanied by the generative model, provides interesting theoretical results that the reviewers also appreciate. Finally, the results are quite strong, as they obtain state-of-art on the primary benchmarks for the task.\n\nBased on the submitted version, the reviewers and AC note the following potential weaknesses: (1) the reviewers felt that the proposed work is a direct application of the random-walk model from Arora et al. and thus limited in novelty, (2) given the generative model, the reviewers felt that the paper would benefit from an analysis of the learned embeddings, and their difference from ones from existing approaches, (3) The reviewers noted that the authors were using an incorrect version of FB15k and WN18, (4) the authors were not providing results for all the metrics, (5) the coverage of related work is quite limited.\n\nThe authors addressed many of the concerns raised by the reviewers in their comments and revision, in particular, they obtained state-of-art results for the corrected versions of the benchmarks. Further, they clarified the assumptions made in their modeling and revised the related work to include the papers that the reviewers mentioned. However, the concerns regarding the lack of novelty of the proposed approach, w.r.t Arora et al 2016 and the need for further analysis of the learned embeddings, still remain.\n\nThis paper comes really close to getting accepted, but ultimately the reviewers agree that the remaining concerns need to be addressed.", "confidence": "2: The area chair is not sure", "recommendation": "Reject", "title": "Limited novelty, and further analysis needed"}, "signatures": ["ICLR.cc/2019/Conference/Paper236/Area_Chair1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference/Paper236/Area_Chair1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "RelWalk -- A Latent Variable Model Approach to Knowledge Graph Embedding", "abstract": "Knowledge Graph Embedding (KGE) is the task of jointly learning entity and relation embeddings for a given knowledge graph. Existing methods for learning KGEs can be seen as a two-stage process where (a) entities and relations in the knowledge graph are represented using some linear algebraic structures (embeddings), and (b) a scoring function is defined that evaluates the strength of a relation that holds between two entities using the corresponding relation and entity embeddings. Unfortunately, prior proposals for the scoring functions in the first step have been heuristically motivated, and it is unclear as to how the scoring functions in KGEs relate to the generation process of the underlying knowledge graph. To address this issue, we propose a generative account of the KGE learning task. Specifically, given a knowledge graph represented by a set of relational triples (h, R, t), where the semantic relation R holds between the two entities h (head) and t (tail), we extend the random walk model (Arora et al., 2016a) of word embeddings to KGE. We derive a theoretical relationship between the joint probability p(h, R, t) and the embeddings of h, R and t. Moreover, we show that marginal loss minimisation, a popular objective used by much prior work in KGE, follows naturally from the log-likelihood ratio maximisation under the probabilities estimated from the KGEs according to our theoretical relationship. We propose a learning objective motivated by the theoretical analysis to learn KGEs from a given knowledge graph. The KGEs learnt by our proposed method obtain state-of-the-art performance on FB15K237 and WN18RR benchmark datasets, providing empirical evidence in support of the theory.\n", "keywords": ["relation representations", "natural language processing", "theoretical analysis", "knowledge graphs"], "authorids": ["danushka@liverpool.ac.uk", "h.a.hakami@liverpool.ac.uk", "yyoshida@nii.ac.jp", "k_keniti@nii.ac.jp"], "authors": ["Danushka Bollegala", "Huda Hakami", "Yuichi Yoshida", "Ken-ichi Kawarabayashi"], "TL;DR": "We present a theoretically proven generative model of knowledge graph embedding. ", "pdf": "/pdf/d70821e9867c967f02ed7b2eb093b95ef3fa0e3d.pdf", "paperhash": "bollegala|relwalk_a_latent_variable_model_approach_to_knowledge_graph_embedding", "_bibtex": "@misc{\nbollegala2019relwalk,\ntitle={RelWalk -- A Latent Variable Model Approach to Knowledge Graph Embedding},\nauthor={Danushka Bollegala and Huda Hakami and Yuichi Yoshida and Ken-ichi Kawarabayashi},\nyear={2019},\nurl={https://openreview.net/forum?id=SkxbDsR9Ym},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper236/Meta_Review", "rdate": null, "ddate": null, "expdate": null, "duedate": 1541548800000, "tmdate": 1545353288287, "tddate": null, "super": null, "final": null, "reply": {"forum": "SkxbDsR9Ym", "replyto": "SkxbDsR9Ym", "readers": {"description": "Select all user groups that should be able to read this comment. Selecting 'All Users' will allow paper authors, reviewers, area chairs, and program chairs to view this comment.", "values": ["everyone"]}, "signatures": {"description": "How your identity will be displayed with the above content.", "values-regex": "ICLR.cc/2019/Conference/Paper236/Area_Chair[0-9]+"}, "writers": {"description": "Users that may modify this record.", "values-regex": "ICLR.cc/2019/Conference/Paper236/Area_Chair[0-9]+"}, "content": {"title": {"order": 1, "value-regex": ".{1,500}", "description": "Brief summary of your review.", "required": true}, "metareview": {"order": 2, "value-regex": "[\\S\\s]{1,5000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "required": true}, "recommendation": {"order": 3, "value-dropdown": ["Accept (Oral)", "Accept (Poster)", "Reject"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The area chair is absolutely certain", "4: The area chair is confident but not absolutely certain", "3: The area chair is somewhat confident", "2: The area chair is not sure", "1: The area chair's evaluation is an educated guess"], "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper236/Area_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": false, "taskCompletionCount": null, "transform": null, "cdate": 1545353288287}}}, {"id": "HyxKd25wp7", "original": null, "number": 3, "cdate": 1542069360817, "ddate": null, "tcdate": 1542069360817, "tmdate": 1543105179992, "tddate": null, "forum": "SkxbDsR9Ym", "replyto": "SkxbDsR9Ym", "invitation": "ICLR.cc/2019/Conference/-/Paper236/Official_Review", "content": {"title": "A solid idea that seems to work in practic but the novelty and the empirical justification may not be enough. ", "review": "This paper proposes to perform the link prediction in knowledge bases by introducing a new scoring function and theoretically motivating their method. The authors validate their proposed approach through several experiments. \n\nThis paper reads well and the results appear sound. I personally find the theoretical argument behind the proposed scoring function very interesting. Unfortunately, the contribution seems rather small to be accepted for ICLR. This is a straight application and combination of existing pieces with not much originality and without being backed up by very strong experimental results. My concerns are as follows:\n\n   - Having only results on two flawed datasets (considering the inverse relations in them) makes it hard to evaluate the quality of the method. I suggest conducting the experiments on the FB15K-237 and WN18RR from [1] instead. \n   - You only evaluate on MR and Hits@10, but it is standard to include metrics like MRR and Hits@1 and 3 also, since no metric is perfect for this task.\n   - Since the goal of the work is not providing a state of the art method, and focus on the theoretical understanding of their scoring function, it is of high importance to assess the characteristics of their embeddings and scoring function through designing other experiments. As a result, I suggest to study the geometric behavior of their embeddings and compare it to the other methods. Further, investigating the semantic purity of the embeddings by calculating the entropy of the type distribution of the entities, similar as [2], can shed more light on the significance of their method.\n\nOn overall, although the proposed method seems a direct application of Arora et al.,2016a, I find their extension novel and quite interesting, But the paper needs more experimental results to validate the idea.  \n\n\n[1] Dettmers, Tim, et al. \"Convolutional 2d knowledge graph embeddings.\", AAAI-18.\n[2] Ding, Boyang, et al. \"Improving Knowledge Graph Embedding Using Simple Constraints.\", ACL-18.\n", "rating": "6: Marginally above acceptance threshold", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["ICLR.cc/2019/Conference/Paper236/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": true, "forumContent": {"title": "RelWalk -- A Latent Variable Model Approach to Knowledge Graph Embedding", "abstract": "Knowledge Graph Embedding (KGE) is the task of jointly learning entity and relation embeddings for a given knowledge graph. Existing methods for learning KGEs can be seen as a two-stage process where (a) entities and relations in the knowledge graph are represented using some linear algebraic structures (embeddings), and (b) a scoring function is defined that evaluates the strength of a relation that holds between two entities using the corresponding relation and entity embeddings. Unfortunately, prior proposals for the scoring functions in the first step have been heuristically motivated, and it is unclear as to how the scoring functions in KGEs relate to the generation process of the underlying knowledge graph. To address this issue, we propose a generative account of the KGE learning task. Specifically, given a knowledge graph represented by a set of relational triples (h, R, t), where the semantic relation R holds between the two entities h (head) and t (tail), we extend the random walk model (Arora et al., 2016a) of word embeddings to KGE. We derive a theoretical relationship between the joint probability p(h, R, t) and the embeddings of h, R and t. Moreover, we show that marginal loss minimisation, a popular objective used by much prior work in KGE, follows naturally from the log-likelihood ratio maximisation under the probabilities estimated from the KGEs according to our theoretical relationship. We propose a learning objective motivated by the theoretical analysis to learn KGEs from a given knowledge graph. The KGEs learnt by our proposed method obtain state-of-the-art performance on FB15K237 and WN18RR benchmark datasets, providing empirical evidence in support of the theory.\n", "keywords": ["relation representations", "natural language processing", "theoretical analysis", "knowledge graphs"], "authorids": ["danushka@liverpool.ac.uk", "h.a.hakami@liverpool.ac.uk", "yyoshida@nii.ac.jp", "k_keniti@nii.ac.jp"], "authors": ["Danushka Bollegala", "Huda Hakami", "Yuichi Yoshida", "Ken-ichi Kawarabayashi"], "TL;DR": "We present a theoretically proven generative model of knowledge graph embedding. ", "pdf": "/pdf/d70821e9867c967f02ed7b2eb093b95ef3fa0e3d.pdf", "paperhash": "bollegala|relwalk_a_latent_variable_model_approach_to_knowledge_graph_embedding", "_bibtex": "@misc{\nbollegala2019relwalk,\ntitle={RelWalk -- A Latent Variable Model Approach to Knowledge Graph Embedding},\nauthor={Danushka Bollegala and Huda Hakami and Yuichi Yoshida and Ken-ichi Kawarabayashi},\nyear={2019},\nurl={https://openreview.net/forum?id=SkxbDsR9Ym},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper236/Official_Review", "cdate": 1542234508022, "expdate": 1552335264000, "duedate": 1541196000000, "reply": {"forum": "SkxbDsR9Ym", "replyto": "SkxbDsR9Ym", "readers": {"description": "The users who will be allowed to read the reply content.", "values": ["everyone"]}, "nonreaders": {"values": []}, "signatures": {"description": "How your identity will be displayed with the above content.", "values-regex": "ICLR.cc/2019/Conference/Paper236/AnonReviewer[0-9]+"}, "writers": {"description": "Users that may modify this record.", "values": ["ICLR.cc/2019/Conference"]}, "content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "required": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}}, "multiReply": false, "tcdate": 1552335678992, "tmdate": 1552335678992, "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "invitees": ["ICLR.cc/2019/Conference/Paper236/Reviewers"], "noninvitees": [], "signatures": ["ICLR.cc/2019/Conference"]}}}, {"id": "S1gUjPPvRm", "original": null, "number": 12, "cdate": 1543104413591, "ddate": null, "tcdate": 1543104413591, "tmdate": 1543104413591, "tddate": null, "forum": "SkxbDsR9Ym", "replyto": "BJgxzoVCam", "invitation": "ICLR.cc/2019/Conference/-/Paper236/Official_Comment", "content": {"title": "Re: Interesting Results", "comment": "Thank you for your comment. We have added ConvE results to Table 3 in the paper. Interestingly, the proposed method (RelWalk) outperforms ConvE also on both FB15k237 and WN18RR datasets."}, "signatures": ["ICLR.cc/2019/Conference/Paper236/Authors"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper236/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper236/Authors", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "RelWalk -- A Latent Variable Model Approach to Knowledge Graph Embedding", "abstract": "Knowledge Graph Embedding (KGE) is the task of jointly learning entity and relation embeddings for a given knowledge graph. Existing methods for learning KGEs can be seen as a two-stage process where (a) entities and relations in the knowledge graph are represented using some linear algebraic structures (embeddings), and (b) a scoring function is defined that evaluates the strength of a relation that holds between two entities using the corresponding relation and entity embeddings. Unfortunately, prior proposals for the scoring functions in the first step have been heuristically motivated, and it is unclear as to how the scoring functions in KGEs relate to the generation process of the underlying knowledge graph. To address this issue, we propose a generative account of the KGE learning task. Specifically, given a knowledge graph represented by a set of relational triples (h, R, t), where the semantic relation R holds between the two entities h (head) and t (tail), we extend the random walk model (Arora et al., 2016a) of word embeddings to KGE. We derive a theoretical relationship between the joint probability p(h, R, t) and the embeddings of h, R and t. Moreover, we show that marginal loss minimisation, a popular objective used by much prior work in KGE, follows naturally from the log-likelihood ratio maximisation under the probabilities estimated from the KGEs according to our theoretical relationship. We propose a learning objective motivated by the theoretical analysis to learn KGEs from a given knowledge graph. The KGEs learnt by our proposed method obtain state-of-the-art performance on FB15K237 and WN18RR benchmark datasets, providing empirical evidence in support of the theory.\n", "keywords": ["relation representations", "natural language processing", "theoretical analysis", "knowledge graphs"], "authorids": ["danushka@liverpool.ac.uk", "h.a.hakami@liverpool.ac.uk", "yyoshida@nii.ac.jp", "k_keniti@nii.ac.jp"], "authors": ["Danushka Bollegala", "Huda Hakami", "Yuichi Yoshida", "Ken-ichi Kawarabayashi"], "TL;DR": "We present a theoretically proven generative model of knowledge graph embedding. ", "pdf": "/pdf/d70821e9867c967f02ed7b2eb093b95ef3fa0e3d.pdf", "paperhash": "bollegala|relwalk_a_latent_variable_model_approach_to_knowledge_graph_embedding", "_bibtex": "@misc{\nbollegala2019relwalk,\ntitle={RelWalk -- A Latent Variable Model Approach to Knowledge Graph Embedding},\nauthor={Danushka Bollegala and Huda Hakami and Yuichi Yoshida and Ken-ichi Kawarabayashi},\nyear={2019},\nurl={https://openreview.net/forum?id=SkxbDsR9Ym},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper236/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621613867, "tddate": null, "super": null, "final": null, "reply": {"forum": "SkxbDsR9Ym", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper236/Authors", "ICLR.cc/2019/Conference/Paper236/Reviewers", "ICLR.cc/2019/Conference/Paper236/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper236/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper236/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper236/Authors|ICLR.cc/2019/Conference/Paper236/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper236/Reviewers", "ICLR.cc/2019/Conference/Paper236/Authors", "ICLR.cc/2019/Conference/Paper236/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621613867}}}, {"id": "BJgxzoVCam", "original": null, "number": 11, "cdate": 1542503175814, "ddate": null, "tcdate": 1542503175814, "tmdate": 1542503232389, "tddate": null, "forum": "SkxbDsR9Ym", "replyto": "rkxdq_JOT7", "invitation": "ICLR.cc/2019/Conference/-/Paper236/Official_Comment", "content": {"title": "Interesting Results", "comment": "It is impressive that you could achieve state of the art results with your proposed scoring function, but I suggest updating your Table 2 with more recent baselines, specifically adding ConvE [1]. Furthermore, I believe the number of page restriction does not strongly being enforced in ICLR venue, and you could even add the results of your method for more metrics to the Appendix; I am really interested in seeing those results.\n\n[1] Dettmers, Tim, et al. \"Convolutional 2d knowledge graph embeddings.\", AAAI-18."}, "signatures": ["ICLR.cc/2019/Conference/Paper236/AnonReviewer2"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper236/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper236/AnonReviewer2", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "RelWalk -- A Latent Variable Model Approach to Knowledge Graph Embedding", "abstract": "Knowledge Graph Embedding (KGE) is the task of jointly learning entity and relation embeddings for a given knowledge graph. Existing methods for learning KGEs can be seen as a two-stage process where (a) entities and relations in the knowledge graph are represented using some linear algebraic structures (embeddings), and (b) a scoring function is defined that evaluates the strength of a relation that holds between two entities using the corresponding relation and entity embeddings. Unfortunately, prior proposals for the scoring functions in the first step have been heuristically motivated, and it is unclear as to how the scoring functions in KGEs relate to the generation process of the underlying knowledge graph. To address this issue, we propose a generative account of the KGE learning task. Specifically, given a knowledge graph represented by a set of relational triples (h, R, t), where the semantic relation R holds between the two entities h (head) and t (tail), we extend the random walk model (Arora et al., 2016a) of word embeddings to KGE. We derive a theoretical relationship between the joint probability p(h, R, t) and the embeddings of h, R and t. Moreover, we show that marginal loss minimisation, a popular objective used by much prior work in KGE, follows naturally from the log-likelihood ratio maximisation under the probabilities estimated from the KGEs according to our theoretical relationship. We propose a learning objective motivated by the theoretical analysis to learn KGEs from a given knowledge graph. The KGEs learnt by our proposed method obtain state-of-the-art performance on FB15K237 and WN18RR benchmark datasets, providing empirical evidence in support of the theory.\n", "keywords": ["relation representations", "natural language processing", "theoretical analysis", "knowledge graphs"], "authorids": ["danushka@liverpool.ac.uk", "h.a.hakami@liverpool.ac.uk", "yyoshida@nii.ac.jp", "k_keniti@nii.ac.jp"], "authors": ["Danushka Bollegala", "Huda Hakami", "Yuichi Yoshida", "Ken-ichi Kawarabayashi"], "TL;DR": "We present a theoretically proven generative model of knowledge graph embedding. ", "pdf": "/pdf/d70821e9867c967f02ed7b2eb093b95ef3fa0e3d.pdf", "paperhash": "bollegala|relwalk_a_latent_variable_model_approach_to_knowledge_graph_embedding", "_bibtex": "@misc{\nbollegala2019relwalk,\ntitle={RelWalk -- A Latent Variable Model Approach to Knowledge Graph Embedding},\nauthor={Danushka Bollegala and Huda Hakami and Yuichi Yoshida and Ken-ichi Kawarabayashi},\nyear={2019},\nurl={https://openreview.net/forum?id=SkxbDsR9Ym},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper236/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621613867, "tddate": null, "super": null, "final": null, "reply": {"forum": "SkxbDsR9Ym", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper236/Authors", "ICLR.cc/2019/Conference/Paper236/Reviewers", "ICLR.cc/2019/Conference/Paper236/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper236/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper236/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper236/Authors|ICLR.cc/2019/Conference/Paper236/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper236/Reviewers", "ICLR.cc/2019/Conference/Paper236/Authors", "ICLR.cc/2019/Conference/Paper236/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621613867}}}, {"id": "HJlNV5yu6X", "original": null, "number": 10, "cdate": 1542089259953, "ddate": null, "tcdate": 1542089259953, "tmdate": 1542089259953, "tddate": null, "forum": "SkxbDsR9Ym", "replyto": "r1eY4IjF2X", "invitation": "ICLR.cc/2019/Conference/-/Paper236/Official_Comment", "content": {"title": "Author response: AnonReviewer1", "comment": "Q1: - The authors missed [1] which also introduces a generative model for knowledge graph embeddings. \n\nAns: TransG [1] is described in detail in the related work section and is compared against in the experiments section. The proposed method, RelWalk, out performs TransG in FB13 dataset in the triple classification task.\n\nQ2: - The authors are not mentioning and comparing to walk based approaches like node2vec [2], Deepwalk [3], and rdf2vec [4]. Due to the missing comparisons to the mentioned references above and the possible bias in the evaluation, I am leaning towards rejecting the paper. \n\nAns: Please note that all these papers are cited in the revised version and their relevance discussed in the related work section. However, we note that [2], [3], [4] are only weakly related to the KGE task we consider in this paper because those paper are either assuming a richer knowledge graph (RDF annotated) than a simple relation-labelled knowledge base or learning vertex representations only. Therefore, following the prior work on KGE, in our evaluations, we compare methods that use the standard benchmarks such as Freebase and WordNet.\n\nAll minor comments are updated in the paper and the papers are cited.\n"}, "signatures": ["ICLR.cc/2019/Conference/Paper236/Authors"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper236/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper236/Authors", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "RelWalk -- A Latent Variable Model Approach to Knowledge Graph Embedding", "abstract": "Knowledge Graph Embedding (KGE) is the task of jointly learning entity and relation embeddings for a given knowledge graph. Existing methods for learning KGEs can be seen as a two-stage process where (a) entities and relations in the knowledge graph are represented using some linear algebraic structures (embeddings), and (b) a scoring function is defined that evaluates the strength of a relation that holds between two entities using the corresponding relation and entity embeddings. Unfortunately, prior proposals for the scoring functions in the first step have been heuristically motivated, and it is unclear as to how the scoring functions in KGEs relate to the generation process of the underlying knowledge graph. To address this issue, we propose a generative account of the KGE learning task. Specifically, given a knowledge graph represented by a set of relational triples (h, R, t), where the semantic relation R holds between the two entities h (head) and t (tail), we extend the random walk model (Arora et al., 2016a) of word embeddings to KGE. We derive a theoretical relationship between the joint probability p(h, R, t) and the embeddings of h, R and t. Moreover, we show that marginal loss minimisation, a popular objective used by much prior work in KGE, follows naturally from the log-likelihood ratio maximisation under the probabilities estimated from the KGEs according to our theoretical relationship. We propose a learning objective motivated by the theoretical analysis to learn KGEs from a given knowledge graph. The KGEs learnt by our proposed method obtain state-of-the-art performance on FB15K237 and WN18RR benchmark datasets, providing empirical evidence in support of the theory.\n", "keywords": ["relation representations", "natural language processing", "theoretical analysis", "knowledge graphs"], "authorids": ["danushka@liverpool.ac.uk", "h.a.hakami@liverpool.ac.uk", "yyoshida@nii.ac.jp", "k_keniti@nii.ac.jp"], "authors": ["Danushka Bollegala", "Huda Hakami", "Yuichi Yoshida", "Ken-ichi Kawarabayashi"], "TL;DR": "We present a theoretically proven generative model of knowledge graph embedding. ", "pdf": "/pdf/d70821e9867c967f02ed7b2eb093b95ef3fa0e3d.pdf", "paperhash": "bollegala|relwalk_a_latent_variable_model_approach_to_knowledge_graph_embedding", "_bibtex": "@misc{\nbollegala2019relwalk,\ntitle={RelWalk -- A Latent Variable Model Approach to Knowledge Graph Embedding},\nauthor={Danushka Bollegala and Huda Hakami and Yuichi Yoshida and Ken-ichi Kawarabayashi},\nyear={2019},\nurl={https://openreview.net/forum?id=SkxbDsR9Ym},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper236/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621613867, "tddate": null, "super": null, "final": null, "reply": {"forum": "SkxbDsR9Ym", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper236/Authors", "ICLR.cc/2019/Conference/Paper236/Reviewers", "ICLR.cc/2019/Conference/Paper236/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper236/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper236/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper236/Authors|ICLR.cc/2019/Conference/Paper236/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper236/Reviewers", "ICLR.cc/2019/Conference/Paper236/Authors", "ICLR.cc/2019/Conference/Paper236/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621613867}}}, {"id": "H1ey7t1_6Q", "original": null, "number": 9, "cdate": 1542088982826, "ddate": null, "tcdate": 1542088982826, "tmdate": 1542088982826, "tddate": null, "forum": "SkxbDsR9Ym", "replyto": "SklgyeG5hX", "invitation": "ICLR.cc/2019/Conference/-/Paper236/Official_Comment", "content": {"title": "Author response: AnonReviewer3", "comment": "Q1:  To me, this paper sounds like a direct application of the method of Arora et al., 2016a to KGE. Therefore, this does look like a very obvious application, and it is not clear to me if this paper presents any new methods or if you have obtained any new insights. \n\nAns: We would like to thank the reviewer for the time and review. \n\nIt is true that we are extending the original Random Walk model proposed by Arora et al [2016a] to model relations. However, we do not agree that is a \u201cvery obvious application\u201d. Next, we detail the reasons for this.\n\nThe original random walk model was proposed for a co-occurrence graph, ignoring the relations between the entities. It is nontrivial as how to incorporate relational information into this model. We have both proposed a new relational version of the original random walk model and have proven that it can obtain state-of-the-art knowledge graph embeddings.\n\nQ2: The paper claims that all prior work use some sort of heuristics in the KGE task, and their approach is a generative account that might deal with this issue? But I personally found that by using a random walk and the exp function, you are also making some very strong assumptions that are similar to heuristics? How do you know it is exp function but not other function?\n\nAns: This is a very standard way to represent the potential function in a probabilistic graph. Moreover, as you can see from the Taylor expansion of exp, it contains all polynomials terms in it. In fact, prior work on kernel methods have shown that exponential kernels such as Radial Basis Functions (RBF) kernel can theoretically subsume all other types of kernel functions. Therefore, this is not a heuristic but a very general modelling assumption that does not assume anything about the properties of entities and their relations.\n\n Q3:  I am not sure what the purpose for the evaluation section is. You mention that this paper is not about state-of-the-art results, but if your theory really works, your scoring function should beat SOTA results. Overall, I have to say that I am very disappointed with this paper, because there are no new theoretical tools being introduced, and the authors seem to be applying Arora et al., 2016a from word embedding to KGE only. \n\nAns: At the initial submission of the paper, we did not have state-of-the-art results for KGE. Therefore, we did not claim this in the initial submission. However, we have obtained state-of-the-art results for FB15k237 and WN18RR datasets as shown in the updated version of the paper. Note that FB15k237 and WN18RR datasets were recently proposed by removing reverse relations that were easier to predict in the original versions of those two datasets. We have revised the paper with these results and have claimed as such. Therefore, this paper not only provides a theoretical analysis but also obtains state-of-the-art results on two modern benchmarks for KGE. \n\n"}, "signatures": ["ICLR.cc/2019/Conference/Paper236/Authors"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper236/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper236/Authors", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "RelWalk -- A Latent Variable Model Approach to Knowledge Graph Embedding", "abstract": "Knowledge Graph Embedding (KGE) is the task of jointly learning entity and relation embeddings for a given knowledge graph. Existing methods for learning KGEs can be seen as a two-stage process where (a) entities and relations in the knowledge graph are represented using some linear algebraic structures (embeddings), and (b) a scoring function is defined that evaluates the strength of a relation that holds between two entities using the corresponding relation and entity embeddings. Unfortunately, prior proposals for the scoring functions in the first step have been heuristically motivated, and it is unclear as to how the scoring functions in KGEs relate to the generation process of the underlying knowledge graph. To address this issue, we propose a generative account of the KGE learning task. Specifically, given a knowledge graph represented by a set of relational triples (h, R, t), where the semantic relation R holds between the two entities h (head) and t (tail), we extend the random walk model (Arora et al., 2016a) of word embeddings to KGE. We derive a theoretical relationship between the joint probability p(h, R, t) and the embeddings of h, R and t. Moreover, we show that marginal loss minimisation, a popular objective used by much prior work in KGE, follows naturally from the log-likelihood ratio maximisation under the probabilities estimated from the KGEs according to our theoretical relationship. We propose a learning objective motivated by the theoretical analysis to learn KGEs from a given knowledge graph. The KGEs learnt by our proposed method obtain state-of-the-art performance on FB15K237 and WN18RR benchmark datasets, providing empirical evidence in support of the theory.\n", "keywords": ["relation representations", "natural language processing", "theoretical analysis", "knowledge graphs"], "authorids": ["danushka@liverpool.ac.uk", "h.a.hakami@liverpool.ac.uk", "yyoshida@nii.ac.jp", "k_keniti@nii.ac.jp"], "authors": ["Danushka Bollegala", "Huda Hakami", "Yuichi Yoshida", "Ken-ichi Kawarabayashi"], "TL;DR": "We present a theoretically proven generative model of knowledge graph embedding. ", "pdf": "/pdf/d70821e9867c967f02ed7b2eb093b95ef3fa0e3d.pdf", "paperhash": "bollegala|relwalk_a_latent_variable_model_approach_to_knowledge_graph_embedding", "_bibtex": "@misc{\nbollegala2019relwalk,\ntitle={RelWalk -- A Latent Variable Model Approach to Knowledge Graph Embedding},\nauthor={Danushka Bollegala and Huda Hakami and Yuichi Yoshida and Ken-ichi Kawarabayashi},\nyear={2019},\nurl={https://openreview.net/forum?id=SkxbDsR9Ym},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper236/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621613867, "tddate": null, "super": null, "final": null, "reply": {"forum": "SkxbDsR9Ym", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper236/Authors", "ICLR.cc/2019/Conference/Paper236/Reviewers", "ICLR.cc/2019/Conference/Paper236/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper236/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper236/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper236/Authors|ICLR.cc/2019/Conference/Paper236/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper236/Reviewers", "ICLR.cc/2019/Conference/Paper236/Authors", "ICLR.cc/2019/Conference/Paper236/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621613867}}}, {"id": "rkxdq_JOT7", "original": null, "number": 8, "cdate": 1542088848000, "ddate": null, "tcdate": 1542088848000, "tmdate": 1542088848000, "tddate": null, "forum": "SkxbDsR9Ym", "replyto": "HyxKd25wp7", "invitation": "ICLR.cc/2019/Conference/-/Paper236/Official_Comment", "content": {"title": "Author response: AnnonReviewer2", "comment": "Q1: - Having only results on two flawed datasets (considering the inverse relations in them) makes it hard to evaluate the quality of the method. I suggest conducting the experiments on the FB15K-237 and WN18RR from [1] instead. \n\nAns: In the revised version we have conducted experiments using both FB15K-23k and WN18RR datasets and the proposed method (RelWalk) obtains the state-of-the-art performance on both datasets. \n\nQ2: - You only evaluate on MR and Hits@10, but it is standard to include metrics like MRR and Hits@1 and 3 also, since no metric is perfect for this task.\n\nAns: Given the limited availability of space, we had to select the evaluation measures that are more widely used for this task, which are MR and Hits@10. \n\nQ3:  Since the goal of the work is not providing a state of the art method, and focus on the theoretical understanding of their scoring function, it is of high importance to assess the characteristics of their embeddings and scoring function through designing other experiments. As a result, I suggest to study the geometric behavior of their embeddings and compare it to the other methods. Further, investigating the semantic purity of the embeddings by calculating the entropy of the type distribution of the entities, similar as [2], can shed more light on the significance of their method.\n\nAns: Thank you for the suggestion. As shown in the revised version, the proposed method is obtaining state-of-the-art results in addition to its theoretical contribution. Therefore, we would believe this is sufficient for an 8-page conference publication and would consider the suggested additional evaluations in a longer journal version."}, "signatures": ["ICLR.cc/2019/Conference/Paper236/Authors"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper236/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper236/Authors", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "RelWalk -- A Latent Variable Model Approach to Knowledge Graph Embedding", "abstract": "Knowledge Graph Embedding (KGE) is the task of jointly learning entity and relation embeddings for a given knowledge graph. Existing methods for learning KGEs can be seen as a two-stage process where (a) entities and relations in the knowledge graph are represented using some linear algebraic structures (embeddings), and (b) a scoring function is defined that evaluates the strength of a relation that holds between two entities using the corresponding relation and entity embeddings. Unfortunately, prior proposals for the scoring functions in the first step have been heuristically motivated, and it is unclear as to how the scoring functions in KGEs relate to the generation process of the underlying knowledge graph. To address this issue, we propose a generative account of the KGE learning task. Specifically, given a knowledge graph represented by a set of relational triples (h, R, t), where the semantic relation R holds between the two entities h (head) and t (tail), we extend the random walk model (Arora et al., 2016a) of word embeddings to KGE. We derive a theoretical relationship between the joint probability p(h, R, t) and the embeddings of h, R and t. Moreover, we show that marginal loss minimisation, a popular objective used by much prior work in KGE, follows naturally from the log-likelihood ratio maximisation under the probabilities estimated from the KGEs according to our theoretical relationship. We propose a learning objective motivated by the theoretical analysis to learn KGEs from a given knowledge graph. The KGEs learnt by our proposed method obtain state-of-the-art performance on FB15K237 and WN18RR benchmark datasets, providing empirical evidence in support of the theory.\n", "keywords": ["relation representations", "natural language processing", "theoretical analysis", "knowledge graphs"], "authorids": ["danushka@liverpool.ac.uk", "h.a.hakami@liverpool.ac.uk", "yyoshida@nii.ac.jp", "k_keniti@nii.ac.jp"], "authors": ["Danushka Bollegala", "Huda Hakami", "Yuichi Yoshida", "Ken-ichi Kawarabayashi"], "TL;DR": "We present a theoretically proven generative model of knowledge graph embedding. ", "pdf": "/pdf/d70821e9867c967f02ed7b2eb093b95ef3fa0e3d.pdf", "paperhash": "bollegala|relwalk_a_latent_variable_model_approach_to_knowledge_graph_embedding", "_bibtex": "@misc{\nbollegala2019relwalk,\ntitle={RelWalk -- A Latent Variable Model Approach to Knowledge Graph Embedding},\nauthor={Danushka Bollegala and Huda Hakami and Yuichi Yoshida and Ken-ichi Kawarabayashi},\nyear={2019},\nurl={https://openreview.net/forum?id=SkxbDsR9Ym},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper236/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621613867, "tddate": null, "super": null, "final": null, "reply": {"forum": "SkxbDsR9Ym", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper236/Authors", "ICLR.cc/2019/Conference/Paper236/Reviewers", "ICLR.cc/2019/Conference/Paper236/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper236/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper236/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper236/Authors|ICLR.cc/2019/Conference/Paper236/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper236/Reviewers", "ICLR.cc/2019/Conference/Paper236/Authors", "ICLR.cc/2019/Conference/Paper236/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621613867}}}, {"id": "SklgyeG5hX", "original": null, "number": 2, "cdate": 1541181400408, "ddate": null, "tcdate": 1541181400408, "tmdate": 1541534169583, "tddate": null, "forum": "SkxbDsR9Ym", "replyto": "SkxbDsR9Ym", "invitation": "ICLR.cc/2019/Conference/-/Paper236/Official_Review", "content": {"title": "An OK paper on theoretical understanding the KGE", "review": "In this paper, the author proposed a way to understand the knowledge graph embedding task. More specifically, the authors try to extend the random walk model (Arora et al., 2016a) of word embeddings to KGE.\n\nSome of my detailed comments and questions below.\n\n1. To me, this paper sounds like a direct application of the method of Arora et al., 2016a to KGE. Therefore, this does look like a very obvious application, and it is not clear to me if this paper presents any new methods or if you have obtained any new insights.\n\n2. The paper claims that all prior work use some sort of heuristics in the KGE task, and their approach is a generative account that might deal with this issue? But I personally found that by using random walk and the exp function, you are also making some very strong assumptions that are similar to heuristics? How do you know it is exp function but not other function? \n\n3. I am not sure what the purpose for the evaluation section is. You mention that this paper is not about state-of-the-art results, but if you theory really works, your scoring function should beat SOTA results. \n\nOverall, I have to say that I am very disappointed with this paper, because there are no new theoretical tools being introduced, and the authors seem to be applying Arora et al., 2016a from word embedding to KGE only. ", "rating": "5: Marginally below acceptance threshold", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}, "signatures": ["ICLR.cc/2019/Conference/Paper236/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "RelWalk -- A Latent Variable Model Approach to Knowledge Graph Embedding", "abstract": "Knowledge Graph Embedding (KGE) is the task of jointly learning entity and relation embeddings for a given knowledge graph. Existing methods for learning KGEs can be seen as a two-stage process where (a) entities and relations in the knowledge graph are represented using some linear algebraic structures (embeddings), and (b) a scoring function is defined that evaluates the strength of a relation that holds between two entities using the corresponding relation and entity embeddings. Unfortunately, prior proposals for the scoring functions in the first step have been heuristically motivated, and it is unclear as to how the scoring functions in KGEs relate to the generation process of the underlying knowledge graph. To address this issue, we propose a generative account of the KGE learning task. Specifically, given a knowledge graph represented by a set of relational triples (h, R, t), where the semantic relation R holds between the two entities h (head) and t (tail), we extend the random walk model (Arora et al., 2016a) of word embeddings to KGE. We derive a theoretical relationship between the joint probability p(h, R, t) and the embeddings of h, R and t. Moreover, we show that marginal loss minimisation, a popular objective used by much prior work in KGE, follows naturally from the log-likelihood ratio maximisation under the probabilities estimated from the KGEs according to our theoretical relationship. We propose a learning objective motivated by the theoretical analysis to learn KGEs from a given knowledge graph. The KGEs learnt by our proposed method obtain state-of-the-art performance on FB15K237 and WN18RR benchmark datasets, providing empirical evidence in support of the theory.\n", "keywords": ["relation representations", "natural language processing", "theoretical analysis", "knowledge graphs"], "authorids": ["danushka@liverpool.ac.uk", "h.a.hakami@liverpool.ac.uk", "yyoshida@nii.ac.jp", "k_keniti@nii.ac.jp"], "authors": ["Danushka Bollegala", "Huda Hakami", "Yuichi Yoshida", "Ken-ichi Kawarabayashi"], "TL;DR": "We present a theoretically proven generative model of knowledge graph embedding. ", "pdf": "/pdf/d70821e9867c967f02ed7b2eb093b95ef3fa0e3d.pdf", "paperhash": "bollegala|relwalk_a_latent_variable_model_approach_to_knowledge_graph_embedding", "_bibtex": "@misc{\nbollegala2019relwalk,\ntitle={RelWalk -- A Latent Variable Model Approach to Knowledge Graph Embedding},\nauthor={Danushka Bollegala and Huda Hakami and Yuichi Yoshida and Ken-ichi Kawarabayashi},\nyear={2019},\nurl={https://openreview.net/forum?id=SkxbDsR9Ym},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper236/Official_Review", "cdate": 1542234508022, "expdate": 1552335264000, "duedate": 1541196000000, "reply": {"forum": "SkxbDsR9Ym", "replyto": "SkxbDsR9Ym", "readers": {"description": "The users who will be allowed to read the reply content.", "values": ["everyone"]}, "nonreaders": {"values": []}, "signatures": {"description": "How your identity will be displayed with the above content.", "values-regex": "ICLR.cc/2019/Conference/Paper236/AnonReviewer[0-9]+"}, "writers": {"description": "Users that may modify this record.", "values": ["ICLR.cc/2019/Conference"]}, "content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "required": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}}, "multiReply": false, "tcdate": 1552335678992, "tmdate": 1552335678992, "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "invitees": ["ICLR.cc/2019/Conference/Paper236/Reviewers"], "noninvitees": [], "signatures": ["ICLR.cc/2019/Conference"]}}}, {"id": "r1eY4IjF2X", "original": null, "number": 1, "cdate": 1541154353284, "ddate": null, "tcdate": 1541154353284, "tmdate": 1541534169382, "tddate": null, "forum": "SkxbDsR9Ym", "replyto": "SkxbDsR9Ym", "invitation": "ICLR.cc/2019/Conference/-/Paper236/Official_Review", "content": {"title": "The paper \"RELWALK \u2013 A LATENT VARIABLE MODEL APPROACH TO KNOWLEDGE GRAPH EMBEDDING\" is about a generative knowledge graph embedding process and a theoretic motivation for a corresponding scoring function.", "review": "+ Theoretic explanation for the scoring function.\n+ (Promise for) Online provided source code.\n+ The paper is well-written.\n\n- The authors missed [1] which also introduces a generative model for knowledge graph embeddings. \n- The use of the datasets FB15k-237 and WN18RR instead of FB15k and WN18 (without inverse relations) would enable a better empirical evaluation. By using the flawed FB15k and WN18 datasets, the evaluation is biased towards the usage of inverse relations which should not exist in a link prediction evaluation dataset.\n- The authors are not mentioning and comparing to walk based approaches like node2vec [2], Deepwalk [3], and rdf2vec [4]. \n\n\nDue to the missing comparisons to the mentioned references above and the possible bias in the evaluation, I am leaning towards rejecting the paper.\n\n\nMinor comments:\n\n. Abbreviations like h for head are used before they are introduced.\n. \"The the\" -> \"The\"\n. \"triples are likely too be obvious examples\" -> \"triples are likely to be obvious examples\"\n\n\n[1] Xiao, Han, Minlie Huang, and Xiaoyan Zhu. \"TransG: A generative model for knowledge graph embedding.\" Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers). Vol. 1. 2016.\n\n[2] Grover, Aditya, and Jure Leskovec. \"node2vec: Scalable feature learning for networks.\" Proceedings of the 22nd ACM SIGKDD international conference on Knowledge discovery and data mining. ACM, 2016.\n\n[3]  Perozzi, Bryan, Rami Al-Rfou, and Steven Skiena. \"Deepwalk: Online learning of social representations.\" Proceedings of the 20th ACM SIGKDD international conference on Knowledge discovery and data mining. ACM, 2014.\n\n[4] Petar Ristoski, Jessica Rosati, Tommaso Di Noia, Renato De Leone, and Heiko Paulheim. \"RDF2Vec: RDF Graph Embeddings and Their Applications.\" SWJ http://www.semantic-web-journal.net/content/rdf2vec-rdf-graph-embeddings-and-their-applications-1", "rating": "4: Ok but not good enough - rejection", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["ICLR.cc/2019/Conference/Paper236/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "RelWalk -- A Latent Variable Model Approach to Knowledge Graph Embedding", "abstract": "Knowledge Graph Embedding (KGE) is the task of jointly learning entity and relation embeddings for a given knowledge graph. Existing methods for learning KGEs can be seen as a two-stage process where (a) entities and relations in the knowledge graph are represented using some linear algebraic structures (embeddings), and (b) a scoring function is defined that evaluates the strength of a relation that holds between two entities using the corresponding relation and entity embeddings. Unfortunately, prior proposals for the scoring functions in the first step have been heuristically motivated, and it is unclear as to how the scoring functions in KGEs relate to the generation process of the underlying knowledge graph. To address this issue, we propose a generative account of the KGE learning task. Specifically, given a knowledge graph represented by a set of relational triples (h, R, t), where the semantic relation R holds between the two entities h (head) and t (tail), we extend the random walk model (Arora et al., 2016a) of word embeddings to KGE. We derive a theoretical relationship between the joint probability p(h, R, t) and the embeddings of h, R and t. Moreover, we show that marginal loss minimisation, a popular objective used by much prior work in KGE, follows naturally from the log-likelihood ratio maximisation under the probabilities estimated from the KGEs according to our theoretical relationship. We propose a learning objective motivated by the theoretical analysis to learn KGEs from a given knowledge graph. The KGEs learnt by our proposed method obtain state-of-the-art performance on FB15K237 and WN18RR benchmark datasets, providing empirical evidence in support of the theory.\n", "keywords": ["relation representations", "natural language processing", "theoretical analysis", "knowledge graphs"], "authorids": ["danushka@liverpool.ac.uk", "h.a.hakami@liverpool.ac.uk", "yyoshida@nii.ac.jp", "k_keniti@nii.ac.jp"], "authors": ["Danushka Bollegala", "Huda Hakami", "Yuichi Yoshida", "Ken-ichi Kawarabayashi"], "TL;DR": "We present a theoretically proven generative model of knowledge graph embedding. ", "pdf": "/pdf/d70821e9867c967f02ed7b2eb093b95ef3fa0e3d.pdf", "paperhash": "bollegala|relwalk_a_latent_variable_model_approach_to_knowledge_graph_embedding", "_bibtex": "@misc{\nbollegala2019relwalk,\ntitle={RelWalk -- A Latent Variable Model Approach to Knowledge Graph Embedding},\nauthor={Danushka Bollegala and Huda Hakami and Yuichi Yoshida and Ken-ichi Kawarabayashi},\nyear={2019},\nurl={https://openreview.net/forum?id=SkxbDsR9Ym},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper236/Official_Review", "cdate": 1542234508022, "expdate": 1552335264000, "duedate": 1541196000000, "reply": {"forum": "SkxbDsR9Ym", "replyto": "SkxbDsR9Ym", "readers": {"description": "The users who will be allowed to read the reply content.", "values": ["everyone"]}, "nonreaders": {"values": []}, "signatures": {"description": "How your identity will be displayed with the above content.", "values-regex": "ICLR.cc/2019/Conference/Paper236/AnonReviewer[0-9]+"}, "writers": {"description": "Users that may modify this record.", "values": ["ICLR.cc/2019/Conference"]}, "content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "required": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}}, "multiReply": false, "tcdate": 1552335678992, "tmdate": 1552335678992, "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "invitees": ["ICLR.cc/2019/Conference/Paper236/Reviewers"], "noninvitees": [], "signatures": ["ICLR.cc/2019/Conference"]}}}, {"id": "rkxAisFCcm", "original": null, "number": 5, "cdate": 1539378086153, "ddate": null, "tcdate": 1539378086153, "tmdate": 1539378086153, "tddate": null, "forum": "SkxbDsR9Ym", "replyto": "BJgu1f6cqQ", "invitation": "ICLR.cc/2019/Conference/-/Paper236/Official_Comment", "content": {"title": "Re: Spherical Gaussian", "comment": ">If, as you said, \\hat{h} is distributed as the multivariate Gaussian with zero mean and unit covariance matrix, ||\\hat{h}||_2 is not guaranteed to be 1 (because \\hat{h} \\in R^D), whereas in the paper \\hat{h} is a unit vector.\n\nTrue. But you could always scale the sampled vector such that it has unit length."}, "signatures": ["ICLR.cc/2019/Conference/Paper236/Authors"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper236/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper236/Authors", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "RelWalk -- A Latent Variable Model Approach to Knowledge Graph Embedding", "abstract": "Knowledge Graph Embedding (KGE) is the task of jointly learning entity and relation embeddings for a given knowledge graph. Existing methods for learning KGEs can be seen as a two-stage process where (a) entities and relations in the knowledge graph are represented using some linear algebraic structures (embeddings), and (b) a scoring function is defined that evaluates the strength of a relation that holds between two entities using the corresponding relation and entity embeddings. Unfortunately, prior proposals for the scoring functions in the first step have been heuristically motivated, and it is unclear as to how the scoring functions in KGEs relate to the generation process of the underlying knowledge graph. To address this issue, we propose a generative account of the KGE learning task. Specifically, given a knowledge graph represented by a set of relational triples (h, R, t), where the semantic relation R holds between the two entities h (head) and t (tail), we extend the random walk model (Arora et al., 2016a) of word embeddings to KGE. We derive a theoretical relationship between the joint probability p(h, R, t) and the embeddings of h, R and t. Moreover, we show that marginal loss minimisation, a popular objective used by much prior work in KGE, follows naturally from the log-likelihood ratio maximisation under the probabilities estimated from the KGEs according to our theoretical relationship. We propose a learning objective motivated by the theoretical analysis to learn KGEs from a given knowledge graph. The KGEs learnt by our proposed method obtain state-of-the-art performance on FB15K237 and WN18RR benchmark datasets, providing empirical evidence in support of the theory.\n", "keywords": ["relation representations", "natural language processing", "theoretical analysis", "knowledge graphs"], "authorids": ["danushka@liverpool.ac.uk", "h.a.hakami@liverpool.ac.uk", "yyoshida@nii.ac.jp", "k_keniti@nii.ac.jp"], "authors": ["Danushka Bollegala", "Huda Hakami", "Yuichi Yoshida", "Ken-ichi Kawarabayashi"], "TL;DR": "We present a theoretically proven generative model of knowledge graph embedding. ", "pdf": "/pdf/d70821e9867c967f02ed7b2eb093b95ef3fa0e3d.pdf", "paperhash": "bollegala|relwalk_a_latent_variable_model_approach_to_knowledge_graph_embedding", "_bibtex": "@misc{\nbollegala2019relwalk,\ntitle={RelWalk -- A Latent Variable Model Approach to Knowledge Graph Embedding},\nauthor={Danushka Bollegala and Huda Hakami and Yuichi Yoshida and Ken-ichi Kawarabayashi},\nyear={2019},\nurl={https://openreview.net/forum?id=SkxbDsR9Ym},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper236/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621613867, "tddate": null, "super": null, "final": null, "reply": {"forum": "SkxbDsR9Ym", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper236/Authors", "ICLR.cc/2019/Conference/Paper236/Reviewers", "ICLR.cc/2019/Conference/Paper236/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper236/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper236/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper236/Authors|ICLR.cc/2019/Conference/Paper236/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper236/Reviewers", "ICLR.cc/2019/Conference/Paper236/Authors", "ICLR.cc/2019/Conference/Paper236/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621613867}}}, {"id": "BJgu1f6cqQ", "original": null, "number": 5, "cdate": 1539129824162, "ddate": null, "tcdate": 1539129824162, "tmdate": 1539129868220, "tddate": null, "forum": "SkxbDsR9Ym", "replyto": "r1eH1XsOc7", "invitation": "ICLR.cc/2019/Conference/-/Paper236/Public_Comment", "content": {"comment": "I think you still don't understand the question.\n\nIf, as you said, \\hat{h} is distributed as the multivariate Gaussian with zero mean and unit covariance matrix, ||\\hat{h}||_2 is not guaranteed to be 1 (because \\hat{h} \\in R^D), whereas in the paper \\hat{h} is a unit vector.\n\nThe unit covariance matrix does not make the multivariate Gaussian distributed on a unit sphere. \nIn the other words, \\hat{h} = (1, 1, 1) can be drawn from MN(0, I) where ||(1,1,1)||_2 = \\sqrt{3} != 1. \n", "title": "Clarification"}, "signatures": ["(anonymous)"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper236/Reviewers/Unsubmitted"], "writers": ["(anonymous)", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "RelWalk -- A Latent Variable Model Approach to Knowledge Graph Embedding", "abstract": "Knowledge Graph Embedding (KGE) is the task of jointly learning entity and relation embeddings for a given knowledge graph. Existing methods for learning KGEs can be seen as a two-stage process where (a) entities and relations in the knowledge graph are represented using some linear algebraic structures (embeddings), and (b) a scoring function is defined that evaluates the strength of a relation that holds between two entities using the corresponding relation and entity embeddings. Unfortunately, prior proposals for the scoring functions in the first step have been heuristically motivated, and it is unclear as to how the scoring functions in KGEs relate to the generation process of the underlying knowledge graph. To address this issue, we propose a generative account of the KGE learning task. Specifically, given a knowledge graph represented by a set of relational triples (h, R, t), where the semantic relation R holds between the two entities h (head) and t (tail), we extend the random walk model (Arora et al., 2016a) of word embeddings to KGE. We derive a theoretical relationship between the joint probability p(h, R, t) and the embeddings of h, R and t. Moreover, we show that marginal loss minimisation, a popular objective used by much prior work in KGE, follows naturally from the log-likelihood ratio maximisation under the probabilities estimated from the KGEs according to our theoretical relationship. We propose a learning objective motivated by the theoretical analysis to learn KGEs from a given knowledge graph. The KGEs learnt by our proposed method obtain state-of-the-art performance on FB15K237 and WN18RR benchmark datasets, providing empirical evidence in support of the theory.\n", "keywords": ["relation representations", "natural language processing", "theoretical analysis", "knowledge graphs"], "authorids": ["danushka@liverpool.ac.uk", "h.a.hakami@liverpool.ac.uk", "yyoshida@nii.ac.jp", "k_keniti@nii.ac.jp"], "authors": ["Danushka Bollegala", "Huda Hakami", "Yuichi Yoshida", "Ken-ichi Kawarabayashi"], "TL;DR": "We present a theoretically proven generative model of knowledge graph embedding. ", "pdf": "/pdf/d70821e9867c967f02ed7b2eb093b95ef3fa0e3d.pdf", "paperhash": "bollegala|relwalk_a_latent_variable_model_approach_to_knowledge_graph_embedding", "_bibtex": "@misc{\nbollegala2019relwalk,\ntitle={RelWalk -- A Latent Variable Model Approach to Knowledge Graph Embedding},\nauthor={Danushka Bollegala and Huda Hakami and Yuichi Yoshida and Ken-ichi Kawarabayashi},\nyear={2019},\nurl={https://openreview.net/forum?id=SkxbDsR9Ym},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper236/Public_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1542311887393, "tddate": null, "super": null, "final": null, "reply": {"signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed."}, "nonreaders": {"values": []}, "forum": "SkxbDsR9Ym", "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper236/Authors", "ICLR.cc/2019/Conference/Paper236/Reviewers", "ICLR.cc/2019/Conference/Paper236/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "replyto": null, "content": {"comment": {"value-regex": "[\\S\\s]{1,5000}", "required": true, "order": 1, "description": "Your comment or reply (max 5000 characters)."}, "title": {"value-regex": ".{1,500}", "required": true, "order": 0, "description": "Brief summary of your comment."}}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["~"], "noninvitees": ["ICLR.cc/2019/Conference/Paper236/Authors", "ICLR.cc/2019/Conference/Paper236/Reviewers", "ICLR.cc/2019/Conference/Paper236/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1542311887393}}}, {"id": "r1eH1XsOc7", "original": null, "number": 4, "cdate": 1538990812560, "ddate": null, "tcdate": 1538990812560, "tmdate": 1539002701192, "tddate": null, "forum": "SkxbDsR9Ym", "replyto": "HJgNw8ZOqm", "invitation": "ICLR.cc/2019/Conference/-/Paper236/Official_Comment", "content": {"title": "Clarification", "comment": "Thank you for spotting the typo.  $\\hat{h}$ is in the Spherical Gaussian with unit covariance matrix $\\mat{I} \\in \\R^{d \\times d}$ and not $s^2\\mat{I} \\in \\R^{d \\times d}$. \n\n> I guess you have confused C and \\hat{h} where the former is distributed on a unit sphere whereas the latter is not.\n\nNo. They are both on the unit sphere. c is on the unit sphere from the assumption, whereas h is represented in the polar coordinate form where the direction is given by the unit vector \\hat{h} and the scale is given by s_h. This transformation can be done for any vector h.\n"}, "signatures": ["ICLR.cc/2019/Conference/Paper236/Authors"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper236/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper236/Authors", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "RelWalk -- A Latent Variable Model Approach to Knowledge Graph Embedding", "abstract": "Knowledge Graph Embedding (KGE) is the task of jointly learning entity and relation embeddings for a given knowledge graph. Existing methods for learning KGEs can be seen as a two-stage process where (a) entities and relations in the knowledge graph are represented using some linear algebraic structures (embeddings), and (b) a scoring function is defined that evaluates the strength of a relation that holds between two entities using the corresponding relation and entity embeddings. Unfortunately, prior proposals for the scoring functions in the first step have been heuristically motivated, and it is unclear as to how the scoring functions in KGEs relate to the generation process of the underlying knowledge graph. To address this issue, we propose a generative account of the KGE learning task. Specifically, given a knowledge graph represented by a set of relational triples (h, R, t), where the semantic relation R holds between the two entities h (head) and t (tail), we extend the random walk model (Arora et al., 2016a) of word embeddings to KGE. We derive a theoretical relationship between the joint probability p(h, R, t) and the embeddings of h, R and t. Moreover, we show that marginal loss minimisation, a popular objective used by much prior work in KGE, follows naturally from the log-likelihood ratio maximisation under the probabilities estimated from the KGEs according to our theoretical relationship. We propose a learning objective motivated by the theoretical analysis to learn KGEs from a given knowledge graph. The KGEs learnt by our proposed method obtain state-of-the-art performance on FB15K237 and WN18RR benchmark datasets, providing empirical evidence in support of the theory.\n", "keywords": ["relation representations", "natural language processing", "theoretical analysis", "knowledge graphs"], "authorids": ["danushka@liverpool.ac.uk", "h.a.hakami@liverpool.ac.uk", "yyoshida@nii.ac.jp", "k_keniti@nii.ac.jp"], "authors": ["Danushka Bollegala", "Huda Hakami", "Yuichi Yoshida", "Ken-ichi Kawarabayashi"], "TL;DR": "We present a theoretically proven generative model of knowledge graph embedding. ", "pdf": "/pdf/d70821e9867c967f02ed7b2eb093b95ef3fa0e3d.pdf", "paperhash": "bollegala|relwalk_a_latent_variable_model_approach_to_knowledge_graph_embedding", "_bibtex": "@misc{\nbollegala2019relwalk,\ntitle={RelWalk -- A Latent Variable Model Approach to Knowledge Graph Embedding},\nauthor={Danushka Bollegala and Huda Hakami and Yuichi Yoshida and Ken-ichi Kawarabayashi},\nyear={2019},\nurl={https://openreview.net/forum?id=SkxbDsR9Ym},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper236/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621613867, "tddate": null, "super": null, "final": null, "reply": {"forum": "SkxbDsR9Ym", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper236/Authors", "ICLR.cc/2019/Conference/Paper236/Reviewers", "ICLR.cc/2019/Conference/Paper236/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper236/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper236/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper236/Authors|ICLR.cc/2019/Conference/Paper236/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper236/Reviewers", "ICLR.cc/2019/Conference/Paper236/Authors", "ICLR.cc/2019/Conference/Paper236/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621613867}}}, {"id": "HJgNw8ZOqm", "original": null, "number": 4, "cdate": 1538950748501, "ddate": null, "tcdate": 1538950748501, "tmdate": 1538950830836, "tddate": null, "forum": "SkxbDsR9Ym", "replyto": "HJxptPnIqX", "invitation": "ICLR.cc/2019/Conference/-/Paper236/Public_Comment", "content": {"comment": "In that case the ||\\hat{h} ||_1 should not a unit vector (described under equation 7). The support should be R^D. Right? I guess you have confused C and \\hat{h} where the former is distributed on a unit sphere whereas the latter is not. Now I understand it's just a typo, but it makes me confused while reading the proof of lemma 1. Thanks.", "title": "Re: Spherical Gaussian distribution "}, "signatures": ["(anonymous)"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper236/Reviewers/Unsubmitted"], "writers": ["(anonymous)", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "RelWalk -- A Latent Variable Model Approach to Knowledge Graph Embedding", "abstract": "Knowledge Graph Embedding (KGE) is the task of jointly learning entity and relation embeddings for a given knowledge graph. Existing methods for learning KGEs can be seen as a two-stage process where (a) entities and relations in the knowledge graph are represented using some linear algebraic structures (embeddings), and (b) a scoring function is defined that evaluates the strength of a relation that holds between two entities using the corresponding relation and entity embeddings. Unfortunately, prior proposals for the scoring functions in the first step have been heuristically motivated, and it is unclear as to how the scoring functions in KGEs relate to the generation process of the underlying knowledge graph. To address this issue, we propose a generative account of the KGE learning task. Specifically, given a knowledge graph represented by a set of relational triples (h, R, t), where the semantic relation R holds between the two entities h (head) and t (tail), we extend the random walk model (Arora et al., 2016a) of word embeddings to KGE. We derive a theoretical relationship between the joint probability p(h, R, t) and the embeddings of h, R and t. Moreover, we show that marginal loss minimisation, a popular objective used by much prior work in KGE, follows naturally from the log-likelihood ratio maximisation under the probabilities estimated from the KGEs according to our theoretical relationship. We propose a learning objective motivated by the theoretical analysis to learn KGEs from a given knowledge graph. The KGEs learnt by our proposed method obtain state-of-the-art performance on FB15K237 and WN18RR benchmark datasets, providing empirical evidence in support of the theory.\n", "keywords": ["relation representations", "natural language processing", "theoretical analysis", "knowledge graphs"], "authorids": ["danushka@liverpool.ac.uk", "h.a.hakami@liverpool.ac.uk", "yyoshida@nii.ac.jp", "k_keniti@nii.ac.jp"], "authors": ["Danushka Bollegala", "Huda Hakami", "Yuichi Yoshida", "Ken-ichi Kawarabayashi"], "TL;DR": "We present a theoretically proven generative model of knowledge graph embedding. ", "pdf": "/pdf/d70821e9867c967f02ed7b2eb093b95ef3fa0e3d.pdf", "paperhash": "bollegala|relwalk_a_latent_variable_model_approach_to_knowledge_graph_embedding", "_bibtex": "@misc{\nbollegala2019relwalk,\ntitle={RelWalk -- A Latent Variable Model Approach to Knowledge Graph Embedding},\nauthor={Danushka Bollegala and Huda Hakami and Yuichi Yoshida and Ken-ichi Kawarabayashi},\nyear={2019},\nurl={https://openreview.net/forum?id=SkxbDsR9Ym},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper236/Public_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1542311887393, "tddate": null, "super": null, "final": null, "reply": {"signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed."}, "nonreaders": {"values": []}, "forum": "SkxbDsR9Ym", "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper236/Authors", "ICLR.cc/2019/Conference/Paper236/Reviewers", "ICLR.cc/2019/Conference/Paper236/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "replyto": null, "content": {"comment": {"value-regex": "[\\S\\s]{1,5000}", "required": true, "order": 1, "description": "Your comment or reply (max 5000 characters)."}, "title": {"value-regex": ".{1,500}", "required": true, "order": 0, "description": "Brief summary of your comment."}}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["~"], "noninvitees": ["ICLR.cc/2019/Conference/Paper236/Authors", "ICLR.cc/2019/Conference/Paper236/Reviewers", "ICLR.cc/2019/Conference/Paper236/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1542311887393}}}, {"id": "HJxptPnIqX", "original": null, "number": 3, "cdate": 1538865028965, "ddate": null, "tcdate": 1538865028965, "tmdate": 1538865028965, "tddate": null, "forum": "SkxbDsR9Ym", "replyto": "rkl-f_f757", "invitation": "ICLR.cc/2019/Conference/-/Paper236/Official_Comment", "content": {"title": "Re: Spherical Gaussian distribution ", "comment": "Thank you for your question.\n\nIt is the latter. Specifically, we consider a multivariate Gaussian with Identity covariance. A spherical distribution, in general, is a one with equal variances in each dimension and without any cross-correlations. Hope this clarifies your concern."}, "signatures": ["ICLR.cc/2019/Conference/Paper236/Authors"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper236/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper236/Authors", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "RelWalk -- A Latent Variable Model Approach to Knowledge Graph Embedding", "abstract": "Knowledge Graph Embedding (KGE) is the task of jointly learning entity and relation embeddings for a given knowledge graph. Existing methods for learning KGEs can be seen as a two-stage process where (a) entities and relations in the knowledge graph are represented using some linear algebraic structures (embeddings), and (b) a scoring function is defined that evaluates the strength of a relation that holds between two entities using the corresponding relation and entity embeddings. Unfortunately, prior proposals for the scoring functions in the first step have been heuristically motivated, and it is unclear as to how the scoring functions in KGEs relate to the generation process of the underlying knowledge graph. To address this issue, we propose a generative account of the KGE learning task. Specifically, given a knowledge graph represented by a set of relational triples (h, R, t), where the semantic relation R holds between the two entities h (head) and t (tail), we extend the random walk model (Arora et al., 2016a) of word embeddings to KGE. We derive a theoretical relationship between the joint probability p(h, R, t) and the embeddings of h, R and t. Moreover, we show that marginal loss minimisation, a popular objective used by much prior work in KGE, follows naturally from the log-likelihood ratio maximisation under the probabilities estimated from the KGEs according to our theoretical relationship. We propose a learning objective motivated by the theoretical analysis to learn KGEs from a given knowledge graph. The KGEs learnt by our proposed method obtain state-of-the-art performance on FB15K237 and WN18RR benchmark datasets, providing empirical evidence in support of the theory.\n", "keywords": ["relation representations", "natural language processing", "theoretical analysis", "knowledge graphs"], "authorids": ["danushka@liverpool.ac.uk", "h.a.hakami@liverpool.ac.uk", "yyoshida@nii.ac.jp", "k_keniti@nii.ac.jp"], "authors": ["Danushka Bollegala", "Huda Hakami", "Yuichi Yoshida", "Ken-ichi Kawarabayashi"], "TL;DR": "We present a theoretically proven generative model of knowledge graph embedding. ", "pdf": "/pdf/d70821e9867c967f02ed7b2eb093b95ef3fa0e3d.pdf", "paperhash": "bollegala|relwalk_a_latent_variable_model_approach_to_knowledge_graph_embedding", "_bibtex": "@misc{\nbollegala2019relwalk,\ntitle={RelWalk -- A Latent Variable Model Approach to Knowledge Graph Embedding},\nauthor={Danushka Bollegala and Huda Hakami and Yuichi Yoshida and Ken-ichi Kawarabayashi},\nyear={2019},\nurl={https://openreview.net/forum?id=SkxbDsR9Ym},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper236/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621613867, "tddate": null, "super": null, "final": null, "reply": {"forum": "SkxbDsR9Ym", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper236/Authors", "ICLR.cc/2019/Conference/Paper236/Reviewers", "ICLR.cc/2019/Conference/Paper236/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper236/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper236/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper236/Authors|ICLR.cc/2019/Conference/Paper236/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper236/Reviewers", "ICLR.cc/2019/Conference/Paper236/Authors", "ICLR.cc/2019/Conference/Paper236/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621613867}}}, {"id": "rkl-f_f757", "original": null, "number": 3, "cdate": 1538627592561, "ddate": null, "tcdate": 1538627592561, "tmdate": 1538635769459, "tddate": null, "forum": "SkxbDsR9Ym", "replyto": "SkxbDsR9Ym", "invitation": "ICLR.cc/2019/Conference/-/Paper236/Public_Comment", "content": {"comment": "Hello, \n\nThanks for the nice paper.\nCould you provide the definition of spherical Gaussian distribution? I thought that it is a distribution on l_2 ball since the random variable has a unit norm, but the description saying it has zero means and diagonal covariance matrix makes me confused. since it is somewhat different from the usual description here: https://mynameismjp.wordpress.com/2016/10/09/sg-series-part-2-spherical-gaussians-101/\n\nOr is that the multivariate Gaussian where each dimension is independent to each other while having the same variance? if then, did you normalize the random vector to make a unit vector? In this case, is it still normally distributed? it should be uniformly distributed on the unit ball.\n\nThanks in advance!", "title": "Spherical Gaussian distribution"}, "signatures": ["(anonymous)"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper236/Reviewers/Unsubmitted"], "writers": ["(anonymous)", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "RelWalk -- A Latent Variable Model Approach to Knowledge Graph Embedding", "abstract": "Knowledge Graph Embedding (KGE) is the task of jointly learning entity and relation embeddings for a given knowledge graph. Existing methods for learning KGEs can be seen as a two-stage process where (a) entities and relations in the knowledge graph are represented using some linear algebraic structures (embeddings), and (b) a scoring function is defined that evaluates the strength of a relation that holds between two entities using the corresponding relation and entity embeddings. Unfortunately, prior proposals for the scoring functions in the first step have been heuristically motivated, and it is unclear as to how the scoring functions in KGEs relate to the generation process of the underlying knowledge graph. To address this issue, we propose a generative account of the KGE learning task. Specifically, given a knowledge graph represented by a set of relational triples (h, R, t), where the semantic relation R holds between the two entities h (head) and t (tail), we extend the random walk model (Arora et al., 2016a) of word embeddings to KGE. We derive a theoretical relationship between the joint probability p(h, R, t) and the embeddings of h, R and t. Moreover, we show that marginal loss minimisation, a popular objective used by much prior work in KGE, follows naturally from the log-likelihood ratio maximisation under the probabilities estimated from the KGEs according to our theoretical relationship. We propose a learning objective motivated by the theoretical analysis to learn KGEs from a given knowledge graph. The KGEs learnt by our proposed method obtain state-of-the-art performance on FB15K237 and WN18RR benchmark datasets, providing empirical evidence in support of the theory.\n", "keywords": ["relation representations", "natural language processing", "theoretical analysis", "knowledge graphs"], "authorids": ["danushka@liverpool.ac.uk", "h.a.hakami@liverpool.ac.uk", "yyoshida@nii.ac.jp", "k_keniti@nii.ac.jp"], "authors": ["Danushka Bollegala", "Huda Hakami", "Yuichi Yoshida", "Ken-ichi Kawarabayashi"], "TL;DR": "We present a theoretically proven generative model of knowledge graph embedding. ", "pdf": "/pdf/d70821e9867c967f02ed7b2eb093b95ef3fa0e3d.pdf", "paperhash": "bollegala|relwalk_a_latent_variable_model_approach_to_knowledge_graph_embedding", "_bibtex": "@misc{\nbollegala2019relwalk,\ntitle={RelWalk -- A Latent Variable Model Approach to Knowledge Graph Embedding},\nauthor={Danushka Bollegala and Huda Hakami and Yuichi Yoshida and Ken-ichi Kawarabayashi},\nyear={2019},\nurl={https://openreview.net/forum?id=SkxbDsR9Ym},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper236/Public_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1542311887393, "tddate": null, "super": null, "final": null, "reply": {"signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed."}, "nonreaders": {"values": []}, "forum": "SkxbDsR9Ym", "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper236/Authors", "ICLR.cc/2019/Conference/Paper236/Reviewers", "ICLR.cc/2019/Conference/Paper236/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "replyto": null, "content": {"comment": {"value-regex": "[\\S\\s]{1,5000}", "required": true, "order": 1, "description": "Your comment or reply (max 5000 characters)."}, "title": {"value-regex": ".{1,500}", "required": true, "order": 0, "description": "Brief summary of your comment."}}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["~"], "noninvitees": ["ICLR.cc/2019/Conference/Paper236/Authors", "ICLR.cc/2019/Conference/Paper236/Reviewers", "ICLR.cc/2019/Conference/Paper236/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1542311887393}}}, {"id": "rygUojWAKQ", "original": null, "number": 2, "cdate": 1538296733828, "ddate": null, "tcdate": 1538296733828, "tmdate": 1538297706375, "tddate": null, "forum": "SkxbDsR9Ym", "replyto": "HJlffFoTFX", "invitation": "ICLR.cc/2019/Conference/-/Paper236/Official_Comment", "content": {"title": "Re Re: not mention recent results", "comment": "Thank you again for the comments. Much appreciated. We have added results on WN18RR, which shows that the proposed method (RelWalk) is doing well on this dataset as well. We have also added TransG to the evaluations on Link Prediction and discussed briefly in the related work section.\n\nsee the version here:  https://www.dropbox.com/s/x3kixodqays7nwi/RelWalk-ICLR.pdf?dl=0\n\nWe will reflect these additional details during the rebuttal stage.\n\nHowever, as stated in the previous response and also in the paper, the main contributions in the paper is the theoretical extension of the word embedding model of to KGE.\n\n\"More importantly, you did an important heuristic assumption: \"...\nNo we DO NOT make this assumption at all. The third sentence in Sec 3 explicitly states that we assume relation to be asymmetric in general. Asymmetry is a general assumption and the model can capture symmetry as a special case. You can see this from the scoring function we derive as well. Unless otherwise, R_1 and R_2 are equal  (for the symmetric case) p(h,t | R) and p(t,h | R) will not be equal.\n\n"}, "signatures": ["ICLR.cc/2019/Conference/Paper236/Authors"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper236/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper236/Authors", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "RelWalk -- A Latent Variable Model Approach to Knowledge Graph Embedding", "abstract": "Knowledge Graph Embedding (KGE) is the task of jointly learning entity and relation embeddings for a given knowledge graph. Existing methods for learning KGEs can be seen as a two-stage process where (a) entities and relations in the knowledge graph are represented using some linear algebraic structures (embeddings), and (b) a scoring function is defined that evaluates the strength of a relation that holds between two entities using the corresponding relation and entity embeddings. Unfortunately, prior proposals for the scoring functions in the first step have been heuristically motivated, and it is unclear as to how the scoring functions in KGEs relate to the generation process of the underlying knowledge graph. To address this issue, we propose a generative account of the KGE learning task. Specifically, given a knowledge graph represented by a set of relational triples (h, R, t), where the semantic relation R holds between the two entities h (head) and t (tail), we extend the random walk model (Arora et al., 2016a) of word embeddings to KGE. We derive a theoretical relationship between the joint probability p(h, R, t) and the embeddings of h, R and t. Moreover, we show that marginal loss minimisation, a popular objective used by much prior work in KGE, follows naturally from the log-likelihood ratio maximisation under the probabilities estimated from the KGEs according to our theoretical relationship. We propose a learning objective motivated by the theoretical analysis to learn KGEs from a given knowledge graph. The KGEs learnt by our proposed method obtain state-of-the-art performance on FB15K237 and WN18RR benchmark datasets, providing empirical evidence in support of the theory.\n", "keywords": ["relation representations", "natural language processing", "theoretical analysis", "knowledge graphs"], "authorids": ["danushka@liverpool.ac.uk", "h.a.hakami@liverpool.ac.uk", "yyoshida@nii.ac.jp", "k_keniti@nii.ac.jp"], "authors": ["Danushka Bollegala", "Huda Hakami", "Yuichi Yoshida", "Ken-ichi Kawarabayashi"], "TL;DR": "We present a theoretically proven generative model of knowledge graph embedding. ", "pdf": "/pdf/d70821e9867c967f02ed7b2eb093b95ef3fa0e3d.pdf", "paperhash": "bollegala|relwalk_a_latent_variable_model_approach_to_knowledge_graph_embedding", "_bibtex": "@misc{\nbollegala2019relwalk,\ntitle={RelWalk -- A Latent Variable Model Approach to Knowledge Graph Embedding},\nauthor={Danushka Bollegala and Huda Hakami and Yuichi Yoshida and Ken-ichi Kawarabayashi},\nyear={2019},\nurl={https://openreview.net/forum?id=SkxbDsR9Ym},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper236/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621613867, "tddate": null, "super": null, "final": null, "reply": {"forum": "SkxbDsR9Ym", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper236/Authors", "ICLR.cc/2019/Conference/Paper236/Reviewers", "ICLR.cc/2019/Conference/Paper236/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper236/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper236/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper236/Authors|ICLR.cc/2019/Conference/Paper236/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper236/Reviewers", "ICLR.cc/2019/Conference/Paper236/Authors", "ICLR.cc/2019/Conference/Paper236/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621613867}}}, {"id": "HJlffFoTFX", "original": null, "number": 2, "cdate": 1538271497584, "ddate": null, "tcdate": 1538271497584, "tmdate": 1538272843646, "tddate": null, "forum": "SkxbDsR9Ym", "replyto": "r1l8S-KhY7", "invitation": "ICLR.cc/2019/Conference/-/Paper236/Public_Comment", "content": {"comment": "You had one sentence about Ding et al. (2018) in related work section and ignored most works in 2017 and 2018. You did not motivate well how we should need the generative process of a knowledge graph. You can see [1] that you did not cite.\n\nMore importantly, you did an important heuristic assumption: relations are asymmetric in general, this may be not true in real-world datasets. For example, you did experiments on WN18 (WN11) and FB15 (FB11) consisting of many reversible relations. That's reason why you were not among SOTA results (results of ComplexE and NTN as you mentioned were not SOTA since 2017). I would suggest you do experiments on WN18RR and FB15k-237 as mentioned in [2].\n\n[1] TransG : A Generative Model for Knowledge Graph Embedding. ACL 2016.\n[2] Convolutional 2D Knowledge Graph Embeddings. AAAI 2018.", "title": "Re: not mention recent results"}, "signatures": ["(anonymous)"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper236/Reviewers/Unsubmitted"], "writers": ["(anonymous)", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "RelWalk -- A Latent Variable Model Approach to Knowledge Graph Embedding", "abstract": "Knowledge Graph Embedding (KGE) is the task of jointly learning entity and relation embeddings for a given knowledge graph. Existing methods for learning KGEs can be seen as a two-stage process where (a) entities and relations in the knowledge graph are represented using some linear algebraic structures (embeddings), and (b) a scoring function is defined that evaluates the strength of a relation that holds between two entities using the corresponding relation and entity embeddings. Unfortunately, prior proposals for the scoring functions in the first step have been heuristically motivated, and it is unclear as to how the scoring functions in KGEs relate to the generation process of the underlying knowledge graph. To address this issue, we propose a generative account of the KGE learning task. Specifically, given a knowledge graph represented by a set of relational triples (h, R, t), where the semantic relation R holds between the two entities h (head) and t (tail), we extend the random walk model (Arora et al., 2016a) of word embeddings to KGE. We derive a theoretical relationship between the joint probability p(h, R, t) and the embeddings of h, R and t. Moreover, we show that marginal loss minimisation, a popular objective used by much prior work in KGE, follows naturally from the log-likelihood ratio maximisation under the probabilities estimated from the KGEs according to our theoretical relationship. We propose a learning objective motivated by the theoretical analysis to learn KGEs from a given knowledge graph. The KGEs learnt by our proposed method obtain state-of-the-art performance on FB15K237 and WN18RR benchmark datasets, providing empirical evidence in support of the theory.\n", "keywords": ["relation representations", "natural language processing", "theoretical analysis", "knowledge graphs"], "authorids": ["danushka@liverpool.ac.uk", "h.a.hakami@liverpool.ac.uk", "yyoshida@nii.ac.jp", "k_keniti@nii.ac.jp"], "authors": ["Danushka Bollegala", "Huda Hakami", "Yuichi Yoshida", "Ken-ichi Kawarabayashi"], "TL;DR": "We present a theoretically proven generative model of knowledge graph embedding. ", "pdf": "/pdf/d70821e9867c967f02ed7b2eb093b95ef3fa0e3d.pdf", "paperhash": "bollegala|relwalk_a_latent_variable_model_approach_to_knowledge_graph_embedding", "_bibtex": "@misc{\nbollegala2019relwalk,\ntitle={RelWalk -- A Latent Variable Model Approach to Knowledge Graph Embedding},\nauthor={Danushka Bollegala and Huda Hakami and Yuichi Yoshida and Ken-ichi Kawarabayashi},\nyear={2019},\nurl={https://openreview.net/forum?id=SkxbDsR9Ym},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper236/Public_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1542311887393, "tddate": null, "super": null, "final": null, "reply": {"signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed."}, "nonreaders": {"values": []}, "forum": "SkxbDsR9Ym", "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper236/Authors", "ICLR.cc/2019/Conference/Paper236/Reviewers", "ICLR.cc/2019/Conference/Paper236/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "replyto": null, "content": {"comment": {"value-regex": "[\\S\\s]{1,5000}", "required": true, "order": 1, "description": "Your comment or reply (max 5000 characters)."}, "title": {"value-regex": ".{1,500}", "required": true, "order": 0, "description": "Brief summary of your comment."}}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["~"], "noninvitees": ["ICLR.cc/2019/Conference/Paper236/Authors", "ICLR.cc/2019/Conference/Paper236/Reviewers", "ICLR.cc/2019/Conference/Paper236/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1542311887393}}}, {"id": "r1l8S-KhY7", "original": null, "number": 1, "cdate": 1538195774475, "ddate": null, "tcdate": 1538195774475, "tmdate": 1538195774475, "tddate": null, "forum": "SkxbDsR9Ym", "replyto": "r1ecOjvhFQ", "invitation": "ICLR.cc/2019/Conference/-/Paper236/Official_Comment", "content": {"title": "Re: not mention recent results", "comment": "Thank you for your comment. As we have stated in several places in the paper, the focus of this work is to provide a theoretical explanation to the knowledge graph embedding and not to propose yet another heuristically-motivated scoring formula. We have discussed the most recent work by Ding et al. (ACL 2018, which happened in July 2018), which is the most recent venue. It is true that there are over 35 scoring formulas proposed in the literature as shown in [1]. However, we did not find any method to be providing a rigorous theoretical analysis as done in our work. In the empirical validation section, we have selected methods that have been repeatedly used in prior work as comparison points. As we have stated in the paper, and shown in the empirical validation section, although the derived scoring formula obtains good results they are not SoTA. However, the main contribution of the paper is in the theoretical extension of the generative model proposed by Arora et al. (2016), and to this extent, we have covered all theoretically-relevant prior work on such extensions. "}, "signatures": ["ICLR.cc/2019/Conference/Paper236/Authors"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper236/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper236/Authors", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "RelWalk -- A Latent Variable Model Approach to Knowledge Graph Embedding", "abstract": "Knowledge Graph Embedding (KGE) is the task of jointly learning entity and relation embeddings for a given knowledge graph. Existing methods for learning KGEs can be seen as a two-stage process where (a) entities and relations in the knowledge graph are represented using some linear algebraic structures (embeddings), and (b) a scoring function is defined that evaluates the strength of a relation that holds between two entities using the corresponding relation and entity embeddings. Unfortunately, prior proposals for the scoring functions in the first step have been heuristically motivated, and it is unclear as to how the scoring functions in KGEs relate to the generation process of the underlying knowledge graph. To address this issue, we propose a generative account of the KGE learning task. Specifically, given a knowledge graph represented by a set of relational triples (h, R, t), where the semantic relation R holds between the two entities h (head) and t (tail), we extend the random walk model (Arora et al., 2016a) of word embeddings to KGE. We derive a theoretical relationship between the joint probability p(h, R, t) and the embeddings of h, R and t. Moreover, we show that marginal loss minimisation, a popular objective used by much prior work in KGE, follows naturally from the log-likelihood ratio maximisation under the probabilities estimated from the KGEs according to our theoretical relationship. We propose a learning objective motivated by the theoretical analysis to learn KGEs from a given knowledge graph. The KGEs learnt by our proposed method obtain state-of-the-art performance on FB15K237 and WN18RR benchmark datasets, providing empirical evidence in support of the theory.\n", "keywords": ["relation representations", "natural language processing", "theoretical analysis", "knowledge graphs"], "authorids": ["danushka@liverpool.ac.uk", "h.a.hakami@liverpool.ac.uk", "yyoshida@nii.ac.jp", "k_keniti@nii.ac.jp"], "authors": ["Danushka Bollegala", "Huda Hakami", "Yuichi Yoshida", "Ken-ichi Kawarabayashi"], "TL;DR": "We present a theoretically proven generative model of knowledge graph embedding. ", "pdf": "/pdf/d70821e9867c967f02ed7b2eb093b95ef3fa0e3d.pdf", "paperhash": "bollegala|relwalk_a_latent_variable_model_approach_to_knowledge_graph_embedding", "_bibtex": "@misc{\nbollegala2019relwalk,\ntitle={RelWalk -- A Latent Variable Model Approach to Knowledge Graph Embedding},\nauthor={Danushka Bollegala and Huda Hakami and Yuichi Yoshida and Ken-ichi Kawarabayashi},\nyear={2019},\nurl={https://openreview.net/forum?id=SkxbDsR9Ym},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper236/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621613867, "tddate": null, "super": null, "final": null, "reply": {"forum": "SkxbDsR9Ym", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper236/Authors", "ICLR.cc/2019/Conference/Paper236/Reviewers", "ICLR.cc/2019/Conference/Paper236/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper236/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper236/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper236/Authors|ICLR.cc/2019/Conference/Paper236/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper236/Reviewers", "ICLR.cc/2019/Conference/Paper236/Authors", "ICLR.cc/2019/Conference/Paper236/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621613867}}}, {"id": "r1ecOjvhFQ", "original": null, "number": 1, "cdate": 1538190193975, "ddate": null, "tcdate": 1538190193975, "tmdate": 1538190193975, "tddate": null, "forum": "SkxbDsR9Ym", "replyto": "SkxbDsR9Ym", "invitation": "ICLR.cc/2019/Conference/-/Paper236/Public_Comment", "content": {"comment": "You missed to mention a lot of recent results which are much better than yours from last two years, as you can see a part from [1].\n\n[1] An overview of embedding models of entities and relationships for knowledge base completion. \n", "title": "Not mention recent results"}, "signatures": ["(anonymous)"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper236/Reviewers/Unsubmitted"], "writers": ["(anonymous)", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "RelWalk -- A Latent Variable Model Approach to Knowledge Graph Embedding", "abstract": "Knowledge Graph Embedding (KGE) is the task of jointly learning entity and relation embeddings for a given knowledge graph. Existing methods for learning KGEs can be seen as a two-stage process where (a) entities and relations in the knowledge graph are represented using some linear algebraic structures (embeddings), and (b) a scoring function is defined that evaluates the strength of a relation that holds between two entities using the corresponding relation and entity embeddings. Unfortunately, prior proposals for the scoring functions in the first step have been heuristically motivated, and it is unclear as to how the scoring functions in KGEs relate to the generation process of the underlying knowledge graph. To address this issue, we propose a generative account of the KGE learning task. Specifically, given a knowledge graph represented by a set of relational triples (h, R, t), where the semantic relation R holds between the two entities h (head) and t (tail), we extend the random walk model (Arora et al., 2016a) of word embeddings to KGE. We derive a theoretical relationship between the joint probability p(h, R, t) and the embeddings of h, R and t. Moreover, we show that marginal loss minimisation, a popular objective used by much prior work in KGE, follows naturally from the log-likelihood ratio maximisation under the probabilities estimated from the KGEs according to our theoretical relationship. We propose a learning objective motivated by the theoretical analysis to learn KGEs from a given knowledge graph. The KGEs learnt by our proposed method obtain state-of-the-art performance on FB15K237 and WN18RR benchmark datasets, providing empirical evidence in support of the theory.\n", "keywords": ["relation representations", "natural language processing", "theoretical analysis", "knowledge graphs"], "authorids": ["danushka@liverpool.ac.uk", "h.a.hakami@liverpool.ac.uk", "yyoshida@nii.ac.jp", "k_keniti@nii.ac.jp"], "authors": ["Danushka Bollegala", "Huda Hakami", "Yuichi Yoshida", "Ken-ichi Kawarabayashi"], "TL;DR": "We present a theoretically proven generative model of knowledge graph embedding. ", "pdf": "/pdf/d70821e9867c967f02ed7b2eb093b95ef3fa0e3d.pdf", "paperhash": "bollegala|relwalk_a_latent_variable_model_approach_to_knowledge_graph_embedding", "_bibtex": "@misc{\nbollegala2019relwalk,\ntitle={RelWalk -- A Latent Variable Model Approach to Knowledge Graph Embedding},\nauthor={Danushka Bollegala and Huda Hakami and Yuichi Yoshida and Ken-ichi Kawarabayashi},\nyear={2019},\nurl={https://openreview.net/forum?id=SkxbDsR9Ym},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper236/Public_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1542311887393, "tddate": null, "super": null, "final": null, "reply": {"signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed."}, "nonreaders": {"values": []}, "forum": "SkxbDsR9Ym", "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper236/Authors", "ICLR.cc/2019/Conference/Paper236/Reviewers", "ICLR.cc/2019/Conference/Paper236/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "replyto": null, "content": {"comment": {"value-regex": "[\\S\\s]{1,5000}", "required": true, "order": 1, "description": "Your comment or reply (max 5000 characters)."}, "title": {"value-regex": ".{1,500}", "required": true, "order": 0, "description": "Brief summary of your comment."}}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["~"], "noninvitees": ["ICLR.cc/2019/Conference/Paper236/Authors", "ICLR.cc/2019/Conference/Paper236/Reviewers", "ICLR.cc/2019/Conference/Paper236/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1542311887393}}}], "count": 20}