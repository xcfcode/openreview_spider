{"notes": [{"id": "vyY0jnWG-tK", "original": "NBqYOJa5zD", "number": 3030, "cdate": 1601308335959, "ddate": null, "tcdate": 1601308335959, "tmdate": 1615884019410, "tddate": null, "forum": "vyY0jnWG-tK", "replyto": null, "invitation": "ICLR.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Physics-aware, probabilistic model order reduction with guaranteed stability", "authorids": ["~Sebastian_Kaltenbach1", "~Phaedon_Stelios_Koutsourelakis1"], "authors": ["Sebastian Kaltenbach", "Phaedon Stelios Koutsourelakis"], "keywords": ["inductive bias", "probabilistic generative models", "state-space models", "model order reduction", "slowness", "long-term stability"], "abstract": "Given (small amounts of) time-series' data from  a high-dimensional, fine-grained, multiscale dynamical system, we propose a generative framework for learning an effective, lower-dimensional, coarse-grained dynamical model that is predictive of the fine-grained system's long-term evolution but also of its behavior under different initial conditions.\nWe target fine-grained models as they arise in physical applications (e.g. molecular dynamics, agent-based models), the dynamics  of which are strongly non-stationary but their transition to equilibrium is governed by unknown slow processes which are largely inaccessible by brute-force simulations.\nApproaches based on domain knowledge heavily rely on physical insight in identifying temporally slow features and fail to enforce the long-term stability of the learned dynamics. On the other hand, purely statistical frameworks lack interpretability and rely on large amounts of expensive simulation data (long and multiple trajectories) as they cannot infuse domain knowledge. \nThe generative framework proposed achieves  the aforementioned desiderata by  employing a flexible prior on the complex plane for the latent, slow processes, and  an intermediate layer of physics-motivated latent variables that reduces reliance on data and imbues inductive bias. In contrast to existing schemes, it does not require  the a priori definition of projection operators from the fine-grained description and addresses simultaneously the tasks of dimensionality reduction and model estimation.\nWe demonstrate its efficacy and accuracy in multiscale physical systems of particle dynamics where probabilistic, long-term predictions of phenomena not contained in the training data are produced.", "one-sentence_summary": "We propose a novel physics-aware, generative, probabilistic state-space model for learning an effective, lower-dimensional description that can produce long-term predictions.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "kaltenbach|physicsaware_probabilistic_model_order_reduction_with_guaranteed_stability", "pdf": "/pdf/0dbc13eb90ca0605840fb7ee708d76db95df9cbd.pdf", "venue": "ICLR 2021 Poster", "venueid": "ICLR.cc/2021/Conference", "_bibtex": "@inproceedings{\nkaltenbach2021physicsaware,\ntitle={Physics-aware, probabilistic model order reduction with guaranteed stability},\nauthor={Sebastian Kaltenbach and Phaedon Stelios Koutsourelakis},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=vyY0jnWG-tK}\n}"}, "signatures": ["ICLR.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference"], "details": {"replyCount": 13, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"reply": {"readers": {"values-regex": ".*"}, "writers": {"values": ["ICLR.cc/2021/Conference"]}, "signatures": {"values": ["ICLR.cc/2021/Conference"]}, "content": {"authors": {"values": ["Anonymous"]}, "authorids": {"values-regex": ".*"}, "reviewed_version_(pdf)": {"required": false, "description": "Upload a PDF file that ends with .pdf", "value-regex": ".*"}}}, "signatures": ["ICLR.cc/2021/Conference"], "readers": ["everyone"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["~", "OpenReview.net/Support"], "tcdate": 1601308008205, "tmdate": 1614984599368, "id": "ICLR.cc/2021/Conference/-/Blind_Submission"}}, "tauthor": "OpenReview.net"}, {"id": "lJTwbSyIQV7", "original": null, "number": 1, "cdate": 1610040484454, "ddate": null, "tcdate": 1610040484454, "tmdate": 1610474089701, "tddate": null, "forum": "vyY0jnWG-tK", "replyto": "vyY0jnWG-tK", "invitation": "ICLR.cc/2021/Conference/Paper3030/-/Decision", "content": {"title": "Final Decision", "decision": "Accept (Poster)", "comment": "The consensus of the reviews is to accept the paper. I agree.\n\nReviewers highlighted many strengths, including a compelling main idea:\n* R5: \"The paper presents an interesting and motivating case for Bayesian inference in probabilistic generative models: a problem that has inherent uncertainty along with the ability to incorporate domain knowledge that can reduce the inference complexity.\"\n* R3: \"Overall, the idea is interesting and supported by correct mathematical derivations and experimental proofs of concept.\"\n* R4: \"the generative approach is novel. Adding domain knowledge is relevant and significant when dealing with real world applications\"\n\nAs well as compelling experiments, substantially improved in the discussion period:\n* R1: \"The authors have shown some promising results in modeling particle dynamics.\"\n* R5: \"The addition of Appendix H, in my opinion, considerably strengthens the paper's story and case for acceptance. [... T]he authors have addressed most of my major concerns.\"\n\nAnd clear writing:\n* R5: \"In general, the paper is well written (apart from some higher-level structural issues discussed below) and the notation is clear and unambiguous.\"\n* R4: \"The paper is very well written, clear\"\n\nThe main weaknesses highlighted were in experiments (lacking good baselines, as well as ablations), and in discussing some choices in the model's construction. These were effectively addressed in the discussion (though R5 still points to some places that could be improved)."}, "signatures": ["ICLR.cc/2021/Conference/Program_Chairs"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference/Program_Chairs"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Physics-aware, probabilistic model order reduction with guaranteed stability", "authorids": ["~Sebastian_Kaltenbach1", "~Phaedon_Stelios_Koutsourelakis1"], "authors": ["Sebastian Kaltenbach", "Phaedon Stelios Koutsourelakis"], "keywords": ["inductive bias", "probabilistic generative models", "state-space models", "model order reduction", "slowness", "long-term stability"], "abstract": "Given (small amounts of) time-series' data from  a high-dimensional, fine-grained, multiscale dynamical system, we propose a generative framework for learning an effective, lower-dimensional, coarse-grained dynamical model that is predictive of the fine-grained system's long-term evolution but also of its behavior under different initial conditions.\nWe target fine-grained models as they arise in physical applications (e.g. molecular dynamics, agent-based models), the dynamics  of which are strongly non-stationary but their transition to equilibrium is governed by unknown slow processes which are largely inaccessible by brute-force simulations.\nApproaches based on domain knowledge heavily rely on physical insight in identifying temporally slow features and fail to enforce the long-term stability of the learned dynamics. On the other hand, purely statistical frameworks lack interpretability and rely on large amounts of expensive simulation data (long and multiple trajectories) as they cannot infuse domain knowledge. \nThe generative framework proposed achieves  the aforementioned desiderata by  employing a flexible prior on the complex plane for the latent, slow processes, and  an intermediate layer of physics-motivated latent variables that reduces reliance on data and imbues inductive bias. In contrast to existing schemes, it does not require  the a priori definition of projection operators from the fine-grained description and addresses simultaneously the tasks of dimensionality reduction and model estimation.\nWe demonstrate its efficacy and accuracy in multiscale physical systems of particle dynamics where probabilistic, long-term predictions of phenomena not contained in the training data are produced.", "one-sentence_summary": "We propose a novel physics-aware, generative, probabilistic state-space model for learning an effective, lower-dimensional description that can produce long-term predictions.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "kaltenbach|physicsaware_probabilistic_model_order_reduction_with_guaranteed_stability", "pdf": "/pdf/0dbc13eb90ca0605840fb7ee708d76db95df9cbd.pdf", "venue": "ICLR 2021 Poster", "venueid": "ICLR.cc/2021/Conference", "_bibtex": "@inproceedings{\nkaltenbach2021physicsaware,\ntitle={Physics-aware, probabilistic model order reduction with guaranteed stability},\nauthor={Sebastian Kaltenbach and Phaedon Stelios Koutsourelakis},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=vyY0jnWG-tK}\n}"}, "tags": [], "invitation": {"reply": {"forum": "vyY0jnWG-tK", "replyto": "vyY0jnWG-tK", "readers": {"values": ["everyone"]}, "writers": {"values": ["ICLR.cc/2021/Conference/Program_Chairs"]}, "signatures": {"values": ["ICLR.cc/2021/Conference/Program_Chairs"]}, "content": {"title": {"value": "Final Decision"}, "decision": {"value-radio": ["Accept (Oral)", "Accept (Spotlight)", "Accept (Poster)", "Reject"]}, "comment": {"value-regex": "[\\S\\s]{0,50000}", "markdown": true}}}, "multiReply": false, "signatures": ["ICLR.cc/2021/Conference"], "readers": ["everyone"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Program_Chairs"], "tcdate": 1610040484438, "tmdate": 1610474089685, "id": "ICLR.cc/2021/Conference/Paper3030/-/Decision"}}}, {"id": "iQRRZKI1aW6", "original": null, "number": 5, "cdate": 1604959223071, "ddate": null, "tcdate": 1604959223071, "tmdate": 1606769336934, "tddate": null, "forum": "vyY0jnWG-tK", "replyto": "vyY0jnWG-tK", "invitation": "ICLR.cc/2021/Conference/Paper3030/-/Official_Review", "content": {"title": "Interesting idea with encouraging results but lacks necessary motivation and ablations (updated)", "review": "Summary:\n\nThe paper presents a generative approach to modeling physical systems with high-dimensional, nonlinear dynamical systems such as those found in fluid mechanics. The authors provide a physics-motivated hierarchical model for high-dimensional time series and a variational inference method for inferring latent variables and dynamical system parameters. They demonstrate its performance on simulated fluid mechanics prediction tasks.\n\nStrong points:\n\nThe paper presents an interesting and motivating case for Bayesian inference in probabilistic generative models: a problem that has inherent uncertainty along with the ability to incorporate domain knowledge that can reduce the inference complexity.\n\nThe results on the simulated tasks are encouraging, especially the results in Appendix H which demonstrate generalization to out-of-distribution data. The paper does an excellent job of presenting and analyzing the results, along with compelling visualizations.\n\nIn general, the paper is well written (apart from some higher-level structural issues discussed below) and the notation is clear and unambiguous. \n\nWeak points:\n\nStructurally, the paper could do a better job of motivating the particular choices made when designing the model. The choices that could be made more clearly motivated are:\n\n1) using a complex-valued latent dynamical system. Although there is a sentence in the \u201cRelated Work\u201d section (\u201cthe prior proposed and the use of complex variables enable the discovery of slow features\u201d), this important choice could use additional discussion and motivation.\n\n2) On first read, it was unclear what the likelihood model was, especially when it was stated that the observed data were time-series of (e.g.) particle velocities and positions. In Appendix E, it is stated that a Multinomial observation model is used, which could not be used for particle velocities/positions since it models counts of discrete variables. Thus, the observations $x_t$ in this case are statistics of velocities/positions (i.e. counts of particles in discrete buckets). This choice should be discussed in the main text, as it both changes the dataset size and dimensionality, along with the goal of the model itself. Rather than modeling particle positions and velocities, it seems like the model is generating statistics of the system. While this isn\u2019t inherently problematic, this choice is not clearly indicated in the text.\n\n3) Finally, the paper includes $z_t$ in the model to help make predictions converge to equilibrium. While intuitively, having $z_t$ decay according to the model corresponds to some notion of \u201cstability\u201d, the paper should also explain how the exclusion of $z_t$ can lead to unstable or diverging predictions. Although the paper cites related work to justify the choice, it is such an important choice that I think it merits more discussion in the main text.\n\nThese structural issues with the paper are worsened by the fact that there are no ablations or comparisons in the paper. I think the minimal set of additional experiments would include 1) a model with real-valued (not complex) latent dynamics and 2) a model without $z$ in it, to demonstrate the necessity of a stabilizing element in the model. Even better would be comparisons to non-probabilistic models, demonstrating the necessity of uncertainty in the face of \u201cinformation loss\u201d. Finally, comparisons to related methods (e.g. Koopman-operator baselines) would help understand how the proposed model improves on the surrounding literature.\n\nRecommendation:\n\nWhile I find the problem setting and proposed approach very interesting, the writing of the paper and the results still need work. The paper needs to better justify the modeling choices both in writing and with additional experiments. The provided results are encouraging, but I think a proper evaluation of the approach with the appropriate ablations and baselines is necessary for publication. I recommend a reject on these grounds.\n\nClarifying questions:\n\nAre predictions obtained using MAP estimates of the parameters $\\theta$ or by sampling the posterior predictive distribution (i.e. marginalizing out $\\theta$)?\nIn what way is your inference approach \u201chybrid\u201d as opposed to fully Bayesian?\n\nAdditional feedback:\n\nDefining terms like \u201cfine-grained\u201d and \u201cmultiscale\u201d would help make the paper more accessible to readers without physics backgrounds\nNit: \u201cparametrized\u201d -> \u201cparameterized\u201d\nPage 4: \u201calgrithm\u201d -> \u201calgorithm\u201d\n\n\n===========================================\nUpdates:\n\nAfter considering the author's response and updates to the paper, I have bumped the score to a 6. The addition of Appendix H, in my opinion, considerably strengthens the paper's story and case for acceptance. I still have minor concerns about the writing surrounding the use of the Multinomial likelihood - for example, the paper still claims to be dealing with high-dimensional data, but bucketing into 25 buckets immediately reduces the complexity of the observation space to 25-dimensional counts. However, the authors have addressed most of my major concerns.\n", "rating": "6: Marginally above acceptance threshold", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "signatures": ["ICLR.cc/2021/Conference/Paper3030/AnonReviewer5"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper3030/AnonReviewer5"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Physics-aware, probabilistic model order reduction with guaranteed stability", "authorids": ["~Sebastian_Kaltenbach1", "~Phaedon_Stelios_Koutsourelakis1"], "authors": ["Sebastian Kaltenbach", "Phaedon Stelios Koutsourelakis"], "keywords": ["inductive bias", "probabilistic generative models", "state-space models", "model order reduction", "slowness", "long-term stability"], "abstract": "Given (small amounts of) time-series' data from  a high-dimensional, fine-grained, multiscale dynamical system, we propose a generative framework for learning an effective, lower-dimensional, coarse-grained dynamical model that is predictive of the fine-grained system's long-term evolution but also of its behavior under different initial conditions.\nWe target fine-grained models as they arise in physical applications (e.g. molecular dynamics, agent-based models), the dynamics  of which are strongly non-stationary but their transition to equilibrium is governed by unknown slow processes which are largely inaccessible by brute-force simulations.\nApproaches based on domain knowledge heavily rely on physical insight in identifying temporally slow features and fail to enforce the long-term stability of the learned dynamics. On the other hand, purely statistical frameworks lack interpretability and rely on large amounts of expensive simulation data (long and multiple trajectories) as they cannot infuse domain knowledge. \nThe generative framework proposed achieves  the aforementioned desiderata by  employing a flexible prior on the complex plane for the latent, slow processes, and  an intermediate layer of physics-motivated latent variables that reduces reliance on data and imbues inductive bias. In contrast to existing schemes, it does not require  the a priori definition of projection operators from the fine-grained description and addresses simultaneously the tasks of dimensionality reduction and model estimation.\nWe demonstrate its efficacy and accuracy in multiscale physical systems of particle dynamics where probabilistic, long-term predictions of phenomena not contained in the training data are produced.", "one-sentence_summary": "We propose a novel physics-aware, generative, probabilistic state-space model for learning an effective, lower-dimensional description that can produce long-term predictions.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "kaltenbach|physicsaware_probabilistic_model_order_reduction_with_guaranteed_stability", "pdf": "/pdf/0dbc13eb90ca0605840fb7ee708d76db95df9cbd.pdf", "venue": "ICLR 2021 Poster", "venueid": "ICLR.cc/2021/Conference", "_bibtex": "@inproceedings{\nkaltenbach2021physicsaware,\ntitle={Physics-aware, probabilistic model order reduction with guaranteed stability},\nauthor={Sebastian Kaltenbach and Phaedon Stelios Koutsourelakis},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=vyY0jnWG-tK}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq . ***Please remember to file the Code-of-Ethics report. Once you submitted the review, a link to the report will be visible in the bottom right corner of your review.***", "required": true, "markdown": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}, "forum": "vyY0jnWG-tK", "replyto": "vyY0jnWG-tK", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"], "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper3030/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1607428800000, "duedate": 1606752000000, "multiReply": false, "readers": ["everyone"], "tcdate": 1602538083728, "tmdate": 1606915795948, "super": "ICLR.cc/2021/Conference/-/Official_Review", "signatures": ["OpenReview.net"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Paper3030/Reviewers", "OpenReview.net/Support"], "id": "ICLR.cc/2021/Conference/Paper3030/-/Official_Review"}}}, {"id": "gZ11_l6TwB", "original": null, "number": 1, "cdate": 1603458650408, "ddate": null, "tcdate": 1603458650408, "tmdate": 1606745988898, "tddate": null, "forum": "vyY0jnWG-tK", "replyto": "vyY0jnWG-tK", "invitation": "ICLR.cc/2021/Conference/Paper3030/-/Official_Review", "content": {"title": "Interesting paper that adds a physics-motivated latent space to the standard latent space", "review": "The paper proposes a generative model for learning a low-dimensional representation of a dynamical system from high-dimensional observations. The novelty of the approach is to introduce two latent spaces, one representing the standard physics-agnostic latent space learned from the data and one representing physics-motivated variables. The goal is to learn the dynamics of the first layer, denoted by z_t, which is a coarse-grained representation of the dynamical system and mostly captures the slow processes that drive the system. \n\nQuality, clarity, originality and significance:\nPro: The paper is very well written, clear, and the generative approach is novel. Adding domain knowledge is relevant and significant when dealing with real world applications. Cons: Below are a few comments and questions to clarify some of the aspects and choices made. \n\nHow are the physics-motivated variables chosen? Is there a guarantee that the chosen representation/variables are sufficient to allow a one-on-one mapping between the physics-based latent space $X_t$ and the observations/data $x_t$? (As a small comment, I found it slightly confusing to use the same letter for the latent space and data space, even if one is lower case and the other upper case.) \n\nWhat does equilibrium represent here? Does it necessarily need to be a stationary process as in the experiments, or can it be a trend, or a periodic signal? Are the latter two cases handled well by the method?\n\nFig. 1: Would it be possible to add the maps F and G to the figure? It is not very clear to me how the latent variables X are obtained, are they computed from the data? If X is the generative process for x, why do we need the latent space z? Would it be possible that the latent space X is sufficient, and if not, would the authors have examples when this is not the case?\n\nThe framework is applied to physics simulations. How easy/difficult would it be to apply the method to real world data, and what would be the main challenges?\n\nSect. 2: Should it be $x_t \\in \\mathcal{M}$, instead of $x \\in \\mathcal{M}$? The paper mentions that the $z_t$\u2019s correspond to a nonlinear coordinate transformation, but do not specify of what?\n\nWhat is the motivation for using the Ornstein-Uhlenbeck process for z, and what would be other alternatives? Why exactly does z need to be complex, is it in order to be able to capture slow and fast processes? In Figs. 2 and 5, the slow processes seem to have imaginary part close to zero, and fast processes real part close to zero. What is the explanation for this (this might be a known fact in dynamical systems theory, but not so much in ML)? Does it always have to be the case that the \\lambda\u2019s have either the real or imaginary parts close to zero? What would happen if the system is still multi-scale but on a much more continuous scale than in the experiments presented here and where there wouldn\u2019t be such a clear distinction between slow/intermediate/fast scales (this would probably be the case in complex real world systems)? \n\nAccording to eq (4) to ensure long-term stability, the real part of $\\lambda_j$ should be\nnegative. This only applies to the slow processes, is that right? What is an explanation for this? \n\nIn the definition for $\\sigma_j$ there is a 2 factor which is not in eq (7). Same line: the latent dynamics are stationary refers to which layer, $z_t$ or $X_t$? Using clearly defined names for the two latent spaces would make the paper easier to read. Maybe even add this to Fig. 1.\n\nIn ML we don\u2019t see often complex distribution, and it would be good to specify that $\\mathcal{CN}$ is the complex distribution.\n\nEq (1): as $\\lambda$ and $\\sigma$ do not depend on time, it means that all hidden processes $z_t$ follow the same dynamical model. What are the implications of this, and would this be a reasonable choice in a real world scenario?\n\nHow robust are the results to the choice of the number of latent variables h, and the choice of the physics-based variables?\n\n--------------------------\nRebuttal: Thank you to the authors for their detailed response. I am happy with the response and will keep the original score.", "rating": "7: Good paper, accept", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["ICLR.cc/2021/Conference/Paper3030/AnonReviewer4"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper3030/AnonReviewer4"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Physics-aware, probabilistic model order reduction with guaranteed stability", "authorids": ["~Sebastian_Kaltenbach1", "~Phaedon_Stelios_Koutsourelakis1"], "authors": ["Sebastian Kaltenbach", "Phaedon Stelios Koutsourelakis"], "keywords": ["inductive bias", "probabilistic generative models", "state-space models", "model order reduction", "slowness", "long-term stability"], "abstract": "Given (small amounts of) time-series' data from  a high-dimensional, fine-grained, multiscale dynamical system, we propose a generative framework for learning an effective, lower-dimensional, coarse-grained dynamical model that is predictive of the fine-grained system's long-term evolution but also of its behavior under different initial conditions.\nWe target fine-grained models as they arise in physical applications (e.g. molecular dynamics, agent-based models), the dynamics  of which are strongly non-stationary but their transition to equilibrium is governed by unknown slow processes which are largely inaccessible by brute-force simulations.\nApproaches based on domain knowledge heavily rely on physical insight in identifying temporally slow features and fail to enforce the long-term stability of the learned dynamics. On the other hand, purely statistical frameworks lack interpretability and rely on large amounts of expensive simulation data (long and multiple trajectories) as they cannot infuse domain knowledge. \nThe generative framework proposed achieves  the aforementioned desiderata by  employing a flexible prior on the complex plane for the latent, slow processes, and  an intermediate layer of physics-motivated latent variables that reduces reliance on data and imbues inductive bias. In contrast to existing schemes, it does not require  the a priori definition of projection operators from the fine-grained description and addresses simultaneously the tasks of dimensionality reduction and model estimation.\nWe demonstrate its efficacy and accuracy in multiscale physical systems of particle dynamics where probabilistic, long-term predictions of phenomena not contained in the training data are produced.", "one-sentence_summary": "We propose a novel physics-aware, generative, probabilistic state-space model for learning an effective, lower-dimensional description that can produce long-term predictions.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "kaltenbach|physicsaware_probabilistic_model_order_reduction_with_guaranteed_stability", "pdf": "/pdf/0dbc13eb90ca0605840fb7ee708d76db95df9cbd.pdf", "venue": "ICLR 2021 Poster", "venueid": "ICLR.cc/2021/Conference", "_bibtex": "@inproceedings{\nkaltenbach2021physicsaware,\ntitle={Physics-aware, probabilistic model order reduction with guaranteed stability},\nauthor={Sebastian Kaltenbach and Phaedon Stelios Koutsourelakis},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=vyY0jnWG-tK}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq . ***Please remember to file the Code-of-Ethics report. Once you submitted the review, a link to the report will be visible in the bottom right corner of your review.***", "required": true, "markdown": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}, "forum": "vyY0jnWG-tK", "replyto": "vyY0jnWG-tK", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"], "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper3030/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1607428800000, "duedate": 1606752000000, "multiReply": false, "readers": ["everyone"], "tcdate": 1602538083728, "tmdate": 1606915795948, "super": "ICLR.cc/2021/Conference/-/Official_Review", "signatures": ["OpenReview.net"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Paper3030/Reviewers", "OpenReview.net/Support"], "id": "ICLR.cc/2021/Conference/Paper3030/-/Official_Review"}}}, {"id": "jjaRzWc6duh", "original": null, "number": 6, "cdate": 1605700310448, "ddate": null, "tcdate": 1605700310448, "tmdate": 1605701805658, "tddate": null, "forum": "vyY0jnWG-tK", "replyto": "gZ11_l6TwB", "invitation": "ICLR.cc/2021/Conference/Paper3030/-/Official_Comment", "content": {"title": "Response to Reviewer 4", "comment": "We thank the reviewer for their assessment and the positive feedback as well as the suggestions for improving the paper.\n\n\n- The physics-motivated variables have to be chosen a priori and necessitate the availability of  some physical knowledge about the system. A one-to-one mapping will (almost) never  exist as long as the physically-motivated variables $\\boldsymbol{X}$ (or more generally the reduced description) are lower-dimensional than the observables $\\boldsymbol{x}$. The goal of predictability can be achieved if the conditional of $\\boldsymbol{x}$ given $\\boldsymbol{X}$ is unimodal and preferably of low variance. \nAs we pointed in  our response to reviewer R1,  we have investigated  cases where the $\\boldsymbol{X}$ used was known to provide an incomplete picture. Our  preliminary  observations suggested an increased uncertainty in the reconstructed $\\boldsymbol{x}_t$ i.e. insufficient $\\boldsymbol{X}_t$ implied increased stochasticity in the predicted $\\boldsymbol{x}_t$.\nIn a way, this is already the case in the examples considered, i.e. even if one assumes that the particle density is sufficient for the reconstruction of the particle positions $\\boldsymbol{x}_t$, the $\\boldsymbol{X}$ that we employ are based on a discretization of this density which unavoidably implies some information loss.\nNevertheless, for a lot of applications or observables,  increased predictive uncertainty  could constitute predictions irrelevant or impractical and  reduce the utility of the method proposed. An option that we also mention in the Conclusions is to include (some of) the $\\boldsymbol{z}_t$ in the decoder. We note though that  increasing the inputs of the decoder, complicates the associated map and unavoidably would increase the amount of training data needed. An option we are exploring is to use only  a small number of features of $\\boldsymbol{z}_t$ which are identified by sparsity-enforcing priors.  We would be happy to expand on the technical aspects, if the reviewer requests it. As  a side note regarding the notational conventions, and while we do not claim that our choices were optimal for a diverse audience such as ICLR's, we would like to explain our reasoning for $\\boldsymbol{X}_t$: Given the notation $\\boldsymbol{x}_t$ for the fine-scale observables,  we selected a capital letter as it alludes to a macro/coarse-description and the same letter as for the fine-scale system  to evoke  a physical meaning.\n\n\n\n- The notion of equilibrium is meant in the statistical sense i.e. the density of particle positions' $\\boldsymbol{x}$ becomes independent of time $t$. This does not mean that the system cannot change in time, but rather that its  statistics would remain  constant. In our formulation, transient characteristics are determined by the latent processes $\\boldsymbol{z}_{t,j}$. We have added some details in Appendix B regarding their  stationary density as well as their autocovariance. We show that the latter contains modulated periodic functions that depend on the imaginary part of the learned parameters $\\lambda_j$. We finally note that due to the nonlinear maps involved, the resulting equilibrium density of $\\boldsymbol{X}$ and more importantly of $\\boldsymbol{x}$, will be highly non-Gaussian.   \n\n- We improved Figure 1 according to the reviewer's suggestions. We note that the latent, physically-motivated variables $\\boldsymbol{X}$ act as an information bottleneck and facilitate the reconstruction of the high-dimensional observables $\\boldsymbol{x}$. The dynamics of $\\boldsymbol{X}$ can be highly nonlinear and non-Markovian. As we demonstrate in the newly added Appendix H.2, learning their dynamics from data does not guarantee long-term stability. Hence, the latent variables $\\boldsymbol{z}$ are employed in an additional layer in order to capture their dynamics in a manner that always guarantees stability, but also provides interpretability by ordering processes based on their slowness. \n\n- The most important challenge for the application of the proposed model to other  dynamical systems pertains to the definition of the physically-motivated variables $\\boldsymbol{X}$. These constitute the necessary information bottleneck that enables us to model  very high-dimensional systems with small amounts of training  data. While such variables are usually readily available in large classes of physical problems, this might not be the case in other contexts, e.g. financial time-series. \n\n\n- We thank the reviewer for pointing out the mistake in the notation of $\\boldsymbol{x}_t$. \n\n\n"}, "signatures": ["ICLR.cc/2021/Conference/Paper3030/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper3030/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Physics-aware, probabilistic model order reduction with guaranteed stability", "authorids": ["~Sebastian_Kaltenbach1", "~Phaedon_Stelios_Koutsourelakis1"], "authors": ["Sebastian Kaltenbach", "Phaedon Stelios Koutsourelakis"], "keywords": ["inductive bias", "probabilistic generative models", "state-space models", "model order reduction", "slowness", "long-term stability"], "abstract": "Given (small amounts of) time-series' data from  a high-dimensional, fine-grained, multiscale dynamical system, we propose a generative framework for learning an effective, lower-dimensional, coarse-grained dynamical model that is predictive of the fine-grained system's long-term evolution but also of its behavior under different initial conditions.\nWe target fine-grained models as they arise in physical applications (e.g. molecular dynamics, agent-based models), the dynamics  of which are strongly non-stationary but their transition to equilibrium is governed by unknown slow processes which are largely inaccessible by brute-force simulations.\nApproaches based on domain knowledge heavily rely on physical insight in identifying temporally slow features and fail to enforce the long-term stability of the learned dynamics. On the other hand, purely statistical frameworks lack interpretability and rely on large amounts of expensive simulation data (long and multiple trajectories) as they cannot infuse domain knowledge. \nThe generative framework proposed achieves  the aforementioned desiderata by  employing a flexible prior on the complex plane for the latent, slow processes, and  an intermediate layer of physics-motivated latent variables that reduces reliance on data and imbues inductive bias. In contrast to existing schemes, it does not require  the a priori definition of projection operators from the fine-grained description and addresses simultaneously the tasks of dimensionality reduction and model estimation.\nWe demonstrate its efficacy and accuracy in multiscale physical systems of particle dynamics where probabilistic, long-term predictions of phenomena not contained in the training data are produced.", "one-sentence_summary": "We propose a novel physics-aware, generative, probabilistic state-space model for learning an effective, lower-dimensional description that can produce long-term predictions.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "kaltenbach|physicsaware_probabilistic_model_order_reduction_with_guaranteed_stability", "pdf": "/pdf/0dbc13eb90ca0605840fb7ee708d76db95df9cbd.pdf", "venue": "ICLR 2021 Poster", "venueid": "ICLR.cc/2021/Conference", "_bibtex": "@inproceedings{\nkaltenbach2021physicsaware,\ntitle={Physics-aware, probabilistic model order reduction with guaranteed stability},\nauthor={Sebastian Kaltenbach and Phaedon Stelios Koutsourelakis},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=vyY0jnWG-tK}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "vyY0jnWG-tK", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper3030/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper3030/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper3030/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper3030/Authors|ICLR.cc/2021/Conference/Paper3030/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper3030/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923841909, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper3030/-/Official_Comment"}}}, {"id": "hrVhbwQl8hk", "original": null, "number": 5, "cdate": 1605700065663, "ddate": null, "tcdate": 1605700065663, "tmdate": 1605700997367, "tddate": null, "forum": "vyY0jnWG-tK", "replyto": "ny1lA_xqjMF", "invitation": "ICLR.cc/2021/Conference/Paper3030/-/Official_Comment", "content": {"title": "Response to Reviewer 3", "comment": "We thank the reviewer for their thorough  analysis and  positive appraisal as well as the constructive criticism .\n\n\n- We have  added a new section (Appendix H) where we evaluated the performance of various approaches on our two test examples. These include deterministic and probabilistic models such as those based on  the Koopman operator or those employing deep neural networks to parameterize the latent dynamics. We believe that the results obtained support our modeling choices in terms of the complex-valued latent variables that capture slow-varying transients and enforce long-term stability, the use of the intermediate, physically-motivated variables as well as the adoption of a probabilistic framework. As our approach does not require  time-derivatives of the observables (which we consider a significant advantage as in most applications derivatives are estimated with finite differences and are therefore noisy), we did not compare our method with algorithms which do require such derivatives. We would also like to note that even though a wide variety of methods for the analysis of time-series (irrespective of their origin) have been proposed, their applicability would be limited or even impossible due to the very large number of observables (i.e. particles) in the problems considered.\n\n- The reviewer correctly points out that in our example the mapping $p(\\boldsymbol{x}_t | \\boldsymbol{X}_t)$  is predetermined. This was previously contained in the appendix but in the updated version has been moved to the main text.\nFurthermore, the reviewer is also right that the viscous Burgers' equation upon discretization does not lead to linear dynamics and special care has to be taken to ensure that solution does not \"blow up\" i.e. to ensure stability. Interestingly for such a nonlinear PDE, it is known that there is a nonlinear transformation (the Hopf-Cole transform) that converts it to the well-behaved linear heat equation. This is effectively the role of the latent variables $\\boldsymbol{z}$ and the associated transformation $G$ in Equation 2, i.e. to learn nonlinear transformations that constitute the $\\boldsymbol{X}$-dynamics linear (and Markovian). Furthermore, even if the Cole-Hopf transfrom was a-priori enforced, the spatial-discretization of the new field would require more degrees of freedom than the $5$ complex-valued variables $\\boldsymbol{z}$ with which our model is able to encode the system's dynamics.\nFinally with regards to other examples, we recognize that the central role of the physically-motivated variables $\\boldsymbol{X}$ precludes the direct application in problems (like the single molecules mentioned) where such variables are not readily available or some dimensionality reduction technique would have to be applied beforehand in order to identify them. For low-dimensional systems, the utility of our method would be reduced as in such cases there is generally no need to  find lower-dimensional descriptions. With regards to a high number of $\\lambda$'s needed, we note that an automatic selection of the right dimension of the low-dimensional state-space is a direction for future work as also pointed out by other reviewers. If the chosen latent variables are not capable of expressing the dynamics than the predictive uncertainty will become high.\n\n\n- The reviewer addresses a common misunderstanding for such (single-species) particle systems and gave us the opportunity to clarify this in the updated text. While the system of interest consists of a very large number of particles these are exchangeable or put differently, the system is permutation- invariant. One does not care about an individual particle but rather than first-, second- and higher-order interactions such as the ones reported in the text and in Appendix F. On one hand this simplifies the task but it is also well-known that enforcing a priori such invariances (or more generally symmetries, equivariances etc) is not easy particularly if highly-expressive models (such as neural networks) are employed. In part, the physically-motivated variables $\\boldsymbol{X}$ are introduced to facilitate this task.\n\n- We agree with the reviewer that Appendix  H (with old numbering)  is very important and have now moved it to the main text.\n\n- We took again a closer look at our inference section and added more explanations regarding the factorization of our variational distributions. We also improved the graphs and the color-bar in Figures 13-16. We have also addressed all the editorial remarks   and are thankful to the reviewer for pointing them out.\n"}, "signatures": ["ICLR.cc/2021/Conference/Paper3030/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper3030/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Physics-aware, probabilistic model order reduction with guaranteed stability", "authorids": ["~Sebastian_Kaltenbach1", "~Phaedon_Stelios_Koutsourelakis1"], "authors": ["Sebastian Kaltenbach", "Phaedon Stelios Koutsourelakis"], "keywords": ["inductive bias", "probabilistic generative models", "state-space models", "model order reduction", "slowness", "long-term stability"], "abstract": "Given (small amounts of) time-series' data from  a high-dimensional, fine-grained, multiscale dynamical system, we propose a generative framework for learning an effective, lower-dimensional, coarse-grained dynamical model that is predictive of the fine-grained system's long-term evolution but also of its behavior under different initial conditions.\nWe target fine-grained models as they arise in physical applications (e.g. molecular dynamics, agent-based models), the dynamics  of which are strongly non-stationary but their transition to equilibrium is governed by unknown slow processes which are largely inaccessible by brute-force simulations.\nApproaches based on domain knowledge heavily rely on physical insight in identifying temporally slow features and fail to enforce the long-term stability of the learned dynamics. On the other hand, purely statistical frameworks lack interpretability and rely on large amounts of expensive simulation data (long and multiple trajectories) as they cannot infuse domain knowledge. \nThe generative framework proposed achieves  the aforementioned desiderata by  employing a flexible prior on the complex plane for the latent, slow processes, and  an intermediate layer of physics-motivated latent variables that reduces reliance on data and imbues inductive bias. In contrast to existing schemes, it does not require  the a priori definition of projection operators from the fine-grained description and addresses simultaneously the tasks of dimensionality reduction and model estimation.\nWe demonstrate its efficacy and accuracy in multiscale physical systems of particle dynamics where probabilistic, long-term predictions of phenomena not contained in the training data are produced.", "one-sentence_summary": "We propose a novel physics-aware, generative, probabilistic state-space model for learning an effective, lower-dimensional description that can produce long-term predictions.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "kaltenbach|physicsaware_probabilistic_model_order_reduction_with_guaranteed_stability", "pdf": "/pdf/0dbc13eb90ca0605840fb7ee708d76db95df9cbd.pdf", "venue": "ICLR 2021 Poster", "venueid": "ICLR.cc/2021/Conference", "_bibtex": "@inproceedings{\nkaltenbach2021physicsaware,\ntitle={Physics-aware, probabilistic model order reduction with guaranteed stability},\nauthor={Sebastian Kaltenbach and Phaedon Stelios Koutsourelakis},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=vyY0jnWG-tK}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "vyY0jnWG-tK", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper3030/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper3030/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper3030/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper3030/Authors|ICLR.cc/2021/Conference/Paper3030/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper3030/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923841909, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper3030/-/Official_Comment"}}}, {"id": "dnH0G-Nqrpn", "original": null, "number": 3, "cdate": 1605699602030, "ddate": null, "tcdate": 1605699602030, "tmdate": 1605700930559, "tddate": null, "forum": "vyY0jnWG-tK", "replyto": "nDAEBjmLAQI", "invitation": "ICLR.cc/2021/Conference/Paper3030/-/Official_Comment", "content": {"title": "Response to Reviewer 1", "comment": "We thank the reviewer for their comments and the positive feedback as well as for the suggestions for improving the paper.\n\n- We have included  a  study in  the newly-added Appendix G of the  paper that examines the effect of the amount of  training data. We have observed that even with a quarter of the original data, the model can capture the salient dynamical features and the correct steady state.   We believe that this is due to the intermediate layer of physically-motivated variables $\\boldsymbol{X}_t$ which introduce an information bottleneck. As one would perhaps expect, fewer training data  leads to increased predictive  uncertainty. We further  contrast this performance with several other methods that have been added in Appendix H. \n\n- The reviewer is right that in a lot of physical systems we do not know exactly the governing physical variables. Very often some physical variables are available but they do not necessarily provide the full picture (e.g. unknown internal state variables). In such a discussion, we should distinguish  between unknown variables that are needed to capture the dynamics of (known variables or variables of interest) $\\boldsymbol{X}_t$ and, secondly, unknown variables that are needed to reconstruct $\\boldsymbol{x}_t$. For the first case, the premise of the method is that given a sufficient number of $\\boldsymbol{z}_t$ , the dynamics of $\\boldsymbol{X}_t$ can be correctly captured. This should apply to cases where memory terms appear in the latter i.e. we exchange memory for additional variables [Kondrashov et al. : Data-driven non-Markovian closure models, 2015]. We recognize that  an automated scheme for determining the right number of $\\boldsymbol{z}_t$ is currently missing. The second case would require augmenting the inputs of the decoder $\\boldsymbol{F}$ in Equation 3. We are currently investigating such cases and preliminary results (which do not constitute conclusive evidence) suggest an increased uncertainty in the reconstructed $\\boldsymbol{x}_t$ i.e. insufficient $\\boldsymbol{X}_t$ implied increased stochasticity in the predicted $\\boldsymbol{x}_t$. \nIn a way, this is already the case in the examples considered, i.e. even if one assumes that the particle density is sufficient for the reconstruction of particle variables $\\boldsymbol{x}_t$, the $\\boldsymbol{X}$ that we employ are based on a discretization of this density which unavoidably implies some information loss.\nNevertheless, we recognize that for a lot of applications or observables,  increased predictive uncertainty  could constitute predictions irrelevant or impractical and  reduce the utility of the method proposed. An option that we also mention in the Conclusions is to include (some of) the $\\boldsymbol{z}_t$ in the decoder. We note though that  increasing the inputs of the decoder complicates the associated map and unavoidably would increase the amount of training data needed. An option we are exploring is to use only  a small number of features of $\\boldsymbol{z}_t$ which are identified by sparsity-enforcing priors.  We would be happy to expand on the technical aspects, if the reviewer requests it."}, "signatures": ["ICLR.cc/2021/Conference/Paper3030/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper3030/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Physics-aware, probabilistic model order reduction with guaranteed stability", "authorids": ["~Sebastian_Kaltenbach1", "~Phaedon_Stelios_Koutsourelakis1"], "authors": ["Sebastian Kaltenbach", "Phaedon Stelios Koutsourelakis"], "keywords": ["inductive bias", "probabilistic generative models", "state-space models", "model order reduction", "slowness", "long-term stability"], "abstract": "Given (small amounts of) time-series' data from  a high-dimensional, fine-grained, multiscale dynamical system, we propose a generative framework for learning an effective, lower-dimensional, coarse-grained dynamical model that is predictive of the fine-grained system's long-term evolution but also of its behavior under different initial conditions.\nWe target fine-grained models as they arise in physical applications (e.g. molecular dynamics, agent-based models), the dynamics  of which are strongly non-stationary but their transition to equilibrium is governed by unknown slow processes which are largely inaccessible by brute-force simulations.\nApproaches based on domain knowledge heavily rely on physical insight in identifying temporally slow features and fail to enforce the long-term stability of the learned dynamics. On the other hand, purely statistical frameworks lack interpretability and rely on large amounts of expensive simulation data (long and multiple trajectories) as they cannot infuse domain knowledge. \nThe generative framework proposed achieves  the aforementioned desiderata by  employing a flexible prior on the complex plane for the latent, slow processes, and  an intermediate layer of physics-motivated latent variables that reduces reliance on data and imbues inductive bias. In contrast to existing schemes, it does not require  the a priori definition of projection operators from the fine-grained description and addresses simultaneously the tasks of dimensionality reduction and model estimation.\nWe demonstrate its efficacy and accuracy in multiscale physical systems of particle dynamics where probabilistic, long-term predictions of phenomena not contained in the training data are produced.", "one-sentence_summary": "We propose a novel physics-aware, generative, probabilistic state-space model for learning an effective, lower-dimensional description that can produce long-term predictions.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "kaltenbach|physicsaware_probabilistic_model_order_reduction_with_guaranteed_stability", "pdf": "/pdf/0dbc13eb90ca0605840fb7ee708d76db95df9cbd.pdf", "venue": "ICLR 2021 Poster", "venueid": "ICLR.cc/2021/Conference", "_bibtex": "@inproceedings{\nkaltenbach2021physicsaware,\ntitle={Physics-aware, probabilistic model order reduction with guaranteed stability},\nauthor={Sebastian Kaltenbach and Phaedon Stelios Koutsourelakis},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=vyY0jnWG-tK}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "vyY0jnWG-tK", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper3030/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper3030/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper3030/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper3030/Authors|ICLR.cc/2021/Conference/Paper3030/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper3030/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923841909, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper3030/-/Official_Comment"}}}, {"id": "iujFumXoUAa", "original": null, "number": 8, "cdate": 1605700823528, "ddate": null, "tcdate": 1605700823528, "tmdate": 1605700823528, "tddate": null, "forum": "vyY0jnWG-tK", "replyto": "iQRRZKI1aW6", "invitation": "ICLR.cc/2021/Conference/Paper3030/-/Official_Comment", "content": {"title": "Response to Reviewer 5", "comment": "We would like to thank R5 for recognizing the paper's strong points and the suggestions for improving it.\n\n1. It is true that on occasion and in our attempt to fit everything in the space allowed, a lot of the details and explanations are compromised. This has hopefully been in large-part improved in the updated version of the main text as well as in the pre-existing and new Appendices. The real-part of the complex-valued model parameters $\\lambda_j$ is responsible for  the rate of time decay whereas the imaginary-part for the harmonic fluctuations. We have added expanded explanations in Appendix B with regards to the properties of these processes as well as a justification for the parameter choices. \nTo demonstrate the utility of the extension in the  complex domain, we have added in Appendix H.1 the results obtained by  a method that makes use only of  real-valued variables. \n\n\n2. We would like to clarify the fine-scale model  and the associated observables. The system consists of single-species, interacting particles. The label of each particle is not important as they are indistinguishable. Predictions of interest pertain to first-, second- and higher-order interaction statistics such as the ones reported in the main text and in Appendix F. The likelihood model should therefore possess permutation-invariance. This is achieved with the choice of physically-motivated variables $\\boldsymbol{X}$ i.e. the discretized particle density and the multinomial distribution.\nWe have updated the text to indicate this more clearly and moved the details  of the numerical experiments to the main text.\n\n3. The (prior) dynamics of the latent processes $z_{t,j}$ are explained in more more detail in the expanded Appendix B and the choice of parameters is justified. We have added numerical illustrations in the new  Appendix H where we demonstrate that fitting a flexible dynamical model (even when retaining the physically-motivated variables $\\boldsymbol{X}$) can lead to good short-term predictions but in the longer time-horizon can fail dramatically leading to \"unphysical\" predictions. This could also be problematic when the trained model is used to make predictions with new initial conditions where the chaotic nature of the nonlinear dynamics can lead to significant errors even for shorter time horizons. \n\n\n- We have also included comparisons with variations of the method where the latent variables $\\boldsymbol{z}_t$ lie  on the real-axis instead of the complex-plane as well as with deterministic and probabilistic  Koopman-based methods. We note that the latter generally require the definition of an encoder in order to identify some feature functions (also called, observables) and an associated finite-dimensional approximation of the Koopman operator. This gives rise to slew of model selection issues which we circumvent in our implementation with a fully generative model in which case the aforementioned encoder  becomes that posterior that is learned consistently with the decoder.  In the same settings illustrated in the main text and for the same amount of training data, we observe that the aforementioned alternatives produce predictive estimates of reduced accuracy and cannot capture the equilibrium density of the system. We hope that the results provided constitute sufficient evidence of the requested ablations.\n\n\n\n- Clarification: Predictions are obtained by using MAP estimates of the parameters $\\theta$ but the (approximate) posteriors of state-variables $\\boldsymbol{z}_t, \\boldsymbol{X}_t$. We refer to this formulation as a hybrid  Bayesian approach as we do not infer the whole posterior of the model parameters $\\boldsymbol{\\theta}$.\n\n- Additional feedback: We have attempted to clarify such definitions in order to make the paper accessible to as wide of an audience as possible. We  thank the reviewer  for pointing out the typos."}, "signatures": ["ICLR.cc/2021/Conference/Paper3030/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper3030/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Physics-aware, probabilistic model order reduction with guaranteed stability", "authorids": ["~Sebastian_Kaltenbach1", "~Phaedon_Stelios_Koutsourelakis1"], "authors": ["Sebastian Kaltenbach", "Phaedon Stelios Koutsourelakis"], "keywords": ["inductive bias", "probabilistic generative models", "state-space models", "model order reduction", "slowness", "long-term stability"], "abstract": "Given (small amounts of) time-series' data from  a high-dimensional, fine-grained, multiscale dynamical system, we propose a generative framework for learning an effective, lower-dimensional, coarse-grained dynamical model that is predictive of the fine-grained system's long-term evolution but also of its behavior under different initial conditions.\nWe target fine-grained models as they arise in physical applications (e.g. molecular dynamics, agent-based models), the dynamics  of which are strongly non-stationary but their transition to equilibrium is governed by unknown slow processes which are largely inaccessible by brute-force simulations.\nApproaches based on domain knowledge heavily rely on physical insight in identifying temporally slow features and fail to enforce the long-term stability of the learned dynamics. On the other hand, purely statistical frameworks lack interpretability and rely on large amounts of expensive simulation data (long and multiple trajectories) as they cannot infuse domain knowledge. \nThe generative framework proposed achieves  the aforementioned desiderata by  employing a flexible prior on the complex plane for the latent, slow processes, and  an intermediate layer of physics-motivated latent variables that reduces reliance on data and imbues inductive bias. In contrast to existing schemes, it does not require  the a priori definition of projection operators from the fine-grained description and addresses simultaneously the tasks of dimensionality reduction and model estimation.\nWe demonstrate its efficacy and accuracy in multiscale physical systems of particle dynamics where probabilistic, long-term predictions of phenomena not contained in the training data are produced.", "one-sentence_summary": "We propose a novel physics-aware, generative, probabilistic state-space model for learning an effective, lower-dimensional description that can produce long-term predictions.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "kaltenbach|physicsaware_probabilistic_model_order_reduction_with_guaranteed_stability", "pdf": "/pdf/0dbc13eb90ca0605840fb7ee708d76db95df9cbd.pdf", "venue": "ICLR 2021 Poster", "venueid": "ICLR.cc/2021/Conference", "_bibtex": "@inproceedings{\nkaltenbach2021physicsaware,\ntitle={Physics-aware, probabilistic model order reduction with guaranteed stability},\nauthor={Sebastian Kaltenbach and Phaedon Stelios Koutsourelakis},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=vyY0jnWG-tK}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "vyY0jnWG-tK", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper3030/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper3030/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper3030/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper3030/Authors|ICLR.cc/2021/Conference/Paper3030/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper3030/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923841909, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper3030/-/Official_Comment"}}}, {"id": "f_QLrI7eDw", "original": null, "number": 7, "cdate": 1605700423477, "ddate": null, "tcdate": 1605700423477, "tmdate": 1605700423477, "tddate": null, "forum": "vyY0jnWG-tK", "replyto": "jjaRzWc6duh", "invitation": "ICLR.cc/2021/Conference/Paper3030/-/Official_Comment", "content": {"title": "Response to Reviewer 4 [continued]", "comment": "- The motivation behind the modeling assumptions for  $z_{t,j}$ is multi-fold. Firstly, the dynamics selected (i.e. $AR(1)$ or discretized  Ornstein-Uhlenbeck processes) guarantee long-term stability for all possible parameter values. Secondly, they enable an interpretable disentanglement of the underlying dynamics on the basis of their slowness. Capturing the slowest evolving features is especially important in multiscale problems as these determine the long-term evolution of the system. Finally, and while this is not explored in the paper, the simplicity of these processes would allows to readily consider continuous time versions. These would be able to handle observables at non-regular time-intervals and even invalidate the need of defining a time-step.   \nThe novel contribution of our paper in this regard consists of the extension of this processes in the complex domain. As discussed  in the expanded Appendix B, this enables us to capture harmonic effects that frequently are present in dynamics of physical systems.\nThe reviewer is right with regards to the necessary condition for negative real-parts for the parameters $\\lambda_j$. We note that in Figures 2 and 7 the horizontal axis corresponds to the real-part, and the vertical to the imaginary (we have improved the labels of these Figures). The former represents the rate of time decay whereas the latter the harmonic parts. The lack of clear distinction between slow and fast scales would not constitute a big problem. More important is in our opinion the number of latent processes $z_{t,j}$ that are needed to capture these scales. A continuous spectrum of equally-important time scales would most probably necessitate the use of several $z_{t,j}$.\nAn obvious deficiency of the proposed model is the lack of an automated procedure for determining the appropriate number of $\\boldsymbol{z}$.\nWe believe that the ELBO which provides a lower bound on the model evidence could be used to that end, but some technical aspects would need to be resolved first.\n\n\n- We have addressed and clarified all issues related to $\\sigma_j$ and their effect. In Appendix B we provide further justification for the selected values of $\\sigma_j$. \n\n- We have  added a better explanation for the complex-normal density  in the footnote as well as in Appendix A.\n\n- While the parameters $\\lambda_j$ and $\\sigma_j$ are independent of time $t$, they generally differ with $j$ i.e. each latent process $z_{t,j}$ has distinct dynamics.\n\n\n- With regards to the number of $z_{t,j}$ variables, we have noted in our experiments that additional ones are associated with very fast dynamics and capture stochastic small-scale fluctuations. While these become irrelevant in long-range predictions, they might be important for some observables (higher-order statistics in particular) and for (very) short-term predictions.\n\n\n- With regards to the physics-based variables $\\boldsymbol{X}$ and as mentioned in responses to other reviewers as well, these   necessitate the availability of  some physical knowledge about the system. \nThey constitute the necessary information bottleneck that enables us to model  very high-dimensional systems with small amounts of training  data. While such variables are usually readily available in large classes of physical problems, we recognize that this might not be the case in other contexts, e.g. financial time-series. "}, "signatures": ["ICLR.cc/2021/Conference/Paper3030/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper3030/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Physics-aware, probabilistic model order reduction with guaranteed stability", "authorids": ["~Sebastian_Kaltenbach1", "~Phaedon_Stelios_Koutsourelakis1"], "authors": ["Sebastian Kaltenbach", "Phaedon Stelios Koutsourelakis"], "keywords": ["inductive bias", "probabilistic generative models", "state-space models", "model order reduction", "slowness", "long-term stability"], "abstract": "Given (small amounts of) time-series' data from  a high-dimensional, fine-grained, multiscale dynamical system, we propose a generative framework for learning an effective, lower-dimensional, coarse-grained dynamical model that is predictive of the fine-grained system's long-term evolution but also of its behavior under different initial conditions.\nWe target fine-grained models as they arise in physical applications (e.g. molecular dynamics, agent-based models), the dynamics  of which are strongly non-stationary but their transition to equilibrium is governed by unknown slow processes which are largely inaccessible by brute-force simulations.\nApproaches based on domain knowledge heavily rely on physical insight in identifying temporally slow features and fail to enforce the long-term stability of the learned dynamics. On the other hand, purely statistical frameworks lack interpretability and rely on large amounts of expensive simulation data (long and multiple trajectories) as they cannot infuse domain knowledge. \nThe generative framework proposed achieves  the aforementioned desiderata by  employing a flexible prior on the complex plane for the latent, slow processes, and  an intermediate layer of physics-motivated latent variables that reduces reliance on data and imbues inductive bias. In contrast to existing schemes, it does not require  the a priori definition of projection operators from the fine-grained description and addresses simultaneously the tasks of dimensionality reduction and model estimation.\nWe demonstrate its efficacy and accuracy in multiscale physical systems of particle dynamics where probabilistic, long-term predictions of phenomena not contained in the training data are produced.", "one-sentence_summary": "We propose a novel physics-aware, generative, probabilistic state-space model for learning an effective, lower-dimensional description that can produce long-term predictions.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "kaltenbach|physicsaware_probabilistic_model_order_reduction_with_guaranteed_stability", "pdf": "/pdf/0dbc13eb90ca0605840fb7ee708d76db95df9cbd.pdf", "venue": "ICLR 2021 Poster", "venueid": "ICLR.cc/2021/Conference", "_bibtex": "@inproceedings{\nkaltenbach2021physicsaware,\ntitle={Physics-aware, probabilistic model order reduction with guaranteed stability},\nauthor={Sebastian Kaltenbach and Phaedon Stelios Koutsourelakis},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=vyY0jnWG-tK}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "vyY0jnWG-tK", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper3030/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper3030/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper3030/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper3030/Authors|ICLR.cc/2021/Conference/Paper3030/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper3030/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923841909, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper3030/-/Official_Comment"}}}, {"id": "CLZRb6WkZQu", "original": null, "number": 4, "cdate": 1605699692318, "ddate": null, "tcdate": 1605699692318, "tmdate": 1605699692318, "tddate": null, "forum": "vyY0jnWG-tK", "replyto": "-gbBGE2uvXi", "invitation": "ICLR.cc/2021/Conference/Paper3030/-/Official_Comment", "content": {"title": "Response to Reviewer 2", "comment": "We thank the reviewer for their comments and the positive feedback as well as for the suggestions for improving the paper.\n\n\n- We have incorporated the papers suggested into the discussion and thank the reviewer for pointing  them out.\n\n- The captions and explanations for Figures 2-3 as well as the Equations (1)-(3) have also been improved  and the  points mentioned are  hopefully more clearly presented. Additional clarifications regarding the latent dynamics of $z_{t,j}$ as well as the associated parameter choices have been added in Appendix B."}, "signatures": ["ICLR.cc/2021/Conference/Paper3030/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper3030/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Physics-aware, probabilistic model order reduction with guaranteed stability", "authorids": ["~Sebastian_Kaltenbach1", "~Phaedon_Stelios_Koutsourelakis1"], "authors": ["Sebastian Kaltenbach", "Phaedon Stelios Koutsourelakis"], "keywords": ["inductive bias", "probabilistic generative models", "state-space models", "model order reduction", "slowness", "long-term stability"], "abstract": "Given (small amounts of) time-series' data from  a high-dimensional, fine-grained, multiscale dynamical system, we propose a generative framework for learning an effective, lower-dimensional, coarse-grained dynamical model that is predictive of the fine-grained system's long-term evolution but also of its behavior under different initial conditions.\nWe target fine-grained models as they arise in physical applications (e.g. molecular dynamics, agent-based models), the dynamics  of which are strongly non-stationary but their transition to equilibrium is governed by unknown slow processes which are largely inaccessible by brute-force simulations.\nApproaches based on domain knowledge heavily rely on physical insight in identifying temporally slow features and fail to enforce the long-term stability of the learned dynamics. On the other hand, purely statistical frameworks lack interpretability and rely on large amounts of expensive simulation data (long and multiple trajectories) as they cannot infuse domain knowledge. \nThe generative framework proposed achieves  the aforementioned desiderata by  employing a flexible prior on the complex plane for the latent, slow processes, and  an intermediate layer of physics-motivated latent variables that reduces reliance on data and imbues inductive bias. In contrast to existing schemes, it does not require  the a priori definition of projection operators from the fine-grained description and addresses simultaneously the tasks of dimensionality reduction and model estimation.\nWe demonstrate its efficacy and accuracy in multiscale physical systems of particle dynamics where probabilistic, long-term predictions of phenomena not contained in the training data are produced.", "one-sentence_summary": "We propose a novel physics-aware, generative, probabilistic state-space model for learning an effective, lower-dimensional description that can produce long-term predictions.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "kaltenbach|physicsaware_probabilistic_model_order_reduction_with_guaranteed_stability", "pdf": "/pdf/0dbc13eb90ca0605840fb7ee708d76db95df9cbd.pdf", "venue": "ICLR 2021 Poster", "venueid": "ICLR.cc/2021/Conference", "_bibtex": "@inproceedings{\nkaltenbach2021physicsaware,\ntitle={Physics-aware, probabilistic model order reduction with guaranteed stability},\nauthor={Sebastian Kaltenbach and Phaedon Stelios Koutsourelakis},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=vyY0jnWG-tK}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "vyY0jnWG-tK", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper3030/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper3030/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper3030/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper3030/Authors|ICLR.cc/2021/Conference/Paper3030/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper3030/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923841909, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper3030/-/Official_Comment"}}}, {"id": "k4B4VN1XRx", "original": null, "number": 2, "cdate": 1605699433580, "ddate": null, "tcdate": 1605699433580, "tmdate": 1605699433580, "tddate": null, "forum": "vyY0jnWG-tK", "replyto": "vyY0jnWG-tK", "invitation": "ICLR.cc/2021/Conference/Paper3030/-/Official_Comment", "content": {"title": "Revised Paper Uploaded", "comment": "We would like to thank the reviewers for their valuable feedback and have incorporated their suggestions in an updated version of our paper.\nA detailed response to the reviewers' comments can be found below their reviews."}, "signatures": ["ICLR.cc/2021/Conference/Paper3030/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper3030/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Physics-aware, probabilistic model order reduction with guaranteed stability", "authorids": ["~Sebastian_Kaltenbach1", "~Phaedon_Stelios_Koutsourelakis1"], "authors": ["Sebastian Kaltenbach", "Phaedon Stelios Koutsourelakis"], "keywords": ["inductive bias", "probabilistic generative models", "state-space models", "model order reduction", "slowness", "long-term stability"], "abstract": "Given (small amounts of) time-series' data from  a high-dimensional, fine-grained, multiscale dynamical system, we propose a generative framework for learning an effective, lower-dimensional, coarse-grained dynamical model that is predictive of the fine-grained system's long-term evolution but also of its behavior under different initial conditions.\nWe target fine-grained models as they arise in physical applications (e.g. molecular dynamics, agent-based models), the dynamics  of which are strongly non-stationary but their transition to equilibrium is governed by unknown slow processes which are largely inaccessible by brute-force simulations.\nApproaches based on domain knowledge heavily rely on physical insight in identifying temporally slow features and fail to enforce the long-term stability of the learned dynamics. On the other hand, purely statistical frameworks lack interpretability and rely on large amounts of expensive simulation data (long and multiple trajectories) as they cannot infuse domain knowledge. \nThe generative framework proposed achieves  the aforementioned desiderata by  employing a flexible prior on the complex plane for the latent, slow processes, and  an intermediate layer of physics-motivated latent variables that reduces reliance on data and imbues inductive bias. In contrast to existing schemes, it does not require  the a priori definition of projection operators from the fine-grained description and addresses simultaneously the tasks of dimensionality reduction and model estimation.\nWe demonstrate its efficacy and accuracy in multiscale physical systems of particle dynamics where probabilistic, long-term predictions of phenomena not contained in the training data are produced.", "one-sentence_summary": "We propose a novel physics-aware, generative, probabilistic state-space model for learning an effective, lower-dimensional description that can produce long-term predictions.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "kaltenbach|physicsaware_probabilistic_model_order_reduction_with_guaranteed_stability", "pdf": "/pdf/0dbc13eb90ca0605840fb7ee708d76db95df9cbd.pdf", "venue": "ICLR 2021 Poster", "venueid": "ICLR.cc/2021/Conference", "_bibtex": "@inproceedings{\nkaltenbach2021physicsaware,\ntitle={Physics-aware, probabilistic model order reduction with guaranteed stability},\nauthor={Sebastian Kaltenbach and Phaedon Stelios Koutsourelakis},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=vyY0jnWG-tK}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "vyY0jnWG-tK", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper3030/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper3030/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper3030/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper3030/Authors|ICLR.cc/2021/Conference/Paper3030/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper3030/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923841909, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper3030/-/Official_Comment"}}}, {"id": "ny1lA_xqjMF", "original": null, "number": 2, "cdate": 1603804735449, "ddate": null, "tcdate": 1603804735449, "tmdate": 1605024082363, "tddate": null, "forum": "vyY0jnWG-tK", "replyto": "vyY0jnWG-tK", "invitation": "ICLR.cc/2021/Conference/Paper3030/-/Official_Review", "content": {"title": "Good ideas - weak applications - several points to be improved", "review": "\nThis paper proposes a new dimensional reduction scheme, based on a latent representation, using a generative model and variational inference.\n\nThe method is successfully applied to 2 simple one-dimensional physical processes, for which the macroscopic equations are known from the physics literature.\n\nChoosing only a couple of simple physical variables X (as far as I understand, here it's the density in binned areas of the domain), and an arbitrary number (5) of latent variables (here we see that 5 is enough because it captures all the slow degrees of freedom), the model is able to learn the slow-variables values (eigenvalues controlling the evolution of the macroscopic variables) and then correctly reproduce the long-time behavior of the macroscopic observables (the X), and additionally produce realistic noise (x) / realistic microscopic fluctuations (this last part is not very clear, I am guessing here).\nIn addition, the latent representation of previously unseen initial conditions can be inferred (with decent error bars), allowing to predict the future of unseen initial trajectories.\n\n\nOverall, the idea is interesting and supported by correct mathematical derivations and experimental proofs of concept.\n\nThus I lean on accepting the paper.\n\n\nHowever, I have some questions and remarks that I would like to be addressed.\n\n\nMy main criticism would be the following: the paper does not use any pre-existing benchmarks, which makes accuracy comparisons essentially impossible.\nOf course one may object that the novelty of the approach makes comparison impossible, however I think that it should be possible to re-implement State of the art methods (by the way I appreciated the literature review section), and show how much the new method deals well with smallish data sets (which I believe it does ?).\n\nMy second main criticism is that although the method is general and in principle applicable to complex problems, here it is applied to textbook cases, for which the exact macroscopic equations are known, and for which a mechanically stable state is reached in finite time, in other words, two very simple problems. (although if I recall well the equations (26), (27) do not allow a simple diagonal form in the style of (21)).\nThe simplicity of the problems attacked is seen also in the important (but hidden) remark, that equation (25) is sufficient to produce x, and that \"no parameters need to be learned for p(x_t|X_t)\".\nWhat would happen for more complicated problems ? (e.g. protein folding, even in the case of small molecules like butane (C2H6 if I recall is a simple standard)? )\nIn particular, if the true number of \"independent\" components (number of lambda's) needed was very large ?\n\n\nAlso I have a trivial question, that however I think needs to be discussed in the paper. What is the error on the prediction of the microscopic positions of the {x} variables (the elementary particles) ? My guess is that by construction, the generative model has a 100% error (as good as random, I mean), because it does not track the future of individual particles, but rather predicts the future of the large-scale, slowly-evolving coarse-grained variables (X, governed by the latent z's).\nAm I correct ? I think it may be worth mentioning that quickly, for the readers that are unfamiliar with the topic.\nIf I am completely wrong, it is then even more worth mentioning the accuracy of x(t+P) predictions.\n\nI did not understand why section H of appendix was not part of the main text. It seems quite central to be able to forecast unseen initial conditions, and not just the future of already seen trajectories.\n\n\n\n\nLess important remarks about how the paper presents the research:\n\nsec 2.2 : additional intuitive explanation about how the learning is performed would be welcomed.\nIt is not clear to the unfamiliar reader as to how learning proceeds.\nIt seems to me that you directly learned the parameters of the joint probability distribution, which is quite factored, as you showed in Eq. (8), but needs Variational Inference methods to be solved for. What I don't see clearly is the shape of q_\\phi, or rather, what it means for B to be bi-diagonal. Maybe you could explain which variables are connected with which, given your assumptions on B_\\phi.\nAlso, after reading Appendix , Figure 9 and 11 could be compressed and included in the main text, or at least referred to explicitly.\n\nA number of graphs are un-readable, in particular the x- and y-axis labels are so tiny that one cannot get what is plotted against what.\nPlease correct that, increasing both figure size and x/y-labels sizes.\n\n\n-------\na couple of detailed remarks:\n\nIn Fig 13-16, the central plot does not have a colorbar. Is it because it's exactly the same as for the left plot ? If so, mention it or center the colorbar in a visually suggestive way\n\ntypo: \"is is\" (search it)\n\n", "rating": "7: Good paper, accept", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["ICLR.cc/2021/Conference/Paper3030/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper3030/AnonReviewer3"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Physics-aware, probabilistic model order reduction with guaranteed stability", "authorids": ["~Sebastian_Kaltenbach1", "~Phaedon_Stelios_Koutsourelakis1"], "authors": ["Sebastian Kaltenbach", "Phaedon Stelios Koutsourelakis"], "keywords": ["inductive bias", "probabilistic generative models", "state-space models", "model order reduction", "slowness", "long-term stability"], "abstract": "Given (small amounts of) time-series' data from  a high-dimensional, fine-grained, multiscale dynamical system, we propose a generative framework for learning an effective, lower-dimensional, coarse-grained dynamical model that is predictive of the fine-grained system's long-term evolution but also of its behavior under different initial conditions.\nWe target fine-grained models as they arise in physical applications (e.g. molecular dynamics, agent-based models), the dynamics  of which are strongly non-stationary but their transition to equilibrium is governed by unknown slow processes which are largely inaccessible by brute-force simulations.\nApproaches based on domain knowledge heavily rely on physical insight in identifying temporally slow features and fail to enforce the long-term stability of the learned dynamics. On the other hand, purely statistical frameworks lack interpretability and rely on large amounts of expensive simulation data (long and multiple trajectories) as they cannot infuse domain knowledge. \nThe generative framework proposed achieves  the aforementioned desiderata by  employing a flexible prior on the complex plane for the latent, slow processes, and  an intermediate layer of physics-motivated latent variables that reduces reliance on data and imbues inductive bias. In contrast to existing schemes, it does not require  the a priori definition of projection operators from the fine-grained description and addresses simultaneously the tasks of dimensionality reduction and model estimation.\nWe demonstrate its efficacy and accuracy in multiscale physical systems of particle dynamics where probabilistic, long-term predictions of phenomena not contained in the training data are produced.", "one-sentence_summary": "We propose a novel physics-aware, generative, probabilistic state-space model for learning an effective, lower-dimensional description that can produce long-term predictions.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "kaltenbach|physicsaware_probabilistic_model_order_reduction_with_guaranteed_stability", "pdf": "/pdf/0dbc13eb90ca0605840fb7ee708d76db95df9cbd.pdf", "venue": "ICLR 2021 Poster", "venueid": "ICLR.cc/2021/Conference", "_bibtex": "@inproceedings{\nkaltenbach2021physicsaware,\ntitle={Physics-aware, probabilistic model order reduction with guaranteed stability},\nauthor={Sebastian Kaltenbach and Phaedon Stelios Koutsourelakis},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=vyY0jnWG-tK}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq . ***Please remember to file the Code-of-Ethics report. Once you submitted the review, a link to the report will be visible in the bottom right corner of your review.***", "required": true, "markdown": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}, "forum": "vyY0jnWG-tK", "replyto": "vyY0jnWG-tK", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"], "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper3030/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1607428800000, "duedate": 1606752000000, "multiReply": false, "readers": ["everyone"], "tcdate": 1602538083728, "tmdate": 1606915795948, "super": "ICLR.cc/2021/Conference/-/Official_Review", "signatures": ["OpenReview.net"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Paper3030/Reviewers", "OpenReview.net/Support"], "id": "ICLR.cc/2021/Conference/Paper3030/-/Official_Review"}}}, {"id": "nDAEBjmLAQI", "original": null, "number": 3, "cdate": 1603938202095, "ddate": null, "tcdate": 1603938202095, "tmdate": 1605024082303, "tddate": null, "forum": "vyY0jnWG-tK", "replyto": "vyY0jnWG-tK", "invitation": "ICLR.cc/2021/Conference/Paper3030/-/Official_Review", "content": {"title": "Nice way of combining physics", "review": "This paper presents a generative state-space model using two layers of latent variables. The latent variables in the first layer aim to capture long-term dynamics and ensures the stability. The variables in the second layer are physical variables. The authors have shown some promising results in modeling particle dynamics.  \n\nSince the authors claim that the use of X can reduce the complexity/the search space of the learning model, it would be great if the authors can show how the performance change given different number of training samples. \n\nAnother issue is about the effectiveness of this model in simulating real-world physical phenomena. This method can work well on simulated dataset because simulated data always follow the dependencies between X and x (as the simulator is built based on these rules). Real-world physical systems can be complex and usually we do not know exactly the governing physical variables (X). It would be great to discuss whether the proposed method allows some flexibility to automatically discover these unknown physical variables.\n", "rating": "6: Marginally above acceptance threshold", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}, "signatures": ["ICLR.cc/2021/Conference/Paper3030/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper3030/AnonReviewer1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Physics-aware, probabilistic model order reduction with guaranteed stability", "authorids": ["~Sebastian_Kaltenbach1", "~Phaedon_Stelios_Koutsourelakis1"], "authors": ["Sebastian Kaltenbach", "Phaedon Stelios Koutsourelakis"], "keywords": ["inductive bias", "probabilistic generative models", "state-space models", "model order reduction", "slowness", "long-term stability"], "abstract": "Given (small amounts of) time-series' data from  a high-dimensional, fine-grained, multiscale dynamical system, we propose a generative framework for learning an effective, lower-dimensional, coarse-grained dynamical model that is predictive of the fine-grained system's long-term evolution but also of its behavior under different initial conditions.\nWe target fine-grained models as they arise in physical applications (e.g. molecular dynamics, agent-based models), the dynamics  of which are strongly non-stationary but their transition to equilibrium is governed by unknown slow processes which are largely inaccessible by brute-force simulations.\nApproaches based on domain knowledge heavily rely on physical insight in identifying temporally slow features and fail to enforce the long-term stability of the learned dynamics. On the other hand, purely statistical frameworks lack interpretability and rely on large amounts of expensive simulation data (long and multiple trajectories) as they cannot infuse domain knowledge. \nThe generative framework proposed achieves  the aforementioned desiderata by  employing a flexible prior on the complex plane for the latent, slow processes, and  an intermediate layer of physics-motivated latent variables that reduces reliance on data and imbues inductive bias. In contrast to existing schemes, it does not require  the a priori definition of projection operators from the fine-grained description and addresses simultaneously the tasks of dimensionality reduction and model estimation.\nWe demonstrate its efficacy and accuracy in multiscale physical systems of particle dynamics where probabilistic, long-term predictions of phenomena not contained in the training data are produced.", "one-sentence_summary": "We propose a novel physics-aware, generative, probabilistic state-space model for learning an effective, lower-dimensional description that can produce long-term predictions.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "kaltenbach|physicsaware_probabilistic_model_order_reduction_with_guaranteed_stability", "pdf": "/pdf/0dbc13eb90ca0605840fb7ee708d76db95df9cbd.pdf", "venue": "ICLR 2021 Poster", "venueid": "ICLR.cc/2021/Conference", "_bibtex": "@inproceedings{\nkaltenbach2021physicsaware,\ntitle={Physics-aware, probabilistic model order reduction with guaranteed stability},\nauthor={Sebastian Kaltenbach and Phaedon Stelios Koutsourelakis},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=vyY0jnWG-tK}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq . ***Please remember to file the Code-of-Ethics report. Once you submitted the review, a link to the report will be visible in the bottom right corner of your review.***", "required": true, "markdown": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}, "forum": "vyY0jnWG-tK", "replyto": "vyY0jnWG-tK", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"], "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper3030/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1607428800000, "duedate": 1606752000000, "multiReply": false, "readers": ["everyone"], "tcdate": 1602538083728, "tmdate": 1606915795948, "super": "ICLR.cc/2021/Conference/-/Official_Review", "signatures": ["OpenReview.net"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Paper3030/Reviewers", "OpenReview.net/Support"], "id": "ICLR.cc/2021/Conference/Paper3030/-/Official_Review"}}}, {"id": "-gbBGE2uvXi", "original": null, "number": 4, "cdate": 1603969874624, "ddate": null, "tcdate": 1603969874624, "tmdate": 1605024082232, "tddate": null, "forum": "vyY0jnWG-tK", "replyto": "vyY0jnWG-tK", "invitation": "ICLR.cc/2021/Conference/Paper3030/-/Official_Review", "content": {"title": "Interesting paper. But some parts can be improved.", "review": "This is a good paper, in my opinion. I have some suggestion to improve the quality of the work.\nSee below.\n\n - I suggest to improve Section 3, open a bit the range of references,  considering general and relevant works such as\n \nC. Grigo et al. A physics-aware, probabilistic machine learning framework for coarse-graining high-dimensional systems in the Small Data regime\narXiv:1902.03968, 2019.\n\nG. Camps-Valls, et al. \"Physics-Aware Gaussian Processes in Remote Sensing\", Applied Soft Computing, Volume 28, Pages: 69-82, 2018.\n\nSungyong Seo et al. \"Physics-aware Difference Graph Networks for Sparsely-Observed Dynamics\",  ICLR 2020,\n\n- Explain better figure 2, improving its caption.\n\n- Figure 3 is completely unclear, remove it or improve.\n\n- Please explain better your system in Eqs (1)-(2)-(3). What are the measurements/observations? what is your inference goal? please clearer state these points.\n", "rating": "7: Good paper, accept", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "signatures": ["ICLR.cc/2021/Conference/Paper3030/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper3030/AnonReviewer2"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Physics-aware, probabilistic model order reduction with guaranteed stability", "authorids": ["~Sebastian_Kaltenbach1", "~Phaedon_Stelios_Koutsourelakis1"], "authors": ["Sebastian Kaltenbach", "Phaedon Stelios Koutsourelakis"], "keywords": ["inductive bias", "probabilistic generative models", "state-space models", "model order reduction", "slowness", "long-term stability"], "abstract": "Given (small amounts of) time-series' data from  a high-dimensional, fine-grained, multiscale dynamical system, we propose a generative framework for learning an effective, lower-dimensional, coarse-grained dynamical model that is predictive of the fine-grained system's long-term evolution but also of its behavior under different initial conditions.\nWe target fine-grained models as they arise in physical applications (e.g. molecular dynamics, agent-based models), the dynamics  of which are strongly non-stationary but their transition to equilibrium is governed by unknown slow processes which are largely inaccessible by brute-force simulations.\nApproaches based on domain knowledge heavily rely on physical insight in identifying temporally slow features and fail to enforce the long-term stability of the learned dynamics. On the other hand, purely statistical frameworks lack interpretability and rely on large amounts of expensive simulation data (long and multiple trajectories) as they cannot infuse domain knowledge. \nThe generative framework proposed achieves  the aforementioned desiderata by  employing a flexible prior on the complex plane for the latent, slow processes, and  an intermediate layer of physics-motivated latent variables that reduces reliance on data and imbues inductive bias. In contrast to existing schemes, it does not require  the a priori definition of projection operators from the fine-grained description and addresses simultaneously the tasks of dimensionality reduction and model estimation.\nWe demonstrate its efficacy and accuracy in multiscale physical systems of particle dynamics where probabilistic, long-term predictions of phenomena not contained in the training data are produced.", "one-sentence_summary": "We propose a novel physics-aware, generative, probabilistic state-space model for learning an effective, lower-dimensional description that can produce long-term predictions.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "kaltenbach|physicsaware_probabilistic_model_order_reduction_with_guaranteed_stability", "pdf": "/pdf/0dbc13eb90ca0605840fb7ee708d76db95df9cbd.pdf", "venue": "ICLR 2021 Poster", "venueid": "ICLR.cc/2021/Conference", "_bibtex": "@inproceedings{\nkaltenbach2021physicsaware,\ntitle={Physics-aware, probabilistic model order reduction with guaranteed stability},\nauthor={Sebastian Kaltenbach and Phaedon Stelios Koutsourelakis},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=vyY0jnWG-tK}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq . ***Please remember to file the Code-of-Ethics report. Once you submitted the review, a link to the report will be visible in the bottom right corner of your review.***", "required": true, "markdown": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}, "forum": "vyY0jnWG-tK", "replyto": "vyY0jnWG-tK", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"], "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper3030/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1607428800000, "duedate": 1606752000000, "multiReply": false, "readers": ["everyone"], "tcdate": 1602538083728, "tmdate": 1606915795948, "super": "ICLR.cc/2021/Conference/-/Official_Review", "signatures": ["OpenReview.net"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Paper3030/Reviewers", "OpenReview.net/Support"], "id": "ICLR.cc/2021/Conference/Paper3030/-/Official_Review"}}}], "count": 14}