{"notes": [{"id": "HyxG3p4twS", "original": "BygZBayuPS", "number": 772, "cdate": 1569439145539, "ddate": null, "tcdate": 1569439145539, "tmdate": 1583912049231, "tddate": null, "forum": "HyxG3p4twS", "replyto": null, "invitation": "ICLR.cc/2020/Conference/-/Blind_Submission", "content": {"title": "Quantifying the Cost of Reliable Photo Authentication via High-Performance Learned Lossy Representations", "authors": ["Pawel Korus", "Nasir Memon"], "authorids": ["pkorus@nyu.edu", "memon@nyu.edu"], "keywords": ["image forensics", "photo manipulation detection", "learned compression", "lossy compression", "image compression", "entropy estimation"], "TL;DR": "We learn an efficient lossy image codec that can be optimized to facilitate reliable photo manipulation detection at fractional cost in payload/quality and even at low bitrates.", "abstract": "Detection of photo manipulation relies on subtle statistical traces, notoriously removed by aggressive lossy compression employed online. We demonstrate that end-to-end modeling of complex photo dissemination channels allows for codec optimization with explicit provenance objectives. We design a lightweight trainable lossy image codec, that delivers competitive rate-distortion performance, on par with best hand-engineered alternatives, but has lower computational footprint on modern GPU-enabled platforms. Our results show that significant improvements in manipulation detection accuracy are possible at fractional costs in bandwidth/storage. Our codec improved the accuracy from 37% to 86% even at very low bit-rates, well below the practicality of JPEG (QF 20). ", "pdf": "/pdf/32e1296b257a0494d8ad34f00f7f657df8ab9455.pdf", "paperhash": "korus|quantifying_the_cost_of_reliable_photo_authentication_via_highperformance_learned_lossy_representations", "code": "https://github.com/pkorus/neural-imaging", "_bibtex": "@inproceedings{\nKorus2020Quantifying,\ntitle={Quantifying the Cost of Reliable Photo Authentication via High-Performance Learned Lossy Representations},\nauthor={Pawel Korus and Nasir Memon},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=HyxG3p4twS}\n}", "full_presentation_video": "", "original_pdf": "/attachment/640ac77bdbf38b9b7d6efb37744f5b62213a760a.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "signatures": ["ICLR.cc/2020/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference"], "details": {"replyCount": 7, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"reply": {"readers": {"values-regex": ".*"}, "writers": {"values": ["ICLR.cc/2020/Conference"]}, "signatures": {"values": ["ICLR.cc/2020/Conference"]}, "content": {"spotlight_video": {"value-regex": ".*"}, "full_presentation_video": {"value-regex": ".*"}, "original_pdf": {"required": false, "description": "Upload a PDF file that ends with .pdf", "value-regex": ".*"}, "appendix": {"value-regex": ".*"}, "authorids": {"values-regex": ".*"}, "poster": {"value-regex": ".*"}, "authors": {"values": ["Anonymous"]}, "slides": {"value-regex": ".*"}}}, "final": [], "signatures": ["ICLR.cc/2020/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference"], "noninvitees": [], "tcdate": 1569271260237, "tmdate": 1593459412141, "id": "ICLR.cc/2020/Conference/-/Blind_Submission"}}, "tauthor": "ICLR.cc/2020/Conference"}, {"id": "jNm-GJX8vd", "original": null, "number": 1, "cdate": 1576798705639, "ddate": null, "tcdate": 1576798705639, "tmdate": 1576800930496, "tddate": null, "forum": "HyxG3p4twS", "replyto": "HyxG3p4twS", "invitation": "ICLR.cc/2020/Conference/Paper772/-/Decision", "content": {"decision": "Accept (Poster)", "comment": "The paper introduces a new image compression approach that preserves the patterns indicating image manipulation. The reviewers appreciate the idea and the method. Please take into account the suggestions of Reviewer1, when preparing the final version.", "title": "Paper Decision"}, "signatures": ["ICLR.cc/2020/Conference/Program_Chairs"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Program_Chairs"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Quantifying the Cost of Reliable Photo Authentication via High-Performance Learned Lossy Representations", "authors": ["Pawel Korus", "Nasir Memon"], "authorids": ["pkorus@nyu.edu", "memon@nyu.edu"], "keywords": ["image forensics", "photo manipulation detection", "learned compression", "lossy compression", "image compression", "entropy estimation"], "TL;DR": "We learn an efficient lossy image codec that can be optimized to facilitate reliable photo manipulation detection at fractional cost in payload/quality and even at low bitrates.", "abstract": "Detection of photo manipulation relies on subtle statistical traces, notoriously removed by aggressive lossy compression employed online. We demonstrate that end-to-end modeling of complex photo dissemination channels allows for codec optimization with explicit provenance objectives. We design a lightweight trainable lossy image codec, that delivers competitive rate-distortion performance, on par with best hand-engineered alternatives, but has lower computational footprint on modern GPU-enabled platforms. Our results show that significant improvements in manipulation detection accuracy are possible at fractional costs in bandwidth/storage. Our codec improved the accuracy from 37% to 86% even at very low bit-rates, well below the practicality of JPEG (QF 20). ", "pdf": "/pdf/32e1296b257a0494d8ad34f00f7f657df8ab9455.pdf", "paperhash": "korus|quantifying_the_cost_of_reliable_photo_authentication_via_highperformance_learned_lossy_representations", "code": "https://github.com/pkorus/neural-imaging", "_bibtex": "@inproceedings{\nKorus2020Quantifying,\ntitle={Quantifying the Cost of Reliable Photo Authentication via High-Performance Learned Lossy Representations},\nauthor={Pawel Korus and Nasir Memon},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=HyxG3p4twS}\n}", "full_presentation_video": "", "original_pdf": "/attachment/640ac77bdbf38b9b7d6efb37744f5b62213a760a.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "tags": [], "invitation": {"reply": {"writers": {"description": "How your identity will be displayed.", "values-regex": ["ICLR.cc/2020/Conference/Program_Chairs"]}, "signatures": {"values": ["ICLR.cc/2020/Conference/Program_Chairs"], "description": "How your identity will be displayed."}, "content": {"decision": {"value-radio": ["Accept (Spotlight)", "Accept (Talk)", "Accept (Poster)", "Reject"], "description": "Decision", "required": true, "order": 2}, "title": {"value": "Paper Decision", "required": true, "order": 1}, "comment": {"value-regex": "[\\S\\s]{0,5000}", "description": "", "required": false, "order": 3}}, "forum": "HyxG3p4twS", "replyto": "HyxG3p4twS", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}}, "expdate": 1576854540000, "duedate": 1576853940000, "multiReply": false, "readers": ["everyone"], "invitees": ["ICLR.cc/2020/Conference/Program_Chairs"], "tcdate": 1576795716712, "tmdate": 1576800266915, "super": "ICLR.cc/2020/Conference/-/Decision", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper772/-/Decision"}}}, {"id": "Bygdj379iB", "original": null, "number": 3, "cdate": 1573694624139, "ddate": null, "tcdate": 1573694624139, "tmdate": 1573694624139, "tddate": null, "forum": "HyxG3p4twS", "replyto": "H1l-LJJAKS", "invitation": "ICLR.cc/2020/Conference/Paper772/-/Official_Comment", "content": {"title": "Response to Reviewer #2", "comment": "Thank you for your comments. "}, "signatures": ["ICLR.cc/2020/Conference/Paper772/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper772/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Quantifying the Cost of Reliable Photo Authentication via High-Performance Learned Lossy Representations", "authors": ["Pawel Korus", "Nasir Memon"], "authorids": ["pkorus@nyu.edu", "memon@nyu.edu"], "keywords": ["image forensics", "photo manipulation detection", "learned compression", "lossy compression", "image compression", "entropy estimation"], "TL;DR": "We learn an efficient lossy image codec that can be optimized to facilitate reliable photo manipulation detection at fractional cost in payload/quality and even at low bitrates.", "abstract": "Detection of photo manipulation relies on subtle statistical traces, notoriously removed by aggressive lossy compression employed online. We demonstrate that end-to-end modeling of complex photo dissemination channels allows for codec optimization with explicit provenance objectives. We design a lightweight trainable lossy image codec, that delivers competitive rate-distortion performance, on par with best hand-engineered alternatives, but has lower computational footprint on modern GPU-enabled platforms. Our results show that significant improvements in manipulation detection accuracy are possible at fractional costs in bandwidth/storage. Our codec improved the accuracy from 37% to 86% even at very low bit-rates, well below the practicality of JPEG (QF 20). ", "pdf": "/pdf/32e1296b257a0494d8ad34f00f7f657df8ab9455.pdf", "paperhash": "korus|quantifying_the_cost_of_reliable_photo_authentication_via_highperformance_learned_lossy_representations", "code": "https://github.com/pkorus/neural-imaging", "_bibtex": "@inproceedings{\nKorus2020Quantifying,\ntitle={Quantifying the Cost of Reliable Photo Authentication via High-Performance Learned Lossy Representations},\nauthor={Pawel Korus and Nasir Memon},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=HyxG3p4twS}\n}", "full_presentation_video": "", "original_pdf": "/attachment/640ac77bdbf38b9b7d6efb37744f5b62213a760a.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "HyxG3p4twS", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper772/Authors", "ICLR.cc/2020/Conference/Paper772/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper772/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper772/Reviewers", "ICLR.cc/2020/Conference/Paper772/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper772/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper772/Authors|ICLR.cc/2020/Conference/Paper772/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504166456, "tmdate": 1576860532961, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper772/Authors", "ICLR.cc/2020/Conference/Paper772/Reviewers", "ICLR.cc/2020/Conference/Paper772/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper772/-/Official_Comment"}}}, {"id": "rkgpVnXqiB", "original": null, "number": 2, "cdate": 1573694517118, "ddate": null, "tcdate": 1573694517118, "tmdate": 1573694517118, "tddate": null, "forum": "HyxG3p4twS", "replyto": "BJeC0l9yjS", "invitation": "ICLR.cc/2020/Conference/Paper772/-/Official_Comment", "content": {"title": "Response to Reviewer #4", "comment": "Thank you for detailed comments. \n\nOur setup involves a forensic analysis network which learns to distinguish basic image manipulations. This corresponds to a well-established foundational test scenario, which can later be built upon to deliver practical manipulation detection algorithms. Once the model learns to distinguish different image processing paths, it will respond differently to content coming from different sources. For example, if an object is inserted or removed from a photo, that region is likely to solicit a different response than the rest of the image. An anomaly detection scheme then then be used to precisely detect and pin-point the manipulation. For a state-of-the-art system built upon this principle, we can refer readers to a recent work from CVPR [1].\n\nRegarding, Fig. 5 and Fig. 8, although there is some conceptual overlap, each figure is self-sufficient and should be viewed independently. Fig. 5 shows the standard rate-distortion trade-off for the baseline DCN model as well as standard hand-crafted codecs. Fig. 8 aims to show a more complex trade-off between rate, distortion, and forensic analysis accuracy. The main goal is to show the impact of optimization for forensic analysis at different levels of its importance. Fig. 5 can be compared with Fig. A6 which uses the same protocol and shows the same codecs using the same colors. \n\nWe agree that in principle we cannot prove that more reliable detection for JPEG image is not possible. However, the forensic analysis network that we used was developed for and tested on JPEG images [2]. Due to their prevalence, forensic analysis of JPEG images is well investigated. Hence, we can assume that the accuracy we observe is a good proxy for the upper bound on the achievable classification performance. We did not perform any compression-specific tweaks and used exactly the same model in all cases.\n\nThank you for the suggestion. We have included MS-SSIM results in the current manuscript (Figures A.5 and A.6). We agree that performing a user study would be valuable. We leave this evaluation for future work.\n\nReferences (all of them were already referenced in the manuscript):\n[1] Wu, Yue, Wael AbdAlmageed, and Premkumar Natarajan. \"ManTra-Net: Manipulation Tracing Network for Detection and Localization of Image Forgeries With Anomalous Features.\" In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 9543-9552. 2019.\n[2] Bayar, Belhassen, and Matthew C. Stamm. \"Constrained convolutional neural networks: A new approach towards general purpose image manipulation detection.\" IEEE Transactions on Information Forensics and Security 13, no. 11 (2018): 2691-2706.\n"}, "signatures": ["ICLR.cc/2020/Conference/Paper772/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper772/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Quantifying the Cost of Reliable Photo Authentication via High-Performance Learned Lossy Representations", "authors": ["Pawel Korus", "Nasir Memon"], "authorids": ["pkorus@nyu.edu", "memon@nyu.edu"], "keywords": ["image forensics", "photo manipulation detection", "learned compression", "lossy compression", "image compression", "entropy estimation"], "TL;DR": "We learn an efficient lossy image codec that can be optimized to facilitate reliable photo manipulation detection at fractional cost in payload/quality and even at low bitrates.", "abstract": "Detection of photo manipulation relies on subtle statistical traces, notoriously removed by aggressive lossy compression employed online. We demonstrate that end-to-end modeling of complex photo dissemination channels allows for codec optimization with explicit provenance objectives. We design a lightweight trainable lossy image codec, that delivers competitive rate-distortion performance, on par with best hand-engineered alternatives, but has lower computational footprint on modern GPU-enabled platforms. Our results show that significant improvements in manipulation detection accuracy are possible at fractional costs in bandwidth/storage. Our codec improved the accuracy from 37% to 86% even at very low bit-rates, well below the practicality of JPEG (QF 20). ", "pdf": "/pdf/32e1296b257a0494d8ad34f00f7f657df8ab9455.pdf", "paperhash": "korus|quantifying_the_cost_of_reliable_photo_authentication_via_highperformance_learned_lossy_representations", "code": "https://github.com/pkorus/neural-imaging", "_bibtex": "@inproceedings{\nKorus2020Quantifying,\ntitle={Quantifying the Cost of Reliable Photo Authentication via High-Performance Learned Lossy Representations},\nauthor={Pawel Korus and Nasir Memon},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=HyxG3p4twS}\n}", "full_presentation_video": "", "original_pdf": "/attachment/640ac77bdbf38b9b7d6efb37744f5b62213a760a.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "HyxG3p4twS", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper772/Authors", "ICLR.cc/2020/Conference/Paper772/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper772/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper772/Reviewers", "ICLR.cc/2020/Conference/Paper772/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper772/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper772/Authors|ICLR.cc/2020/Conference/Paper772/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504166456, "tmdate": 1576860532961, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper772/Authors", "ICLR.cc/2020/Conference/Paper772/Reviewers", "ICLR.cc/2020/Conference/Paper772/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper772/-/Official_Comment"}}}, {"id": "rkxW2iQcoB", "original": null, "number": 1, "cdate": 1573694376925, "ddate": null, "tcdate": 1573694376925, "tmdate": 1573694376925, "tddate": null, "forum": "HyxG3p4twS", "replyto": "Byegr-2J5B", "invitation": "ICLR.cc/2020/Conference/Paper772/-/Official_Comment", "content": {"title": "Response to Reviewer #1", "comment": "Thank you for your detailed comments and for pointing out more recent hand-crafted codecs.\n\nWe apologize for the confusion. We do not claim to get better results than state-of-the-art hand-crafted solutions. In fact, in terms of the rate-distortion performance, our codec is slightly worse, although very close to BPG. This is what we meant by saying \u201c... is competitive with best hand-engineered codecs\u201d. We have rephrased all related statements in the abstract and the introduction to avoid the confusion and better reflect the actual results. \n\nRegarding the remaining remarks:\n\n# please be sure to explain that SSIM is computed in <RGB | grayscale>\nThe SSIM was computed as the average over RGB channels. We used the default implementation in the scikit-image package. We have extended the manuscript to explain how image quality scores are calculated (Section 3.5 / Rate-distortion Trade-off). \n\n# please be more explicit about which loss is used during training for distortion (i.e., \"we use MSE for the training loss, but stop training when SSIM converges\")\nWe repeated again in Section 3.4 that MSE was used as the training loss explicitly optimized using Adam.\n\n# please provide PSNR numbers for the method; and ideally MS-SSIM (in decibels) instead of PSNR\nWe extended the results to include MS-SSIM in decibels. The new results are included in the appendix (Figures A.5 and A.6). \n\n# please add other neural compression methods to the graphs\nWe apologize but due to limited time for rebuttal, we were not able to include more neural compression methods in the comparison. We hope to include more methods upon publication of the codec on github. \n\n# please clarify that you create a file and decode a file for each image used to create the graphs (very important topic), as opposed to using the estimated file size\nYes, we fully encoded an image into a bit-stream and subsequently decoded and reconstructed the images. The bit-stream structure is already explained in Section 3.3. To address your doubt, we emphasized that this is the case in Section 3.5.\n\n# tone down the claims w.r.t. beating classical codecs\nWe rephrased all statements to clarify the confusion and better reflect the actual results. \n"}, "signatures": ["ICLR.cc/2020/Conference/Paper772/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper772/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Quantifying the Cost of Reliable Photo Authentication via High-Performance Learned Lossy Representations", "authors": ["Pawel Korus", "Nasir Memon"], "authorids": ["pkorus@nyu.edu", "memon@nyu.edu"], "keywords": ["image forensics", "photo manipulation detection", "learned compression", "lossy compression", "image compression", "entropy estimation"], "TL;DR": "We learn an efficient lossy image codec that can be optimized to facilitate reliable photo manipulation detection at fractional cost in payload/quality and even at low bitrates.", "abstract": "Detection of photo manipulation relies on subtle statistical traces, notoriously removed by aggressive lossy compression employed online. We demonstrate that end-to-end modeling of complex photo dissemination channels allows for codec optimization with explicit provenance objectives. We design a lightweight trainable lossy image codec, that delivers competitive rate-distortion performance, on par with best hand-engineered alternatives, but has lower computational footprint on modern GPU-enabled platforms. Our results show that significant improvements in manipulation detection accuracy are possible at fractional costs in bandwidth/storage. Our codec improved the accuracy from 37% to 86% even at very low bit-rates, well below the practicality of JPEG (QF 20). ", "pdf": "/pdf/32e1296b257a0494d8ad34f00f7f657df8ab9455.pdf", "paperhash": "korus|quantifying_the_cost_of_reliable_photo_authentication_via_highperformance_learned_lossy_representations", "code": "https://github.com/pkorus/neural-imaging", "_bibtex": "@inproceedings{\nKorus2020Quantifying,\ntitle={Quantifying the Cost of Reliable Photo Authentication via High-Performance Learned Lossy Representations},\nauthor={Pawel Korus and Nasir Memon},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=HyxG3p4twS}\n}", "full_presentation_video": "", "original_pdf": "/attachment/640ac77bdbf38b9b7d6efb37744f5b62213a760a.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "HyxG3p4twS", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper772/Authors", "ICLR.cc/2020/Conference/Paper772/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper772/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper772/Reviewers", "ICLR.cc/2020/Conference/Paper772/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper772/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper772/Authors|ICLR.cc/2020/Conference/Paper772/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504166456, "tmdate": 1576860532961, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper772/Authors", "ICLR.cc/2020/Conference/Paper772/Reviewers", "ICLR.cc/2020/Conference/Paper772/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper772/-/Official_Comment"}}}, {"id": "BJeC0l9yjS", "original": null, "number": 3, "cdate": 1572999382429, "ddate": null, "tcdate": 1572999382429, "tmdate": 1572999382429, "tddate": null, "forum": "HyxG3p4twS", "replyto": "HyxG3p4twS", "invitation": "ICLR.cc/2020/Conference/Paper772/-/Official_Review", "content": {"experience_assessment": "I do not know much about this area.", "rating": "6: Weak Accept", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "review_assessment:_thoroughness_in_paper_reading": "I made a quick assessment of this paper.", "title": "Official Blind Review #4", "review": "The paper describes a pipeline for image compression which allows to reliably detect specific manipulation patterns in compressed images.  The results show that it is possible to learn image compression that performs similarly to a modern image compression algorithm while in the same time is optimized to reveal specific kinds of manipulations. The authors build upon (Korus & Memon, 2019), but use a learnable codec instead of differentiable JPEG. \n\nThe idea to regularize entropy of the latent representation of images is interesting. A method to train a well-performing image compression system which can also follow additional constraints (such as ability to reveal certain manipulations) is very valuable for practice. Unfortunately, there are already available trainable compression methods and the authors do not compare to these methods. However, in my opinion to detect manipulation in the image one should prove that visual content in some area of the image was significantly changed with respect to some original, while in the other parts of the image it was not changed. Otherwise it becomes impossible to distinguish in-camera filtering and secondary postprocessing. Basically, the authors present a method to detect whether a very particular configuration of some basic image processing filters (Gaussian blur, median filter, resampling)  was applied to the image. Therefore the particular problem formulation looks very artificial. \n\nWith regards to the experiments in the paper, I was somewhat lost. Compare the Fig. 5 and the Fig. 8. In the Fig. 8, we see a big set of possible system configurations having different manipulation detection accuracy, image quality and compression performance.  In the Fig. 5, we see a compression efficiency-image quality dependency. However, it remains unclear how do the systems represented at these two graphs relate to each other, or, in the other words, what is he mapping between points of these graphs. Next, poor performance of JPEG manipulation detection by the proposed  network does not prove that JPEG manipulation cannot be detected, it just shows that the proposed architecture does not perform well in this problem. A comparative study which relates a new system to a current state of the art is required to claim that a proposed approach is better. Finally, SSIM is not a standard way to compute image quality. MS-SSIM and PSNR are also popular, and a user study is usually recommended to claim that some method generates images of better visual quality.\n\nSummarizing, the authors do not provide a new best-performing image compression algorithm, and neither solve a problem of image manipulation detection, but show that it is possible to learn an image compression system with some additional constraints. I believe it is an interesting contribution, and I hope the authors can improve presentation of the experiments.", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory."}, "signatures": ["ICLR.cc/2020/Conference/Paper772/AnonReviewer4"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper772/AnonReviewer4"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Quantifying the Cost of Reliable Photo Authentication via High-Performance Learned Lossy Representations", "authors": ["Pawel Korus", "Nasir Memon"], "authorids": ["pkorus@nyu.edu", "memon@nyu.edu"], "keywords": ["image forensics", "photo manipulation detection", "learned compression", "lossy compression", "image compression", "entropy estimation"], "TL;DR": "We learn an efficient lossy image codec that can be optimized to facilitate reliable photo manipulation detection at fractional cost in payload/quality and even at low bitrates.", "abstract": "Detection of photo manipulation relies on subtle statistical traces, notoriously removed by aggressive lossy compression employed online. We demonstrate that end-to-end modeling of complex photo dissemination channels allows for codec optimization with explicit provenance objectives. We design a lightweight trainable lossy image codec, that delivers competitive rate-distortion performance, on par with best hand-engineered alternatives, but has lower computational footprint on modern GPU-enabled platforms. Our results show that significant improvements in manipulation detection accuracy are possible at fractional costs in bandwidth/storage. Our codec improved the accuracy from 37% to 86% even at very low bit-rates, well below the practicality of JPEG (QF 20). ", "pdf": "/pdf/32e1296b257a0494d8ad34f00f7f657df8ab9455.pdf", "paperhash": "korus|quantifying_the_cost_of_reliable_photo_authentication_via_highperformance_learned_lossy_representations", "code": "https://github.com/pkorus/neural-imaging", "_bibtex": "@inproceedings{\nKorus2020Quantifying,\ntitle={Quantifying the Cost of Reliable Photo Authentication via High-Performance Learned Lossy Representations},\nauthor={Pawel Korus and Nasir Memon},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=HyxG3p4twS}\n}", "full_presentation_video": "", "original_pdf": "/attachment/640ac77bdbf38b9b7d6efb37744f5b62213a760a.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "HyxG3p4twS", "replyto": "HyxG3p4twS", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper772/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper772/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1575644483967, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper772/Reviewers"], "noninvitees": [], "tcdate": 1570237747313, "tmdate": 1575644483981, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper772/-/Official_Review"}}}, {"id": "H1l-LJJAKS", "original": null, "number": 1, "cdate": 1571839816678, "ddate": null, "tcdate": 1571839816678, "tmdate": 1572972554206, "tddate": null, "forum": "HyxG3p4twS", "replyto": "HyxG3p4twS", "invitation": "ICLR.cc/2020/Conference/Paper772/-/Official_Review", "content": {"experience_assessment": "I do not know much about this area.", "rating": "6: Weak Accept", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #772", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "\nSummary of the paper\n- This work proposes a new deep-learning-based method to replace the lossy compression techniques of images., jpg.\n- The work investigates the role of codec and shows that the proposed complex photo dissemination channels optimizes the codec related traits on images.\n- The method achieved much better performance in compressing images compared to practically used JPEG (QF-20)\n\nI think the paper is well written and the experiment seems to support the author's argument. Unfortunately, this field is not overlapped to my research field, and it is hard for me to judge this paper."}, "signatures": ["ICLR.cc/2020/Conference/Paper772/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper772/AnonReviewer2"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Quantifying the Cost of Reliable Photo Authentication via High-Performance Learned Lossy Representations", "authors": ["Pawel Korus", "Nasir Memon"], "authorids": ["pkorus@nyu.edu", "memon@nyu.edu"], "keywords": ["image forensics", "photo manipulation detection", "learned compression", "lossy compression", "image compression", "entropy estimation"], "TL;DR": "We learn an efficient lossy image codec that can be optimized to facilitate reliable photo manipulation detection at fractional cost in payload/quality and even at low bitrates.", "abstract": "Detection of photo manipulation relies on subtle statistical traces, notoriously removed by aggressive lossy compression employed online. We demonstrate that end-to-end modeling of complex photo dissemination channels allows for codec optimization with explicit provenance objectives. We design a lightweight trainable lossy image codec, that delivers competitive rate-distortion performance, on par with best hand-engineered alternatives, but has lower computational footprint on modern GPU-enabled platforms. Our results show that significant improvements in manipulation detection accuracy are possible at fractional costs in bandwidth/storage. Our codec improved the accuracy from 37% to 86% even at very low bit-rates, well below the practicality of JPEG (QF 20). ", "pdf": "/pdf/32e1296b257a0494d8ad34f00f7f657df8ab9455.pdf", "paperhash": "korus|quantifying_the_cost_of_reliable_photo_authentication_via_highperformance_learned_lossy_representations", "code": "https://github.com/pkorus/neural-imaging", "_bibtex": "@inproceedings{\nKorus2020Quantifying,\ntitle={Quantifying the Cost of Reliable Photo Authentication via High-Performance Learned Lossy Representations},\nauthor={Pawel Korus and Nasir Memon},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=HyxG3p4twS}\n}", "full_presentation_video": "", "original_pdf": "/attachment/640ac77bdbf38b9b7d6efb37744f5b62213a760a.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "HyxG3p4twS", "replyto": "HyxG3p4twS", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper772/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper772/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1575644483967, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper772/Reviewers"], "noninvitees": [], "tcdate": 1570237747313, "tmdate": 1575644483981, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper772/-/Official_Review"}}}, {"id": "Byegr-2J5B", "original": null, "number": 2, "cdate": 1571959096482, "ddate": null, "tcdate": 1571959096482, "tmdate": 1572972554164, "tddate": null, "forum": "HyxG3p4twS", "replyto": "HyxG3p4twS", "invitation": "ICLR.cc/2020/Conference/Paper772/-/Official_Review", "content": {"experience_assessment": "I have published in this field for several years.", "rating": "6: Weak Accept", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #1", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "This paper presents a learned image compression method that is able to be robust under a variety of tasks. The results aren't state of the art in terms of rate-distortion performance, but this paper has a very good analysis of the results, and has produced a very fast codec. In that sense, this is a very interesting paper that may lead to other fast methods (the other fast method they compared the runtime against - WaveOne never published a complete description).\n\nThis paper should be likely accepted, but the authors should town down the claims a bit. The results presented do NOT show that this method is better than the best hand engineered approach, despite what they claim. Even compared to BPG, which is NOT state of the art, the results are a mixed bag. \n\nWe would like to point out to the authors that the VVC codec has shown much stronger performance than BPG, and similarly the AV1 codec has surpassed the performance of BPG. Moreover, even Pik has also surpassed the performance of BPG, so just showing stronger performance than BPG is not grounds to make the claim that this method is superior to hand engineered approaches.\n\nMoreover, as I stated earlier, this method is not even better all the time, therefore weakening the claim.\n\nOn the positives:\n- the paper fully describes the architecture, unlike WaveOne\n- the runtime numbers are impressive (as far as I know, there is no faster published method)\n- the authors consider applications other than compression performance (such as classification performance in forensic analysis)\n\nOn the negatives, which I highly suggest that the authors fix if this paper is to be taken seriously by the community:\n- please be sure to explain that SSIM is computed in <RGB | grayscale>\n- please be more explicit about which loss is used during training for distortion (i.e., \"we use MSE for the training loss, but stop training when SSIM converges\")\n- please provide PSNR numbers for the method; and ideally MS-SSIM (in decibels) instead of PSNR\n- please add other neural compression methods to the graphs \n- please clarify that you create a file and decode a file for each image used to create the graphs (very important topic), as opposed to using the estimated file size\n- tone down the claims w.r.t. beating classical codecs"}, "signatures": ["ICLR.cc/2020/Conference/Paper772/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper772/AnonReviewer1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Quantifying the Cost of Reliable Photo Authentication via High-Performance Learned Lossy Representations", "authors": ["Pawel Korus", "Nasir Memon"], "authorids": ["pkorus@nyu.edu", "memon@nyu.edu"], "keywords": ["image forensics", "photo manipulation detection", "learned compression", "lossy compression", "image compression", "entropy estimation"], "TL;DR": "We learn an efficient lossy image codec that can be optimized to facilitate reliable photo manipulation detection at fractional cost in payload/quality and even at low bitrates.", "abstract": "Detection of photo manipulation relies on subtle statistical traces, notoriously removed by aggressive lossy compression employed online. We demonstrate that end-to-end modeling of complex photo dissemination channels allows for codec optimization with explicit provenance objectives. We design a lightweight trainable lossy image codec, that delivers competitive rate-distortion performance, on par with best hand-engineered alternatives, but has lower computational footprint on modern GPU-enabled platforms. Our results show that significant improvements in manipulation detection accuracy are possible at fractional costs in bandwidth/storage. Our codec improved the accuracy from 37% to 86% even at very low bit-rates, well below the practicality of JPEG (QF 20). ", "pdf": "/pdf/32e1296b257a0494d8ad34f00f7f657df8ab9455.pdf", "paperhash": "korus|quantifying_the_cost_of_reliable_photo_authentication_via_highperformance_learned_lossy_representations", "code": "https://github.com/pkorus/neural-imaging", "_bibtex": "@inproceedings{\nKorus2020Quantifying,\ntitle={Quantifying the Cost of Reliable Photo Authentication via High-Performance Learned Lossy Representations},\nauthor={Pawel Korus and Nasir Memon},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=HyxG3p4twS}\n}", "full_presentation_video": "", "original_pdf": "/attachment/640ac77bdbf38b9b7d6efb37744f5b62213a760a.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "HyxG3p4twS", "replyto": "HyxG3p4twS", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper772/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper772/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1575644483967, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper772/Reviewers"], "noninvitees": [], "tcdate": 1570237747313, "tmdate": 1575644483981, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper772/-/Official_Review"}}}], "count": 8}