{"notes": [{"tddate": null, "replyto": null, "ddate": null, "tmdate": 1486468149679, "tcdate": 1478076656020, "number": 42, "id": "ryuxYmvel", "invitation": "ICLR.cc/2017/conference/-/submission", "forum": "ryuxYmvel", "signatures": ["~Cezary_Kaliszyk1"], "readers": ["everyone"], "content": {"TL;DR": "", "title": "HolStep: A Machine Learning Dataset for Higher-order Logic Theorem Proving", "abstract": "Large computer-understandable proofs consist of millions of intermediate\nlogical steps. The vast majority of such steps originate from manually\nselected and manually guided heuristics applied to intermediate goals.\nSo far, machine learning has generally not been used to filter or\ngenerate these steps. In this paper, we introduce a new dataset based on\nHigher-Order Logic (HOL) proofs, for the purpose of developing new\nmachine learning-based theorem-proving strategies. We make this dataset\npublicly available under the BSD license. We propose various machine\nlearning tasks that can be performed on this dataset, and discuss their\nsignificance for theorem proving. We also benchmark a set of simple baseline\nmachine learning models suited for the tasks (including logistic regression\nconvolutional neural networks and recurrent neural networks). The results of our\nbaseline models show the promise of applying machine learning to HOL\ntheorem proving.\n", "pdf": "/pdf/81bc078db86f22433df5930629717f6545aa4d3e.pdf", "paperhash": "kaliszyk|holstep_a_machine_learning_dataset_for_higherorder_logic_theorem_proving", "conflicts": ["uibk.ac.at", "google.com"], "keywords": [], "authors": ["Cezary Kaliszyk", "Fran\u00e7ois Chollet", "Christian Szegedy"], "authorids": ["cezary.kaliszyk@uibk.ac.at", "fchollet@google.com", "szegedy@google.com"]}, "writers": [], "nonreaders": [], "details": {"replyCount": 11, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1475686800000, "tmdate": 1478287705855, "id": "ICLR.cc/2017/conference/-/submission", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/pcs"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": null, "replyto": null, "writers": {"values-regex": "~.*"}, "signatures": {"values-regex": "~.*", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"pdf": {"required": true, "order": 5, "description": "Either upload a PDF file or provide a direct link to your PDF on ArXiv (link must begin with http(s) and end with .pdf)", "value-regex": "upload|(http|https):\\/\\/.+\\.pdf"}, "title": {"required": true, "order": 1, "description": "Title of paper.", "value-regex": ".{1,250}"}, "abstract": {"required": true, "order": 4, "description": "Abstract of paper.", "value-regex": "[\\S\\s]{1,5000}"}, "authors": {"required": true, "order": 2, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of author names, as they appear in the paper."}, "conflicts": {"required": true, "order": 100, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of email domains of people who would have a conflict of interest in reviewing this paper, (e.g., cs.umass.edu;google.com, etc.)."}, "keywords": {"order": 6, "description": "Comma separated list of keywords.", "values-dropdown": ["Theory", "Computer vision", "Speech", "Natural language processing", "Deep learning", "Unsupervised Learning", "Supervised Learning", "Semi-Supervised Learning", "Reinforcement Learning", "Transfer Learning", "Multi-modal learning", "Applications", "Optimization", "Structured prediction", "Games"]}, "TL;DR": {"required": false, "order": 3, "description": "\"Too Long; Didn't Read\": a short sentence describing your paper", "value-regex": "[^\\n]{0,250}"}, "authorids": {"required": true, "order": 3, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of author email addresses, in the same order as above."}}}, "nonreaders": [], "noninvitees": [], "expdate": 1483462800000, "cdate": 1478287705855}}}, {"tddate": null, "ddate": null, "cdate": null, "tmdate": 1486396321001, "tcdate": 1486396321001, "number": 1, "id": "BytiiGL_x", "invitation": "ICLR.cc/2017/conference/-/paper42/acceptance", "forum": "ryuxYmvel", "replyto": "ryuxYmvel", "signatures": ["ICLR.cc/2017/pcs"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/pcs"], "content": {"title": "ICLR committee final decision", "comment": "The paper presents a new dataset and initial machine-learning results for an interesting problem, namely, higher-order logic theorem proving. This dataset is of great potential value in the development of deep-learning approaches for (mathematical) reasoning.\n \n As a personal side note: It would be great if the camera-ready version of the paper would provide somewhat more context on how the state-of-the-art approaches in automatic theorem proving perform on the conjectures in HolStep. Also, it would be good to clarify how the dataset makes sure there is no \"overlap\" between the training and test set: for instance, a typical proof of the Cauchy-Schwarz inequality employs the Pythagorean theorem: how can we be sure that we don't have Cauchy-Schwarz in the training set and Pythagoras in the test set?", "decision": "Accept (Poster)"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"TL;DR": "", "title": "HolStep: A Machine Learning Dataset for Higher-order Logic Theorem Proving", "abstract": "Large computer-understandable proofs consist of millions of intermediate\nlogical steps. The vast majority of such steps originate from manually\nselected and manually guided heuristics applied to intermediate goals.\nSo far, machine learning has generally not been used to filter or\ngenerate these steps. In this paper, we introduce a new dataset based on\nHigher-Order Logic (HOL) proofs, for the purpose of developing new\nmachine learning-based theorem-proving strategies. We make this dataset\npublicly available under the BSD license. We propose various machine\nlearning tasks that can be performed on this dataset, and discuss their\nsignificance for theorem proving. We also benchmark a set of simple baseline\nmachine learning models suited for the tasks (including logistic regression\nconvolutional neural networks and recurrent neural networks). The results of our\nbaseline models show the promise of applying machine learning to HOL\ntheorem proving.\n", "pdf": "/pdf/81bc078db86f22433df5930629717f6545aa4d3e.pdf", "paperhash": "kaliszyk|holstep_a_machine_learning_dataset_for_higherorder_logic_theorem_proving", "conflicts": ["uibk.ac.at", "google.com"], "keywords": [], "authors": ["Cezary Kaliszyk", "Fran\u00e7ois Chollet", "Christian Szegedy"], "authorids": ["cezary.kaliszyk@uibk.ac.at", "fchollet@google.com", "szegedy@google.com"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1486396321544, "id": "ICLR.cc/2017/conference/-/paper42/acceptance", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/pcs"], "noninvitees": ["ICLR.cc/2017/pcs"], "reply": {"forum": "ryuxYmvel", "replyto": "ryuxYmvel", "writers": {"values-regex": "ICLR.cc/2017/pcs"}, "signatures": {"values-regex": "ICLR.cc/2017/pcs", "description": "Your displayed identity associated with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your decision.", "value": "ICLR committee final decision"}, "comment": {"required": true, "order": 2, "description": "Decision comments.", "value-regex": "[\\S\\s]{1,5000}"}, "decision": {"required": true, "order": 3, "value-radio": ["Accept (Oral)", "Accept (Poster)", "Reject", "Invite to Workshop Track"]}}}, "nonreaders": [], "cdate": 1486396321544}}}, {"tddate": null, "tmdate": 1485069893822, "tcdate": 1482521928297, "number": 3, "id": "Hkl86ls4e", "invitation": "ICLR.cc/2017/conference/-/paper42/official/review", "forum": "ryuxYmvel", "replyto": "ryuxYmvel", "signatures": ["ICLR.cc/2017/conference/paper42/AnonReviewer3"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/conference/paper42/AnonReviewer3"], "content": {"title": "Interesting dataset, reasonable first steps", "rating": "6: Marginally above acceptance threshold", "review": "Use of ML in ITP is an interesting direction of research. Authors consider the problem of predicting whether a given statement would be useful in a proof of a conjecture or not. This is posed as a binary classification task and authors propose a dataset and some deep learning based baselines. \n\nI am not an expert on ITP or theorem proving, so I will present a review from more of a ML perspective. I feel one of the goals of the paper should be to present the problem to a ML audience in a way that is easy for them to grasp. While most of the paper is well written, there are some sections that are not clear (especially section 2):\n-\tTerms such as LCF, OCaml-top level, deBruijn indices have been used without explaining or any references. These terms might be trivial in ITP literature, but were hard for me to follow.  \n-\tSection 2 describes how the data was splits into train and test set. One thing which is unclear is \u2013 can the examples in the train and test set be statements about the same conjecture or are they always statements about different conjectures? \n\n\nIt also unclear how the deep learning models are applied. Let\u2019s consider the leftmost architecture in Figure 1. Each character is embedded into 256-D vector \u2013 and processed until the global max-pooling layer. Does this layer take a max along each feature and across all characters in the input? \n\nMy another concern is only deep learning methods are presented as baselines. It would be great to compare with standard NLP techniques such as Bag of Words followed by SVM. I am sure these would be outperformed by neural networks, but the numbers would give a sense of how easy/hard the current problem setup is. \n\nDid the authors look at the success and failure cases of the algorithm? Are there any insights that can be drawn from such analysis that can inform design of future models? \n\nOverall I think the research direction of using ML for theorem proving is an interesting one. However, I also feel the paper is quite opaque. Many parts of how the data is constructed is unclear (atleast to someone with little knowledge in ITPs). If authors can revise the text to make it clearer \u2013 it would be great. The baseline models seem to perform quite well, however there are no insights into what kind of ability the models are lacking. Authors mention that they are unable to perform logical reasoning \u2013 but that\u2019s a very vague statement. Some examples of mistakes might help make the message clearer. Further, since I am not well versed with the ITP literature it\u2019s not possible for me to judge how valuable is this dataset. From the references, it seems like it\u2019s drawn from a set of benchmark conjectures/proofs used in the ITP community \u2013 so its possibly a good dataset. \n\nMy current rating is a weak reject, but if the authors address my concerns I would change to an accept.\n\n\n", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"TL;DR": "", "title": "HolStep: A Machine Learning Dataset for Higher-order Logic Theorem Proving", "abstract": "Large computer-understandable proofs consist of millions of intermediate\nlogical steps. The vast majority of such steps originate from manually\nselected and manually guided heuristics applied to intermediate goals.\nSo far, machine learning has generally not been used to filter or\ngenerate these steps. In this paper, we introduce a new dataset based on\nHigher-Order Logic (HOL) proofs, for the purpose of developing new\nmachine learning-based theorem-proving strategies. We make this dataset\npublicly available under the BSD license. We propose various machine\nlearning tasks that can be performed on this dataset, and discuss their\nsignificance for theorem proving. We also benchmark a set of simple baseline\nmachine learning models suited for the tasks (including logistic regression\nconvolutional neural networks and recurrent neural networks). The results of our\nbaseline models show the promise of applying machine learning to HOL\ntheorem proving.\n", "pdf": "/pdf/81bc078db86f22433df5930629717f6545aa4d3e.pdf", "paperhash": "kaliszyk|holstep_a_machine_learning_dataset_for_higherorder_logic_theorem_proving", "conflicts": ["uibk.ac.at", "google.com"], "keywords": [], "authors": ["Cezary Kaliszyk", "Fran\u00e7ois Chollet", "Christian Szegedy"], "authorids": ["cezary.kaliszyk@uibk.ac.at", "fchollet@google.com", "szegedy@google.com"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1481932799000, "tmdate": 1482521928930, "id": "ICLR.cc/2017/conference/-/paper42/official/review", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/conference/paper42/reviewers"], "noninvitees": ["ICLR.cc/2017/conference/paper42/AnonReviewer2", "ICLR.cc/2017/conference/paper42/AnonReviewer1", "ICLR.cc/2017/conference/paper42/AnonReviewer3"], "reply": {"forum": "ryuxYmvel", "replyto": "ryuxYmvel", "writers": {"values-regex": "ICLR.cc/2017/conference/paper42/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/conference/paper42/AnonReviewer[0-9]+"}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "value-regex": "[\\S\\s]{1,20000}"}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1489708799000, "cdate": 1482521928930}}}, {"tddate": null, "tmdate": 1485069876830, "tcdate": 1485069876830, "number": 1, "id": "rkT4RRZDg", "invitation": "ICLR.cc/2017/conference/-/paper42/official/comment", "forum": "ryuxYmvel", "replyto": "BJiUOeIUx", "signatures": ["ICLR.cc/2017/conference/paper42/AnonReviewer3"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/conference/paper42/AnonReviewer3"], "content": {"title": "Regarding Updates", "comment": "Thanks for rewriting section 2- it is much clearer now. I have upgraded my rating. "}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"TL;DR": "", "title": "HolStep: A Machine Learning Dataset for Higher-order Logic Theorem Proving", "abstract": "Large computer-understandable proofs consist of millions of intermediate\nlogical steps. The vast majority of such steps originate from manually\nselected and manually guided heuristics applied to intermediate goals.\nSo far, machine learning has generally not been used to filter or\ngenerate these steps. In this paper, we introduce a new dataset based on\nHigher-Order Logic (HOL) proofs, for the purpose of developing new\nmachine learning-based theorem-proving strategies. We make this dataset\npublicly available under the BSD license. We propose various machine\nlearning tasks that can be performed on this dataset, and discuss their\nsignificance for theorem proving. We also benchmark a set of simple baseline\nmachine learning models suited for the tasks (including logistic regression\nconvolutional neural networks and recurrent neural networks). The results of our\nbaseline models show the promise of applying machine learning to HOL\ntheorem proving.\n", "pdf": "/pdf/81bc078db86f22433df5930629717f6545aa4d3e.pdf", "paperhash": "kaliszyk|holstep_a_machine_learning_dataset_for_higherorder_logic_theorem_proving", "conflicts": ["uibk.ac.at", "google.com"], "keywords": [], "authors": ["Cezary Kaliszyk", "Fran\u00e7ois Chollet", "Christian Szegedy"], "authorids": ["cezary.kaliszyk@uibk.ac.at", "fchollet@google.com", "szegedy@google.com"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287753754, "id": "ICLR.cc/2017/conference/-/paper42/official/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "reply": {"forum": "ryuxYmvel", "writers": {"values-regex": "ICLR.cc/2017/conference/paper42/(AnonReviewer|areachair)[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/conference/paper42/(AnonReviewer|areachair)[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": [], "invitees": ["ICLR.cc/2017/conference/paper42/reviewers", "ICLR.cc/2017/conference/paper42/areachairs"], "cdate": 1485287753754}}}, {"tddate": null, "tmdate": 1484290385374, "tcdate": 1484290385374, "number": 4, "id": "SJt8tlI8l", "invitation": "ICLR.cc/2017/conference/-/paper42/public/comment", "forum": "ryuxYmvel", "replyto": "BkeTwcZVx", "signatures": ["~Cezary_Kaliszyk1"], "readers": ["everyone"], "writers": ["~Cezary_Kaliszyk1"], "content": {"title": "Answer to Review 2", "comment": "We thank the reviewer for the insightful comments.\n\nIndeed the dataset is smaller than that of AlphaGo, as it has been created as a benchmark for machine learning technologies applied to higher-order logic. The proposed approach can be directly applied to other HOL proof corpora to create a much larger training dataset, which can be used to practically guide ATPs. We imagine that already with the current accuracy integrating the prediction of usefulness of a statement could help modern ATPs. And the difference could become more signigicant with further improvements to the proposed baselines.\n"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"TL;DR": "", "title": "HolStep: A Machine Learning Dataset for Higher-order Logic Theorem Proving", "abstract": "Large computer-understandable proofs consist of millions of intermediate\nlogical steps. The vast majority of such steps originate from manually\nselected and manually guided heuristics applied to intermediate goals.\nSo far, machine learning has generally not been used to filter or\ngenerate these steps. In this paper, we introduce a new dataset based on\nHigher-Order Logic (HOL) proofs, for the purpose of developing new\nmachine learning-based theorem-proving strategies. We make this dataset\npublicly available under the BSD license. We propose various machine\nlearning tasks that can be performed on this dataset, and discuss their\nsignificance for theorem proving. We also benchmark a set of simple baseline\nmachine learning models suited for the tasks (including logistic regression\nconvolutional neural networks and recurrent neural networks). The results of our\nbaseline models show the promise of applying machine learning to HOL\ntheorem proving.\n", "pdf": "/pdf/81bc078db86f22433df5930629717f6545aa4d3e.pdf", "paperhash": "kaliszyk|holstep_a_machine_learning_dataset_for_higherorder_logic_theorem_proving", "conflicts": ["uibk.ac.at", "google.com"], "keywords": [], "authors": ["Cezary Kaliszyk", "Fran\u00e7ois Chollet", "Christian Szegedy"], "authorids": ["cezary.kaliszyk@uibk.ac.at", "fchollet@google.com", "szegedy@google.com"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287753881, "id": "ICLR.cc/2017/conference/-/paper42/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "ryuxYmvel", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper42/reviewers", "ICLR.cc/2017/conference/paper42/areachairs"], "cdate": 1485287753881}}}, {"tddate": null, "tmdate": 1484290130658, "tcdate": 1484290130658, "number": 3, "id": "BJiUOeIUx", "invitation": "ICLR.cc/2017/conference/-/paper42/public/comment", "forum": "ryuxYmvel", "replyto": "Hkl86ls4e", "signatures": ["~Cezary_Kaliszyk1"], "readers": ["everyone"], "writers": ["~Cezary_Kaliszyk1"], "content": {"title": "Answer to Review 3", "comment": "We thank the reviewer for the insightful comments. We have taken all into account and attempted to adapt the paper accordingly. In particular:\n\nWe rewrote section 2 explaining and giving citations to the theorem proving terms and eliminating the unnecessary ones.\n\nIndeed, the training and test sets concern different conjectures. This is for the machine learning task to correspond to the theorem proving task. In the latter, learning from parts of proofs of a conjecture is only possible after it has been completely proved. This is now explained in the paper.\n\nThe global max pooling does reduce the sequence of vectors corresponding to the characters to a single vector. We have made this clearer in section 4.1.\n\nAn initial analysis of success and failure cases suggests that the design of future models should attempt to leverage the graph structure of HOL statements, for example by considering recursive graph models and generative models.\n\nFinally, deep learning models are compared to relatively simpler logistic regression baseline. The difference, as visible in Tables 2-3 and Figures 3-6 is significant.\n"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"TL;DR": "", "title": "HolStep: A Machine Learning Dataset for Higher-order Logic Theorem Proving", "abstract": "Large computer-understandable proofs consist of millions of intermediate\nlogical steps. The vast majority of such steps originate from manually\nselected and manually guided heuristics applied to intermediate goals.\nSo far, machine learning has generally not been used to filter or\ngenerate these steps. In this paper, we introduce a new dataset based on\nHigher-Order Logic (HOL) proofs, for the purpose of developing new\nmachine learning-based theorem-proving strategies. We make this dataset\npublicly available under the BSD license. We propose various machine\nlearning tasks that can be performed on this dataset, and discuss their\nsignificance for theorem proving. We also benchmark a set of simple baseline\nmachine learning models suited for the tasks (including logistic regression\nconvolutional neural networks and recurrent neural networks). The results of our\nbaseline models show the promise of applying machine learning to HOL\ntheorem proving.\n", "pdf": "/pdf/81bc078db86f22433df5930629717f6545aa4d3e.pdf", "paperhash": "kaliszyk|holstep_a_machine_learning_dataset_for_higherorder_logic_theorem_proving", "conflicts": ["uibk.ac.at", "google.com"], "keywords": [], "authors": ["Cezary Kaliszyk", "Fran\u00e7ois Chollet", "Christian Szegedy"], "authorids": ["cezary.kaliszyk@uibk.ac.at", "fchollet@google.com", "szegedy@google.com"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287753881, "id": "ICLR.cc/2017/conference/-/paper42/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "ryuxYmvel", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper42/reviewers", "ICLR.cc/2017/conference/paper42/areachairs"], "cdate": 1485287753881}}}, {"tddate": null, "tmdate": 1481908044929, "tcdate": 1481908044929, "number": 2, "id": "rkB8kiWNl", "invitation": "ICLR.cc/2017/conference/-/paper42/official/review", "forum": "ryuxYmvel", "replyto": "ryuxYmvel", "signatures": ["ICLR.cc/2017/conference/paper42/AnonReviewer1"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/conference/paper42/AnonReviewer1"], "content": {"title": "", "rating": "8: Top 50% of accepted papers, clear accept", "review": "The authors present a dataset extraction method, dataset and first interesting results for machine-learning supported higher order logic theorem proving. The experimental results are impressively good for a first baseline and with an accuracy higher than 0.83 in relevance classification a lot better than chance, and encourage future research in this direction. The paper is well-written in terms of presentation and argumentation and leaves little room for criticism. The related work seems to be well-covered, though I have to note that I am not an expert for automated theorem proving.", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"TL;DR": "", "title": "HolStep: A Machine Learning Dataset for Higher-order Logic Theorem Proving", "abstract": "Large computer-understandable proofs consist of millions of intermediate\nlogical steps. The vast majority of such steps originate from manually\nselected and manually guided heuristics applied to intermediate goals.\nSo far, machine learning has generally not been used to filter or\ngenerate these steps. In this paper, we introduce a new dataset based on\nHigher-Order Logic (HOL) proofs, for the purpose of developing new\nmachine learning-based theorem-proving strategies. We make this dataset\npublicly available under the BSD license. We propose various machine\nlearning tasks that can be performed on this dataset, and discuss their\nsignificance for theorem proving. We also benchmark a set of simple baseline\nmachine learning models suited for the tasks (including logistic regression\nconvolutional neural networks and recurrent neural networks). The results of our\nbaseline models show the promise of applying machine learning to HOL\ntheorem proving.\n", "pdf": "/pdf/81bc078db86f22433df5930629717f6545aa4d3e.pdf", "paperhash": "kaliszyk|holstep_a_machine_learning_dataset_for_higherorder_logic_theorem_proving", "conflicts": ["uibk.ac.at", "google.com"], "keywords": [], "authors": ["Cezary Kaliszyk", "Fran\u00e7ois Chollet", "Christian Szegedy"], "authorids": ["cezary.kaliszyk@uibk.ac.at", "fchollet@google.com", "szegedy@google.com"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1481932799000, "tmdate": 1482521928930, "id": "ICLR.cc/2017/conference/-/paper42/official/review", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/conference/paper42/reviewers"], "noninvitees": ["ICLR.cc/2017/conference/paper42/AnonReviewer2", "ICLR.cc/2017/conference/paper42/AnonReviewer1", "ICLR.cc/2017/conference/paper42/AnonReviewer3"], "reply": {"forum": "ryuxYmvel", "replyto": "ryuxYmvel", "writers": {"values-regex": "ICLR.cc/2017/conference/paper42/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/conference/paper42/AnonReviewer[0-9]+"}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "value-regex": "[\\S\\s]{1,20000}"}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1489708799000, "cdate": 1482521928930}}}, {"tddate": null, "tmdate": 1481906224615, "tcdate": 1481906104025, "number": 1, "id": "BkeTwcZVx", "invitation": "ICLR.cc/2017/conference/-/paper42/official/review", "forum": "ryuxYmvel", "replyto": "ryuxYmvel", "signatures": ["ICLR.cc/2017/conference/paper42/AnonReviewer2"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/conference/paper42/AnonReviewer2"], "content": {"title": "Great start, interested in future work", "rating": "7: Good paper, accept", "review": "The authors describe a dataset of proof steps in higher order logic derived from a set of proven theorems. The success of methods like AlphaGo suggests that for hard combinatorial style problems, having a curated set of expert data (in this case the sequence of subproofs) is a good launching point for possibly super-human performance. Super-human ATPs are clearly extremely valuable. Although relatively smaller than the original Go datasets, this dataset seems to be a great first step. Unfortunately, the ATP and HOL aspect of this work is not my area of expertise. I can't comment on the quality of this aspect.\n\nIt would be great to see future work scale up the baselines and integrate the networks into state of the art ATPs. The capacity of deep learning methods to scale and take advantage of larger datasets means there's a possibility of an iterative approach to improving ATPs: as the ATPs get stronger they may generate more data in the form of new theorems. This may be a long way off, but the possibility is exciting.", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"TL;DR": "", "title": "HolStep: A Machine Learning Dataset for Higher-order Logic Theorem Proving", "abstract": "Large computer-understandable proofs consist of millions of intermediate\nlogical steps. The vast majority of such steps originate from manually\nselected and manually guided heuristics applied to intermediate goals.\nSo far, machine learning has generally not been used to filter or\ngenerate these steps. In this paper, we introduce a new dataset based on\nHigher-Order Logic (HOL) proofs, for the purpose of developing new\nmachine learning-based theorem-proving strategies. We make this dataset\npublicly available under the BSD license. We propose various machine\nlearning tasks that can be performed on this dataset, and discuss their\nsignificance for theorem proving. We also benchmark a set of simple baseline\nmachine learning models suited for the tasks (including logistic regression\nconvolutional neural networks and recurrent neural networks). The results of our\nbaseline models show the promise of applying machine learning to HOL\ntheorem proving.\n", "pdf": "/pdf/81bc078db86f22433df5930629717f6545aa4d3e.pdf", "paperhash": "kaliszyk|holstep_a_machine_learning_dataset_for_higherorder_logic_theorem_proving", "conflicts": ["uibk.ac.at", "google.com"], "keywords": [], "authors": ["Cezary Kaliszyk", "Fran\u00e7ois Chollet", "Christian Szegedy"], "authorids": ["cezary.kaliszyk@uibk.ac.at", "fchollet@google.com", "szegedy@google.com"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1481932799000, "tmdate": 1482521928930, "id": "ICLR.cc/2017/conference/-/paper42/official/review", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/conference/paper42/reviewers"], "noninvitees": ["ICLR.cc/2017/conference/paper42/AnonReviewer2", "ICLR.cc/2017/conference/paper42/AnonReviewer1", "ICLR.cc/2017/conference/paper42/AnonReviewer3"], "reply": {"forum": "ryuxYmvel", "replyto": "ryuxYmvel", "writers": {"values-regex": "ICLR.cc/2017/conference/paper42/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/conference/paper42/AnonReviewer[0-9]+"}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "value-regex": "[\\S\\s]{1,20000}"}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1489708799000, "cdate": 1482521928930}}}, {"tddate": null, "tmdate": 1481112220020, "tcdate": 1481112220013, "number": 2, "id": "HyNiqdHme", "invitation": "ICLR.cc/2017/conference/-/paper42/public/comment", "forum": "ryuxYmvel", "replyto": "SJgTvB4Xg", "signatures": ["~Cezary_Kaliszyk1"], "readers": ["everyone"], "writers": ["~Cezary_Kaliszyk1"], "content": {"title": "Re: When is this applicable?", "comment": "Using machine learning to predict branches is already useful in\ntableaux based first-order automated provers. The HOL proofs have\na much higher branching factor and inferences are slowe, so being\nbeing able to predict branches more accurately will help more there.\n\nThe bias from learning on human proofs is to an extent present in\nthe proposed dataset. It is possible to extend the dataset to\ninclude the steps that are derived by automated proof search (we\nsuggested in future work to possibly include steps found by the\nmodel elimination automated procedure).\n\nFinally, indeed many of the proofs we consider are proofs that\nhumans find easy. ATPs are at the moment very week in comparison\nwith human intuition, and cases where they find proofs that a\nhuman cannot find quickly are rare. Therefore improving the quality\nof ATPs even for the many proofs humans do not find difficult would\nbe an important gain.\n\nWe have modified the conclusion and future work parts of the paper\nto include these remarks.\n"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"TL;DR": "", "title": "HolStep: A Machine Learning Dataset for Higher-order Logic Theorem Proving", "abstract": "Large computer-understandable proofs consist of millions of intermediate\nlogical steps. The vast majority of such steps originate from manually\nselected and manually guided heuristics applied to intermediate goals.\nSo far, machine learning has generally not been used to filter or\ngenerate these steps. In this paper, we introduce a new dataset based on\nHigher-Order Logic (HOL) proofs, for the purpose of developing new\nmachine learning-based theorem-proving strategies. We make this dataset\npublicly available under the BSD license. We propose various machine\nlearning tasks that can be performed on this dataset, and discuss their\nsignificance for theorem proving. We also benchmark a set of simple baseline\nmachine learning models suited for the tasks (including logistic regression\nconvolutional neural networks and recurrent neural networks). The results of our\nbaseline models show the promise of applying machine learning to HOL\ntheorem proving.\n", "pdf": "/pdf/81bc078db86f22433df5930629717f6545aa4d3e.pdf", "paperhash": "kaliszyk|holstep_a_machine_learning_dataset_for_higherorder_logic_theorem_proving", "conflicts": ["uibk.ac.at", "google.com"], "keywords": [], "authors": ["Cezary Kaliszyk", "Fran\u00e7ois Chollet", "Christian Szegedy"], "authorids": ["cezary.kaliszyk@uibk.ac.at", "fchollet@google.com", "szegedy@google.com"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287753881, "id": "ICLR.cc/2017/conference/-/paper42/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "ryuxYmvel", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper42/reviewers", "ICLR.cc/2017/conference/paper42/areachairs"], "cdate": 1485287753881}}}, {"tddate": null, "tmdate": 1481111447215, "tcdate": 1481111447209, "number": 1, "id": "rJJjwOBml", "invitation": "ICLR.cc/2017/conference/-/paper42/public/comment", "forum": "ryuxYmvel", "replyto": "B1RMgGkXg", "signatures": ["~Cezary_Kaliszyk1"], "readers": ["everyone"], "writers": ["~Cezary_Kaliszyk1"], "content": {"title": "Re: The dataset extraction method", "comment": "We have now included the scripts and code which we used to generate the dataset, as well as the code used to compute the baseline models. This is also now mentioned in the paper.\n\nThe dataset generation approach could easily generalize to LCF-style interactive theorem provers. For ATPs, extraction from a dataset such as TPTP might conceptually be simpler. However, the data is typically less consistent across problems, so further techniques for matching concepts would likely be necessary to make the predictions meaningful."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"TL;DR": "", "title": "HolStep: A Machine Learning Dataset for Higher-order Logic Theorem Proving", "abstract": "Large computer-understandable proofs consist of millions of intermediate\nlogical steps. The vast majority of such steps originate from manually\nselected and manually guided heuristics applied to intermediate goals.\nSo far, machine learning has generally not been used to filter or\ngenerate these steps. In this paper, we introduce a new dataset based on\nHigher-Order Logic (HOL) proofs, for the purpose of developing new\nmachine learning-based theorem-proving strategies. We make this dataset\npublicly available under the BSD license. We propose various machine\nlearning tasks that can be performed on this dataset, and discuss their\nsignificance for theorem proving. We also benchmark a set of simple baseline\nmachine learning models suited for the tasks (including logistic regression\nconvolutional neural networks and recurrent neural networks). The results of our\nbaseline models show the promise of applying machine learning to HOL\ntheorem proving.\n", "pdf": "/pdf/81bc078db86f22433df5930629717f6545aa4d3e.pdf", "paperhash": "kaliszyk|holstep_a_machine_learning_dataset_for_higherorder_logic_theorem_proving", "conflicts": ["uibk.ac.at", "google.com"], "keywords": [], "authors": ["Cezary Kaliszyk", "Fran\u00e7ois Chollet", "Christian Szegedy"], "authorids": ["cezary.kaliszyk@uibk.ac.at", "fchollet@google.com", "szegedy@google.com"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287753881, "id": "ICLR.cc/2017/conference/-/paper42/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "ryuxYmvel", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper42/reviewers", "ICLR.cc/2017/conference/paper42/areachairs"], "cdate": 1485287753881}}}, {"tddate": null, "tmdate": 1481033656359, "tcdate": 1481033656354, "number": 2, "id": "SJgTvB4Xg", "invitation": "ICLR.cc/2017/conference/-/paper42/pre-review/question", "forum": "ryuxYmvel", "replyto": "ryuxYmvel", "signatures": ["ICLR.cc/2017/conference/paper42/AnonReviewer2"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/conference/paper42/AnonReviewer2"], "content": {"title": "When is this applicable?", "question": "Thanks for the interesting paper. In your results you report proof step classification accuracy. As in AlphaGo this reflects the ability of your models in mimicking the bias in proof structure of proofs that humans discovered. Can you comment whether this bias will affect an automated theorem prover if these models are used as subroutines? Moreover, it's possible that the class of proofs which we find difficult are exactly the proofs for which this method won't help. Thanks!"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"TL;DR": "", "title": "HolStep: A Machine Learning Dataset for Higher-order Logic Theorem Proving", "abstract": "Large computer-understandable proofs consist of millions of intermediate\nlogical steps. The vast majority of such steps originate from manually\nselected and manually guided heuristics applied to intermediate goals.\nSo far, machine learning has generally not been used to filter or\ngenerate these steps. In this paper, we introduce a new dataset based on\nHigher-Order Logic (HOL) proofs, for the purpose of developing new\nmachine learning-based theorem-proving strategies. We make this dataset\npublicly available under the BSD license. We propose various machine\nlearning tasks that can be performed on this dataset, and discuss their\nsignificance for theorem proving. We also benchmark a set of simple baseline\nmachine learning models suited for the tasks (including logistic regression\nconvolutional neural networks and recurrent neural networks). The results of our\nbaseline models show the promise of applying machine learning to HOL\ntheorem proving.\n", "pdf": "/pdf/81bc078db86f22433df5930629717f6545aa4d3e.pdf", "paperhash": "kaliszyk|holstep_a_machine_learning_dataset_for_higherorder_logic_theorem_proving", "conflicts": ["uibk.ac.at", "google.com"], "keywords": [], "authors": ["Cezary Kaliszyk", "Fran\u00e7ois Chollet", "Christian Szegedy"], "authorids": ["cezary.kaliszyk@uibk.ac.at", "fchollet@google.com", "szegedy@google.com"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1480741199000, "tmdate": 1481033656859, "id": "ICLR.cc/2017/conference/-/paper42/pre-review/question", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/conference/paper42/reviewers"], "noninvitees": ["ICLR.cc/2017/conference/paper42/AnonReviewer1", "ICLR.cc/2017/conference/paper42/AnonReviewer2"], "reply": {"forum": "ryuxYmvel", "replyto": "ryuxYmvel", "writers": {"values-regex": "ICLR.cc/2017/conference/paper42/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/conference/paper42/AnonReviewer[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your question.", "value-regex": ".{1,500}"}, "question": {"order": 2, "description": "Your question", "value-regex": "[\\S\\s]{1,5000}"}}}, "nonreaders": [], "expdate": 1488517199000, "cdate": 1481033656859}}}, {"tddate": null, "tmdate": 1480691734131, "tcdate": 1480691734125, "number": 1, "id": "B1RMgGkXg", "invitation": "ICLR.cc/2017/conference/-/paper42/pre-review/question", "forum": "ryuxYmvel", "replyto": "ryuxYmvel", "signatures": ["ICLR.cc/2017/conference/paper42/AnonReviewer1"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/conference/paper42/AnonReviewer1"], "content": {"title": "The dataset extraction method", "question": "In Section 2, you describe the extraction process for the dataset. It becomes clear that it was not a trivial undertaking and probably even more subtleties had to be taken into account to generate the final dataset. Could the same strategy/code be applied directly to other proofs?\n\nIn the conclusion, you state that other ITPs or ATPs could be targeted in future work, whereas it could be interesting to integrate even more proofs into the existing dataset. Are you planning to disclose your code for dataset generation?"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"TL;DR": "", "title": "HolStep: A Machine Learning Dataset for Higher-order Logic Theorem Proving", "abstract": "Large computer-understandable proofs consist of millions of intermediate\nlogical steps. The vast majority of such steps originate from manually\nselected and manually guided heuristics applied to intermediate goals.\nSo far, machine learning has generally not been used to filter or\ngenerate these steps. In this paper, we introduce a new dataset based on\nHigher-Order Logic (HOL) proofs, for the purpose of developing new\nmachine learning-based theorem-proving strategies. We make this dataset\npublicly available under the BSD license. We propose various machine\nlearning tasks that can be performed on this dataset, and discuss their\nsignificance for theorem proving. We also benchmark a set of simple baseline\nmachine learning models suited for the tasks (including logistic regression\nconvolutional neural networks and recurrent neural networks). The results of our\nbaseline models show the promise of applying machine learning to HOL\ntheorem proving.\n", "pdf": "/pdf/81bc078db86f22433df5930629717f6545aa4d3e.pdf", "paperhash": "kaliszyk|holstep_a_machine_learning_dataset_for_higherorder_logic_theorem_proving", "conflicts": ["uibk.ac.at", "google.com"], "keywords": [], "authors": ["Cezary Kaliszyk", "Fran\u00e7ois Chollet", "Christian Szegedy"], "authorids": ["cezary.kaliszyk@uibk.ac.at", "fchollet@google.com", "szegedy@google.com"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1480741199000, "tmdate": 1481033656859, "id": "ICLR.cc/2017/conference/-/paper42/pre-review/question", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/conference/paper42/reviewers"], "noninvitees": ["ICLR.cc/2017/conference/paper42/AnonReviewer1", "ICLR.cc/2017/conference/paper42/AnonReviewer2"], "reply": {"forum": "ryuxYmvel", "replyto": "ryuxYmvel", "writers": {"values-regex": "ICLR.cc/2017/conference/paper42/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/conference/paper42/AnonReviewer[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your question.", "value-regex": ".{1,500}"}, "question": {"order": 2, "description": "Your question", "value-regex": "[\\S\\s]{1,5000}"}}}, "nonreaders": [], "expdate": 1488517199000, "cdate": 1481033656859}}}], "count": 12}