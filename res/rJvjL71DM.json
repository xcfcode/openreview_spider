{"notes": [{"tddate": null, "replyto": null, "ddate": null, "tmdate": 1528124477329, "tcdate": 1518446239253, "number": 127, "cdate": 1518446239253, "id": "rJvjL71DM", "invitation": "ICLR.cc/2018/Workshop/-/Submission", "forum": "rJvjL71DM", "signatures": ["~Lior_Wolf1"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Workshop"], "content": {"title": "Visual Analogies between Atari Games for Studying Transfer Learning in RL", "abstract": "In this work, we ask the following question: can visual analogies, learned in an unsupervised way, be used in order to transfer knowledge between pairs of games and even play one game using an agent trained for another game. We attempt to answer this research question by creating visual analogies between a pair of games: a source game and a target game. For example, given a video frame in the target game, we map it to an analogous state in the source game and then attempt to play using a trained policy learned for the source game. We demonstrate convincing visual mapping between four pairs of games (eight mappings). These mappings are used to evaluate three transfer learning approaches. The code and models are available at https://github.com/doronsobol/Visual_analogies_for_RL_transfer_Learning.\n", "paperhash": "sobol|visual_analogies_between_atari_games_for_studying_transfer_learning_in_rl", "_bibtex": "@misc{\n  sobol2018visual,\n  title={Visual Analogies between Atari Games for Studying Transfer Learning in RL},\n  author={Doron Sobol and Lior Wolf and Yaniv Taigman},\n  year={2018},\n  url={https://openreview.net/forum?id=rJvjL71DM}\n}", "authorids": ["doronsobol@gmail.com", "wolf@fb.com", "yaniv@fb.com"], "authors": ["Doron Sobol", "Lior Wolf", "Yaniv Taigman"], "keywords": [], "pdf": "/pdf/8abe8517a4f35b1b6bba8b21245ae5f69a35708e.pdf"}, "nonreaders": [], "details": {"replyCount": 4, "writable": false, "overwriting": [], "revisions": false, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1518472800000, "tmdate": 1518474081690, "id": "ICLR.cc/2018/Workshop/-/Submission", "writers": ["ICLR.cc/2018/Workshop"], "signatures": ["ICLR.cc/2018/Workshop"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": null, "replyto": null, "writers": {"values": ["ICLR.cc/2018/Workshop"]}, "signatures": {"values-regex": "~.*|ICLR.cc/2018/Workshop", "description": "Your authorized identity to be associated with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"pdf": {"required": true, "order": 9, "value-regex": "upload", "description": "Upload a PDF file that ends with .pdf"}, "title": {"required": true, "order": 1, "description": "Title of paper.", "value-regex": ".{1,250}"}, "abstract": {"required": true, "order": 8, "description": "Abstract of paper.", "value-regex": "[\\S\\s]{1,5000}"}, "authors": {"required": true, "order": 2, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of author names. Please provide real names; identities will be anonymized."}, "keywords": {"order": 6, "values-regex": "(^$)|[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of keywords."}, "TL;DR": {"required": false, "order": 7, "description": "\"Too Long; Didn't Read\": a short sentence describing your paper", "value-regex": "[^\\n]{0,500}"}, "authorids": {"required": true, "order": 3, "values-regex": "([a-z0-9_\\-\\.]{2,}@[a-z0-9_\\-\\.]{2,}\\.[a-z]{2,},){0,}([a-z0-9_\\-\\.]{2,}@[a-z0-9_\\-\\.]{2,}\\.[a-z]{2,})", "description": "Comma separated list of author email addresses, lowercased, in the same order as above. For authors with existing OpenReview accounts, please make sure that the provided email address(es) match those listed in the author's profile. Please provide real emails; identities will be anonymized."}}}, "nonreaders": [], "noninvitees": [], "expdate": 1526248800000, "cdate": 1518474081690}}}, {"tddate": null, "ddate": null, "original": null, "tmdate": 1521582970322, "tcdate": 1520005096975, "number": 1, "cdate": 1520005096975, "id": "ry-gexvOf", "invitation": "ICLR.cc/2018/Workshop/-/Paper127/Official_Review", "forum": "rJvjL71DM", "replyto": "rJvjL71DM", "signatures": ["ICLR.cc/2018/Workshop/Paper127/AnonReviewer2"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Workshop/Paper127/AnonReviewer2"], "content": {"title": "A transfer learning technique lacking clear practical applications", "rating": "4: Ok but not good enough - rejection", "review": "This paper proposes an RL transfer learning algorithm between Atari games, based on mapping a game state representation (as pre-processed visual input) to another similar game\u2019s state representation. This requires both games to have relatively similar state representations and game mechanics, for instance in both Pong and Breakout the player needs to catch a ball with a paddle at the bottom of the screen (after rotating Pong accordingly). Authors investigate three transfer learning schemes, with the best one consisting in pre-training the policy on game #1 with states mapped to game #2\u2019s representation, before fine-tuning it on game #2.\n\nThis sounds like an intriguing idea, but to be honest I am not an expert in transfer learning, and the lack of related work makes it hard for me to assess its originality. Although I am not very familiar with this research, I know there is active work on transferring in particular policies learned in simulators into the real world, and it seems to me that there should be links to be made with such approaches. In addition, the (GAN-based) technique to map states from one game to another is presented way too briefly for me to understand how it works (and in particular how much data from the target game is required, since this can be a constraint in a transfer learning scenario). Images from Fig. 2 show that it learned a rather \u00ab naive \u00bb mapping, with the game-specific elements (at the top of the screen) being generated essentially as constant pixels. This is not particularly surprising since there is no obvious true answer to this mapping task, but it suggests it is going to be hard to learn meaningful policies from such representations, where important state information may not be available (I can see how it can still work to some extent here because for instance just being able to catch the ball is already a decent strategy in both Pong and Breakout, but this may not always be the case). Overall the usefulness of this method seems limited to me, and there is no discussion on potential practical applications (nor on the reasons why / when the proposed techiques may or may not work).\n\nOn the positive side, I appreciate that the authors are willing to share some negative results as well, along with the associated code.\n\nI would also like to suggest another related transfer learning strategy that might be worth experimenting with: train a policy pi_s on frames G^-1(G(source game frame)), then pre-train pi_t to mimick pi_s(G^-1(target game frame)). This is close to the \u00ab Distillation \u00bb strategy but with the difference that pi_s would be trained on mapped images, which might work better (?)", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Visual Analogies between Atari Games for Studying Transfer Learning in RL", "abstract": "In this work, we ask the following question: can visual analogies, learned in an unsupervised way, be used in order to transfer knowledge between pairs of games and even play one game using an agent trained for another game. We attempt to answer this research question by creating visual analogies between a pair of games: a source game and a target game. For example, given a video frame in the target game, we map it to an analogous state in the source game and then attempt to play using a trained policy learned for the source game. We demonstrate convincing visual mapping between four pairs of games (eight mappings). These mappings are used to evaluate three transfer learning approaches. The code and models are available at https://github.com/doronsobol/Visual_analogies_for_RL_transfer_Learning.\n", "paperhash": "sobol|visual_analogies_between_atari_games_for_studying_transfer_learning_in_rl", "_bibtex": "@misc{\n  sobol2018visual,\n  title={Visual Analogies between Atari Games for Studying Transfer Learning in RL},\n  author={Doron Sobol and Lior Wolf and Yaniv Taigman},\n  year={2018},\n  url={https://openreview.net/forum?id=rJvjL71DM}\n}", "authorids": ["doronsobol@gmail.com", "wolf@fb.com", "yaniv@fb.com"], "authors": ["Doron Sobol", "Lior Wolf", "Yaniv Taigman"], "keywords": [], "pdf": "/pdf/8abe8517a4f35b1b6bba8b21245ae5f69a35708e.pdf"}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1520657999000, "tmdate": 1521582970105, "id": "ICLR.cc/2018/Workshop/-/Paper127/Official_Review", "writers": ["ICLR.cc/2018/Workshop"], "signatures": ["ICLR.cc/2018/Workshop"], "readers": ["everyone"], "invitees": ["ICLR.cc/2018/Workshop/Paper127/Reviewers"], "noninvitees": ["ICLR.cc/2018/Workshop/Paper127/AnonReviewer2", "ICLR.cc/2018/Workshop/Paper127/AnonReviewer1", "ICLR.cc/2018/Workshop/Paper127/AnonReviewer3"], "reply": {"forum": "rJvjL71DM", "replyto": "rJvjL71DM", "writers": {"values-regex": "ICLR.cc/2018/Workshop/Paper127/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2018/Workshop/Paper127/AnonReviewer[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"required": true, "order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"required": true, "order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "value-regex": "[\\S\\s]{1,200000}"}, "rating": {"required": true, "order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"required": true, "order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1528433999000, "cdate": 1521582970105}}}, {"tddate": null, "ddate": null, "original": null, "tmdate": 1521582944838, "tcdate": 1520250336686, "number": 2, "cdate": 1520250336686, "id": "SkKyRi5Oz", "invitation": "ICLR.cc/2018/Workshop/-/Paper127/Official_Review", "forum": "rJvjL71DM", "replyto": "rJvjL71DM", "signatures": ["ICLR.cc/2018/Workshop/Paper127/AnonReviewer1"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Workshop/Paper127/AnonReviewer1"], "content": {"title": "Visual Analogies may not be enough for transfer learning between Atari games", "rating": "4: Ok but not good enough - rejection", "review": "Summary: Visual analogies between individual frames in pairs of (source & target) Atari  games are employed in the service of policy learning on the target game. Several transfer methods are used in order to take advantage of visual analogies, but results are mixed with the exception of transfer to the game of Tennis, where data efficiency seems better.\n\nPros:\nFairly generic video conversion methods were used, based on GANs.\nSeveral knowledge transfer methods were evaluated, including dataset augmentation, distillation and pre-training.\nIn my mind, the paper provides convincing evidence suggesting that visual analogies are *not* sufficient in the Atari domain.\n\nCons:\nDomain knowledge in the form of game-specific image pre-processing is used to facilitate the process. \nSome amount of manual data collection is used, which makes it difficult to infer how the method would perform with a different human in the loop or with a different game were expert trajectories are not available.\nIt is very unlikely that states in Atari video-games would be generally well characterized by single frames, especially in fast paced games such as Breakout. This is because it is not possible to infer a ball\u2019s direction from a single frame. I suggest using frame sequences as the starting point for state analogies.\n\nNotes/Questions:\nPerhaps the authors could clarify why visual analogies are supposed to be sufficient for transfer. IMHO it does not follow that similar frames should lead to similar actions, not even within a single game. In fact, state aliasing is a well known problem in (deep) reinforcement learning [1].\nConsidering only visual analogies ignores games dynamics, which is obviously dangerous in fast-paced, \u201dreflex\u201d based games as those considered; for example, ignoring dynamics implicitly assumes the ball is moving at the same speed in both games, which is obviously not true, since the ball accelerates across the game of Breakout.\nIt may be advisable to evaluate the components of the approach in isolation. Would you see transfer if you were to use Vertically Flipped Pong as your source game and transfer to regular Pong? What about Horizontally Flipped Pong as a source. I suggest perfecting the method such that these \u2018artificial\u2019 transfer problems work well.\nSince you\u2019re using GANs, are all the hand-engineer, game-specific transformations really required? They severely restrict the applicability of the method, imho.\nThere may exist domains where visual analogies are indeed sufficient, but different Atari games may not be the best examples, particularly due to different dynamics of every game.\n\n\n[1] E.g. https://arxiv.org/abs/1707.06887\n", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Visual Analogies between Atari Games for Studying Transfer Learning in RL", "abstract": "In this work, we ask the following question: can visual analogies, learned in an unsupervised way, be used in order to transfer knowledge between pairs of games and even play one game using an agent trained for another game. We attempt to answer this research question by creating visual analogies between a pair of games: a source game and a target game. For example, given a video frame in the target game, we map it to an analogous state in the source game and then attempt to play using a trained policy learned for the source game. We demonstrate convincing visual mapping between four pairs of games (eight mappings). These mappings are used to evaluate three transfer learning approaches. The code and models are available at https://github.com/doronsobol/Visual_analogies_for_RL_transfer_Learning.\n", "paperhash": "sobol|visual_analogies_between_atari_games_for_studying_transfer_learning_in_rl", "_bibtex": "@misc{\n  sobol2018visual,\n  title={Visual Analogies between Atari Games for Studying Transfer Learning in RL},\n  author={Doron Sobol and Lior Wolf and Yaniv Taigman},\n  year={2018},\n  url={https://openreview.net/forum?id=rJvjL71DM}\n}", "authorids": ["doronsobol@gmail.com", "wolf@fb.com", "yaniv@fb.com"], "authors": ["Doron Sobol", "Lior Wolf", "Yaniv Taigman"], "keywords": [], "pdf": "/pdf/8abe8517a4f35b1b6bba8b21245ae5f69a35708e.pdf"}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1520657999000, "tmdate": 1521582970105, "id": "ICLR.cc/2018/Workshop/-/Paper127/Official_Review", "writers": ["ICLR.cc/2018/Workshop"], "signatures": ["ICLR.cc/2018/Workshop"], "readers": ["everyone"], "invitees": ["ICLR.cc/2018/Workshop/Paper127/Reviewers"], "noninvitees": ["ICLR.cc/2018/Workshop/Paper127/AnonReviewer2", "ICLR.cc/2018/Workshop/Paper127/AnonReviewer1", "ICLR.cc/2018/Workshop/Paper127/AnonReviewer3"], "reply": {"forum": "rJvjL71DM", "replyto": "rJvjL71DM", "writers": {"values-regex": "ICLR.cc/2018/Workshop/Paper127/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2018/Workshop/Paper127/AnonReviewer[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"required": true, "order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"required": true, "order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "value-regex": "[\\S\\s]{1,200000}"}, "rating": {"required": true, "order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"required": true, "order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1528433999000, "cdate": 1521582970105}}}, {"tddate": null, "ddate": null, "original": null, "tmdate": 1521582611139, "tcdate": 1520887993564, "number": 3, "cdate": 1520887993564, "id": "rybT_w4FG", "invitation": "ICLR.cc/2018/Workshop/-/Paper127/Official_Review", "forum": "rJvjL71DM", "replyto": "rJvjL71DM", "signatures": ["ICLR.cc/2018/Workshop/Paper127/AnonReviewer3"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Workshop/Paper127/AnonReviewer3"], "content": {"title": "review", "rating": "5: Marginally below acceptance threshold", "review": "The authors propose a brief study on the effectiveness of certain kinds of transfer-learning in RL tasks, employing visual-analogies as the basis for transferring information.\n\nThe paper is reasonably straightforward to follow -- although there are a couple of places where the exposition is short of detail and difficult to follow (e.g. Section 2.2).\n\nSome issues I encountered:\n1. The authors claim \".. we are successful at the challenging video conversion task ...\"\n   This is somewhat difficult to substantiate for two reasons:\n   a. There is a fairly substantial amount of manual feature-extraction/augmentation to enable this conversion, and\n   b. The is no quantitative evaluation of it -- just a few qualitative examples with not too much in the way of explanation of what to look for.\n\n2. They also state \"... a critical view of the practical value of TL in the current RL landscape is seldom heard.\"\n   The manuscript does not state anything about the value of TL for RL. If the authors intended the lack of success they faced as evidence for it, I'm afraid that doesn't quite fit. If anything, the lack of success points to the difficultly in making TL work in RL, not so much about the value of doing TL in/for RL.\n\n3. The description of transfer-learning methods in Section 2.2 is somewhat difficult to follow; particularly the 'distillation' part. It's not clear what the authors refer to as \"fine-tuning\" here.\n   When they say \"Directly fine tunning[sic] $\\pi_s$ failed ...\", do they mean they were trying to directly adapt a policy learnt on the source game in the target game?\n\n4. It's not clear if the different 'levels of success' proposed are actually computed off-of significant values. In the graphs reported in the appendix, the authors state that the mean of three runs was plotted, but the std-deviation/variance is not present.\nWithout this, it's really difficult to say if, say the Breakout->Tennis transfer, actually does outperform the baseline (the difference in asymptotic reward obtained is almost negligible), or if the ordering is simply what it is because of randomness.\n\nOverall, I feel that the manuscript could have more value with a careful analysis of results [the significance (rather, the potential lack of) of results worries me] and a cleaned-up exposition.\n", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Visual Analogies between Atari Games for Studying Transfer Learning in RL", "abstract": "In this work, we ask the following question: can visual analogies, learned in an unsupervised way, be used in order to transfer knowledge between pairs of games and even play one game using an agent trained for another game. We attempt to answer this research question by creating visual analogies between a pair of games: a source game and a target game. For example, given a video frame in the target game, we map it to an analogous state in the source game and then attempt to play using a trained policy learned for the source game. We demonstrate convincing visual mapping between four pairs of games (eight mappings). These mappings are used to evaluate three transfer learning approaches. The code and models are available at https://github.com/doronsobol/Visual_analogies_for_RL_transfer_Learning.\n", "paperhash": "sobol|visual_analogies_between_atari_games_for_studying_transfer_learning_in_rl", "_bibtex": "@misc{\n  sobol2018visual,\n  title={Visual Analogies between Atari Games for Studying Transfer Learning in RL},\n  author={Doron Sobol and Lior Wolf and Yaniv Taigman},\n  year={2018},\n  url={https://openreview.net/forum?id=rJvjL71DM}\n}", "authorids": ["doronsobol@gmail.com", "wolf@fb.com", "yaniv@fb.com"], "authors": ["Doron Sobol", "Lior Wolf", "Yaniv Taigman"], "keywords": [], "pdf": "/pdf/8abe8517a4f35b1b6bba8b21245ae5f69a35708e.pdf"}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1520657999000, "tmdate": 1521582970105, "id": "ICLR.cc/2018/Workshop/-/Paper127/Official_Review", "writers": ["ICLR.cc/2018/Workshop"], "signatures": ["ICLR.cc/2018/Workshop"], "readers": ["everyone"], "invitees": ["ICLR.cc/2018/Workshop/Paper127/Reviewers"], "noninvitees": ["ICLR.cc/2018/Workshop/Paper127/AnonReviewer2", "ICLR.cc/2018/Workshop/Paper127/AnonReviewer1", "ICLR.cc/2018/Workshop/Paper127/AnonReviewer3"], "reply": {"forum": "rJvjL71DM", "replyto": "rJvjL71DM", "writers": {"values-regex": "ICLR.cc/2018/Workshop/Paper127/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2018/Workshop/Paper127/AnonReviewer[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"required": true, "order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"required": true, "order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "value-regex": "[\\S\\s]{1,200000}"}, "rating": {"required": true, "order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"required": true, "order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1528433999000, "cdate": 1521582970105}}}, {"tddate": null, "ddate": null, "original": null, "tmdate": 1521573598113, "tcdate": 1521573598113, "number": 236, "cdate": 1521573597772, "id": "ry8JJ1J5M", "invitation": "ICLR.cc/2018/Workshop/-/Acceptance_Decision", "forum": "rJvjL71DM", "replyto": "rJvjL71DM", "signatures": ["ICLR.cc/2018/Workshop/Program_Chairs"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Workshop/Program_Chairs"], "content": {"decision": "Reject", "title": "ICLR 2018 Workshop Acceptance Decision", "comment": "Based on the reviews, this paper has not been accepted for presentation at the ICLR workshop. However, the conversation and updates can continue to appear here on OpenReview."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Visual Analogies between Atari Games for Studying Transfer Learning in RL", "abstract": "In this work, we ask the following question: can visual analogies, learned in an unsupervised way, be used in order to transfer knowledge between pairs of games and even play one game using an agent trained for another game. We attempt to answer this research question by creating visual analogies between a pair of games: a source game and a target game. For example, given a video frame in the target game, we map it to an analogous state in the source game and then attempt to play using a trained policy learned for the source game. We demonstrate convincing visual mapping between four pairs of games (eight mappings). These mappings are used to evaluate three transfer learning approaches. The code and models are available at https://github.com/doronsobol/Visual_analogies_for_RL_transfer_Learning.\n", "paperhash": "sobol|visual_analogies_between_atari_games_for_studying_transfer_learning_in_rl", "_bibtex": "@misc{\n  sobol2018visual,\n  title={Visual Analogies between Atari Games for Studying Transfer Learning in RL},\n  author={Doron Sobol and Lior Wolf and Yaniv Taigman},\n  year={2018},\n  url={https://openreview.net/forum?id=rJvjL71DM}\n}", "authorids": ["doronsobol@gmail.com", "wolf@fb.com", "yaniv@fb.com"], "authors": ["Doron Sobol", "Lior Wolf", "Yaniv Taigman"], "keywords": [], "pdf": "/pdf/8abe8517a4f35b1b6bba8b21245ae5f69a35708e.pdf"}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "tmdate": 1518629844880, "id": "ICLR.cc/2018/Workshop/-/Acceptance_Decision", "writers": ["ICLR.cc/2018/Workshop"], "signatures": ["ICLR.cc/2018/Workshop"], "readers": ["everyone"], "invitees": ["ICLR.cc/2018/Workshop/Program_Chairs"], "reply": {"forum": null, "replyto": null, "invitation": "ICLR.cc/2018/Workshop/-/Submission", "writers": {"values": ["ICLR.cc/2018/Workshop/Program_Chairs"]}, "signatures": {"description": "How your identity will be displayed with the above content.", "values": ["ICLR.cc/2018/Workshop/Program_Chairs"]}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["ICLR.cc/2018/Workshop/Program_Chairs", "everyone"]}, "content": {"title": {"required": true, "order": 1, "value": "ICLR 2018 Workshop Acceptance Decision"}, "comment": {"required": false, "order": 3, "description": "(optional) Comment on this decision.", "value-regex": "[\\S\\s]{0,5000}"}, "decision": {"required": true, "order": 2, "value-dropdown": ["Accept", "Reject"]}}}, "nonreaders": [], "noninvitees": [], "cdate": 1518629844880}}}], "count": 5}