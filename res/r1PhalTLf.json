{"notes": [{"tddate": null, "replyto": null, "ddate": null, "tmdate": 1528124475602, "tcdate": 1518304686910, "number": 59, "cdate": 1518304686910, "id": "r1PhalTLf", "invitation": "ICLR.cc/2018/Workshop/-/Submission", "forum": "r1PhalTLf", "signatures": ["~Robert_J._Wang1"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Workshop"], "content": {"title": "Pelee: A Real-Time Object Detection System on Mobile Devices", "abstract": "An increasing need of running Convolutional Neural Network (CNN)  models on mobile devices with limited computing power and memory resource encourages studies on efficient model design. A number of efficient architectures have been proposed in recent years,  for example, MobileNet, ShuffleNet, and NASNet-A. However, all these models are heavily dependent on depthwise separable convolution which lacks efficient implementation in most deep learning frameworks. In this study, we propose an efficient architecture named PeleeNet, which is built with conventional convolution instead. On ImageNet ILSVRC 2012 dataset, our proposed PeleeNet achieves a higher accuracy by 0.6% (71.3% vs. 70.7%) and 11% lower computational cost than MobileNet, the state-of-the-art efficient architecture. Meanwhile, PeleeNet is only half of the model size of MobileNet. We then propose a real-time object detection system by combining PeleeNet with Single Shot MultiBox Detector (SSD) method and optimizing the architecture for fast speed. Our proposed detection system, named Pelee, achieves 70.9% mAP (mean average precision) on PASCAL VOC2007 dataset at the speed of 17.1 FPS on iPhone 6s and 23.6 FPS on iPhone 8. Compared to TinyYOLOv2, our proposed Pelee is more accurate (70.9% vs. 57.1%), 1.88 times lower in computational cost and 1.92 times smaller in model size. The code and models are open sourced.\n", "paperhash": "wang|pelee_a_realtime_object_detection_system_on_mobile_devices", "_bibtex": "@misc{\n  wang2018pelee:,\n  title={Pelee: A Real-Time Object Detection System on Mobile Devices},\n  author={Robert J. Wang and Xiang Li and Shuang Ao and Charles X. Ling},\n  year={2018},\n  url={https://openreview.net/forum?id=r1PhalTLf}\n}", "authorids": ["jwan563@uwo.ca", "lxiang2@uwo.ca", "sao@uwo.ca", "charles.ling@uwo.ca"], "authors": ["Robert J. Wang", "Xiang Li", "Shuang Ao", "Charles X. Ling"], "keywords": ["Real-time Object Detection", "Convolutional Neural Network", "Efficient Architecture", "Mobile Device", "Embedded Vision"], "pdf": "/pdf/f2d2bdb13ef82e9f8e5fe1d3c70ba3f9a178560d.pdf"}, "nonreaders": [], "details": {"replyCount": 3, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1518472800000, "tmdate": 1518474081690, "id": "ICLR.cc/2018/Workshop/-/Submission", "writers": ["ICLR.cc/2018/Workshop"], "signatures": ["ICLR.cc/2018/Workshop"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": null, "replyto": null, "writers": {"values": ["ICLR.cc/2018/Workshop"]}, "signatures": {"values-regex": "~.*|ICLR.cc/2018/Workshop", "description": "Your authorized identity to be associated with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"pdf": {"required": true, "order": 9, "value-regex": "upload", "description": "Upload a PDF file that ends with .pdf"}, "title": {"required": true, "order": 1, "description": "Title of paper.", "value-regex": ".{1,250}"}, "abstract": {"required": true, "order": 8, "description": "Abstract of paper.", "value-regex": "[\\S\\s]{1,5000}"}, "authors": {"required": true, "order": 2, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of author names. Please provide real names; identities will be anonymized."}, "keywords": {"order": 6, "values-regex": "(^$)|[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of keywords."}, "TL;DR": {"required": false, "order": 7, "description": "\"Too Long; Didn't Read\": a short sentence describing your paper", "value-regex": "[^\\n]{0,500}"}, "authorids": {"required": true, "order": 3, "values-regex": "([a-z0-9_\\-\\.]{2,}@[a-z0-9_\\-\\.]{2,}\\.[a-z]{2,},){0,}([a-z0-9_\\-\\.]{2,}@[a-z0-9_\\-\\.]{2,}\\.[a-z]{2,})", "description": "Comma separated list of author email addresses, lowercased, in the same order as above. For authors with existing OpenReview accounts, please make sure that the provided email address(es) match those listed in the author's profile. Please provide real emails; identities will be anonymized."}}}, "nonreaders": [], "noninvitees": [], "expdate": 1526248800000, "cdate": 1518474081690}}}, {"tddate": null, "ddate": null, "original": null, "tmdate": 1521582711732, "tcdate": 1520688187198, "number": 1, "cdate": 1520688187198, "id": "HymB2LZKG", "invitation": "ICLR.cc/2018/Workshop/-/Paper59/Official_Review", "forum": "r1PhalTLf", "replyto": "r1PhalTLf", "signatures": ["ICLR.cc/2018/Workshop/Paper59/AnonReviewer1"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Workshop/Paper59/AnonReviewer1"], "content": {"title": "-", "rating": "6: Marginally above acceptance threshold", "review": "This paper proposes a new convnet architecture intended to be accurate yet efficient for inference on mobile devices. It does so using computationally efficient convolutional blocks involving bottleneck layers. While somewhat incremental, the results in terms of accuracy (for classification and detection) and computational efficiency compare favorably with other models designed for efficient mobile inference*, and good performance on mobile devices is a topic of wide interest.  The code and models are available. A few comments:\n\n- The bottleneck structure of the 2-way dense layer is similar to that of ResNets [He et al., 2016]. ResNets should be cited as related work in the description of the module at the least.  Ideally there would also be a direct comparison to the ResNet module design vs. the proposed 2-way dense layer in terms of computational efficiency and accuracy, but I don\u2019t think this is necessary for a workshop submission.\n\n- I wasn\u2019t able to understand the \u201cResidual Prediction Block\u201d description -- it should be clarified.  E.g., how many residual blocks are there (just 1?)? What are its inputs? Why not use residuals elsewhere?\n\n- What are \u201cMACs\u201d (as used in the results Tables 1 and 2)?  This should be defined.\n\n(* I have not closely followed the progress on efficient mobile convnet architectures and am assuming the alternatives this work compares against -- MobileNet, DenseNet, TinyYOLO, etc. -- are the state of the art.)", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Pelee: A Real-Time Object Detection System on Mobile Devices", "abstract": "An increasing need of running Convolutional Neural Network (CNN)  models on mobile devices with limited computing power and memory resource encourages studies on efficient model design. A number of efficient architectures have been proposed in recent years,  for example, MobileNet, ShuffleNet, and NASNet-A. However, all these models are heavily dependent on depthwise separable convolution which lacks efficient implementation in most deep learning frameworks. In this study, we propose an efficient architecture named PeleeNet, which is built with conventional convolution instead. On ImageNet ILSVRC 2012 dataset, our proposed PeleeNet achieves a higher accuracy by 0.6% (71.3% vs. 70.7%) and 11% lower computational cost than MobileNet, the state-of-the-art efficient architecture. Meanwhile, PeleeNet is only half of the model size of MobileNet. We then propose a real-time object detection system by combining PeleeNet with Single Shot MultiBox Detector (SSD) method and optimizing the architecture for fast speed. Our proposed detection system, named Pelee, achieves 70.9% mAP (mean average precision) on PASCAL VOC2007 dataset at the speed of 17.1 FPS on iPhone 6s and 23.6 FPS on iPhone 8. Compared to TinyYOLOv2, our proposed Pelee is more accurate (70.9% vs. 57.1%), 1.88 times lower in computational cost and 1.92 times smaller in model size. The code and models are open sourced.\n", "paperhash": "wang|pelee_a_realtime_object_detection_system_on_mobile_devices", "_bibtex": "@misc{\n  wang2018pelee:,\n  title={Pelee: A Real-Time Object Detection System on Mobile Devices},\n  author={Robert J. Wang and Xiang Li and Shuang Ao and Charles X. Ling},\n  year={2018},\n  url={https://openreview.net/forum?id=r1PhalTLf}\n}", "authorids": ["jwan563@uwo.ca", "lxiang2@uwo.ca", "sao@uwo.ca", "charles.ling@uwo.ca"], "authors": ["Robert J. Wang", "Xiang Li", "Shuang Ao", "Charles X. Ling"], "keywords": ["Real-time Object Detection", "Convolutional Neural Network", "Efficient Architecture", "Mobile Device", "Embedded Vision"], "pdf": "/pdf/f2d2bdb13ef82e9f8e5fe1d3c70ba3f9a178560d.pdf"}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1520657999000, "tmdate": 1521582711502, "id": "ICLR.cc/2018/Workshop/-/Paper59/Official_Review", "writers": ["ICLR.cc/2018/Workshop"], "signatures": ["ICLR.cc/2018/Workshop"], "readers": ["everyone"], "invitees": ["ICLR.cc/2018/Workshop/Paper59/Reviewers"], "noninvitees": ["ICLR.cc/2018/Workshop/Paper59/AnonReviewer1", "ICLR.cc/2018/Workshop/Paper59/AnonReviewer3"], "reply": {"forum": "r1PhalTLf", "replyto": "r1PhalTLf", "writers": {"values-regex": "ICLR.cc/2018/Workshop/Paper59/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2018/Workshop/Paper59/AnonReviewer[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"required": true, "order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"required": true, "order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "value-regex": "[\\S\\s]{1,200000}"}, "rating": {"required": true, "order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"required": true, "order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1528433999000, "cdate": 1521582711502}}}, {"tddate": null, "ddate": null, "original": null, "tmdate": 1521582614768, "tcdate": 1520876572855, "number": 2, "cdate": 1520876572855, "id": "S1BmhN4FG", "invitation": "ICLR.cc/2018/Workshop/-/Paper59/Official_Review", "forum": "r1PhalTLf", "replyto": "r1PhalTLf", "signatures": ["ICLR.cc/2018/Workshop/Paper59/AnonReviewer3"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Workshop/Paper59/AnonReviewer3"], "content": {"title": "Nice work on improving computing constraint object-detection architectures", "rating": "7: Good paper, accept", "review": "This work addresses the task of creating high quality object detection system at low computational cost.\n\nThe heart of this work is a new modular convolutional block (similar to Inception) that is designed for more efficient processing of computer vision signals, especially for (but not limited to) object detection.\n\nThe authors report significant improvements over MobileNet based SSD at a similar or lower computational cost.\n\nThis work is original and the paper is clearly and well written, clearly suitable for a workshop submission.\n\n", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Pelee: A Real-Time Object Detection System on Mobile Devices", "abstract": "An increasing need of running Convolutional Neural Network (CNN)  models on mobile devices with limited computing power and memory resource encourages studies on efficient model design. A number of efficient architectures have been proposed in recent years,  for example, MobileNet, ShuffleNet, and NASNet-A. However, all these models are heavily dependent on depthwise separable convolution which lacks efficient implementation in most deep learning frameworks. In this study, we propose an efficient architecture named PeleeNet, which is built with conventional convolution instead. On ImageNet ILSVRC 2012 dataset, our proposed PeleeNet achieves a higher accuracy by 0.6% (71.3% vs. 70.7%) and 11% lower computational cost than MobileNet, the state-of-the-art efficient architecture. Meanwhile, PeleeNet is only half of the model size of MobileNet. We then propose a real-time object detection system by combining PeleeNet with Single Shot MultiBox Detector (SSD) method and optimizing the architecture for fast speed. Our proposed detection system, named Pelee, achieves 70.9% mAP (mean average precision) on PASCAL VOC2007 dataset at the speed of 17.1 FPS on iPhone 6s and 23.6 FPS on iPhone 8. Compared to TinyYOLOv2, our proposed Pelee is more accurate (70.9% vs. 57.1%), 1.88 times lower in computational cost and 1.92 times smaller in model size. The code and models are open sourced.\n", "paperhash": "wang|pelee_a_realtime_object_detection_system_on_mobile_devices", "_bibtex": "@misc{\n  wang2018pelee:,\n  title={Pelee: A Real-Time Object Detection System on Mobile Devices},\n  author={Robert J. Wang and Xiang Li and Shuang Ao and Charles X. Ling},\n  year={2018},\n  url={https://openreview.net/forum?id=r1PhalTLf}\n}", "authorids": ["jwan563@uwo.ca", "lxiang2@uwo.ca", "sao@uwo.ca", "charles.ling@uwo.ca"], "authors": ["Robert J. Wang", "Xiang Li", "Shuang Ao", "Charles X. Ling"], "keywords": ["Real-time Object Detection", "Convolutional Neural Network", "Efficient Architecture", "Mobile Device", "Embedded Vision"], "pdf": "/pdf/f2d2bdb13ef82e9f8e5fe1d3c70ba3f9a178560d.pdf"}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1520657999000, "tmdate": 1521582711502, "id": "ICLR.cc/2018/Workshop/-/Paper59/Official_Review", "writers": ["ICLR.cc/2018/Workshop"], "signatures": ["ICLR.cc/2018/Workshop"], "readers": ["everyone"], "invitees": ["ICLR.cc/2018/Workshop/Paper59/Reviewers"], "noninvitees": ["ICLR.cc/2018/Workshop/Paper59/AnonReviewer1", "ICLR.cc/2018/Workshop/Paper59/AnonReviewer3"], "reply": {"forum": "r1PhalTLf", "replyto": "r1PhalTLf", "writers": {"values-regex": "ICLR.cc/2018/Workshop/Paper59/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2018/Workshop/Paper59/AnonReviewer[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"required": true, "order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"required": true, "order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "value-regex": "[\\S\\s]{1,200000}"}, "rating": {"required": true, "order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"required": true, "order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1528433999000, "cdate": 1521582711502}}}, {"tddate": null, "ddate": null, "original": null, "tmdate": 1521573560472, "tcdate": 1521573560472, "number": 77, "cdate": 1521573560136, "id": "SJgTCAAYf", "invitation": "ICLR.cc/2018/Workshop/-/Acceptance_Decision", "forum": "r1PhalTLf", "replyto": "r1PhalTLf", "signatures": ["ICLR.cc/2018/Workshop/Program_Chairs"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Workshop/Program_Chairs"], "content": {"decision": "Accept", "title": "ICLR 2018 Workshop Acceptance Decision", "comment": "Congratulations, your paper was accepted to the ICLR workshop."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Pelee: A Real-Time Object Detection System on Mobile Devices", "abstract": "An increasing need of running Convolutional Neural Network (CNN)  models on mobile devices with limited computing power and memory resource encourages studies on efficient model design. A number of efficient architectures have been proposed in recent years,  for example, MobileNet, ShuffleNet, and NASNet-A. However, all these models are heavily dependent on depthwise separable convolution which lacks efficient implementation in most deep learning frameworks. In this study, we propose an efficient architecture named PeleeNet, which is built with conventional convolution instead. On ImageNet ILSVRC 2012 dataset, our proposed PeleeNet achieves a higher accuracy by 0.6% (71.3% vs. 70.7%) and 11% lower computational cost than MobileNet, the state-of-the-art efficient architecture. Meanwhile, PeleeNet is only half of the model size of MobileNet. We then propose a real-time object detection system by combining PeleeNet with Single Shot MultiBox Detector (SSD) method and optimizing the architecture for fast speed. Our proposed detection system, named Pelee, achieves 70.9% mAP (mean average precision) on PASCAL VOC2007 dataset at the speed of 17.1 FPS on iPhone 6s and 23.6 FPS on iPhone 8. Compared to TinyYOLOv2, our proposed Pelee is more accurate (70.9% vs. 57.1%), 1.88 times lower in computational cost and 1.92 times smaller in model size. The code and models are open sourced.\n", "paperhash": "wang|pelee_a_realtime_object_detection_system_on_mobile_devices", "_bibtex": "@misc{\n  wang2018pelee:,\n  title={Pelee: A Real-Time Object Detection System on Mobile Devices},\n  author={Robert J. Wang and Xiang Li and Shuang Ao and Charles X. Ling},\n  year={2018},\n  url={https://openreview.net/forum?id=r1PhalTLf}\n}", "authorids": ["jwan563@uwo.ca", "lxiang2@uwo.ca", "sao@uwo.ca", "charles.ling@uwo.ca"], "authors": ["Robert J. Wang", "Xiang Li", "Shuang Ao", "Charles X. Ling"], "keywords": ["Real-time Object Detection", "Convolutional Neural Network", "Efficient Architecture", "Mobile Device", "Embedded Vision"], "pdf": "/pdf/f2d2bdb13ef82e9f8e5fe1d3c70ba3f9a178560d.pdf"}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "tmdate": 1518629844880, "id": "ICLR.cc/2018/Workshop/-/Acceptance_Decision", "writers": ["ICLR.cc/2018/Workshop"], "signatures": ["ICLR.cc/2018/Workshop"], "readers": ["everyone"], "invitees": ["ICLR.cc/2018/Workshop/Program_Chairs"], "reply": {"forum": null, "replyto": null, "invitation": "ICLR.cc/2018/Workshop/-/Submission", "writers": {"values": ["ICLR.cc/2018/Workshop/Program_Chairs"]}, "signatures": {"description": "How your identity will be displayed with the above content.", "values": ["ICLR.cc/2018/Workshop/Program_Chairs"]}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["ICLR.cc/2018/Workshop/Program_Chairs", "everyone"]}, "content": {"title": {"required": true, "order": 1, "value": "ICLR 2018 Workshop Acceptance Decision"}, "comment": {"required": false, "order": 3, "description": "(optional) Comment on this decision.", "value-regex": "[\\S\\s]{0,5000}"}, "decision": {"required": true, "order": 2, "value-dropdown": ["Accept", "Reject"]}}}, "nonreaders": [], "noninvitees": [], "cdate": 1518629844880}}}], "count": 4}