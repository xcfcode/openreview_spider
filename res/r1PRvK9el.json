{"notes": [{"tddate": null, "ddate": null, "cdate": null, "tmdate": 1486396635201, "tcdate": 1486396635201, "number": 1, "id": "H1Q1pGLOl", "invitation": "ICLR.cc/2017/conference/-/paper507/acceptance", "forum": "r1PRvK9el", "replyto": "r1PRvK9el", "signatures": ["ICLR.cc/2017/pcs"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/pcs"], "content": {"decision": "Reject", "title": "ICLR committee final decision", "comment": "This paper develops a new shared memory based model for doing inference in knowledge bases. The work shows strong empirical results, and potentially could be impactful. However the reviewers felt that the work was not completely convincing without more analysis into the mechanisms of the system itself. \n \n Pros:\n - Quality: The reviewers like the experimental results of this work, praising them as \"strikingly good\", but giving the caveat the dataset used is now a bit old for this task. \n \n Mixed:\n - Clarity: Some reviewers found the work to be fairly well-written although there was mixed opinions about the exposition. Details of the model could be better explained, as could the development of the model\n \n Cons:\n - Quality: The main criticism is not feeling that the methodology is motivated for this task. Multiple reviewers claim there is \"little analysis about how it works\". Or that was \"hard to see\" how this would help. All reviewers are in agreement, that the paper should explore more deeply what shared memory is adding to this task, and introduce the approach better in this regard."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"TL;DR": "", "title": "Implicit ReasoNet: Modeling Large-Scale Structured Relationships with Shared Memory", "abstract": "Recent studies on knowledge base completion, the task of recovering missing relationships based on recorded relations, demonstrate the importance of learning embeddings from multi-step relations. However, due to the size of knowledge bases, learning multi-step relations directly on top of observed instances could be costly. In this paper, we propose Implicit ReasoNets (IRNs), which is designed to perform large-scale inference implicitly through a search controller and shared memory. Unlike previous work, IRNs use training data to learn to perform multi-step inference through the shared memory, which is also jointly updated during training. While the inference procedure is not operating on top of observed instances for IRNs, our proposed model outperforms all previous approaches on the popular FB15k benchmark by more than 5.7%.", "pdf": "/pdf/2e8438d59fa94b4a252c91116cb86eaf877c76b1.pdf", "paperhash": "shen|implicit_reasonet_modeling_largescale_structured_relationships_with_shared_memory", "conflicts": ["microsoft.com"], "keywords": ["Deep learning", "Reinforcement Learning"], "authors": ["Yelong Shen*", "Po-Sen Huang*", "Ming-Wei Chang", "Jianfeng Gao"], "authorids": ["yeshen@microsoft.com", "pshuang@microsoft.com", "minchang@microsoft.com", "jfgao@microsoft.com"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1486396637149, "id": "ICLR.cc/2017/conference/-/paper507/acceptance", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/pcs"], "noninvitees": ["ICLR.cc/2017/pcs"], "reply": {"forum": "r1PRvK9el", "replyto": "r1PRvK9el", "writers": {"values-regex": "ICLR.cc/2017/pcs"}, "signatures": {"values-regex": "ICLR.cc/2017/pcs", "description": "Your displayed identity associated with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your decision.", "value": "ICLR committee final decision"}, "comment": {"required": true, "order": 2, "description": "Decision comments.", "value-regex": "[\\S\\s]{1,5000}"}, "decision": {"required": true, "order": 3, "value-radio": ["Accept (Oral)", "Accept (Poster)", "Reject", "Invite to Workshop Track"]}}}, "nonreaders": [], "cdate": 1486396637149}}}, {"tddate": null, "tmdate": 1484344069657, "tcdate": 1484344069657, "number": 10, "id": "SkRbj6LUl", "invitation": "ICLR.cc/2017/conference/-/paper507/public/comment", "forum": "r1PRvK9el", "replyto": "BJF_A9INl", "signatures": ["~Po-Sen_Huang1"], "readers": ["everyone"], "writers": ["~Po-Sen_Huang1"], "content": {"title": "Reply to Reviewer3", "comment": "Thanks for your insightful review. To address your comment, we added Table 2 and a corresponding paragraph to analyze the performance with different termination steps (T_max = 1, 2, 5, 8) and memory sizes (|M| = 32, 64, 128, 256, 4096).\nAs for the introduction section, we will update the introduction to incorporate the motivation and the comparison against existing methods from Section 2.\n"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"TL;DR": "", "title": "Implicit ReasoNet: Modeling Large-Scale Structured Relationships with Shared Memory", "abstract": "Recent studies on knowledge base completion, the task of recovering missing relationships based on recorded relations, demonstrate the importance of learning embeddings from multi-step relations. However, due to the size of knowledge bases, learning multi-step relations directly on top of observed instances could be costly. In this paper, we propose Implicit ReasoNets (IRNs), which is designed to perform large-scale inference implicitly through a search controller and shared memory. Unlike previous work, IRNs use training data to learn to perform multi-step inference through the shared memory, which is also jointly updated during training. While the inference procedure is not operating on top of observed instances for IRNs, our proposed model outperforms all previous approaches on the popular FB15k benchmark by more than 5.7%.", "pdf": "/pdf/2e8438d59fa94b4a252c91116cb86eaf877c76b1.pdf", "paperhash": "shen|implicit_reasonet_modeling_largescale_structured_relationships_with_shared_memory", "conflicts": ["microsoft.com"], "keywords": ["Deep learning", "Reinforcement Learning"], "authors": ["Yelong Shen*", "Po-Sen Huang*", "Ming-Wei Chang", "Jianfeng Gao"], "authorids": ["yeshen@microsoft.com", "pshuang@microsoft.com", "minchang@microsoft.com", "jfgao@microsoft.com"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287547454, "id": "ICLR.cc/2017/conference/-/paper507/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "r1PRvK9el", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper507/reviewers", "ICLR.cc/2017/conference/paper507/areachairs"], "cdate": 1485287547454}}}, {"tddate": null, "tmdate": 1484344044179, "tcdate": 1484344044179, "number": 9, "id": "Hk4lipIUx", "invitation": "ICLR.cc/2017/conference/-/paper507/public/comment", "forum": "r1PRvK9el", "replyto": "SyHbpXIVl", "signatures": ["~Po-Sen_Huang1"], "readers": ["everyone"], "writers": ["~Po-Sen_Huang1"], "content": {"title": "Reply to Reviewer1", "comment": "Thanks for your insightful review. To address your comments, we added Table 2 and a corresponding paragraph to analyze the performance with different termination steps (T_max = 1, 2, 5, 8) and memory sizes (|M| = 32, 64, 128, 256, 4096). In the T_max = 1 cases, it is the case where IRNs do not use the shared memory. We found the number of times IRNs access the shared memory is critical for the performance, so IRNs cannot achieve the same level of performance without using shared memory.\nRegarding the attention over memory cells, we have found some interesting behaviors of the shared memory by counting the most active relations of each memory cell. For example, in one particular memory cell, we observe its most active relations from a cluster around \u201cfamily/spouse based\u201d relations. We will update some findings in the discussion and we will test the current model on more challenge tasks, i.e., knowledge base QA, machine reading, and conversation bot in the future.\n"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"TL;DR": "", "title": "Implicit ReasoNet: Modeling Large-Scale Structured Relationships with Shared Memory", "abstract": "Recent studies on knowledge base completion, the task of recovering missing relationships based on recorded relations, demonstrate the importance of learning embeddings from multi-step relations. However, due to the size of knowledge bases, learning multi-step relations directly on top of observed instances could be costly. In this paper, we propose Implicit ReasoNets (IRNs), which is designed to perform large-scale inference implicitly through a search controller and shared memory. Unlike previous work, IRNs use training data to learn to perform multi-step inference through the shared memory, which is also jointly updated during training. While the inference procedure is not operating on top of observed instances for IRNs, our proposed model outperforms all previous approaches on the popular FB15k benchmark by more than 5.7%.", "pdf": "/pdf/2e8438d59fa94b4a252c91116cb86eaf877c76b1.pdf", "paperhash": "shen|implicit_reasonet_modeling_largescale_structured_relationships_with_shared_memory", "conflicts": ["microsoft.com"], "keywords": ["Deep learning", "Reinforcement Learning"], "authors": ["Yelong Shen*", "Po-Sen Huang*", "Ming-Wei Chang", "Jianfeng Gao"], "authorids": ["yeshen@microsoft.com", "pshuang@microsoft.com", "minchang@microsoft.com", "jfgao@microsoft.com"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287547454, "id": "ICLR.cc/2017/conference/-/paper507/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "r1PRvK9el", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper507/reviewers", "ICLR.cc/2017/conference/paper507/areachairs"], "cdate": 1485287547454}}}, {"tddate": null, "tmdate": 1484343990636, "tcdate": 1484343990636, "number": 8, "id": "Skya5aIIl", "invitation": "ICLR.cc/2017/conference/-/paper507/public/comment", "forum": "r1PRvK9el", "replyto": "B1g02CM4g", "signatures": ["~Po-Sen_Huang1"], "readers": ["everyone"], "writers": ["~Po-Sen_Huang1"], "content": {"title": "Reply to Reviewer2 ", "comment": "Thanks for your insightful review. To address your comments, we added Table 2 and a corresponding paragraph to analyze the performance with different termination steps (T_max = 1, 2, 5, 8) and memory sizes (|M| = 32, 64, 128, 256, 4096). Regarding the shortest path experiments on KB and models with dynamic memory size, we will investigate these directions in the future."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"TL;DR": "", "title": "Implicit ReasoNet: Modeling Large-Scale Structured Relationships with Shared Memory", "abstract": "Recent studies on knowledge base completion, the task of recovering missing relationships based on recorded relations, demonstrate the importance of learning embeddings from multi-step relations. However, due to the size of knowledge bases, learning multi-step relations directly on top of observed instances could be costly. In this paper, we propose Implicit ReasoNets (IRNs), which is designed to perform large-scale inference implicitly through a search controller and shared memory. Unlike previous work, IRNs use training data to learn to perform multi-step inference through the shared memory, which is also jointly updated during training. While the inference procedure is not operating on top of observed instances for IRNs, our proposed model outperforms all previous approaches on the popular FB15k benchmark by more than 5.7%.", "pdf": "/pdf/2e8438d59fa94b4a252c91116cb86eaf877c76b1.pdf", "paperhash": "shen|implicit_reasonet_modeling_largescale_structured_relationships_with_shared_memory", "conflicts": ["microsoft.com"], "keywords": ["Deep learning", "Reinforcement Learning"], "authors": ["Yelong Shen*", "Po-Sen Huang*", "Ming-Wei Chang", "Jianfeng Gao"], "authorids": ["yeshen@microsoft.com", "pshuang@microsoft.com", "minchang@microsoft.com", "jfgao@microsoft.com"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287547454, "id": "ICLR.cc/2017/conference/-/paper507/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "r1PRvK9el", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper507/reviewers", "ICLR.cc/2017/conference/paper507/areachairs"], "cdate": 1485287547454}}}, {"tddate": null, "replyto": null, "ddate": null, "tmdate": 1483503512792, "tcdate": 1478297550666, "number": 507, "id": "r1PRvK9el", "invitation": "ICLR.cc/2017/conference/-/submission", "forum": "r1PRvK9el", "signatures": ["~yelong_shen1"], "readers": ["everyone"], "content": {"TL;DR": "", "title": "Implicit ReasoNet: Modeling Large-Scale Structured Relationships with Shared Memory", "abstract": "Recent studies on knowledge base completion, the task of recovering missing relationships based on recorded relations, demonstrate the importance of learning embeddings from multi-step relations. However, due to the size of knowledge bases, learning multi-step relations directly on top of observed instances could be costly. In this paper, we propose Implicit ReasoNets (IRNs), which is designed to perform large-scale inference implicitly through a search controller and shared memory. Unlike previous work, IRNs use training data to learn to perform multi-step inference through the shared memory, which is also jointly updated during training. While the inference procedure is not operating on top of observed instances for IRNs, our proposed model outperforms all previous approaches on the popular FB15k benchmark by more than 5.7%.", "pdf": "/pdf/2e8438d59fa94b4a252c91116cb86eaf877c76b1.pdf", "paperhash": "shen|implicit_reasonet_modeling_largescale_structured_relationships_with_shared_memory", "conflicts": ["microsoft.com"], "keywords": ["Deep learning", "Reinforcement Learning"], "authors": ["Yelong Shen*", "Po-Sen Huang*", "Ming-Wei Chang", "Jianfeng Gao"], "authorids": ["yeshen@microsoft.com", "pshuang@microsoft.com", "minchang@microsoft.com", "jfgao@microsoft.com"]}, "writers": [], "nonreaders": [], "details": {"replyCount": 15, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1475686800000, "tmdate": 1478287705855, "id": "ICLR.cc/2017/conference/-/submission", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/pcs"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": null, "replyto": null, "writers": {"values-regex": "~.*"}, "signatures": {"values-regex": "~.*", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"pdf": {"required": true, "order": 5, "description": "Either upload a PDF file or provide a direct link to your PDF on ArXiv (link must begin with http(s) and end with .pdf)", "value-regex": "upload|(http|https):\\/\\/.+\\.pdf"}, "title": {"required": true, "order": 1, "description": "Title of paper.", "value-regex": ".{1,250}"}, "abstract": {"required": true, "order": 4, "description": "Abstract of paper.", "value-regex": "[\\S\\s]{1,5000}"}, "authors": {"required": true, "order": 2, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of author names, as they appear in the paper."}, "conflicts": {"required": true, "order": 100, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of email domains of people who would have a conflict of interest in reviewing this paper, (e.g., cs.umass.edu;google.com, etc.)."}, "keywords": {"order": 6, "description": "Comma separated list of keywords.", "values-dropdown": ["Theory", "Computer vision", "Speech", "Natural language processing", "Deep learning", "Unsupervised Learning", "Supervised Learning", "Semi-Supervised Learning", "Reinforcement Learning", "Transfer Learning", "Multi-modal learning", "Applications", "Optimization", "Structured prediction", "Games"]}, "TL;DR": {"required": false, "order": 3, "description": "\"Too Long; Didn't Read\": a short sentence describing your paper", "value-regex": "[^\\n]{0,250}"}, "authorids": {"required": true, "order": 3, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of author email addresses, in the same order as above."}}}, "nonreaders": [], "noninvitees": [], "expdate": 1483462800000, "cdate": 1478287705855}}}, {"tddate": null, "tmdate": 1482448620925, "tcdate": 1482448620925, "number": 7, "id": "S1Blkk5Ng", "invitation": "ICLR.cc/2017/conference/-/paper507/public/comment", "forum": "r1PRvK9el", "replyto": "r1PRvK9el", "signatures": ["~yelong_shen1"], "readers": ["everyone"], "writers": ["~yelong_shen1"], "content": {"title": "Report the performance of IRNs with different memory sizes and inference steps on FB15K", "comment": "Thanks all reviewers for your great feedback and comments. We have updated the paper to address the major comments for adding analysis in the KB experiments. We add Table 2 and a corresponding paragraph to analyze the performance with different termination steps and memory sizes. (Note that for T_max =1, it is the case where IRNs do not use the shared memory.)  We found the number of times IRNs access the shared memory is critical for the performance, so IRNs cannot achieve the same level of performance without using shared memory. \nIn response to reviewer 2, regarding the shortest path experiments on KB and models with dynamic memory size, we will investigate these directions for future work. \nWe will update our paper to improve the introduction section and figure 1, and add more analysis on the termination steps.\n"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"TL;DR": "", "title": "Implicit ReasoNet: Modeling Large-Scale Structured Relationships with Shared Memory", "abstract": "Recent studies on knowledge base completion, the task of recovering missing relationships based on recorded relations, demonstrate the importance of learning embeddings from multi-step relations. However, due to the size of knowledge bases, learning multi-step relations directly on top of observed instances could be costly. In this paper, we propose Implicit ReasoNets (IRNs), which is designed to perform large-scale inference implicitly through a search controller and shared memory. Unlike previous work, IRNs use training data to learn to perform multi-step inference through the shared memory, which is also jointly updated during training. While the inference procedure is not operating on top of observed instances for IRNs, our proposed model outperforms all previous approaches on the popular FB15k benchmark by more than 5.7%.", "pdf": "/pdf/2e8438d59fa94b4a252c91116cb86eaf877c76b1.pdf", "paperhash": "shen|implicit_reasonet_modeling_largescale_structured_relationships_with_shared_memory", "conflicts": ["microsoft.com"], "keywords": ["Deep learning", "Reinforcement Learning"], "authors": ["Yelong Shen*", "Po-Sen Huang*", "Ming-Wei Chang", "Jianfeng Gao"], "authorids": ["yeshen@microsoft.com", "pshuang@microsoft.com", "minchang@microsoft.com", "jfgao@microsoft.com"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287547454, "id": "ICLR.cc/2017/conference/-/paper507/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "r1PRvK9el", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper507/reviewers", "ICLR.cc/2017/conference/paper507/areachairs"], "cdate": 1485287547454}}}, {"tddate": null, "tmdate": 1482235505121, "tcdate": 1482235505121, "number": 3, "id": "BJF_A9INl", "invitation": "ICLR.cc/2017/conference/-/paper507/official/review", "forum": "r1PRvK9el", "replyto": "r1PRvK9el", "signatures": ["ICLR.cc/2017/conference/paper507/AnonReviewer3"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/conference/paper507/AnonReviewer3"], "content": {"title": "Interesting paper", "rating": "6: Marginally above acceptance threshold", "review": "In this paper, the authors proposed an implicit ResoNet model for knowledge base completion. The proposed model performs inference implicitly by a search controller and shared memory. The proposed approach demonstrates promising results on FB15k benchmark dataset. \n\nPros:\n\n- The proposed approach demonstrates strong performance on FB15k dataset. \n\n- The idea of using shared memory for knowledge base completion is new and interesting. \n\n- The proposed approach is general and can be applied in various tasks. \n\nCons:\n\n- There is no qualitative analysis on the results, and it is hard to see why the proposed approach works on the knowledge-base completion task. \n\n- The introduction section can be improved. Specifically, the authors should motivate \"shared memory\" more in the introduction and how it different from existing methods that using \"unshared memory\" for knowledge base completion. Similarly, the function of search controller is unclear in the introduction section as it is unclear what does search mean in the content of knowledge base completion.  The concept of shared memory and search controller only make sense to me after reading through section 2. \n", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"TL;DR": "", "title": "Implicit ReasoNet: Modeling Large-Scale Structured Relationships with Shared Memory", "abstract": "Recent studies on knowledge base completion, the task of recovering missing relationships based on recorded relations, demonstrate the importance of learning embeddings from multi-step relations. However, due to the size of knowledge bases, learning multi-step relations directly on top of observed instances could be costly. In this paper, we propose Implicit ReasoNets (IRNs), which is designed to perform large-scale inference implicitly through a search controller and shared memory. Unlike previous work, IRNs use training data to learn to perform multi-step inference through the shared memory, which is also jointly updated during training. While the inference procedure is not operating on top of observed instances for IRNs, our proposed model outperforms all previous approaches on the popular FB15k benchmark by more than 5.7%.", "pdf": "/pdf/2e8438d59fa94b4a252c91116cb86eaf877c76b1.pdf", "paperhash": "shen|implicit_reasonet_modeling_largescale_structured_relationships_with_shared_memory", "conflicts": ["microsoft.com"], "keywords": ["Deep learning", "Reinforcement Learning"], "authors": ["Yelong Shen*", "Po-Sen Huang*", "Ming-Wei Chang", "Jianfeng Gao"], "authorids": ["yeshen@microsoft.com", "pshuang@microsoft.com", "minchang@microsoft.com", "jfgao@microsoft.com"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1481932799000, "tmdate": 1482512560272, "id": "ICLR.cc/2017/conference/-/paper507/official/review", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/conference/paper507/reviewers"], "noninvitees": ["ICLR.cc/2017/conference/paper507/AnonReviewer2", "ICLR.cc/2017/conference/paper507/AnonReviewer1", "ICLR.cc/2017/conference/paper507/AnonReviewer3"], "reply": {"forum": "r1PRvK9el", "replyto": "r1PRvK9el", "writers": {"values-regex": "ICLR.cc/2017/conference/paper507/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/conference/paper507/AnonReviewer[0-9]+"}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "value-regex": "[\\S\\s]{1,20000}"}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1489708799000, "cdate": 1482512560272}}}, {"tddate": null, "tmdate": 1482206461119, "tcdate": 1482206461119, "number": 2, "id": "SyHbpXIVl", "invitation": "ICLR.cc/2017/conference/-/paper507/official/review", "forum": "r1PRvK9el", "replyto": "r1PRvK9el", "signatures": ["ICLR.cc/2017/conference/paper507/AnonReviewer1"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/conference/paper507/AnonReviewer1"], "content": {"title": "Review ", "rating": "6: Marginally above acceptance threshold", "review": "This paper proposes a method for link prediction on Knowledge Bases. The method contains 2 main innovations: (1) an iterative inference process that allows the model to refine its predictions and (2) a shared memory component. Thanks to these 2 elements, the model introduced in the paper achieved remarkable results on two benchmarks.\n\n\nThe paper is fairly written. The model is interesting and the experimental results are strikingly good. Still, I only rate for a weak accept for the following reasons.\n\n* The main problem with this paper is that there is little explanation of how and why the two new elements aforementioned are leading to such better results. For instance:\n  - What are the performance without the shared memory? And when its size is grown? \n  - How does the performance is impacted when one varies Tmax from 1 to 5 (which the chosen value for the experiments I assume)? This gives an indications of how often the termination gate works.\n  - It would also be interesting to give the proportion of examples for which the inference is terminated before hitting Tmax.\n  - What is the proportion of examples for which the prediction changed along several inference iterations?\n\n* A value of \\lambda set to 10 (Section 2) seems to indicate a low temperature for the softmax. Is the attention finally attending mostly at a single cell? How do the softmax activations change with the type of relationships? the entity type?\n\n* FB15k and WN18 are quite old overused benchmarks now. It would be interesting to test on larger conditions.", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"TL;DR": "", "title": "Implicit ReasoNet: Modeling Large-Scale Structured Relationships with Shared Memory", "abstract": "Recent studies on knowledge base completion, the task of recovering missing relationships based on recorded relations, demonstrate the importance of learning embeddings from multi-step relations. However, due to the size of knowledge bases, learning multi-step relations directly on top of observed instances could be costly. In this paper, we propose Implicit ReasoNets (IRNs), which is designed to perform large-scale inference implicitly through a search controller and shared memory. Unlike previous work, IRNs use training data to learn to perform multi-step inference through the shared memory, which is also jointly updated during training. While the inference procedure is not operating on top of observed instances for IRNs, our proposed model outperforms all previous approaches on the popular FB15k benchmark by more than 5.7%.", "pdf": "/pdf/2e8438d59fa94b4a252c91116cb86eaf877c76b1.pdf", "paperhash": "shen|implicit_reasonet_modeling_largescale_structured_relationships_with_shared_memory", "conflicts": ["microsoft.com"], "keywords": ["Deep learning", "Reinforcement Learning"], "authors": ["Yelong Shen*", "Po-Sen Huang*", "Ming-Wei Chang", "Jianfeng Gao"], "authorids": ["yeshen@microsoft.com", "pshuang@microsoft.com", "minchang@microsoft.com", "jfgao@microsoft.com"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1481932799000, "tmdate": 1482512560272, "id": "ICLR.cc/2017/conference/-/paper507/official/review", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/conference/paper507/reviewers"], "noninvitees": ["ICLR.cc/2017/conference/paper507/AnonReviewer2", "ICLR.cc/2017/conference/paper507/AnonReviewer1", "ICLR.cc/2017/conference/paper507/AnonReviewer3"], "reply": {"forum": "r1PRvK9el", "replyto": "r1PRvK9el", "writers": {"values-regex": "ICLR.cc/2017/conference/paper507/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/conference/paper507/AnonReviewer[0-9]+"}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "value-regex": "[\\S\\s]{1,20000}"}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1489708799000, "cdate": 1482512560272}}}, {"tddate": null, "tmdate": 1481991878846, "tcdate": 1481989320200, "number": 1, "id": "B1g02CM4g", "invitation": "ICLR.cc/2017/conference/-/paper507/official/review", "forum": "r1PRvK9el", "replyto": "r1PRvK9el", "signatures": ["ICLR.cc/2017/conference/paper507/AnonReviewer2"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/conference/paper507/AnonReviewer2"], "content": {"title": "review", "rating": "6: Marginally above acceptance threshold", "review": "\n[Summary]\nThis paper proposes a new way for knowledge base completion which highlights: 1) adopting an implicit shared memory, which makes no assumption about its structure and is completely learned during training; 2) modeling a multi-step search process that can decide when to terminate.\n\nThe experimental results on WN18 and FB15k seem pretty good. The authors also perform an analysis on a shortest path synthetic task, and demonstrate that this model is better than standard seq2seq.\n\nThe paper is well-written and it is easy to follow.\n\n[Major comments]\nI actually do like the idea and am also impressed that this model can work well.\nThe main concern is that this paper presents too little analysis about how it works and whether it is sensitive to the hyper-parameters, besides that only reporting a final model on WN18 and FB15k.\n\nOne key hyper-parameter I believe is the size of shared memory (using 64 for the experiments). I don\u2019t think that this number should be fixed for all tasks, at least it should depend on the KB scale. Could you verify this in your experiments? Would it be even possible to make a memory structure with dynamic size?\n\nThe RL setting (stochastic search process) is also one highlight of the paper, but could you demonstrate that how much it does really help? I think it is necessary to compare to the following: remove the termination gate and fix the number of inference steps and see how well the model does? Also show how the performance varies on # of steps?\n\nI appreciate your attempts on the shortest path synthetic task. However, I think it would be much better if you can demonstrate that under a real KB setting. You can still perform the shortest path analysis, but using KB  (e.g., Freebase) entities and relations.\n\n[Minor comments]\nI am afraid that the output gate illustrated in Figure 1 is a bit confusing. There should be only one output, depending on when the search process is terminated.\n\n\n", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"TL;DR": "", "title": "Implicit ReasoNet: Modeling Large-Scale Structured Relationships with Shared Memory", "abstract": "Recent studies on knowledge base completion, the task of recovering missing relationships based on recorded relations, demonstrate the importance of learning embeddings from multi-step relations. However, due to the size of knowledge bases, learning multi-step relations directly on top of observed instances could be costly. In this paper, we propose Implicit ReasoNets (IRNs), which is designed to perform large-scale inference implicitly through a search controller and shared memory. Unlike previous work, IRNs use training data to learn to perform multi-step inference through the shared memory, which is also jointly updated during training. While the inference procedure is not operating on top of observed instances for IRNs, our proposed model outperforms all previous approaches on the popular FB15k benchmark by more than 5.7%.", "pdf": "/pdf/2e8438d59fa94b4a252c91116cb86eaf877c76b1.pdf", "paperhash": "shen|implicit_reasonet_modeling_largescale_structured_relationships_with_shared_memory", "conflicts": ["microsoft.com"], "keywords": ["Deep learning", "Reinforcement Learning"], "authors": ["Yelong Shen*", "Po-Sen Huang*", "Ming-Wei Chang", "Jianfeng Gao"], "authorids": ["yeshen@microsoft.com", "pshuang@microsoft.com", "minchang@microsoft.com", "jfgao@microsoft.com"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1481932799000, "tmdate": 1482512560272, "id": "ICLR.cc/2017/conference/-/paper507/official/review", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/conference/paper507/reviewers"], "noninvitees": ["ICLR.cc/2017/conference/paper507/AnonReviewer2", "ICLR.cc/2017/conference/paper507/AnonReviewer1", "ICLR.cc/2017/conference/paper507/AnonReviewer3"], "reply": {"forum": "r1PRvK9el", "replyto": "r1PRvK9el", "writers": {"values-regex": "ICLR.cc/2017/conference/paper507/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/conference/paper507/AnonReviewer[0-9]+"}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "value-regex": "[\\S\\s]{1,20000}"}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1489708799000, "cdate": 1482512560272}}}, {"tddate": null, "tmdate": 1481126816919, "tcdate": 1481126816911, "number": 6, "id": "rJKomhHml", "invitation": "ICLR.cc/2017/conference/-/paper507/public/comment", "forum": "r1PRvK9el", "replyto": "ryU05ayXx", "signatures": ["~yelong_shen1"], "readers": ["everyone"], "writers": ["~yelong_shen1"], "content": {"title": "Reply to AnonReviewer1", "comment": "Thanks for providing feed-backs about the paper. Here is our reply to your questions. \n\n- Is there any way to know what is encoded in the shared memory? It seems a bit hard to understand what is stored there.\nReply :\nDeveloping a full-scale visualization method for the neural network weights is a research topic by itself, and so far it is not clear to us what is the best way to visualize the shared memory. We are open and happy to discuss with you about how to perform visualization experiment on shared memories.\n\nHowever, we tried a few visualization experiments, and did find some interesting behaviors of the shared memory by sampling some shared memory cells and their most active relations (according to the sum of the attention weights).  For example, in one particular memory cell, we observe its most active relations from a cluster around  \u201cfamily/spouse based\u201d relations such as \u201c/celebrity/lived_with\u201d,\u201c/celebrity/breakup\u201d and \u201c/people/person/spouse\u201d. Other clusters can be observed in other cells as well.  \nWe also plan to apply the shared memory structure to other applications to fully understand its potential power in the future.\n\n- In section 3 is written \"We sample a set of incorrect entity embeddings\". This is just for training, right? For test, all entities have to be considered as candidate.\nReply : Yes, sampling negative entities is just for training phase. For test, all entities will be considered as candidates.\n\n- Is the same model used to predict head and tail entities?\nReply : Yes, we use the same model to predict head and tail entities.\n"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"TL;DR": "", "title": "Implicit ReasoNet: Modeling Large-Scale Structured Relationships with Shared Memory", "abstract": "Recent studies on knowledge base completion, the task of recovering missing relationships based on recorded relations, demonstrate the importance of learning embeddings from multi-step relations. However, due to the size of knowledge bases, learning multi-step relations directly on top of observed instances could be costly. In this paper, we propose Implicit ReasoNets (IRNs), which is designed to perform large-scale inference implicitly through a search controller and shared memory. Unlike previous work, IRNs use training data to learn to perform multi-step inference through the shared memory, which is also jointly updated during training. While the inference procedure is not operating on top of observed instances for IRNs, our proposed model outperforms all previous approaches on the popular FB15k benchmark by more than 5.7%.", "pdf": "/pdf/2e8438d59fa94b4a252c91116cb86eaf877c76b1.pdf", "paperhash": "shen|implicit_reasonet_modeling_largescale_structured_relationships_with_shared_memory", "conflicts": ["microsoft.com"], "keywords": ["Deep learning", "Reinforcement Learning"], "authors": ["Yelong Shen*", "Po-Sen Huang*", "Ming-Wei Chang", "Jianfeng Gao"], "authorids": ["yeshen@microsoft.com", "pshuang@microsoft.com", "minchang@microsoft.com", "jfgao@microsoft.com"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287547454, "id": "ICLR.cc/2017/conference/-/paper507/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "r1PRvK9el", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper507/reviewers", "ICLR.cc/2017/conference/paper507/areachairs"], "cdate": 1485287547454}}}, {"tddate": null, "tmdate": 1480769793356, "tcdate": 1480769793352, "number": 5, "id": "r1Yb-SeQg", "invitation": "ICLR.cc/2017/conference/-/paper507/public/comment", "forum": "r1PRvK9el", "replyto": "SyyWn3w-x", "signatures": ["~Tsendsuren_Munkhdalai1"], "readers": ["everyone"], "writers": ["~Tsendsuren_Munkhdalai1"], "content": {"title": "Comment on shared memory", "comment": "Thank you for clarifying this!"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"TL;DR": "", "title": "Implicit ReasoNet: Modeling Large-Scale Structured Relationships with Shared Memory", "abstract": "Recent studies on knowledge base completion, the task of recovering missing relationships based on recorded relations, demonstrate the importance of learning embeddings from multi-step relations. However, due to the size of knowledge bases, learning multi-step relations directly on top of observed instances could be costly. In this paper, we propose Implicit ReasoNets (IRNs), which is designed to perform large-scale inference implicitly through a search controller and shared memory. Unlike previous work, IRNs use training data to learn to perform multi-step inference through the shared memory, which is also jointly updated during training. While the inference procedure is not operating on top of observed instances for IRNs, our proposed model outperforms all previous approaches on the popular FB15k benchmark by more than 5.7%.", "pdf": "/pdf/2e8438d59fa94b4a252c91116cb86eaf877c76b1.pdf", "paperhash": "shen|implicit_reasonet_modeling_largescale_structured_relationships_with_shared_memory", "conflicts": ["microsoft.com"], "keywords": ["Deep learning", "Reinforcement Learning"], "authors": ["Yelong Shen*", "Po-Sen Huang*", "Ming-Wei Chang", "Jianfeng Gao"], "authorids": ["yeshen@microsoft.com", "pshuang@microsoft.com", "minchang@microsoft.com", "jfgao@microsoft.com"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287547454, "id": "ICLR.cc/2017/conference/-/paper507/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "r1PRvK9el", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper507/reviewers", "ICLR.cc/2017/conference/paper507/areachairs"], "cdate": 1485287547454}}}, {"tddate": null, "tmdate": 1480739534259, "tcdate": 1480739534252, "number": 1, "id": "ryU05ayXx", "invitation": "ICLR.cc/2017/conference/-/paper507/pre-review/question", "forum": "r1PRvK9el", "replyto": "r1PRvK9el", "signatures": ["ICLR.cc/2017/conference/paper507/AnonReviewer1"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/conference/paper507/AnonReviewer1"], "content": {"title": "Questions", "question": "- Is there any way to know what is encoded in the shared memory? It seems a bit hard to understand what is stored there.\n- In section 3 is written \"We sample a set of incorrect entity embeddings\". This is just for training, right? For test, all entities have to be considered as candidate.\n- Is the same model used to predict head and tail entities?"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"TL;DR": "", "title": "Implicit ReasoNet: Modeling Large-Scale Structured Relationships with Shared Memory", "abstract": "Recent studies on knowledge base completion, the task of recovering missing relationships based on recorded relations, demonstrate the importance of learning embeddings from multi-step relations. However, due to the size of knowledge bases, learning multi-step relations directly on top of observed instances could be costly. In this paper, we propose Implicit ReasoNets (IRNs), which is designed to perform large-scale inference implicitly through a search controller and shared memory. Unlike previous work, IRNs use training data to learn to perform multi-step inference through the shared memory, which is also jointly updated during training. While the inference procedure is not operating on top of observed instances for IRNs, our proposed model outperforms all previous approaches on the popular FB15k benchmark by more than 5.7%.", "pdf": "/pdf/2e8438d59fa94b4a252c91116cb86eaf877c76b1.pdf", "paperhash": "shen|implicit_reasonet_modeling_largescale_structured_relationships_with_shared_memory", "conflicts": ["microsoft.com"], "keywords": ["Deep learning", "Reinforcement Learning"], "authors": ["Yelong Shen*", "Po-Sen Huang*", "Ming-Wei Chang", "Jianfeng Gao"], "authorids": ["yeshen@microsoft.com", "pshuang@microsoft.com", "minchang@microsoft.com", "jfgao@microsoft.com"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1480741199000, "tmdate": 1480959242841, "id": "ICLR.cc/2017/conference/-/paper507/pre-review/question", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/conference/paper507/reviewers"], "noninvitees": ["ICLR.cc/2017/conference/paper507/AnonReviewer1"], "reply": {"forum": "r1PRvK9el", "replyto": "r1PRvK9el", "writers": {"values-regex": "ICLR.cc/2017/conference/paper507/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/conference/paper507/AnonReviewer[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your question.", "value-regex": ".{1,500}"}, "question": {"order": 2, "description": "Your question", "value-regex": "[\\S\\s]{1,5000}"}}}, "nonreaders": [], "expdate": 1488517199000, "cdate": 1480959242841}}}, {"tddate": null, "tmdate": 1479934186489, "tcdate": 1479759492946, "number": 4, "id": "BkaKICgfl", "invitation": "ICLR.cc/2017/conference/-/paper507/public/comment", "forum": "r1PRvK9el", "replyto": "ryKrzdCbg", "signatures": ["~Po-Sen_Huang1"], "readers": ["everyone"], "writers": ["~Po-Sen_Huang1"], "content": {"title": "comment on the shared memory", "comment": "Thank you for your interests in our paper. It seems that there are some misunderstandings in the comments, and please see our responses below.\n\nThe point of our model is that IRNS do *not* need human to manually construct the content of the shared memory. In the previous the neural KB paper such as [1], the authors construct the memory by storing the whole KB information explicitly at the initialization step. Unlike these models, IRNs initialize the memory randomly. At each step, a training triplet is processed through the model by Algorithm 1 (hence, no explicit path information is given). Instead of storing any triplet information explicitly, the shared memory in IRNs is designed to store the information implicitly. Therefore, the size of memory can be much smaller than the size of the whole knowledge base.\n\nWe did list the comparisons of our work and ReasonNet in Section 2. We found that the usage of the shared memory is necessary for KB completion, and this critical issue is not addressed in our previous paper. In original ReasoNets, the memory vectors are explicitly reinitialized to store the given information associated with each instance (the size of the memory is same as the length of the corresponding information source). In contrast, IRNs incorporate the shared memory component, which is used by all instances.\n\nThanks again for your comments. (We add this clarification in Section 3.)\n\n[1] Alexander Miller, Adam Fisch, Jesse Dodge, Amir-Hossein Karimi, Antoine Bordes, Jason Weston, Key-Value Memory Networks for Directly Reading Documents, In EMNLP, 2016\n"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"TL;DR": "", "title": "Implicit ReasoNet: Modeling Large-Scale Structured Relationships with Shared Memory", "abstract": "Recent studies on knowledge base completion, the task of recovering missing relationships based on recorded relations, demonstrate the importance of learning embeddings from multi-step relations. However, due to the size of knowledge bases, learning multi-step relations directly on top of observed instances could be costly. In this paper, we propose Implicit ReasoNets (IRNs), which is designed to perform large-scale inference implicitly through a search controller and shared memory. Unlike previous work, IRNs use training data to learn to perform multi-step inference through the shared memory, which is also jointly updated during training. While the inference procedure is not operating on top of observed instances for IRNs, our proposed model outperforms all previous approaches on the popular FB15k benchmark by more than 5.7%.", "pdf": "/pdf/2e8438d59fa94b4a252c91116cb86eaf877c76b1.pdf", "paperhash": "shen|implicit_reasonet_modeling_largescale_structured_relationships_with_shared_memory", "conflicts": ["microsoft.com"], "keywords": ["Deep learning", "Reinforcement Learning"], "authors": ["Yelong Shen*", "Po-Sen Huang*", "Ming-Wei Chang", "Jianfeng Gao"], "authorids": ["yeshen@microsoft.com", "pshuang@microsoft.com", "minchang@microsoft.com", "jfgao@microsoft.com"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287547454, "id": "ICLR.cc/2017/conference/-/paper507/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "r1PRvK9el", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper507/reviewers", "ICLR.cc/2017/conference/paper507/areachairs"], "cdate": 1485287547454}}}, {"tddate": null, "tmdate": 1479602826972, "tcdate": 1479602753050, "number": 3, "id": "ryKrzdCbg", "invitation": "ICLR.cc/2017/conference/-/paper507/public/comment", "forum": "r1PRvK9el", "replyto": "r1PRvK9el", "signatures": ["(anonymous)"], "readers": ["everyone"], "writers": ["(anonymous)"], "content": {"title": "comment on the shared memory", "comment": "Can you explain in detail how you construct the shared memory for each training sample <t, r, h>? It's completely unclear to me and never mentioned in the paper. If you use many triples (those triples in which any of the t, r, h appears) for each sample as shared memory, then you use the path information and you should mentioned this in the table. \n"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"TL;DR": "", "title": "Implicit ReasoNet: Modeling Large-Scale Structured Relationships with Shared Memory", "abstract": "Recent studies on knowledge base completion, the task of recovering missing relationships based on recorded relations, demonstrate the importance of learning embeddings from multi-step relations. However, due to the size of knowledge bases, learning multi-step relations directly on top of observed instances could be costly. In this paper, we propose Implicit ReasoNets (IRNs), which is designed to perform large-scale inference implicitly through a search controller and shared memory. Unlike previous work, IRNs use training data to learn to perform multi-step inference through the shared memory, which is also jointly updated during training. While the inference procedure is not operating on top of observed instances for IRNs, our proposed model outperforms all previous approaches on the popular FB15k benchmark by more than 5.7%.", "pdf": "/pdf/2e8438d59fa94b4a252c91116cb86eaf877c76b1.pdf", "paperhash": "shen|implicit_reasonet_modeling_largescale_structured_relationships_with_shared_memory", "conflicts": ["microsoft.com"], "keywords": ["Deep learning", "Reinforcement Learning"], "authors": ["Yelong Shen*", "Po-Sen Huang*", "Ming-Wei Chang", "Jianfeng Gao"], "authorids": ["yeshen@microsoft.com", "pshuang@microsoft.com", "minchang@microsoft.com", "jfgao@microsoft.com"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287547454, "id": "ICLR.cc/2017/conference/-/paper507/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "r1PRvK9el", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper507/reviewers", "ICLR.cc/2017/conference/paper507/areachairs"], "cdate": 1485287547454}}}, {"tddate": null, "tmdate": 1479162871124, "tcdate": 1479162871120, "number": 2, "id": "SyyWn3w-x", "invitation": "ICLR.cc/2017/conference/-/paper507/public/comment", "forum": "r1PRvK9el", "replyto": "BJ5pYRxZl", "signatures": ["~Po-Sen_Huang1"], "readers": ["everyone"], "writers": ["~Po-Sen_Huang1"], "content": {"title": "Comment on shared memory", "comment": "We have added some clarifications in the latest draft.  The idea of exploiting shared memory is proposed by [1] independently.  Despite of using the same term, the goal and the operations used by IRNs are different from the one used in [1], as IRNs allow the model to perform multi-step for each instance dynamically.\nIn [1], the input instance encoding and the memory  access is synchronized, as the number of memory access is equal to the input length. In our work, the number of memory access is decided by the complexity of instance, which is modeled by the search controller. The paper [2] is in fact more related to our earlier previous work [3] (in terms of model and the task), which proposes the dynamic termination for machine comprehension tasks. \n\n[1]. Munkhdalai, Tsendsuren, and Hong Yu. \"Neural Semantic Encoders.\" arXiv preprint arXiv:1607.04315 (2016), July 20, 2016. \n[2]. Munkhdalai, Tsendsuren, and Hong Yu. \"Reasoning with Memory Augmented Neural Networks for Language Comprehension.\" arXiv preprint arXiv:1610.06454 (2016), Oct 20 2016.\n[3] Shen et al., ReasoNet: Learning to Stop Reading in Machine Comprehension, https://arxiv.org/abs/1609.05284, Sep 17, 2016\n"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"TL;DR": "", "title": "Implicit ReasoNet: Modeling Large-Scale Structured Relationships with Shared Memory", "abstract": "Recent studies on knowledge base completion, the task of recovering missing relationships based on recorded relations, demonstrate the importance of learning embeddings from multi-step relations. However, due to the size of knowledge bases, learning multi-step relations directly on top of observed instances could be costly. In this paper, we propose Implicit ReasoNets (IRNs), which is designed to perform large-scale inference implicitly through a search controller and shared memory. Unlike previous work, IRNs use training data to learn to perform multi-step inference through the shared memory, which is also jointly updated during training. While the inference procedure is not operating on top of observed instances for IRNs, our proposed model outperforms all previous approaches on the popular FB15k benchmark by more than 5.7%.", "pdf": "/pdf/2e8438d59fa94b4a252c91116cb86eaf877c76b1.pdf", "paperhash": "shen|implicit_reasonet_modeling_largescale_structured_relationships_with_shared_memory", "conflicts": ["microsoft.com"], "keywords": ["Deep learning", "Reinforcement Learning"], "authors": ["Yelong Shen*", "Po-Sen Huang*", "Ming-Wei Chang", "Jianfeng Gao"], "authorids": ["yeshen@microsoft.com", "pshuang@microsoft.com", "minchang@microsoft.com", "jfgao@microsoft.com"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287547454, "id": "ICLR.cc/2017/conference/-/paper507/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "r1PRvK9el", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper507/reviewers", "ICLR.cc/2017/conference/paper507/areachairs"], "cdate": 1485287547454}}}, {"tddate": null, "tmdate": 1478711745803, "tcdate": 1478711745795, "number": 1, "id": "BJ5pYRxZl", "invitation": "ICLR.cc/2017/conference/-/paper507/public/comment", "forum": "r1PRvK9el", "replyto": "r1PRvK9el", "signatures": ["~Tsendsuren_Munkhdalai1"], "readers": ["everyone"], "writers": ["~Tsendsuren_Munkhdalai1"], "content": {"title": "Comment on shared memory", "comment": "The idea of shared memory in context of memory augmented neural networks is not novel. Neural Semantic Encoders previously introduced shared and multiple memory accesses [1, 2]. Please discuss the connection between Implicit ReasoNet and Neural Semantic Encoders in your manuscript.\n\nThanks,\n\n\nRef:\n\n1. Munkhdalai, Tsendsuren, and Hong Yu. \"Neural Semantic Encoders.\" arXiv preprint arXiv:1607.04315 (2016).\n2. Munkhdalai, Tsendsuren, and Hong Yu. \"Reasoning with Memory Augmented Neural Networks for Language Comprehension.\" arXiv preprint arXiv:1610.06454 (2016)."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"TL;DR": "", "title": "Implicit ReasoNet: Modeling Large-Scale Structured Relationships with Shared Memory", "abstract": "Recent studies on knowledge base completion, the task of recovering missing relationships based on recorded relations, demonstrate the importance of learning embeddings from multi-step relations. However, due to the size of knowledge bases, learning multi-step relations directly on top of observed instances could be costly. In this paper, we propose Implicit ReasoNets (IRNs), which is designed to perform large-scale inference implicitly through a search controller and shared memory. Unlike previous work, IRNs use training data to learn to perform multi-step inference through the shared memory, which is also jointly updated during training. While the inference procedure is not operating on top of observed instances for IRNs, our proposed model outperforms all previous approaches on the popular FB15k benchmark by more than 5.7%.", "pdf": "/pdf/2e8438d59fa94b4a252c91116cb86eaf877c76b1.pdf", "paperhash": "shen|implicit_reasonet_modeling_largescale_structured_relationships_with_shared_memory", "conflicts": ["microsoft.com"], "keywords": ["Deep learning", "Reinforcement Learning"], "authors": ["Yelong Shen*", "Po-Sen Huang*", "Ming-Wei Chang", "Jianfeng Gao"], "authorids": ["yeshen@microsoft.com", "pshuang@microsoft.com", "minchang@microsoft.com", "jfgao@microsoft.com"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287547454, "id": "ICLR.cc/2017/conference/-/paper507/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "r1PRvK9el", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper507/reviewers", "ICLR.cc/2017/conference/paper507/areachairs"], "cdate": 1485287547454}}}], "count": 16}