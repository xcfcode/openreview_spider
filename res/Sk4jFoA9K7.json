{"notes": [{"id": "Sk4jFoA9K7", "original": "Bkgq6OP9t7", "number": 479, "cdate": 1538087811508, "ddate": null, "tcdate": 1538087811508, "tmdate": 1550562265149, "tddate": null, "forum": "Sk4jFoA9K7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "PeerNets: Exploiting Peer Wisdom Against Adversarial Attacks", "abstract": "Deep learning systems have become ubiquitous in many aspects of our lives. Unfortunately, it has been shown that such systems are vulnerable to adversarial attacks, making them prone to potential unlawful uses. \nDesigning deep neural networks that are robust to adversarial attacks is a fundamental step in making such systems safer and deployable in a broader variety of applications (e.g. autonomous driving), but more importantly is a necessary step to design novel and more advanced architectures built on new computational paradigms rather than marginally building on the existing ones.\nIn this paper we introduce PeerNets, a novel family of convolutional networks alternating classical Euclidean convolutions with graph convolutions to harness information from a graph of peer samples. This results in a form of non-local forward propagation in the model, where latent features are conditioned on the global structure induced by the graph, that is up to 3 times more robust to a variety of white- and black-box adversarial attacks compared to conventional architectures with almost no drop in accuracy.", "keywords": ["peernet", "peernets", "graph", "geometric deep learning", "adversarial", "perturbation", "defense", "peer regularization"], "authorids": ["jan.svoboda@usi.ch", "jonathan@nnaisense.com", "federico.monti@usi.ch", "michael.bronstein@usi.ch", "guibas@cs.stanford.edu"], "authors": ["Jan Svoboda", "Jonathan Masci", "Federico Monti", "Michael Bronstein", "Leonidas Guibas"], "pdf": "/pdf/db4c845b7b0cec7cb15d73ff07356dfcd900c1b4.pdf", "paperhash": "svoboda|peernets_exploiting_peer_wisdom_against_adversarial_attacks", "_bibtex": "@inproceedings{\nsvoboda2018peernets,\ntitle={PeerNets: Exploiting Peer Wisdom Against Adversarial Attacks},\nauthor={Jan Svoboda and Jonathan Masci and Federico Monti and Michael Bronstein and Leonidas Guibas},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=Sk4jFoA9K7},\n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"replyCount": 13, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Blind_Submission", "rdate": null, "ddate": null, "expdate": null, "duedate": 1538085600000, "tmdate": 1538142958393, "tddate": null, "super": null, "final": null, "reply": {"signatures": {"values": ["ICLR.cc/2019/Conference"]}, "forum": null, "readers": {"values": ["everyone"]}, "replyto": null, "content": {"authorids": {"values-regex": ".*"}, "authors": {"values": ["Anonymous"]}}, "writers": {"values": ["ICLR.cc/2019/Conference"]}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["~"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": null, "taskCompletionCount": null, "transform": null, "cdate": 1538142958393}}, "tauthor": "OpenReview.net"}, {"id": "Syx_k8PHl4", "original": null, "number": 1, "cdate": 1545070047851, "ddate": null, "tcdate": 1545070047851, "tmdate": 1545354481763, "tddate": null, "forum": "Sk4jFoA9K7", "replyto": "Sk4jFoA9K7", "invitation": "ICLR.cc/2019/Conference/-/Paper479/Meta_Review", "content": {"metareview": "The paper presents a novel with compelling experiments. Good paper, accept. \n", "confidence": "5: The area chair is absolutely certain", "recommendation": "Accept (Poster)", "title": "Accept"}, "signatures": ["ICLR.cc/2019/Conference/Paper479/Area_Chair1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference/Paper479/Area_Chair1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "PeerNets: Exploiting Peer Wisdom Against Adversarial Attacks", "abstract": "Deep learning systems have become ubiquitous in many aspects of our lives. Unfortunately, it has been shown that such systems are vulnerable to adversarial attacks, making them prone to potential unlawful uses. \nDesigning deep neural networks that are robust to adversarial attacks is a fundamental step in making such systems safer and deployable in a broader variety of applications (e.g. autonomous driving), but more importantly is a necessary step to design novel and more advanced architectures built on new computational paradigms rather than marginally building on the existing ones.\nIn this paper we introduce PeerNets, a novel family of convolutional networks alternating classical Euclidean convolutions with graph convolutions to harness information from a graph of peer samples. This results in a form of non-local forward propagation in the model, where latent features are conditioned on the global structure induced by the graph, that is up to 3 times more robust to a variety of white- and black-box adversarial attacks compared to conventional architectures with almost no drop in accuracy.", "keywords": ["peernet", "peernets", "graph", "geometric deep learning", "adversarial", "perturbation", "defense", "peer regularization"], "authorids": ["jan.svoboda@usi.ch", "jonathan@nnaisense.com", "federico.monti@usi.ch", "michael.bronstein@usi.ch", "guibas@cs.stanford.edu"], "authors": ["Jan Svoboda", "Jonathan Masci", "Federico Monti", "Michael Bronstein", "Leonidas Guibas"], "pdf": "/pdf/db4c845b7b0cec7cb15d73ff07356dfcd900c1b4.pdf", "paperhash": "svoboda|peernets_exploiting_peer_wisdom_against_adversarial_attacks", "_bibtex": "@inproceedings{\nsvoboda2018peernets,\ntitle={PeerNets: Exploiting Peer Wisdom Against Adversarial Attacks},\nauthor={Jan Svoboda and Jonathan Masci and Federico Monti and Michael Bronstein and Leonidas Guibas},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=Sk4jFoA9K7},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper479/Meta_Review", "rdate": null, "ddate": null, "expdate": null, "duedate": 1541548800000, "tmdate": 1545353202903, "tddate": null, "super": null, "final": null, "reply": {"forum": "Sk4jFoA9K7", "replyto": "Sk4jFoA9K7", "readers": {"description": "Select all user groups that should be able to read this comment. Selecting 'All Users' will allow paper authors, reviewers, area chairs, and program chairs to view this comment.", "values": ["everyone"]}, "signatures": {"description": "How your identity will be displayed with the above content.", "values-regex": "ICLR.cc/2019/Conference/Paper479/Area_Chair[0-9]+"}, "writers": {"description": "Users that may modify this record.", "values-regex": "ICLR.cc/2019/Conference/Paper479/Area_Chair[0-9]+"}, "content": {"title": {"order": 1, "value-regex": ".{1,500}", "description": "Brief summary of your review.", "required": true}, "metareview": {"order": 2, "value-regex": "[\\S\\s]{1,5000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "required": true}, "recommendation": {"order": 3, "value-dropdown": ["Accept (Oral)", "Accept (Poster)", "Reject"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The area chair is absolutely certain", "4: The area chair is confident but not absolutely certain", "3: The area chair is somewhat confident", "2: The area chair is not sure", "1: The area chair's evaluation is an educated guess"], "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper479/Area_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": false, "taskCompletionCount": null, "transform": null, "cdate": 1545353202903}}}, {"id": "rJxejaXmhQ", "original": null, "number": 1, "cdate": 1540730263735, "ddate": null, "tcdate": 1540730263735, "tmdate": 1544553561225, "tddate": null, "forum": "Sk4jFoA9K7", "replyto": "Sk4jFoA9K7", "invitation": "ICLR.cc/2019/Conference/-/Paper479/Official_Review", "content": {"title": "Analysis and experimental comparisons are lacking", "review": "After reading the authors' response, I'm revising my score upwards from 5 to 6.\n\nThe authors propose a defense against adversarial examples, that is inspired by \"non local means filtering\". The underlying assumption seems to be that, at feature level, adversarial examples manifest as IID noise in feature maps, which can be \"filtered away\" by using features from other images. While this assumption seems plausible,  no analysis has been done to verify it in a systematic way. Some examples of verifying this are:\n\n1. How does varying the number of nearest neighbors change the network behavior?\n2. At test time, a fixed number of images are used for denoising - how does the choice of these images change accuracy or adversarial robustness?\n3. Does just simple filtering of the feature map, say, by local averaging, perform equally well? \n4. When do things start to break down? I imagine randomly replacing feature map values (i.e. with very poor nearest neighbors) will cause robustness and accuracy to go down - was this tested?\n\nBased on the paper of Athalye et. al., really the only method worth comparing to for adversarial defense, is adversarial training. It is hard to judge absolute adversarial robustness performance without a baseline of adversarial training.", "rating": "6: Marginally above acceptance threshold", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}, "signatures": ["ICLR.cc/2019/Conference/Paper479/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": true, "forumContent": {"title": "PeerNets: Exploiting Peer Wisdom Against Adversarial Attacks", "abstract": "Deep learning systems have become ubiquitous in many aspects of our lives. Unfortunately, it has been shown that such systems are vulnerable to adversarial attacks, making them prone to potential unlawful uses. \nDesigning deep neural networks that are robust to adversarial attacks is a fundamental step in making such systems safer and deployable in a broader variety of applications (e.g. autonomous driving), but more importantly is a necessary step to design novel and more advanced architectures built on new computational paradigms rather than marginally building on the existing ones.\nIn this paper we introduce PeerNets, a novel family of convolutional networks alternating classical Euclidean convolutions with graph convolutions to harness information from a graph of peer samples. This results in a form of non-local forward propagation in the model, where latent features are conditioned on the global structure induced by the graph, that is up to 3 times more robust to a variety of white- and black-box adversarial attacks compared to conventional architectures with almost no drop in accuracy.", "keywords": ["peernet", "peernets", "graph", "geometric deep learning", "adversarial", "perturbation", "defense", "peer regularization"], "authorids": ["jan.svoboda@usi.ch", "jonathan@nnaisense.com", "federico.monti@usi.ch", "michael.bronstein@usi.ch", "guibas@cs.stanford.edu"], "authors": ["Jan Svoboda", "Jonathan Masci", "Federico Monti", "Michael Bronstein", "Leonidas Guibas"], "pdf": "/pdf/db4c845b7b0cec7cb15d73ff07356dfcd900c1b4.pdf", "paperhash": "svoboda|peernets_exploiting_peer_wisdom_against_adversarial_attacks", "_bibtex": "@inproceedings{\nsvoboda2018peernets,\ntitle={PeerNets: Exploiting Peer Wisdom Against Adversarial Attacks},\nauthor={Jan Svoboda and Jonathan Masci and Federico Monti and Michael Bronstein and Leonidas Guibas},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=Sk4jFoA9K7},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper479/Official_Review", "cdate": 1542234452036, "expdate": 1552335264000, "duedate": 1541196000000, "reply": {"forum": "Sk4jFoA9K7", "replyto": "Sk4jFoA9K7", "readers": {"description": "The users who will be allowed to read the reply content.", "values": ["everyone"]}, "nonreaders": {"values": []}, "signatures": {"description": "How your identity will be displayed with the above content.", "values-regex": "ICLR.cc/2019/Conference/Paper479/AnonReviewer[0-9]+"}, "writers": {"description": "Users that may modify this record.", "values": ["ICLR.cc/2019/Conference"]}, "content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "required": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}}, "multiReply": false, "tcdate": 1552335733572, "tmdate": 1552335733572, "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "invitees": ["ICLR.cc/2019/Conference/Paper479/Reviewers"], "noninvitees": [], "signatures": ["ICLR.cc/2019/Conference"]}}}, {"id": "HylOU1LpAQ", "original": null, "number": 9, "cdate": 1543491408482, "ddate": null, "tcdate": 1543491408482, "tmdate": 1543504699450, "tddate": null, "forum": "Sk4jFoA9K7", "replyto": "SJeLIho2C7", "invitation": "ICLR.cc/2019/Conference/-/Paper479/Official_Comment", "content": {"title": "Answering other concerns", "comment": "We apologize to the reviewer for our brief response. We have tried to address what we believed to be the most prominent concern, thus inadvertently overseeing some other important comments.\n\nPlease find answers to the additional concerns below.\n\n1. I would have liked to see a response regarding my point on batch sizes? Is that a problem at all in your approach.\n---\nAs we mention in our paper, we used somewhat smaller batch sizes than traditional CNNs, primarily due to the current memory requirements and non-optimized implementation of our code. \nThe attention weights do not depend on number of peers in the graph and we can therefore change batch size dynamically as we want. We have tried batch sizes as small as 8 samples without seeing dramatic decrease in performance. \nDuring test time, we have tried different number of peers in the graph - 10,50,100,200,500. We did not observe any significant changes in performance, please refer to some additional results in Table 4 of Appendix C.\n\n2. What conclusions can we draw from MNIST and CIFAR for real-world applications?\n---\nWe believe that key novelty of our work is a deep-learning network architecture where we can interleave graph layers with convolutional layers and learn everything end-to-end. To our knowledge, this is the first such architecture, and it has many potential use-cases, e.g. image inpainting, few-shot learning, adversarial defense, etc. We have chosen to showcase our architecture on a very hot topic of adversarial attack defense.\nIt should be noted that a vast majority of the defense mechanisms described in the literature or available online do not show any results on ImageNet but rather smaller benchmarks such as CIFAR. We have therefore focused on such datasets, in order to provide if not direct comparison, at least a ballpark compared to the current state-of-the-art.\nWe agree with the reviewer that it is hard to draw conclusions regarding real-world applications of our approach from the datasets we have tested on. We however firmly believe that extending our approach with ideas mentioned in our comment on scalability should make our method a good fit for real-world scenarios.\n"}, "signatures": ["ICLR.cc/2019/Conference/Paper479/Authors"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper479/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper479/Authors", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "PeerNets: Exploiting Peer Wisdom Against Adversarial Attacks", "abstract": "Deep learning systems have become ubiquitous in many aspects of our lives. Unfortunately, it has been shown that such systems are vulnerable to adversarial attacks, making them prone to potential unlawful uses. \nDesigning deep neural networks that are robust to adversarial attacks is a fundamental step in making such systems safer and deployable in a broader variety of applications (e.g. autonomous driving), but more importantly is a necessary step to design novel and more advanced architectures built on new computational paradigms rather than marginally building on the existing ones.\nIn this paper we introduce PeerNets, a novel family of convolutional networks alternating classical Euclidean convolutions with graph convolutions to harness information from a graph of peer samples. This results in a form of non-local forward propagation in the model, where latent features are conditioned on the global structure induced by the graph, that is up to 3 times more robust to a variety of white- and black-box adversarial attacks compared to conventional architectures with almost no drop in accuracy.", "keywords": ["peernet", "peernets", "graph", "geometric deep learning", "adversarial", "perturbation", "defense", "peer regularization"], "authorids": ["jan.svoboda@usi.ch", "jonathan@nnaisense.com", "federico.monti@usi.ch", "michael.bronstein@usi.ch", "guibas@cs.stanford.edu"], "authors": ["Jan Svoboda", "Jonathan Masci", "Federico Monti", "Michael Bronstein", "Leonidas Guibas"], "pdf": "/pdf/db4c845b7b0cec7cb15d73ff07356dfcd900c1b4.pdf", "paperhash": "svoboda|peernets_exploiting_peer_wisdom_against_adversarial_attacks", "_bibtex": "@inproceedings{\nsvoboda2018peernets,\ntitle={PeerNets: Exploiting Peer Wisdom Against Adversarial Attacks},\nauthor={Jan Svoboda and Jonathan Masci and Federico Monti and Michael Bronstein and Leonidas Guibas},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=Sk4jFoA9K7},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper479/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621617202, "tddate": null, "super": null, "final": null, "reply": {"forum": "Sk4jFoA9K7", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper479/Authors", "ICLR.cc/2019/Conference/Paper479/Reviewers", "ICLR.cc/2019/Conference/Paper479/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper479/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper479/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper479/Authors|ICLR.cc/2019/Conference/Paper479/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper479/Reviewers", "ICLR.cc/2019/Conference/Paper479/Authors", "ICLR.cc/2019/Conference/Paper479/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621617202}}}, {"id": "SJeLIho2C7", "original": null, "number": 8, "cdate": 1543449678028, "ddate": null, "tcdate": 1543449678028, "tmdate": 1543449678028, "tddate": null, "forum": "Sk4jFoA9K7", "replyto": "Bkecy4F-0Q", "invitation": "ICLR.cc/2019/Conference/-/Paper479/Official_Comment", "content": {"title": "please elaborate on all concerns", "comment": "I am a bit disappointed by the author's response which only picks up one of my points raised in the review.\n\n1) I would have liked to see a response regarding my point on batch sizes? Is that a problem at all in your approach?\n\n2) What conclusions can we draw from MNIST and CIFAR for real-world applications?"}, "signatures": ["ICLR.cc/2019/Conference/Paper479/AnonReviewer1"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper479/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper479/AnonReviewer1", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "PeerNets: Exploiting Peer Wisdom Against Adversarial Attacks", "abstract": "Deep learning systems have become ubiquitous in many aspects of our lives. Unfortunately, it has been shown that such systems are vulnerable to adversarial attacks, making them prone to potential unlawful uses. \nDesigning deep neural networks that are robust to adversarial attacks is a fundamental step in making such systems safer and deployable in a broader variety of applications (e.g. autonomous driving), but more importantly is a necessary step to design novel and more advanced architectures built on new computational paradigms rather than marginally building on the existing ones.\nIn this paper we introduce PeerNets, a novel family of convolutional networks alternating classical Euclidean convolutions with graph convolutions to harness information from a graph of peer samples. This results in a form of non-local forward propagation in the model, where latent features are conditioned on the global structure induced by the graph, that is up to 3 times more robust to a variety of white- and black-box adversarial attacks compared to conventional architectures with almost no drop in accuracy.", "keywords": ["peernet", "peernets", "graph", "geometric deep learning", "adversarial", "perturbation", "defense", "peer regularization"], "authorids": ["jan.svoboda@usi.ch", "jonathan@nnaisense.com", "federico.monti@usi.ch", "michael.bronstein@usi.ch", "guibas@cs.stanford.edu"], "authors": ["Jan Svoboda", "Jonathan Masci", "Federico Monti", "Michael Bronstein", "Leonidas Guibas"], "pdf": "/pdf/db4c845b7b0cec7cb15d73ff07356dfcd900c1b4.pdf", "paperhash": "svoboda|peernets_exploiting_peer_wisdom_against_adversarial_attacks", "_bibtex": "@inproceedings{\nsvoboda2018peernets,\ntitle={PeerNets: Exploiting Peer Wisdom Against Adversarial Attacks},\nauthor={Jan Svoboda and Jonathan Masci and Federico Monti and Michael Bronstein and Leonidas Guibas},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=Sk4jFoA9K7},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper479/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621617202, "tddate": null, "super": null, "final": null, "reply": {"forum": "Sk4jFoA9K7", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper479/Authors", "ICLR.cc/2019/Conference/Paper479/Reviewers", "ICLR.cc/2019/Conference/Paper479/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper479/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper479/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper479/Authors|ICLR.cc/2019/Conference/Paper479/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper479/Reviewers", "ICLR.cc/2019/Conference/Paper479/Authors", "ICLR.cc/2019/Conference/Paper479/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621617202}}}, {"id": "Byg8yHtZRX", "original": null, "number": 5, "cdate": 1542718685643, "ddate": null, "tcdate": 1542718685643, "tmdate": 1542718685643, "tddate": null, "forum": "Sk4jFoA9K7", "replyto": "B1lhSkeq67", "invitation": "ICLR.cc/2019/Conference/-/Paper479/Official_Comment", "content": {"title": "Additional evaluation suggests the defense does not cause gradient masking", "comment": "Thank you for your comments.\n\nBased on your concerns, we below provide additional evaluation to show that our approach does not cause gradient masking. We also add the new results to the supplementary material of our paper.\n\n1. It appears this paper is causing gradient masking. Looking at Figure 5, FGSM is a more effective attack than PGD at eps=0.1, which is highly suspicious and is listed as one of the tests for identifying gradient masking in Athalye et al. 2018.\n---\nRegarding your concern to the Figure 5, where FGSM seems more effective than PGD at eps=0.1. We attribute this to the selection of the hyperparameters of the FGSM and PGD attack. The number of iterations per each value of epsilon for the PGD attack was set to 40. We have tried to increase this parameters to 100 iterations and evaluate on a small subset of the test set. This causes the PGD to find a slightly better perturbations in many cases, and slightly improves the attack on PeerNet. The overall comparison PeerNet vs. CNN baseline however does not change significantly, and we therefore choose to leave the default configuration of 40 iterations, as it is much more computationally feasible for the full test set of 10000 samples.\n\n2. The authors may wish to try black-box attacks (e.g., SPSA by Uesato et al at ICML'18) to see if this is happening.\n---\nFurther, to support our claim, we have taken this repository implementing black box attacks, including SPSA mentioned by the reviewer https://github.com/sunblaze-ucb/blackbox-attacks .\nWe have used their code for cifar-10 dataset and performed evaluation on a subset of 100 test samples. Using untargetted both single-step and iterative query black-box attack computed using finite difference method, compared to CW-loss based white-box attack.\nThe code reports \"fraction of targtets achieved\" for both white-box (whitebox_succ) and black-box (blackbox_succ) attacks, which is the percentage of samples that the attack was successful on.\nWe have left the default attack configuration from the repository, using epsilon = 8.0.\nSingle step:\nResNet-32 CNN (eps=8.0): whitebox_succ = 82% | blackbox_succ = 82%\nPeerNet (eps=8.0):       whitebox_succ = 34% | blackbox_succ = 14%\n\nFor the iterative attack, we have tried different values of epsilon for CNN and PeerNet to allow fair comparison of the attacks\nIterative:\nResNet-32 CNN (eps=0.5): whitebox_succ = 41%  | blackbox_succ = 41%\nResNet-32 CNN (eps=8.0): whitebox_succ = 100% | blackbox_succ = 100%\nPeerNet (eps=8.0):       whitebox_succ = 45%  | blackbox_succ = 28%\nPeerNet (eps=12.0):      whitebox_succ = 63%  | blackbox_succ = 37%\n\nFrom the results above, we verify that our method does not cause gradient masking. Athalye et al. 2018 mentions that iterative attacks should be stronger than single step, which in the results above holds. Moreover, it states that black-box attacks should be strict subset of white-box attacks, which is confirmed as well.\n\n3. Further, this paper claims ~15% robustness at eps=0.1 (25/255) on CIFAR-10, and a non-zero robustness at eps=0.2 (50/255). No prior work has been able to achieve greater than ~10% accuracy at eps=0.06 (16/255), see Madry et al. 2018.\n---\nWe are not aware of any proof that would set the theoretical bound of ~10% accuracy at eps=0.06 on CIFAR-10. We attribute the significant gap to the superiority of our approach. The significant margin can be potentially partially reduced by tuning hyperparameters of the attack methods. Nevertheless, from our observations, PeerNet will still stay very robust."}, "signatures": ["ICLR.cc/2019/Conference/Paper479/Authors"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper479/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper479/Authors", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "PeerNets: Exploiting Peer Wisdom Against Adversarial Attacks", "abstract": "Deep learning systems have become ubiquitous in many aspects of our lives. Unfortunately, it has been shown that such systems are vulnerable to adversarial attacks, making them prone to potential unlawful uses. \nDesigning deep neural networks that are robust to adversarial attacks is a fundamental step in making such systems safer and deployable in a broader variety of applications (e.g. autonomous driving), but more importantly is a necessary step to design novel and more advanced architectures built on new computational paradigms rather than marginally building on the existing ones.\nIn this paper we introduce PeerNets, a novel family of convolutional networks alternating classical Euclidean convolutions with graph convolutions to harness information from a graph of peer samples. This results in a form of non-local forward propagation in the model, where latent features are conditioned on the global structure induced by the graph, that is up to 3 times more robust to a variety of white- and black-box adversarial attacks compared to conventional architectures with almost no drop in accuracy.", "keywords": ["peernet", "peernets", "graph", "geometric deep learning", "adversarial", "perturbation", "defense", "peer regularization"], "authorids": ["jan.svoboda@usi.ch", "jonathan@nnaisense.com", "federico.monti@usi.ch", "michael.bronstein@usi.ch", "guibas@cs.stanford.edu"], "authors": ["Jan Svoboda", "Jonathan Masci", "Federico Monti", "Michael Bronstein", "Leonidas Guibas"], "pdf": "/pdf/db4c845b7b0cec7cb15d73ff07356dfcd900c1b4.pdf", "paperhash": "svoboda|peernets_exploiting_peer_wisdom_against_adversarial_attacks", "_bibtex": "@inproceedings{\nsvoboda2018peernets,\ntitle={PeerNets: Exploiting Peer Wisdom Against Adversarial Attacks},\nauthor={Jan Svoboda and Jonathan Masci and Federico Monti and Michael Bronstein and Leonidas Guibas},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=Sk4jFoA9K7},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper479/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621617202, "tddate": null, "super": null, "final": null, "reply": {"forum": "Sk4jFoA9K7", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper479/Authors", "ICLR.cc/2019/Conference/Paper479/Reviewers", "ICLR.cc/2019/Conference/Paper479/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper479/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper479/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper479/Authors|ICLR.cc/2019/Conference/Paper479/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper479/Reviewers", "ICLR.cc/2019/Conference/Paper479/Authors", "ICLR.cc/2019/Conference/Paper479/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621617202}}}, {"id": "HklyONYZAX", "original": null, "number": 4, "cdate": 1542718567063, "ddate": null, "tcdate": 1542718567063, "tmdate": 1542718567063, "tddate": null, "forum": "Sk4jFoA9K7", "replyto": "rJxejaXmhQ", "invitation": "ICLR.cc/2019/Conference/-/Paper479/Official_Comment", "content": {"title": "Requested analysis and comparison", "comment": "Thank you for the valuable remarks.\n \nWe have tested most of the concerns in points 1. - 4. during our experiments. We however could not provide full-extent analysis due to the limited length of the paper. Let us respond to each of the points separately below.\n\n1. How does varying the number of nearest neighbors change the network behavior?\n---\nWe observe that using small k (~5) doesn't always provide enough information to perform the denoising and the network is therefore less robust against adversarial examples.\nOn the other hand, having k too high (~20) yields too much regularization and the network original performance decreases more significantly.\nIn our experiments, we have found k=10 to be a reasonable compromise.\n\n2. At test time, a fixed number of images are used for denoising - how does the choice of these images change accuracy or adversarial robustness?\n---\nWe refer the reviewer to the Section 3 and Section 4.1. of our paper where this is addressed in detail.\n\n3. Does just simple filtering of the feature map, say, by local averaging, perform equally well? \n---\nIt does not. We have tried simple smoothing of the feature maps and it not only does not make the network robust against adversarial attacks, but also regularizes the original network too much which results in significant loss in classification accuracy. Moreover, local averaging uses the information from the corrupted image itself to filter the feature map, which could even further amplify the noise.\n\n4. When do things start to break down? I imagine randomly replacing feature map values (i.e. with very poor nearest neighbors) will cause robustness and accuracy to go down - was this tested?\n---\nThis is of-course true. Obviously, selecting very poor nearest neighbors will definitely break the method as the newly created feature map will not express the original information anymore. In our paper, we even reason that the adversary often tries to fool the KNN algorithm directly, as we mention at the end of Section 4.3.2.\nMoreover, we believe that our results show when do things start to \"break down\". We explicitly mention that an unbounded attack will always fool the network. Also, our figures in the main text and tables in the supplementary material show that with increasing magnitude of the perturbation, things start to \"break down\". \n\n5. Based on the paper of Athalye et. al., really the only method worth comparing to for adversarial defense, is adversarial training. It is hard to judge absolute adversarial robustness performance without a baseline of adversarial training.\n---\nWe provide an evaluation below as well as add an additional section with the results in the supplementary material.\n\nWe have compared our approach to adversarial training method using the code provided by Madry etal. https://github.com/MadryLab/cifar10_challenge.\nThe ResNet-32 baseline model provided in Tensorflow repository (the same we use as CNN baseline in our paper) was trained using the script provided in the cifar10_challenge repository above.\nWe have used two training configurations producing two baseline models1 - the default one provided by the repository (ResNet-32 CNN A) and then the same one as in our paper (ResNet-32 CNN B).\nPeerNet was trained traditionally without adversarial training. \nThe attack was left as defined by the repository by Madry etal.\n\nResNet-32 CNN A: original_acc = 78.86% | adversarial_acc = 45.47%\nResNet-32 CNN B: original_acc = 75.59% | adversarial_acc = 42.53% \nPeerNet:         original_acc = 77.44% | adversarial_acc = 64.76%\n\nResults show superiority of PeerNet on this benchmark. PeerNet was trained without considering any specific attacks and still outperforms ResNet-32 CNN, which was adversarially trained using this specific attack, by margin of 20%."}, "signatures": ["ICLR.cc/2019/Conference/Paper479/Authors"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper479/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper479/Authors", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "PeerNets: Exploiting Peer Wisdom Against Adversarial Attacks", "abstract": "Deep learning systems have become ubiquitous in many aspects of our lives. Unfortunately, it has been shown that such systems are vulnerable to adversarial attacks, making them prone to potential unlawful uses. \nDesigning deep neural networks that are robust to adversarial attacks is a fundamental step in making such systems safer and deployable in a broader variety of applications (e.g. autonomous driving), but more importantly is a necessary step to design novel and more advanced architectures built on new computational paradigms rather than marginally building on the existing ones.\nIn this paper we introduce PeerNets, a novel family of convolutional networks alternating classical Euclidean convolutions with graph convolutions to harness information from a graph of peer samples. This results in a form of non-local forward propagation in the model, where latent features are conditioned on the global structure induced by the graph, that is up to 3 times more robust to a variety of white- and black-box adversarial attacks compared to conventional architectures with almost no drop in accuracy.", "keywords": ["peernet", "peernets", "graph", "geometric deep learning", "adversarial", "perturbation", "defense", "peer regularization"], "authorids": ["jan.svoboda@usi.ch", "jonathan@nnaisense.com", "federico.monti@usi.ch", "michael.bronstein@usi.ch", "guibas@cs.stanford.edu"], "authors": ["Jan Svoboda", "Jonathan Masci", "Federico Monti", "Michael Bronstein", "Leonidas Guibas"], "pdf": "/pdf/db4c845b7b0cec7cb15d73ff07356dfcd900c1b4.pdf", "paperhash": "svoboda|peernets_exploiting_peer_wisdom_against_adversarial_attacks", "_bibtex": "@inproceedings{\nsvoboda2018peernets,\ntitle={PeerNets: Exploiting Peer Wisdom Against Adversarial Attacks},\nauthor={Jan Svoboda and Jonathan Masci and Federico Monti and Michael Bronstein and Leonidas Guibas},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=Sk4jFoA9K7},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper479/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621617202, "tddate": null, "super": null, "final": null, "reply": {"forum": "Sk4jFoA9K7", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper479/Authors", "ICLR.cc/2019/Conference/Paper479/Reviewers", "ICLR.cc/2019/Conference/Paper479/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper479/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper479/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper479/Authors|ICLR.cc/2019/Conference/Paper479/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper479/Reviewers", "ICLR.cc/2019/Conference/Paper479/Authors", "ICLR.cc/2019/Conference/Paper479/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621617202}}}, {"id": "Bkecy4F-0Q", "original": null, "number": 3, "cdate": 1542718433564, "ddate": null, "tcdate": 1542718433564, "tmdate": 1542718433564, "tddate": null, "forum": "Sk4jFoA9K7", "replyto": "HkgMKRcth7", "invitation": "ICLR.cc/2019/Conference/-/Paper479/Official_Comment", "content": {"title": "Scalability of our method", "comment": "Thank you for the insightful comments. \n\n1. It is stated that future work will aim at scaling PeerNets to benchmarks like ImageNet, but it is unclear how this could be done. Is there any hope this could be applied to problems like 3D imaging data or videos?\n---\nRegarding the concerns on method scalability. The current bottleneck of our approach is processing of all feature maps pixel-wise. We see potential of scaling our approach by operating on superpixels, or NxN patches, instead of processing all pixels individually.\n"}, "signatures": ["ICLR.cc/2019/Conference/Paper479/Authors"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper479/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper479/Authors", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "PeerNets: Exploiting Peer Wisdom Against Adversarial Attacks", "abstract": "Deep learning systems have become ubiquitous in many aspects of our lives. Unfortunately, it has been shown that such systems are vulnerable to adversarial attacks, making them prone to potential unlawful uses. \nDesigning deep neural networks that are robust to adversarial attacks is a fundamental step in making such systems safer and deployable in a broader variety of applications (e.g. autonomous driving), but more importantly is a necessary step to design novel and more advanced architectures built on new computational paradigms rather than marginally building on the existing ones.\nIn this paper we introduce PeerNets, a novel family of convolutional networks alternating classical Euclidean convolutions with graph convolutions to harness information from a graph of peer samples. This results in a form of non-local forward propagation in the model, where latent features are conditioned on the global structure induced by the graph, that is up to 3 times more robust to a variety of white- and black-box adversarial attacks compared to conventional architectures with almost no drop in accuracy.", "keywords": ["peernet", "peernets", "graph", "geometric deep learning", "adversarial", "perturbation", "defense", "peer regularization"], "authorids": ["jan.svoboda@usi.ch", "jonathan@nnaisense.com", "federico.monti@usi.ch", "michael.bronstein@usi.ch", "guibas@cs.stanford.edu"], "authors": ["Jan Svoboda", "Jonathan Masci", "Federico Monti", "Michael Bronstein", "Leonidas Guibas"], "pdf": "/pdf/db4c845b7b0cec7cb15d73ff07356dfcd900c1b4.pdf", "paperhash": "svoboda|peernets_exploiting_peer_wisdom_against_adversarial_attacks", "_bibtex": "@inproceedings{\nsvoboda2018peernets,\ntitle={PeerNets: Exploiting Peer Wisdom Against Adversarial Attacks},\nauthor={Jan Svoboda and Jonathan Masci and Federico Monti and Michael Bronstein and Leonidas Guibas},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=Sk4jFoA9K7},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper479/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621617202, "tddate": null, "super": null, "final": null, "reply": {"forum": "Sk4jFoA9K7", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper479/Authors", "ICLR.cc/2019/Conference/Paper479/Reviewers", "ICLR.cc/2019/Conference/Paper479/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper479/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper479/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper479/Authors|ICLR.cc/2019/Conference/Paper479/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper479/Reviewers", "ICLR.cc/2019/Conference/Paper479/Authors", "ICLR.cc/2019/Conference/Paper479/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621617202}}}, {"id": "B1lhSkeq67", "original": null, "number": 3, "cdate": 1542221635841, "ddate": null, "tcdate": 1542221635841, "tmdate": 1542221635841, "tddate": null, "forum": "Sk4jFoA9K7", "replyto": "Sk4jFoA9K7", "invitation": "ICLR.cc/2019/Conference/-/Paper479/Public_Comment", "content": {"comment": "It appears this paper is causing gradient masking. Looking at Figure 5, FGSM is a more effective attack than PGD at eps=0.1, which is highly suspicious and is listed as one of the tests for identifying gradient masking in Athalye et al. 2018.\n\nThe authors may wish to try black-box attacks (e.g., SPSA by Uesato et al at ICML'18) to see if this is happening.\n\nFurther, this paper claims ~15% robustness at eps=0.1 (25/255) on CIFAR-10, and a non-zero robustness at eps=0.2 (50/255). No prior work has been able to achieve greater than ~10% accuracy at eps=0.06 (16/255), see Madry et al. 2018.", "title": "The defense appears to be causing gradient masking"}, "signatures": ["(anonymous)"], "readers": ["everyone"], "nonreaders": [], "writers": ["(anonymous)", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "PeerNets: Exploiting Peer Wisdom Against Adversarial Attacks", "abstract": "Deep learning systems have become ubiquitous in many aspects of our lives. Unfortunately, it has been shown that such systems are vulnerable to adversarial attacks, making them prone to potential unlawful uses. \nDesigning deep neural networks that are robust to adversarial attacks is a fundamental step in making such systems safer and deployable in a broader variety of applications (e.g. autonomous driving), but more importantly is a necessary step to design novel and more advanced architectures built on new computational paradigms rather than marginally building on the existing ones.\nIn this paper we introduce PeerNets, a novel family of convolutional networks alternating classical Euclidean convolutions with graph convolutions to harness information from a graph of peer samples. This results in a form of non-local forward propagation in the model, where latent features are conditioned on the global structure induced by the graph, that is up to 3 times more robust to a variety of white- and black-box adversarial attacks compared to conventional architectures with almost no drop in accuracy.", "keywords": ["peernet", "peernets", "graph", "geometric deep learning", "adversarial", "perturbation", "defense", "peer regularization"], "authorids": ["jan.svoboda@usi.ch", "jonathan@nnaisense.com", "federico.monti@usi.ch", "michael.bronstein@usi.ch", "guibas@cs.stanford.edu"], "authors": ["Jan Svoboda", "Jonathan Masci", "Federico Monti", "Michael Bronstein", "Leonidas Guibas"], "pdf": "/pdf/db4c845b7b0cec7cb15d73ff07356dfcd900c1b4.pdf", "paperhash": "svoboda|peernets_exploiting_peer_wisdom_against_adversarial_attacks", "_bibtex": "@inproceedings{\nsvoboda2018peernets,\ntitle={PeerNets: Exploiting Peer Wisdom Against Adversarial Attacks},\nauthor={Jan Svoboda and Jonathan Masci and Federico Monti and Michael Bronstein and Leonidas Guibas},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=Sk4jFoA9K7},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper479/Public_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1542311830701, "tddate": null, "super": null, "final": null, "reply": {"signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed."}, "nonreaders": {"values": []}, "forum": "Sk4jFoA9K7", "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper479/Authors", "ICLR.cc/2019/Conference/Paper479/Reviewers", "ICLR.cc/2019/Conference/Paper479/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "replyto": null, "content": {"comment": {"value-regex": "[\\S\\s]{1,5000}", "required": true, "order": 1, "description": "Your comment or reply (max 5000 characters)."}, "title": {"value-regex": ".{1,500}", "required": true, "order": 0, "description": "Brief summary of your comment."}}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["~"], "noninvitees": ["ICLR.cc/2019/Conference/Paper479/Authors", "ICLR.cc/2019/Conference/Paper479/Reviewers", "ICLR.cc/2019/Conference/Paper479/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1542311830701}}}, {"id": "HkgMKRcth7", "original": null, "number": 2, "cdate": 1541152377520, "ddate": null, "tcdate": 1541152377520, "tmdate": 1541533961382, "tddate": null, "forum": "Sk4jFoA9K7", "replyto": "Sk4jFoA9K7", "invitation": "ICLR.cc/2019/Conference/-/Paper479/Official_Review", "content": {"title": "interesting work introducing graph neural nets as regularization, with practical limitations", "review": "The paper presents a an interesting novel approach to train neural networks with so called peer regularization which aims to provide robustness to adversarial attacks. The idea is to add a graph neural network to a spatial CNN. A graph is defined over similar training samples which are found using a Monte Carlo approximation.\n\nThe regularization using graphs reminds me of recent work at ICML on semi-supervised learning (Kamnitsas et al. (2018) Semi-supervised learning via compact latent space clustering) which is using a graph to approximate cluster density which acts as a regularizer for training on labelled data.\n\nThe main problem I see with these approaches is that they rely on sufficiently large batch sizes which could be (currently) problematic for many real-world applications. Memory and computation limitations are mentioned, but not sufficently discussed. It would be good to add further details on practical limitations.\n\nExperiments are limited to benchmark data using MNIST, CIFAR-10, CIFAR-100. Comprehensive evaluation has been carried out with insightful experiments and good comparison to state-of-the-art. Both white- and black-box adversarial attacks are explored with promising results for the proposed approach.\n\nHowever, it is difficult to draw conclusions for real-world problems of larger scale. The authors state that proposed framework can be added to any baseline model, but miss to clearly mention the limitations. It is stated that future work will aim at scaling PeerNets to benchmarks like ImageNet, but it is unclear how this could be done. Is there any hope this could be applied to problems like 3D imaging data or videos?\n", "rating": "7: Good paper, accept", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["ICLR.cc/2019/Conference/Paper479/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "PeerNets: Exploiting Peer Wisdom Against Adversarial Attacks", "abstract": "Deep learning systems have become ubiquitous in many aspects of our lives. Unfortunately, it has been shown that such systems are vulnerable to adversarial attacks, making them prone to potential unlawful uses. \nDesigning deep neural networks that are robust to adversarial attacks is a fundamental step in making such systems safer and deployable in a broader variety of applications (e.g. autonomous driving), but more importantly is a necessary step to design novel and more advanced architectures built on new computational paradigms rather than marginally building on the existing ones.\nIn this paper we introduce PeerNets, a novel family of convolutional networks alternating classical Euclidean convolutions with graph convolutions to harness information from a graph of peer samples. This results in a form of non-local forward propagation in the model, where latent features are conditioned on the global structure induced by the graph, that is up to 3 times more robust to a variety of white- and black-box adversarial attacks compared to conventional architectures with almost no drop in accuracy.", "keywords": ["peernet", "peernets", "graph", "geometric deep learning", "adversarial", "perturbation", "defense", "peer regularization"], "authorids": ["jan.svoboda@usi.ch", "jonathan@nnaisense.com", "federico.monti@usi.ch", "michael.bronstein@usi.ch", "guibas@cs.stanford.edu"], "authors": ["Jan Svoboda", "Jonathan Masci", "Federico Monti", "Michael Bronstein", "Leonidas Guibas"], "pdf": "/pdf/db4c845b7b0cec7cb15d73ff07356dfcd900c1b4.pdf", "paperhash": "svoboda|peernets_exploiting_peer_wisdom_against_adversarial_attacks", "_bibtex": "@inproceedings{\nsvoboda2018peernets,\ntitle={PeerNets: Exploiting Peer Wisdom Against Adversarial Attacks},\nauthor={Jan Svoboda and Jonathan Masci and Federico Monti and Michael Bronstein and Leonidas Guibas},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=Sk4jFoA9K7},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper479/Official_Review", "cdate": 1542234452036, "expdate": 1552335264000, "duedate": 1541196000000, "reply": {"forum": "Sk4jFoA9K7", "replyto": "Sk4jFoA9K7", "readers": {"description": "The users who will be allowed to read the reply content.", "values": ["everyone"]}, "nonreaders": {"values": []}, "signatures": {"description": "How your identity will be displayed with the above content.", "values-regex": "ICLR.cc/2019/Conference/Paper479/AnonReviewer[0-9]+"}, "writers": {"description": "Users that may modify this record.", "values": ["ICLR.cc/2019/Conference"]}, "content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "required": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}}, "multiReply": false, "tcdate": 1552335733572, "tmdate": 1552335733572, "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "invitees": ["ICLR.cc/2019/Conference/Paper479/Reviewers"], "noninvitees": [], "signatures": ["ICLR.cc/2019/Conference"]}}}, {"id": "BkxmCEYpnX", "original": null, "number": 2, "cdate": 1541407947109, "ddate": null, "tcdate": 1541407947109, "tmdate": 1541407947109, "tddate": null, "forum": "Sk4jFoA9K7", "replyto": "H1x6i6fgnm", "invitation": "ICLR.cc/2019/Conference/-/Paper479/Official_Comment", "content": {"title": "Baseline comparisons", "comment": "Thanks for suggesting the reference, which we will include in the revision. Considering the paper by Athalye et al. (https://arxiv.org/abs/1802.00420), most of the recently proposed defenses are ineffective. We actually refer to this fact in Section 4.3.2, where the 2nd paragraph points out that the way we train our model should make it more robust compared to the baselines, which, by the nature of their use, are prone to the problem of obfuscated gradients.\n\nWe however needed to select some baselines to compare to, and chose the methods that are, in some sense, similar to our approach. "}, "signatures": ["ICLR.cc/2019/Conference/Paper479/Authors"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper479/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper479/Authors", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "PeerNets: Exploiting Peer Wisdom Against Adversarial Attacks", "abstract": "Deep learning systems have become ubiquitous in many aspects of our lives. Unfortunately, it has been shown that such systems are vulnerable to adversarial attacks, making them prone to potential unlawful uses. \nDesigning deep neural networks that are robust to adversarial attacks is a fundamental step in making such systems safer and deployable in a broader variety of applications (e.g. autonomous driving), but more importantly is a necessary step to design novel and more advanced architectures built on new computational paradigms rather than marginally building on the existing ones.\nIn this paper we introduce PeerNets, a novel family of convolutional networks alternating classical Euclidean convolutions with graph convolutions to harness information from a graph of peer samples. This results in a form of non-local forward propagation in the model, where latent features are conditioned on the global structure induced by the graph, that is up to 3 times more robust to a variety of white- and black-box adversarial attacks compared to conventional architectures with almost no drop in accuracy.", "keywords": ["peernet", "peernets", "graph", "geometric deep learning", "adversarial", "perturbation", "defense", "peer regularization"], "authorids": ["jan.svoboda@usi.ch", "jonathan@nnaisense.com", "federico.monti@usi.ch", "michael.bronstein@usi.ch", "guibas@cs.stanford.edu"], "authors": ["Jan Svoboda", "Jonathan Masci", "Federico Monti", "Michael Bronstein", "Leonidas Guibas"], "pdf": "/pdf/db4c845b7b0cec7cb15d73ff07356dfcd900c1b4.pdf", "paperhash": "svoboda|peernets_exploiting_peer_wisdom_against_adversarial_attacks", "_bibtex": "@inproceedings{\nsvoboda2018peernets,\ntitle={PeerNets: Exploiting Peer Wisdom Against Adversarial Attacks},\nauthor={Jan Svoboda and Jonathan Masci and Federico Monti and Michael Bronstein and Leonidas Guibas},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=Sk4jFoA9K7},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper479/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621617202, "tddate": null, "super": null, "final": null, "reply": {"forum": "Sk4jFoA9K7", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper479/Authors", "ICLR.cc/2019/Conference/Paper479/Reviewers", "ICLR.cc/2019/Conference/Paper479/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper479/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper479/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper479/Authors|ICLR.cc/2019/Conference/Paper479/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper479/Reviewers", "ICLR.cc/2019/Conference/Paper479/Authors", "ICLR.cc/2019/Conference/Paper479/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621617202}}}, {"id": "HygvKNtThX", "original": null, "number": 1, "cdate": 1541407870571, "ddate": null, "tcdate": 1541407870571, "tmdate": 1541407914269, "tddate": null, "forum": "Sk4jFoA9K7", "replyto": "H1lwBrml27", "invitation": "ICLR.cc/2019/Conference/-/Paper479/Official_Comment", "content": {"title": "Additional comparison", "comment": "Thank you for your comments.\n\nCan you compare with adversarial training? \n---\n\n1. We tried ResNet-32 with adversarial training. The resulting combination is not efficient, as also reported by Dezfooli et al. \n\n2. We used the default parameters suggested by foolbox. During PGD iterations, we have observed that the update in perturbation strength (increase or decrease) is diminishing into orders of 1-e3 over the iterations and we therefore did not expect that increasing the  number of iterations would give us any noticeable improvement. \n\nFurther, have you considered the CW attack, gradient-free attacks and adaptive versions?\n---\n\n3. In our work, we mainly focused on gradient-based white box attacks and compared primarily against universal adversarial perturbations by Dezfooli etal. and also against some of the classic gradient-based attacks (gradient descent, FGSM, PGD). We have not tried gradient-free attacks. \n\nFollowing your suggestion, we evaluated out method on CW L2 attack, which is newly implemented in foolbox. To provide a fair comparison, we used the same settings for PeerNets and CNN baseline. The results are reported below:\n\nCNN baseline: L2 error = 49.86 | Linf error = 4.327 | fooling rate = 100%\nPeerNets: L2 error = 365.59 | Linf error = 27.43 | fooling rate = 93.76%\n\nThis clearly shows that PeerNets are more robust to CW L2 attack (the perturbation required to achieve a similar fooling rate on PeerNet has to be nearly an order of magnitude stronger). \n\n"}, "signatures": ["ICLR.cc/2019/Conference/Paper479/Authors"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper479/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper479/Authors", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "PeerNets: Exploiting Peer Wisdom Against Adversarial Attacks", "abstract": "Deep learning systems have become ubiquitous in many aspects of our lives. Unfortunately, it has been shown that such systems are vulnerable to adversarial attacks, making them prone to potential unlawful uses. \nDesigning deep neural networks that are robust to adversarial attacks is a fundamental step in making such systems safer and deployable in a broader variety of applications (e.g. autonomous driving), but more importantly is a necessary step to design novel and more advanced architectures built on new computational paradigms rather than marginally building on the existing ones.\nIn this paper we introduce PeerNets, a novel family of convolutional networks alternating classical Euclidean convolutions with graph convolutions to harness information from a graph of peer samples. This results in a form of non-local forward propagation in the model, where latent features are conditioned on the global structure induced by the graph, that is up to 3 times more robust to a variety of white- and black-box adversarial attacks compared to conventional architectures with almost no drop in accuracy.", "keywords": ["peernet", "peernets", "graph", "geometric deep learning", "adversarial", "perturbation", "defense", "peer regularization"], "authorids": ["jan.svoboda@usi.ch", "jonathan@nnaisense.com", "federico.monti@usi.ch", "michael.bronstein@usi.ch", "guibas@cs.stanford.edu"], "authors": ["Jan Svoboda", "Jonathan Masci", "Federico Monti", "Michael Bronstein", "Leonidas Guibas"], "pdf": "/pdf/db4c845b7b0cec7cb15d73ff07356dfcd900c1b4.pdf", "paperhash": "svoboda|peernets_exploiting_peer_wisdom_against_adversarial_attacks", "_bibtex": "@inproceedings{\nsvoboda2018peernets,\ntitle={PeerNets: Exploiting Peer Wisdom Against Adversarial Attacks},\nauthor={Jan Svoboda and Jonathan Masci and Federico Monti and Michael Bronstein and Leonidas Guibas},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=Sk4jFoA9K7},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper479/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621617202, "tddate": null, "super": null, "final": null, "reply": {"forum": "Sk4jFoA9K7", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper479/Authors", "ICLR.cc/2019/Conference/Paper479/Reviewers", "ICLR.cc/2019/Conference/Paper479/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper479/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper479/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper479/Authors|ICLR.cc/2019/Conference/Paper479/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper479/Reviewers", "ICLR.cc/2019/Conference/Paper479/Authors", "ICLR.cc/2019/Conference/Paper479/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621617202}}}, {"id": "H1lwBrml27", "original": null, "number": 2, "cdate": 1540531518696, "ddate": null, "tcdate": 1540531518696, "tmdate": 1540531518696, "tddate": null, "forum": "Sk4jFoA9K7", "replyto": "Sk4jFoA9K7", "invitation": "ICLR.cc/2019/Conference/-/Paper479/Public_Comment", "content": {"comment": "Can you compare with adversarial training? Also, did you vary the PGD iterations and verify that the accuracy does not change?\n\nFurther, have you considered the CW attack, gradient-free attacks and adaptive versions?", "title": "Comparison with Madry et al. 2017"}, "signatures": ["(anonymous)"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper479/Reviewers/Unsubmitted"], "writers": ["(anonymous)", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "PeerNets: Exploiting Peer Wisdom Against Adversarial Attacks", "abstract": "Deep learning systems have become ubiquitous in many aspects of our lives. Unfortunately, it has been shown that such systems are vulnerable to adversarial attacks, making them prone to potential unlawful uses. \nDesigning deep neural networks that are robust to adversarial attacks is a fundamental step in making such systems safer and deployable in a broader variety of applications (e.g. autonomous driving), but more importantly is a necessary step to design novel and more advanced architectures built on new computational paradigms rather than marginally building on the existing ones.\nIn this paper we introduce PeerNets, a novel family of convolutional networks alternating classical Euclidean convolutions with graph convolutions to harness information from a graph of peer samples. This results in a form of non-local forward propagation in the model, where latent features are conditioned on the global structure induced by the graph, that is up to 3 times more robust to a variety of white- and black-box adversarial attacks compared to conventional architectures with almost no drop in accuracy.", "keywords": ["peernet", "peernets", "graph", "geometric deep learning", "adversarial", "perturbation", "defense", "peer regularization"], "authorids": ["jan.svoboda@usi.ch", "jonathan@nnaisense.com", "federico.monti@usi.ch", "michael.bronstein@usi.ch", "guibas@cs.stanford.edu"], "authors": ["Jan Svoboda", "Jonathan Masci", "Federico Monti", "Michael Bronstein", "Leonidas Guibas"], "pdf": "/pdf/db4c845b7b0cec7cb15d73ff07356dfcd900c1b4.pdf", "paperhash": "svoboda|peernets_exploiting_peer_wisdom_against_adversarial_attacks", "_bibtex": "@inproceedings{\nsvoboda2018peernets,\ntitle={PeerNets: Exploiting Peer Wisdom Against Adversarial Attacks},\nauthor={Jan Svoboda and Jonathan Masci and Federico Monti and Michael Bronstein and Leonidas Guibas},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=Sk4jFoA9K7},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper479/Public_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1542311830701, "tddate": null, "super": null, "final": null, "reply": {"signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed."}, "nonreaders": {"values": []}, "forum": "Sk4jFoA9K7", "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper479/Authors", "ICLR.cc/2019/Conference/Paper479/Reviewers", "ICLR.cc/2019/Conference/Paper479/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "replyto": null, "content": {"comment": {"value-regex": "[\\S\\s]{1,5000}", "required": true, "order": 1, "description": "Your comment or reply (max 5000 characters)."}, "title": {"value-regex": ".{1,500}", "required": true, "order": 0, "description": "Brief summary of your comment."}}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["~"], "noninvitees": ["ICLR.cc/2019/Conference/Paper479/Authors", "ICLR.cc/2019/Conference/Paper479/Reviewers", "ICLR.cc/2019/Conference/Paper479/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1542311830701}}}, {"id": "H1x6i6fgnm", "original": null, "number": 1, "cdate": 1540529572646, "ddate": null, "tcdate": 1540529572646, "tmdate": 1540529572646, "tddate": null, "forum": "Sk4jFoA9K7", "replyto": "Sk4jFoA9K7", "invitation": "ICLR.cc/2019/Conference/-/Paper479/Public_Comment", "content": {"comment": "For what it's worth, both of these defenses you compare against are ineffective ( https://arxiv.org/abs/1711.08478 ).", "title": "Neither MagNet nor BRELU are effective"}, "signatures": ["(anonymous)"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper479/Reviewers/Unsubmitted"], "writers": ["(anonymous)", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "PeerNets: Exploiting Peer Wisdom Against Adversarial Attacks", "abstract": "Deep learning systems have become ubiquitous in many aspects of our lives. Unfortunately, it has been shown that such systems are vulnerable to adversarial attacks, making them prone to potential unlawful uses. \nDesigning deep neural networks that are robust to adversarial attacks is a fundamental step in making such systems safer and deployable in a broader variety of applications (e.g. autonomous driving), but more importantly is a necessary step to design novel and more advanced architectures built on new computational paradigms rather than marginally building on the existing ones.\nIn this paper we introduce PeerNets, a novel family of convolutional networks alternating classical Euclidean convolutions with graph convolutions to harness information from a graph of peer samples. This results in a form of non-local forward propagation in the model, where latent features are conditioned on the global structure induced by the graph, that is up to 3 times more robust to a variety of white- and black-box adversarial attacks compared to conventional architectures with almost no drop in accuracy.", "keywords": ["peernet", "peernets", "graph", "geometric deep learning", "adversarial", "perturbation", "defense", "peer regularization"], "authorids": ["jan.svoboda@usi.ch", "jonathan@nnaisense.com", "federico.monti@usi.ch", "michael.bronstein@usi.ch", "guibas@cs.stanford.edu"], "authors": ["Jan Svoboda", "Jonathan Masci", "Federico Monti", "Michael Bronstein", "Leonidas Guibas"], "pdf": "/pdf/db4c845b7b0cec7cb15d73ff07356dfcd900c1b4.pdf", "paperhash": "svoboda|peernets_exploiting_peer_wisdom_against_adversarial_attacks", "_bibtex": "@inproceedings{\nsvoboda2018peernets,\ntitle={PeerNets: Exploiting Peer Wisdom Against Adversarial Attacks},\nauthor={Jan Svoboda and Jonathan Masci and Federico Monti and Michael Bronstein and Leonidas Guibas},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=Sk4jFoA9K7},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper479/Public_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1542311830701, "tddate": null, "super": null, "final": null, "reply": {"signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed."}, "nonreaders": {"values": []}, "forum": "Sk4jFoA9K7", "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper479/Authors", "ICLR.cc/2019/Conference/Paper479/Reviewers", "ICLR.cc/2019/Conference/Paper479/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "replyto": null, "content": {"comment": {"value-regex": "[\\S\\s]{1,5000}", "required": true, "order": 1, "description": "Your comment or reply (max 5000 characters)."}, "title": {"value-regex": ".{1,500}", "required": true, "order": 0, "description": "Brief summary of your comment."}}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["~"], "noninvitees": ["ICLR.cc/2019/Conference/Paper479/Authors", "ICLR.cc/2019/Conference/Paper479/Reviewers", "ICLR.cc/2019/Conference/Paper479/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1542311830701}}}], "count": 14}