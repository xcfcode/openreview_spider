{"notes": [{"tddate": null, "ddate": null, "cdate": null, "tmdate": 1486396488722, "tcdate": 1486396488722, "number": 1, "id": "ryW82MUOe", "invitation": "ICLR.cc/2017/conference/-/paper297/acceptance", "forum": "HJ9rLLcxg", "replyto": "HJ9rLLcxg", "signatures": ["ICLR.cc/2017/pcs"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/pcs"], "content": {"title": "ICLR committee final decision", "comment": "This paper proposes to regularize neural networks by adding synthetic data created by interpolating or extrapolating in an abstract feature space, learning by an autoencoder.\n \n The main idea is sensible, and clearly presented and motivated. Overall this paper is a good contribution. However, the idea seems unlikely to have much impact for two reasons:\n  - It's unclear when we should expect this method to help vs hurt\n  - Relatedly, the method has a number of hyperparameters that it's unclear how to set except by cross-validation.\n \n We also want to remark that other regularization methods effectively already do closely related things. Dropout, gradient noise, and Bayesian methods, for instance, effectively produce 'synthetic data' in a similar way when the high-level weights of the network are perturbed.", "decision": "Invite to Workshop Track"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Dataset Augmentation in Feature Space", "abstract": "Dataset augmentation, the practice of applying a wide array of domain-specific transformations to synthetically expand a training set, is a standard tool in supervised learning. While effective in tasks such as visual recognition, the set of transformations must be carefully designed, implemented, and tested for every new domain, limiting its re-use and generality. In this paper, we adopt a simpler, domain-agnostic approach to dataset augmentation. We start with existing data points and apply simple transformations such as adding noise, interpolating, or extrapolating between them. Our main insight is to perform the transformation not in input space, but in a learned feature space. A re-kindling of interest in unsupervised representation learning makes this technique timely and more effective. It is a simple proposal, but to-date one that has not been tested empirically. Working in the space of context vectors generated by sequence-to-sequence models, we demonstrate a technique that is effective for both static and sequential data.\n", "pdf": "/pdf/e71c24cd3ac439f1182d49e1db0451552b447455.pdf", "TL;DR": "We argue for domain-agnostic data augmentation in feature space by applying simple transformations to seq2seq context vectors.", "paperhash": "devries|dataset_augmentation_in_feature_space", "keywords": ["Unsupervised Learning"], "conflicts": ["uoguelph.ca"], "authors": ["Terrance DeVries", "Graham W. Taylor"], "authorids": ["terrance@uoguelph.ca", "gwtaylor@uoguelph.ca"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1486396489235, "id": "ICLR.cc/2017/conference/-/paper297/acceptance", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/pcs"], "noninvitees": ["ICLR.cc/2017/pcs"], "reply": {"forum": "HJ9rLLcxg", "replyto": "HJ9rLLcxg", "writers": {"values-regex": "ICLR.cc/2017/pcs"}, "signatures": {"values-regex": "ICLR.cc/2017/pcs", "description": "Your displayed identity associated with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your decision.", "value": "ICLR committee final decision"}, "comment": {"required": true, "order": 2, "description": "Decision comments.", "value-regex": "[\\S\\s]{1,5000}"}, "decision": {"required": true, "order": 3, "value-radio": ["Accept (Oral)", "Accept (Poster)", "Reject", "Invite to Workshop Track"]}}}, "nonreaders": [], "cdate": 1486396489235}}}, {"tddate": null, "tmdate": 1485369915469, "tcdate": 1485369915469, "number": 6, "id": "S1QSGO8Pg", "invitation": "ICLR.cc/2017/conference/-/paper297/public/comment", "forum": "HJ9rLLcxg", "replyto": "HJ9rLLcxg", "signatures": ["~Terrance_DeVries1"], "readers": ["everyone"], "writers": ["~Terrance_DeVries1"], "content": {"title": "Update regarding CIFAR-10 Wide ResNet results", "comment": "In our previous experiments with the Wide ResNet architecture (see our response to Reviewer1's review for details) we tested to see whether using reconstructed inputs, rather than context vectors, still yielded improved model performance. In these tests we encoded CIFAR-10 images with the encoder portion of a sequence autoencoder, extrapolated between the resulting context vectors, and then projected the context vectors back into input space with the decoder to reconstruct augmented images. The newly generated images were then added to the original dataset. We found that this data augmentation approach resulted in worse classification performance compared to the baseline model. However, we also observed that training a model on only reconstructed images (encoded then decoded, with no extrapolation) yielded results much worse than the equivalent test trained on unmodified data. We hypothesized that the decrease in performance from the tests with extrapolation may possibly be attributed to the decoder's reconstruction error rather than the effects of extrapolation. \n\nTo isolate the effects of extrapolation we conducted several more experiments, this time using reconstructed samples for all tests so that reconstruction error affected all tests equally. Any difference between baseline and extrapolation tests could now be contributed solely to the effects of extrapolation. The results from our tests are shown below:\n\nTest 1 - 24x24 reconstructions, center crop: 18.75 +/- 0.24 (% test error)\nTest 2 - 24x24 reconstructions, center crop + extrapolation: 17.72 +/- 0.45 (% test error)\nTest 3 - 24x24 reconstructions, simple data augmentation (shift + mirror): 13.55 +/- 0.15 (% test error)\nTest 4 - 24x24 reconstructions, simple data augmentation + extrapolation: 11.99 +/- 0.11 (% test error)\n\nIn these tests we observed a consistent reduction in classification error when feature space extrapolation is applied: about 1% reduction in test error when applied to 24x24 center crops of the original images, and a 1.5% reduction in test error when coupled with input space data augmentation. We believe that these results demonstrate the potential benefits of the feature space extrapolation technique, which persist even when applied to complex model architectures such as Wide ResNet. As previously mentioned we are currently investigating methods which may reduce the reconstruction error introduced during the decoding process.\n"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Dataset Augmentation in Feature Space", "abstract": "Dataset augmentation, the practice of applying a wide array of domain-specific transformations to synthetically expand a training set, is a standard tool in supervised learning. While effective in tasks such as visual recognition, the set of transformations must be carefully designed, implemented, and tested for every new domain, limiting its re-use and generality. In this paper, we adopt a simpler, domain-agnostic approach to dataset augmentation. We start with existing data points and apply simple transformations such as adding noise, interpolating, or extrapolating between them. Our main insight is to perform the transformation not in input space, but in a learned feature space. A re-kindling of interest in unsupervised representation learning makes this technique timely and more effective. It is a simple proposal, but to-date one that has not been tested empirically. Working in the space of context vectors generated by sequence-to-sequence models, we demonstrate a technique that is effective for both static and sequential data.\n", "pdf": "/pdf/e71c24cd3ac439f1182d49e1db0451552b447455.pdf", "TL;DR": "We argue for domain-agnostic data augmentation in feature space by applying simple transformations to seq2seq context vectors.", "paperhash": "devries|dataset_augmentation_in_feature_space", "keywords": ["Unsupervised Learning"], "conflicts": ["uoguelph.ca"], "authors": ["Terrance DeVries", "Graham W. Taylor"], "authorids": ["terrance@uoguelph.ca", "gwtaylor@uoguelph.ca"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287633509, "id": "ICLR.cc/2017/conference/-/paper297/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "HJ9rLLcxg", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper297/reviewers", "ICLR.cc/2017/conference/paper297/areachairs"], "cdate": 1485287633509}}}, {"tddate": null, "replyto": null, "ddate": null, "tmdate": 1484958444980, "tcdate": 1478284866065, "number": 297, "id": "HJ9rLLcxg", "invitation": "ICLR.cc/2017/conference/-/submission", "forum": "HJ9rLLcxg", "signatures": ["~Terrance_DeVries1"], "readers": ["everyone"], "content": {"title": "Dataset Augmentation in Feature Space", "abstract": "Dataset augmentation, the practice of applying a wide array of domain-specific transformations to synthetically expand a training set, is a standard tool in supervised learning. While effective in tasks such as visual recognition, the set of transformations must be carefully designed, implemented, and tested for every new domain, limiting its re-use and generality. In this paper, we adopt a simpler, domain-agnostic approach to dataset augmentation. We start with existing data points and apply simple transformations such as adding noise, interpolating, or extrapolating between them. Our main insight is to perform the transformation not in input space, but in a learned feature space. A re-kindling of interest in unsupervised representation learning makes this technique timely and more effective. It is a simple proposal, but to-date one that has not been tested empirically. Working in the space of context vectors generated by sequence-to-sequence models, we demonstrate a technique that is effective for both static and sequential data.\n", "pdf": "/pdf/e71c24cd3ac439f1182d49e1db0451552b447455.pdf", "TL;DR": "We argue for domain-agnostic data augmentation in feature space by applying simple transformations to seq2seq context vectors.", "paperhash": "devries|dataset_augmentation_in_feature_space", "keywords": ["Unsupervised Learning"], "conflicts": ["uoguelph.ca"], "authors": ["Terrance DeVries", "Graham W. Taylor"], "authorids": ["terrance@uoguelph.ca", "gwtaylor@uoguelph.ca"]}, "writers": [], "nonreaders": [], "details": {"replyCount": 13, "writable": false, "overwriting": ["HyaF53XYx"], "revisions": false, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1475686800000, "tmdate": 1478287705855, "id": "ICLR.cc/2017/conference/-/submission", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/pcs"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": null, "replyto": null, "writers": {"values-regex": "~.*"}, "signatures": {"values-regex": "~.*", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"pdf": {"required": true, "order": 5, "description": "Either upload a PDF file or provide a direct link to your PDF on ArXiv (link must begin with http(s) and end with .pdf)", "value-regex": "upload|(http|https):\\/\\/.+\\.pdf"}, "title": {"required": true, "order": 1, "description": "Title of paper.", "value-regex": ".{1,250}"}, "abstract": {"required": true, "order": 4, "description": "Abstract of paper.", "value-regex": "[\\S\\s]{1,5000}"}, "authors": {"required": true, "order": 2, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of author names, as they appear in the paper."}, "conflicts": {"required": true, "order": 100, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of email domains of people who would have a conflict of interest in reviewing this paper, (e.g., cs.umass.edu;google.com, etc.)."}, "keywords": {"order": 6, "description": "Comma separated list of keywords.", "values-dropdown": ["Theory", "Computer vision", "Speech", "Natural language processing", "Deep learning", "Unsupervised Learning", "Supervised Learning", "Semi-Supervised Learning", "Reinforcement Learning", "Transfer Learning", "Multi-modal learning", "Applications", "Optimization", "Structured prediction", "Games"]}, "TL;DR": {"required": false, "order": 3, "description": "\"Too Long; Didn't Read\": a short sentence describing your paper", "value-regex": "[^\\n]{0,250}"}, "authorids": {"required": true, "order": 3, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of author email addresses, in the same order as above."}}}, "nonreaders": [], "noninvitees": [], "expdate": 1483462800000, "cdate": 1478287705855}}}, {"tddate": null, "tmdate": 1484955537259, "tcdate": 1484955537259, "number": 1, "id": "BkY9y7lPe", "invitation": "ICLR.cc/2017/conference/-/paper297/official/comment", "forum": "HJ9rLLcxg", "replyto": "B1Yd0O_Ix", "signatures": ["ICLR.cc/2017/conference/paper297/AnonReviewer3"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/conference/paper297/AnonReviewer3"], "content": {"title": "comment", "comment": "Dear Authors,\n\nThank you for your rebuttal.\n\nRE: Datasets\nAs mentioned in my original review, the problem I have with [Arabic Digits, AUSLAN, UCFKinect] datasets are that they are not commonly used datasets in DL literature. Even for the reported results, SOTA is not always achieved. For Arabic Digits (Table 1), the method does not show SOTA, 0.74 (author's method) vs. 0.69 (Hammami et al) (lower is better). For UCFKinect (Table 3), similarly 96.41 (author's method) vs. 98.9 (Beh et al) (higher is better). Only AUSLAN showed SOTA results (this reviewer is also not familiar w/ the AUSLAN dataset). Additionally, these tasks are not necessarily suitable for the sequence-autoencoder (i.e., see Dai et al., for more relevant sequence autoencoder tasks). Side: might be wise to be consistent in reporting numbers to stick with errors (lower is better) or accuracy (higher is better).\n\nRE: \"without the usage of attention\"\nI mentioned that in my TLDR since many (not all) modern seq2seq applications/papers use attention. Since experiments were conducted w/o attention; it is unclear whether the method would extend to other models of seq2seq+attention.\n\nRE: Machine Translation\nAs repeated in the original review, if the author's showed results on MT, and showed improvements over other published numbers, this reviewer would be much more convinced w/ the method. An alternative (as mentioned in original review) is some of Dai et al. text classification tasks which also uses sequence autoencoders (i.e., there is a lot of published literature with good baselines). The text classification tasks that Dai et al. is used should be good comparison points as well, since this paper is heavily relies on the sequence autoencoder that Dai et al. introduced.\n\nRE: discrepancy between the baseline\nIt is unfortunate that the CIFAR baseline could not be replicated from Dai et al. If the author's showed convincing results on CIFAR, this reviewer would be much more inclined to improve the score even without the said MT/text experiments mentioned above. However, the discrepancy is too large between the author's baseline and Dai et al.'s baseline -- and even the improvement shown from the author's baseline is not very convincing (32.3 vs. 31.9; Dai et al., achieved 26% error -- lower is better).\n\nThis reviewer will maintain their score at 4."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Dataset Augmentation in Feature Space", "abstract": "Dataset augmentation, the practice of applying a wide array of domain-specific transformations to synthetically expand a training set, is a standard tool in supervised learning. While effective in tasks such as visual recognition, the set of transformations must be carefully designed, implemented, and tested for every new domain, limiting its re-use and generality. In this paper, we adopt a simpler, domain-agnostic approach to dataset augmentation. We start with existing data points and apply simple transformations such as adding noise, interpolating, or extrapolating between them. Our main insight is to perform the transformation not in input space, but in a learned feature space. A re-kindling of interest in unsupervised representation learning makes this technique timely and more effective. It is a simple proposal, but to-date one that has not been tested empirically. Working in the space of context vectors generated by sequence-to-sequence models, we demonstrate a technique that is effective for both static and sequential data.\n", "pdf": "/pdf/e71c24cd3ac439f1182d49e1db0451552b447455.pdf", "TL;DR": "We argue for domain-agnostic data augmentation in feature space by applying simple transformations to seq2seq context vectors.", "paperhash": "devries|dataset_augmentation_in_feature_space", "keywords": ["Unsupervised Learning"], "conflicts": ["uoguelph.ca"], "authors": ["Terrance DeVries", "Graham W. Taylor"], "authorids": ["terrance@uoguelph.ca", "gwtaylor@uoguelph.ca"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287633382, "id": "ICLR.cc/2017/conference/-/paper297/official/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "reply": {"forum": "HJ9rLLcxg", "writers": {"values-regex": "ICLR.cc/2017/conference/paper297/(AnonReviewer|areachair)[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/conference/paper297/(AnonReviewer|areachair)[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": [], "invitees": ["ICLR.cc/2017/conference/paper297/reviewers", "ICLR.cc/2017/conference/paper297/areachairs"], "cdate": 1485287633382}}}, {"tddate": null, "tmdate": 1484455537044, "tcdate": 1484455537044, "number": 5, "id": "B1Yd0O_Ix", "invitation": "ICLR.cc/2017/conference/-/paper297/public/comment", "forum": "HJ9rLLcxg", "replyto": "ByUItzz4g", "signatures": ["~Terrance_DeVries1"], "readers": ["everyone"], "writers": ["~Terrance_DeVries1"], "content": {"title": "no title", "comment": "Thanks for your feedback. We wanted to point out a few simplifications in Reviewer 3\u2019s TLDR statement which we thought unfairly represented the work:\n- When R3 said \u201cthey add noise to some representation space\u201d, this incorrectly represents what we did. We experimented with noise injection, interpolation, and extrapolation in feature space and actually found that adding noise did not work well compared to extrapolation. \n- When R3 said \u201cExperimental results show improvement from author\u2019s baseline on some toy tasks\u201d, there are two errors here. First, our Arabic Digits, Australian Sign Language Signs, and UCFKinect tests all include results that were not our own baselines; they were the best results reported by other groups that we could find on these datasets. Second, while we completely agree that Arabic Digits, AUSLAN, UCFKinect, MNIST, and CIFAR-10 are not large-scale datasets, calling them toy seems unnecessarily punitive. Our aim in choosing these datasets was breadth of modalities.\n- We\u2019re not sure why it was necessary to qualify \u201cwithout the usage of attention\u201d in the TLDR statement as it does not seem relevant to what we are exploring.\n\nWe agree that it would be interesting to explore this approach on Machine Translation (or other text-based applications). However, neither of the authors have experience in this domain and, to our understanding, most existing approaches require significant infrastructure (in terms of datasets and computational resources). We weren't able to introduce such a pipeline in the time frame allotted by the review period, but we will certainly consider it in future work.\n\nDropout on the context vector can be seen as a specific case of our method; it\u2019s a (severe) kind of noise applied to the feature-mapped inputs. We performed some tests by applying dropout to the context vectors and found that it neither increased nor decreased performance significantly.\n\nWe acknowledge the discrepancy between the baseline published by Dai et al. (26% error vs. our 32% error) and while we believe that we have exactly replicated their approach, we cannot explain the discrepancy. We reached out to these authors requesting more detail but have yet to receive a response. We have since tried more sophisticated classification (Wide ResNets), the details of which are in the response to Reviewer 1.\n\nThanks for catching the problem with the references; there was a serious error which we corrected. We have updated the Arxiv papers that were subsequently published. Thanks for taking the time to identify these."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Dataset Augmentation in Feature Space", "abstract": "Dataset augmentation, the practice of applying a wide array of domain-specific transformations to synthetically expand a training set, is a standard tool in supervised learning. While effective in tasks such as visual recognition, the set of transformations must be carefully designed, implemented, and tested for every new domain, limiting its re-use and generality. In this paper, we adopt a simpler, domain-agnostic approach to dataset augmentation. We start with existing data points and apply simple transformations such as adding noise, interpolating, or extrapolating between them. Our main insight is to perform the transformation not in input space, but in a learned feature space. A re-kindling of interest in unsupervised representation learning makes this technique timely and more effective. It is a simple proposal, but to-date one that has not been tested empirically. Working in the space of context vectors generated by sequence-to-sequence models, we demonstrate a technique that is effective for both static and sequential data.\n", "pdf": "/pdf/e71c24cd3ac439f1182d49e1db0451552b447455.pdf", "TL;DR": "We argue for domain-agnostic data augmentation in feature space by applying simple transformations to seq2seq context vectors.", "paperhash": "devries|dataset_augmentation_in_feature_space", "keywords": ["Unsupervised Learning"], "conflicts": ["uoguelph.ca"], "authors": ["Terrance DeVries", "Graham W. Taylor"], "authorids": ["terrance@uoguelph.ca", "gwtaylor@uoguelph.ca"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287633509, "id": "ICLR.cc/2017/conference/-/paper297/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "HJ9rLLcxg", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper297/reviewers", "ICLR.cc/2017/conference/paper297/areachairs"], "cdate": 1485287633509}}}, {"tddate": null, "tmdate": 1484454493258, "tcdate": 1484450814162, "number": 3, "id": "r18W2vO8x", "invitation": "ICLR.cc/2017/conference/-/paper297/public/comment", "forum": "HJ9rLLcxg", "replyto": "S1qqrWz4l", "signatures": ["~Terrance_DeVries1"], "readers": ["everyone"], "writers": ["~Terrance_DeVries1"], "content": {"title": "Classification on Reconstructed Inputs", "comment": "Thank you for your positive feedback on the paper and your constructive suggestions.\n\nWith respect to the more complex baseline, since the reviews were received, we experimented with a more state-of-the-art architecture (Wide ResNets by Zagoruyko and Komodakis, 2016) for the CIFAR-10 task. In all of our tests we held constant the  Wide Residual Network architecture (same as the one used in the Wide ResNets paper) and changed only the data. We conducted tests on the following 6 setups: \nTest 1 \u2013 32x32 input with no data augmentation (8.79% test error)\nTest 2 - 24x24 center crops with no data augmentation (11.21% test error)\nTest 3 - 24x24 center crops, reconstructed from context vectors of the original images, with no data augmentation (18.68% test error)\nTest 4 - 24x24 center crops + extrapolation (14.11% test error)\nTest 5 - 24x24 with simple data augmentation (shifting and horizontal flipping) (7.33% test error)\nTest 6 - 24x24 with simple data augmentation + extrapolation (8.55% test error)\n\nOverall performance improved greatly compared to our current sequence autoencoder + MLP results. In the Test 4 and 6 described above, we used reconstructions of the extrapolated feature vectors (in addition to the original images) to train the classifier. Although visual inspection of the reconstructions looked to us like valid training cases (i.e. objects maintained their class identity and we saw no visible artifacts) training with reconstructed extrapolated context vectors actually worsened performance. We also trained a model on only reconstructions of the original examples mapped to context vectors (i.e. no extrapolation) for Test 3. This test performed considerably worse compared to training on the original examples themselves (Test 2). Therefore we believe that, at least for CIFAR-10, there is significant loss of fidelity of the examples (original or extrapolated) when mapping to and from context vectors. We are currently investigating alternative methods that could be used to reduce the amount of error introduced during the reconstruction process,  such as static encoder-decoder architectures or performing extrapolation within the feature space of the classifier itself.\n\nWe\u2019re still in the process of running these experiments, but will add the Wide ResNet results to the final version."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Dataset Augmentation in Feature Space", "abstract": "Dataset augmentation, the practice of applying a wide array of domain-specific transformations to synthetically expand a training set, is a standard tool in supervised learning. While effective in tasks such as visual recognition, the set of transformations must be carefully designed, implemented, and tested for every new domain, limiting its re-use and generality. In this paper, we adopt a simpler, domain-agnostic approach to dataset augmentation. We start with existing data points and apply simple transformations such as adding noise, interpolating, or extrapolating between them. Our main insight is to perform the transformation not in input space, but in a learned feature space. A re-kindling of interest in unsupervised representation learning makes this technique timely and more effective. It is a simple proposal, but to-date one that has not been tested empirically. Working in the space of context vectors generated by sequence-to-sequence models, we demonstrate a technique that is effective for both static and sequential data.\n", "pdf": "/pdf/e71c24cd3ac439f1182d49e1db0451552b447455.pdf", "TL;DR": "We argue for domain-agnostic data augmentation in feature space by applying simple transformations to seq2seq context vectors.", "paperhash": "devries|dataset_augmentation_in_feature_space", "keywords": ["Unsupervised Learning"], "conflicts": ["uoguelph.ca"], "authors": ["Terrance DeVries", "Graham W. Taylor"], "authorids": ["terrance@uoguelph.ca", "gwtaylor@uoguelph.ca"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287633509, "id": "ICLR.cc/2017/conference/-/paper297/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "HJ9rLLcxg", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper297/reviewers", "ICLR.cc/2017/conference/paper297/areachairs"], "cdate": 1485287633509}}}, {"tddate": null, "tmdate": 1484451255129, "tcdate": 1484451255129, "number": 4, "id": "rkkaTPd8x", "invitation": "ICLR.cc/2017/conference/-/paper297/public/comment", "forum": "HJ9rLLcxg", "replyto": "rk7Sgr-Eg", "signatures": ["~Terrance_DeVries1"], "readers": ["everyone"], "writers": ["~Terrance_DeVries1"], "content": {"title": "no title", "comment": "Thank you for your valuable suggestions for improving the paper.\n\na) This is an interesting suggestion. In the case where noise is the transformation, this would simply amount to noise injection in the hidden layer (which we know works well as a regularizer). However, doing interpolation or extrapolation amounts to something that, to the best of our knowledge, hasn't been reported. For this paper one of our aims was to keep the encoding architecture and transformation in feature space consistent, however, we are very interested in exploring this direction for the next paper.\n\nb) Since the reviews were submitted we conducted some tests on utilizing samples from competing classes for extrapolation and interpolation, however we found that both approaches resulted in worse performance compared to the baseline.\n\nc) We ran some additional synthetic data experiments where we could control the complexity of the class boundaries. We found that extrapolation helped only in the case where there were complex class boundaries, not when the boundaries were simple (e.g. linearly separable, or one class encircling another). However, interpolation did help in these simple cases. Our best explanation at present is that interpolation tends to tighten class boundaries and unnecessarily increase confidence, leading to overfitting. In essence, it may cause the model to ignore informative extremities that can describe a complex decision boundary and produce an unnecessarily smooth decision boundary. High-dimensional, real datasets will typically have complex decision boundaries, and this is the case where we found extrapolation to shine. We have added a discussion on this matter to the conclusion section in the most recent revision of the paper.\n\nd) Please see our response to Reviewer 1 detailing the use of Wide ResNets."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Dataset Augmentation in Feature Space", "abstract": "Dataset augmentation, the practice of applying a wide array of domain-specific transformations to synthetically expand a training set, is a standard tool in supervised learning. While effective in tasks such as visual recognition, the set of transformations must be carefully designed, implemented, and tested for every new domain, limiting its re-use and generality. In this paper, we adopt a simpler, domain-agnostic approach to dataset augmentation. We start with existing data points and apply simple transformations such as adding noise, interpolating, or extrapolating between them. Our main insight is to perform the transformation not in input space, but in a learned feature space. A re-kindling of interest in unsupervised representation learning makes this technique timely and more effective. It is a simple proposal, but to-date one that has not been tested empirically. Working in the space of context vectors generated by sequence-to-sequence models, we demonstrate a technique that is effective for both static and sequential data.\n", "pdf": "/pdf/e71c24cd3ac439f1182d49e1db0451552b447455.pdf", "TL;DR": "We argue for domain-agnostic data augmentation in feature space by applying simple transformations to seq2seq context vectors.", "paperhash": "devries|dataset_augmentation_in_feature_space", "keywords": ["Unsupervised Learning"], "conflicts": ["uoguelph.ca"], "authors": ["Terrance DeVries", "Graham W. Taylor"], "authorids": ["terrance@uoguelph.ca", "gwtaylor@uoguelph.ca"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287633509, "id": "ICLR.cc/2017/conference/-/paper297/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "HJ9rLLcxg", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper297/reviewers", "ICLR.cc/2017/conference/paper297/areachairs"], "cdate": 1485287633509}}}, {"tddate": null, "tmdate": 1481939278443, "tcdate": 1481939278443, "number": 3, "id": "ByUItzz4g", "invitation": "ICLR.cc/2017/conference/-/paper297/official/review", "forum": "HJ9rLLcxg", "replyto": "HJ9rLLcxg", "signatures": ["ICLR.cc/2017/conference/paper297/AnonReviewer3"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/conference/paper297/AnonReviewer3"], "content": {"title": "review", "rating": "4: Ok but not good enough - rejection", "review": "TDLR: The authors present a regularization method wherein they add noise to some representation space. The paper mainly applies the technique w/ sequence autoencoders (Dai et al., 2015) without the usage of attention (i.e., only using the context vector). Experimental results show improvement from author's baseline on some toy tasks.\n\n=== Augmentation ===\nThe augmentation process is simple enough, take the seq2seq context vector and add noise/interpolate/extrapolate to it (Section 3.2). This reviewer is very curious whether this process will also work in non seq2seq applications. \n\nThis reviewer would have liked to see comparison with dropout on the context vector.\n\n=== Experiments ===\nSince the authors are experimenting w/ seq2seq architectures, its a little bit disappointing they didn't compare it w/ Machine Translation (MT), where there are many published papers to compare to.\n\nThe authors did compare their method on several toy datasets (that are less commonly used in DL literature) and MNIST/CIFAR. The authors show improvement over their own baselines on several toy datasets. The improvement on MNIST/CIFAR over the author's baseline seems marginal at best. The author also didn't cite/compare to the baseline published by Dai et al., 2015 for CIFAR -- here they have a much better LSTM baseline of 25% for CIFAR which beats the author's baseline of 32.35% and the author's method of 31.93%.\n\nThe experiments would be much more convincing if they did it on seq2seq+MT on say EN-FR or EN-DE. There is almost no excuse why the experiments wasn't run on the MT task, given this is the first application of seq2seq was born from. Even if not MT, then at least the sentiment analysis tasks (IMDB/Rotten Tomatoes) of the Dai et al., 2015 paper which this paper is so heavily based on for the sequence autoencoder.\n\n=== References ===\nSomething is wrong w/ your references latex setting? Seems like a lot of the conference/journal names are omitted. Additionally, you should update many cites to use the conference/journal name rather than just \"arxiv\".\n\nListen, attend and spell (should be Listen, Attend and Spell: A Neural Network for Large Vocabulary Conversational Speech Recognition) -> ICASSP\nif citing ICASSP paper above, should also cite Bahandau paper \"End-to-End Attention-based Large Vocabulary Speech Recognition\" which was published in parallel (also in ICASSP).\n\nAdam: A method for stochastic optimization -> ICLR\nAuto-encoding variational bayes -> ICLR\nAddressing the rare word problem in neural machine translation -> ACL\nPixel recurrent neural networks -> ICML\nA neural conversational model -> ICML Workshop\n", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Dataset Augmentation in Feature Space", "abstract": "Dataset augmentation, the practice of applying a wide array of domain-specific transformations to synthetically expand a training set, is a standard tool in supervised learning. While effective in tasks such as visual recognition, the set of transformations must be carefully designed, implemented, and tested for every new domain, limiting its re-use and generality. In this paper, we adopt a simpler, domain-agnostic approach to dataset augmentation. We start with existing data points and apply simple transformations such as adding noise, interpolating, or extrapolating between them. Our main insight is to perform the transformation not in input space, but in a learned feature space. A re-kindling of interest in unsupervised representation learning makes this technique timely and more effective. It is a simple proposal, but to-date one that has not been tested empirically. Working in the space of context vectors generated by sequence-to-sequence models, we demonstrate a technique that is effective for both static and sequential data.\n", "pdf": "/pdf/e71c24cd3ac439f1182d49e1db0451552b447455.pdf", "TL;DR": "We argue for domain-agnostic data augmentation in feature space by applying simple transformations to seq2seq context vectors.", "paperhash": "devries|dataset_augmentation_in_feature_space", "keywords": ["Unsupervised Learning"], "conflicts": ["uoguelph.ca"], "authors": ["Terrance DeVries", "Graham W. Taylor"], "authorids": ["terrance@uoguelph.ca", "gwtaylor@uoguelph.ca"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1481932799000, "tmdate": 1482512632802, "id": "ICLR.cc/2017/conference/-/paper297/official/review", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/conference/paper297/reviewers"], "noninvitees": ["ICLR.cc/2017/conference/paper297/AnonReviewer2", "ICLR.cc/2017/conference/paper297/AnonReviewer1", "ICLR.cc/2017/conference/paper297/AnonReviewer3"], "reply": {"forum": "HJ9rLLcxg", "replyto": "HJ9rLLcxg", "writers": {"values-regex": "ICLR.cc/2017/conference/paper297/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/conference/paper297/AnonReviewer[0-9]+"}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "value-regex": "[\\S\\s]{1,20000}"}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1489708799000, "cdate": 1482512632802}}}, {"tddate": null, "tmdate": 1481934226286, "tcdate": 1481934226286, "number": 2, "id": "S1qqrWz4l", "invitation": "ICLR.cc/2017/conference/-/paper297/official/review", "forum": "HJ9rLLcxg", "replyto": "HJ9rLLcxg", "signatures": ["ICLR.cc/2017/conference/paper297/AnonReviewer1"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/conference/paper297/AnonReviewer1"], "content": {"title": "", "rating": "7: Good paper, accept", "review": "The concept of data augmentation in the embedding space is very interesting. The method is well presented and also justified on different tasks such as spoken digits and image recognition etc.\n\nOne comments of the comparison is the use of a simple 2-layer MLP as the baseline model throughout all the tasks. It's not clear whether the gains maintain when a more complex baseline model is used. \n\nAnother comment is that the augmented context vectors are used for classification, just wondering how does it compare to using the reconstructed inputs. And furthermore, as in Table 4, both input and feature space extrapolation improves the performance, whether these two are complementary or not? ", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Dataset Augmentation in Feature Space", "abstract": "Dataset augmentation, the practice of applying a wide array of domain-specific transformations to synthetically expand a training set, is a standard tool in supervised learning. While effective in tasks such as visual recognition, the set of transformations must be carefully designed, implemented, and tested for every new domain, limiting its re-use and generality. In this paper, we adopt a simpler, domain-agnostic approach to dataset augmentation. We start with existing data points and apply simple transformations such as adding noise, interpolating, or extrapolating between them. Our main insight is to perform the transformation not in input space, but in a learned feature space. A re-kindling of interest in unsupervised representation learning makes this technique timely and more effective. It is a simple proposal, but to-date one that has not been tested empirically. Working in the space of context vectors generated by sequence-to-sequence models, we demonstrate a technique that is effective for both static and sequential data.\n", "pdf": "/pdf/e71c24cd3ac439f1182d49e1db0451552b447455.pdf", "TL;DR": "We argue for domain-agnostic data augmentation in feature space by applying simple transformations to seq2seq context vectors.", "paperhash": "devries|dataset_augmentation_in_feature_space", "keywords": ["Unsupervised Learning"], "conflicts": ["uoguelph.ca"], "authors": ["Terrance DeVries", "Graham W. Taylor"], "authorids": ["terrance@uoguelph.ca", "gwtaylor@uoguelph.ca"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1481932799000, "tmdate": 1482512632802, "id": "ICLR.cc/2017/conference/-/paper297/official/review", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/conference/paper297/reviewers"], "noninvitees": ["ICLR.cc/2017/conference/paper297/AnonReviewer2", "ICLR.cc/2017/conference/paper297/AnonReviewer1", "ICLR.cc/2017/conference/paper297/AnonReviewer3"], "reply": {"forum": "HJ9rLLcxg", "replyto": "HJ9rLLcxg", "writers": {"values-regex": "ICLR.cc/2017/conference/paper297/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/conference/paper297/AnonReviewer[0-9]+"}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "value-regex": "[\\S\\s]{1,20000}"}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1489708799000, "cdate": 1482512632802}}}, {"tddate": null, "tmdate": 1481883707389, "tcdate": 1481883707389, "number": 1, "id": "rk7Sgr-Eg", "invitation": "ICLR.cc/2017/conference/-/paper297/official/review", "forum": "HJ9rLLcxg", "replyto": "HJ9rLLcxg", "signatures": ["ICLR.cc/2017/conference/paper297/AnonReviewer2"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/conference/paper297/AnonReviewer2"], "content": {"title": "", "rating": "6: Marginally above acceptance threshold", "review": "In this paper authors propose a novel data augmentation scheme where instead of augmenting the input data, they augment intermediate feature representations.  Sequence auto-encoder based features are considered, and random perturbation, feature interpolation, and extrapolation based augmentation are evaluated. On three sequence classification tasks and on MNIST and CIFAR-10, it is shown that augmentation in feature space, specifically extrapolation based augmentation, results in good accuracy gains w.r.t. authors baseline.\n\nMy main questions and suggestions for further strengthening the paper are:\n\na) The proposed data augmentation approach is applied to a learnt auto-encoder based feature space termed \u2018context vector\u2019 in the paper.  The context vectors are then augmented and used as input to train classification models. Have the authors considered applying their feature space augmentation idea directly to the classification model during training, and applying it to potentially many layers of the model?  Also, have the authors considered convolutional neural network (CNN) architectures as well for feature space augmentation?  CNNs are now the state-of-the-art in many image and sequence classification task, it would be very valuable to see the impact of the proposed approach in that model.\n\nb) When interpolation or extrapolation based augmentation was being applied, did the authors also consider utilizing nearby samples from competing classes as well?  Especially in case of extrapolation based augmentation it will be interesting to check if the extrapolated features are closer to competing classes than original ones.\n\nc) With random interpolation or nearest neighbor interpolation based augmentation the accuracy seems to degrade pretty consistently.  This is counter-intuitive.  Do the authors have explanation for why the accuracy degraded with interpolation based augmentation?\n\nd) The results on MNIST and CIFAR-10 are inconclusive.  For instance the error rate on CIFAR-10 is well below 10% these days, so I think it is hard to draw conclusions based on error rates above 30%.  For MNIST it is surprising to see that data augmentation in the input space substantially degrades the accuracy (1.093% -> 1.477%).  As mentioned above, I think this will require extending the feature space augmentation idea to CNN based models.", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Dataset Augmentation in Feature Space", "abstract": "Dataset augmentation, the practice of applying a wide array of domain-specific transformations to synthetically expand a training set, is a standard tool in supervised learning. While effective in tasks such as visual recognition, the set of transformations must be carefully designed, implemented, and tested for every new domain, limiting its re-use and generality. In this paper, we adopt a simpler, domain-agnostic approach to dataset augmentation. We start with existing data points and apply simple transformations such as adding noise, interpolating, or extrapolating between them. Our main insight is to perform the transformation not in input space, but in a learned feature space. A re-kindling of interest in unsupervised representation learning makes this technique timely and more effective. It is a simple proposal, but to-date one that has not been tested empirically. Working in the space of context vectors generated by sequence-to-sequence models, we demonstrate a technique that is effective for both static and sequential data.\n", "pdf": "/pdf/e71c24cd3ac439f1182d49e1db0451552b447455.pdf", "TL;DR": "We argue for domain-agnostic data augmentation in feature space by applying simple transformations to seq2seq context vectors.", "paperhash": "devries|dataset_augmentation_in_feature_space", "keywords": ["Unsupervised Learning"], "conflicts": ["uoguelph.ca"], "authors": ["Terrance DeVries", "Graham W. Taylor"], "authorids": ["terrance@uoguelph.ca", "gwtaylor@uoguelph.ca"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1481932799000, "tmdate": 1482512632802, "id": "ICLR.cc/2017/conference/-/paper297/official/review", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/conference/paper297/reviewers"], "noninvitees": ["ICLR.cc/2017/conference/paper297/AnonReviewer2", "ICLR.cc/2017/conference/paper297/AnonReviewer1", "ICLR.cc/2017/conference/paper297/AnonReviewer3"], "reply": {"forum": "HJ9rLLcxg", "replyto": "HJ9rLLcxg", "writers": {"values-regex": "ICLR.cc/2017/conference/paper297/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/conference/paper297/AnonReviewer[0-9]+"}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "value-regex": "[\\S\\s]{1,20000}"}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1489708799000, "cdate": 1482512632802}}}, {"tddate": null, "tmdate": 1481723590614, "tcdate": 1481723590608, "number": 2, "id": "HJ1RAaR7x", "invitation": "ICLR.cc/2017/conference/-/paper297/public/comment", "forum": "HJ9rLLcxg", "replyto": "HygjiMdQe", "signatures": ["~Terrance_DeVries1"], "readers": ["everyone"], "writers": ["~Terrance_DeVries1"], "content": {"title": "Re: Is extrapolation based augmentation risky?", "comment": "When extrapolation based augmentation is carried out it is between neighbouring samples from the same class. The amount of extrapolation can be controlled by setting the lambda parameter in Equation 3. For large values of lambda there would definitely be the possibility of generating a sample that appears to belong to a different class, but for smaller values of lambda this risk is much reduced. We found that using a lambda value of 0.5 consistently yielded good results; generated samples were different enough from the original samples so as to contribute helpful diversity to the training set, but still similar enough that they did not appear to come from different classes."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Dataset Augmentation in Feature Space", "abstract": "Dataset augmentation, the practice of applying a wide array of domain-specific transformations to synthetically expand a training set, is a standard tool in supervised learning. While effective in tasks such as visual recognition, the set of transformations must be carefully designed, implemented, and tested for every new domain, limiting its re-use and generality. In this paper, we adopt a simpler, domain-agnostic approach to dataset augmentation. We start with existing data points and apply simple transformations such as adding noise, interpolating, or extrapolating between them. Our main insight is to perform the transformation not in input space, but in a learned feature space. A re-kindling of interest in unsupervised representation learning makes this technique timely and more effective. It is a simple proposal, but to-date one that has not been tested empirically. Working in the space of context vectors generated by sequence-to-sequence models, we demonstrate a technique that is effective for both static and sequential data.\n", "pdf": "/pdf/e71c24cd3ac439f1182d49e1db0451552b447455.pdf", "TL;DR": "We argue for domain-agnostic data augmentation in feature space by applying simple transformations to seq2seq context vectors.", "paperhash": "devries|dataset_augmentation_in_feature_space", "keywords": ["Unsupervised Learning"], "conflicts": ["uoguelph.ca"], "authors": ["Terrance DeVries", "Graham W. Taylor"], "authorids": ["terrance@uoguelph.ca", "gwtaylor@uoguelph.ca"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287633509, "id": "ICLR.cc/2017/conference/-/paper297/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "HJ9rLLcxg", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper297/reviewers", "ICLR.cc/2017/conference/paper297/areachairs"], "cdate": 1485287633509}}}, {"tddate": null, "tmdate": 1481284504171, "tcdate": 1481284504165, "number": 2, "id": "HygjiMdQe", "invitation": "ICLR.cc/2017/conference/-/paper297/pre-review/question", "forum": "HJ9rLLcxg", "replyto": "HJ9rLLcxg", "signatures": ["ICLR.cc/2017/conference/paper297/AnonReviewer2"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/conference/paper297/AnonReviewer2"], "content": {"title": "Is extrapolation based augmentation risky?", "question": "Hi, when extrapolation based augmentation is carried out, do the neighboring context vectors belong to different classes (this is not clear from the paper, it seems they belong to the same class)?  If they are in the same class extrapolation based augmentation feels more risky as it could push a class into a confusable class (e.g. digit 1 into digit 7)?"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Dataset Augmentation in Feature Space", "abstract": "Dataset augmentation, the practice of applying a wide array of domain-specific transformations to synthetically expand a training set, is a standard tool in supervised learning. While effective in tasks such as visual recognition, the set of transformations must be carefully designed, implemented, and tested for every new domain, limiting its re-use and generality. In this paper, we adopt a simpler, domain-agnostic approach to dataset augmentation. We start with existing data points and apply simple transformations such as adding noise, interpolating, or extrapolating between them. Our main insight is to perform the transformation not in input space, but in a learned feature space. A re-kindling of interest in unsupervised representation learning makes this technique timely and more effective. It is a simple proposal, but to-date one that has not been tested empirically. Working in the space of context vectors generated by sequence-to-sequence models, we demonstrate a technique that is effective for both static and sequential data.\n", "pdf": "/pdf/e71c24cd3ac439f1182d49e1db0451552b447455.pdf", "TL;DR": "We argue for domain-agnostic data augmentation in feature space by applying simple transformations to seq2seq context vectors.", "paperhash": "devries|dataset_augmentation_in_feature_space", "keywords": ["Unsupervised Learning"], "conflicts": ["uoguelph.ca"], "authors": ["Terrance DeVries", "Graham W. Taylor"], "authorids": ["terrance@uoguelph.ca", "gwtaylor@uoguelph.ca"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1480741199000, "tmdate": 1481284504764, "id": "ICLR.cc/2017/conference/-/paper297/pre-review/question", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/conference/paper297/reviewers"], "noninvitees": ["ICLR.cc/2017/conference/paper297/AnonReviewer1", "ICLR.cc/2017/conference/paper297/AnonReviewer2"], "reply": {"forum": "HJ9rLLcxg", "replyto": "HJ9rLLcxg", "writers": {"values-regex": "ICLR.cc/2017/conference/paper297/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/conference/paper297/AnonReviewer[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your question.", "value-regex": ".{1,500}"}, "question": {"order": 2, "description": "Your question", "value-regex": "[\\S\\s]{1,5000}"}}}, "nonreaders": [], "expdate": 1488517199000, "cdate": 1481284504764}}}, {"tddate": null, "tmdate": 1480791659115, "tcdate": 1480791659106, "number": 1, "id": "Bk7OI5lXg", "invitation": "ICLR.cc/2017/conference/-/paper297/public/comment", "forum": "HJ9rLLcxg", "replyto": "SkSN1t0fx", "signatures": ["~Terrance_DeVries1"], "readers": ["everyone"], "writers": ["~Terrance_DeVries1"], "content": {"title": "Re: Random corruption", "comment": "Thanks for your interest and positive feedback. We view random noise as a type of \u201crandom corruption\u201d. If we have correctly understood your question, perhaps you are referring to a more structured type of corruption? Yes, this should work within our framework but if the corruption process is domain-specific then we lose one of the advantages of our method, which is that it requires no domain knowledge.\n"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Dataset Augmentation in Feature Space", "abstract": "Dataset augmentation, the practice of applying a wide array of domain-specific transformations to synthetically expand a training set, is a standard tool in supervised learning. While effective in tasks such as visual recognition, the set of transformations must be carefully designed, implemented, and tested for every new domain, limiting its re-use and generality. In this paper, we adopt a simpler, domain-agnostic approach to dataset augmentation. We start with existing data points and apply simple transformations such as adding noise, interpolating, or extrapolating between them. Our main insight is to perform the transformation not in input space, but in a learned feature space. A re-kindling of interest in unsupervised representation learning makes this technique timely and more effective. It is a simple proposal, but to-date one that has not been tested empirically. Working in the space of context vectors generated by sequence-to-sequence models, we demonstrate a technique that is effective for both static and sequential data.\n", "pdf": "/pdf/e71c24cd3ac439f1182d49e1db0451552b447455.pdf", "TL;DR": "We argue for domain-agnostic data augmentation in feature space by applying simple transformations to seq2seq context vectors.", "paperhash": "devries|dataset_augmentation_in_feature_space", "keywords": ["Unsupervised Learning"], "conflicts": ["uoguelph.ca"], "authors": ["Terrance DeVries", "Graham W. Taylor"], "authorids": ["terrance@uoguelph.ca", "gwtaylor@uoguelph.ca"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287633509, "id": "ICLR.cc/2017/conference/-/paper297/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "HJ9rLLcxg", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper297/reviewers", "ICLR.cc/2017/conference/paper297/areachairs"], "cdate": 1485287633509}}}, {"tddate": null, "tmdate": 1480654637548, "tcdate": 1480654637544, "number": 1, "id": "SkSN1t0fx", "invitation": "ICLR.cc/2017/conference/-/paper297/pre-review/question", "forum": "HJ9rLLcxg", "replyto": "HJ9rLLcxg", "signatures": ["ICLR.cc/2017/conference/paper297/AnonReviewer1"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/conference/paper297/AnonReviewer1"], "content": {"title": "Random corruption", "question": "The proposed method is interesting and the paper is well presented. Just some thoughts on the augmentation methods. Besides adding random noise, interpolation and extrapolation, one other way of improving model robustness is to randomly corrupt the representation. Wondering how that works within the proposed framework. "}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Dataset Augmentation in Feature Space", "abstract": "Dataset augmentation, the practice of applying a wide array of domain-specific transformations to synthetically expand a training set, is a standard tool in supervised learning. While effective in tasks such as visual recognition, the set of transformations must be carefully designed, implemented, and tested for every new domain, limiting its re-use and generality. In this paper, we adopt a simpler, domain-agnostic approach to dataset augmentation. We start with existing data points and apply simple transformations such as adding noise, interpolating, or extrapolating between them. Our main insight is to perform the transformation not in input space, but in a learned feature space. A re-kindling of interest in unsupervised representation learning makes this technique timely and more effective. It is a simple proposal, but to-date one that has not been tested empirically. Working in the space of context vectors generated by sequence-to-sequence models, we demonstrate a technique that is effective for both static and sequential data.\n", "pdf": "/pdf/e71c24cd3ac439f1182d49e1db0451552b447455.pdf", "TL;DR": "We argue for domain-agnostic data augmentation in feature space by applying simple transformations to seq2seq context vectors.", "paperhash": "devries|dataset_augmentation_in_feature_space", "keywords": ["Unsupervised Learning"], "conflicts": ["uoguelph.ca"], "authors": ["Terrance DeVries", "Graham W. Taylor"], "authorids": ["terrance@uoguelph.ca", "gwtaylor@uoguelph.ca"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1480741199000, "tmdate": 1481284504764, "id": "ICLR.cc/2017/conference/-/paper297/pre-review/question", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/conference/paper297/reviewers"], "noninvitees": ["ICLR.cc/2017/conference/paper297/AnonReviewer1", "ICLR.cc/2017/conference/paper297/AnonReviewer2"], "reply": {"forum": "HJ9rLLcxg", "replyto": "HJ9rLLcxg", "writers": {"values-regex": "ICLR.cc/2017/conference/paper297/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/conference/paper297/AnonReviewer[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your question.", "value-regex": ".{1,500}"}, "question": {"order": 2, "description": "Your question", "value-regex": "[\\S\\s]{1,5000}"}}}, "nonreaders": [], "expdate": 1488517199000, "cdate": 1481284504764}}}], "count": 14}