{"notes": [{"id": "-aThAo4b1zn", "original": "wld72sLx2iL", "number": 3823, "cdate": 1601308424893, "ddate": null, "tcdate": 1601308424893, "tmdate": 1614985651266, "tddate": null, "forum": "-aThAo4b1zn", "replyto": null, "invitation": "ICLR.cc/2021/Conference/-/Blind_Submission", "content": {"title": "A Theory of Self-Supervised Framework for Few-Shot Learning", "authorids": ["~Zhong_Cao1", "~Jiang_Lu1", "~Jian_Liang3", "~Changshui_Zhang2"], "authors": ["Zhong Cao", "Jiang Lu", "Jian Liang", "Changshui Zhang"], "keywords": [], "abstract": "Recently, self-supervised learning (SSL) algorithms have been applied to Few-shot learning(FSL). FSL aims at distilling transferable knowledge on existing classes with large-scale labeled data to cope with novel classes for which only a few labeled data are available. Due to the limited number of novel classes, the initial embedding network becomes an essential component and can largely affect the performance in practice. But almost no one analyzes why a pre-trained embedding network with self-supervised training can provide representation for downstream FSL tasks in theory. In this paper, we first summarized the supervised FSL methods and explained why SSL is suitable for FSL. Then we further analyzed the main difference between supervised training and self-supervised training on FSL and obtained the bound for the gap between self-supervised loss and supervised loss. Finally, we proposed potential ways to improve the test accuracy under the setting of self-supervised FSL. ", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "cao|a_theory_of_selfsupervised_framework_for_fewshot_learning", "pdf": "/pdf/3f730ddfd0ec9ef3031a78a16e0c3403defafa22.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=JZdm5cS0P7", "_bibtex": "@misc{\ncao2021a,\ntitle={A Theory of Self-Supervised Framework for Few-Shot Learning},\nauthor={Zhong Cao and Jiang Lu and Jian Liang and Changshui Zhang},\nyear={2021},\nurl={https://openreview.net/forum?id=-aThAo4b1zn}\n}"}, "signatures": ["ICLR.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference"], "details": {"replyCount": 8, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"reply": {"readers": {"values-regex": ".*"}, "writers": {"values": ["ICLR.cc/2021/Conference"]}, "signatures": {"values": ["ICLR.cc/2021/Conference"]}, "content": {"authors": {"values": ["Anonymous"]}, "authorids": {"values-regex": ".*"}, "reviewed_version_(pdf)": {"required": false, "description": "Upload a PDF file that ends with .pdf", "value-regex": ".*"}}}, "signatures": ["ICLR.cc/2021/Conference"], "readers": ["everyone"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["~", "OpenReview.net/Support"], "tcdate": 1601308008205, "tmdate": 1614984599368, "id": "ICLR.cc/2021/Conference/-/Blind_Submission"}}, "tauthor": "OpenReview.net"}, {"id": "r4z7ByMW-oO", "original": null, "number": 1, "cdate": 1610040511759, "ddate": null, "tcdate": 1610040511759, "tmdate": 1610474119625, "tddate": null, "forum": "-aThAo4b1zn", "replyto": "-aThAo4b1zn", "invitation": "ICLR.cc/2021/Conference/Paper3823/-/Decision", "content": {"title": "Final Decision", "decision": "Reject", "comment": "This paper proposed to theoretically explain why a pre-trained embedding network with self-supervised training (SSL) can provide representation for downstream few-shot learning (FSL) tasks. The review process finds that the paper may over-claim the results and that the results seem unsatisfactory. Both Reviewer 4 and Reviewer 5 expressed concerns regarding the writing, organizing, and grammar errors of this paper. The paper needs a substantial revision to improve clarity and accessibility. As pointed out by Nikunj Saunshi\u2019s public comment, this paper may benefit from discussing the differences from the previous works, including [1].  \n\n[1] Arora et al., A Theoretical Analysis of Contrastive Unsupervised Representation Learning, ICML 2019"}, "signatures": ["ICLR.cc/2021/Conference/Program_Chairs"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference/Program_Chairs"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "A Theory of Self-Supervised Framework for Few-Shot Learning", "authorids": ["~Zhong_Cao1", "~Jiang_Lu1", "~Jian_Liang3", "~Changshui_Zhang2"], "authors": ["Zhong Cao", "Jiang Lu", "Jian Liang", "Changshui Zhang"], "keywords": [], "abstract": "Recently, self-supervised learning (SSL) algorithms have been applied to Few-shot learning(FSL). FSL aims at distilling transferable knowledge on existing classes with large-scale labeled data to cope with novel classes for which only a few labeled data are available. Due to the limited number of novel classes, the initial embedding network becomes an essential component and can largely affect the performance in practice. But almost no one analyzes why a pre-trained embedding network with self-supervised training can provide representation for downstream FSL tasks in theory. In this paper, we first summarized the supervised FSL methods and explained why SSL is suitable for FSL. Then we further analyzed the main difference between supervised training and self-supervised training on FSL and obtained the bound for the gap between self-supervised loss and supervised loss. Finally, we proposed potential ways to improve the test accuracy under the setting of self-supervised FSL. ", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "cao|a_theory_of_selfsupervised_framework_for_fewshot_learning", "pdf": "/pdf/3f730ddfd0ec9ef3031a78a16e0c3403defafa22.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=JZdm5cS0P7", "_bibtex": "@misc{\ncao2021a,\ntitle={A Theory of Self-Supervised Framework for Few-Shot Learning},\nauthor={Zhong Cao and Jiang Lu and Jian Liang and Changshui Zhang},\nyear={2021},\nurl={https://openreview.net/forum?id=-aThAo4b1zn}\n}"}, "tags": [], "invitation": {"reply": {"forum": "-aThAo4b1zn", "replyto": "-aThAo4b1zn", "readers": {"values": ["everyone"]}, "writers": {"values": ["ICLR.cc/2021/Conference/Program_Chairs"]}, "signatures": {"values": ["ICLR.cc/2021/Conference/Program_Chairs"]}, "content": {"title": {"value": "Final Decision"}, "decision": {"value-radio": ["Accept (Oral)", "Accept (Spotlight)", "Accept (Poster)", "Reject"]}, "comment": {"value-regex": "[\\S\\s]{0,50000}", "markdown": true}}}, "multiReply": false, "signatures": ["ICLR.cc/2021/Conference"], "readers": ["everyone"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Program_Chairs"], "tcdate": 1610040511746, "tmdate": 1610474119609, "id": "ICLR.cc/2021/Conference/Paper3823/-/Decision"}}}, {"id": "raEVa7FTBh", "original": null, "number": 2, "cdate": 1604043351665, "ddate": null, "tcdate": 1604043351665, "tmdate": 1606288250808, "tddate": null, "forum": "-aThAo4b1zn", "replyto": "-aThAo4b1zn", "invitation": "ICLR.cc/2021/Conference/Paper3823/-/Official_Review", "content": {"title": "A theoretical trial for understanding whether self-supervised learning helps solving FSL problem", "review": "The paper proposes to theoretically analyze whether self-supervised learning can help FSL. \nUnder simplified assumptions (a simple mean classifier is used; training data is balanced; and a particular form of loss is used), the main result in Theorem 1 shows that self-supervised training loss is an upper bound of the supervised metric loss function. \n\nThe idea is interesting and inspiring. However, the analysis is less satisfactory. \nThe main concern is that Theorem 1 and 2 are quite loose. \nThey only apply for the so-called  supervised metric loss function. Is it work for any fk and fq? Can you provide more strict error bound to quantify the difference? As said in the paper, \"\u03b30, \u03b4 are constants depending on the class distribution \u03c1\", then how to estimate \u03b30, \u03b4? If they cannot be estimated, why we need this theory? How to link this theory to the success of self-supervised learning in solving FSL problem? Or can this theory be validated empirically?\n\nI think this paper indeed proposes an interesting direction to explore. But without answering the above questions, the current version is not complete enough to be published. \n\n===\n\nDuring discussion period, I noticed import missing references of this paper as written by Nikunj Saunshi. \nBesides, the authors do not respond to any of the reviewers' questions. Hence I change my score to strong rejection. \n", "rating": "2: Strong rejection", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "signatures": ["ICLR.cc/2021/Conference/Paper3823/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper3823/AnonReviewer1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "A Theory of Self-Supervised Framework for Few-Shot Learning", "authorids": ["~Zhong_Cao1", "~Jiang_Lu1", "~Jian_Liang3", "~Changshui_Zhang2"], "authors": ["Zhong Cao", "Jiang Lu", "Jian Liang", "Changshui Zhang"], "keywords": [], "abstract": "Recently, self-supervised learning (SSL) algorithms have been applied to Few-shot learning(FSL). FSL aims at distilling transferable knowledge on existing classes with large-scale labeled data to cope with novel classes for which only a few labeled data are available. Due to the limited number of novel classes, the initial embedding network becomes an essential component and can largely affect the performance in practice. But almost no one analyzes why a pre-trained embedding network with self-supervised training can provide representation for downstream FSL tasks in theory. In this paper, we first summarized the supervised FSL methods and explained why SSL is suitable for FSL. Then we further analyzed the main difference between supervised training and self-supervised training on FSL and obtained the bound for the gap between self-supervised loss and supervised loss. Finally, we proposed potential ways to improve the test accuracy under the setting of self-supervised FSL. ", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "cao|a_theory_of_selfsupervised_framework_for_fewshot_learning", "pdf": "/pdf/3f730ddfd0ec9ef3031a78a16e0c3403defafa22.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=JZdm5cS0P7", "_bibtex": "@misc{\ncao2021a,\ntitle={A Theory of Self-Supervised Framework for Few-Shot Learning},\nauthor={Zhong Cao and Jiang Lu and Jian Liang and Changshui Zhang},\nyear={2021},\nurl={https://openreview.net/forum?id=-aThAo4b1zn}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq . ***Please remember to file the Code-of-Ethics report. Once you submitted the review, a link to the report will be visible in the bottom right corner of your review.***", "required": true, "markdown": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}, "forum": "-aThAo4b1zn", "replyto": "-aThAo4b1zn", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"], "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper3823/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1607428800000, "duedate": 1606752000000, "multiReply": false, "readers": ["everyone"], "tcdate": 1602538069746, "tmdate": 1606915803437, "super": "ICLR.cc/2021/Conference/-/Official_Review", "signatures": ["OpenReview.net"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Paper3823/Reviewers", "OpenReview.net/Support"], "id": "ICLR.cc/2021/Conference/Paper3823/-/Official_Review"}}}, {"id": "iL0I81vT27r", "original": null, "number": 4, "cdate": 1605606726606, "ddate": null, "tcdate": 1605606726606, "tmdate": 1605606726606, "tddate": null, "forum": "-aThAo4b1zn", "replyto": "hqp53oRYSr", "invitation": "ICLR.cc/2021/Conference/Paper3823/-/Official_Comment", "content": {"title": "Missing important citations", "comment": "You are right, I think we should read and discuss the differences."}, "signatures": ["ICLR.cc/2021/Conference/Paper3823/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper3823/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "A Theory of Self-Supervised Framework for Few-Shot Learning", "authorids": ["~Zhong_Cao1", "~Jiang_Lu1", "~Jian_Liang3", "~Changshui_Zhang2"], "authors": ["Zhong Cao", "Jiang Lu", "Jian Liang", "Changshui Zhang"], "keywords": [], "abstract": "Recently, self-supervised learning (SSL) algorithms have been applied to Few-shot learning(FSL). FSL aims at distilling transferable knowledge on existing classes with large-scale labeled data to cope with novel classes for which only a few labeled data are available. Due to the limited number of novel classes, the initial embedding network becomes an essential component and can largely affect the performance in practice. But almost no one analyzes why a pre-trained embedding network with self-supervised training can provide representation for downstream FSL tasks in theory. In this paper, we first summarized the supervised FSL methods and explained why SSL is suitable for FSL. Then we further analyzed the main difference between supervised training and self-supervised training on FSL and obtained the bound for the gap between self-supervised loss and supervised loss. Finally, we proposed potential ways to improve the test accuracy under the setting of self-supervised FSL. ", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "cao|a_theory_of_selfsupervised_framework_for_fewshot_learning", "pdf": "/pdf/3f730ddfd0ec9ef3031a78a16e0c3403defafa22.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=JZdm5cS0P7", "_bibtex": "@misc{\ncao2021a,\ntitle={A Theory of Self-Supervised Framework for Few-Shot Learning},\nauthor={Zhong Cao and Jiang Lu and Jian Liang and Changshui Zhang},\nyear={2021},\nurl={https://openreview.net/forum?id=-aThAo4b1zn}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "-aThAo4b1zn", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper3823/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper3823/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper3823/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper3823/Authors|ICLR.cc/2021/Conference/Paper3823/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper3823/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923833844, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper3823/-/Official_Comment"}}}, {"id": "hqp53oRYSr", "original": null, "number": 1, "cdate": 1605559180887, "ddate": null, "tcdate": 1605559180887, "tmdate": 1605560336219, "tddate": null, "forum": "-aThAo4b1zn", "replyto": "-aThAo4b1zn", "invitation": "ICLR.cc/2021/Conference/Paper3823/-/Public_Comment", "content": {"title": "Missing important citations; very similar results and analysis to prior work", "comment": "The introduction of this submission states, \u201cAlmost no one analyzes why a pre-trained embedded network with self-supervised training can provide a representation for downstream FSL tasks in theory.\u201d and the related work section does not seem to have any citations to this effect. We would like to point out that the following works [1,2,4] have theoretically analyzed representations learned from contrastive learning on downstream tasks with few samples, while [3] analyzes the same for reconstruction based self-supervised learning. While [3,4] are quite recent, [1,2] have been online since at least 6 months before the deadline.\n\n\nIn particular, the results and analysis in this submission bear strong resemblance to those from our work [1]. Particularly, theorems 1 and 2 from this submission look very similar to theorems 4.1 and 4.5 (also Theorem 6.1) from [1], with the definition of $\\mathcal{L}\\_{U}$, $\\mathcal{L}\\_{U}^{-}$ and $\\mathcal{L}\\_{sup}$ (from the proof) being very similar to $L\\_{un}$, $L_{un}^{\\neq}$ and $L_{sup}$ from [1].\nFurthermore, the proofs of these results are primarily based on the use of Jensen\u2019s inequality and handling of the \u201cfalse negative data\u201d using an intra-class deviation measure $s(f)$, both of which also appear in [1], as does the use of mean classifier in the supervised learning phase.\nThe main difference seems to be the use of different representation functions $f_q$ and $f_k$ as opposed to the same function $f$ in [1]. This, however, is a straightforward extension since the proofs in [1] do not need the functions to be the same.\n\u00a0\n\nIf the authors benefited from looking at our results from [1], it should be cited as such, along with a discussion about the differences from [1].\n\n\n[1] Arora et al., A Theoretical Analysis of Contrastive Unsupervised Representation Learning, ICML 2019\n\n[2] Tosh et al., Contrastive estimation reveals topic posterior information to linear models, 2020\n\n[3] Lee et al., Predicting What You Already Know Helps: Provable Self-Supervised Learning, 2020\n\n[4] Tosh et al., Contrastive learning, multi-view redundancy, and linear models, 2020  "}, "signatures": ["~Nikunj_Saunshi1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "~Nikunj_Saunshi1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "A Theory of Self-Supervised Framework for Few-Shot Learning", "authorids": ["~Zhong_Cao1", "~Jiang_Lu1", "~Jian_Liang3", "~Changshui_Zhang2"], "authors": ["Zhong Cao", "Jiang Lu", "Jian Liang", "Changshui Zhang"], "keywords": [], "abstract": "Recently, self-supervised learning (SSL) algorithms have been applied to Few-shot learning(FSL). FSL aims at distilling transferable knowledge on existing classes with large-scale labeled data to cope with novel classes for which only a few labeled data are available. Due to the limited number of novel classes, the initial embedding network becomes an essential component and can largely affect the performance in practice. But almost no one analyzes why a pre-trained embedding network with self-supervised training can provide representation for downstream FSL tasks in theory. In this paper, we first summarized the supervised FSL methods and explained why SSL is suitable for FSL. Then we further analyzed the main difference between supervised training and self-supervised training on FSL and obtained the bound for the gap between self-supervised loss and supervised loss. Finally, we proposed potential ways to improve the test accuracy under the setting of self-supervised FSL. ", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "cao|a_theory_of_selfsupervised_framework_for_fewshot_learning", "pdf": "/pdf/3f730ddfd0ec9ef3031a78a16e0c3403defafa22.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=JZdm5cS0P7", "_bibtex": "@misc{\ncao2021a,\ntitle={A Theory of Self-Supervised Framework for Few-Shot Learning},\nauthor={Zhong Cao and Jiang Lu and Jian Liang and Changshui Zhang},\nyear={2021},\nurl={https://openreview.net/forum?id=-aThAo4b1zn}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "-aThAo4b1zn", "readers": {"description": "User groups that will be able to read this comment.", "values": ["everyone"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "~.*", "description": "How your identity will be displayed."}}, "expdate": 1605630600000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["everyone"], "noninvitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper3823/Authors", "ICLR.cc/2021/Conference/Paper3823/Reviewers", "ICLR.cc/2021/Conference/Paper3823/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs"], "tcdate": 1605024952736, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper3823/-/Public_Comment"}}}, {"id": "KRD0zkNQEmJ", "original": null, "number": 3, "cdate": 1604088138743, "ddate": null, "tcdate": 1604088138743, "tmdate": 1605092771032, "tddate": null, "forum": "-aThAo4b1zn", "replyto": "-aThAo4b1zn", "invitation": "ICLR.cc/2021/Conference/Paper3823/-/Official_Review", "content": {"title": "A theoretical justification for why self-supervised learning (SSL) helps few-shot learning (FSL). Make connection between SSL loss and supervised learning loss.", "review": "\n*** Key idea justification ***\n\nThis work shows that contrastive loss (for self-supervised learning) is an upper bound of cross-entropy loss (for supervised learning) and leads to a conclusion that this is the underlying reason why self-supervised learning can help supervised learning in FSL. This reasoning makes little sense with little logic. \n\nConcretely, there exist a number of to-be-answered questions before connecting the two things and making theoretical conclusion: \n1) Why we need to know the upper bound of supervised learning loss given that we already have label data with the training data? \n2) Decreasing SSL loss does not necessarily mean that supervised learning loss is also decreased, as it is just an upper bound. No guarantee there. \n3) Assume SSL helps decrease the supervised learning loss, then why is this needed when we can simply use class labels to minimize it? Intuitively, the two are overlapping and SSL should be not useful. \n\nBesides, this paper only considers the case of contrastive loss which involves false negative samples. What if applying other SSL loss function, for example rotation? I do see the same analysis applies to that.\n\nIn conclusion, the proposed theory makes little sense and is also over-claimed. The whole study is neither theoretical nor logical. \n\n\n*** Presentation clarity ***\n\n1) In general, the presentation of this paper is poor. One reason is using odd/strange terminologies and equation expressions. For example, contrastive loss (Eq 1) and cross-entropy loss (Eq 3) both are not given in their common expression. Other examples are \"Supervised Metric for Representations\" and \"Self-Supervised Metric (SSM) for Representations\", \"a metric loss\", etc. \n\n2) Quite a few equations are hard to read and understand. First, Eq (1) and (3) are not expressed in a standard way. How are they derived? \n\n3) What is the difference between a class-wise prototype pc and an episodic mean of support samples (At the end of Sec 3).\n\n4) What means by \"the class distribution \u03c1 is uniform\" in the proof of Theorem 2?\n\n5) What is implied by the last sentence of Sec 4: Theoretically, if given an unsupervised set with infinite classes and data, the performance achieved by SSM can be very close to that by supervised training?\n\n\n\n*** Grammatical errors ***\n1) a episodic -> an episodic\n", "rating": "2: Strong rejection", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["ICLR.cc/2021/Conference/Paper3823/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper3823/AnonReviewer2"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "A Theory of Self-Supervised Framework for Few-Shot Learning", "authorids": ["~Zhong_Cao1", "~Jiang_Lu1", "~Jian_Liang3", "~Changshui_Zhang2"], "authors": ["Zhong Cao", "Jiang Lu", "Jian Liang", "Changshui Zhang"], "keywords": [], "abstract": "Recently, self-supervised learning (SSL) algorithms have been applied to Few-shot learning(FSL). FSL aims at distilling transferable knowledge on existing classes with large-scale labeled data to cope with novel classes for which only a few labeled data are available. Due to the limited number of novel classes, the initial embedding network becomes an essential component and can largely affect the performance in practice. But almost no one analyzes why a pre-trained embedding network with self-supervised training can provide representation for downstream FSL tasks in theory. In this paper, we first summarized the supervised FSL methods and explained why SSL is suitable for FSL. Then we further analyzed the main difference between supervised training and self-supervised training on FSL and obtained the bound for the gap between self-supervised loss and supervised loss. Finally, we proposed potential ways to improve the test accuracy under the setting of self-supervised FSL. ", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "cao|a_theory_of_selfsupervised_framework_for_fewshot_learning", "pdf": "/pdf/3f730ddfd0ec9ef3031a78a16e0c3403defafa22.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=JZdm5cS0P7", "_bibtex": "@misc{\ncao2021a,\ntitle={A Theory of Self-Supervised Framework for Few-Shot Learning},\nauthor={Zhong Cao and Jiang Lu and Jian Liang and Changshui Zhang},\nyear={2021},\nurl={https://openreview.net/forum?id=-aThAo4b1zn}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq . ***Please remember to file the Code-of-Ethics report. Once you submitted the review, a link to the report will be visible in the bottom right corner of your review.***", "required": true, "markdown": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}, "forum": "-aThAo4b1zn", "replyto": "-aThAo4b1zn", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"], "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper3823/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1607428800000, "duedate": 1606752000000, "multiReply": false, "readers": ["everyone"], "tcdate": 1602538069746, "tmdate": 1606915803437, "super": "ICLR.cc/2021/Conference/-/Official_Review", "signatures": ["OpenReview.net"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Paper3823/Reviewers", "OpenReview.net/Support"], "id": "ICLR.cc/2021/Conference/Paper3823/-/Official_Review"}}}, {"id": "Uvxbqhu7Tbg", "original": null, "number": 1, "cdate": 1603868534676, "ddate": null, "tcdate": 1603868534676, "tmdate": 1605023938165, "tddate": null, "forum": "-aThAo4b1zn", "replyto": "-aThAo4b1zn", "invitation": "ICLR.cc/2021/Conference/Paper3823/-/Official_Review", "content": {"title": "A Theory of Self-Supervised Framework for Few-Shot Learning", "review": "The paper establishes a relationship between self-supervised learning (SSL) and supervised few-shot learning (FSL) method and shows that when both are equivalent. The whole analysis and proof are based upon the two main assumptions: mean classifier and balanced class training data. The paper shows that if we have a too large number of classes in the SSL, then it is equivalent to the supervised learning scenario and model enjoy the same generalization ability. Always supervised loss is the upper bound by the SSL loss.\n\nComment:\n1: The paper theoretically connects the SSL and FSL and shows when both will be equivalent. Theorem-1 shows that the supervised loss is upper bound by SSL loss by a linear relation (mostly scale+shift) when |C|-->infinity then both loss is equivalent. It seems that Theorem-1 is trivial since it is obvious that for the large class there will be very less chance of the negative pair is incorrect (i.e. false negative). If all the negative pair is correct, then it is same as we know the class label and we make the negative pair using the class information of all samples. I believe this theorem provides less useful information for a practical perspective.\n\n2: Theorem 2 provides the underlying factor between the L_sup and L_U, and shows that L_sup loss is upper bound by the loss of the true-negative and the intraclass variance. For the small variance, we can reduce the gap between the supervised loss and SSL loss. Once a trivial solution is when |C|--> infinity. This theorem shows then when |C| is not large still we can still focus on reducing the intraclass variance and reduce the gap. \n\n3: It is clear that if we have large number of class, we can reduce the gap between the supervised loss and self-supervised loss, but why the large batch size help in to get a practically better result? In this case, the probability of the false-negative samples is the same, and it does not depend on the batch size. Could you please explain that? It is written that \"We can increase N by increasing the total negative samples N_k\", is true but in the total negative samples the probability of the false-negative will be same, and it depends on the number of class only. Then how large batch size help?\n\n4: In the N-way and M-shot, it is intuitive that when M increase the model performance will increase, but why with the increase of the N model performance will increase? \n\n5: Omniglot dataset has 1623 classes, while in the paper it is written that \"Omniglot involves up to 4800 classes\" please check that.\nhttps://github.com/brendenlake/omniglot", "rating": "4: Ok but not good enough - rejection", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "signatures": ["ICLR.cc/2021/Conference/Paper3823/AnonReviewer4"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper3823/AnonReviewer4"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "A Theory of Self-Supervised Framework for Few-Shot Learning", "authorids": ["~Zhong_Cao1", "~Jiang_Lu1", "~Jian_Liang3", "~Changshui_Zhang2"], "authors": ["Zhong Cao", "Jiang Lu", "Jian Liang", "Changshui Zhang"], "keywords": [], "abstract": "Recently, self-supervised learning (SSL) algorithms have been applied to Few-shot learning(FSL). FSL aims at distilling transferable knowledge on existing classes with large-scale labeled data to cope with novel classes for which only a few labeled data are available. Due to the limited number of novel classes, the initial embedding network becomes an essential component and can largely affect the performance in practice. But almost no one analyzes why a pre-trained embedding network with self-supervised training can provide representation for downstream FSL tasks in theory. In this paper, we first summarized the supervised FSL methods and explained why SSL is suitable for FSL. Then we further analyzed the main difference between supervised training and self-supervised training on FSL and obtained the bound for the gap between self-supervised loss and supervised loss. Finally, we proposed potential ways to improve the test accuracy under the setting of self-supervised FSL. ", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "cao|a_theory_of_selfsupervised_framework_for_fewshot_learning", "pdf": "/pdf/3f730ddfd0ec9ef3031a78a16e0c3403defafa22.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=JZdm5cS0P7", "_bibtex": "@misc{\ncao2021a,\ntitle={A Theory of Self-Supervised Framework for Few-Shot Learning},\nauthor={Zhong Cao and Jiang Lu and Jian Liang and Changshui Zhang},\nyear={2021},\nurl={https://openreview.net/forum?id=-aThAo4b1zn}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq . ***Please remember to file the Code-of-Ethics report. Once you submitted the review, a link to the report will be visible in the bottom right corner of your review.***", "required": true, "markdown": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}, "forum": "-aThAo4b1zn", "replyto": "-aThAo4b1zn", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"], "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper3823/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1607428800000, "duedate": 1606752000000, "multiReply": false, "readers": ["everyone"], "tcdate": 1602538069746, "tmdate": 1606915803437, "super": "ICLR.cc/2021/Conference/-/Official_Review", "signatures": ["OpenReview.net"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Paper3823/Reviewers", "OpenReview.net/Support"], "id": "ICLR.cc/2021/Conference/Paper3823/-/Official_Review"}}}, {"id": "_YqJ6ZJzPb", "original": null, "number": 4, "cdate": 1604121016038, "ddate": null, "tcdate": 1604121016038, "tmdate": 1605023937958, "tddate": null, "forum": "-aThAo4b1zn", "replyto": "-aThAo4b1zn", "invitation": "ICLR.cc/2021/Conference/Paper3823/-/Official_Review", "content": {"title": "Nice motivation and some good ideas. Need to improve writing and empirical validation. ", "review": "This paper performs theoretical analysis of the relationship between supervised learning (SL) and self-supervised learning (SSL) in the context of few-shot learning (FSL). It aims to quantify the gap in training loss between SL and contrastive SSL on FSL tasks by casting SSL as an SL problem. Using this formulation, the authors show that the self-supervised training loss is an upper bound of the supervised metric loss function, implying that if you reduce the self-supervision loss to be small enough, you can control the model\u2019s supervision loss on the training data, and thus improve results on the downstream FSL tasks. The theoretical formulation also provides guidelines for the optimal values for the queue size in contrastive SSL, which the authors evaluate on omniglot and miniImageNet datasets, showing that the test performance varies with queue size. \n\nStrengths: The motivation to perform theoretical analysis on the utility of SSL for few-shot learning is a good one. While I could not check the proofs thoroughly, they seem to provide a nice framework for explaining why SSL might provide good performance on few-shot learning. \n\nWeaknesses and suggestions: 1. The paper is very difficult to follow. While the theory section (Section 4) is reasonably well-written, the rest of the paper needs a substantial rewrite to improve clarity and accessibility. Unfortunately the writing quality makes it difficult  to make a strong case for the paper. 2. The experiments only touch upon one aspect of theory discussed in the paper -- the impact of N and M on test performance. A more  thorough comparison with SL based few-shot learning and the impact of other factors like number of classes and class imbalance on test performance would make the paper stronger.\n", "rating": "4: Ok but not good enough - rejection", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["ICLR.cc/2021/Conference/Paper3823/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper3823/AnonReviewer3"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "A Theory of Self-Supervised Framework for Few-Shot Learning", "authorids": ["~Zhong_Cao1", "~Jiang_Lu1", "~Jian_Liang3", "~Changshui_Zhang2"], "authors": ["Zhong Cao", "Jiang Lu", "Jian Liang", "Changshui Zhang"], "keywords": [], "abstract": "Recently, self-supervised learning (SSL) algorithms have been applied to Few-shot learning(FSL). FSL aims at distilling transferable knowledge on existing classes with large-scale labeled data to cope with novel classes for which only a few labeled data are available. Due to the limited number of novel classes, the initial embedding network becomes an essential component and can largely affect the performance in practice. But almost no one analyzes why a pre-trained embedding network with self-supervised training can provide representation for downstream FSL tasks in theory. In this paper, we first summarized the supervised FSL methods and explained why SSL is suitable for FSL. Then we further analyzed the main difference between supervised training and self-supervised training on FSL and obtained the bound for the gap between self-supervised loss and supervised loss. Finally, we proposed potential ways to improve the test accuracy under the setting of self-supervised FSL. ", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "cao|a_theory_of_selfsupervised_framework_for_fewshot_learning", "pdf": "/pdf/3f730ddfd0ec9ef3031a78a16e0c3403defafa22.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=JZdm5cS0P7", "_bibtex": "@misc{\ncao2021a,\ntitle={A Theory of Self-Supervised Framework for Few-Shot Learning},\nauthor={Zhong Cao and Jiang Lu and Jian Liang and Changshui Zhang},\nyear={2021},\nurl={https://openreview.net/forum?id=-aThAo4b1zn}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq . ***Please remember to file the Code-of-Ethics report. Once you submitted the review, a link to the report will be visible in the bottom right corner of your review.***", "required": true, "markdown": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}, "forum": "-aThAo4b1zn", "replyto": "-aThAo4b1zn", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"], "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper3823/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1607428800000, "duedate": 1606752000000, "multiReply": false, "readers": ["everyone"], "tcdate": 1602538069746, "tmdate": 1606915803437, "super": "ICLR.cc/2021/Conference/-/Official_Review", "signatures": ["OpenReview.net"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Paper3823/Reviewers", "OpenReview.net/Support"], "id": "ICLR.cc/2021/Conference/Paper3823/-/Official_Review"}}}, {"id": "ffIrngqRY9m", "original": null, "number": 5, "cdate": 1604642274129, "ddate": null, "tcdate": 1604642274129, "tmdate": 1605023937875, "tddate": null, "forum": "-aThAo4b1zn", "replyto": "-aThAo4b1zn", "invitation": "ICLR.cc/2021/Conference/Paper3823/-/Official_Review", "content": {"title": "Poor writing hampers an otherwise interesting study of a simple method", "review": "#### Summary\n- The authors analyze a self-supervised learning framework for downstream (supervised) few-shot classification. The self-supervised stage is a simplified version of MoCo (He et al. 2019) and relies on class-invariant augmentation of unlabeled data to produce samples for a contrastive loss. This produces two encoder networks that are used in the subsequent few-shot learning stage via a distance-based classification scheme similar to that used by Snell et al. (2017), [1], [2], and Chen et al. (2019). \n\n- The authors show that the method minimizes an upper bound on an oracle supervised distance-based classification loss. They then further analyze the looseness by decomposing the self-supervised loss into contributions from false-negative and true-negative samples. They relate these quantities to key methodological considerations, such as the level of diversity in the meta-training/base data and the number of negative samples to use during contrastive learning.\n\n- The authors assess this method on the Omniglot and miniImageNet few-shot datasets, following the setup proposed by Hsu et al. (2019) in which the meta-training (aka base) split is treated as unlabeled. The results are strong, though are curiously relegated entirely to the Appendix.\n\n#### Strengths\n- The overall pipeline is to my knowledge novel, even though the authors are careful to state that the method is not a core contribution as it draws heavily from prior methods. Unlike previous works that consider unsupervised/self-supervised pre-training for few-shot learning, this work provides some theoretical justification for its method. \n\n- Due to the judicious choice of considering contrastive learning and distance-based classification, the resulting analysis is relatively straightforward.\n\n#### Weaknesses\n- This submission is overall poorly written. It was very difficult to parse due to a copious number of grammatical errors. In numerous instances, I can't quite discern what the authors mean. Aside from this, there are many vague statements unsupported by reference or argument.\n\n- The organization leaves much to be desired. For example, results of an ablation take center stage in the main text, while key experimental exposition and benchmark results are left entirely to the Appendix.\n\n- Comparison to CACTUs (Hsu et al., 2019) is not entirely fair as the method (like most modern contrastive learning methods) requires the specification of instance transformations that are class-invariant for test tasks. This should be noted. (Though comparison to UMTRA (Khodadadeh et al., 2019) is fair.)\n\n#### Recommendation\n- I currently recommend rejection (3), as the submission's poor writing severely hampers clarity and thus prevents it from meeting publication standards. If the writing were fixed, I would probably rate it around a 6. \n\n#### References\n- [1] Qi et al., Low-Shot Learning with Imprinted Weights, CVPR 2018\n- [2] Gidaris et al., Dynamic Few-Shot Visual Learning without Forgetting, CVPR 2018", "rating": "3: Clear rejection", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "signatures": ["ICLR.cc/2021/Conference/Paper3823/AnonReviewer5"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper3823/AnonReviewer5"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "A Theory of Self-Supervised Framework for Few-Shot Learning", "authorids": ["~Zhong_Cao1", "~Jiang_Lu1", "~Jian_Liang3", "~Changshui_Zhang2"], "authors": ["Zhong Cao", "Jiang Lu", "Jian Liang", "Changshui Zhang"], "keywords": [], "abstract": "Recently, self-supervised learning (SSL) algorithms have been applied to Few-shot learning(FSL). FSL aims at distilling transferable knowledge on existing classes with large-scale labeled data to cope with novel classes for which only a few labeled data are available. Due to the limited number of novel classes, the initial embedding network becomes an essential component and can largely affect the performance in practice. But almost no one analyzes why a pre-trained embedding network with self-supervised training can provide representation for downstream FSL tasks in theory. In this paper, we first summarized the supervised FSL methods and explained why SSL is suitable for FSL. Then we further analyzed the main difference between supervised training and self-supervised training on FSL and obtained the bound for the gap between self-supervised loss and supervised loss. Finally, we proposed potential ways to improve the test accuracy under the setting of self-supervised FSL. ", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "cao|a_theory_of_selfsupervised_framework_for_fewshot_learning", "pdf": "/pdf/3f730ddfd0ec9ef3031a78a16e0c3403defafa22.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=JZdm5cS0P7", "_bibtex": "@misc{\ncao2021a,\ntitle={A Theory of Self-Supervised Framework for Few-Shot Learning},\nauthor={Zhong Cao and Jiang Lu and Jian Liang and Changshui Zhang},\nyear={2021},\nurl={https://openreview.net/forum?id=-aThAo4b1zn}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq . ***Please remember to file the Code-of-Ethics report. Once you submitted the review, a link to the report will be visible in the bottom right corner of your review.***", "required": true, "markdown": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}, "forum": "-aThAo4b1zn", "replyto": "-aThAo4b1zn", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"], "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper3823/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1607428800000, "duedate": 1606752000000, "multiReply": false, "readers": ["everyone"], "tcdate": 1602538069746, "tmdate": 1606915803437, "super": "ICLR.cc/2021/Conference/-/Official_Review", "signatures": ["OpenReview.net"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Paper3823/Reviewers", "OpenReview.net/Support"], "id": "ICLR.cc/2021/Conference/Paper3823/-/Official_Review"}}}], "count": 9}