{"notes": [{"id": "SJxsV2R5FQ", "original": "BkghyT29YX", "number": 1481, "cdate": 1538087987012, "ddate": null, "tcdate": 1538087987012, "tmdate": 1550854467174, "tddate": null, "forum": "SJxsV2R5FQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Learning sparse relational transition models", "abstract": "We present a representation for describing transition models in complex uncertain domains using relational rules.  For any action, a rule selects a set of relevant objects and computes a distribution over properties of just those objects in the resulting state given their properties in the previous state.  An iterative greedy algorithm is used to construct a set of deictic references that determine which objects are relevant in any given state.   Feed-forward neural networks are used to learn the transition distribution on the relevant objects' properties.  This strategy is demonstrated to be both more versatile and more sample efficient than learning a monolithic transition model in a simulated domain in which a robot pushes stacks of objects on a cluttered table.", "keywords": ["Deictic reference", "relational model", "rule-based transition model"], "authorids": ["victoria.f.xia281@gmail.com", "ziw@mit.edu", "krallen@mit.edu", "tslvr@mit.edu", "lpk@csail.mit.edu"], "authors": ["Victoria Xia", "Zi Wang", "Kelsey Allen", "Tom Silver", "Leslie Pack Kaelbling"], "TL;DR": "A new approach that learns a representation for describing transition models in complex uncertaindomains using relational rules. ", "pdf": "/pdf/86de7d9edeb7dd915d0c2ec57c62bfb09f44b540.pdf", "paperhash": "xia|learning_sparse_relational_transition_models", "_bibtex": "@inproceedings{\nxia2018learning,\ntitle={Learning sparse relational transition models},\nauthor={Victoria Xia and Zi Wang and Leslie Pack Kaelbling},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=SJxsV2R5FQ},\n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"replyCount": 5, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Blind_Submission", "rdate": null, "ddate": null, "expdate": null, "duedate": 1538085600000, "tmdate": 1538142958393, "tddate": null, "super": null, "final": null, "reply": {"signatures": {"values": ["ICLR.cc/2019/Conference"]}, "forum": null, "readers": {"values": ["everyone"]}, "replyto": null, "content": {"authorids": {"values-regex": ".*"}, "authors": {"values": ["Anonymous"]}}, "writers": {"values": ["ICLR.cc/2019/Conference"]}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["~"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": null, "taskCompletionCount": null, "transform": null, "cdate": 1538142958393}}, "tauthor": "OpenReview.net"}, {"id": "HJlW_1KC3m", "original": null, "number": 1, "cdate": 1541472104828, "ddate": null, "tcdate": 1541472104828, "tmdate": 1545354495018, "tddate": null, "forum": "SJxsV2R5FQ", "replyto": "SJxsV2R5FQ", "invitation": "ICLR.cc/2019/Conference/-/Paper1481/Meta_Review", "content": {"metareview": "pros:\n- the paper is well-written and precise\n- the proposed method is novel\n- valuable for real-world problems\n\ncons:\n- Reviewer 2 expresses some concern about the organization of the paper and over-generality in the exposition\n- There could be more discussion of scalability", "confidence": "3: The area chair is somewhat confident", "recommendation": "Accept (Poster)", "title": "Good paper and valuable direction"}, "signatures": ["ICLR.cc/2019/Conference/Paper1481/Area_Chair1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference/Paper1481/Area_Chair1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Learning sparse relational transition models", "abstract": "We present a representation for describing transition models in complex uncertain domains using relational rules.  For any action, a rule selects a set of relevant objects and computes a distribution over properties of just those objects in the resulting state given their properties in the previous state.  An iterative greedy algorithm is used to construct a set of deictic references that determine which objects are relevant in any given state.   Feed-forward neural networks are used to learn the transition distribution on the relevant objects' properties.  This strategy is demonstrated to be both more versatile and more sample efficient than learning a monolithic transition model in a simulated domain in which a robot pushes stacks of objects on a cluttered table.", "keywords": ["Deictic reference", "relational model", "rule-based transition model"], "authorids": ["victoria.f.xia281@gmail.com", "ziw@mit.edu", "krallen@mit.edu", "tslvr@mit.edu", "lpk@csail.mit.edu"], "authors": ["Victoria Xia", "Zi Wang", "Kelsey Allen", "Tom Silver", "Leslie Pack Kaelbling"], "TL;DR": "A new approach that learns a representation for describing transition models in complex uncertaindomains using relational rules. ", "pdf": "/pdf/86de7d9edeb7dd915d0c2ec57c62bfb09f44b540.pdf", "paperhash": "xia|learning_sparse_relational_transition_models", "_bibtex": "@inproceedings{\nxia2018learning,\ntitle={Learning sparse relational transition models},\nauthor={Victoria Xia and Zi Wang and Leslie Pack Kaelbling},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=SJxsV2R5FQ},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper1481/Meta_Review", "rdate": null, "ddate": null, "expdate": null, "duedate": 1541548800000, "tmdate": 1545352769999, "tddate": null, "super": null, "final": null, "reply": {"forum": "SJxsV2R5FQ", "replyto": "SJxsV2R5FQ", "readers": {"description": "Select all user groups that should be able to read this comment. Selecting 'All Users' will allow paper authors, reviewers, area chairs, and program chairs to view this comment.", "values": ["everyone"]}, "signatures": {"description": "How your identity will be displayed with the above content.", "values-regex": "ICLR.cc/2019/Conference/Paper1481/Area_Chair[0-9]+"}, "writers": {"description": "Users that may modify this record.", "values-regex": "ICLR.cc/2019/Conference/Paper1481/Area_Chair[0-9]+"}, "content": {"title": {"order": 1, "value-regex": ".{1,500}", "description": "Brief summary of your review.", "required": true}, "metareview": {"order": 2, "value-regex": "[\\S\\s]{1,5000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "required": true}, "recommendation": {"order": 3, "value-dropdown": ["Accept (Oral)", "Accept (Poster)", "Reject"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The area chair is absolutely certain", "4: The area chair is confident but not absolutely certain", "3: The area chair is somewhat confident", "2: The area chair is not sure", "1: The area chair's evaluation is an educated guess"], "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper1481/Area_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": false, "taskCompletionCount": null, "transform": null, "cdate": 1545352769999}}}, {"id": "Byluqeapam", "original": null, "number": 1, "cdate": 1542471824481, "ddate": null, "tcdate": 1542471824481, "tmdate": 1542471824481, "tddate": null, "forum": "SJxsV2R5FQ", "replyto": "SJxsV2R5FQ", "invitation": "ICLR.cc/2019/Conference/-/Paper1481/Official_Comment", "content": {"title": "Author rebuttal", "comment": "We thank the reviewers for their constructive feedback and address individual questions below. \n\nAR2:\n\nQ: \"the authors could have gotten to the loss function sooner.\" \nA: We will add an explanation near Eq. (1)  and emphasize that the transition will be learned.\n\nQ: ... \"it was unclear if more than a few (with few parameters) were used in the actual application, and so it's unclear that so much generality was required by the application.\"\nA: It is true that, although the framework is quite general, our demonstration domain is relatively simple.  This work is not intended to be a solution to just that domain, but to introduce a new representation and learning strategy for transition models.\n\nQ: compare to \"modern deep learning techniques for reinforcement learning such as DeepMimic (Peng et al 2018).\"\nA: Our method aims to learn a compact transition model that can generalize to different problem instances while deep RL approaches such as DeepMimic typically focuses on obtaining a policy in a model-free manner without explicitly predicting a transition model. Hence, we can't directly compare to them. Our approach can potentially be combined with model-based deep RL approaches, thought it is not a focus of this work. \n\nWe will fix the typos. \n\nAR1:\n\nQ: relation to ILP and statistical relational learning (SRL)\nA: We will amplify our discussion of the work of Benson (1997), which developed an inductive concept learning approach based on ILP to learn descriptions of the action model from data. Benson (1997), however, relies on a full description of the states in ground first-order logic and does not have a mechanism to introduce new \"references\" to the action model. Our approach is also more flexible than Benson (1997) because of the usage of neural nets as predictors. The Pasula et al work is a type of SRL, and is the closest work in that area.\n\nQ: scalability of the approach \nA: We emphasize that the rule learning EM approach can be done offline. The online prediction only requires a forward pass on the learned predictor for each applicable rule.  \n"}, "signatures": ["ICLR.cc/2019/Conference/Paper1481/Authors"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper1481/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper1481/Authors", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Learning sparse relational transition models", "abstract": "We present a representation for describing transition models in complex uncertain domains using relational rules.  For any action, a rule selects a set of relevant objects and computes a distribution over properties of just those objects in the resulting state given their properties in the previous state.  An iterative greedy algorithm is used to construct a set of deictic references that determine which objects are relevant in any given state.   Feed-forward neural networks are used to learn the transition distribution on the relevant objects' properties.  This strategy is demonstrated to be both more versatile and more sample efficient than learning a monolithic transition model in a simulated domain in which a robot pushes stacks of objects on a cluttered table.", "keywords": ["Deictic reference", "relational model", "rule-based transition model"], "authorids": ["victoria.f.xia281@gmail.com", "ziw@mit.edu", "krallen@mit.edu", "tslvr@mit.edu", "lpk@csail.mit.edu"], "authors": ["Victoria Xia", "Zi Wang", "Kelsey Allen", "Tom Silver", "Leslie Pack Kaelbling"], "TL;DR": "A new approach that learns a representation for describing transition models in complex uncertaindomains using relational rules. ", "pdf": "/pdf/86de7d9edeb7dd915d0c2ec57c62bfb09f44b540.pdf", "paperhash": "xia|learning_sparse_relational_transition_models", "_bibtex": "@inproceedings{\nxia2018learning,\ntitle={Learning sparse relational transition models},\nauthor={Victoria Xia and Zi Wang and Leslie Pack Kaelbling},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=SJxsV2R5FQ},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper1481/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621618538, "tddate": null, "super": null, "final": null, "reply": {"forum": "SJxsV2R5FQ", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper1481/Authors", "ICLR.cc/2019/Conference/Paper1481/Reviewers", "ICLR.cc/2019/Conference/Paper1481/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper1481/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper1481/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper1481/Authors|ICLR.cc/2019/Conference/Paper1481/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper1481/Reviewers", "ICLR.cc/2019/Conference/Paper1481/Authors", "ICLR.cc/2019/Conference/Paper1481/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621618538}}}, {"id": "ByePXT9anX", "original": null, "number": 3, "cdate": 1541414175214, "ddate": null, "tcdate": 1541414175214, "tmdate": 1541532986842, "tddate": null, "forum": "SJxsV2R5FQ", "replyto": "SJxsV2R5FQ", "invitation": "ICLR.cc/2019/Conference/-/Paper1481/Official_Review", "content": {"title": "Learning sparse relational transition models", "review": "In the manuscript \"Learning sparse relational transition models\", the authors combine neural nets with relational models, using ideas from linguistics. They apply this to learning the representations of the space in which a simulated robot operates in a reinforcement learning ML paradigm. This work is of interest to the AI community and ICLR is a good venue for this work.\n\nThe authors apply their model in particular to a problem in which the simulated robot must rearrange objects in space, and they achieve reasonable accuracy.\n\nMajor points:\n\n- Organisationally, I thought that the authors could have gotten to the loss function sooner, as much of the development of the theory is lacking in motivation until specific tasks are defined.\n\n- The application domain seemed to lose some of the power of the linguistic analysis they were doing to develop the representation through \"properties\" and \"action templates\". These definitions were quite general, but it was unclear if more than a few (with few parameters) were used in the actual application, and so it's unclear that so much generality was required by the application.\n\n- The authors could have compared with more modern deep learning techniques for reinforcement learning such as DeepMimic (Peng et al 2018).\n\nMinor points:\n- Typesetting periods \"Pasula et al. and\" -> \"Pasula et al.\\ and\"\n\n- Page 2: \"value of a note\" -> \"value of a node\"\n\n- 3.1 was hard to follow.", "rating": "6: Marginally above acceptance threshold", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["ICLR.cc/2019/Conference/Paper1481/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Learning sparse relational transition models", "abstract": "We present a representation for describing transition models in complex uncertain domains using relational rules.  For any action, a rule selects a set of relevant objects and computes a distribution over properties of just those objects in the resulting state given their properties in the previous state.  An iterative greedy algorithm is used to construct a set of deictic references that determine which objects are relevant in any given state.   Feed-forward neural networks are used to learn the transition distribution on the relevant objects' properties.  This strategy is demonstrated to be both more versatile and more sample efficient than learning a monolithic transition model in a simulated domain in which a robot pushes stacks of objects on a cluttered table.", "keywords": ["Deictic reference", "relational model", "rule-based transition model"], "authorids": ["victoria.f.xia281@gmail.com", "ziw@mit.edu", "krallen@mit.edu", "tslvr@mit.edu", "lpk@csail.mit.edu"], "authors": ["Victoria Xia", "Zi Wang", "Kelsey Allen", "Tom Silver", "Leslie Pack Kaelbling"], "TL;DR": "A new approach that learns a representation for describing transition models in complex uncertaindomains using relational rules. ", "pdf": "/pdf/86de7d9edeb7dd915d0c2ec57c62bfb09f44b540.pdf", "paperhash": "xia|learning_sparse_relational_transition_models", "_bibtex": "@inproceedings{\nxia2018learning,\ntitle={Learning sparse relational transition models},\nauthor={Victoria Xia and Zi Wang and Leslie Pack Kaelbling},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=SJxsV2R5FQ},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper1481/Official_Review", "cdate": 1542234191242, "expdate": 1552335264000, "duedate": 1541196000000, "reply": {"forum": "SJxsV2R5FQ", "replyto": "SJxsV2R5FQ", "readers": {"description": "The users who will be allowed to read the reply content.", "values": ["everyone"]}, "nonreaders": {"values": []}, "signatures": {"description": "How your identity will be displayed with the above content.", "values-regex": "ICLR.cc/2019/Conference/Paper1481/AnonReviewer[0-9]+"}, "writers": {"description": "Users that may modify this record.", "values": ["ICLR.cc/2019/Conference"]}, "content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "required": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}}, "multiReply": false, "tcdate": 1552335985097, "tmdate": 1552335985097, "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "invitees": ["ICLR.cc/2019/Conference/Paper1481/Reviewers"], "noninvitees": [], "signatures": ["ICLR.cc/2019/Conference"]}}}, {"id": "HJgA6WL5nm", "original": null, "number": 2, "cdate": 1541198278405, "ddate": null, "tcdate": 1541198278405, "tmdate": 1541532986634, "tddate": null, "forum": "SJxsV2R5FQ", "replyto": "SJxsV2R5FQ", "invitation": "ICLR.cc/2019/Conference/-/Paper1481/Official_Review", "content": {"title": "An approach to learn lifted transition rules using neural networks that take advantage of relational structure", "review": "An approach is proposed that learns transition rules in terms of local contexts. Specifically, transition rules make predictions as a distribution over the set of possible states based on local context of objects. A learning algorithm is described that learns the transition rules by maximizing the conditional likelihood. To learn the rules jointly with selecting the right samples for the transition rule, and EM algorithm is proposed. \n\nThe paper is well-written. The contribution seems significant considering that relational structure is integrated with neural networks in a systematic manner. Though written from the perspective of learning transition rules for tasks such as robotic manipulation, I think similar ideas can be for general tasks that can benefit from both relational structure and neural network representation.  Learning lifted rules has also been studied in  domains such as ILP and Statistical Relational Learning (Getoor and Taskar 07)(lifted rules with uncertainty). I think including their perspective and commenting on their relationship with the proposed work will be useful.\n\nExperiments are performed on a robotic manipulation task involving pushing a stack of blocks in a cluttered environment. A method that does not take object relations into account and simply predicts the state transition is used as baseline for comparison. The proposed approach shows the benefits of exploiting the structure between objects. There is not too much discussion on scalability. Does the propose method scale up for learning transition rules in real tasks? Are there any tradeoffs involved, etc. would be good to know.\nIn summary, this seems to be a well-written and novel contribution.", "rating": "7: Good paper, accept", "confidence": "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper"}, "signatures": ["ICLR.cc/2019/Conference/Paper1481/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Learning sparse relational transition models", "abstract": "We present a representation for describing transition models in complex uncertain domains using relational rules.  For any action, a rule selects a set of relevant objects and computes a distribution over properties of just those objects in the resulting state given their properties in the previous state.  An iterative greedy algorithm is used to construct a set of deictic references that determine which objects are relevant in any given state.   Feed-forward neural networks are used to learn the transition distribution on the relevant objects' properties.  This strategy is demonstrated to be both more versatile and more sample efficient than learning a monolithic transition model in a simulated domain in which a robot pushes stacks of objects on a cluttered table.", "keywords": ["Deictic reference", "relational model", "rule-based transition model"], "authorids": ["victoria.f.xia281@gmail.com", "ziw@mit.edu", "krallen@mit.edu", "tslvr@mit.edu", "lpk@csail.mit.edu"], "authors": ["Victoria Xia", "Zi Wang", "Kelsey Allen", "Tom Silver", "Leslie Pack Kaelbling"], "TL;DR": "A new approach that learns a representation for describing transition models in complex uncertaindomains using relational rules. ", "pdf": "/pdf/86de7d9edeb7dd915d0c2ec57c62bfb09f44b540.pdf", "paperhash": "xia|learning_sparse_relational_transition_models", "_bibtex": "@inproceedings{\nxia2018learning,\ntitle={Learning sparse relational transition models},\nauthor={Victoria Xia and Zi Wang and Leslie Pack Kaelbling},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=SJxsV2R5FQ},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper1481/Official_Review", "cdate": 1542234191242, "expdate": 1552335264000, "duedate": 1541196000000, "reply": {"forum": "SJxsV2R5FQ", "replyto": "SJxsV2R5FQ", "readers": {"description": "The users who will be allowed to read the reply content.", "values": ["everyone"]}, "nonreaders": {"values": []}, "signatures": {"description": "How your identity will be displayed with the above content.", "values-regex": "ICLR.cc/2019/Conference/Paper1481/AnonReviewer[0-9]+"}, "writers": {"description": "Users that may modify this record.", "values": ["ICLR.cc/2019/Conference"]}, "content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "required": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}}, "multiReply": false, "tcdate": 1552335985097, "tmdate": 1552335985097, "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "invitees": ["ICLR.cc/2019/Conference/Paper1481/Reviewers"], "noninvitees": [], "signatures": ["ICLR.cc/2019/Conference"]}}}, {"id": "SyelB6J93m", "original": null, "number": 1, "cdate": 1541172535681, "ddate": null, "tcdate": 1541172535681, "tmdate": 1541532986418, "tddate": null, "forum": "SJxsV2R5FQ", "replyto": "SJxsV2R5FQ", "invitation": "ICLR.cc/2019/Conference/-/Paper1481/Official_Review", "content": {"title": "L EARNING SPARSE RELATIONAL TRANSITION MODELS", "review": "\nSUMMARY:\nThis work is about learning state-transition models in complex domains represented as sets of objects, their properties, ``\"deictic\" reference functions between sets of objects, and possible actions (or action templates). A parametric model for the actions is assumed, and these parameters act on a neural net that learns the transition model (probabilistic rule) from the current state to the next one.  It is basically this nonlinear transition model implemented by a network which makes this work different from previous models described in the literature. The relational transition model proposed is sparse, based on the assumption that actions have only ``local effects on related objects. The prediction model itself is basically a Gaussian distribution whose mean and variances are represented by neural nets. For jointly learning multiple rules, a clustering strategy is presented which assigns experience samples to transition rules. The method is applied to simulated data in the context of predicting pushing stacks of blocks on a cluttered table top.\n\nEVALUATION: \nThe type of problems addressed in this paper is challenging and highly relevant for solving problems in the ``real'' world. Although the method proposed is in some sense a direct generalization of the work in [Pasula et al.], it still contains many novel and interesting aspects.Any single part of the model (like the use of Gaussians parametrized by functions implemented via neural nets) is somehow ``standard in deep latent variable models, but in complex real-world rule-learning problems the whole system presented  defines  certainly a big improvement over the state-of-the-art, which in my opinion has the potential to indeed advance this field of research.     \n ", "rating": "8: Top 50% of accepted papers, clear accept", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "signatures": ["ICLR.cc/2019/Conference/Paper1481/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Learning sparse relational transition models", "abstract": "We present a representation for describing transition models in complex uncertain domains using relational rules.  For any action, a rule selects a set of relevant objects and computes a distribution over properties of just those objects in the resulting state given their properties in the previous state.  An iterative greedy algorithm is used to construct a set of deictic references that determine which objects are relevant in any given state.   Feed-forward neural networks are used to learn the transition distribution on the relevant objects' properties.  This strategy is demonstrated to be both more versatile and more sample efficient than learning a monolithic transition model in a simulated domain in which a robot pushes stacks of objects on a cluttered table.", "keywords": ["Deictic reference", "relational model", "rule-based transition model"], "authorids": ["victoria.f.xia281@gmail.com", "ziw@mit.edu", "krallen@mit.edu", "tslvr@mit.edu", "lpk@csail.mit.edu"], "authors": ["Victoria Xia", "Zi Wang", "Kelsey Allen", "Tom Silver", "Leslie Pack Kaelbling"], "TL;DR": "A new approach that learns a representation for describing transition models in complex uncertaindomains using relational rules. ", "pdf": "/pdf/86de7d9edeb7dd915d0c2ec57c62bfb09f44b540.pdf", "paperhash": "xia|learning_sparse_relational_transition_models", "_bibtex": "@inproceedings{\nxia2018learning,\ntitle={Learning sparse relational transition models},\nauthor={Victoria Xia and Zi Wang and Leslie Pack Kaelbling},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=SJxsV2R5FQ},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper1481/Official_Review", "cdate": 1542234191242, "expdate": 1552335264000, "duedate": 1541196000000, "reply": {"forum": "SJxsV2R5FQ", "replyto": "SJxsV2R5FQ", "readers": {"description": "The users who will be allowed to read the reply content.", "values": ["everyone"]}, "nonreaders": {"values": []}, "signatures": {"description": "How your identity will be displayed with the above content.", "values-regex": "ICLR.cc/2019/Conference/Paper1481/AnonReviewer[0-9]+"}, "writers": {"description": "Users that may modify this record.", "values": ["ICLR.cc/2019/Conference"]}, "content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "required": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}}, "multiReply": false, "tcdate": 1552335985097, "tmdate": 1552335985097, "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "invitees": ["ICLR.cc/2019/Conference/Paper1481/Reviewers"], "noninvitees": [], "signatures": ["ICLR.cc/2019/Conference"]}}}], "count": 6}