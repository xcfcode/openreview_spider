{"notes": [{"tddate": null, "ddate": null, "cdate": null, "tmdate": 1486396327986, "tcdate": 1486396327986, "number": 1, "id": "HJlnsGUOl", "invitation": "ICLR.cc/2017/conference/-/paper52/acceptance", "forum": "SypU81Ole", "replyto": "SypU81Ole", "signatures": ["ICLR.cc/2017/pcs"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/pcs"], "content": {"decision": "Reject", "title": "ICLR committee final decision", "comment": "This paper proposes some interesting ideas about visualizing latent-variable models. The paper is nicely written and presented, but the originality and importance of the work isn't enough. Also, neither the reviewers nor I were convinced that spherical interpolation makes more sense than linear interpolation."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Sampling Generative Networks", "abstract": "We introduce several techniques for sampling and visualizing the latent spaces of generative models. Replacing linear interpolation with spherical linear interpolation prevents diverging from a model's prior distribution and produces sharper samples. J-Diagrams and MINE grids are introduced as visualizations of manifolds created by analogies and nearest neighbors. We demonstrate two new techniques for deriving attribute vectors: bias-corrected vectors with data replication and synthetic vectors with data augmentation.  Binary classification using attribute vectors is presented as a technique supporting quantitative analysis of the latent space. Most techniques are intended to be independent of model type and examples are shown on both Variational Autoencoders and Generative Adversarial Networks.\n", "pdf": "/pdf/33f8c62a4f32ce72c31a3c14e8bec5d26520c402.pdf", "TL;DR": "Demonstrates improved techniques for interpolation and deriving + evaluating attribute vectors in latent spaces applicable to both VAE and GAN models.", "paperhash": "white|sampling_generative_networks", "conflicts": ["vuw.ac.nz"], "authors": ["Tom White"], "authorids": ["tom.white@vuw.ac.nz"], "keywords": ["Unsupervised Learning", "Deep learning", "Computer vision"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1486396328460, "id": "ICLR.cc/2017/conference/-/paper52/acceptance", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/pcs"], "noninvitees": ["ICLR.cc/2017/pcs"], "reply": {"forum": "SypU81Ole", "replyto": "SypU81Ole", "writers": {"values-regex": "ICLR.cc/2017/pcs"}, "signatures": {"values-regex": "ICLR.cc/2017/pcs", "description": "Your displayed identity associated with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your decision.", "value": "ICLR committee final decision"}, "comment": {"required": true, "order": 2, "description": "Decision comments.", "value-regex": "[\\S\\s]{1,5000}"}, "decision": {"required": true, "order": 3, "value-radio": ["Accept (Oral)", "Accept (Poster)", "Reject", "Invite to Workshop Track"]}}}, "nonreaders": [], "cdate": 1486396328460}}}, {"tddate": null, "tmdate": 1485814607176, "tcdate": 1485814607176, "number": 4, "id": "H1D8j4TDx", "invitation": "ICLR.cc/2017/conference/-/paper52/official/comment", "forum": "SypU81Ole", "replyto": "SyF9R2qvl", "signatures": ["ICLR.cc/2017/conference/paper52/areachair1"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/conference/paper52/areachair1"], "content": {"title": "interesting", "comment": "Ah, thanks for running that experiment - that's an interesting observation.  I suppose that the gap between these numbers will shrink as the dimension increases, but it's good to know the different between these numbers is still appreciable even in 100 dimensions.  You've convinced me that linear interpolation biases the samples towards the origin.\n\nPerhaps a plot of these two distributions on the same axes would be informative."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Sampling Generative Networks", "abstract": "We introduce several techniques for sampling and visualizing the latent spaces of generative models. Replacing linear interpolation with spherical linear interpolation prevents diverging from a model's prior distribution and produces sharper samples. J-Diagrams and MINE grids are introduced as visualizations of manifolds created by analogies and nearest neighbors. We demonstrate two new techniques for deriving attribute vectors: bias-corrected vectors with data replication and synthetic vectors with data augmentation.  Binary classification using attribute vectors is presented as a technique supporting quantitative analysis of the latent space. Most techniques are intended to be independent of model type and examples are shown on both Variational Autoencoders and Generative Adversarial Networks.\n", "pdf": "/pdf/33f8c62a4f32ce72c31a3c14e8bec5d26520c402.pdf", "TL;DR": "Demonstrates improved techniques for interpolation and deriving + evaluating attribute vectors in latent spaces applicable to both VAE and GAN models.", "paperhash": "white|sampling_generative_networks", "conflicts": ["vuw.ac.nz"], "authors": ["Tom White"], "authorids": ["tom.white@vuw.ac.nz"], "keywords": ["Unsupervised Learning", "Deep learning", "Computer vision"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287748814, "id": "ICLR.cc/2017/conference/-/paper52/official/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "reply": {"forum": "SypU81Ole", "writers": {"values-regex": "ICLR.cc/2017/conference/paper52/(AnonReviewer|areachair)[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/conference/paper52/(AnonReviewer|areachair)[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": [], "invitees": ["ICLR.cc/2017/conference/paper52/reviewers", "ICLR.cc/2017/conference/paper52/areachairs"], "cdate": 1485287748814}}}, {"tddate": null, "tmdate": 1485651600699, "tcdate": 1485651600699, "number": 9, "id": "SyF9R2qvl", "invitation": "ICLR.cc/2017/conference/-/paper52/public/comment", "forum": "SypU81Ole", "replyto": "S1D_ww9we", "signatures": ["~Tom_White1"], "readers": ["everyone"], "writers": ["~Tom_White1"], "content": {"title": "approaching the origin", "comment": "Agreed crossing near the origin when interpolating two random vectors would be a rare event. However, this effect occurs as samples approach the origin and is not limited to the immediate vicinity of the origin. For reference, the approximate magnitude of random normal (mean=0, sd=1) vector in 100 dimensional space is 10, but the expected length of the midpoint of two such vectors is approximately 7.\n"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Sampling Generative Networks", "abstract": "We introduce several techniques for sampling and visualizing the latent spaces of generative models. Replacing linear interpolation with spherical linear interpolation prevents diverging from a model's prior distribution and produces sharper samples. J-Diagrams and MINE grids are introduced as visualizations of manifolds created by analogies and nearest neighbors. We demonstrate two new techniques for deriving attribute vectors: bias-corrected vectors with data replication and synthetic vectors with data augmentation.  Binary classification using attribute vectors is presented as a technique supporting quantitative analysis of the latent space. Most techniques are intended to be independent of model type and examples are shown on both Variational Autoencoders and Generative Adversarial Networks.\n", "pdf": "/pdf/33f8c62a4f32ce72c31a3c14e8bec5d26520c402.pdf", "TL;DR": "Demonstrates improved techniques for interpolation and deriving + evaluating attribute vectors in latent spaces applicable to both VAE and GAN models.", "paperhash": "white|sampling_generative_networks", "conflicts": ["vuw.ac.nz"], "authors": ["Tom White"], "authorids": ["tom.white@vuw.ac.nz"], "keywords": ["Unsupervised Learning", "Deep learning", "Computer vision"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287748940, "id": "ICLR.cc/2017/conference/-/paper52/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "SypU81Ole", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper52/reviewers", "ICLR.cc/2017/conference/paper52/areachairs"], "cdate": 1485287748940}}}, {"tddate": null, "tmdate": 1485629294698, "tcdate": 1485629294698, "number": 3, "id": "S1D_ww9we", "invitation": "ICLR.cc/2017/conference/-/paper52/official/comment", "forum": "SypU81Ole", "replyto": "r1fpydeVg", "signatures": ["ICLR.cc/2017/conference/paper52/areachair1"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/conference/paper52/areachair1"], "content": {"title": "But wouldn't linear interpolation also miss the origin?", "comment": "You say that \"I have found a dead zone where modes collapse as you approach the origin of the latent space.\"  But linearly interpolating between two random Normal vectors wouldn't get close to the origin very often, would it?  I think that that would only happen if the second random vector happened to be the negative of the first."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Sampling Generative Networks", "abstract": "We introduce several techniques for sampling and visualizing the latent spaces of generative models. Replacing linear interpolation with spherical linear interpolation prevents diverging from a model's prior distribution and produces sharper samples. J-Diagrams and MINE grids are introduced as visualizations of manifolds created by analogies and nearest neighbors. We demonstrate two new techniques for deriving attribute vectors: bias-corrected vectors with data replication and synthetic vectors with data augmentation.  Binary classification using attribute vectors is presented as a technique supporting quantitative analysis of the latent space. Most techniques are intended to be independent of model type and examples are shown on both Variational Autoencoders and Generative Adversarial Networks.\n", "pdf": "/pdf/33f8c62a4f32ce72c31a3c14e8bec5d26520c402.pdf", "TL;DR": "Demonstrates improved techniques for interpolation and deriving + evaluating attribute vectors in latent spaces applicable to both VAE and GAN models.", "paperhash": "white|sampling_generative_networks", "conflicts": ["vuw.ac.nz"], "authors": ["Tom White"], "authorids": ["tom.white@vuw.ac.nz"], "keywords": ["Unsupervised Learning", "Deep learning", "Computer vision"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287748814, "id": "ICLR.cc/2017/conference/-/paper52/official/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "reply": {"forum": "SypU81Ole", "writers": {"values-regex": "ICLR.cc/2017/conference/paper52/(AnonReviewer|areachair)[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/conference/paper52/(AnonReviewer|areachair)[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": [], "invitees": ["ICLR.cc/2017/conference/paper52/reviewers", "ICLR.cc/2017/conference/paper52/areachairs"], "cdate": 1485287748814}}}, {"tddate": null, "tmdate": 1482163763322, "tcdate": 1482163763322, "number": 3, "id": "Skj48YSNg", "invitation": "ICLR.cc/2017/conference/-/paper52/official/review", "forum": "SypU81Ole", "replyto": "SypU81Ole", "signatures": ["ICLR.cc/2017/conference/paper52/AnonReviewer1"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/conference/paper52/AnonReviewer1"], "content": {"title": "review", "rating": "5: Marginally below acceptance threshold", "review": "This paper proposes a variety of techniques for visualizing learned generative models, focussing specifically on VAE and GAN models. This paper is somewhat challenging to assess since it doesn't propose a new algorithm, model, application etc. On the one hand these techniques will be highly relevant to the generative modeling community and I think this paper deserves a wide audience. The techniques proposed are simple, well explained, and of immediate use to those working on generative models. However, I'm not sure the paper is appropriate for an ICLR conference track as it doesn't provide any greater theoretical insights into sampling generative models and there are no comparisons / quantitative evaluations of the techniques proposed. Overall, I'm very much on the fence since I think the techniques are useful and this paper should be read by those interested in generating modeling. I would be willing to increase my core if the author could present a case for why ICLR is an appropriate venue for this work.", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Sampling Generative Networks", "abstract": "We introduce several techniques for sampling and visualizing the latent spaces of generative models. Replacing linear interpolation with spherical linear interpolation prevents diverging from a model's prior distribution and produces sharper samples. J-Diagrams and MINE grids are introduced as visualizations of manifolds created by analogies and nearest neighbors. We demonstrate two new techniques for deriving attribute vectors: bias-corrected vectors with data replication and synthetic vectors with data augmentation.  Binary classification using attribute vectors is presented as a technique supporting quantitative analysis of the latent space. Most techniques are intended to be independent of model type and examples are shown on both Variational Autoencoders and Generative Adversarial Networks.\n", "pdf": "/pdf/33f8c62a4f32ce72c31a3c14e8bec5d26520c402.pdf", "TL;DR": "Demonstrates improved techniques for interpolation and deriving + evaluating attribute vectors in latent spaces applicable to both VAE and GAN models.", "paperhash": "white|sampling_generative_networks", "conflicts": ["vuw.ac.nz"], "authors": ["Tom White"], "authorids": ["tom.white@vuw.ac.nz"], "keywords": ["Unsupervised Learning", "Deep learning", "Computer vision"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1481932799000, "tmdate": 1482512714498, "id": "ICLR.cc/2017/conference/-/paper52/official/review", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/conference/paper52/reviewers"], "noninvitees": ["ICLR.cc/2017/conference/paper52/AnonReviewer4", "ICLR.cc/2017/conference/paper52/AnonReviewer3", "ICLR.cc/2017/conference/paper52/AnonReviewer1"], "reply": {"forum": "SypU81Ole", "replyto": "SypU81Ole", "writers": {"values-regex": "ICLR.cc/2017/conference/paper52/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/conference/paper52/AnonReviewer[0-9]+"}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "value-regex": "[\\S\\s]{1,20000}"}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1489708799000, "cdate": 1482512714498}}}, {"tddate": null, "tmdate": 1482047821020, "tcdate": 1482047821020, "number": 8, "id": "BJBU-p7Vl", "invitation": "ICLR.cc/2017/conference/-/paper52/public/comment", "forum": "SypU81Ole", "replyto": "HJyvnP74e", "signatures": ["~Tom_White1"], "readers": ["everyone"], "writers": ["~Tom_White1"], "content": {"title": "re: a mixture of many things", "comment": "Thanks for taking the time to review my paper. I generally agree with your assessment - the paper is a mixture of ideas that I tried to assemble into a summary and the justification for spherical interpolation is more empirically than theoretically grounded (and thus, I should probably use more or better visual examples).\n\nA couple of notes specific to your review. Slerp interpolation does not actually strictly assume that the points q1 and q2 lie on the same sphere - it can interpolate across vectors with different distances to the origin. I also agree that the original paper lacked quantitative evaluation - in an updated revision I added a quantitative assessment of the attribute vectors (Section 3.3) showing that these vectors can be the basis of binary classifiers which can be more throughly evaluated."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Sampling Generative Networks", "abstract": "We introduce several techniques for sampling and visualizing the latent spaces of generative models. Replacing linear interpolation with spherical linear interpolation prevents diverging from a model's prior distribution and produces sharper samples. J-Diagrams and MINE grids are introduced as visualizations of manifolds created by analogies and nearest neighbors. We demonstrate two new techniques for deriving attribute vectors: bias-corrected vectors with data replication and synthetic vectors with data augmentation.  Binary classification using attribute vectors is presented as a technique supporting quantitative analysis of the latent space. Most techniques are intended to be independent of model type and examples are shown on both Variational Autoencoders and Generative Adversarial Networks.\n", "pdf": "/pdf/33f8c62a4f32ce72c31a3c14e8bec5d26520c402.pdf", "TL;DR": "Demonstrates improved techniques for interpolation and deriving + evaluating attribute vectors in latent spaces applicable to both VAE and GAN models.", "paperhash": "white|sampling_generative_networks", "conflicts": ["vuw.ac.nz"], "authors": ["Tom White"], "authorids": ["tom.white@vuw.ac.nz"], "keywords": ["Unsupervised Learning", "Deep learning", "Computer vision"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287748940, "id": "ICLR.cc/2017/conference/-/paper52/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "SypU81Ole", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper52/reviewers", "ICLR.cc/2017/conference/paper52/areachairs"], "cdate": 1485287748940}}}, {"tddate": null, "tmdate": 1482032941014, "tcdate": 1482032941014, "number": 7, "id": "ByBEvYXNe", "invitation": "ICLR.cc/2017/conference/-/paper52/public/comment", "forum": "SypU81Ole", "replyto": "HJyvnP74e", "signatures": ["~Ishaan_Gulrajani1"], "readers": ["everyone"], "writers": ["~Ishaan_Gulrajani1"], "content": {"title": "Re. spherical linear interpolation", "comment": "(I also do work on decoder-based generative models, so I thought I'd offer a comment)\n\nI agree with your comment that in theory, these models should map the center of the latent space to a meaningful sample. However this paper convincingly demonstrates that this isn't the case in practice. I've also observed the same issue consistently in my models. One possible explanation for this is what while, as you note, the density of an isotropic Gaussian is highest at the center, because the volume is low there, that region is never sampled from during training and consequently the model never learns to decode that \"type\" of vector (i.e. one with a small norm). On the other hand, even though any other given similarly-sized region is also very unlikely to be sampled from even once during training, the model nonetheless learns to generalize from other \"similar\" sampled points (i.e. points which are similar along some of the axes) so that it maps that region to plausible-looking data.\n\nI think that the paper's contributions here (identifying the problem and demonstrating a good workaround for it) are substantial, regardless of whether or not it convincingly establishes an underlying cause."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Sampling Generative Networks", "abstract": "We introduce several techniques for sampling and visualizing the latent spaces of generative models. Replacing linear interpolation with spherical linear interpolation prevents diverging from a model's prior distribution and produces sharper samples. J-Diagrams and MINE grids are introduced as visualizations of manifolds created by analogies and nearest neighbors. We demonstrate two new techniques for deriving attribute vectors: bias-corrected vectors with data replication and synthetic vectors with data augmentation.  Binary classification using attribute vectors is presented as a technique supporting quantitative analysis of the latent space. Most techniques are intended to be independent of model type and examples are shown on both Variational Autoencoders and Generative Adversarial Networks.\n", "pdf": "/pdf/33f8c62a4f32ce72c31a3c14e8bec5d26520c402.pdf", "TL;DR": "Demonstrates improved techniques for interpolation and deriving + evaluating attribute vectors in latent spaces applicable to both VAE and GAN models.", "paperhash": "white|sampling_generative_networks", "conflicts": ["vuw.ac.nz"], "authors": ["Tom White"], "authorids": ["tom.white@vuw.ac.nz"], "keywords": ["Unsupervised Learning", "Deep learning", "Computer vision"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287748940, "id": "ICLR.cc/2017/conference/-/paper52/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "SypU81Ole", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper52/reviewers", "ICLR.cc/2017/conference/paper52/areachairs"], "cdate": 1485287748940}}}, {"tddate": null, "tmdate": 1482026070671, "tcdate": 1482026070671, "number": 2, "id": "HJyvnP74e", "invitation": "ICLR.cc/2017/conference/-/paper52/official/review", "forum": "SypU81Ole", "replyto": "SypU81Ole", "signatures": ["ICLR.cc/2017/conference/paper52/AnonReviewer3"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/conference/paper52/AnonReviewer3"], "content": {"title": "A mixture of many things", "rating": "5: Marginally below acceptance threshold", "review": "This paper proposed a set of different things under the name of \"sampling generative models\", focusing on analyzing the learned latent space and synthesizing desirable output images with certain properties for GANs.  This paper does not have one single clear message or idea, but rather proposed a set of techniques that seem to produce visually good looking results.  While this paper has some interesting ideas, it also has a number of problems.\n\nThe spherical interpolation idea is interesting, but after a second thought this does not make much sense.  The proposed slerp interpolation equation (page 2) implicitly assumes that the two points q1 and q2 lie on the same sphere, in which case the parameter theta is the angle corresponding to the great arc connecting the two points on the sphere.  However, the latent space of a GAN, no matter trained with a uniform distribution or a Gaussian distribution, is not a distribution on a sphere, and many points have different distances to the origin.  The author's justification for this comes from the well known fact that in high dimensional space, even with a uniform distribution most points lie on a thin shell in the unit cube.  This is true because in high-dimensional space, the outer shell takes up most of the volume in space, and the inner part takes only a very small fraction of the space, in terms of volume.  This does not mean the density of data in the outer shell is greater than the inner part, though.  In a uniform distribution, the data density should be equal everywhere, a point on the outer shell is not more likely than a point in the inner part.  Under a Gaussian model, the data density is on the other hand higher in the center and much lower on the out side.  If we have a good model of data, then sampling the most likely points from the model should give us plausible looking samples.  In this sense, spherical interpolation should do no better than the normally used linear interpolation.  From the questions and answers it seems that the author does not recognize this distinction.  The results shown in this paper seem to indicate that spherical interpolation is better visually, but it is rather hard to make any concrete conclusions from three pairs of examples.  If this is really the case then there must be something else wrong about our understanding of the learned model.\n\nAside from these, the J-diagram and the nearest neighbor latent space traversal both seems to be good ways to explore the latent space of a learned model.  The attribute vector section on transforming images to new ones with desired attributes is also interesting, and it provides a few new ways to make the GAN latent space more interpretable.\n\nOverall I feel most of the techniques proposed in this paper are nice visualization tools.  The contributions however, are mostly on the design of the visualizations, and not much on the technical and model side.  The spherical interpolation provides the only mathematical equation in the paper, yet the correctness of the technique is arguable.  For the visualization tools, there are also no quantitative evaluation, maybe these results are more art than science.", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Sampling Generative Networks", "abstract": "We introduce several techniques for sampling and visualizing the latent spaces of generative models. Replacing linear interpolation with spherical linear interpolation prevents diverging from a model's prior distribution and produces sharper samples. J-Diagrams and MINE grids are introduced as visualizations of manifolds created by analogies and nearest neighbors. We demonstrate two new techniques for deriving attribute vectors: bias-corrected vectors with data replication and synthetic vectors with data augmentation.  Binary classification using attribute vectors is presented as a technique supporting quantitative analysis of the latent space. Most techniques are intended to be independent of model type and examples are shown on both Variational Autoencoders and Generative Adversarial Networks.\n", "pdf": "/pdf/33f8c62a4f32ce72c31a3c14e8bec5d26520c402.pdf", "TL;DR": "Demonstrates improved techniques for interpolation and deriving + evaluating attribute vectors in latent spaces applicable to both VAE and GAN models.", "paperhash": "white|sampling_generative_networks", "conflicts": ["vuw.ac.nz"], "authors": ["Tom White"], "authorids": ["tom.white@vuw.ac.nz"], "keywords": ["Unsupervised Learning", "Deep learning", "Computer vision"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1481932799000, "tmdate": 1482512714498, "id": "ICLR.cc/2017/conference/-/paper52/official/review", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/conference/paper52/reviewers"], "noninvitees": ["ICLR.cc/2017/conference/paper52/AnonReviewer4", "ICLR.cc/2017/conference/paper52/AnonReviewer3", "ICLR.cc/2017/conference/paper52/AnonReviewer1"], "reply": {"forum": "SypU81Ole", "replyto": "SypU81Ole", "writers": {"values-regex": "ICLR.cc/2017/conference/paper52/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/conference/paper52/AnonReviewer[0-9]+"}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "value-regex": "[\\S\\s]{1,20000}"}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1489708799000, "cdate": 1482512714498}}}, {"tddate": null, "tmdate": 1482024427817, "tcdate": 1482024427817, "number": 1, "id": "ByVgIvXEe", "invitation": "ICLR.cc/2017/conference/-/paper52/official/review", "forum": "SypU81Ole", "replyto": "SypU81Ole", "signatures": ["ICLR.cc/2017/conference/paper52/AnonReviewer4"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/conference/paper52/AnonReviewer4"], "content": {"title": "", "rating": "6: Marginally above acceptance threshold", "review": "In this paper the authors propose various techniques to sample visualizations from generative models with high dimensional latent spaces like VAEs and GANs. For example, the authors highlight the well known but often not sufficiently appreciated fact that the probability mass of high dimensional Gaussian distributions concentrates near a thin hyper-shell with a certain radius. They therefore propose to use spherical interpolations (great arcs) instead of the commonly used linear interpolations. In a similar spirit they propose a visualisation for analogies and techniques to reinforce structure in VAE latent spaces.\n\nI find it hard to give clear recommendation for this paper: On the one hand I enjoyed reading it and I might want use some of the proposals (e.g. spherical interpolations; J-diagrams) in future work of mine. On the other hand, it\u2019s obvious that this paper is not a typical machine learning paper; it does not propose a new model, or training method, or provide (theoretical/empirical) insight and it does not have the scientific quality and depth I\u2019ve seen in many other ICLR submissions. But it does more than just describing useful \u201ctricks\u201d. And all things considered I think this paper deserves a wider audience (but  I'm not convinced that ICLR is the right venue)\n", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Sampling Generative Networks", "abstract": "We introduce several techniques for sampling and visualizing the latent spaces of generative models. Replacing linear interpolation with spherical linear interpolation prevents diverging from a model's prior distribution and produces sharper samples. J-Diagrams and MINE grids are introduced as visualizations of manifolds created by analogies and nearest neighbors. We demonstrate two new techniques for deriving attribute vectors: bias-corrected vectors with data replication and synthetic vectors with data augmentation.  Binary classification using attribute vectors is presented as a technique supporting quantitative analysis of the latent space. Most techniques are intended to be independent of model type and examples are shown on both Variational Autoencoders and Generative Adversarial Networks.\n", "pdf": "/pdf/33f8c62a4f32ce72c31a3c14e8bec5d26520c402.pdf", "TL;DR": "Demonstrates improved techniques for interpolation and deriving + evaluating attribute vectors in latent spaces applicable to both VAE and GAN models.", "paperhash": "white|sampling_generative_networks", "conflicts": ["vuw.ac.nz"], "authors": ["Tom White"], "authorids": ["tom.white@vuw.ac.nz"], "keywords": ["Unsupervised Learning", "Deep learning", "Computer vision"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1481932799000, "tmdate": 1482512714498, "id": "ICLR.cc/2017/conference/-/paper52/official/review", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/conference/paper52/reviewers"], "noninvitees": ["ICLR.cc/2017/conference/paper52/AnonReviewer4", "ICLR.cc/2017/conference/paper52/AnonReviewer3", "ICLR.cc/2017/conference/paper52/AnonReviewer1"], "reply": {"forum": "SypU81Ole", "replyto": "SypU81Ole", "writers": {"values-regex": "ICLR.cc/2017/conference/paper52/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/conference/paper52/AnonReviewer[0-9]+"}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "value-regex": "[\\S\\s]{1,20000}"}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1489708799000, "cdate": 1482512714498}}}, {"tddate": null, "tmdate": 1481963066921, "tcdate": 1481963066921, "number": 6, "id": "HJmH8dM4x", "invitation": "ICLR.cc/2017/conference/-/paper52/public/comment", "forum": "SypU81Ole", "replyto": "HJz_280ee", "signatures": ["~Tom_White1"], "readers": ["everyone"], "writers": ["~Tom_White1"], "content": {"title": "Re: ICLR Paper Format", "comment": "Thanks Tara for your comment. My more recent revision is in ICLR 2017 format."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Sampling Generative Networks", "abstract": "We introduce several techniques for sampling and visualizing the latent spaces of generative models. Replacing linear interpolation with spherical linear interpolation prevents diverging from a model's prior distribution and produces sharper samples. J-Diagrams and MINE grids are introduced as visualizations of manifolds created by analogies and nearest neighbors. We demonstrate two new techniques for deriving attribute vectors: bias-corrected vectors with data replication and synthetic vectors with data augmentation.  Binary classification using attribute vectors is presented as a technique supporting quantitative analysis of the latent space. Most techniques are intended to be independent of model type and examples are shown on both Variational Autoencoders and Generative Adversarial Networks.\n", "pdf": "/pdf/33f8c62a4f32ce72c31a3c14e8bec5d26520c402.pdf", "TL;DR": "Demonstrates improved techniques for interpolation and deriving + evaluating attribute vectors in latent spaces applicable to both VAE and GAN models.", "paperhash": "white|sampling_generative_networks", "conflicts": ["vuw.ac.nz"], "authors": ["Tom White"], "authorids": ["tom.white@vuw.ac.nz"], "keywords": ["Unsupervised Learning", "Deep learning", "Computer vision"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287748940, "id": "ICLR.cc/2017/conference/-/paper52/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "SypU81Ole", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper52/reviewers", "ICLR.cc/2017/conference/paper52/areachairs"], "cdate": 1485287748940}}}, {"tddate": null, "tmdate": 1481830330110, "tcdate": 1481830330105, "number": 5, "id": "r1fpydeVg", "invitation": "ICLR.cc/2017/conference/-/paper52/public/comment", "forum": "SypU81Ole", "replyto": "ByX8EiA7l", "signatures": ["~Tom_White1"], "readers": ["everyone"], "writers": ["~Tom_White1"], "content": {"title": "re: spherical interpolation with uniform prior, follow up", "comment": "Thanks for your comment. It is possible I am using terminology inconsistently and I would be interested if others also concur with your distinction. Let me instead try to explain this motivation within the context of a Generative Adversarial Network with a uniform prior, since in practice this is where this issue comes up. If my reasoning is flawed here, I am of course very grateful to learn this.\n\nThe GAN generator uses vectors from this distribution during training to generate samples. So at train time the generator is optimized to generate samples based on a region within this thin shell around a hypersphere. If we later try to sample from a point halfway between two such points, we are effectively asking the generator to generate a sample from a vector drawn from a set which is effectively disjoint from the distribution of vectors it was trained on. This seems inconsistent, and in practice I have found a dead zone where modes collapse as you approach the origin of the latent space.\n"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Sampling Generative Networks", "abstract": "We introduce several techniques for sampling and visualizing the latent spaces of generative models. Replacing linear interpolation with spherical linear interpolation prevents diverging from a model's prior distribution and produces sharper samples. J-Diagrams and MINE grids are introduced as visualizations of manifolds created by analogies and nearest neighbors. We demonstrate two new techniques for deriving attribute vectors: bias-corrected vectors with data replication and synthetic vectors with data augmentation.  Binary classification using attribute vectors is presented as a technique supporting quantitative analysis of the latent space. Most techniques are intended to be independent of model type and examples are shown on both Variational Autoencoders and Generative Adversarial Networks.\n", "pdf": "/pdf/33f8c62a4f32ce72c31a3c14e8bec5d26520c402.pdf", "TL;DR": "Demonstrates improved techniques for interpolation and deriving + evaluating attribute vectors in latent spaces applicable to both VAE and GAN models.", "paperhash": "white|sampling_generative_networks", "conflicts": ["vuw.ac.nz"], "authors": ["Tom White"], "authorids": ["tom.white@vuw.ac.nz"], "keywords": ["Unsupervised Learning", "Deep learning", "Computer vision"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287748940, "id": "ICLR.cc/2017/conference/-/paper52/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "SypU81Ole", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper52/reviewers", "ICLR.cc/2017/conference/paper52/areachairs"], "cdate": 1485287748940}}}, {"tddate": null, "tmdate": 1481712715016, "tcdate": 1481712715010, "number": 2, "id": "ByX8EiA7l", "invitation": "ICLR.cc/2017/conference/-/paper52/official/comment", "forum": "SypU81Ole", "replyto": "r1VS31C7x", "signatures": ["ICLR.cc/2017/conference/paper52/AnonReviewer3"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/conference/paper52/AnonReviewer3"], "content": {"title": "spherical interpolation with uniform prior, follow up", "comment": "I think the author is confusing two things: quantity and density.  It is true that in the high dimensional space, even with a uniform distribution most of the data points will lie on a thin shell in the unit cube, that is about the quantity of data - most of the data points are in this thin shell as it takes up most of the volume in the space.  But that does not mean the thin shell has higher data density - it is a uniform distribution after all, so the density in space should be the same everywhere.  Based on this it does not make much sense to use spherical interpolation for uniform distributions."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Sampling Generative Networks", "abstract": "We introduce several techniques for sampling and visualizing the latent spaces of generative models. Replacing linear interpolation with spherical linear interpolation prevents diverging from a model's prior distribution and produces sharper samples. J-Diagrams and MINE grids are introduced as visualizations of manifolds created by analogies and nearest neighbors. We demonstrate two new techniques for deriving attribute vectors: bias-corrected vectors with data replication and synthetic vectors with data augmentation.  Binary classification using attribute vectors is presented as a technique supporting quantitative analysis of the latent space. Most techniques are intended to be independent of model type and examples are shown on both Variational Autoencoders and Generative Adversarial Networks.\n", "pdf": "/pdf/33f8c62a4f32ce72c31a3c14e8bec5d26520c402.pdf", "TL;DR": "Demonstrates improved techniques for interpolation and deriving + evaluating attribute vectors in latent spaces applicable to both VAE and GAN models.", "paperhash": "white|sampling_generative_networks", "conflicts": ["vuw.ac.nz"], "authors": ["Tom White"], "authorids": ["tom.white@vuw.ac.nz"], "keywords": ["Unsupervised Learning", "Deep learning", "Computer vision"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287748814, "id": "ICLR.cc/2017/conference/-/paper52/official/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "reply": {"forum": "SypU81Ole", "writers": {"values-regex": "ICLR.cc/2017/conference/paper52/(AnonReviewer|areachair)[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/conference/paper52/(AnonReviewer|areachair)[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": [], "invitees": ["ICLR.cc/2017/conference/paper52/reviewers", "ICLR.cc/2017/conference/paper52/areachairs"], "cdate": 1485287748814}}}, {"tddate": null, "tmdate": 1481709836629, "tcdate": 1481709836624, "number": 4, "id": "H1Bft90ml", "invitation": "ICLR.cc/2017/conference/-/paper52/public/comment", "forum": "SypU81Ole", "replyto": "BkP_hHhQe", "signatures": ["~Tom_White1"], "readers": ["everyone"], "writers": ["~Tom_White1"], "content": {"title": "Re: Shallow-shell assumption for the approx. posterior", "comment": "Thanks for your comment. This is an interesting experiment that I had not previously considered."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Sampling Generative Networks", "abstract": "We introduce several techniques for sampling and visualizing the latent spaces of generative models. Replacing linear interpolation with spherical linear interpolation prevents diverging from a model's prior distribution and produces sharper samples. J-Diagrams and MINE grids are introduced as visualizations of manifolds created by analogies and nearest neighbors. We demonstrate two new techniques for deriving attribute vectors: bias-corrected vectors with data replication and synthetic vectors with data augmentation.  Binary classification using attribute vectors is presented as a technique supporting quantitative analysis of the latent space. Most techniques are intended to be independent of model type and examples are shown on both Variational Autoencoders and Generative Adversarial Networks.\n", "pdf": "/pdf/33f8c62a4f32ce72c31a3c14e8bec5d26520c402.pdf", "TL;DR": "Demonstrates improved techniques for interpolation and deriving + evaluating attribute vectors in latent spaces applicable to both VAE and GAN models.", "paperhash": "white|sampling_generative_networks", "conflicts": ["vuw.ac.nz"], "authors": ["Tom White"], "authorids": ["tom.white@vuw.ac.nz"], "keywords": ["Unsupervised Learning", "Deep learning", "Computer vision"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287748940, "id": "ICLR.cc/2017/conference/-/paper52/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "SypU81Ole", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper52/reviewers", "ICLR.cc/2017/conference/paper52/areachairs"], "cdate": 1485287748940}}}, {"tddate": null, "tmdate": 1481709134929, "tcdate": 1481709021768, "number": 3, "id": "BJ8yIcAXe", "invitation": "ICLR.cc/2017/conference/-/paper52/public/comment", "forum": "SypU81Ole", "replyto": "r1VS31C7x", "signatures": ["~Tom_White1"], "readers": ["everyone"], "writers": ["~Tom_White1"], "content": {"title": "spherical interpolation with uniform prior", "comment": "Because in high dimensional space uniform random vectors will have roughly the same magnitude.\n\n>>> import numpy as np\n>>> random_points = np.random.uniform(low=-1, high=1, size=(1000,100))\n>>> lengths = map(np.linalg.norm, random_points)\n>>> print(\"Mean length is {:3.2f} and std is {:3.2f}\".format(np.mean(lengths), np.std(lengths)))\nMean length is 5.76 and std is 0.26\n\nThe central limit theorem says this magnitude will converge toward a normal distribution as you increase the dimensionality of the vector."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Sampling Generative Networks", "abstract": "We introduce several techniques for sampling and visualizing the latent spaces of generative models. Replacing linear interpolation with spherical linear interpolation prevents diverging from a model's prior distribution and produces sharper samples. J-Diagrams and MINE grids are introduced as visualizations of manifolds created by analogies and nearest neighbors. We demonstrate two new techniques for deriving attribute vectors: bias-corrected vectors with data replication and synthetic vectors with data augmentation.  Binary classification using attribute vectors is presented as a technique supporting quantitative analysis of the latent space. Most techniques are intended to be independent of model type and examples are shown on both Variational Autoencoders and Generative Adversarial Networks.\n", "pdf": "/pdf/33f8c62a4f32ce72c31a3c14e8bec5d26520c402.pdf", "TL;DR": "Demonstrates improved techniques for interpolation and deriving + evaluating attribute vectors in latent spaces applicable to both VAE and GAN models.", "paperhash": "white|sampling_generative_networks", "conflicts": ["vuw.ac.nz"], "authors": ["Tom White"], "authorids": ["tom.white@vuw.ac.nz"], "keywords": ["Unsupervised Learning", "Deep learning", "Computer vision"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287748940, "id": "ICLR.cc/2017/conference/-/paper52/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "SypU81Ole", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper52/reviewers", "ICLR.cc/2017/conference/paper52/areachairs"], "cdate": 1485287748940}}}, {"tddate": null, "tmdate": 1481665595988, "tcdate": 1481665595981, "number": 1, "id": "r1VS31C7x", "invitation": "ICLR.cc/2017/conference/-/paper52/official/comment", "forum": "SypU81Ole", "replyto": "SypU81Ole", "signatures": ["ICLR.cc/2017/conference/paper52/AnonReviewer1"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/conference/paper52/AnonReviewer1"], "content": {"title": "pre-review question", "comment": "Could you please explain why the spherical interpolation is better when the prior is uniform?"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Sampling Generative Networks", "abstract": "We introduce several techniques for sampling and visualizing the latent spaces of generative models. Replacing linear interpolation with spherical linear interpolation prevents diverging from a model's prior distribution and produces sharper samples. J-Diagrams and MINE grids are introduced as visualizations of manifolds created by analogies and nearest neighbors. We demonstrate two new techniques for deriving attribute vectors: bias-corrected vectors with data replication and synthetic vectors with data augmentation.  Binary classification using attribute vectors is presented as a technique supporting quantitative analysis of the latent space. Most techniques are intended to be independent of model type and examples are shown on both Variational Autoencoders and Generative Adversarial Networks.\n", "pdf": "/pdf/33f8c62a4f32ce72c31a3c14e8bec5d26520c402.pdf", "TL;DR": "Demonstrates improved techniques for interpolation and deriving + evaluating attribute vectors in latent spaces applicable to both VAE and GAN models.", "paperhash": "white|sampling_generative_networks", "conflicts": ["vuw.ac.nz"], "authors": ["Tom White"], "authorids": ["tom.white@vuw.ac.nz"], "keywords": ["Unsupervised Learning", "Deep learning", "Computer vision"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287748814, "id": "ICLR.cc/2017/conference/-/paper52/official/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "reply": {"forum": "SypU81Ole", "writers": {"values-regex": "ICLR.cc/2017/conference/paper52/(AnonReviewer|areachair)[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/conference/paper52/(AnonReviewer|areachair)[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": [], "invitees": ["ICLR.cc/2017/conference/paper52/reviewers", "ICLR.cc/2017/conference/paper52/areachairs"], "cdate": 1485287748814}}}, {"tddate": null, "tmdate": 1481559150754, "tcdate": 1481559150748, "number": 2, "id": "BkP_hHhQe", "invitation": "ICLR.cc/2017/conference/-/paper52/pre-review/question", "forum": "SypU81Ole", "replyto": "SypU81Ole", "signatures": ["ICLR.cc/2017/conference/paper52/AnonReviewer4"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/conference/paper52/AnonReviewer4"], "content": {"title": "Shallow-shell assumption for the approx. posterior", "question": "I (obviously) agree that we expect a majority of the probability mass to be concentrated near a shallow shell in the high dimensional latent space and that this fact merits discussion because it is often overlooked and not taken into consideration.\n\nBut did you actually test whether this assumption indeed holds for the (average) approximate posterior q(h|x), and not just for the prior p(h)? This could otherwise indicate an interesting mismatch between the prior and the model. A simple histogram over the L2 norms of samples from the approx. posterior might be sufficient here."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Sampling Generative Networks", "abstract": "We introduce several techniques for sampling and visualizing the latent spaces of generative models. Replacing linear interpolation with spherical linear interpolation prevents diverging from a model's prior distribution and produces sharper samples. J-Diagrams and MINE grids are introduced as visualizations of manifolds created by analogies and nearest neighbors. We demonstrate two new techniques for deriving attribute vectors: bias-corrected vectors with data replication and synthetic vectors with data augmentation.  Binary classification using attribute vectors is presented as a technique supporting quantitative analysis of the latent space. Most techniques are intended to be independent of model type and examples are shown on both Variational Autoencoders and Generative Adversarial Networks.\n", "pdf": "/pdf/33f8c62a4f32ce72c31a3c14e8bec5d26520c402.pdf", "TL;DR": "Demonstrates improved techniques for interpolation and deriving + evaluating attribute vectors in latent spaces applicable to both VAE and GAN models.", "paperhash": "white|sampling_generative_networks", "conflicts": ["vuw.ac.nz"], "authors": ["Tom White"], "authorids": ["tom.white@vuw.ac.nz"], "keywords": ["Unsupervised Learning", "Deep learning", "Computer vision"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1480741199000, "tmdate": 1481559151317, "id": "ICLR.cc/2017/conference/-/paper52/pre-review/question", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/conference/paper52/reviewers"], "noninvitees": ["ICLR.cc/2017/conference/paper52/AnonReviewer3", "ICLR.cc/2017/conference/paper52/AnonReviewer4"], "reply": {"forum": "SypU81Ole", "replyto": "SypU81Ole", "writers": {"values-regex": "ICLR.cc/2017/conference/paper52/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/conference/paper52/AnonReviewer[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your question.", "value-regex": ".{1,500}"}, "question": {"order": 2, "description": "Your question", "value-regex": "[\\S\\s]{1,5000}"}}}, "nonreaders": [], "expdate": 1488517199000, "cdate": 1481559151317}}}, {"tddate": null, "replyto": null, "ddate": null, "tmdate": 1481309648504, "tcdate": 1478125141036, "number": 52, "id": "SypU81Ole", "invitation": "ICLR.cc/2017/conference/-/submission", "forum": "SypU81Ole", "signatures": ["~Tom_White1"], "readers": ["everyone"], "content": {"title": "Sampling Generative Networks", "abstract": "We introduce several techniques for sampling and visualizing the latent spaces of generative models. Replacing linear interpolation with spherical linear interpolation prevents diverging from a model's prior distribution and produces sharper samples. J-Diagrams and MINE grids are introduced as visualizations of manifolds created by analogies and nearest neighbors. We demonstrate two new techniques for deriving attribute vectors: bias-corrected vectors with data replication and synthetic vectors with data augmentation.  Binary classification using attribute vectors is presented as a technique supporting quantitative analysis of the latent space. Most techniques are intended to be independent of model type and examples are shown on both Variational Autoencoders and Generative Adversarial Networks.\n", "pdf": "/pdf/33f8c62a4f32ce72c31a3c14e8bec5d26520c402.pdf", "TL;DR": "Demonstrates improved techniques for interpolation and deriving + evaluating attribute vectors in latent spaces applicable to both VAE and GAN models.", "paperhash": "white|sampling_generative_networks", "conflicts": ["vuw.ac.nz"], "authors": ["Tom White"], "authorids": ["tom.white@vuw.ac.nz"], "keywords": ["Unsupervised Learning", "Deep learning", "Computer vision"]}, "writers": [], "nonreaders": [], "details": {"replyCount": 19, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1475686800000, "tmdate": 1478287705855, "id": "ICLR.cc/2017/conference/-/submission", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/pcs"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": null, "replyto": null, "writers": {"values-regex": "~.*"}, "signatures": {"values-regex": "~.*", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"pdf": {"required": true, "order": 5, "description": "Either upload a PDF file or provide a direct link to your PDF on ArXiv (link must begin with http(s) and end with .pdf)", "value-regex": "upload|(http|https):\\/\\/.+\\.pdf"}, "title": {"required": true, "order": 1, "description": "Title of paper.", "value-regex": ".{1,250}"}, "abstract": {"required": true, "order": 4, "description": "Abstract of paper.", "value-regex": "[\\S\\s]{1,5000}"}, "authors": {"required": true, "order": 2, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of author names, as they appear in the paper."}, "conflicts": {"required": true, "order": 100, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of email domains of people who would have a conflict of interest in reviewing this paper, (e.g., cs.umass.edu;google.com, etc.)."}, "keywords": {"order": 6, "description": "Comma separated list of keywords.", "values-dropdown": ["Theory", "Computer vision", "Speech", "Natural language processing", "Deep learning", "Unsupervised Learning", "Supervised Learning", "Semi-Supervised Learning", "Reinforcement Learning", "Transfer Learning", "Multi-modal learning", "Applications", "Optimization", "Structured prediction", "Games"]}, "TL;DR": {"required": false, "order": 3, "description": "\"Too Long; Didn't Read\": a short sentence describing your paper", "value-regex": "[^\\n]{0,250}"}, "authorids": {"required": true, "order": 3, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of author email addresses, in the same order as above."}}}, "nonreaders": [], "noninvitees": [], "expdate": 1483462800000, "cdate": 1478287705855}}}, {"tddate": null, "tmdate": 1481309384201, "tcdate": 1481309384193, "number": 2, "id": "r1lChdd7x", "invitation": "ICLR.cc/2017/conference/-/paper52/public/comment", "forum": "SypU81Ole", "replyto": "BkzKKYB7l", "signatures": ["~Tom_White1"], "readers": ["everyone"], "writers": ["~Tom_White1"], "content": {"title": "formatting and interpolation", "comment": "Thanks for your comment on format - the pdf is now in ICLR_2017 format.\n\nYes, in practice all random vectors in high dimensions with a gaussian or uniform prior lie very near a hyphersphere. This is non-intuitive but valid assumption for uniform distributions, which is why it merits discussion. Theta is the angle between the two vectors two be interpolated. Here is python function that implements slerp.\n\n# val ranges from [0,1]. interpolates from low to high.\ndef slerp(val, low, high):\n    theta = numpy.arccos(numpy.dot(low/numpy.linalg.norm(low), high/numpy.linalg.norm(high)))\n    so = numpy.sin(theta)\n    return numpy.sin((1.0-val)*omega) / so * low + numpy.sin(val*omega)/so * high\n\nNote that both the formula in the paper and this implementation handle elevation changes and so don't strictly assume that the initial points lie on the same hypersphere."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Sampling Generative Networks", "abstract": "We introduce several techniques for sampling and visualizing the latent spaces of generative models. Replacing linear interpolation with spherical linear interpolation prevents diverging from a model's prior distribution and produces sharper samples. J-Diagrams and MINE grids are introduced as visualizations of manifolds created by analogies and nearest neighbors. We demonstrate two new techniques for deriving attribute vectors: bias-corrected vectors with data replication and synthetic vectors with data augmentation.  Binary classification using attribute vectors is presented as a technique supporting quantitative analysis of the latent space. Most techniques are intended to be independent of model type and examples are shown on both Variational Autoencoders and Generative Adversarial Networks.\n", "pdf": "/pdf/33f8c62a4f32ce72c31a3c14e8bec5d26520c402.pdf", "TL;DR": "Demonstrates improved techniques for interpolation and deriving + evaluating attribute vectors in latent spaces applicable to both VAE and GAN models.", "paperhash": "white|sampling_generative_networks", "conflicts": ["vuw.ac.nz"], "authors": ["Tom White"], "authorids": ["tom.white@vuw.ac.nz"], "keywords": ["Unsupervised Learning", "Deep learning", "Computer vision"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287748940, "id": "ICLR.cc/2017/conference/-/paper52/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "SypU81Ole", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper52/reviewers", "ICLR.cc/2017/conference/paper52/areachairs"], "cdate": 1485287748940}}}, {"tddate": null, "tmdate": 1481116026229, "tcdate": 1481116026225, "number": 1, "id": "BkzKKYB7l", "invitation": "ICLR.cc/2017/conference/-/paper52/pre-review/question", "forum": "SypU81Ole", "replyto": "SypU81Ole", "signatures": ["ICLR.cc/2017/conference/paper52/AnonReviewer3"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/conference/paper52/AnonReviewer3"], "content": {"title": "formatting and others", "question": "The format of this paper is not ICLR format.\n\nThe spherical interpolation makes an implicit assumption that all data points lie on a sphere, which maybe a better assumption than linear space for Gaussian distributed data but not for uniform distributions.  Also the theta parameter in spherical interpolation looks arbitrary, I wonder how is it chosen?"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Sampling Generative Networks", "abstract": "We introduce several techniques for sampling and visualizing the latent spaces of generative models. Replacing linear interpolation with spherical linear interpolation prevents diverging from a model's prior distribution and produces sharper samples. J-Diagrams and MINE grids are introduced as visualizations of manifolds created by analogies and nearest neighbors. We demonstrate two new techniques for deriving attribute vectors: bias-corrected vectors with data replication and synthetic vectors with data augmentation.  Binary classification using attribute vectors is presented as a technique supporting quantitative analysis of the latent space. Most techniques are intended to be independent of model type and examples are shown on both Variational Autoencoders and Generative Adversarial Networks.\n", "pdf": "/pdf/33f8c62a4f32ce72c31a3c14e8bec5d26520c402.pdf", "TL;DR": "Demonstrates improved techniques for interpolation and deriving + evaluating attribute vectors in latent spaces applicable to both VAE and GAN models.", "paperhash": "white|sampling_generative_networks", "conflicts": ["vuw.ac.nz"], "authors": ["Tom White"], "authorids": ["tom.white@vuw.ac.nz"], "keywords": ["Unsupervised Learning", "Deep learning", "Computer vision"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1480741199000, "tmdate": 1481559151317, "id": "ICLR.cc/2017/conference/-/paper52/pre-review/question", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/conference/paper52/reviewers"], "noninvitees": ["ICLR.cc/2017/conference/paper52/AnonReviewer3", "ICLR.cc/2017/conference/paper52/AnonReviewer4"], "reply": {"forum": "SypU81Ole", "replyto": "SypU81Ole", "writers": {"values-regex": "ICLR.cc/2017/conference/paper52/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/conference/paper52/AnonReviewer[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your question.", "value-regex": ".{1,500}"}, "question": {"order": 2, "description": "Your question", "value-regex": "[\\S\\s]{1,5000}"}}}, "nonreaders": [], "expdate": 1488517199000, "cdate": 1481559151317}}}, {"tddate": null, "tmdate": 1478554555678, "tcdate": 1478548586324, "number": 1, "id": "HJz_280ee", "invitation": "ICLR.cc/2017/conference/-/paper52/public/comment", "forum": "SypU81Ole", "replyto": "SypU81Ole", "signatures": ["~Tara_N_Sainath1"], "readers": ["everyone"], "writers": ["~Tara_N_Sainath1"], "content": {"title": "ICLR Paper Format", "comment": "Dear Authors,\n\nPlease resubmit your paper in the ICLR 2017 format for your submissions to be considered. Thank you!"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Sampling Generative Networks", "abstract": "We introduce several techniques for sampling and visualizing the latent spaces of generative models. Replacing linear interpolation with spherical linear interpolation prevents diverging from a model's prior distribution and produces sharper samples. J-Diagrams and MINE grids are introduced as visualizations of manifolds created by analogies and nearest neighbors. We demonstrate two new techniques for deriving attribute vectors: bias-corrected vectors with data replication and synthetic vectors with data augmentation.  Binary classification using attribute vectors is presented as a technique supporting quantitative analysis of the latent space. Most techniques are intended to be independent of model type and examples are shown on both Variational Autoencoders and Generative Adversarial Networks.\n", "pdf": "/pdf/33f8c62a4f32ce72c31a3c14e8bec5d26520c402.pdf", "TL;DR": "Demonstrates improved techniques for interpolation and deriving + evaluating attribute vectors in latent spaces applicable to both VAE and GAN models.", "paperhash": "white|sampling_generative_networks", "conflicts": ["vuw.ac.nz"], "authors": ["Tom White"], "authorids": ["tom.white@vuw.ac.nz"], "keywords": ["Unsupervised Learning", "Deep learning", "Computer vision"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287748940, "id": "ICLR.cc/2017/conference/-/paper52/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "SypU81Ole", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper52/reviewers", "ICLR.cc/2017/conference/paper52/areachairs"], "cdate": 1485287748940}}}], "count": 20}