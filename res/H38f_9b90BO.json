{"notes": [{"id": "H38f_9b90BO", "original": "lc6M716i2ib", "number": 317, "cdate": 1601308043103, "ddate": null, "tcdate": 1601308043103, "tmdate": 1614985664197, "tddate": null, "forum": "H38f_9b90BO", "replyto": null, "invitation": "ICLR.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Towards Robust Graph Neural Networks against Label Noise", "authorids": ["~Jun_Xia1", "~Haitao_Lin2", "~Yongjie_Xu1", "~Lirong_Wu1", "~Zhangyang_Gao1", "~Siyuan_Li6", "~Stan_Z._Li2"], "authors": ["Jun Xia", "Haitao Lin", "Yongjie Xu", "Lirong Wu", "Zhangyang Gao", "Siyuan Li", "Stan Z. Li"], "keywords": ["Graph Neural Networks", "Graph Node Classification", "Label Noise"], "abstract": "Massive labeled data have been used in training deep neural networks, thus label noise has become an important issue therein.  Although learning with noisy labels has made great progress on image datasets in recent years, it has not yet been studied in connection with utilizing GNNs to classify graph nodes. In this paper, we proposed a method, named LPM,  to address the problem using Label Propagation (LP) and Meta learning.  Different from previous methods designed for image datasets, our method is based on a special attribute (label smoothness) of graph-structured data, i.e., neighboring nodes in a graph tend to have the same label.  A pseudo label is computed from the neighboring labels for each node in the training set using LP; meta learning is utilized to learn a proper aggregation of the original and pseudo label as the final label.  Experimental results demonstrate that LPM outperforms state-of-the-art methods in graph node classification task with both synthetic and real-world label noise. Source code to reproduce all results will be released.", "one-sentence_summary": "To the best of our knowledge, we are the first to focus on the label noise existing in utilizing GNNs to classify graph nodes.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "xia|towards_robust_graph_neural_networks_against_label_noise", "supplementary_material": "/attachment/a5c59bad1a3c6aef2da8f19b4e7498938c51714a.zip", "pdf": "/pdf/0f5774c96a06ab9bc0c9353ff3f2a59b2ef885ae.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=UW4yOOs9Yw", "_bibtex": "@misc{\nxia2021towards,\ntitle={Towards Robust Graph Neural Networks against Label Noise},\nauthor={Jun Xia and Haitao Lin and Yongjie Xu and Lirong Wu and Zhangyang Gao and Siyuan Li and Stan Z. Li},\nyear={2021},\nurl={https://openreview.net/forum?id=H38f_9b90BO}\n}"}, "signatures": ["ICLR.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference"], "details": {"replyCount": 12, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"reply": {"readers": {"values-regex": ".*"}, "writers": {"values": ["ICLR.cc/2021/Conference"]}, "signatures": {"values": ["ICLR.cc/2021/Conference"]}, "content": {"authors": {"values": ["Anonymous"]}, "authorids": {"values-regex": ".*"}, "reviewed_version_(pdf)": {"required": false, "description": "Upload a PDF file that ends with .pdf", "value-regex": ".*"}}}, "signatures": ["ICLR.cc/2021/Conference"], "readers": ["everyone"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["~", "OpenReview.net/Support"], "tcdate": 1601308008205, "tmdate": 1614984599368, "id": "ICLR.cc/2021/Conference/-/Blind_Submission"}}, "tauthor": "OpenReview.net"}, {"id": "Ts1YNQbwkDw", "original": null, "number": 2, "cdate": 1612660480770, "ddate": null, "tcdate": 1612660480770, "tmdate": 1612660480770, "tddate": null, "forum": "H38f_9b90BO", "replyto": "ZmvcDyLjDtX", "invitation": "ICLR.cc/2021/Conference/Paper317/-/Comment", "content": {"title": "Response to the decision", "comment": "Thank you for your insightful and to-the-point comments and we will further improve this work."}, "signatures": ["~Jun_Xia1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "~Jun_Xia1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Towards Robust Graph Neural Networks against Label Noise", "authorids": ["~Jun_Xia1", "~Haitao_Lin2", "~Yongjie_Xu1", "~Lirong_Wu1", "~Zhangyang_Gao1", "~Siyuan_Li6", "~Stan_Z._Li2"], "authors": ["Jun Xia", "Haitao Lin", "Yongjie Xu", "Lirong Wu", "Zhangyang Gao", "Siyuan Li", "Stan Z. Li"], "keywords": ["Graph Neural Networks", "Graph Node Classification", "Label Noise"], "abstract": "Massive labeled data have been used in training deep neural networks, thus label noise has become an important issue therein.  Although learning with noisy labels has made great progress on image datasets in recent years, it has not yet been studied in connection with utilizing GNNs to classify graph nodes. In this paper, we proposed a method, named LPM,  to address the problem using Label Propagation (LP) and Meta learning.  Different from previous methods designed for image datasets, our method is based on a special attribute (label smoothness) of graph-structured data, i.e., neighboring nodes in a graph tend to have the same label.  A pseudo label is computed from the neighboring labels for each node in the training set using LP; meta learning is utilized to learn a proper aggregation of the original and pseudo label as the final label.  Experimental results demonstrate that LPM outperforms state-of-the-art methods in graph node classification task with both synthetic and real-world label noise. Source code to reproduce all results will be released.", "one-sentence_summary": "To the best of our knowledge, we are the first to focus on the label noise existing in utilizing GNNs to classify graph nodes.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "xia|towards_robust_graph_neural_networks_against_label_noise", "supplementary_material": "/attachment/a5c59bad1a3c6aef2da8f19b4e7498938c51714a.zip", "pdf": "/pdf/0f5774c96a06ab9bc0c9353ff3f2a59b2ef885ae.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=UW4yOOs9Yw", "_bibtex": "@misc{\nxia2021towards,\ntitle={Towards Robust Graph Neural Networks against Label Noise},\nauthor={Jun Xia and Haitao Lin and Yongjie Xu and Lirong Wu and Zhangyang Gao and Siyuan Li and Stan Z. Li},\nyear={2021},\nurl={https://openreview.net/forum?id=H38f_9b90BO}\n}"}, "tags": [], "invitation": {"reply": {"forum": "H38f_9b90BO", "readers": {"values": ["everyone"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "~.*|ICLR.cc/2021/Conference/Paper317/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper317/Authors|ICLR.cc/2021/Conference/Paper317/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs"}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}}, "multiReply": true, "signatures": ["ICLR.cc/2021/Conference"], "readers": ["everyone"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["everyone"], "tcdate": 1610649465997, "tmdate": 1610649465997, "id": "ICLR.cc/2021/Conference/Paper317/-/Comment"}}}, {"id": "ZmvcDyLjDtX", "original": null, "number": 1, "cdate": 1610040497057, "ddate": null, "tcdate": 1610040497057, "tmdate": 1610474103472, "tddate": null, "forum": "H38f_9b90BO", "replyto": "H38f_9b90BO", "invitation": "ICLR.cc/2021/Conference/Paper317/-/Decision", "content": {"title": "Final Decision", "decision": "Reject", "comment": "We thank the authors for their detailed answers and for providing an updated version of the paper addressing several of the issues raised by the reviewers, including new experimental results.\n\nThe paper is technically correct. The comparison with other methods is thorough and includes ablation studies clarifying the contributions of different aspects of the proposed method. One aspect that has been moderately addressed in the new version is the comparison between the \"learned lambda\" of the paper with a \"tuned lambda\" suggested by a reviewer. The authors added results where lambda is set to a particular value, however it would be more interesting relevant to consider a real \"tuned lambda\", i.e., a scalar parameter, shared by all vertices, that is optimized during training; the goal being to clarifying the benefit (if any) of parameterizing lambda as a function of the node, as opposed to a value shared by all nodes.\n\nThe paper is clearly written, particularly the revised version.\n\nThe novelty is the weakest aspect of the paper. While the specific problem of learning with noisy labels with GCNN may be new, the field of learning with noisy labels in general, and of using label propagation from clean labels to guide the prediction of uncertain labels, has been proposed before, and mentioned in the reviews. The specific instantiation of this idea to the GCNN framework is novel.\n\nThe significance of the work is rather positive. The revised version contains results on two real-world datasets, where the proposed method outperforms several existing ones. As mentioned by a reviewer, this paper may inspire other researchers to explore in more depth the specific problems of learning with noise on graphs with GCNN, and to exploit the knowledge of a limited set of clean labels which may have practical importance to reduce human annotation efforts.\n\nIn summary, the paper proposes a novel model and demonstrates its potential to address a possibly important problem.\nAlthough the reviewers did not update their reviews, the authors' responses and updated version correctly addresses several of the initial concerns. The limited conceptual novelty compared to existing work did however not convince us to recommend acceptance, given the high selectivity of the conference."}, "signatures": ["ICLR.cc/2021/Conference/Program_Chairs"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference/Program_Chairs"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Towards Robust Graph Neural Networks against Label Noise", "authorids": ["~Jun_Xia1", "~Haitao_Lin2", "~Yongjie_Xu1", "~Lirong_Wu1", "~Zhangyang_Gao1", "~Siyuan_Li6", "~Stan_Z._Li2"], "authors": ["Jun Xia", "Haitao Lin", "Yongjie Xu", "Lirong Wu", "Zhangyang Gao", "Siyuan Li", "Stan Z. Li"], "keywords": ["Graph Neural Networks", "Graph Node Classification", "Label Noise"], "abstract": "Massive labeled data have been used in training deep neural networks, thus label noise has become an important issue therein.  Although learning with noisy labels has made great progress on image datasets in recent years, it has not yet been studied in connection with utilizing GNNs to classify graph nodes. In this paper, we proposed a method, named LPM,  to address the problem using Label Propagation (LP) and Meta learning.  Different from previous methods designed for image datasets, our method is based on a special attribute (label smoothness) of graph-structured data, i.e., neighboring nodes in a graph tend to have the same label.  A pseudo label is computed from the neighboring labels for each node in the training set using LP; meta learning is utilized to learn a proper aggregation of the original and pseudo label as the final label.  Experimental results demonstrate that LPM outperforms state-of-the-art methods in graph node classification task with both synthetic and real-world label noise. Source code to reproduce all results will be released.", "one-sentence_summary": "To the best of our knowledge, we are the first to focus on the label noise existing in utilizing GNNs to classify graph nodes.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "xia|towards_robust_graph_neural_networks_against_label_noise", "supplementary_material": "/attachment/a5c59bad1a3c6aef2da8f19b4e7498938c51714a.zip", "pdf": "/pdf/0f5774c96a06ab9bc0c9353ff3f2a59b2ef885ae.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=UW4yOOs9Yw", "_bibtex": "@misc{\nxia2021towards,\ntitle={Towards Robust Graph Neural Networks against Label Noise},\nauthor={Jun Xia and Haitao Lin and Yongjie Xu and Lirong Wu and Zhangyang Gao and Siyuan Li and Stan Z. Li},\nyear={2021},\nurl={https://openreview.net/forum?id=H38f_9b90BO}\n}"}, "tags": [], "invitation": {"reply": {"forum": "H38f_9b90BO", "replyto": "H38f_9b90BO", "readers": {"values": ["everyone"]}, "writers": {"values": ["ICLR.cc/2021/Conference/Program_Chairs"]}, "signatures": {"values": ["ICLR.cc/2021/Conference/Program_Chairs"]}, "content": {"title": {"value": "Final Decision"}, "decision": {"value-radio": ["Accept (Oral)", "Accept (Spotlight)", "Accept (Poster)", "Reject"]}, "comment": {"value-regex": "[\\S\\s]{0,50000}", "markdown": true}}}, "multiReply": false, "signatures": ["ICLR.cc/2021/Conference"], "readers": ["everyone"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Program_Chairs"], "tcdate": 1610040497044, "tmdate": 1610474103457, "id": "ICLR.cc/2021/Conference/Paper317/-/Decision"}}}, {"id": "CfiUK9-4t-q", "original": null, "number": 7, "cdate": 1605879322781, "ddate": null, "tcdate": 1605879322781, "tmdate": 1605879322781, "tddate": null, "forum": "H38f_9b90BO", "replyto": "N93hLNfZGYj", "invitation": "ICLR.cc/2021/Conference/Paper317/-/Official_Comment", "content": {"title": "Summary of revisions made to the paper", "comment": " A summary of the major changes is given below:\n-  We modify our contribution as the first work to handle with the label noise existing in utilizing GNNs to classify graph nodes, which may serve as a beginning for future research towards robust GNNs against label noise.\n---\n- We describe our meta learning based method more clearly in case that our method is categorized as reinforcement learning.\n---\n- We add some additional experiments for the size of $D_{clean}$ as the reviewer's advice and have some interesting findings by this. Besides, we add an dataset with real-world label noise called Webvision and two additional experiments to make the improvement from the learnable $\\lambda$ more trustful. \n---       \n- We investigate the performance of other baselines  without finetuning when they are applied in graph-structured data and find their performances are disappointing. So we  propose the motivation of this work is to utilize the structure information of graph-structured data to train GNNs robustly against label noise.  \n---\n- We compare our method with re-weight based methods and some robust metods in semi-supervised nodes classification task. \n---\nWe submitted a revised version including the aforementioned revisions. Thank you for all the efforts that help us improve the paper. Looking forward to your valuable reply!"}, "signatures": ["ICLR.cc/2021/Conference/Paper317/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper317/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Towards Robust Graph Neural Networks against Label Noise", "authorids": ["~Jun_Xia1", "~Haitao_Lin2", "~Yongjie_Xu1", "~Lirong_Wu1", "~Zhangyang_Gao1", "~Siyuan_Li6", "~Stan_Z._Li2"], "authors": ["Jun Xia", "Haitao Lin", "Yongjie Xu", "Lirong Wu", "Zhangyang Gao", "Siyuan Li", "Stan Z. Li"], "keywords": ["Graph Neural Networks", "Graph Node Classification", "Label Noise"], "abstract": "Massive labeled data have been used in training deep neural networks, thus label noise has become an important issue therein.  Although learning with noisy labels has made great progress on image datasets in recent years, it has not yet been studied in connection with utilizing GNNs to classify graph nodes. In this paper, we proposed a method, named LPM,  to address the problem using Label Propagation (LP) and Meta learning.  Different from previous methods designed for image datasets, our method is based on a special attribute (label smoothness) of graph-structured data, i.e., neighboring nodes in a graph tend to have the same label.  A pseudo label is computed from the neighboring labels for each node in the training set using LP; meta learning is utilized to learn a proper aggregation of the original and pseudo label as the final label.  Experimental results demonstrate that LPM outperforms state-of-the-art methods in graph node classification task with both synthetic and real-world label noise. Source code to reproduce all results will be released.", "one-sentence_summary": "To the best of our knowledge, we are the first to focus on the label noise existing in utilizing GNNs to classify graph nodes.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "xia|towards_robust_graph_neural_networks_against_label_noise", "supplementary_material": "/attachment/a5c59bad1a3c6aef2da8f19b4e7498938c51714a.zip", "pdf": "/pdf/0f5774c96a06ab9bc0c9353ff3f2a59b2ef885ae.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=UW4yOOs9Yw", "_bibtex": "@misc{\nxia2021towards,\ntitle={Towards Robust Graph Neural Networks against Label Noise},\nauthor={Jun Xia and Haitao Lin and Yongjie Xu and Lirong Wu and Zhangyang Gao and Siyuan Li and Stan Z. Li},\nyear={2021},\nurl={https://openreview.net/forum?id=H38f_9b90BO}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "H38f_9b90BO", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper317/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper317/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper317/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper317/Authors|ICLR.cc/2021/Conference/Paper317/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper317/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923872272, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper317/-/Official_Comment"}}}, {"id": "ja3Hm0EPNr5", "original": null, "number": 4, "cdate": 1605600682468, "ddate": null, "tcdate": 1605600682468, "tmdate": 1605755910232, "tddate": null, "forum": "H38f_9b90BO", "replyto": "AlA5s0LC9cr", "invitation": "ICLR.cc/2021/Conference/Paper317/-/Official_Comment", "content": {"title": "#Response to reviewer 2", "comment": "Thanks for your helpful and insightful feedback! We address your concerns and questions as follows:\n- Q1: The idea of using LP (or another algorithm different from GNN) to create pseudo labels for uncertainty nodes is not a new idea.\n- Answer1: Thanks for your recommendation. We carefully check the paper [1] you recommended and find that it utilized a random walk model to find the most confident vertices and add them to label set to train a GCN. Label propagation in the paper is just a baseline for comparison. Although it is similar to ours in select confident nodes, firstly we utilize label propagation instead of random walk and secondly we select confident nodes in training sets to train GNNs robustly instead of expanding the training sets to explore the global graph structure as paper [1]. \n---\n- Q2: Why the joint learning of \\theta with GNN parameters is named meta-learning is not very clear. Algorithm 1 shows both \\theta and \\w_t are fixed to estimate labels for uncertain nodes. Then those parameters are updated with the estimated nodes.\n- Answer2: We are so sorry that we may describe our method unclearly in our original paper so that you have some misunderstandings of our method. $D_{clean}$ is the initial given a few clean nodes which are not in training set and it is utilized to update $\\theta$ in each epoch, not as you claimed to update $\\theta$ with the estimated nodes, you can find this in Page 6, Algorithm 1, line 22-23. $\\theta$ is the parameters of MLPs which outputs $\\lambda$ that is corresponding to a label. We learn the labels that are necessary for better learning, this agrees with the definition of meta learning (\u201clearn to learn\u201d ). We note that you mentioned \u2018RL\u2019 in the review. The clean set here serves as the supervision for $\\theta$ updating, which is different from reinforcement learning.  If you don\u2019t agree with us, we beg the reviewer to explain the connection between ours and RL.\n---\n- Q3: In the experiment part there is no tuned \\lambda compared. This makes the improvement from the learnable \\lambda less trustful. \n- Answer3: We have added two experiments to validate the $\\lambda$ optimized by our method are more effective in the revision. Firstly, we compare our $\\lambda$ with the tuned $\\lambda$ as your advice. We assign the percentage of clean nodes of each label class as $\\lambda$. Additionally, we compare the learned $\\lambda$ between clean nodes and noisy nodes and find that $\\lambda$ of clean nodes are larger on the whole. More details and results can be seen in the revision Sec.4.3, Table 5 and Fig 4.  \n---\n- Q4: The experiments are less convincing because only one real-world noisy dataset is available.\n- Answer4: We have added a dataset (Webvision) with real-world noisy labels in the revision. You can find the results in Table 4.  In fact, it is common to validate the effectiveness of methods handling with real-world label noise on 1or 2 datasets [2,3] because there are not so many open-source datasets with real-world label noise.\n---\n- Q5: The reported numbers show the improvement of proposed method is rather limited, I would suggest run the methods more times and report mean performance with variance.\n-Answer5: Many baselines that rank the second are after our finetuning on clean set. If we didn\u2019t finetune, their results will be disappointing and the gap between baselines and ours will be enlarged. We have investigated their performance without finetuning in the revision, Sec 4.4 and Fig.5. In fact, we have mentioned that experiment results are repeated 5 times (then average) with different random seeds in the origin paper Sec 4.2. However, we didn\u2019t report the std for the limited space. Now we add it.\n---\n- Q6: I would suggest adding some additional experiments for the size of D_clean.\n- Answer6: We have added some additional experiments for the size of $D_{clean}$ as your advice and we have some interesting findings by this. More details can be found in revision Sec. 4.5 and Fig. 6. Thanks for your valuable advice again!\n---\n- Q7: How will the rest RL + learnable \\lambda contribute w.r.t the number of clean nodes?\n- Answer7: Our method is meta learning instead of reinforcement learning as our analysis in Answer 2. Besides, we investigate the results w.r.t size of clean nodes in the revision Sec. 4.5 and Fig. 6. \n---\n[1] Li, Qimai, Zhichao Han and Xiao-Ming Wu. \"Deeper insights into graph convolutional networks for semi-supervised learning.\" AAAI 2018.\n\n[2]Yao, Yu, et al. \"Dual t: Reducing estimation error for transition matrix in label-noise learning.\" NIPS 2020.\n\n[3]Liu, Yun-Peng, et al. \"Label Distribution for Learning with Noisy Labels.\" IJCAI 2020.\n"}, "signatures": ["ICLR.cc/2021/Conference/Paper317/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper317/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Towards Robust Graph Neural Networks against Label Noise", "authorids": ["~Jun_Xia1", "~Haitao_Lin2", "~Yongjie_Xu1", "~Lirong_Wu1", "~Zhangyang_Gao1", "~Siyuan_Li6", "~Stan_Z._Li2"], "authors": ["Jun Xia", "Haitao Lin", "Yongjie Xu", "Lirong Wu", "Zhangyang Gao", "Siyuan Li", "Stan Z. Li"], "keywords": ["Graph Neural Networks", "Graph Node Classification", "Label Noise"], "abstract": "Massive labeled data have been used in training deep neural networks, thus label noise has become an important issue therein.  Although learning with noisy labels has made great progress on image datasets in recent years, it has not yet been studied in connection with utilizing GNNs to classify graph nodes. In this paper, we proposed a method, named LPM,  to address the problem using Label Propagation (LP) and Meta learning.  Different from previous methods designed for image datasets, our method is based on a special attribute (label smoothness) of graph-structured data, i.e., neighboring nodes in a graph tend to have the same label.  A pseudo label is computed from the neighboring labels for each node in the training set using LP; meta learning is utilized to learn a proper aggregation of the original and pseudo label as the final label.  Experimental results demonstrate that LPM outperforms state-of-the-art methods in graph node classification task with both synthetic and real-world label noise. Source code to reproduce all results will be released.", "one-sentence_summary": "To the best of our knowledge, we are the first to focus on the label noise existing in utilizing GNNs to classify graph nodes.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "xia|towards_robust_graph_neural_networks_against_label_noise", "supplementary_material": "/attachment/a5c59bad1a3c6aef2da8f19b4e7498938c51714a.zip", "pdf": "/pdf/0f5774c96a06ab9bc0c9353ff3f2a59b2ef885ae.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=UW4yOOs9Yw", "_bibtex": "@misc{\nxia2021towards,\ntitle={Towards Robust Graph Neural Networks against Label Noise},\nauthor={Jun Xia and Haitao Lin and Yongjie Xu and Lirong Wu and Zhangyang Gao and Siyuan Li and Stan Z. Li},\nyear={2021},\nurl={https://openreview.net/forum?id=H38f_9b90BO}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "H38f_9b90BO", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper317/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper317/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper317/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper317/Authors|ICLR.cc/2021/Conference/Paper317/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper317/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923872272, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper317/-/Official_Comment"}}}, {"id": "91mrwdpw2Z", "original": null, "number": 3, "cdate": 1605599549542, "ddate": null, "tcdate": 1605599549542, "tmdate": 1605713550582, "tddate": null, "forum": "H38f_9b90BO", "replyto": "7RHeTJnpnB3", "invitation": "ICLR.cc/2021/Conference/Paper317/-/Official_Comment", "content": {"title": "#Response to reviewer 1", "comment": "Thanks for your insightful reviews and we appreciate your valuable suggestions! We address your concerns and questions as follows:\n- Q1:  If check the GNN with label noise, I do can find some literature published on CVPR and ECCV. \n- Answer1: There are some recent papers combing GNNs with label noise in recent years. But they just utilized GNNs to train DNNs robustly against label noise, not to train GNNs robustly against label noise. For example, the authors of this paper [1] devised a graph convolutional network to correct noisy labels in video anomaly detection; The structure of clean and noisy data is modeled by a graph per class and Graph Convolutional Networks (GCN) are used to predict class relevance of noisy examples in paper [2]. Besides, there is a previous work [3] which presented a noise-tolerant approach for the graph classification task. However, our work is the first to train GNNs robustly against label noise in graph node classification task utilizing the structure information in graph-structured data.\n---\n- Q2: The third one is evaluation result, cannot be categorized as a contribution.\n- Answer2: We have modified our contribution in the revision and the evaluation results are not categorized as a contribution now. Thanks for your valuable advice again!\n---\n\n[1]Zhong, Jia-Xing, et al. \"Graph convolutional label noise cleaner: Train a plug-and-play action classifier for anomaly detection.\" CVPR, 2019.\n\n[2]Iscen, Ahmet, et al. \"Graph convolutional networks for learning with few clean and many noisy labels.\" ECCV,2019.\n\n[3] Hoang NT, et al. \u201cLearning Graph Neural Networks with Noisy Labels.\u201d ICLR workshop, 2019.\n"}, "signatures": ["ICLR.cc/2021/Conference/Paper317/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper317/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Towards Robust Graph Neural Networks against Label Noise", "authorids": ["~Jun_Xia1", "~Haitao_Lin2", "~Yongjie_Xu1", "~Lirong_Wu1", "~Zhangyang_Gao1", "~Siyuan_Li6", "~Stan_Z._Li2"], "authors": ["Jun Xia", "Haitao Lin", "Yongjie Xu", "Lirong Wu", "Zhangyang Gao", "Siyuan Li", "Stan Z. Li"], "keywords": ["Graph Neural Networks", "Graph Node Classification", "Label Noise"], "abstract": "Massive labeled data have been used in training deep neural networks, thus label noise has become an important issue therein.  Although learning with noisy labels has made great progress on image datasets in recent years, it has not yet been studied in connection with utilizing GNNs to classify graph nodes. In this paper, we proposed a method, named LPM,  to address the problem using Label Propagation (LP) and Meta learning.  Different from previous methods designed for image datasets, our method is based on a special attribute (label smoothness) of graph-structured data, i.e., neighboring nodes in a graph tend to have the same label.  A pseudo label is computed from the neighboring labels for each node in the training set using LP; meta learning is utilized to learn a proper aggregation of the original and pseudo label as the final label.  Experimental results demonstrate that LPM outperforms state-of-the-art methods in graph node classification task with both synthetic and real-world label noise. Source code to reproduce all results will be released.", "one-sentence_summary": "To the best of our knowledge, we are the first to focus on the label noise existing in utilizing GNNs to classify graph nodes.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "xia|towards_robust_graph_neural_networks_against_label_noise", "supplementary_material": "/attachment/a5c59bad1a3c6aef2da8f19b4e7498938c51714a.zip", "pdf": "/pdf/0f5774c96a06ab9bc0c9353ff3f2a59b2ef885ae.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=UW4yOOs9Yw", "_bibtex": "@misc{\nxia2021towards,\ntitle={Towards Robust Graph Neural Networks against Label Noise},\nauthor={Jun Xia and Haitao Lin and Yongjie Xu and Lirong Wu and Zhangyang Gao and Siyuan Li and Stan Z. Li},\nyear={2021},\nurl={https://openreview.net/forum?id=H38f_9b90BO}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "H38f_9b90BO", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper317/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper317/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper317/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper317/Authors|ICLR.cc/2021/Conference/Paper317/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper317/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923872272, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper317/-/Official_Comment"}}}, {"id": "TybGhjr6xIo", "original": null, "number": 6, "cdate": 1605602100356, "ddate": null, "tcdate": 1605602100356, "tmdate": 1605713163712, "tddate": null, "forum": "H38f_9b90BO", "replyto": "yctm2N1LE3b", "invitation": "ICLR.cc/2021/Conference/Paper317/-/Official_Comment", "content": {"title": "#Response to reviewer 4", "comment": "Thanks for your insightful reviews and we appreciate your valuable suggestions and recommendations! We address your concerns as follows:\n- Q1: There already exist some prior works focusing on the label noise existing in graph node classification tasks.\n- Answer1: We have cited, discussed and compared with the papers you recommended in the revision, Sec 2.2. We are so sorry that we make an inaccurate description of our contribution. Instead, we are first to address the label noise problem existing in utilizing GNNs to classify graph nodes. This is meaningful because GNNs have been widely applied in various real-world scenarios while high-quality labels are difficult to collect.\n---\n- Q2: Some recent works on label propagation can be cited.\n- Answer2: We have carefully checked the papers about label propagation you recommended and cited them in the revision, Sec 2.2. Thanks for your recommendation again!\n---\n- Q3: The motivation behind aggregation of the original labels and pseudo labels should be explained appropriately.\n- Answer3: The reasons why we aggregate the original labels and pseudo labels can be seen as follows. Firstly, as is illustrated in this paper [1], lots of original labels are correct in real world and they designed a compatibility loss to enforce the estimated labels are not completely different from original noisy labels. Secondly, the pseudo labels in our method are soft, not one hot or hard.\n---\n- Q4: In the experiments, it seems that the author do not use the public splitting for Cora, CiteSeer, and PubMed datasets.\n- Answer4: Firstly, our method is designed to train existing GNNs robustly against label noise, not to propose a new one to compare with existing GNNs so it is unnecessary to correspond to public splitting. Secondly, we have to collect the same nodes per class as clean set, however, clean set with one node per class will be relatively large according to public splitting. And our open-source codes can show our splitting for fair comparison between future methods that train GNNs robustly.\n---\n- Q5:The proposed model outperforms the comparison methods when the level of flip noise is greater than 0, but cannot perform as good as L2RW when the level equals 0. The reason for such inconsistencies should be analyzed in the experiments.\n- Answer5: Thanks for your reminding! At 0% noise, our method only slightly underperforms L2RW. This is reasonable because the original labels are all correct but our method will inevitably perturb a few labels while the L2RW will not. We have added this explanation in the revision.\n---\n- Q6: The selection of clean labels is a critical step. However, the authors do not give enough details about this process. \n- Answer6: Only 28,24,24,25 nodes with clean labels in the validation set are provided as the clean set in Cora, Citeseer, Pubmed and Coauthor-Phy datasets and we ensure that each class has the same number of nodes. Besides, we have added some additional experiments for the size of $D_{clean}$ as your advice and we have some interesting findings by this. More details can be found in the revision Sec. 4.5 and Fig. 6. Thanks for your valuable advice again!\n---\n- Q7: I cannot find the hyper-parameter configurations for the baselines, and these information should be provided.\n- Answer7: We have mentioned hyper-parameter configurations for the baselines in the appendix B, page 14.\n---\n\n[1] Yi, Kun, and Jianxin Wu. \"Probabilistic end-to-end noise correction for learning with noisy labels.\" CVPR 2019.\n"}, "signatures": ["ICLR.cc/2021/Conference/Paper317/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper317/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Towards Robust Graph Neural Networks against Label Noise", "authorids": ["~Jun_Xia1", "~Haitao_Lin2", "~Yongjie_Xu1", "~Lirong_Wu1", "~Zhangyang_Gao1", "~Siyuan_Li6", "~Stan_Z._Li2"], "authors": ["Jun Xia", "Haitao Lin", "Yongjie Xu", "Lirong Wu", "Zhangyang Gao", "Siyuan Li", "Stan Z. Li"], "keywords": ["Graph Neural Networks", "Graph Node Classification", "Label Noise"], "abstract": "Massive labeled data have been used in training deep neural networks, thus label noise has become an important issue therein.  Although learning with noisy labels has made great progress on image datasets in recent years, it has not yet been studied in connection with utilizing GNNs to classify graph nodes. In this paper, we proposed a method, named LPM,  to address the problem using Label Propagation (LP) and Meta learning.  Different from previous methods designed for image datasets, our method is based on a special attribute (label smoothness) of graph-structured data, i.e., neighboring nodes in a graph tend to have the same label.  A pseudo label is computed from the neighboring labels for each node in the training set using LP; meta learning is utilized to learn a proper aggregation of the original and pseudo label as the final label.  Experimental results demonstrate that LPM outperforms state-of-the-art methods in graph node classification task with both synthetic and real-world label noise. Source code to reproduce all results will be released.", "one-sentence_summary": "To the best of our knowledge, we are the first to focus on the label noise existing in utilizing GNNs to classify graph nodes.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "xia|towards_robust_graph_neural_networks_against_label_noise", "supplementary_material": "/attachment/a5c59bad1a3c6aef2da8f19b4e7498938c51714a.zip", "pdf": "/pdf/0f5774c96a06ab9bc0c9353ff3f2a59b2ef885ae.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=UW4yOOs9Yw", "_bibtex": "@misc{\nxia2021towards,\ntitle={Towards Robust Graph Neural Networks against Label Noise},\nauthor={Jun Xia and Haitao Lin and Yongjie Xu and Lirong Wu and Zhangyang Gao and Siyuan Li and Stan Z. Li},\nyear={2021},\nurl={https://openreview.net/forum?id=H38f_9b90BO}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "H38f_9b90BO", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper317/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper317/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper317/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper317/Authors|ICLR.cc/2021/Conference/Paper317/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper317/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923872272, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper317/-/Official_Comment"}}}, {"id": "jT_1RoRjwB", "original": null, "number": 5, "cdate": 1605601313543, "ddate": null, "tcdate": 1605601313543, "tmdate": 1605712529028, "tddate": null, "forum": "H38f_9b90BO", "replyto": "uyXhiMNwchh", "invitation": "ICLR.cc/2021/Conference/Paper317/-/Official_Comment", "content": {"title": "#Response to reviewer 3", "comment": "We thank reviewer #3 for the helpful and insightful feedback. We provide answers to individual questions below :\n- Q1: the usage of $w$ is never defined.\n- Answer1: $w$ in our paper is the GNNs parameters and we defined it in the revision.\n---\n- Q2: The usage of meta learning is not novel,it tried to use several equations to explain the L2R method, which is not sufficient to be clear but makes unnecessary confusion.\n- Answer2: Utilizing meta learning to learn the parameters for better learning is common to see. For example, meta-learning with validation set to optimize the discrete graph structure for attack [1]. Combining the formulations with Fig. 2 can help us understand the procedure more clearly. To some extent, this part is similar to re-weight based method. We make a comparison with re-weight based methods (L2R) in the revision Sec 3.3. Instead of learning the weights for samples [2], we utilize meta learning to learn the labels. There are two significant advantages: Firstly, re-weight based methods can not remove the damages caused by incorrect labels because they assign every noisy training sample a positive weight while ours potentially has the ability to take full advantage of noisy samples positively. Secondly, ours can generate comparatively credible labels for other usages while re-weight or some other methods can not. \n---\n- Q3: Most compared methods are only evaluated on common image datasets. The comparison may not be very fair. The proposed method is marginally better than several other methods.\n- Answer3: The motivation of this work is to utilize the structure information in graph-structured data to train GNNs robustly against label noise. However, there is no intrinsic structure in image dataset. In other words, our method is specially designed for GNNs and graph-structured data. Besides, almost all previous methods are designed for image datasets. Although they can be applied in graph data, they perform not so well in graph data without finetuning. We show their results after removing finetuning in the revision Sec. 4.4 and Fig. 5. The gap between their methods and ours will be enlarged.  \n---\n- Q4: The results are not generally useful to compare to other methods which have tested on full Clothing1M.\n- Answer4: There is no previous method which address the label noise existing in utilizing GNNs to classify graph nodes and there is no graph-structured dataset with real-world label noise like Clothing 1M currently. Besides, GCN is a transductive model which utilize the validation and test nodes during training stage and it is difficult to be applied in large-scale dataset such as Clothing 1M. So we validate the effectiveness of our method to handle real-world label noise on mini-Clothing 1M. Although it is not full dataset, the label noise is still real-world, not synthetic and all the baselines are evaluated on this mini-Clothing 1M for fair comparison. Additionally, we preprocess the Webvision dataset with real-world label noise in the same way with our preprocess on Clothing 1M. The results are reported in the revision, Table 4. Although we validate the real-world effectiveness on mini-Clothing 1M, we believe that our work will motivate future inductive methods that train GNNs robustly against label noise just like the development of GNNs from transductive to inductive models. Also, it is necessary to publish an open-source graph dataset with real-world label noise so that we can evaluate various methods because GNNs have been widely applied in various real-world scenarios while high-quality labels are difficult to collect. Thanks for your valuable advice again!\n---\n\n\t \n[1] Z\u00fcgner, Daniel, and Stephan G\u00fcnnemann. \"Adversarial attacks on graph neural networks via meta learning.\" ICLR 2019.\n\n[2] Ren, Mengye et al. \"Learning to reweight examples for robust deep learning.\" ICML 2018.\n"}, "signatures": ["ICLR.cc/2021/Conference/Paper317/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper317/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Towards Robust Graph Neural Networks against Label Noise", "authorids": ["~Jun_Xia1", "~Haitao_Lin2", "~Yongjie_Xu1", "~Lirong_Wu1", "~Zhangyang_Gao1", "~Siyuan_Li6", "~Stan_Z._Li2"], "authors": ["Jun Xia", "Haitao Lin", "Yongjie Xu", "Lirong Wu", "Zhangyang Gao", "Siyuan Li", "Stan Z. Li"], "keywords": ["Graph Neural Networks", "Graph Node Classification", "Label Noise"], "abstract": "Massive labeled data have been used in training deep neural networks, thus label noise has become an important issue therein.  Although learning with noisy labels has made great progress on image datasets in recent years, it has not yet been studied in connection with utilizing GNNs to classify graph nodes. In this paper, we proposed a method, named LPM,  to address the problem using Label Propagation (LP) and Meta learning.  Different from previous methods designed for image datasets, our method is based on a special attribute (label smoothness) of graph-structured data, i.e., neighboring nodes in a graph tend to have the same label.  A pseudo label is computed from the neighboring labels for each node in the training set using LP; meta learning is utilized to learn a proper aggregation of the original and pseudo label as the final label.  Experimental results demonstrate that LPM outperforms state-of-the-art methods in graph node classification task with both synthetic and real-world label noise. Source code to reproduce all results will be released.", "one-sentence_summary": "To the best of our knowledge, we are the first to focus on the label noise existing in utilizing GNNs to classify graph nodes.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "xia|towards_robust_graph_neural_networks_against_label_noise", "supplementary_material": "/attachment/a5c59bad1a3c6aef2da8f19b4e7498938c51714a.zip", "pdf": "/pdf/0f5774c96a06ab9bc0c9353ff3f2a59b2ef885ae.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=UW4yOOs9Yw", "_bibtex": "@misc{\nxia2021towards,\ntitle={Towards Robust Graph Neural Networks against Label Noise},\nauthor={Jun Xia and Haitao Lin and Yongjie Xu and Lirong Wu and Zhangyang Gao and Siyuan Li and Stan Z. Li},\nyear={2021},\nurl={https://openreview.net/forum?id=H38f_9b90BO}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "H38f_9b90BO", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper317/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper317/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper317/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper317/Authors|ICLR.cc/2021/Conference/Paper317/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper317/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923872272, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper317/-/Official_Comment"}}}, {"id": "N93hLNfZGYj", "original": null, "number": 2, "cdate": 1605598982092, "ddate": null, "tcdate": 1605598982092, "tmdate": 1605598982092, "tddate": null, "forum": "H38f_9b90BO", "replyto": "H38f_9b90BO", "invitation": "ICLR.cc/2021/Conference/Paper317/-/Official_Comment", "content": {"title": "General response", "comment": "We thank all the reviewers for their thorough and very helpful feedback. We have uploaded an updated version based on the comments. The modified parts are shown in red for your convenience. If the title of a subsection is red, the subsection is new. In the meantime, we have provided detailed responses to all your questions below. Please take a look and let us know if you have any further questions or comments!"}, "signatures": ["ICLR.cc/2021/Conference/Paper317/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper317/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Towards Robust Graph Neural Networks against Label Noise", "authorids": ["~Jun_Xia1", "~Haitao_Lin2", "~Yongjie_Xu1", "~Lirong_Wu1", "~Zhangyang_Gao1", "~Siyuan_Li6", "~Stan_Z._Li2"], "authors": ["Jun Xia", "Haitao Lin", "Yongjie Xu", "Lirong Wu", "Zhangyang Gao", "Siyuan Li", "Stan Z. Li"], "keywords": ["Graph Neural Networks", "Graph Node Classification", "Label Noise"], "abstract": "Massive labeled data have been used in training deep neural networks, thus label noise has become an important issue therein.  Although learning with noisy labels has made great progress on image datasets in recent years, it has not yet been studied in connection with utilizing GNNs to classify graph nodes. In this paper, we proposed a method, named LPM,  to address the problem using Label Propagation (LP) and Meta learning.  Different from previous methods designed for image datasets, our method is based on a special attribute (label smoothness) of graph-structured data, i.e., neighboring nodes in a graph tend to have the same label.  A pseudo label is computed from the neighboring labels for each node in the training set using LP; meta learning is utilized to learn a proper aggregation of the original and pseudo label as the final label.  Experimental results demonstrate that LPM outperforms state-of-the-art methods in graph node classification task with both synthetic and real-world label noise. Source code to reproduce all results will be released.", "one-sentence_summary": "To the best of our knowledge, we are the first to focus on the label noise existing in utilizing GNNs to classify graph nodes.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "xia|towards_robust_graph_neural_networks_against_label_noise", "supplementary_material": "/attachment/a5c59bad1a3c6aef2da8f19b4e7498938c51714a.zip", "pdf": "/pdf/0f5774c96a06ab9bc0c9353ff3f2a59b2ef885ae.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=UW4yOOs9Yw", "_bibtex": "@misc{\nxia2021towards,\ntitle={Towards Robust Graph Neural Networks against Label Noise},\nauthor={Jun Xia and Haitao Lin and Yongjie Xu and Lirong Wu and Zhangyang Gao and Siyuan Li and Stan Z. Li},\nyear={2021},\nurl={https://openreview.net/forum?id=H38f_9b90BO}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "H38f_9b90BO", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper317/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper317/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper317/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper317/Authors|ICLR.cc/2021/Conference/Paper317/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper317/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923872272, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper317/-/Official_Comment"}}}, {"id": "yctm2N1LE3b", "original": null, "number": 1, "cdate": 1603415972806, "ddate": null, "tcdate": 1603415972806, "tmdate": 1605024715720, "tddate": null, "forum": "H38f_9b90BO", "replyto": "H38f_9b90BO", "invitation": "ICLR.cc/2021/Conference/Paper317/-/Official_Review", "content": {"title": "Interesting work, but can be further improved", "review": "*quality*\nThis paper is well-organized. However, the contributions are not clear. Meanwhile, the experimental validation is weak and needs to be improved.\n\n*clarity*\nIt is not difficult to understand the framework of the proposed algorithm.\n\n*originality*\nIn this paper, the proposed algorithm focuses on the label noise existing in graph node classification tasks. The contributions are somewhat limited, since this is not the first work focusing on this problem. Besides, the main motivation is also not new for semi-supervised label propagation. \n\n*significance*\nAlthough the proposed algorithm is limited in its novelty, I feel that the significance of this paper will inspire researchers focusing on this domain.\n\n*pros and cons*\n\nPros:\n1.\tThe topic is practical in realistic machine learning problems, and the proposed method is helpful to reduce the human annotation efforts.\n2.\tThe theoretical study of this paper is meaningful.\n\nCons:\n1.\tThe authors claim that they are the first to focus on the label noise existing in graph node classification tasks. However, to the best of my knowledge, there already exist some prior works, such as \u2018Learning with Inadequate and Incorrect Supervision\u2019,\u2018Self-Training of Graph Neural Networks using Similarity Reference for Robust Training with Noisy Labels\u2019, \u2018Noise-robust semisupervised learning by large-scale sparse coding\u2019, \u2018Robust semi-supervised classification for noisy labels based on self-paced learning\u2019, and \u2018Label Diagnosis through Self Tuning for Web Image Search\u2019. In this sense, the authors cannot claim that they are the first to solve the label noise in the label propagation or node classification task. Besides, the abovementioned works should be cited, discussed, and even compared.\n2.\tSome recent works on label propagation can be cited, such as \u2018Label propagation via teaching-to-learn and learning-to-teach\u2019, \u2018Robust Triple-Matrix-Recovery-Based Auto-Weighted Label Propagation for Classification\u2019, etc.\n3.\tIn Eq. (8), the authors calculate the final predictions by aggregating the original labels and pseudo labels, in order to fully exploit the abundant information contained in the left training nodes D_left. This is a bit confusing, since both the original label y_j and the pseudo label y^\\tilde_j may not be the correct labels. The motivation behind this aggregation process should be explained appropriately. \n4.\tIn the experiments, it seems that the author do not use the public splitting for Cora, CiteSeer, and PubMed datasets. As a consequence, the results reported in the paper may not be convincing enough. It would be better to follow the public split for fair comparison.\n5.\tThe proposed model outperforms the comparison methods when the level of flip noise is greater than 0, but cannot perform as good as L2RW when the level equals 0. The reason for such inconsistencies should be analyzed in the experiments.\n6.\tAs for me, the selection of clean labels is a critical step. However, the authors do not give enough details about this process. I suggest analyzing the influence of the scale of clean labels on different datasets.\n7.\tI cannot find the hyper-parameter configurations for the baselines, and these information should be provided. \n", "rating": "6: Marginally above acceptance threshold", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["ICLR.cc/2021/Conference/Paper317/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper317/AnonReviewer1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Towards Robust Graph Neural Networks against Label Noise", "authorids": ["~Jun_Xia1", "~Haitao_Lin2", "~Yongjie_Xu1", "~Lirong_Wu1", "~Zhangyang_Gao1", "~Siyuan_Li6", "~Stan_Z._Li2"], "authors": ["Jun Xia", "Haitao Lin", "Yongjie Xu", "Lirong Wu", "Zhangyang Gao", "Siyuan Li", "Stan Z. Li"], "keywords": ["Graph Neural Networks", "Graph Node Classification", "Label Noise"], "abstract": "Massive labeled data have been used in training deep neural networks, thus label noise has become an important issue therein.  Although learning with noisy labels has made great progress on image datasets in recent years, it has not yet been studied in connection with utilizing GNNs to classify graph nodes. In this paper, we proposed a method, named LPM,  to address the problem using Label Propagation (LP) and Meta learning.  Different from previous methods designed for image datasets, our method is based on a special attribute (label smoothness) of graph-structured data, i.e., neighboring nodes in a graph tend to have the same label.  A pseudo label is computed from the neighboring labels for each node in the training set using LP; meta learning is utilized to learn a proper aggregation of the original and pseudo label as the final label.  Experimental results demonstrate that LPM outperforms state-of-the-art methods in graph node classification task with both synthetic and real-world label noise. Source code to reproduce all results will be released.", "one-sentence_summary": "To the best of our knowledge, we are the first to focus on the label noise existing in utilizing GNNs to classify graph nodes.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "xia|towards_robust_graph_neural_networks_against_label_noise", "supplementary_material": "/attachment/a5c59bad1a3c6aef2da8f19b4e7498938c51714a.zip", "pdf": "/pdf/0f5774c96a06ab9bc0c9353ff3f2a59b2ef885ae.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=UW4yOOs9Yw", "_bibtex": "@misc{\nxia2021towards,\ntitle={Towards Robust Graph Neural Networks against Label Noise},\nauthor={Jun Xia and Haitao Lin and Yongjie Xu and Lirong Wu and Zhangyang Gao and Siyuan Li and Stan Z. Li},\nyear={2021},\nurl={https://openreview.net/forum?id=H38f_9b90BO}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq . ***Please remember to file the Code-of-Ethics report. Once you submitted the review, a link to the report will be visible in the bottom right corner of your review.***", "required": true, "markdown": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}, "forum": "H38f_9b90BO", "replyto": "H38f_9b90BO", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"], "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper317/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1607428800000, "duedate": 1606752000000, "multiReply": false, "readers": ["everyone"], "tcdate": 1602538145772, "tmdate": 1606915799344, "super": "ICLR.cc/2021/Conference/-/Official_Review", "signatures": ["OpenReview.net"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Paper317/Reviewers", "OpenReview.net/Support"], "id": "ICLR.cc/2021/Conference/Paper317/-/Official_Review"}}}, {"id": "uyXhiMNwchh", "original": null, "number": 2, "cdate": 1603842271554, "ddate": null, "tcdate": 1603842271554, "tmdate": 1605024715652, "tddate": null, "forum": "H38f_9b90BO", "replyto": "H38f_9b90BO", "invitation": "ICLR.cc/2021/Conference/Paper317/-/Official_Review", "content": {"title": "Anonymous review", "review": "This paper presents a label propagation based meta learning algorithm to address label noise. Label propagation helps re-label pseudo labels of noisy data and meta learning achieves aggregations. The method is evaluated on several node classification datasets and a custom version of Clothing1M image classification dataset. The comparison to multiple baselines shows better performance.\n\nPros:\n- The combination of graph neural network and meta learning is interesting and novel\n\nCons:\n- The paper is not well written. Some descriptions are unclear. For instance, the usage of $w$ is never defined. The usage of meta learning is not novel, which from a previous method - L2R, but it is never clearly mentioned. However, it tried to use several equations to explain the L2R method, which is not sufficient to be clear but makes unnecessary confusion.\n- Experiments might not be that convincing.\n  - The method is only tested on several graph datasets with synthetic noises, which were uncommon in previous papers. However, most compared methods are only evaluated on common image datasets. The comparison may not be very fair. Moreover, from Table 2 and 3. The proposed method is marginally better than several other methods.\n  - Although the method tries to tackle a real-world dataset Clothing1M, the scalability issue of this algorithm makes it difficult to work so it is only tested on a custom toy version. So the results are not generally useful to compare to other methods which have tested on full Clothing1M.\n", "rating": "5: Marginally below acceptance threshold", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["ICLR.cc/2021/Conference/Paper317/AnonReviewer4"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper317/AnonReviewer4"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Towards Robust Graph Neural Networks against Label Noise", "authorids": ["~Jun_Xia1", "~Haitao_Lin2", "~Yongjie_Xu1", "~Lirong_Wu1", "~Zhangyang_Gao1", "~Siyuan_Li6", "~Stan_Z._Li2"], "authors": ["Jun Xia", "Haitao Lin", "Yongjie Xu", "Lirong Wu", "Zhangyang Gao", "Siyuan Li", "Stan Z. Li"], "keywords": ["Graph Neural Networks", "Graph Node Classification", "Label Noise"], "abstract": "Massive labeled data have been used in training deep neural networks, thus label noise has become an important issue therein.  Although learning with noisy labels has made great progress on image datasets in recent years, it has not yet been studied in connection with utilizing GNNs to classify graph nodes. In this paper, we proposed a method, named LPM,  to address the problem using Label Propagation (LP) and Meta learning.  Different from previous methods designed for image datasets, our method is based on a special attribute (label smoothness) of graph-structured data, i.e., neighboring nodes in a graph tend to have the same label.  A pseudo label is computed from the neighboring labels for each node in the training set using LP; meta learning is utilized to learn a proper aggregation of the original and pseudo label as the final label.  Experimental results demonstrate that LPM outperforms state-of-the-art methods in graph node classification task with both synthetic and real-world label noise. Source code to reproduce all results will be released.", "one-sentence_summary": "To the best of our knowledge, we are the first to focus on the label noise existing in utilizing GNNs to classify graph nodes.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "xia|towards_robust_graph_neural_networks_against_label_noise", "supplementary_material": "/attachment/a5c59bad1a3c6aef2da8f19b4e7498938c51714a.zip", "pdf": "/pdf/0f5774c96a06ab9bc0c9353ff3f2a59b2ef885ae.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=UW4yOOs9Yw", "_bibtex": "@misc{\nxia2021towards,\ntitle={Towards Robust Graph Neural Networks against Label Noise},\nauthor={Jun Xia and Haitao Lin and Yongjie Xu and Lirong Wu and Zhangyang Gao and Siyuan Li and Stan Z. Li},\nyear={2021},\nurl={https://openreview.net/forum?id=H38f_9b90BO}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq . ***Please remember to file the Code-of-Ethics report. Once you submitted the review, a link to the report will be visible in the bottom right corner of your review.***", "required": true, "markdown": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}, "forum": "H38f_9b90BO", "replyto": "H38f_9b90BO", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"], "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper317/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1607428800000, "duedate": 1606752000000, "multiReply": false, "readers": ["everyone"], "tcdate": 1602538145772, "tmdate": 1606915799344, "super": "ICLR.cc/2021/Conference/-/Official_Review", "signatures": ["OpenReview.net"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Paper317/Reviewers", "OpenReview.net/Support"], "id": "ICLR.cc/2021/Conference/Paper317/-/Official_Review"}}}, {"id": "AlA5s0LC9cr", "original": null, "number": 3, "cdate": 1603937120597, "ddate": null, "tcdate": 1603937120597, "tmdate": 1605024715584, "tddate": null, "forum": "H38f_9b90BO", "replyto": "H38f_9b90BO", "invitation": "ICLR.cc/2021/Conference/Paper317/-/Official_Review", "content": {"title": "interesting paper but not good enough", "review": "The paper proposes a robust training algorithm for graph neural networks against label noise. The authors assume the labeled nodes are divided into two parts, clean part without noise and train part with some noise. The proposed method contains two parts. Firstly, it leverages label propagation (LP) trained on the clean nodes to assign pseudo labels on train nodes with noisy labels. Secondly, the authors design a learnable weight \\lambda to learn the label for those noisy nodes where LP does not agree with the original labels. The final graph neural network is trained with clean nodes, high confidence train nodes, and uncertain train nodes with learned labels. The authors conduct experiments on four graph datasets with manual injected noise and one real-world noisy dataset to validate the proposed method.\n\nThe paper studies an important problem of graph neural networks with noisy label. I have several concerns for the paper.\n(1)\tThe idea of using LP (or another algorithm different from GNN) to create pseudo labels for uncertainty nodes is not a new idea (e.g., in [1]). Actually, the LP, original data and GNN are ensembled and the final label comes from the majority vote. When LP agrees with the original data (in noisy part), those labels are retained. \n[1] Li, Qimai, Zhichao Han, and Xiao-Ming Wu. \"Deeper insights into graph convolutional networks for semi-supervised learning.\" arXiv preprint arXiv:1801.07606 (2018).\n(2)\tWhy the joint learning of \\theta with GNN parameters is named meta-learning is not very clear. Algorithm 1 shows both \\theta and \\w_t are fixed to estimate labels for uncertain nodes. Then those parameters are updated with the estimated nodes. Besides, in the experiment part there is no tuned \\lambda compared (random is not good, a wrong \\lambda can hurt the performance). This makes the improvement from the learnable \\lambda less trustful.\n(3)\tThe experiments are less convincing because only one real-world noisy dataset is available. Because the authors have a strong assumption that both noisy and clean labels exist, it would be better if the authors can validate such assumption with some real-world data. The reported numbers show the improvement of proposed method is rather limited, I would suggest run the methods more times and report mean performance with variance. Results with manually tuned \\lambda should be reported. Besides, since GNNs are good for learning on graphs with few labeled nodes (such as the gcn paper actually only use several labeled nodes per class), I would suggest adding some additional experiments for the size of D_clean. How will the rest RL + learnable \\lambda contribute w.r.t the number of clean nodes?\n", "rating": "4: Ok but not good enough - rejection", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}, "signatures": ["ICLR.cc/2021/Conference/Paper317/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper317/AnonReviewer3"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Towards Robust Graph Neural Networks against Label Noise", "authorids": ["~Jun_Xia1", "~Haitao_Lin2", "~Yongjie_Xu1", "~Lirong_Wu1", "~Zhangyang_Gao1", "~Siyuan_Li6", "~Stan_Z._Li2"], "authors": ["Jun Xia", "Haitao Lin", "Yongjie Xu", "Lirong Wu", "Zhangyang Gao", "Siyuan Li", "Stan Z. Li"], "keywords": ["Graph Neural Networks", "Graph Node Classification", "Label Noise"], "abstract": "Massive labeled data have been used in training deep neural networks, thus label noise has become an important issue therein.  Although learning with noisy labels has made great progress on image datasets in recent years, it has not yet been studied in connection with utilizing GNNs to classify graph nodes. In this paper, we proposed a method, named LPM,  to address the problem using Label Propagation (LP) and Meta learning.  Different from previous methods designed for image datasets, our method is based on a special attribute (label smoothness) of graph-structured data, i.e., neighboring nodes in a graph tend to have the same label.  A pseudo label is computed from the neighboring labels for each node in the training set using LP; meta learning is utilized to learn a proper aggregation of the original and pseudo label as the final label.  Experimental results demonstrate that LPM outperforms state-of-the-art methods in graph node classification task with both synthetic and real-world label noise. Source code to reproduce all results will be released.", "one-sentence_summary": "To the best of our knowledge, we are the first to focus on the label noise existing in utilizing GNNs to classify graph nodes.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "xia|towards_robust_graph_neural_networks_against_label_noise", "supplementary_material": "/attachment/a5c59bad1a3c6aef2da8f19b4e7498938c51714a.zip", "pdf": "/pdf/0f5774c96a06ab9bc0c9353ff3f2a59b2ef885ae.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=UW4yOOs9Yw", "_bibtex": "@misc{\nxia2021towards,\ntitle={Towards Robust Graph Neural Networks against Label Noise},\nauthor={Jun Xia and Haitao Lin and Yongjie Xu and Lirong Wu and Zhangyang Gao and Siyuan Li and Stan Z. Li},\nyear={2021},\nurl={https://openreview.net/forum?id=H38f_9b90BO}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq . ***Please remember to file the Code-of-Ethics report. Once you submitted the review, a link to the report will be visible in the bottom right corner of your review.***", "required": true, "markdown": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}, "forum": "H38f_9b90BO", "replyto": "H38f_9b90BO", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"], "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper317/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1607428800000, "duedate": 1606752000000, "multiReply": false, "readers": ["everyone"], "tcdate": 1602538145772, "tmdate": 1606915799344, "super": "ICLR.cc/2021/Conference/-/Official_Review", "signatures": ["OpenReview.net"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Paper317/Reviewers", "OpenReview.net/Support"], "id": "ICLR.cc/2021/Conference/Paper317/-/Official_Review"}}}, {"id": "7RHeTJnpnB3", "original": null, "number": 4, "cdate": 1604002455599, "ddate": null, "tcdate": 1604002455599, "tmdate": 1605024715512, "tddate": null, "forum": "H38f_9b90BO", "replyto": "H38f_9b90BO", "invitation": "ICLR.cc/2021/Conference/Paper317/-/Official_Review", "content": {"title": "The paper is clear and in good quality", "review": "This paper presents the one technique using label propagation with meta learning. The label smoothness is used to pseudo label the nodes in the graph. The experimental results look promising in two conditions of label noises. The paper is presented clearly and easy to read. Overall, the quality is good.\n\nThe paper present the idea and experiments clearly.\n\nI checked a few literature and believe this work is original.\n\nPros:\n1. clear presentation\n2. method is simple but seem very effective\n3. the experimental results outperformed the state-of-the-arts in both synthetic label noise and real noise scenarios.\n\nCons:\n1. the contributions can be challenged. If check the GNN with label noise, I do can find some literature published on CVPR and ECCV. And the third one is evaluation result, cannot be categorized as a contribution.\n", "rating": "7: Good paper, accept", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["ICLR.cc/2021/Conference/Paper317/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper317/AnonReviewer2"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Towards Robust Graph Neural Networks against Label Noise", "authorids": ["~Jun_Xia1", "~Haitao_Lin2", "~Yongjie_Xu1", "~Lirong_Wu1", "~Zhangyang_Gao1", "~Siyuan_Li6", "~Stan_Z._Li2"], "authors": ["Jun Xia", "Haitao Lin", "Yongjie Xu", "Lirong Wu", "Zhangyang Gao", "Siyuan Li", "Stan Z. Li"], "keywords": ["Graph Neural Networks", "Graph Node Classification", "Label Noise"], "abstract": "Massive labeled data have been used in training deep neural networks, thus label noise has become an important issue therein.  Although learning with noisy labels has made great progress on image datasets in recent years, it has not yet been studied in connection with utilizing GNNs to classify graph nodes. In this paper, we proposed a method, named LPM,  to address the problem using Label Propagation (LP) and Meta learning.  Different from previous methods designed for image datasets, our method is based on a special attribute (label smoothness) of graph-structured data, i.e., neighboring nodes in a graph tend to have the same label.  A pseudo label is computed from the neighboring labels for each node in the training set using LP; meta learning is utilized to learn a proper aggregation of the original and pseudo label as the final label.  Experimental results demonstrate that LPM outperforms state-of-the-art methods in graph node classification task with both synthetic and real-world label noise. Source code to reproduce all results will be released.", "one-sentence_summary": "To the best of our knowledge, we are the first to focus on the label noise existing in utilizing GNNs to classify graph nodes.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "xia|towards_robust_graph_neural_networks_against_label_noise", "supplementary_material": "/attachment/a5c59bad1a3c6aef2da8f19b4e7498938c51714a.zip", "pdf": "/pdf/0f5774c96a06ab9bc0c9353ff3f2a59b2ef885ae.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=UW4yOOs9Yw", "_bibtex": "@misc{\nxia2021towards,\ntitle={Towards Robust Graph Neural Networks against Label Noise},\nauthor={Jun Xia and Haitao Lin and Yongjie Xu and Lirong Wu and Zhangyang Gao and Siyuan Li and Stan Z. Li},\nyear={2021},\nurl={https://openreview.net/forum?id=H38f_9b90BO}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq . ***Please remember to file the Code-of-Ethics report. Once you submitted the review, a link to the report will be visible in the bottom right corner of your review.***", "required": true, "markdown": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}, "forum": "H38f_9b90BO", "replyto": "H38f_9b90BO", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"], "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper317/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1607428800000, "duedate": 1606752000000, "multiReply": false, "readers": ["everyone"], "tcdate": 1602538145772, "tmdate": 1606915799344, "super": "ICLR.cc/2021/Conference/-/Official_Review", "signatures": ["OpenReview.net"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Paper317/Reviewers", "OpenReview.net/Support"], "id": "ICLR.cc/2021/Conference/Paper317/-/Official_Review"}}}], "count": 13}