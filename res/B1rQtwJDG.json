{"notes": [{"tddate": null, "replyto": null, "ddate": null, "tmdate": 1528124459730, "tcdate": 1518463261035, "number": 223, "cdate": 1518463261035, "id": "B1rQtwJDG", "invitation": "ICLR.cc/2018/Workshop/-/Submission", "forum": "B1rQtwJDG", "signatures": ["~Rui_Shu1"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Workshop"], "content": {"title": "Rethinking Style and Content Disentanglement in Variational Autoencoders", "abstract": "A common test for whether a generative model learns disentangled representations is its ability to learn style and content as independent factors of variation on digit datasets. To achieve such disentanglement with variational autoencoders, the label information is often provided in either a fully-supervised or semi-supervised fashion. We show, however, that the variational objective is insufficient in explaining the observed style and content disentanglement. Furthermore, we present an empirical framework to systematically evaluate the disentanglement behavior of our models. We show that the encoder and decoder independently favor disentangled representations and that this tendency depends on the implicit regularization by stochastic gradient descent.", "paperhash": "shu|rethinking_style_and_content_disentanglement_in_variational_autoencoders", "keywords": ["disentangled representation", "variational autoencoders", "deep representation prior"], "_bibtex": "@misc{\n  shu2018rethinking,\n  title={Rethinking Style and Content Disentanglement in Variational Autoencoders},\n  author={Rui Shu and Shengjia Zhao and Mykel J. Kochenderfer},\n  year={2018},\n  url={https://openreview.net/forum?id=B1rQtwJDG}\n}", "authorids": ["ruishu@stanford.edu", "sjzhao@stanford.edu", "mykel@stanford.edu"], "authors": ["Rui Shu", "Shengjia Zhao", "Mykel J. Kochenderfer"], "TL;DR": "Understanding deep representation learning requires rethinking disentanglement.", "pdf": "/pdf/eaa313302a9cd809ecdc8edd86f419305f5d14c1.pdf"}, "nonreaders": [], "details": {"replyCount": 7, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1518472800000, "tmdate": 1518474081690, "id": "ICLR.cc/2018/Workshop/-/Submission", "writers": ["ICLR.cc/2018/Workshop"], "signatures": ["ICLR.cc/2018/Workshop"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": null, "replyto": null, "writers": {"values": ["ICLR.cc/2018/Workshop"]}, "signatures": {"values-regex": "~.*|ICLR.cc/2018/Workshop", "description": "Your authorized identity to be associated with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"pdf": {"required": true, "order": 9, "value-regex": "upload", "description": "Upload a PDF file that ends with .pdf"}, "title": {"required": true, "order": 1, "description": "Title of paper.", "value-regex": ".{1,250}"}, "abstract": {"required": true, "order": 8, "description": "Abstract of paper.", "value-regex": "[\\S\\s]{1,5000}"}, "authors": {"required": true, "order": 2, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of author names. Please provide real names; identities will be anonymized."}, "keywords": {"order": 6, "values-regex": "(^$)|[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of keywords."}, "TL;DR": {"required": false, "order": 7, "description": "\"Too Long; Didn't Read\": a short sentence describing your paper", "value-regex": "[^\\n]{0,500}"}, "authorids": {"required": true, "order": 3, "values-regex": "([a-z0-9_\\-\\.]{2,}@[a-z0-9_\\-\\.]{2,}\\.[a-z]{2,},){0,}([a-z0-9_\\-\\.]{2,}@[a-z0-9_\\-\\.]{2,}\\.[a-z]{2,})", "description": "Comma separated list of author email addresses, lowercased, in the same order as above. For authors with existing OpenReview accounts, please make sure that the provided email address(es) match those listed in the author's profile. Please provide real emails; identities will be anonymized."}}}, "nonreaders": [], "noninvitees": [], "expdate": 1526248800000, "cdate": 1518474081690}}}, {"tddate": null, "ddate": null, "tmdate": 1521750227701, "tcdate": 1521749923489, "number": 2, "cdate": 1521749923489, "id": "Syojk9Zcz", "invitation": "ICLR.cc/2018/Workshop/-/Paper223/Public_Comment", "forum": "B1rQtwJDG", "replyto": "HychENZcz", "signatures": ["~Rui_Shu1"], "readers": ["everyone"], "writers": ["~Rui_Shu1"], "content": {"title": "Very much in agreement", "comment": "Thank you, we really appreciated your feedback. \n\nRegarding what constitutes the \"same\" style and whether \"style\"+\"content\" preservation is admissible as a legitimate definition of disentanglement, we agree that such a notion of \"sameness\" of style is often times ill-defined. To give an even more extreme example: in CIFAR-10, it is very hard to intuit what it would mean for a plane and a cat to have the same style. The main reason we chose to experiment on the SVHN dataset is because of the numerous visual cues (color of background, foreground, thickness, rotation, serif/non-serif, etc) present that allow for easy human consensus on what constitutes a \"sameness\" of style.\n\nWe also agree that the literature has observed factorization to help with inducing disentanglement. We believe, however, that more care needs to be taken in determining what we know/do not know. For example: although the ablation test of (VAE objective + deep net + SGD) versus (VAE objective + deep net + SGD + factorization regularization) may confirm that adding factorization regularization is, under certain circumstances, casually related to disentanglement, our workshop paper exposes that a proper theory of why factorization seems to improve disentanglement remains elusive. \n\nTo end on a positive note, we believe this gap between our empirical observations and our theoretical understanding of what is and what causes disentanglement is exciting and worthy of careful consideration as a line of research."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Rethinking Style and Content Disentanglement in Variational Autoencoders", "abstract": "A common test for whether a generative model learns disentangled representations is its ability to learn style and content as independent factors of variation on digit datasets. To achieve such disentanglement with variational autoencoders, the label information is often provided in either a fully-supervised or semi-supervised fashion. We show, however, that the variational objective is insufficient in explaining the observed style and content disentanglement. Furthermore, we present an empirical framework to systematically evaluate the disentanglement behavior of our models. We show that the encoder and decoder independently favor disentangled representations and that this tendency depends on the implicit regularization by stochastic gradient descent.", "paperhash": "shu|rethinking_style_and_content_disentanglement_in_variational_autoencoders", "keywords": ["disentangled representation", "variational autoencoders", "deep representation prior"], "_bibtex": "@misc{\n  shu2018rethinking,\n  title={Rethinking Style and Content Disentanglement in Variational Autoencoders},\n  author={Rui Shu and Shengjia Zhao and Mykel J. Kochenderfer},\n  year={2018},\n  url={https://openreview.net/forum?id=B1rQtwJDG}\n}", "authorids": ["ruishu@stanford.edu", "sjzhao@stanford.edu", "mykel@stanford.edu"], "authors": ["Rui Shu", "Shengjia Zhao", "Mykel J. Kochenderfer"], "TL;DR": "Understanding deep representation learning requires rethinking disentanglement.", "pdf": "/pdf/eaa313302a9cd809ecdc8edd86f419305f5d14c1.pdf"}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "tmdate": 1518712624662, "id": "ICLR.cc/2018/Workshop/-/Paper223/Public_Comment", "writers": ["ICLR.cc/2018/Workshop"], "signatures": ["ICLR.cc/2018/Workshop"], "readers": ["everyone"], "invitees": ["~"], "noninvitees": ["ICLR.cc/2018/Workshop/Paper223/Reviewers"], "reply": {"replyto": null, "forum": "B1rQtwJDG", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone"]}, "content": {"title": {"required": true, "order": 0, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"required": true, "order": 1, "description": "Your comment or reply (max 5000 characters).", "value-regex": "[\\S\\s]{1,5000}"}}}, "nonreaders": [], "cdate": 1518712624662}}}, {"tddate": null, "ddate": null, "tmdate": 1521726641602, "tcdate": 1521726641602, "number": 1, "cdate": 1521726641602, "id": "HychENZcz", "invitation": "ICLR.cc/2018/Workshop/-/Paper223/Official_Comment", "forum": "B1rQtwJDG", "replyto": "SkMynsJ5M", "signatures": ["ICLR.cc/2018/Workshop/Paper223/AnonReviewer1"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Workshop/Paper223/AnonReviewer1"], "content": {"title": "Thanks for the response", "comment": "It is indeed true the factorization in itself does not guarantee disentanglement, depending on what definition of disentanglement one employs \u2013 and I should perhaps have expressed myself more carefully there. In practice however, there is strong evidence that factorization does help induce disentanglement, even if it is in itself not a sufficient condition.\n\nI also agree with the authors that the question of generating images with the \"same\" style z for different values of y is complicated. My understanding of your Proposition 1 is that you could have a VAE in which the marginals p(x) and q(x) are identical, as are the marginals p(y, z) and q(y, z), but does not associate the same style for a given value of z across different values of y. I think this observation is correct. \n\nThe reason why I put the \"same\" in quotes here is that I am perhaps not entirely convinced that a notion of same-ness is always well-defined. Clearly, for a dataset like MNIST there are 10 digit classes and it is easy to detect violation of invariance conditions with respect to y. For the style variables z, there are features such as stroke thickness and slant, for which invariance would be comparatively obvious upon inspection. On the other hand, for a dimension in z that characterizes variation in  2's (say, more or less \"curly\"), it is not less clear what the corresponding \"same\" style should be for, say, a 7. As such, I'm somewhat inclined to accept any model in which y and z are independent as a valid disentangled representation (which differs from the definition that the authors employ here).\n\nWhere I absolutely agree with the authors is that, in practice, the degree of parameter sharing in the encoder decoder framework plays a big role. In particular, I think that the authors make a very useful observation in noting that there is certainly no way to ensure that z values correspond to the \"same\" when we have encoders q(z | y=k, x, \u03c6_k) and p(x | y=k, z,  \u03b8_k) with distinct parameterizations \u03b8_k and \u03c6_k. "}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Rethinking Style and Content Disentanglement in Variational Autoencoders", "abstract": "A common test for whether a generative model learns disentangled representations is its ability to learn style and content as independent factors of variation on digit datasets. To achieve such disentanglement with variational autoencoders, the label information is often provided in either a fully-supervised or semi-supervised fashion. We show, however, that the variational objective is insufficient in explaining the observed style and content disentanglement. Furthermore, we present an empirical framework to systematically evaluate the disentanglement behavior of our models. We show that the encoder and decoder independently favor disentangled representations and that this tendency depends on the implicit regularization by stochastic gradient descent.", "paperhash": "shu|rethinking_style_and_content_disentanglement_in_variational_autoencoders", "keywords": ["disentangled representation", "variational autoencoders", "deep representation prior"], "_bibtex": "@misc{\n  shu2018rethinking,\n  title={Rethinking Style and Content Disentanglement in Variational Autoencoders},\n  author={Rui Shu and Shengjia Zhao and Mykel J. Kochenderfer},\n  year={2018},\n  url={https://openreview.net/forum?id=B1rQtwJDG}\n}", "authorids": ["ruishu@stanford.edu", "sjzhao@stanford.edu", "mykel@stanford.edu"], "authors": ["Rui Shu", "Shengjia Zhao", "Mykel J. Kochenderfer"], "TL;DR": "Understanding deep representation learning requires rethinking disentanglement.", "pdf": "/pdf/eaa313302a9cd809ecdc8edd86f419305f5d14c1.pdf"}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "tmdate": 1519222447298, "id": "ICLR.cc/2018/Workshop/-/Paper223/Official_Comment", "writers": ["ICLR.cc/2018/Workshop"], "signatures": ["ICLR.cc/2018/Workshop"], "readers": ["everyone"], "reply": {"replyto": null, "forum": "B1rQtwJDG", "writers": {"values-regex": "ICLR.cc/2018/Workshop/Paper223/AnonReviewer[0-9]+|ICLR.cc/2018/Workshop/Paper223/Authors|ICLR.cc/2018/Workshop/Program_Chairs"}, "signatures": {"values-regex": "ICLR.cc/2018/Workshop/Paper223/AnonReviewer[0-9]+|ICLR.cc/2018/Workshop/Paper223/Authors|ICLR.cc/2018/Workshop/Program_Chairs", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2018/Workshop/Program_Chairs"]}, "content": {"title": {"required": true, "order": 0, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"required": true, "order": 1, "description": "Your comment or reply (max 5000 characters).", "value-regex": "[\\S\\s]{1,5000}"}}}, "nonreaders": [], "noninvitees": [], "invitees": ["ICLR.cc/2018/Workshop/Paper223/Reviewers", "ICLR.cc/2018/Workshop/Paper223/Authors", "ICLR.cc/2018/Workshop/Program_Chairs"], "cdate": 1519222447298}}}, {"tddate": null, "ddate": null, "tmdate": 1521626838500, "tcdate": 1521626074216, "number": 1, "cdate": 1521626074216, "id": "SkMynsJ5M", "invitation": "ICLR.cc/2018/Workshop/-/Paper223/Public_Comment", "forum": "B1rQtwJDG", "replyto": "B1fIBiYtM", "signatures": ["~Rui_Shu1"], "readers": ["everyone"], "writers": ["~Rui_Shu1"], "content": {"title": "response", "comment": "Thank you for the review. While unstated in this workshop paper, one of our goals is to critique the belief that a factorized prior implies disentanglement.\n\nI would therefore like to inquire about your statement that learning \"a marginal distribution q(y, z) = q(y) q(z) that factorizes [...] implies the invariance conditions.\"\n\nConsider the proposal distribution q'(z, y | x) and entangled generator p'(x | y, z) described in Proposition 1. For simplicity, consider defining q'(x) as simply the density over x described by the joint model p'(x, y, z) = p'(x | z)p(z)p(y). Since q'(z, y | x) is constructed to be the true posterior for p'(x, y, z), and since we've defined q'(x) := p'(x), it is trivially true that \n\nq'(y, z) = q'(z)q'(y) = p(z)p(y),\n\nwhere q'(y, z) = int q'(x)q'(y, z | x) dx.\n\nHowever, by construction, the generative model p' entangles style and content. This provides the counter-example, showing that there exists some dataset (i.e. p_data(x) := q'(x)) for which factorization of q'(y, z) does not imply disentanglement (as defined in our paper).\n\nWe appreciate any feedback on flaws in this line of reasoning."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Rethinking Style and Content Disentanglement in Variational Autoencoders", "abstract": "A common test for whether a generative model learns disentangled representations is its ability to learn style and content as independent factors of variation on digit datasets. To achieve such disentanglement with variational autoencoders, the label information is often provided in either a fully-supervised or semi-supervised fashion. We show, however, that the variational objective is insufficient in explaining the observed style and content disentanglement. Furthermore, we present an empirical framework to systematically evaluate the disentanglement behavior of our models. We show that the encoder and decoder independently favor disentangled representations and that this tendency depends on the implicit regularization by stochastic gradient descent.", "paperhash": "shu|rethinking_style_and_content_disentanglement_in_variational_autoencoders", "keywords": ["disentangled representation", "variational autoencoders", "deep representation prior"], "_bibtex": "@misc{\n  shu2018rethinking,\n  title={Rethinking Style and Content Disentanglement in Variational Autoencoders},\n  author={Rui Shu and Shengjia Zhao and Mykel J. Kochenderfer},\n  year={2018},\n  url={https://openreview.net/forum?id=B1rQtwJDG}\n}", "authorids": ["ruishu@stanford.edu", "sjzhao@stanford.edu", "mykel@stanford.edu"], "authors": ["Rui Shu", "Shengjia Zhao", "Mykel J. Kochenderfer"], "TL;DR": "Understanding deep representation learning requires rethinking disentanglement.", "pdf": "/pdf/eaa313302a9cd809ecdc8edd86f419305f5d14c1.pdf"}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "tmdate": 1518712624662, "id": "ICLR.cc/2018/Workshop/-/Paper223/Public_Comment", "writers": ["ICLR.cc/2018/Workshop"], "signatures": ["ICLR.cc/2018/Workshop"], "readers": ["everyone"], "invitees": ["~"], "noninvitees": ["ICLR.cc/2018/Workshop/Paper223/Reviewers"], "reply": {"replyto": null, "forum": "B1rQtwJDG", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone"]}, "content": {"title": {"required": true, "order": 0, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"required": true, "order": 1, "description": "Your comment or reply (max 5000 characters).", "value-regex": "[\\S\\s]{1,5000}"}}}, "nonreaders": [], "cdate": 1518712624662}}}, {"tddate": null, "ddate": null, "original": null, "tmdate": 1521582722300, "tcdate": 1520681302579, "number": 1, "cdate": 1520681302579, "id": "rJkw-HbYG", "invitation": "ICLR.cc/2018/Workshop/-/Paper223/Official_Review", "forum": "B1rQtwJDG", "replyto": "B1rQtwJDG", "signatures": ["ICLR.cc/2018/Workshop/Paper223/AnonReviewer2"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Workshop/Paper223/AnonReviewer2"], "content": {"title": "Review", "rating": "7: Good paper, accept", "review": "The paper addresses the problem of learning representations that disentangle style from label information. A simple but important observation is made: the loss function used for training VAEs does not promote disentanglement, despite the obtained results. The authors empirically show the importance of the inductive bias provided by the shared parameters in the decoder or decoder for obtaining these results.\n\nThe paper is well written and provides several convincing experiments on a simple dataset.\n\nPlease provide details of the architectures used. Are the encoders/decoders used convolutional or MLPs? How would that affect the results?", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Rethinking Style and Content Disentanglement in Variational Autoencoders", "abstract": "A common test for whether a generative model learns disentangled representations is its ability to learn style and content as independent factors of variation on digit datasets. To achieve such disentanglement with variational autoencoders, the label information is often provided in either a fully-supervised or semi-supervised fashion. We show, however, that the variational objective is insufficient in explaining the observed style and content disentanglement. Furthermore, we present an empirical framework to systematically evaluate the disentanglement behavior of our models. We show that the encoder and decoder independently favor disentangled representations and that this tendency depends on the implicit regularization by stochastic gradient descent.", "paperhash": "shu|rethinking_style_and_content_disentanglement_in_variational_autoencoders", "keywords": ["disentangled representation", "variational autoencoders", "deep representation prior"], "_bibtex": "@misc{\n  shu2018rethinking,\n  title={Rethinking Style and Content Disentanglement in Variational Autoencoders},\n  author={Rui Shu and Shengjia Zhao and Mykel J. Kochenderfer},\n  year={2018},\n  url={https://openreview.net/forum?id=B1rQtwJDG}\n}", "authorids": ["ruishu@stanford.edu", "sjzhao@stanford.edu", "mykel@stanford.edu"], "authors": ["Rui Shu", "Shengjia Zhao", "Mykel J. Kochenderfer"], "TL;DR": "Understanding deep representation learning requires rethinking disentanglement.", "pdf": "/pdf/eaa313302a9cd809ecdc8edd86f419305f5d14c1.pdf"}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1520657999000, "tmdate": 1521582722115, "id": "ICLR.cc/2018/Workshop/-/Paper223/Official_Review", "writers": ["ICLR.cc/2018/Workshop"], "signatures": ["ICLR.cc/2018/Workshop"], "readers": ["everyone"], "invitees": ["ICLR.cc/2018/Workshop/Paper223/Reviewers"], "noninvitees": ["ICLR.cc/2018/Workshop/Paper223/AnonReviewer2", "ICLR.cc/2018/Workshop/Paper223/AnonReviewer3", "ICLR.cc/2018/Workshop/Paper223/AnonReviewer1"], "reply": {"forum": "B1rQtwJDG", "replyto": "B1rQtwJDG", "writers": {"values-regex": "ICLR.cc/2018/Workshop/Paper223/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2018/Workshop/Paper223/AnonReviewer[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"required": true, "order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"required": true, "order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "value-regex": "[\\S\\s]{1,200000}"}, "rating": {"required": true, "order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"required": true, "order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1528433999000, "cdate": 1521582722115}}}, {"tddate": null, "ddate": null, "original": null, "tmdate": 1521582629403, "tcdate": 1520820039959, "number": 2, "cdate": 1520820039959, "id": "HygIyD7FM", "invitation": "ICLR.cc/2018/Workshop/-/Paper223/Official_Review", "forum": "B1rQtwJDG", "replyto": "B1rQtwJDG", "signatures": ["ICLR.cc/2018/Workshop/Paper223/AnonReviewer3"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Workshop/Paper223/AnonReviewer3"], "content": {"title": "this paper studies the relationship between disentangling, SGD, loss and bias in architectures", "rating": "7: Good paper, accept", "review": "- This paper shows an interesting set of experiments investigating the causal relationship between disentangling and (SGD, loss). The claim is that regularization due to SGD is the main factor for disentanglement\n\n- If i am not mistaken, similar types of conclusion were shown in the beta VAE work (Higgins et al), where they show that disentangling is mostly due to the optimization process. It's good to see more studies of it and the paper should better reflect such prior works. \n\n- If its the optimization or inference is causing this, then training the neural net with other algorithms such as SPSA or other evolutionary methods is a good control test\n", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Rethinking Style and Content Disentanglement in Variational Autoencoders", "abstract": "A common test for whether a generative model learns disentangled representations is its ability to learn style and content as independent factors of variation on digit datasets. To achieve such disentanglement with variational autoencoders, the label information is often provided in either a fully-supervised or semi-supervised fashion. We show, however, that the variational objective is insufficient in explaining the observed style and content disentanglement. Furthermore, we present an empirical framework to systematically evaluate the disentanglement behavior of our models. We show that the encoder and decoder independently favor disentangled representations and that this tendency depends on the implicit regularization by stochastic gradient descent.", "paperhash": "shu|rethinking_style_and_content_disentanglement_in_variational_autoencoders", "keywords": ["disentangled representation", "variational autoencoders", "deep representation prior"], "_bibtex": "@misc{\n  shu2018rethinking,\n  title={Rethinking Style and Content Disentanglement in Variational Autoencoders},\n  author={Rui Shu and Shengjia Zhao and Mykel J. Kochenderfer},\n  year={2018},\n  url={https://openreview.net/forum?id=B1rQtwJDG}\n}", "authorids": ["ruishu@stanford.edu", "sjzhao@stanford.edu", "mykel@stanford.edu"], "authors": ["Rui Shu", "Shengjia Zhao", "Mykel J. Kochenderfer"], "TL;DR": "Understanding deep representation learning requires rethinking disentanglement.", "pdf": "/pdf/eaa313302a9cd809ecdc8edd86f419305f5d14c1.pdf"}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1520657999000, "tmdate": 1521582722115, "id": "ICLR.cc/2018/Workshop/-/Paper223/Official_Review", "writers": ["ICLR.cc/2018/Workshop"], "signatures": ["ICLR.cc/2018/Workshop"], "readers": ["everyone"], "invitees": ["ICLR.cc/2018/Workshop/Paper223/Reviewers"], "noninvitees": ["ICLR.cc/2018/Workshop/Paper223/AnonReviewer2", "ICLR.cc/2018/Workshop/Paper223/AnonReviewer3", "ICLR.cc/2018/Workshop/Paper223/AnonReviewer1"], "reply": {"forum": "B1rQtwJDG", "replyto": "B1rQtwJDG", "writers": {"values-regex": "ICLR.cc/2018/Workshop/Paper223/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2018/Workshop/Paper223/AnonReviewer[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"required": true, "order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"required": true, "order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "value-regex": "[\\S\\s]{1,200000}"}, "rating": {"required": true, "order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"required": true, "order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1528433999000, "cdate": 1521582722115}}}, {"tddate": null, "ddate": null, "original": null, "tmdate": 1521582587642, "tcdate": 1521231177596, "number": 3, "cdate": 1521231177596, "id": "B1fIBiYtM", "invitation": "ICLR.cc/2018/Workshop/-/Paper223/Official_Review", "forum": "B1rQtwJDG", "replyto": "B1rQtwJDG", "signatures": ["ICLR.cc/2018/Workshop/Paper223/AnonReviewer1"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Workshop/Paper223/AnonReviewer1"], "content": {"title": "A submission that provides some insights, but lacks some (very recent) references", "rating": "7: Good paper, accept", "review": "The authors explore the question why semi-supervised variational autoencoders that combine a discrete variable y with continuous variables z are able to disentangle style and content. They show that the variational objective admits solutions that have the same ELBO, but do not disentangle style and content. They look at architectures in contain separate encoders/decoders for each value y=k as a means of investigating which component of the model induces disentanglement. They additionally find some evidence to suggest that gradient descent converges more quickly towards an disentangled solution than an entangled one. \n\nThis is overall a very reasonable workshop contribution. My main comment would be that there are some (very recent) references missing from the discussion. These references point to the fact that we can decompose the ELBO into a number of terms, one of which takes the form of a total correlation (a higher-dimensional generalization of the mutual information) between latent variables under the marginal distribution \n\n    q(y, z) = 1/N \u03a3_n q(y,z | x^n)\n\nBased on this, a number of papers have emerged in which authors point out that we can successfully disentangle representations by emphasizing this total correlation term in the objective. This suggests, that, contrary to what the authors write in the abstract, the VAE objective *does* in fact contain a component that induces disentangled. More precisely put, in these models the prior  p(y, z) = p(y) p(z) factorizes. The VAE objective implicitly minimizes KL(q(y, z) || p(y) p(z)), which means that we should in principle learn a marginal distribution q(y, z) = q(y) q(z) that also factorizes, which implies the invariance conditions that the authors pose in section 1. \n\nThis aside, I see nothing wrong with this submission, and I am happy for it to appear, as long as the authors incorporate the references below, and perhaps include some discussion thereof.\n\nReferences\n\n1. Hoffman, M. D. & Johnson, M. J. Elbo surgery: yet another way to carve up the variational evidence lower bound. in Workshop in Advances in Approximate Bayesian Inference, NIPS (2016).\n\n2. Kim, H. & Mnih, A. Disentangling by factorising. arXiv preprint arXiv:1802.05983 (2018).\n\n3. Chen, T. Q., Li, X., Grosse, R. & Duvenaud, D. Isolating Sources of Disentanglement in Variational Autoencoders. arXiv:1802.04942 [cs, stat] (2018).\n\n4. Gao, S., Brekelmans, R., Steeg, G. V. & Galstyan, A. Auto-Encoding Total Correlation Explanation. arXiv:1802.05822 [cs, stat] (2018).", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Rethinking Style and Content Disentanglement in Variational Autoencoders", "abstract": "A common test for whether a generative model learns disentangled representations is its ability to learn style and content as independent factors of variation on digit datasets. To achieve such disentanglement with variational autoencoders, the label information is often provided in either a fully-supervised or semi-supervised fashion. We show, however, that the variational objective is insufficient in explaining the observed style and content disentanglement. Furthermore, we present an empirical framework to systematically evaluate the disentanglement behavior of our models. We show that the encoder and decoder independently favor disentangled representations and that this tendency depends on the implicit regularization by stochastic gradient descent.", "paperhash": "shu|rethinking_style_and_content_disentanglement_in_variational_autoencoders", "keywords": ["disentangled representation", "variational autoencoders", "deep representation prior"], "_bibtex": "@misc{\n  shu2018rethinking,\n  title={Rethinking Style and Content Disentanglement in Variational Autoencoders},\n  author={Rui Shu and Shengjia Zhao and Mykel J. Kochenderfer},\n  year={2018},\n  url={https://openreview.net/forum?id=B1rQtwJDG}\n}", "authorids": ["ruishu@stanford.edu", "sjzhao@stanford.edu", "mykel@stanford.edu"], "authors": ["Rui Shu", "Shengjia Zhao", "Mykel J. Kochenderfer"], "TL;DR": "Understanding deep representation learning requires rethinking disentanglement.", "pdf": "/pdf/eaa313302a9cd809ecdc8edd86f419305f5d14c1.pdf"}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1520657999000, "tmdate": 1521582722115, "id": "ICLR.cc/2018/Workshop/-/Paper223/Official_Review", "writers": ["ICLR.cc/2018/Workshop"], "signatures": ["ICLR.cc/2018/Workshop"], "readers": ["everyone"], "invitees": ["ICLR.cc/2018/Workshop/Paper223/Reviewers"], "noninvitees": ["ICLR.cc/2018/Workshop/Paper223/AnonReviewer2", "ICLR.cc/2018/Workshop/Paper223/AnonReviewer3", "ICLR.cc/2018/Workshop/Paper223/AnonReviewer1"], "reply": {"forum": "B1rQtwJDG", "replyto": "B1rQtwJDG", "writers": {"values-regex": "ICLR.cc/2018/Workshop/Paper223/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2018/Workshop/Paper223/AnonReviewer[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"required": true, "order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"required": true, "order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "value-regex": "[\\S\\s]{1,200000}"}, "rating": {"required": true, "order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"required": true, "order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1528433999000, "cdate": 1521582722115}}}, {"tddate": null, "ddate": null, "original": null, "tmdate": 1521573551870, "tcdate": 1521573551870, "number": 38, "cdate": 1521573551530, "id": "rJd3RARYf", "invitation": "ICLR.cc/2018/Workshop/-/Acceptance_Decision", "forum": "B1rQtwJDG", "replyto": "B1rQtwJDG", "signatures": ["ICLR.cc/2018/Workshop/Program_Chairs"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Workshop/Program_Chairs"], "content": {"decision": "Accept", "title": "ICLR 2018 Workshop Acceptance Decision", "comment": "Congratulations, your paper was accepted to the ICLR workshop."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Rethinking Style and Content Disentanglement in Variational Autoencoders", "abstract": "A common test for whether a generative model learns disentangled representations is its ability to learn style and content as independent factors of variation on digit datasets. To achieve such disentanglement with variational autoencoders, the label information is often provided in either a fully-supervised or semi-supervised fashion. We show, however, that the variational objective is insufficient in explaining the observed style and content disentanglement. Furthermore, we present an empirical framework to systematically evaluate the disentanglement behavior of our models. We show that the encoder and decoder independently favor disentangled representations and that this tendency depends on the implicit regularization by stochastic gradient descent.", "paperhash": "shu|rethinking_style_and_content_disentanglement_in_variational_autoencoders", "keywords": ["disentangled representation", "variational autoencoders", "deep representation prior"], "_bibtex": "@misc{\n  shu2018rethinking,\n  title={Rethinking Style and Content Disentanglement in Variational Autoencoders},\n  author={Rui Shu and Shengjia Zhao and Mykel J. Kochenderfer},\n  year={2018},\n  url={https://openreview.net/forum?id=B1rQtwJDG}\n}", "authorids": ["ruishu@stanford.edu", "sjzhao@stanford.edu", "mykel@stanford.edu"], "authors": ["Rui Shu", "Shengjia Zhao", "Mykel J. Kochenderfer"], "TL;DR": "Understanding deep representation learning requires rethinking disentanglement.", "pdf": "/pdf/eaa313302a9cd809ecdc8edd86f419305f5d14c1.pdf"}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "tmdate": 1518629844880, "id": "ICLR.cc/2018/Workshop/-/Acceptance_Decision", "writers": ["ICLR.cc/2018/Workshop"], "signatures": ["ICLR.cc/2018/Workshop"], "readers": ["everyone"], "invitees": ["ICLR.cc/2018/Workshop/Program_Chairs"], "reply": {"forum": null, "replyto": null, "invitation": "ICLR.cc/2018/Workshop/-/Submission", "writers": {"values": ["ICLR.cc/2018/Workshop/Program_Chairs"]}, "signatures": {"description": "How your identity will be displayed with the above content.", "values": ["ICLR.cc/2018/Workshop/Program_Chairs"]}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["ICLR.cc/2018/Workshop/Program_Chairs", "everyone"]}, "content": {"title": {"required": true, "order": 1, "value": "ICLR 2018 Workshop Acceptance Decision"}, "comment": {"required": false, "order": 3, "description": "(optional) Comment on this decision.", "value-regex": "[\\S\\s]{0,5000}"}, "decision": {"required": true, "order": 2, "value-dropdown": ["Accept", "Reject"]}}}, "nonreaders": [], "noninvitees": [], "cdate": 1518629844880}}}], "count": 8}