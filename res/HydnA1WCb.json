{"notes": [{"tddate": null, "ddate": null, "tmdate": 1518730173957, "tcdate": 1509125807568, "number": 538, "cdate": 1518730173945, "id": "HydnA1WCb", "invitation": "ICLR.cc/2018/Conference/-/Blind_Submission", "forum": "HydnA1WCb", "original": "H1P20JZA-", "signatures": ["ICLR.cc/2018/Conference"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Conference"], "content": {"title": "Gaussian Prototypical Networks for Few-Shot Learning on Omniglot", "abstract": "We propose a novel architecture for k-shot classification on the Omniglot dataset. Building on prototypical networks, we extend their architecture to what we call Gaussian prototypical networks. Prototypical networks learn a map between images and embedding vectors, and use their clustering for classification. In our model, a part of the encoder output is interpreted as a confidence region estimate about the embedding point, and expressed as a Gaussian covariance matrix. Our network then constructs a direction and class dependent distance metric on the embedding space, using uncertainties of individual data points as weights. We show that Gaussian prototypical networks are a preferred architecture over vanilla prototypical networks with an equivalent number of parameters. We report results consistent with state-of-the-art performance in 1-shot and 5-shot classification both in 5-way and 20-way regime on the Omniglot dataset. We explore artificially down-sampling a fraction of images in the training set, which improves our performance. Our experiments therefore lead us to hypothesize that Gaussian prototypical networks might perform better in less homogeneous, noisier datasets, which are commonplace in real world applications.", "pdf": "/pdf/b9dac8f84cc5e7f698a269a9f676e57e7747908d.pdf", "TL;DR": "A novel architecture for few-shot classification capable of dealing with uncertainty.", "paperhash": "fort|gaussian_prototypical_networks_for_fewshot_learning_on_omniglot", "_bibtex": "@misc{\nfort2018gaussian,\ntitle={Gaussian Prototypical Networks for Few-Shot Learning on Omniglot},\nauthor={Stanislav Fort},\nyear={2018},\nurl={https://openreview.net/forum?id=HydnA1WCb},\n}", "authors": ["Stanislav Fort"], "authorids": ["sfort1@stanford.edu"], "keywords": ["one-shot learning", "few-shot learning", "Omniglot"]}, "nonreaders": [], "details": {"replyCount": 4, "writable": false, "overwriting": [], "revisions": false, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "tmdate": 1506717071958, "id": "ICLR.cc/2018/Conference/-/Blind_Submission", "writers": ["ICLR.cc/2018/Conference"], "signatures": ["ICLR.cc/2018/Conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2018/Conference"], "reply": {"forum": null, "replyto": null, "writers": {"values": ["ICLR.cc/2018/Conference"]}, "signatures": {"description": "How your identity will be displayed with the above content.", "values": ["ICLR.cc/2018/Conference"]}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"authors": {"required": false, "order": 1, "values-regex": ".*", "description": "Comma separated list of author names, as they appear in the paper."}, "authorids": {"required": false, "order": 2, "values-regex": ".*", "description": "Comma separated list of author email addresses, in the same order as above."}}}, "nonreaders": [], "noninvitees": [], "cdate": 1506717071958}}, "tauthor": "ICLR.cc/2018/Conference"}, {"tddate": null, "ddate": null, "original": null, "tmdate": 1517260087129, "tcdate": 1517249787613, "number": 505, "cdate": 1517249787599, "id": "B1NZBkaBM", "invitation": "ICLR.cc/2018/Conference/-/Acceptance_Decision", "forum": "HydnA1WCb", "replyto": "HydnA1WCb", "signatures": ["ICLR.cc/2018/Conference/Program_Chairs"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Conference/Program_Chairs"], "content": {"decision": "Reject", "title": "ICLR 2018 Conference Acceptance Decision", "comment": "The reviewers agree that the idea of utilizing covariance information in the few-shot setting is interesting. There are concerns with the novelty of the paper, as well as the correctness in terms of ensuring the covariance matrix is PSD in all cases. There are some concerns with the experimental evaluation as well. In this area, Omniglot is a good sanity check, but other baseline datasets like miniImagenet are necessary to determine if this approach is truly useful."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Gaussian Prototypical Networks for Few-Shot Learning on Omniglot", "abstract": "We propose a novel architecture for k-shot classification on the Omniglot dataset. Building on prototypical networks, we extend their architecture to what we call Gaussian prototypical networks. Prototypical networks learn a map between images and embedding vectors, and use their clustering for classification. In our model, a part of the encoder output is interpreted as a confidence region estimate about the embedding point, and expressed as a Gaussian covariance matrix. Our network then constructs a direction and class dependent distance metric on the embedding space, using uncertainties of individual data points as weights. We show that Gaussian prototypical networks are a preferred architecture over vanilla prototypical networks with an equivalent number of parameters. We report results consistent with state-of-the-art performance in 1-shot and 5-shot classification both in 5-way and 20-way regime on the Omniglot dataset. We explore artificially down-sampling a fraction of images in the training set, which improves our performance. Our experiments therefore lead us to hypothesize that Gaussian prototypical networks might perform better in less homogeneous, noisier datasets, which are commonplace in real world applications.", "pdf": "/pdf/b9dac8f84cc5e7f698a269a9f676e57e7747908d.pdf", "TL;DR": "A novel architecture for few-shot classification capable of dealing with uncertainty.", "paperhash": "fort|gaussian_prototypical_networks_for_fewshot_learning_on_omniglot", "_bibtex": "@misc{\nfort2018gaussian,\ntitle={Gaussian Prototypical Networks for Few-Shot Learning on Omniglot},\nauthor={Stanislav Fort},\nyear={2018},\nurl={https://openreview.net/forum?id=HydnA1WCb},\n}", "authors": ["Stanislav Fort"], "authorids": ["sfort1@stanford.edu"], "keywords": ["one-shot learning", "few-shot learning", "Omniglot"]}, "tags": [], "invitation": {"id": "ICLR.cc/2018/Conference/-/Acceptance_Decision", "rdate": null, "ddate": null, "expdate": 1541175629000, "duedate": null, "tmdate": 1541177635767, "tddate": null, "super": null, "final": null, "reply": {"forum": null, "replyto": null, "invitation": "ICLR.cc/2018/Conference/-/Blind_Submission", "writers": {"values": ["ICLR.cc/2018/Conference/Program_Chairs"]}, "signatures": {"description": "How your identity will be displayed with the above content.", "values": ["ICLR.cc/2018/Conference/Program_Chairs"]}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["ICLR.cc/2018/Conference/Program_Chairs", "everyone"]}, "content": {"title": {"required": true, "order": 1, "value": "ICLR 2018 Conference Acceptance Decision"}, "comment": {"required": false, "order": 3, "description": "(optional) Comment on this decision.", "value-regex": "[\\S\\s]{0,5000}"}, "decision": {"required": true, "order": 2, "value-dropdown": ["Accept (Oral)", "Accept (Poster)", "Reject", "Invite to Workshop Track"]}}}, "signatures": ["ICLR.cc/2018/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": [], "noninvitees": [], "writers": ["ICLR.cc/2018/Conference"], "multiReply": null, "taskCompletionCount": null, "transform": null, "cdate": 1541177635767}}}, {"tddate": null, "ddate": null, "original": null, "tmdate": 1515642464229, "tcdate": 1511664429145, "number": 1, "cdate": 1511664429145, "id": "rkHVojvez", "invitation": "ICLR.cc/2018/Conference/-/Paper538/Official_Review", "forum": "HydnA1WCb", "replyto": "HydnA1WCb", "signatures": ["ICLR.cc/2018/Conference/Paper538/AnonReviewer2"], "readers": ["everyone"], "content": {"title": "An interesting direction, but the presentation is unclear at a few places, and need more experiments/analysis.", "rating": "4: Ok but not good enough - rejection", "review": "This paper presents an interesting extension to Snell et al.'s prototypical networks, by introducing uncertainty through a parameterised estimation of covariance along side the image embeddings (means). Uncertainty may be particularly important in the few-shot learning case this paper examines, when it is helpful to extract more information from limited number of input samples.\n\nHowever, several important concepts in the paper are not well explained or motivated. For example, it is a bit misleading to use the word \"covariance\" throughout the paper, when the best model only employs a scalar estimate of the variance. A related, and potentially technical problem is in computing the prototype's mean and variance (section 3.3). Eq. 5 and 6 are not well motivated, and the claim of \"optimal\" under eq.6 is not explained. More importantly, eq. 5 and 6 do not use any covariance information (off-diagonal elements of S) --- as a result, the model is likely to ignore the covariance structure even when using full covariance estimate. The distance function (eq. 4) is d Mahalanobis distance, instead of \"linear Euclidean distance\". While the paper emphasises the importance of the form of loss function, the loss function used in the model is given without explanation (and using cross-entropy over distances looks hacky).\n\nIn addition, the experiments are too limited to support the claimed benefits from encoding uncertainty. Since the accuracies on omniglot data from recent models are already close to perfect, it is unclear whether the marginally improved number reported here is significant. In addition, more analysis may better support existing claims. For example, showing subsampled images indeed had higher uncertainty, rather than only the histogram for all data points.\n\nPros:\n-Interesting problem and interesting direction.\n-Considers a number of possible alternative models\n-Intuitive illustration in Fig. 1\n\nCons:\n-Misleading use of \"covariance\"\n-The several important concepts including prototype mean/variance, distance, and loss are not well motivated or explained\n-Evaluation is too limited", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "writers": [], "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Gaussian Prototypical Networks for Few-Shot Learning on Omniglot", "abstract": "We propose a novel architecture for k-shot classification on the Omniglot dataset. Building on prototypical networks, we extend their architecture to what we call Gaussian prototypical networks. Prototypical networks learn a map between images and embedding vectors, and use their clustering for classification. In our model, a part of the encoder output is interpreted as a confidence region estimate about the embedding point, and expressed as a Gaussian covariance matrix. Our network then constructs a direction and class dependent distance metric on the embedding space, using uncertainties of individual data points as weights. We show that Gaussian prototypical networks are a preferred architecture over vanilla prototypical networks with an equivalent number of parameters. We report results consistent with state-of-the-art performance in 1-shot and 5-shot classification both in 5-way and 20-way regime on the Omniglot dataset. We explore artificially down-sampling a fraction of images in the training set, which improves our performance. Our experiments therefore lead us to hypothesize that Gaussian prototypical networks might perform better in less homogeneous, noisier datasets, which are commonplace in real world applications.", "pdf": "/pdf/b9dac8f84cc5e7f698a269a9f676e57e7747908d.pdf", "TL;DR": "A novel architecture for few-shot classification capable of dealing with uncertainty.", "paperhash": "fort|gaussian_prototypical_networks_for_fewshot_learning_on_omniglot", "_bibtex": "@misc{\nfort2018gaussian,\ntitle={Gaussian Prototypical Networks for Few-Shot Learning on Omniglot},\nauthor={Stanislav Fort},\nyear={2018},\nurl={https://openreview.net/forum?id=HydnA1WCb},\n}", "authors": ["Stanislav Fort"], "authorids": ["sfort1@stanford.edu"], "keywords": ["one-shot learning", "few-shot learning", "Omniglot"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1511845199000, "tmdate": 1515642464127, "id": "ICLR.cc/2018/Conference/-/Paper538/Official_Review", "writers": ["ICLR.cc/2018/Conference"], "signatures": ["ICLR.cc/2018/Conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2018/Conference/Paper538/Reviewers"], "noninvitees": ["ICLR.cc/2018/Conference/Paper538/AnonReviewer2", "ICLR.cc/2018/Conference/Paper538/AnonReviewer1", "ICLR.cc/2018/Conference/Paper538/AnonReviewer3"], "reply": {"forum": "HydnA1WCb", "replyto": "HydnA1WCb", "writers": {"values": []}, "signatures": {"values-regex": "ICLR.cc/2018/Conference/Paper538/AnonReviewer[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"required": true, "order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"required": true, "order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "value-regex": "[\\S\\s]{1,200000}"}, "rating": {"required": true, "order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"required": true, "order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1519621199000, "cdate": 1515642464127}}}, {"tddate": null, "ddate": null, "original": null, "tmdate": 1515642464183, "tcdate": 1511726813724, "number": 2, "cdate": 1511726813724, "id": "r1LJyjOlM", "invitation": "ICLR.cc/2018/Conference/-/Paper538/Official_Review", "forum": "HydnA1WCb", "replyto": "HydnA1WCb", "signatures": ["ICLR.cc/2018/Conference/Paper538/AnonReviewer1"], "readers": ["everyone"], "content": {"title": "Extension of prototypical networks of Snell et al. NIPS 2017 to learn a metric matrix per instance in addition to the instance projection. ", "rating": "3: Clear rejection", "review": "The paper extends the prototypical networks of Snell et al, NIPS 2017 for one shot learning. Snell et al use a soft kNN classification rule, typically used in standard metric learning work (e.g. NCA, MCML), over learned instance projections, i.e. distances are computed over the learned projections. Each class is represented by a class prototype which is given by the average of the projections of the class instances. Classification is done with soft k-NN on the class prototypes. The distance that is used is the Euclidean distance over the learned representations, i.e. (z-c)^T(z-c), where z is the projection of the x instance to be classified and c is a class prototype, computed as the average of the projections of the support instances of a given class.\n\nThe present paper extends the above work to include the learning of a Mahalanobis matrix, S, for each instance, in addition to learning its projection. Thus now the classification is based on the Mahalanobis distance: (z-c)^T S_c (z-c). On a conceptual level since S_c should be a PSD matrix it can be written as the square of some matrix, i.e. S_c = A_c^TA_c, then the Mahanalobis distance becomes (A_c z - A_c c)^T ( A_c z-A_c c), i.e. in addition to learning a projection as it is done in Snell et al, the authors now learn also a linear transformation matrix which is a function of the support points (i.e. the ones which give rise to the class prototypes). The interesting part here is that the linear projection is a function of the support points. I wonder though if such a transformation could not be learned by the vanilla prototypical networks simply by learning now a projection matrix A_z as a function of the query point z. I am not sure I see any reason why the vanilla prototypical networks cannot learn to project x directly to A_z z and why one would need to do this indirectly through the use of the Mahalanobis distance as proposed in this paper.\n\nOn a more technical level the properties of the learned Mahalanobis matrix, i.e. the fact that it should be PSD, are not really discussed neither how this can be enforced especially in the case where S is a full matrix (even though the authors state that this method was not further explored). If S is diagonal then the S generation methods a) b) c) in the end of section 3.1 will make sure that S is PSD, I do not think that this is the case with d) though.\n\nIn the definition of the prototypes the component wise weigthing (eq. 5) works when the Mahalanobis matrix is diagonal (even though the weighting should be done by the \\sqrt of it), how would it work if it was a full matrix is not clear.\n\nOn the experiments side the authors could have also experimented with miniImageNet and not only omniglot as is the standard practice in one shot learning papers. \n\nI am not sure I understand figure 3 in which the authors try to see what happens if instead of learning the Mahalanobis matrix one would learn a projection that would have as many additional dimensions as free elements in the Mahalanobis matrix. I would expect to see a comparison of the vanilla prototypical nets against their method for each one of the different scenarios of the free parameters of the S matrix, something like a ratio of accuracies of the two methods in order to establish whether learning the Mahalanobis matrix brings an improvement over the prototypical nets with an equal number of output parameters.  \n\n", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "writers": [], "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Gaussian Prototypical Networks for Few-Shot Learning on Omniglot", "abstract": "We propose a novel architecture for k-shot classification on the Omniglot dataset. Building on prototypical networks, we extend their architecture to what we call Gaussian prototypical networks. Prototypical networks learn a map between images and embedding vectors, and use their clustering for classification. In our model, a part of the encoder output is interpreted as a confidence region estimate about the embedding point, and expressed as a Gaussian covariance matrix. Our network then constructs a direction and class dependent distance metric on the embedding space, using uncertainties of individual data points as weights. We show that Gaussian prototypical networks are a preferred architecture over vanilla prototypical networks with an equivalent number of parameters. We report results consistent with state-of-the-art performance in 1-shot and 5-shot classification both in 5-way and 20-way regime on the Omniglot dataset. We explore artificially down-sampling a fraction of images in the training set, which improves our performance. Our experiments therefore lead us to hypothesize that Gaussian prototypical networks might perform better in less homogeneous, noisier datasets, which are commonplace in real world applications.", "pdf": "/pdf/b9dac8f84cc5e7f698a269a9f676e57e7747908d.pdf", "TL;DR": "A novel architecture for few-shot classification capable of dealing with uncertainty.", "paperhash": "fort|gaussian_prototypical_networks_for_fewshot_learning_on_omniglot", "_bibtex": "@misc{\nfort2018gaussian,\ntitle={Gaussian Prototypical Networks for Few-Shot Learning on Omniglot},\nauthor={Stanislav Fort},\nyear={2018},\nurl={https://openreview.net/forum?id=HydnA1WCb},\n}", "authors": ["Stanislav Fort"], "authorids": ["sfort1@stanford.edu"], "keywords": ["one-shot learning", "few-shot learning", "Omniglot"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1511845199000, "tmdate": 1515642464127, "id": "ICLR.cc/2018/Conference/-/Paper538/Official_Review", "writers": ["ICLR.cc/2018/Conference"], "signatures": ["ICLR.cc/2018/Conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2018/Conference/Paper538/Reviewers"], "noninvitees": ["ICLR.cc/2018/Conference/Paper538/AnonReviewer2", "ICLR.cc/2018/Conference/Paper538/AnonReviewer1", "ICLR.cc/2018/Conference/Paper538/AnonReviewer3"], "reply": {"forum": "HydnA1WCb", "replyto": "HydnA1WCb", "writers": {"values": []}, "signatures": {"values-regex": "ICLR.cc/2018/Conference/Paper538/AnonReviewer[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"required": true, "order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"required": true, "order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "value-regex": "[\\S\\s]{1,200000}"}, "rating": {"required": true, "order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"required": true, "order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1519621199000, "cdate": 1515642464127}}}, {"tddate": null, "ddate": null, "original": null, "tmdate": 1515642464143, "tcdate": 1511804290519, "number": 3, "cdate": 1511804290519, "id": "BJ9tT6Fxz", "invitation": "ICLR.cc/2018/Conference/-/Paper538/Official_Review", "forum": "HydnA1WCb", "replyto": "HydnA1WCb", "signatures": ["ICLR.cc/2018/Conference/Paper538/AnonReviewer3"], "readers": ["everyone"], "content": {"title": "A potentially interesting idea for modelling uncertainty in prototype learning is proposed. However, the novelty of the the method is unclear,and the motivation is a bit confusing. Unfortunately, the experiments contain only one specific datasets, and the significance of the results is difficult to interpret. ", "rating": "3: Clear rejection", "review": "SUMMARY: This work is about prototype networks for image classification. The idea is to jointly embed an image and a \"confidence measure\" into a latent space, and to use these embeddings to define prototypes together with confidence estimates. A Gaussian model is used for representing these confidences as covariance matrices. Within a class, the inverse covariance matrices of all corresponding images are averaged to for the inverse class-specific matrix S-C, and this S_C defines the tensor in the Mahalanobis metric for measuring the distances to the prototype.  \n\nEVALUATION:\nCLARITY: I found the paper difficult to read. In principle, the idea seems to be clear, but then the description and motivation of the model remains very vague. For instance, what is the the precise meaning of an image-specific covariance matrix (supported by just one point)? What is the motivation to just average the inverse covariance matrices to compute S_C? Why isn't the covariance matrix estimated in the usual way as the empirical covariance in the embedding space? \nNOVELTY: Honestly, I had difficulties to see which parts of this work could be sufficiently novel. The idea of using a Gaussian model and its associated Mahalanobis metric is certainly interesting, but also a time-honored concept. The experiments focus very specifically on the omniglot dataset, and it is not entirely clear to me what  should be concluded from the results presented. Are you sure that there is any significant improvement over the models in (Snell et al, Mishra et al, Munkhandalai & Yu, Finn et al.)?   \n\n\n", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "writers": [], "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Gaussian Prototypical Networks for Few-Shot Learning on Omniglot", "abstract": "We propose a novel architecture for k-shot classification on the Omniglot dataset. Building on prototypical networks, we extend their architecture to what we call Gaussian prototypical networks. Prototypical networks learn a map between images and embedding vectors, and use their clustering for classification. In our model, a part of the encoder output is interpreted as a confidence region estimate about the embedding point, and expressed as a Gaussian covariance matrix. Our network then constructs a direction and class dependent distance metric on the embedding space, using uncertainties of individual data points as weights. We show that Gaussian prototypical networks are a preferred architecture over vanilla prototypical networks with an equivalent number of parameters. We report results consistent with state-of-the-art performance in 1-shot and 5-shot classification both in 5-way and 20-way regime on the Omniglot dataset. We explore artificially down-sampling a fraction of images in the training set, which improves our performance. Our experiments therefore lead us to hypothesize that Gaussian prototypical networks might perform better in less homogeneous, noisier datasets, which are commonplace in real world applications.", "pdf": "/pdf/b9dac8f84cc5e7f698a269a9f676e57e7747908d.pdf", "TL;DR": "A novel architecture for few-shot classification capable of dealing with uncertainty.", "paperhash": "fort|gaussian_prototypical_networks_for_fewshot_learning_on_omniglot", "_bibtex": "@misc{\nfort2018gaussian,\ntitle={Gaussian Prototypical Networks for Few-Shot Learning on Omniglot},\nauthor={Stanislav Fort},\nyear={2018},\nurl={https://openreview.net/forum?id=HydnA1WCb},\n}", "authors": ["Stanislav Fort"], "authorids": ["sfort1@stanford.edu"], "keywords": ["one-shot learning", "few-shot learning", "Omniglot"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1511845199000, "tmdate": 1515642464127, "id": "ICLR.cc/2018/Conference/-/Paper538/Official_Review", "writers": ["ICLR.cc/2018/Conference"], "signatures": ["ICLR.cc/2018/Conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2018/Conference/Paper538/Reviewers"], "noninvitees": ["ICLR.cc/2018/Conference/Paper538/AnonReviewer2", "ICLR.cc/2018/Conference/Paper538/AnonReviewer1", "ICLR.cc/2018/Conference/Paper538/AnonReviewer3"], "reply": {"forum": "HydnA1WCb", "replyto": "HydnA1WCb", "writers": {"values": []}, "signatures": {"values-regex": "ICLR.cc/2018/Conference/Paper538/AnonReviewer[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"required": true, "order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"required": true, "order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "value-regex": "[\\S\\s]{1,200000}"}, "rating": {"required": true, "order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"required": true, "order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1519621199000, "cdate": 1515642464127}}}], "count": 5}