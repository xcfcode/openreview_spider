{"notes": [{"id": "BVPowUU1cR", "original": "bDJPz5uySR", "number": 1322, "cdate": 1601308147621, "ddate": null, "tcdate": 1601308147621, "tmdate": 1614985749834, "tddate": null, "forum": "BVPowUU1cR", "replyto": null, "invitation": "ICLR.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Assisting the Adversary to Improve GAN Training", "authorids": ["~Andreas_Munk1", "~William_Harvey1", "~Frank_Wood2"], "authors": ["Andreas Munk", "William Harvey", "Frank Wood"], "keywords": ["Generative Adversarial Networks", "GANs"], "abstract": "Some of the most popular methods for improving the stability and performance of GANs involve constraining or regularizing the discriminator. In this paper we consider a largely overlooked regularization technique which we refer to as the Adversary's Assistant (AdvAs). We motivate this using a different perspective to that of prior work. Specifically, we consider a common mismatch between theoretical analysis and practice: analysis often assumes that the discriminator reaches its optimum on each iteration. In practice, this is essentially never true, often leading to poor gradient estimates for the generator. To address this, AdvAs is a theoretically motivated penalty imposed on the generator based on the norm of the gradients used to train the discriminator. This encourages the generator to move towards points where the discriminator is optimal. We demonstrate the effect of applying AdvAs to several GAN objectives, datasets and network architectures. The results indicate a reduction in the mismatch between theory and practice and that AdvAs can lead to improvement of GAN training, as measured by FID scores.\n", "one-sentence_summary": "We propose a method for improved training of generative adversarial networks (GANs) by regularizing the updates on the generator.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "munk|assisting_the_adversary_to_improve_gan_training", "supplementary_material": "/attachment/b5fb0a999be989514622d29c02ab49eed4827a01.zip", "pdf": "/pdf/fff3a6d4387d4d6b13deb7f54af8f65b7c9ca789.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=PFl61vZW-b", "_bibtex": "@misc{\nmunk2021assisting,\ntitle={Assisting the Adversary to Improve {\\{}GAN{\\}} Training},\nauthor={Andreas Munk and William Harvey and Frank Wood},\nyear={2021},\nurl={https://openreview.net/forum?id=BVPowUU1cR}\n}"}, "signatures": ["ICLR.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference"], "details": {"replyCount": 10, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"reply": {"readers": {"values-regex": ".*"}, "writers": {"values": ["ICLR.cc/2021/Conference"]}, "signatures": {"values": ["ICLR.cc/2021/Conference"]}, "content": {"authors": {"values": ["Anonymous"]}, "authorids": {"values-regex": ".*"}, "reviewed_version_(pdf)": {"required": false, "description": "Upload a PDF file that ends with .pdf", "value-regex": ".*"}}}, "signatures": ["ICLR.cc/2021/Conference"], "readers": ["everyone"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["~", "OpenReview.net/Support"], "tcdate": 1601308008205, "tmdate": 1614984599368, "id": "ICLR.cc/2021/Conference/-/Blind_Submission"}}, "tauthor": "OpenReview.net"}, {"id": "k1mFVn3bgmh", "original": null, "number": 1, "cdate": 1610040386036, "ddate": null, "tcdate": 1610040386036, "tmdate": 1610473979602, "tddate": null, "forum": "BVPowUU1cR", "replyto": "BVPowUU1cR", "invitation": "ICLR.cc/2021/Conference/Paper1322/-/Decision", "content": {"title": "Final Decision", "decision": "Reject", "comment": "The paper received low ratings and the reviewers pointed out a number of issues. The authors' short response failed to address these concerns. "}, "signatures": ["ICLR.cc/2021/Conference/Program_Chairs"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference/Program_Chairs"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Assisting the Adversary to Improve GAN Training", "authorids": ["~Andreas_Munk1", "~William_Harvey1", "~Frank_Wood2"], "authors": ["Andreas Munk", "William Harvey", "Frank Wood"], "keywords": ["Generative Adversarial Networks", "GANs"], "abstract": "Some of the most popular methods for improving the stability and performance of GANs involve constraining or regularizing the discriminator. In this paper we consider a largely overlooked regularization technique which we refer to as the Adversary's Assistant (AdvAs). We motivate this using a different perspective to that of prior work. Specifically, we consider a common mismatch between theoretical analysis and practice: analysis often assumes that the discriminator reaches its optimum on each iteration. In practice, this is essentially never true, often leading to poor gradient estimates for the generator. To address this, AdvAs is a theoretically motivated penalty imposed on the generator based on the norm of the gradients used to train the discriminator. This encourages the generator to move towards points where the discriminator is optimal. We demonstrate the effect of applying AdvAs to several GAN objectives, datasets and network architectures. The results indicate a reduction in the mismatch between theory and practice and that AdvAs can lead to improvement of GAN training, as measured by FID scores.\n", "one-sentence_summary": "We propose a method for improved training of generative adversarial networks (GANs) by regularizing the updates on the generator.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "munk|assisting_the_adversary_to_improve_gan_training", "supplementary_material": "/attachment/b5fb0a999be989514622d29c02ab49eed4827a01.zip", "pdf": "/pdf/fff3a6d4387d4d6b13deb7f54af8f65b7c9ca789.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=PFl61vZW-b", "_bibtex": "@misc{\nmunk2021assisting,\ntitle={Assisting the Adversary to Improve {\\{}GAN{\\}} Training},\nauthor={Andreas Munk and William Harvey and Frank Wood},\nyear={2021},\nurl={https://openreview.net/forum?id=BVPowUU1cR}\n}"}, "tags": [], "invitation": {"reply": {"forum": "BVPowUU1cR", "replyto": "BVPowUU1cR", "readers": {"values": ["everyone"]}, "writers": {"values": ["ICLR.cc/2021/Conference/Program_Chairs"]}, "signatures": {"values": ["ICLR.cc/2021/Conference/Program_Chairs"]}, "content": {"title": {"value": "Final Decision"}, "decision": {"value-radio": ["Accept (Oral)", "Accept (Spotlight)", "Accept (Poster)", "Reject"]}, "comment": {"value-regex": "[\\S\\s]{0,50000}", "markdown": true}}}, "multiReply": false, "signatures": ["ICLR.cc/2021/Conference"], "readers": ["everyone"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Program_Chairs"], "tcdate": 1610040386022, "tmdate": 1610473979585, "id": "ICLR.cc/2021/Conference/Paper1322/-/Decision"}}}, {"id": "YDqZJM49gxP", "original": null, "number": 6, "cdate": 1606264338739, "ddate": null, "tcdate": 1606264338739, "tmdate": 1606264338739, "tddate": null, "forum": "BVPowUU1cR", "replyto": "vySURmuERV7", "invitation": "ICLR.cc/2021/Conference/Paper1322/-/Official_Comment", "content": {"title": "Thank you for your thorough review", "comment": "- We thank you for referring us to this prior work, and refer to our the general comments above as well as the revised paper for a discussion and our repositioning.\n\n- Regarding \"well known that the gradient vanishing problem may appear if one train the discriminator to optimality\": This is not true for WGAN and its variations, which we used in this paper. It certainly can be for the original GAN.\n\n- Thank you for pointing out our error in Eq. (1). It has been corrected.\n"}, "signatures": ["ICLR.cc/2021/Conference/Paper1322/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1322/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Assisting the Adversary to Improve GAN Training", "authorids": ["~Andreas_Munk1", "~William_Harvey1", "~Frank_Wood2"], "authors": ["Andreas Munk", "William Harvey", "Frank Wood"], "keywords": ["Generative Adversarial Networks", "GANs"], "abstract": "Some of the most popular methods for improving the stability and performance of GANs involve constraining or regularizing the discriminator. In this paper we consider a largely overlooked regularization technique which we refer to as the Adversary's Assistant (AdvAs). We motivate this using a different perspective to that of prior work. Specifically, we consider a common mismatch between theoretical analysis and practice: analysis often assumes that the discriminator reaches its optimum on each iteration. In practice, this is essentially never true, often leading to poor gradient estimates for the generator. To address this, AdvAs is a theoretically motivated penalty imposed on the generator based on the norm of the gradients used to train the discriminator. This encourages the generator to move towards points where the discriminator is optimal. We demonstrate the effect of applying AdvAs to several GAN objectives, datasets and network architectures. The results indicate a reduction in the mismatch between theory and practice and that AdvAs can lead to improvement of GAN training, as measured by FID scores.\n", "one-sentence_summary": "We propose a method for improved training of generative adversarial networks (GANs) by regularizing the updates on the generator.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "munk|assisting_the_adversary_to_improve_gan_training", "supplementary_material": "/attachment/b5fb0a999be989514622d29c02ab49eed4827a01.zip", "pdf": "/pdf/fff3a6d4387d4d6b13deb7f54af8f65b7c9ca789.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=PFl61vZW-b", "_bibtex": "@misc{\nmunk2021assisting,\ntitle={Assisting the Adversary to Improve {\\{}GAN{\\}} Training},\nauthor={Andreas Munk and William Harvey and Frank Wood},\nyear={2021},\nurl={https://openreview.net/forum?id=BVPowUU1cR}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "BVPowUU1cR", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper1322/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper1322/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper1322/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper1322/Authors|ICLR.cc/2021/Conference/Paper1322/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1322/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923861074, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper1322/-/Official_Comment"}}}, {"id": "9dtCbl5koWR", "original": null, "number": 5, "cdate": 1606264109817, "ddate": null, "tcdate": 1606264109817, "tmdate": 1606264109817, "tddate": null, "forum": "BVPowUU1cR", "replyto": "dZdPaNTbNxZ", "invitation": "ICLR.cc/2021/Conference/Paper1322/-/Official_Comment", "content": {"title": "Thank you for your thorough review", "comment": "Thank you for appreciating the value our paper brings in terms of exposition. We also thank you for bringing the prior work (both of them) to our attention. As we write for reviewer #2 and in the general comments, we have addressed this in the revised paper and point out that we seek to provide further evidence and bring a new motivation as to why AdvAs is an appropriate regularizer to use."}, "signatures": ["ICLR.cc/2021/Conference/Paper1322/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1322/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Assisting the Adversary to Improve GAN Training", "authorids": ["~Andreas_Munk1", "~William_Harvey1", "~Frank_Wood2"], "authors": ["Andreas Munk", "William Harvey", "Frank Wood"], "keywords": ["Generative Adversarial Networks", "GANs"], "abstract": "Some of the most popular methods for improving the stability and performance of GANs involve constraining or regularizing the discriminator. In this paper we consider a largely overlooked regularization technique which we refer to as the Adversary's Assistant (AdvAs). We motivate this using a different perspective to that of prior work. Specifically, we consider a common mismatch between theoretical analysis and practice: analysis often assumes that the discriminator reaches its optimum on each iteration. In practice, this is essentially never true, often leading to poor gradient estimates for the generator. To address this, AdvAs is a theoretically motivated penalty imposed on the generator based on the norm of the gradients used to train the discriminator. This encourages the generator to move towards points where the discriminator is optimal. We demonstrate the effect of applying AdvAs to several GAN objectives, datasets and network architectures. The results indicate a reduction in the mismatch between theory and practice and that AdvAs can lead to improvement of GAN training, as measured by FID scores.\n", "one-sentence_summary": "We propose a method for improved training of generative adversarial networks (GANs) by regularizing the updates on the generator.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "munk|assisting_the_adversary_to_improve_gan_training", "supplementary_material": "/attachment/b5fb0a999be989514622d29c02ab49eed4827a01.zip", "pdf": "/pdf/fff3a6d4387d4d6b13deb7f54af8f65b7c9ca789.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=PFl61vZW-b", "_bibtex": "@misc{\nmunk2021assisting,\ntitle={Assisting the Adversary to Improve {\\{}GAN{\\}} Training},\nauthor={Andreas Munk and William Harvey and Frank Wood},\nyear={2021},\nurl={https://openreview.net/forum?id=BVPowUU1cR}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "BVPowUU1cR", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper1322/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper1322/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper1322/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper1322/Authors|ICLR.cc/2021/Conference/Paper1322/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1322/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923861074, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper1322/-/Official_Comment"}}}, {"id": "n6b_wJ90gyF", "original": null, "number": 4, "cdate": 1606263986875, "ddate": null, "tcdate": 1606263986875, "tmdate": 1606263986875, "tddate": null, "forum": "BVPowUU1cR", "replyto": "vUFWPEcVtf9", "invitation": "ICLR.cc/2021/Conference/Paper1322/-/Official_Comment", "content": {"title": "Regarding prior work", "comment": "Thank you for pointing us to the referred prior work (please see general comments). We have edited the paper to address this and better position our work. We seek to provide further evidence and bring a new motivation as to why AdvAs is an appropriate regularizer to use.\n"}, "signatures": ["ICLR.cc/2021/Conference/Paper1322/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1322/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Assisting the Adversary to Improve GAN Training", "authorids": ["~Andreas_Munk1", "~William_Harvey1", "~Frank_Wood2"], "authors": ["Andreas Munk", "William Harvey", "Frank Wood"], "keywords": ["Generative Adversarial Networks", "GANs"], "abstract": "Some of the most popular methods for improving the stability and performance of GANs involve constraining or regularizing the discriminator. In this paper we consider a largely overlooked regularization technique which we refer to as the Adversary's Assistant (AdvAs). We motivate this using a different perspective to that of prior work. Specifically, we consider a common mismatch between theoretical analysis and practice: analysis often assumes that the discriminator reaches its optimum on each iteration. In practice, this is essentially never true, often leading to poor gradient estimates for the generator. To address this, AdvAs is a theoretically motivated penalty imposed on the generator based on the norm of the gradients used to train the discriminator. This encourages the generator to move towards points where the discriminator is optimal. We demonstrate the effect of applying AdvAs to several GAN objectives, datasets and network architectures. The results indicate a reduction in the mismatch between theory and practice and that AdvAs can lead to improvement of GAN training, as measured by FID scores.\n", "one-sentence_summary": "We propose a method for improved training of generative adversarial networks (GANs) by regularizing the updates on the generator.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "munk|assisting_the_adversary_to_improve_gan_training", "supplementary_material": "/attachment/b5fb0a999be989514622d29c02ab49eed4827a01.zip", "pdf": "/pdf/fff3a6d4387d4d6b13deb7f54af8f65b7c9ca789.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=PFl61vZW-b", "_bibtex": "@misc{\nmunk2021assisting,\ntitle={Assisting the Adversary to Improve {\\{}GAN{\\}} Training},\nauthor={Andreas Munk and William Harvey and Frank Wood},\nyear={2021},\nurl={https://openreview.net/forum?id=BVPowUU1cR}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "BVPowUU1cR", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper1322/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper1322/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper1322/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper1322/Authors|ICLR.cc/2021/Conference/Paper1322/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1322/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923861074, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper1322/-/Official_Comment"}}}, {"id": "6GAIJ81Ipsg", "original": null, "number": 3, "cdate": 1606263874496, "ddate": null, "tcdate": 1606263874496, "tmdate": 1606263874496, "tddate": null, "forum": "BVPowUU1cR", "replyto": "l83gld8C01", "invitation": "ICLR.cc/2021/Conference/Paper1322/-/Official_Comment", "content": {"title": "Thank you for your helpful comments", "comment": "In the response to the first question regarding the batch size: we found that AdvAs was quite robust with respect to the batch size. Without performing any systematic search over the batch size, we did not find any particular sensitivity to it when comparing with and without AdvAs."}, "signatures": ["ICLR.cc/2021/Conference/Paper1322/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1322/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Assisting the Adversary to Improve GAN Training", "authorids": ["~Andreas_Munk1", "~William_Harvey1", "~Frank_Wood2"], "authors": ["Andreas Munk", "William Harvey", "Frank Wood"], "keywords": ["Generative Adversarial Networks", "GANs"], "abstract": "Some of the most popular methods for improving the stability and performance of GANs involve constraining or regularizing the discriminator. In this paper we consider a largely overlooked regularization technique which we refer to as the Adversary's Assistant (AdvAs). We motivate this using a different perspective to that of prior work. Specifically, we consider a common mismatch between theoretical analysis and practice: analysis often assumes that the discriminator reaches its optimum on each iteration. In practice, this is essentially never true, often leading to poor gradient estimates for the generator. To address this, AdvAs is a theoretically motivated penalty imposed on the generator based on the norm of the gradients used to train the discriminator. This encourages the generator to move towards points where the discriminator is optimal. We demonstrate the effect of applying AdvAs to several GAN objectives, datasets and network architectures. The results indicate a reduction in the mismatch between theory and practice and that AdvAs can lead to improvement of GAN training, as measured by FID scores.\n", "one-sentence_summary": "We propose a method for improved training of generative adversarial networks (GANs) by regularizing the updates on the generator.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "munk|assisting_the_adversary_to_improve_gan_training", "supplementary_material": "/attachment/b5fb0a999be989514622d29c02ab49eed4827a01.zip", "pdf": "/pdf/fff3a6d4387d4d6b13deb7f54af8f65b7c9ca789.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=PFl61vZW-b", "_bibtex": "@misc{\nmunk2021assisting,\ntitle={Assisting the Adversary to Improve {\\{}GAN{\\}} Training},\nauthor={Andreas Munk and William Harvey and Frank Wood},\nyear={2021},\nurl={https://openreview.net/forum?id=BVPowUU1cR}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "BVPowUU1cR", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper1322/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper1322/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper1322/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper1322/Authors|ICLR.cc/2021/Conference/Paper1322/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1322/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923861074, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper1322/-/Official_Comment"}}}, {"id": "-tMUN34gS6", "original": null, "number": 2, "cdate": 1606263405804, "ddate": null, "tcdate": 1606263405804, "tmdate": 1606263405804, "tddate": null, "forum": "BVPowUU1cR", "replyto": "BVPowUU1cR", "invitation": "ICLR.cc/2021/Conference/Paper1322/-/Official_Comment", "content": {"title": "General Comments", "comment": "We thank you all for your reviews.\n\nGiven that AdvAs, as a method, is the same as that found in \"Gradient descent\nGAN optimization is locally stable\" (Nagarajan and Kolter, 2017) and \"The\nnumerics of gans\" (Mescheder et al., 2017) we want to address this first and\nforemost. We have edited our paper, especially the abstract, introduction and\nrelated work sections, to appropriately refer to this prior work. Unfortunately\nthis prior work was missed during our background survey, but we would like to\npoint out that our work is independent of this prior work and that the oversight\nwas unintentional. We thank the three reviewers who brought this to our\nattention and appreciate the thoroughness showcased in this review process."}, "signatures": ["ICLR.cc/2021/Conference/Paper1322/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1322/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Assisting the Adversary to Improve GAN Training", "authorids": ["~Andreas_Munk1", "~William_Harvey1", "~Frank_Wood2"], "authors": ["Andreas Munk", "William Harvey", "Frank Wood"], "keywords": ["Generative Adversarial Networks", "GANs"], "abstract": "Some of the most popular methods for improving the stability and performance of GANs involve constraining or regularizing the discriminator. In this paper we consider a largely overlooked regularization technique which we refer to as the Adversary's Assistant (AdvAs). We motivate this using a different perspective to that of prior work. Specifically, we consider a common mismatch between theoretical analysis and practice: analysis often assumes that the discriminator reaches its optimum on each iteration. In practice, this is essentially never true, often leading to poor gradient estimates for the generator. To address this, AdvAs is a theoretically motivated penalty imposed on the generator based on the norm of the gradients used to train the discriminator. This encourages the generator to move towards points where the discriminator is optimal. We demonstrate the effect of applying AdvAs to several GAN objectives, datasets and network architectures. The results indicate a reduction in the mismatch between theory and practice and that AdvAs can lead to improvement of GAN training, as measured by FID scores.\n", "one-sentence_summary": "We propose a method for improved training of generative adversarial networks (GANs) by regularizing the updates on the generator.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "munk|assisting_the_adversary_to_improve_gan_training", "supplementary_material": "/attachment/b5fb0a999be989514622d29c02ab49eed4827a01.zip", "pdf": "/pdf/fff3a6d4387d4d6b13deb7f54af8f65b7c9ca789.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=PFl61vZW-b", "_bibtex": "@misc{\nmunk2021assisting,\ntitle={Assisting the Adversary to Improve {\\{}GAN{\\}} Training},\nauthor={Andreas Munk and William Harvey and Frank Wood},\nyear={2021},\nurl={https://openreview.net/forum?id=BVPowUU1cR}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "BVPowUU1cR", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper1322/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper1322/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper1322/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper1322/Authors|ICLR.cc/2021/Conference/Paper1322/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1322/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923861074, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper1322/-/Official_Comment"}}}, {"id": "vySURmuERV7", "original": null, "number": 1, "cdate": 1603882385601, "ddate": null, "tcdate": 1603882385601, "tmdate": 1605024473778, "tddate": null, "forum": "BVPowUU1cR", "replyto": "BVPowUU1cR", "invitation": "ICLR.cc/2021/Conference/Paper1322/-/Official_Review", "content": {"title": "A nice investigation, but needed to be more rigorous", "review": "This paper concerns how to efficiently regularize the generatior for training generative adversarial networks (GANs). A new regularizer for the generator loss is proposed to penalize the norm of the gradient with respect to discriminator\u2019s parameters ($\\phi$). In other words, the generator learns to encourage small norm of the discriminator\u2019s gradient w.r.t $\\phi$. The author(s) also propose a heuristic to remove the introduction of a further hyperparameter. The author(s) applied the proposed regularizer to WGAN-GP, AutoGAN, and StyleGAN2 to validate its effectiveness. Their experiments reveal that the new regularizer is promising.\n\nPros:\n- The idea of penalizing the gradient w.r.t discriminator\u2019s parameters when learning the generator is interesting. It could be great if the authors could explain more about its implications/meaning.\n- Different formulations and architectures for GAN have been taken into account for investigation. \n\nCons:\n- There exist some works that propose regularizers to both generator and discriminator, including [Mescheder et al., 2017; Nie & Patel, 2019]. Those regularizers are based on gradient vector fields over the parameters of both discriminator and generator. However, this paper does not provide any discussion about those closely related works and hence places itself in an unclear context.\n- Some recent studies [Brock et al., 2019; Zhang et al., 2019] found that regularizing the generator, e.g., using spectral normalization (SN), can help improve training and quality of the generator. SN is a very efficient way to do regularization and can make GAN training much more stable. Therefore, the idea of regularization for generator is not new.\n- Since this paper proposes a penalty when training GAN, I expect to see comparisons with some other regularization methods, e.g, SN and gradient penalty. Unfortunately, such a careful comparison is missing. Instead the author(s) used AutoGAN and StyleGAN2, which focus on generator architecture, for investigation. Such experiments do not help much to understand the effectiveness of the proposed regularizer, in comparison with some other approaches. As a result, the significance of this work is unclear.\n\nMinor comments:\n- An investigation about the sensitivity of parameter $\\lambda$ should be done. It could help us see whether or not the proposed heuristic is effective.\n- One motivation of this work is the optimality of the discriminator. However, it is wellknown that the gradient vanishing problem may appear if one train the discriminator to optimality. Therefore the motivation seems not to be supportive.\n- Formular (1) seems to be wrong. \n- \u201cadvAs as an attempt fulfill\u201d in page 4 --> \u201cadvAs as an attempt to fulfill\u201d\n\nReference:\n- Andrew Brock, Jeff Donahue, and Karen Simonyan. Large scale gan training for high fidelity natural image synthesis. In International Conference on Learning Representations, 2019. \n- Lars Mescheder, Sebastian Nowozin, and Andreas Geiger. The numerics of gans. In Advances in Neural Information Processing Systems, pp. 1825\u20131835, 2017. \n- Weili Nie and Ankit Patel. Towards a better understanding and regularization of gan training dy- namics. In Conference on Uncertainty in Artificial Intelligence (UAI), 2019. \n- Han Zhang, Ian Goodfellow, Dimitris Metaxas, and Augustus Odena. Self-attention generative adversarial networks. In International Conference on Machine Learning, pp. 7354\u20137363, 2019. ", "rating": "4: Ok but not good enough - rejection", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["ICLR.cc/2021/Conference/Paper1322/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1322/AnonReviewer3"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Assisting the Adversary to Improve GAN Training", "authorids": ["~Andreas_Munk1", "~William_Harvey1", "~Frank_Wood2"], "authors": ["Andreas Munk", "William Harvey", "Frank Wood"], "keywords": ["Generative Adversarial Networks", "GANs"], "abstract": "Some of the most popular methods for improving the stability and performance of GANs involve constraining or regularizing the discriminator. In this paper we consider a largely overlooked regularization technique which we refer to as the Adversary's Assistant (AdvAs). We motivate this using a different perspective to that of prior work. Specifically, we consider a common mismatch between theoretical analysis and practice: analysis often assumes that the discriminator reaches its optimum on each iteration. In practice, this is essentially never true, often leading to poor gradient estimates for the generator. To address this, AdvAs is a theoretically motivated penalty imposed on the generator based on the norm of the gradients used to train the discriminator. This encourages the generator to move towards points where the discriminator is optimal. We demonstrate the effect of applying AdvAs to several GAN objectives, datasets and network architectures. The results indicate a reduction in the mismatch between theory and practice and that AdvAs can lead to improvement of GAN training, as measured by FID scores.\n", "one-sentence_summary": "We propose a method for improved training of generative adversarial networks (GANs) by regularizing the updates on the generator.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "munk|assisting_the_adversary_to_improve_gan_training", "supplementary_material": "/attachment/b5fb0a999be989514622d29c02ab49eed4827a01.zip", "pdf": "/pdf/fff3a6d4387d4d6b13deb7f54af8f65b7c9ca789.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=PFl61vZW-b", "_bibtex": "@misc{\nmunk2021assisting,\ntitle={Assisting the Adversary to Improve {\\{}GAN{\\}} Training},\nauthor={Andreas Munk and William Harvey and Frank Wood},\nyear={2021},\nurl={https://openreview.net/forum?id=BVPowUU1cR}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq . ***Please remember to file the Code-of-Ethics report. Once you submitted the review, a link to the report will be visible in the bottom right corner of your review.***", "required": true, "markdown": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}, "forum": "BVPowUU1cR", "replyto": "BVPowUU1cR", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"], "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper1322/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1607428800000, "duedate": 1606752000000, "multiReply": false, "readers": ["everyone"], "tcdate": 1602538121364, "tmdate": 1606915768425, "super": "ICLR.cc/2021/Conference/-/Official_Review", "signatures": ["OpenReview.net"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Paper1322/Reviewers", "OpenReview.net/Support"], "id": "ICLR.cc/2021/Conference/Paper1322/-/Official_Review"}}}, {"id": "dZdPaNTbNxZ", "original": null, "number": 2, "cdate": 1603902354513, "ddate": null, "tcdate": 1603902354513, "tmdate": 1605024473713, "tddate": null, "forum": "BVPowUU1cR", "replyto": "BVPowUU1cR", "invitation": "ICLR.cc/2021/Conference/Paper1322/-/Official_Review", "content": {"title": "Well-written, but not novel", "review": "Summary:\n\nThe authors observe that many GAN forumations assume optimality of the discriminator at each generator step and clarify this by reviewing a variant of an envelope theorem.\nObserving that this optimality condition isn't usually satisfied in practice, the authors propose a generator regularizer term which encourages the discriminator to be approximately optimal by penalizing the norm of the discriminator's gradient vector.\nExperiments on MNIST, CIFAR10, and CelebA show that use of the regularizer often yields improvement wrt baselines.\n\nReview:\n\nIn summary, the paper's main strength is clarity of exposition; its main weaknesses are that the algorithm isn't novel (see below) and that the experimental results are limited. Overall I can't recommend acceptance in the current form.\n\nCorrectness:\n\nThe motivation, theory, and algorithms proposed are broadly correct to my knowledge.\nI do want to point out that it's possible to obtain an unbiased estimate of $|| \\partial_\\theta L ||_2^2$ efficiently by computing two independent estimates of the discriminator gradient vector (i.e. using two independent minibatches) and multiplying them. This owes to the fact that $E[X]^2 = E[X]E[X'] = E[X X']$ when $X, X'$ are independent and identically distributed.\n\nNovelty:\n\nThe observation that GAN theory sometimes relies on an envelope theorem, and the specific envelope theorem given, aren't particularly novel (for instance, the original GAN paper by Goodfellow made a version of this argument), but they are (in my opinion) under-appreciated in existing literature and so the extra exposition is welcome.\n\nThe authors point out that while superficially similar to other gradient penalties, it has a very different motivation, structure, and probably works in a different way; I generally agree with their argument.\nHowever, the proposed regularizer does have exactly the same form (and similar motivation) as the one proposed in https://arxiv.org/abs/1706.04156, so the algorithm isn't novel in the end.\n\nThe proposed algorithm is also closely related to https://arxiv.org/abs/1705.10461 .\n\nIf this paper is to be accepted, at a minimum it needs a full discussion of the algorithms given in these two works and how they relate to the present work.\n\nSignificance:\n\nEmpirically the experiments support the usefulness of the proposed algorithm, albeit not to a very great degree.\nThe baselines compared against aren't state-of-the-art.\n\nOne experimental weakness is that in many places the authors claim a reduction in discriminator-steps-per-generator-step as an improvement, but don't separately search over generator/discriminator learning rates in the baseline.\nIf you want to make this kind of claim, the appropriate baseline is a GAN in which the G and D LRs have been tuned (and tuned independently of each other).\nOtherwise, for example, a trivial \"penalty\" term which just equals the original loss (and hence has the effect of multiplying the generator gradient by two, which is equivalent to multiplying the learning rate by two for SGD) might show improvement.\n\nClarity:\n\nThe paper deserves high marks on clarity in my opinion. It reads easily and contextualizes its work well. The claims made are precise and well-scoped. \nClarity of the exposition is important because it means this paper advances our understanding despite the somewhat limited empirical improvement from the algorithm.", "rating": "4: Ok but not good enough - rejection", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["ICLR.cc/2021/Conference/Paper1322/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1322/AnonReviewer2"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Assisting the Adversary to Improve GAN Training", "authorids": ["~Andreas_Munk1", "~William_Harvey1", "~Frank_Wood2"], "authors": ["Andreas Munk", "William Harvey", "Frank Wood"], "keywords": ["Generative Adversarial Networks", "GANs"], "abstract": "Some of the most popular methods for improving the stability and performance of GANs involve constraining or regularizing the discriminator. In this paper we consider a largely overlooked regularization technique which we refer to as the Adversary's Assistant (AdvAs). We motivate this using a different perspective to that of prior work. Specifically, we consider a common mismatch between theoretical analysis and practice: analysis often assumes that the discriminator reaches its optimum on each iteration. In practice, this is essentially never true, often leading to poor gradient estimates for the generator. To address this, AdvAs is a theoretically motivated penalty imposed on the generator based on the norm of the gradients used to train the discriminator. This encourages the generator to move towards points where the discriminator is optimal. We demonstrate the effect of applying AdvAs to several GAN objectives, datasets and network architectures. The results indicate a reduction in the mismatch between theory and practice and that AdvAs can lead to improvement of GAN training, as measured by FID scores.\n", "one-sentence_summary": "We propose a method for improved training of generative adversarial networks (GANs) by regularizing the updates on the generator.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "munk|assisting_the_adversary_to_improve_gan_training", "supplementary_material": "/attachment/b5fb0a999be989514622d29c02ab49eed4827a01.zip", "pdf": "/pdf/fff3a6d4387d4d6b13deb7f54af8f65b7c9ca789.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=PFl61vZW-b", "_bibtex": "@misc{\nmunk2021assisting,\ntitle={Assisting the Adversary to Improve {\\{}GAN{\\}} Training},\nauthor={Andreas Munk and William Harvey and Frank Wood},\nyear={2021},\nurl={https://openreview.net/forum?id=BVPowUU1cR}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq . ***Please remember to file the Code-of-Ethics report. Once you submitted the review, a link to the report will be visible in the bottom right corner of your review.***", "required": true, "markdown": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}, "forum": "BVPowUU1cR", "replyto": "BVPowUU1cR", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"], "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper1322/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1607428800000, "duedate": 1606752000000, "multiReply": false, "readers": ["everyone"], "tcdate": 1602538121364, "tmdate": 1606915768425, "super": "ICLR.cc/2021/Conference/-/Official_Review", "signatures": ["OpenReview.net"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Paper1322/Reviewers", "OpenReview.net/Support"], "id": "ICLR.cc/2021/Conference/Paper1322/-/Official_Review"}}}, {"id": "vUFWPEcVtf9", "original": null, "number": 3, "cdate": 1603998279679, "ddate": null, "tcdate": 1603998279679, "tmdate": 1605024473650, "tddate": null, "forum": "BVPowUU1cR", "replyto": "BVPowUU1cR", "invitation": "ICLR.cc/2021/Conference/Paper1322/-/Official_Review", "content": {"title": "The proposed regularization was already proposed in a previous work.", "review": "**Summary of contributions:**\nThis paper propose a new regularization for training the generator in GANs. They argue that when the discriminator is not optimal this encourages the generator to stay in region where the discriminator is close to optimal. They then propose an heuristic to adaptively control the coefficient of the regularization term. Finally they show empirically that the proposed regularization can indeed improve the generator performance in several setting.\n\n**Major Concern:**\nI have a big concern about the contribution of this work, the proposed regularization eq 8 is exactly the regularization also proposed in [[1] Gradient descent GAN optimization is locally stable (NeurIPS 2017)](http://papers.nips.cc/paper/7142-gradient-descent-gan-optimization-is-locally-stable) see eq 4.\nThis related work is not even mentioned in this paper, also while the perspective is a bit different here, I find the theoretical motivation more rigorous in [1].\n\n**Clarity:**\nThe paper is quite clear and well written.\n\n**Significance:**\nThe experiments gives a good overview of the performance of the proposed method, however the results don't always show a major advantage of the proposed regularization for example on CIFAR there doesn't seem to be any benefit. Also this should be compared to other regularization technique for the generator for example Jacobian Clamping proposed in [Is Generator Conditioning Causally Related to GAN Performance? (ICML 2018)](http://proceedings.mlr.press/v80/odena18a.html).\nIt would also be interesting to have a plot showing the evolution of the adaptative regularization coefficient along training.\n\n**Other comments:**\nThere is actually a cheap and unbiased estimator for the AdvAs loss by using this property: $||\\mathbb{E}[X]||^2 = \\mathbb{E}[X_i^TX_j]$ where $X_i$ and $X_j$ are two independent random variables sampled from the same distribution as X. For an example on such an unbiased estimator in a context related to yours see Appendix C of [Stochastic Hamiltonian Gradient Methods for Smooth Games  (ICML 2020)](https://proceedings.icml.cc/static/paper_files/icml/2020/6356-Paper.pdf).\n\n\n\n", "rating": "3: Clear rejection", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}, "signatures": ["ICLR.cc/2021/Conference/Paper1322/AnonReviewer4"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1322/AnonReviewer4"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Assisting the Adversary to Improve GAN Training", "authorids": ["~Andreas_Munk1", "~William_Harvey1", "~Frank_Wood2"], "authors": ["Andreas Munk", "William Harvey", "Frank Wood"], "keywords": ["Generative Adversarial Networks", "GANs"], "abstract": "Some of the most popular methods for improving the stability and performance of GANs involve constraining or regularizing the discriminator. In this paper we consider a largely overlooked regularization technique which we refer to as the Adversary's Assistant (AdvAs). We motivate this using a different perspective to that of prior work. Specifically, we consider a common mismatch between theoretical analysis and practice: analysis often assumes that the discriminator reaches its optimum on each iteration. In practice, this is essentially never true, often leading to poor gradient estimates for the generator. To address this, AdvAs is a theoretically motivated penalty imposed on the generator based on the norm of the gradients used to train the discriminator. This encourages the generator to move towards points where the discriminator is optimal. We demonstrate the effect of applying AdvAs to several GAN objectives, datasets and network architectures. The results indicate a reduction in the mismatch between theory and practice and that AdvAs can lead to improvement of GAN training, as measured by FID scores.\n", "one-sentence_summary": "We propose a method for improved training of generative adversarial networks (GANs) by regularizing the updates on the generator.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "munk|assisting_the_adversary_to_improve_gan_training", "supplementary_material": "/attachment/b5fb0a999be989514622d29c02ab49eed4827a01.zip", "pdf": "/pdf/fff3a6d4387d4d6b13deb7f54af8f65b7c9ca789.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=PFl61vZW-b", "_bibtex": "@misc{\nmunk2021assisting,\ntitle={Assisting the Adversary to Improve {\\{}GAN{\\}} Training},\nauthor={Andreas Munk and William Harvey and Frank Wood},\nyear={2021},\nurl={https://openreview.net/forum?id=BVPowUU1cR}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq . ***Please remember to file the Code-of-Ethics report. Once you submitted the review, a link to the report will be visible in the bottom right corner of your review.***", "required": true, "markdown": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}, "forum": "BVPowUU1cR", "replyto": "BVPowUU1cR", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"], "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper1322/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1607428800000, "duedate": 1606752000000, "multiReply": false, "readers": ["everyone"], "tcdate": 1602538121364, "tmdate": 1606915768425, "super": "ICLR.cc/2021/Conference/-/Official_Review", "signatures": ["OpenReview.net"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Paper1322/Reviewers", "OpenReview.net/Support"], "id": "ICLR.cc/2021/Conference/Paper1322/-/Official_Review"}}}, {"id": "l83gld8C01", "original": null, "number": 4, "cdate": 1604629660005, "ddate": null, "tcdate": 1604629660005, "tmdate": 1605024473587, "tddate": null, "forum": "BVPowUU1cR", "replyto": "BVPowUU1cR", "invitation": "ICLR.cc/2021/Conference/Paper1322/-/Official_Review", "content": {"title": "review", "review": "This paper proposes a new regularizer to improve GAN training. By noticing that the discriminator does not always reach optimum at each iteration, this paper proposes Adversary's Assistant (AdvAs) for helping the discriminator to satisfy this condition. Interestingly, compared to the previous methods for improving GAN training, this work applies the regularizer at the generator (rather than the discriminator) and is theoretical motivated. Experiments on several GAN objectives, datasets and network architectures are provided to support the effectiveness of AdvAs.\n\n\n*Pros\n\n(1) This paper is clearly written. Even I am not an expert in GAN, I do not encounter too many difficulties in understanding the whole paper.\n\n(2) The whole framework is theoretical motivated. Given that the discriminator is not always at an optimal point during training, this paper derives several theorems and corollaries, which leads to the finding that adding a regularization on the generator could satisfy a necessary condition for training GAN optimally.\n\n(3) Empirical results are provided to show the proposed AdvAs can help GAN training under different settings.\n\n\n\n*Cons\n\n(1) This paper uses a minibatch to approximately compute the regulizer $r(\\theta,\\phi)$. I am wondering if the proposed AdvAs is sensitive to the estimation quality of $r(\\theta,\\phi)$? For example, if large batch size is used, will the results be better? If yes, then what is the \"minimal\" batch size to train a good GAN with AdvAs (i.e., outperforms the baseline)?\n\n(2) I appreciate that this paper honestly states that the proposed AdvAs cannot help BEGAN and LSGAN. I encourage the authors to delve deeper into this observed phenomenon and provide a brief discussion on explaining the possible reasons why AdvAs cannot help here.\n\n(3) As the main purpose of AdvAs is to encourage the value of Eq. (7) be close to 0, the authors are encouraged to also plot the value of $D_2h(p_\u03b8, a_\u03c6)$ during the training, as direct evidence for supporting the effectiveness of AdvAs.\n\n\n\n**Overall, I think it is an interesting paper, with good theoretical motivation and strong empirical results, therefore I tend to accept it at this time. Nonetheless, I am not an expert in GAN and cannot accurately access the value/importance of this paper. I am open to increase/decrease my score if other expert reviewers provide any positive/negative comments.\n\n\n\n ", "rating": "6: Marginally above acceptance threshold", "confidence": "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper"}, "signatures": ["ICLR.cc/2021/Conference/Paper1322/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1322/AnonReviewer1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Assisting the Adversary to Improve GAN Training", "authorids": ["~Andreas_Munk1", "~William_Harvey1", "~Frank_Wood2"], "authors": ["Andreas Munk", "William Harvey", "Frank Wood"], "keywords": ["Generative Adversarial Networks", "GANs"], "abstract": "Some of the most popular methods for improving the stability and performance of GANs involve constraining or regularizing the discriminator. In this paper we consider a largely overlooked regularization technique which we refer to as the Adversary's Assistant (AdvAs). We motivate this using a different perspective to that of prior work. Specifically, we consider a common mismatch between theoretical analysis and practice: analysis often assumes that the discriminator reaches its optimum on each iteration. In practice, this is essentially never true, often leading to poor gradient estimates for the generator. To address this, AdvAs is a theoretically motivated penalty imposed on the generator based on the norm of the gradients used to train the discriminator. This encourages the generator to move towards points where the discriminator is optimal. We demonstrate the effect of applying AdvAs to several GAN objectives, datasets and network architectures. The results indicate a reduction in the mismatch between theory and practice and that AdvAs can lead to improvement of GAN training, as measured by FID scores.\n", "one-sentence_summary": "We propose a method for improved training of generative adversarial networks (GANs) by regularizing the updates on the generator.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "munk|assisting_the_adversary_to_improve_gan_training", "supplementary_material": "/attachment/b5fb0a999be989514622d29c02ab49eed4827a01.zip", "pdf": "/pdf/fff3a6d4387d4d6b13deb7f54af8f65b7c9ca789.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=PFl61vZW-b", "_bibtex": "@misc{\nmunk2021assisting,\ntitle={Assisting the Adversary to Improve {\\{}GAN{\\}} Training},\nauthor={Andreas Munk and William Harvey and Frank Wood},\nyear={2021},\nurl={https://openreview.net/forum?id=BVPowUU1cR}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq . ***Please remember to file the Code-of-Ethics report. Once you submitted the review, a link to the report will be visible in the bottom right corner of your review.***", "required": true, "markdown": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}, "forum": "BVPowUU1cR", "replyto": "BVPowUU1cR", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"], "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper1322/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1607428800000, "duedate": 1606752000000, "multiReply": false, "readers": ["everyone"], "tcdate": 1602538121364, "tmdate": 1606915768425, "super": "ICLR.cc/2021/Conference/-/Official_Review", "signatures": ["OpenReview.net"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Paper1322/Reviewers", "OpenReview.net/Support"], "id": "ICLR.cc/2021/Conference/Paper1322/-/Official_Review"}}}], "count": 11}