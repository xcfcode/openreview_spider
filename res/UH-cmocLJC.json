{"notes": [{"id": "UH-cmocLJC", "original": "_88KWZFfavA", "number": 700, "cdate": 1601308082727, "ddate": null, "tcdate": 1601308082727, "tmdate": 1614726121518, "tddate": null, "forum": "UH-cmocLJC", "replyto": null, "invitation": "ICLR.cc/2021/Conference/-/Blind_Submission", "content": {"title": "How Neural Networks Extrapolate: From Feedforward to Graph Neural Networks", "authorids": ["~Keyulu_Xu1", "~Mozhi_Zhang1", "~Jingling_Li1", "~Simon_Shaolei_Du1", "~Ken-Ichi_Kawarabayashi1", "~Stefanie_Jegelka3"], "authors": ["Keyulu Xu", "Mozhi Zhang", "Jingling Li", "Simon Shaolei Du", "Ken-Ichi Kawarabayashi", "Stefanie Jegelka"], "keywords": ["extrapolation", "deep learning", "out-of-distribution", "graph neural networks", "deep learning theory"], "abstract": "We study how neural networks trained by gradient descent  extrapolate, i.e., what they learn outside the support of the training distribution. Previous works report mixed empirical results when extrapolating with neural networks: while feedforward neural networks, a.k.a. multilayer perceptrons (MLPs), do not extrapolate well in certain simple tasks, Graph Neural Networks (GNNs) -- structured networks with MLP modules -- have shown some success in more complex tasks.  Working towards a theoretical explanation, we identify conditions under which MLPs and GNNs extrapolate well. First, we quantify the observation that ReLU MLPs quickly converge to linear functions along any direction from the origin, which implies that ReLU MLPs do not extrapolate most nonlinear functions. But, they can provably learn a linear target function when the training distribution is sufficiently diverse. Second, in connection to analyzing the successes and limitations of GNNs, these results suggest a hypothesis for which we provide theoretical and empirical evidence: the success of GNNs in extrapolating algorithmic tasks to new data (e.g., larger graphs or edge weights) relies on encoding task-specific non-linearities in the architecture or features. Our theoretical analysis builds on a connection of over-parameterized networks to the neural tangent kernel.  Empirically, our theory holds across different training settings.", "one-sentence_summary": "We study how neural networks trained by gradient descent extrapolate.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "xu|how_neural_networks_extrapolate_from_feedforward_to_graph_neural_networks", "supplementary_material": "", "pdf": "/pdf/eb776544f1a0835881289e4dad2436f38f88269d.pdf", "venue": "ICLR 2021 Oral", "venueid": "ICLR.cc/2021/Conference", "_bibtex": "@inproceedings{\nxu2021how,\ntitle={How Neural Networks Extrapolate: From Feedforward to Graph Neural Networks},\nauthor={Keyulu Xu and Mozhi Zhang and Jingling Li and Simon Shaolei Du and Ken-Ichi Kawarabayashi and Stefanie Jegelka},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=UH-cmocLJC}\n}"}, "signatures": ["ICLR.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference"], "details": {"replyCount": 13, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"reply": {"readers": {"values-regex": ".*"}, "writers": {"values": ["ICLR.cc/2021/Conference"]}, "signatures": {"values": ["ICLR.cc/2021/Conference"]}, "content": {"authors": {"values": ["Anonymous"]}, "authorids": {"values-regex": ".*"}, "reviewed_version_(pdf)": {"required": false, "description": "Upload a PDF file that ends with .pdf", "value-regex": ".*"}}}, "signatures": ["ICLR.cc/2021/Conference"], "readers": ["everyone"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["~", "OpenReview.net/Support"], "tcdate": 1601308008205, "tmdate": 1614984599368, "id": "ICLR.cc/2021/Conference/-/Blind_Submission"}}, "tauthor": "OpenReview.net"}, {"id": "_YPF0JVTJCX", "original": null, "number": 1, "cdate": 1610040387540, "ddate": null, "tcdate": 1610040387540, "tmdate": 1610473981373, "tddate": null, "forum": "UH-cmocLJC", "replyto": "UH-cmocLJC", "invitation": "ICLR.cc/2021/Conference/Paper700/-/Decision", "content": {"title": "Final Decision", "decision": "Accept (Oral)", "comment": "This paper studies how (two layer) neural nets extrapolates. The paper is beautifully written and the authors very successfully answered all the questions. They managed to update the paper, clarify the assumptions and add additional experiments. "}, "signatures": ["ICLR.cc/2021/Conference/Program_Chairs"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference/Program_Chairs"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "How Neural Networks Extrapolate: From Feedforward to Graph Neural Networks", "authorids": ["~Keyulu_Xu1", "~Mozhi_Zhang1", "~Jingling_Li1", "~Simon_Shaolei_Du1", "~Ken-Ichi_Kawarabayashi1", "~Stefanie_Jegelka3"], "authors": ["Keyulu Xu", "Mozhi Zhang", "Jingling Li", "Simon Shaolei Du", "Ken-Ichi Kawarabayashi", "Stefanie Jegelka"], "keywords": ["extrapolation", "deep learning", "out-of-distribution", "graph neural networks", "deep learning theory"], "abstract": "We study how neural networks trained by gradient descent  extrapolate, i.e., what they learn outside the support of the training distribution. Previous works report mixed empirical results when extrapolating with neural networks: while feedforward neural networks, a.k.a. multilayer perceptrons (MLPs), do not extrapolate well in certain simple tasks, Graph Neural Networks (GNNs) -- structured networks with MLP modules -- have shown some success in more complex tasks.  Working towards a theoretical explanation, we identify conditions under which MLPs and GNNs extrapolate well. First, we quantify the observation that ReLU MLPs quickly converge to linear functions along any direction from the origin, which implies that ReLU MLPs do not extrapolate most nonlinear functions. But, they can provably learn a linear target function when the training distribution is sufficiently diverse. Second, in connection to analyzing the successes and limitations of GNNs, these results suggest a hypothesis for which we provide theoretical and empirical evidence: the success of GNNs in extrapolating algorithmic tasks to new data (e.g., larger graphs or edge weights) relies on encoding task-specific non-linearities in the architecture or features. Our theoretical analysis builds on a connection of over-parameterized networks to the neural tangent kernel.  Empirically, our theory holds across different training settings.", "one-sentence_summary": "We study how neural networks trained by gradient descent extrapolate.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "xu|how_neural_networks_extrapolate_from_feedforward_to_graph_neural_networks", "supplementary_material": "", "pdf": "/pdf/eb776544f1a0835881289e4dad2436f38f88269d.pdf", "venue": "ICLR 2021 Oral", "venueid": "ICLR.cc/2021/Conference", "_bibtex": "@inproceedings{\nxu2021how,\ntitle={How Neural Networks Extrapolate: From Feedforward to Graph Neural Networks},\nauthor={Keyulu Xu and Mozhi Zhang and Jingling Li and Simon Shaolei Du and Ken-Ichi Kawarabayashi and Stefanie Jegelka},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=UH-cmocLJC}\n}"}, "tags": [], "invitation": {"reply": {"forum": "UH-cmocLJC", "replyto": "UH-cmocLJC", "readers": {"values": ["everyone"]}, "writers": {"values": ["ICLR.cc/2021/Conference/Program_Chairs"]}, "signatures": {"values": ["ICLR.cc/2021/Conference/Program_Chairs"]}, "content": {"title": {"value": "Final Decision"}, "decision": {"value-radio": ["Accept (Oral)", "Accept (Spotlight)", "Accept (Poster)", "Reject"]}, "comment": {"value-regex": "[\\S\\s]{0,50000}", "markdown": true}}}, "multiReply": false, "signatures": ["ICLR.cc/2021/Conference"], "readers": ["everyone"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Program_Chairs"], "tcdate": 1610040387526, "tmdate": 1610473981356, "id": "ICLR.cc/2021/Conference/Paper700/-/Decision"}}}, {"id": "kGVmcGiGJqY", "original": null, "number": 9, "cdate": 1605997314121, "ddate": null, "tcdate": 1605997314121, "tmdate": 1605997314121, "tddate": null, "forum": "UH-cmocLJC", "replyto": "wcAlmzMiuA6", "invitation": "ICLR.cc/2021/Conference/Paper700/-/Official_Comment", "content": {"title": "Thank you", "comment": "Thank you! We are glad you like our paper, and we appreciate your insightful comments."}, "signatures": ["ICLR.cc/2021/Conference/Paper700/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper700/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "How Neural Networks Extrapolate: From Feedforward to Graph Neural Networks", "authorids": ["~Keyulu_Xu1", "~Mozhi_Zhang1", "~Jingling_Li1", "~Simon_Shaolei_Du1", "~Ken-Ichi_Kawarabayashi1", "~Stefanie_Jegelka3"], "authors": ["Keyulu Xu", "Mozhi Zhang", "Jingling Li", "Simon Shaolei Du", "Ken-Ichi Kawarabayashi", "Stefanie Jegelka"], "keywords": ["extrapolation", "deep learning", "out-of-distribution", "graph neural networks", "deep learning theory"], "abstract": "We study how neural networks trained by gradient descent  extrapolate, i.e., what they learn outside the support of the training distribution. Previous works report mixed empirical results when extrapolating with neural networks: while feedforward neural networks, a.k.a. multilayer perceptrons (MLPs), do not extrapolate well in certain simple tasks, Graph Neural Networks (GNNs) -- structured networks with MLP modules -- have shown some success in more complex tasks.  Working towards a theoretical explanation, we identify conditions under which MLPs and GNNs extrapolate well. First, we quantify the observation that ReLU MLPs quickly converge to linear functions along any direction from the origin, which implies that ReLU MLPs do not extrapolate most nonlinear functions. But, they can provably learn a linear target function when the training distribution is sufficiently diverse. Second, in connection to analyzing the successes and limitations of GNNs, these results suggest a hypothesis for which we provide theoretical and empirical evidence: the success of GNNs in extrapolating algorithmic tasks to new data (e.g., larger graphs or edge weights) relies on encoding task-specific non-linearities in the architecture or features. Our theoretical analysis builds on a connection of over-parameterized networks to the neural tangent kernel.  Empirically, our theory holds across different training settings.", "one-sentence_summary": "We study how neural networks trained by gradient descent extrapolate.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "xu|how_neural_networks_extrapolate_from_feedforward_to_graph_neural_networks", "supplementary_material": "", "pdf": "/pdf/eb776544f1a0835881289e4dad2436f38f88269d.pdf", "venue": "ICLR 2021 Oral", "venueid": "ICLR.cc/2021/Conference", "_bibtex": "@inproceedings{\nxu2021how,\ntitle={How Neural Networks Extrapolate: From Feedforward to Graph Neural Networks},\nauthor={Keyulu Xu and Mozhi Zhang and Jingling Li and Simon Shaolei Du and Ken-Ichi Kawarabayashi and Stefanie Jegelka},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=UH-cmocLJC}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "UH-cmocLJC", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper700/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper700/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper700/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper700/Authors|ICLR.cc/2021/Conference/Paper700/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper700/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923868139, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper700/-/Official_Comment"}}}, {"id": "wcAlmzMiuA6", "original": null, "number": 8, "cdate": 1605994263457, "ddate": null, "tcdate": 1605994263457, "tmdate": 1605994263457, "tddate": null, "forum": "UH-cmocLJC", "replyto": "LQfVfXXzfT", "invitation": "ICLR.cc/2021/Conference/Paper700/-/Official_Comment", "content": {"title": "Response", "comment": "Thank you for your detailed response!\nI really like the paper and my concerns were addressed so I updated the score to 9."}, "signatures": ["ICLR.cc/2021/Conference/Paper700/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper700/AnonReviewer2"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "How Neural Networks Extrapolate: From Feedforward to Graph Neural Networks", "authorids": ["~Keyulu_Xu1", "~Mozhi_Zhang1", "~Jingling_Li1", "~Simon_Shaolei_Du1", "~Ken-Ichi_Kawarabayashi1", "~Stefanie_Jegelka3"], "authors": ["Keyulu Xu", "Mozhi Zhang", "Jingling Li", "Simon Shaolei Du", "Ken-Ichi Kawarabayashi", "Stefanie Jegelka"], "keywords": ["extrapolation", "deep learning", "out-of-distribution", "graph neural networks", "deep learning theory"], "abstract": "We study how neural networks trained by gradient descent  extrapolate, i.e., what they learn outside the support of the training distribution. Previous works report mixed empirical results when extrapolating with neural networks: while feedforward neural networks, a.k.a. multilayer perceptrons (MLPs), do not extrapolate well in certain simple tasks, Graph Neural Networks (GNNs) -- structured networks with MLP modules -- have shown some success in more complex tasks.  Working towards a theoretical explanation, we identify conditions under which MLPs and GNNs extrapolate well. First, we quantify the observation that ReLU MLPs quickly converge to linear functions along any direction from the origin, which implies that ReLU MLPs do not extrapolate most nonlinear functions. But, they can provably learn a linear target function when the training distribution is sufficiently diverse. Second, in connection to analyzing the successes and limitations of GNNs, these results suggest a hypothesis for which we provide theoretical and empirical evidence: the success of GNNs in extrapolating algorithmic tasks to new data (e.g., larger graphs or edge weights) relies on encoding task-specific non-linearities in the architecture or features. Our theoretical analysis builds on a connection of over-parameterized networks to the neural tangent kernel.  Empirically, our theory holds across different training settings.", "one-sentence_summary": "We study how neural networks trained by gradient descent extrapolate.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "xu|how_neural_networks_extrapolate_from_feedforward_to_graph_neural_networks", "supplementary_material": "", "pdf": "/pdf/eb776544f1a0835881289e4dad2436f38f88269d.pdf", "venue": "ICLR 2021 Oral", "venueid": "ICLR.cc/2021/Conference", "_bibtex": "@inproceedings{\nxu2021how,\ntitle={How Neural Networks Extrapolate: From Feedforward to Graph Neural Networks},\nauthor={Keyulu Xu and Mozhi Zhang and Jingling Li and Simon Shaolei Du and Ken-Ichi Kawarabayashi and Stefanie Jegelka},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=UH-cmocLJC}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "UH-cmocLJC", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper700/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper700/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper700/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper700/Authors|ICLR.cc/2021/Conference/Paper700/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper700/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923868139, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper700/-/Official_Comment"}}}, {"id": "sP3shlpXqlP", "original": null, "number": 5, "cdate": 1603884580172, "ddate": null, "tcdate": 1603884580172, "tmdate": 1605994190444, "tddate": null, "forum": "UH-cmocLJC", "replyto": "UH-cmocLJC", "invitation": "ICLR.cc/2021/Conference/Paper700/-/Official_Review", "content": {"title": "Interesting paper with somewhat specific results", "review": "## Summary\n\nThe paper studies how neural networks extrapolate. The authors theoretically\nexamine two-layer ReLU MLPs with mean squared loss in the NTK regime and,\nbuilding on these results, GNNs. They find that the MLPs quickly converge to\nlinear functions along any direction from the origin, but can provably learn a\nlinear target function where the training distribution is sufficiently diverse.\nFor GNNs, they propose a hypothesis that the success of extrapolating\nalgorithmic tasks to new data relies on encoding task-specific non-linearities\nin the architecture or features. The theoretical results are supported by\nempirical results which sometimes go beyond the specific conditions of the\ntheorems (like increasing the number of layers in the MLP to 4 in Appendix\nC.1.).\n\n## Pros\n\n- The paper provides both theoretical and practical insight into the\n  extrapolation capabilities of neural networks, especially GNNs.\n- I especially liked the part about GNNs and the hypothesis that if we can\n  encode the non-linearities outside the MLPs so the MLPs only have to learn\n  linear functions, GNNs will extrapolate well.\n- Overall I found the paper very interesting and fun to read.\n\n## Concerns\n\n- The theoretical MLP results are very specific. Sometimes this is not apparent\n  from either the abstract or the discussion of the results. Some of the\n  constraints:\n  + The MLPs have two layers, which I find the most limiting constraint as most\n    practical MLPs have more layers.\n  + The mean squared loss is used throughout the paper. I think this is not\n    emphasized enough (it is mentioned only a single time in the paper). As far\n    as I understand the proofs also rely on the loss, so the loss should be\n    included in the conditions of the theorems.\n  + We are under the NTK regime, which is of course evident from the techniques\n    used. Nevertheless, this is not mentioned in the abstract.\n  + The MLPs are ReLU MLPs which is emphasized sufficiently in the paper. The\n    authors include preliminary empirical results for other activations\n    functions in the Appendix (sin, quadratic, and tanh).\n\n## Questions\n\n- Could the proofs of Theorem 3 and Theorem 5 be generalized to MLPs with more\nlayers?\n- Can we gain some insight into extrapolation with other loss functions like\nsoftmax based on these results?\n\n## Reasons for ranking\n\nI found the paper really interesting and gained much insight from it. Some of\nthe constraints of the MLPs are not emphasized enough and the writing is more\ngeneral at parts than the results warrant. Even with the constraints I believe\nthat this is an important step and sheds light on the extrapolation capabilities\nof neural networks. If the constraints can be made clearer I'm willing to\nimprove my score further.\n\n## Minor comments\n\n- Second to last paragraph on page 5: \"for Theoreom 5\" should be \"for Theorem 5\".\n- Caption of Figure 1: outisde => outside\n- In 4.2., \"Experiments: architectures that help extrapolation\": \"GNNs with\n  max-readout are better than GNNs with sum-readout (Fig 6a)\" should be Fig 5a.\n", "rating": "9: Top 15% of accepted papers, strong accept", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "signatures": ["ICLR.cc/2021/Conference/Paper700/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper700/AnonReviewer2"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "How Neural Networks Extrapolate: From Feedforward to Graph Neural Networks", "authorids": ["~Keyulu_Xu1", "~Mozhi_Zhang1", "~Jingling_Li1", "~Simon_Shaolei_Du1", "~Ken-Ichi_Kawarabayashi1", "~Stefanie_Jegelka3"], "authors": ["Keyulu Xu", "Mozhi Zhang", "Jingling Li", "Simon Shaolei Du", "Ken-Ichi Kawarabayashi", "Stefanie Jegelka"], "keywords": ["extrapolation", "deep learning", "out-of-distribution", "graph neural networks", "deep learning theory"], "abstract": "We study how neural networks trained by gradient descent  extrapolate, i.e., what they learn outside the support of the training distribution. Previous works report mixed empirical results when extrapolating with neural networks: while feedforward neural networks, a.k.a. multilayer perceptrons (MLPs), do not extrapolate well in certain simple tasks, Graph Neural Networks (GNNs) -- structured networks with MLP modules -- have shown some success in more complex tasks.  Working towards a theoretical explanation, we identify conditions under which MLPs and GNNs extrapolate well. First, we quantify the observation that ReLU MLPs quickly converge to linear functions along any direction from the origin, which implies that ReLU MLPs do not extrapolate most nonlinear functions. But, they can provably learn a linear target function when the training distribution is sufficiently diverse. Second, in connection to analyzing the successes and limitations of GNNs, these results suggest a hypothesis for which we provide theoretical and empirical evidence: the success of GNNs in extrapolating algorithmic tasks to new data (e.g., larger graphs or edge weights) relies on encoding task-specific non-linearities in the architecture or features. Our theoretical analysis builds on a connection of over-parameterized networks to the neural tangent kernel.  Empirically, our theory holds across different training settings.", "one-sentence_summary": "We study how neural networks trained by gradient descent extrapolate.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "xu|how_neural_networks_extrapolate_from_feedforward_to_graph_neural_networks", "supplementary_material": "", "pdf": "/pdf/eb776544f1a0835881289e4dad2436f38f88269d.pdf", "venue": "ICLR 2021 Oral", "venueid": "ICLR.cc/2021/Conference", "_bibtex": "@inproceedings{\nxu2021how,\ntitle={How Neural Networks Extrapolate: From Feedforward to Graph Neural Networks},\nauthor={Keyulu Xu and Mozhi Zhang and Jingling Li and Simon Shaolei Du and Ken-Ichi Kawarabayashi and Stefanie Jegelka},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=UH-cmocLJC}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq . ***Please remember to file the Code-of-Ethics report. Once you submitted the review, a link to the report will be visible in the bottom right corner of your review.***", "required": true, "markdown": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}, "forum": "UH-cmocLJC", "replyto": "UH-cmocLJC", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"], "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper700/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1607428800000, "duedate": 1606752000000, "multiReply": false, "readers": ["everyone"], "tcdate": 1602538137063, "tmdate": 1606915768872, "super": "ICLR.cc/2021/Conference/-/Official_Review", "signatures": ["OpenReview.net"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Paper700/Reviewers", "OpenReview.net/Support"], "id": "ICLR.cc/2021/Conference/Paper700/-/Official_Review"}}}, {"id": "LQfVfXXzfT", "original": null, "number": 4, "cdate": 1605970936686, "ddate": null, "tcdate": 1605970936686, "tmdate": 1605972629820, "tddate": null, "forum": "UH-cmocLJC", "replyto": "sP3shlpXqlP", "invitation": "ICLR.cc/2021/Conference/Paper700/-/Official_Comment", "content": {"title": "Our response", "comment": "Thank you for your insightful feedback. \n\nWe have made the assumptions of our theorems clearer throughout the paper: (1) In the abstract, we now state that our theoretical results build on the connection between overparameterized networks and the neural tangent kernel; (2) We have clarified that we are using the squared loss in all theorems; (3) In the introduction and Section 3, we have emphasized that our proofs are for two-layer networks. As you have realized, we use experiments to confirm that our theory holds across different training settings, such as 4-layer networks (Appendix C.1 and C.2). Therefore, the assumptions in the theorems can be relaxed in practice. Thank you again for your helpful suggestions. Please let us know if any part remains inaccurate, and we will fix it in the final version.\n\nWe answer your questions below.\n\nQ1: Could the proofs of Theorem 3 and Theorem 5 be generalized to MLPs with more layers?\n\nA1: After some preliminary calculation, we believe our proof techniques can be extended to more than two layers. However, a full proof for more layers requires significant effort, so we do not have a complete proof at the moment. Note that most theoretical works on NTK focus on two layers for similar reasons. As you may have noticed, we do have experimental results to confirm that our theory holds for deeper networks (Appendix C.1 and C.2). We agree that extending the proof to multiple layers is an important future direction.\n\nQ2: Can we gain some insight into extrapolation with other loss functions like softmax based on these results?\n\nA2: Unfortunately, it is hard to extend the theory to the softmax loss, but, we agree this is an important direction for future work. Note that the squared loss can be competitive to other losses for classification [1], so the lessons we learned from regression tasks may also be useful for classification tasks. \n\n[1] On Loss Functions for Deep Neural Networks in Classification. Janocha et al. 2017\n\nWe have fixed the grammar mistakes as suggested.\n\nWe are happy to answer any other questions you may have.\n"}, "signatures": ["ICLR.cc/2021/Conference/Paper700/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper700/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "How Neural Networks Extrapolate: From Feedforward to Graph Neural Networks", "authorids": ["~Keyulu_Xu1", "~Mozhi_Zhang1", "~Jingling_Li1", "~Simon_Shaolei_Du1", "~Ken-Ichi_Kawarabayashi1", "~Stefanie_Jegelka3"], "authors": ["Keyulu Xu", "Mozhi Zhang", "Jingling Li", "Simon Shaolei Du", "Ken-Ichi Kawarabayashi", "Stefanie Jegelka"], "keywords": ["extrapolation", "deep learning", "out-of-distribution", "graph neural networks", "deep learning theory"], "abstract": "We study how neural networks trained by gradient descent  extrapolate, i.e., what they learn outside the support of the training distribution. Previous works report mixed empirical results when extrapolating with neural networks: while feedforward neural networks, a.k.a. multilayer perceptrons (MLPs), do not extrapolate well in certain simple tasks, Graph Neural Networks (GNNs) -- structured networks with MLP modules -- have shown some success in more complex tasks.  Working towards a theoretical explanation, we identify conditions under which MLPs and GNNs extrapolate well. First, we quantify the observation that ReLU MLPs quickly converge to linear functions along any direction from the origin, which implies that ReLU MLPs do not extrapolate most nonlinear functions. But, they can provably learn a linear target function when the training distribution is sufficiently diverse. Second, in connection to analyzing the successes and limitations of GNNs, these results suggest a hypothesis for which we provide theoretical and empirical evidence: the success of GNNs in extrapolating algorithmic tasks to new data (e.g., larger graphs or edge weights) relies on encoding task-specific non-linearities in the architecture or features. Our theoretical analysis builds on a connection of over-parameterized networks to the neural tangent kernel.  Empirically, our theory holds across different training settings.", "one-sentence_summary": "We study how neural networks trained by gradient descent extrapolate.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "xu|how_neural_networks_extrapolate_from_feedforward_to_graph_neural_networks", "supplementary_material": "", "pdf": "/pdf/eb776544f1a0835881289e4dad2436f38f88269d.pdf", "venue": "ICLR 2021 Oral", "venueid": "ICLR.cc/2021/Conference", "_bibtex": "@inproceedings{\nxu2021how,\ntitle={How Neural Networks Extrapolate: From Feedforward to Graph Neural Networks},\nauthor={Keyulu Xu and Mozhi Zhang and Jingling Li and Simon Shaolei Du and Ken-Ichi Kawarabayashi and Stefanie Jegelka},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=UH-cmocLJC}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "UH-cmocLJC", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper700/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper700/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper700/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper700/Authors|ICLR.cc/2021/Conference/Paper700/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper700/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923868139, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper700/-/Official_Comment"}}}, {"id": "GVs8ta3-S2W", "original": null, "number": 3, "cdate": 1605970837391, "ddate": null, "tcdate": 1605970837391, "tmdate": 1605971184677, "tddate": null, "forum": "UH-cmocLJC", "replyto": "UH-cmocLJC", "invitation": "ICLR.cc/2021/Conference/Paper700/-/Official_Comment", "content": {"title": "Update", "comment": "Dear Reviewers and AC,\n\n\nWe have updated our draft to incorporate the insightful suggestions of the reviewers:\n\nFollowing Reviewer 3 and  Reviewer 4\u2019s suggestion, we have added additional extrapolation experiments on MLPs with different activation functions (tanh, quadratic, and cosine) in Section 3.3 (preliminary results previously presented in Appendix).\n\nFollowing Reviewer 4\u2019s suggestion, we have added a section (Section 5) on relations to other out-of-distribution settings, including domain adaptation, self-supervised learning, invariant models, and distributional robustness. \n\nFollowing Reviewer 2\u2019s suggestion, we have made the assumptions of our theorems clearer throughout the paper. We have also emphasized that our theoretical results empirically hold across different training settings (e.g., width, depth, learning rate, batch size), so the assumptions may be relaxed in practice.\n\nFollowing reviewer 3\u2019s suggestion, we have discussed the related work Neural Arithmetic Logic Units in Section 4.1. Our results may suggest an explanation why their proposed architecture improves extrapolation in arithmetic tasks.\n\nWe will improve other minor points of Reviewer 1, Reviewer 2, Reviewer 3, Reviewer 4 in the final version. Thank you all for the valuable suggestions.\n\nPlease let us know if you have additional questions.\n\n\nThank you,\n\nAuthors\n"}, "signatures": ["ICLR.cc/2021/Conference/Paper700/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper700/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "How Neural Networks Extrapolate: From Feedforward to Graph Neural Networks", "authorids": ["~Keyulu_Xu1", "~Mozhi_Zhang1", "~Jingling_Li1", "~Simon_Shaolei_Du1", "~Ken-Ichi_Kawarabayashi1", "~Stefanie_Jegelka3"], "authors": ["Keyulu Xu", "Mozhi Zhang", "Jingling Li", "Simon Shaolei Du", "Ken-Ichi Kawarabayashi", "Stefanie Jegelka"], "keywords": ["extrapolation", "deep learning", "out-of-distribution", "graph neural networks", "deep learning theory"], "abstract": "We study how neural networks trained by gradient descent  extrapolate, i.e., what they learn outside the support of the training distribution. Previous works report mixed empirical results when extrapolating with neural networks: while feedforward neural networks, a.k.a. multilayer perceptrons (MLPs), do not extrapolate well in certain simple tasks, Graph Neural Networks (GNNs) -- structured networks with MLP modules -- have shown some success in more complex tasks.  Working towards a theoretical explanation, we identify conditions under which MLPs and GNNs extrapolate well. First, we quantify the observation that ReLU MLPs quickly converge to linear functions along any direction from the origin, which implies that ReLU MLPs do not extrapolate most nonlinear functions. But, they can provably learn a linear target function when the training distribution is sufficiently diverse. Second, in connection to analyzing the successes and limitations of GNNs, these results suggest a hypothesis for which we provide theoretical and empirical evidence: the success of GNNs in extrapolating algorithmic tasks to new data (e.g., larger graphs or edge weights) relies on encoding task-specific non-linearities in the architecture or features. Our theoretical analysis builds on a connection of over-parameterized networks to the neural tangent kernel.  Empirically, our theory holds across different training settings.", "one-sentence_summary": "We study how neural networks trained by gradient descent extrapolate.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "xu|how_neural_networks_extrapolate_from_feedforward_to_graph_neural_networks", "supplementary_material": "", "pdf": "/pdf/eb776544f1a0835881289e4dad2436f38f88269d.pdf", "venue": "ICLR 2021 Oral", "venueid": "ICLR.cc/2021/Conference", "_bibtex": "@inproceedings{\nxu2021how,\ntitle={How Neural Networks Extrapolate: From Feedforward to Graph Neural Networks},\nauthor={Keyulu Xu and Mozhi Zhang and Jingling Li and Simon Shaolei Du and Ken-Ichi Kawarabayashi and Stefanie Jegelka},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=UH-cmocLJC}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "UH-cmocLJC", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper700/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper700/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper700/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper700/Authors|ICLR.cc/2021/Conference/Paper700/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper700/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923868139, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper700/-/Official_Comment"}}}, {"id": "FxBmvb_LhUK", "original": null, "number": 7, "cdate": 1605971049434, "ddate": null, "tcdate": 1605971049434, "tmdate": 1605971049434, "tddate": null, "forum": "UH-cmocLJC", "replyto": "16iWXj6OMC_", "invitation": "ICLR.cc/2021/Conference/Paper700/-/Official_Comment", "content": {"title": "Our response", "comment": "Thank you for your insightful feedback. \n\nWe have added additional experiments on MLPs with tanh, quadratic, and cosine activation functions in Section 3.3. We explore the extrapolation ability of these MLPs on tasks that we used for ReLU MLPs. In general, an MLP is better at extrapolating functions that involve non-linearities \u201csimilar\u201d to the MLP\u2019s activation, e.g., quadratic MLP extrapolates well when learning quadratic functions. We leave further theoretical analyses to future work.\n\nThank you for pointing us to previous works on arithmetic tasks and neural arithmetic logic units (NALUs). They are indeed quite related. In Section 4.1, we use our theoretical results to offer a potential explanation on why NALUs help extrapolation in arithmetic tasks. To learn multiplication, NALUs encode a log-and-exp non-linear transform in the architecture. Since log(a * b) = log a + log b, this transform reduces multiplication to a linear function, which helps extrapolation following our linear algorithmic alignment hypothesis. To improve learning addition operations, they propose sparsity constraints, which is beyond the scope of our paper.\n\nWe are happy to answer any other questions you may have.\n"}, "signatures": ["ICLR.cc/2021/Conference/Paper700/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper700/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "How Neural Networks Extrapolate: From Feedforward to Graph Neural Networks", "authorids": ["~Keyulu_Xu1", "~Mozhi_Zhang1", "~Jingling_Li1", "~Simon_Shaolei_Du1", "~Ken-Ichi_Kawarabayashi1", "~Stefanie_Jegelka3"], "authors": ["Keyulu Xu", "Mozhi Zhang", "Jingling Li", "Simon Shaolei Du", "Ken-Ichi Kawarabayashi", "Stefanie Jegelka"], "keywords": ["extrapolation", "deep learning", "out-of-distribution", "graph neural networks", "deep learning theory"], "abstract": "We study how neural networks trained by gradient descent  extrapolate, i.e., what they learn outside the support of the training distribution. Previous works report mixed empirical results when extrapolating with neural networks: while feedforward neural networks, a.k.a. multilayer perceptrons (MLPs), do not extrapolate well in certain simple tasks, Graph Neural Networks (GNNs) -- structured networks with MLP modules -- have shown some success in more complex tasks.  Working towards a theoretical explanation, we identify conditions under which MLPs and GNNs extrapolate well. First, we quantify the observation that ReLU MLPs quickly converge to linear functions along any direction from the origin, which implies that ReLU MLPs do not extrapolate most nonlinear functions. But, they can provably learn a linear target function when the training distribution is sufficiently diverse. Second, in connection to analyzing the successes and limitations of GNNs, these results suggest a hypothesis for which we provide theoretical and empirical evidence: the success of GNNs in extrapolating algorithmic tasks to new data (e.g., larger graphs or edge weights) relies on encoding task-specific non-linearities in the architecture or features. Our theoretical analysis builds on a connection of over-parameterized networks to the neural tangent kernel.  Empirically, our theory holds across different training settings.", "one-sentence_summary": "We study how neural networks trained by gradient descent extrapolate.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "xu|how_neural_networks_extrapolate_from_feedforward_to_graph_neural_networks", "supplementary_material": "", "pdf": "/pdf/eb776544f1a0835881289e4dad2436f38f88269d.pdf", "venue": "ICLR 2021 Oral", "venueid": "ICLR.cc/2021/Conference", "_bibtex": "@inproceedings{\nxu2021how,\ntitle={How Neural Networks Extrapolate: From Feedforward to Graph Neural Networks},\nauthor={Keyulu Xu and Mozhi Zhang and Jingling Li and Simon Shaolei Du and Ken-Ichi Kawarabayashi and Stefanie Jegelka},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=UH-cmocLJC}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "UH-cmocLJC", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper700/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper700/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper700/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper700/Authors|ICLR.cc/2021/Conference/Paper700/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper700/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923868139, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper700/-/Official_Comment"}}}, {"id": "T2lcmtQuaN0", "original": null, "number": 6, "cdate": 1605971025650, "ddate": null, "tcdate": 1605971025650, "tmdate": 1605971025650, "tddate": null, "forum": "UH-cmocLJC", "replyto": "ErscdGWPVMS", "invitation": "ICLR.cc/2021/Conference/Paper700/-/Official_Comment", "content": {"title": "Our response", "comment": "Thank you for your insightful feedback. We answer your questions below.\n\nQ1: In Section 3.2, \u201cdiversity\u201d of a distribution is informally defined in terms of training support and direction. A more thorough definition would be helpful.\n\nA1: We have provided an exact definition of \u201cdiversity\u201d in Theorem 5. By \u201cdirection\u201d, we are referring to the non-zero vector w. \n\nQ2: The title of the paper is somewhat misleading: \u201cfrom feedforward to GNN\u201d insinuates that there are other network types that are discussed in the paper.\n\nA2: We are sorry for your confusion. The title refers to the relation that GNNs are built on feedforward network modules. In our paper, our analysis of feedforward networks (Section 3) leads to our understanding of the more complex GNNs (Section 4). We hope the title is appropriate from this perspective. Please let us know if you still have concerns. \n\nWe are happy to answer any other questions you may have.\n"}, "signatures": ["ICLR.cc/2021/Conference/Paper700/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper700/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "How Neural Networks Extrapolate: From Feedforward to Graph Neural Networks", "authorids": ["~Keyulu_Xu1", "~Mozhi_Zhang1", "~Jingling_Li1", "~Simon_Shaolei_Du1", "~Ken-Ichi_Kawarabayashi1", "~Stefanie_Jegelka3"], "authors": ["Keyulu Xu", "Mozhi Zhang", "Jingling Li", "Simon Shaolei Du", "Ken-Ichi Kawarabayashi", "Stefanie Jegelka"], "keywords": ["extrapolation", "deep learning", "out-of-distribution", "graph neural networks", "deep learning theory"], "abstract": "We study how neural networks trained by gradient descent  extrapolate, i.e., what they learn outside the support of the training distribution. Previous works report mixed empirical results when extrapolating with neural networks: while feedforward neural networks, a.k.a. multilayer perceptrons (MLPs), do not extrapolate well in certain simple tasks, Graph Neural Networks (GNNs) -- structured networks with MLP modules -- have shown some success in more complex tasks.  Working towards a theoretical explanation, we identify conditions under which MLPs and GNNs extrapolate well. First, we quantify the observation that ReLU MLPs quickly converge to linear functions along any direction from the origin, which implies that ReLU MLPs do not extrapolate most nonlinear functions. But, they can provably learn a linear target function when the training distribution is sufficiently diverse. Second, in connection to analyzing the successes and limitations of GNNs, these results suggest a hypothesis for which we provide theoretical and empirical evidence: the success of GNNs in extrapolating algorithmic tasks to new data (e.g., larger graphs or edge weights) relies on encoding task-specific non-linearities in the architecture or features. Our theoretical analysis builds on a connection of over-parameterized networks to the neural tangent kernel.  Empirically, our theory holds across different training settings.", "one-sentence_summary": "We study how neural networks trained by gradient descent extrapolate.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "xu|how_neural_networks_extrapolate_from_feedforward_to_graph_neural_networks", "supplementary_material": "", "pdf": "/pdf/eb776544f1a0835881289e4dad2436f38f88269d.pdf", "venue": "ICLR 2021 Oral", "venueid": "ICLR.cc/2021/Conference", "_bibtex": "@inproceedings{\nxu2021how,\ntitle={How Neural Networks Extrapolate: From Feedforward to Graph Neural Networks},\nauthor={Keyulu Xu and Mozhi Zhang and Jingling Li and Simon Shaolei Du and Ken-Ichi Kawarabayashi and Stefanie Jegelka},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=UH-cmocLJC}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "UH-cmocLJC", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper700/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper700/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper700/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper700/Authors|ICLR.cc/2021/Conference/Paper700/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper700/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923868139, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper700/-/Official_Comment"}}}, {"id": "_8lP2qbBpGL", "original": null, "number": 5, "cdate": 1605970989212, "ddate": null, "tcdate": 1605970989212, "tmdate": 1605970989212, "tddate": null, "forum": "UH-cmocLJC", "replyto": "qmzcnHg2Pu", "invitation": "ICLR.cc/2021/Conference/Paper700/-/Official_Comment", "content": {"title": "Our response", "comment": "Thank you for your insightful feedback. \n\nWe have added additional experiments on MLPs with tanh, quadratic, and cosine activation functions in Section 3.3. We explore the extrapolation ability of these MLPs on tasks that we used for ReLU MLPs. In general, an MLP is better at extrapolating functions that involve non-linearities \u201csimilar\u201d to the MLP\u2019s activation, e.g., quadratic MLP extrapolates well when learning quadratic functions. We leave theoretical analysis to future work.\n\nWe have added Section 5 to discuss the connections of our results with other out-of-distribution settings including domain adaptation, self-supervised learning, invariant models, and distributional robustness. We conjecture that some of these methods may improve extrapolation by (1) learning useful non-linearities beyond the training data range from unlabeled out-of-distribution data and (2) mapping relevant out-of-distribution test data to the training data range.\n\nWe are happy to answer any other questions you may have.\n"}, "signatures": ["ICLR.cc/2021/Conference/Paper700/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper700/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "How Neural Networks Extrapolate: From Feedforward to Graph Neural Networks", "authorids": ["~Keyulu_Xu1", "~Mozhi_Zhang1", "~Jingling_Li1", "~Simon_Shaolei_Du1", "~Ken-Ichi_Kawarabayashi1", "~Stefanie_Jegelka3"], "authors": ["Keyulu Xu", "Mozhi Zhang", "Jingling Li", "Simon Shaolei Du", "Ken-Ichi Kawarabayashi", "Stefanie Jegelka"], "keywords": ["extrapolation", "deep learning", "out-of-distribution", "graph neural networks", "deep learning theory"], "abstract": "We study how neural networks trained by gradient descent  extrapolate, i.e., what they learn outside the support of the training distribution. Previous works report mixed empirical results when extrapolating with neural networks: while feedforward neural networks, a.k.a. multilayer perceptrons (MLPs), do not extrapolate well in certain simple tasks, Graph Neural Networks (GNNs) -- structured networks with MLP modules -- have shown some success in more complex tasks.  Working towards a theoretical explanation, we identify conditions under which MLPs and GNNs extrapolate well. First, we quantify the observation that ReLU MLPs quickly converge to linear functions along any direction from the origin, which implies that ReLU MLPs do not extrapolate most nonlinear functions. But, they can provably learn a linear target function when the training distribution is sufficiently diverse. Second, in connection to analyzing the successes and limitations of GNNs, these results suggest a hypothesis for which we provide theoretical and empirical evidence: the success of GNNs in extrapolating algorithmic tasks to new data (e.g., larger graphs or edge weights) relies on encoding task-specific non-linearities in the architecture or features. Our theoretical analysis builds on a connection of over-parameterized networks to the neural tangent kernel.  Empirically, our theory holds across different training settings.", "one-sentence_summary": "We study how neural networks trained by gradient descent extrapolate.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "xu|how_neural_networks_extrapolate_from_feedforward_to_graph_neural_networks", "supplementary_material": "", "pdf": "/pdf/eb776544f1a0835881289e4dad2436f38f88269d.pdf", "venue": "ICLR 2021 Oral", "venueid": "ICLR.cc/2021/Conference", "_bibtex": "@inproceedings{\nxu2021how,\ntitle={How Neural Networks Extrapolate: From Feedforward to Graph Neural Networks},\nauthor={Keyulu Xu and Mozhi Zhang and Jingling Li and Simon Shaolei Du and Ken-Ichi Kawarabayashi and Stefanie Jegelka},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=UH-cmocLJC}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "UH-cmocLJC", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper700/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper700/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper700/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper700/Authors|ICLR.cc/2021/Conference/Paper700/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper700/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923868139, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper700/-/Official_Comment"}}}, {"id": "hQuIfgDRma4", "original": null, "number": 2, "cdate": 1605382409540, "ddate": null, "tcdate": 1605382409540, "tmdate": 1605754539107, "tddate": null, "forum": "UH-cmocLJC", "replyto": "UH-cmocLJC", "invitation": "ICLR.cc/2021/Conference/Paper700/-/Official_Comment", "content": {"title": "General Update", "comment": "Dear Reviewers and AC,\n\nWe sincerely appreciate all the reviews. They give positive and high-quality comments on our paper with a lot of constructive feedback. We are working on incorporating the insightful and valuable suggestions from the reviewers. We will update the draft and post the response soon."}, "signatures": ["ICLR.cc/2021/Conference/Paper700/Authors"], "readers": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper700/Area_Chairs", "ICLR.cc/2021/Conference/Paper700/Reviewers", "ICLR.cc/2021/Conference/Paper700/Authors", "everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper700/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "How Neural Networks Extrapolate: From Feedforward to Graph Neural Networks", "authorids": ["~Keyulu_Xu1", "~Mozhi_Zhang1", "~Jingling_Li1", "~Simon_Shaolei_Du1", "~Ken-Ichi_Kawarabayashi1", "~Stefanie_Jegelka3"], "authors": ["Keyulu Xu", "Mozhi Zhang", "Jingling Li", "Simon Shaolei Du", "Ken-Ichi Kawarabayashi", "Stefanie Jegelka"], "keywords": ["extrapolation", "deep learning", "out-of-distribution", "graph neural networks", "deep learning theory"], "abstract": "We study how neural networks trained by gradient descent  extrapolate, i.e., what they learn outside the support of the training distribution. Previous works report mixed empirical results when extrapolating with neural networks: while feedforward neural networks, a.k.a. multilayer perceptrons (MLPs), do not extrapolate well in certain simple tasks, Graph Neural Networks (GNNs) -- structured networks with MLP modules -- have shown some success in more complex tasks.  Working towards a theoretical explanation, we identify conditions under which MLPs and GNNs extrapolate well. First, we quantify the observation that ReLU MLPs quickly converge to linear functions along any direction from the origin, which implies that ReLU MLPs do not extrapolate most nonlinear functions. But, they can provably learn a linear target function when the training distribution is sufficiently diverse. Second, in connection to analyzing the successes and limitations of GNNs, these results suggest a hypothesis for which we provide theoretical and empirical evidence: the success of GNNs in extrapolating algorithmic tasks to new data (e.g., larger graphs or edge weights) relies on encoding task-specific non-linearities in the architecture or features. Our theoretical analysis builds on a connection of over-parameterized networks to the neural tangent kernel.  Empirically, our theory holds across different training settings.", "one-sentence_summary": "We study how neural networks trained by gradient descent extrapolate.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "xu|how_neural_networks_extrapolate_from_feedforward_to_graph_neural_networks", "supplementary_material": "", "pdf": "/pdf/eb776544f1a0835881289e4dad2436f38f88269d.pdf", "venue": "ICLR 2021 Oral", "venueid": "ICLR.cc/2021/Conference", "_bibtex": "@inproceedings{\nxu2021how,\ntitle={How Neural Networks Extrapolate: From Feedforward to Graph Neural Networks},\nauthor={Keyulu Xu and Mozhi Zhang and Jingling Li and Simon Shaolei Du and Ken-Ichi Kawarabayashi and Stefanie Jegelka},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=UH-cmocLJC}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "UH-cmocLJC", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper700/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper700/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper700/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper700/Authors|ICLR.cc/2021/Conference/Paper700/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper700/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923868139, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper700/-/Official_Comment"}}}, {"id": "16iWXj6OMC_", "original": null, "number": 2, "cdate": 1603797581610, "ddate": null, "tcdate": 1603797581610, "tmdate": 1605024626924, "tddate": null, "forum": "UH-cmocLJC", "replyto": "UH-cmocLJC", "invitation": "ICLR.cc/2021/Conference/Paper700/-/Official_Review", "content": {"title": "An interesting paper that opens new directions to better extrapolate our current knowledge about deep learning", "review": "This paper tackles the challenging question of how deep networks might learn to extrapolate knowledge outside the support of their training distribution. The paper contributes both with novel theoretical arguments as well as with empirical evidence collected on targeted cases. Differently from other recent approaches to the problem, the theoretical analyses presented here are non-asymptotic and provide precise information about the kind of functions that MLPs can learn in the proximity of the training region. Moreover, the authors provide compelling arguments about the need to explicitly encoding (task-specific) non-linearities in the input representation and/or in the model architecture in order to promote successful extrapolation.\nOverall, the paper addresses important issues and can be considered at the frontier of deep learning research. The paper is well-written and the recent literature is properly reviewed. In light of this, I think the paper would be of interest to the ICLR community. However, I would like to explicitly mention that I was not able to carefully review all the details and proofs reported in the Appendix, which is of an unusual length (almost 40 pages) for an ICLR paper.\n\nComments for possible improvements:\n- The analyses reported in Appendix D.3 / C.4 regarding the extrapolation capability of MLPs with different activation functions (sin, tanh, quadratic) are relevant and should be emphasized. They could also be expanded, for example by considering some data generation tasks analyzed in the main text.\n- It would be very interesting to extend this analysis to other simple problems, where MLPs cannot extrapolate appropriately. I am specifically referring to the simple counting and arithmetic tasks discussed in [1], where generalization outside the training distribution was achieved by adding ad-hoc gate units to the network. I think this domain is particularly relevant here, given that arithmetics is mentioned by the authors in the opening sentence of the paper.\n\n[1]\tA. Trask, F. Hill, S. Reed, J. Rae, C. Dyer, and P. Blunsom, \u201cNeural Arithmetic Logic Units,\u201d in arXiv:1808.00508, 2018.", "rating": "8: Top 50% of accepted papers, clear accept", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["ICLR.cc/2021/Conference/Paper700/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper700/AnonReviewer3"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "How Neural Networks Extrapolate: From Feedforward to Graph Neural Networks", "authorids": ["~Keyulu_Xu1", "~Mozhi_Zhang1", "~Jingling_Li1", "~Simon_Shaolei_Du1", "~Ken-Ichi_Kawarabayashi1", "~Stefanie_Jegelka3"], "authors": ["Keyulu Xu", "Mozhi Zhang", "Jingling Li", "Simon Shaolei Du", "Ken-Ichi Kawarabayashi", "Stefanie Jegelka"], "keywords": ["extrapolation", "deep learning", "out-of-distribution", "graph neural networks", "deep learning theory"], "abstract": "We study how neural networks trained by gradient descent  extrapolate, i.e., what they learn outside the support of the training distribution. Previous works report mixed empirical results when extrapolating with neural networks: while feedforward neural networks, a.k.a. multilayer perceptrons (MLPs), do not extrapolate well in certain simple tasks, Graph Neural Networks (GNNs) -- structured networks with MLP modules -- have shown some success in more complex tasks.  Working towards a theoretical explanation, we identify conditions under which MLPs and GNNs extrapolate well. First, we quantify the observation that ReLU MLPs quickly converge to linear functions along any direction from the origin, which implies that ReLU MLPs do not extrapolate most nonlinear functions. But, they can provably learn a linear target function when the training distribution is sufficiently diverse. Second, in connection to analyzing the successes and limitations of GNNs, these results suggest a hypothesis for which we provide theoretical and empirical evidence: the success of GNNs in extrapolating algorithmic tasks to new data (e.g., larger graphs or edge weights) relies on encoding task-specific non-linearities in the architecture or features. Our theoretical analysis builds on a connection of over-parameterized networks to the neural tangent kernel.  Empirically, our theory holds across different training settings.", "one-sentence_summary": "We study how neural networks trained by gradient descent extrapolate.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "xu|how_neural_networks_extrapolate_from_feedforward_to_graph_neural_networks", "supplementary_material": "", "pdf": "/pdf/eb776544f1a0835881289e4dad2436f38f88269d.pdf", "venue": "ICLR 2021 Oral", "venueid": "ICLR.cc/2021/Conference", "_bibtex": "@inproceedings{\nxu2021how,\ntitle={How Neural Networks Extrapolate: From Feedforward to Graph Neural Networks},\nauthor={Keyulu Xu and Mozhi Zhang and Jingling Li and Simon Shaolei Du and Ken-Ichi Kawarabayashi and Stefanie Jegelka},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=UH-cmocLJC}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq . ***Please remember to file the Code-of-Ethics report. Once you submitted the review, a link to the report will be visible in the bottom right corner of your review.***", "required": true, "markdown": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}, "forum": "UH-cmocLJC", "replyto": "UH-cmocLJC", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"], "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper700/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1607428800000, "duedate": 1606752000000, "multiReply": false, "readers": ["everyone"], "tcdate": 1602538137063, "tmdate": 1606915768872, "super": "ICLR.cc/2021/Conference/-/Official_Review", "signatures": ["OpenReview.net"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Paper700/Reviewers", "OpenReview.net/Support"], "id": "ICLR.cc/2021/Conference/Paper700/-/Official_Review"}}}, {"id": "ErscdGWPVMS", "original": null, "number": 3, "cdate": 1603815611771, "ddate": null, "tcdate": 1603815611771, "tmdate": 1605024626857, "tddate": null, "forum": "UH-cmocLJC", "replyto": "UH-cmocLJC", "invitation": "ICLR.cc/2021/Conference/Paper700/-/Official_Review", "content": {"title": "Important work that enhances our understanding of graph neural networks. Ideas are relevant, solid, and well supported. Excellent work overall.", "review": "This paper investigates the extrapolation power of MLPs and GNNs (trained by gradient descent with mean squared loss) from a theoretical perspective. The authors show results of extensive experiments that back up their theoretical findings.  \n\nIn particular, the authors study the question of what these neural networks learn outside the training distribution, and identify conditions when they extrapolate well. Their findings suggest that ReLU MLPs extrapolate well in linear tasks, with a fast convergence rate (O(1/\\epsilon). GNNs (having MLP modules) extrapolate well when the non-linear operations are encoded in either network architecture or data representation, so as the inner MLP modules are aligned with only linear functions.\n\nThe paper is well written, ideas and definitions clearly explained and experiments laid out in detail. The theoretical contributions of the work are important as they enhance our understanding of how these networks learn and how well they generalize. These findings help us design GNNs based on the data and problem at hand. As such, this work addresses a fundamental question in GNN understanding and must be published. \n\nSome comments/questions to the authors:\n- In Section 3.2, \u201cdiversity\u201d of a distribution is informally defined in terms of training support and direction. A more thorough definition would be helpful. \n- The title of the paper is somewhat misleading: \u201cfrom feedforward to GNN\u201d insinuates that there are other network types that are discussed in the paper.\n", "rating": "9: Top 15% of accepted papers, strong accept", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["ICLR.cc/2021/Conference/Paper700/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper700/AnonReviewer1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "How Neural Networks Extrapolate: From Feedforward to Graph Neural Networks", "authorids": ["~Keyulu_Xu1", "~Mozhi_Zhang1", "~Jingling_Li1", "~Simon_Shaolei_Du1", "~Ken-Ichi_Kawarabayashi1", "~Stefanie_Jegelka3"], "authors": ["Keyulu Xu", "Mozhi Zhang", "Jingling Li", "Simon Shaolei Du", "Ken-Ichi Kawarabayashi", "Stefanie Jegelka"], "keywords": ["extrapolation", "deep learning", "out-of-distribution", "graph neural networks", "deep learning theory"], "abstract": "We study how neural networks trained by gradient descent  extrapolate, i.e., what they learn outside the support of the training distribution. Previous works report mixed empirical results when extrapolating with neural networks: while feedforward neural networks, a.k.a. multilayer perceptrons (MLPs), do not extrapolate well in certain simple tasks, Graph Neural Networks (GNNs) -- structured networks with MLP modules -- have shown some success in more complex tasks.  Working towards a theoretical explanation, we identify conditions under which MLPs and GNNs extrapolate well. First, we quantify the observation that ReLU MLPs quickly converge to linear functions along any direction from the origin, which implies that ReLU MLPs do not extrapolate most nonlinear functions. But, they can provably learn a linear target function when the training distribution is sufficiently diverse. Second, in connection to analyzing the successes and limitations of GNNs, these results suggest a hypothesis for which we provide theoretical and empirical evidence: the success of GNNs in extrapolating algorithmic tasks to new data (e.g., larger graphs or edge weights) relies on encoding task-specific non-linearities in the architecture or features. Our theoretical analysis builds on a connection of over-parameterized networks to the neural tangent kernel.  Empirically, our theory holds across different training settings.", "one-sentence_summary": "We study how neural networks trained by gradient descent extrapolate.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "xu|how_neural_networks_extrapolate_from_feedforward_to_graph_neural_networks", "supplementary_material": "", "pdf": "/pdf/eb776544f1a0835881289e4dad2436f38f88269d.pdf", "venue": "ICLR 2021 Oral", "venueid": "ICLR.cc/2021/Conference", "_bibtex": "@inproceedings{\nxu2021how,\ntitle={How Neural Networks Extrapolate: From Feedforward to Graph Neural Networks},\nauthor={Keyulu Xu and Mozhi Zhang and Jingling Li and Simon Shaolei Du and Ken-Ichi Kawarabayashi and Stefanie Jegelka},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=UH-cmocLJC}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq . ***Please remember to file the Code-of-Ethics report. Once you submitted the review, a link to the report will be visible in the bottom right corner of your review.***", "required": true, "markdown": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}, "forum": "UH-cmocLJC", "replyto": "UH-cmocLJC", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"], "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper700/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1607428800000, "duedate": 1606752000000, "multiReply": false, "readers": ["everyone"], "tcdate": 1602538137063, "tmdate": 1606915768872, "super": "ICLR.cc/2021/Conference/-/Official_Review", "signatures": ["OpenReview.net"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Paper700/Reviewers", "OpenReview.net/Support"], "id": "ICLR.cc/2021/Conference/Paper700/-/Official_Review"}}}, {"id": "qmzcnHg2Pu", "original": null, "number": 4, "cdate": 1603820443520, "ddate": null, "tcdate": 1603820443520, "tmdate": 1605024626790, "tddate": null, "forum": "UH-cmocLJC", "replyto": "UH-cmocLJC", "invitation": "ICLR.cc/2021/Conference/Paper700/-/Official_Review", "content": {"title": "Crucial study on extrapolate ability of MLP and GNN that provides a different aspect of analysis on multi-domain adapatation", "review": "This paper analyzes the extrapolate ability of MLPs and GNNs. In contrast to the existing theoretical works that focus on generalizability  and capacity of these models, this paper emphasizes the behavior of training algorithm using gradient descent. It takes analogy of kernel regression via the neural tangent kernel as an example to study the bias induced by the gradient descent algorithm. The presentation of this paper is clear and well-organized with the most significant result shown in the first section, raising interest of the readers, as opposed to leaving them behind a massive amount of proofs. The contribution of this paper is significant as well since it draws attention of the researcher to theoretical analysis on the bias induced from the implementations of the algorithms as compared to the theoretical analysis on the model structure itself. Model extrapolation is also closely connected to topics such as meta-learning, multi-task learning, domain adaptation and semi-supervised learning since the ability of model extrapolation will limit its performance when applied to other tasks. \n\nPros:\n1. This paper has shown some interesting results: for instance, MLP with ReLU trained by GD will converge to linear functions along any direction from origin outside the support of the training data. This coincide with the idea that MLP are piecewise linear in different regions. The proof is complicated though and requires the analogy to the kernel regression as basis.  This result seems to suggest that the learning of MLP on data manifold supported by training data is also local linear and without support of training data, the induction follows the inertia of linearity.  It is curious to see if this is due to the piecewise linearity of ReLU function.  Maybe we will have better nonlinear extrapolation for MLP using tanh and other sigmoid functions. \n2.  Comparison between GNN and Dynamic programming algorithm is very intuitive and inspiring. It suggests that max/min aggregate as opposed to more commonly used sum-aggregate in GNN is more suitable for extrapolation and the similarity between max/min aggregate GNN and DP is also very convincing. In general, this paper built up a good intuition before diving into the proof, which is well-appreciated. \n3.   The suggestion to improve extrapolation is to put the nonlinearity into the architecture of the GNN or into the input representation is useful. For instance, replacing sum-aggregate to min/max aggregate helps to achieve good extrapolation. It also explains why the pre-trained embeddings such as BERT can be used in other tasks and still extrapolate well.\n\n\nSuggestions:\n1. Limitations of the study scope. This paper only discuss results of neural network using ReLU and GD. Although GD is widely used, the ReLU as the activation function plays a critical role in the study of extrapolation. It is necessary to provide analysis on the use of other common activation function to understand if the extrapolation ability is expanded. \n2.  It is interesting to see more connection with domain adaptation and semi-supervised learning as well.", "rating": "9: Top 15% of accepted papers, strong accept", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["ICLR.cc/2021/Conference/Paper700/AnonReviewer4"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper700/AnonReviewer4"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "How Neural Networks Extrapolate: From Feedforward to Graph Neural Networks", "authorids": ["~Keyulu_Xu1", "~Mozhi_Zhang1", "~Jingling_Li1", "~Simon_Shaolei_Du1", "~Ken-Ichi_Kawarabayashi1", "~Stefanie_Jegelka3"], "authors": ["Keyulu Xu", "Mozhi Zhang", "Jingling Li", "Simon Shaolei Du", "Ken-Ichi Kawarabayashi", "Stefanie Jegelka"], "keywords": ["extrapolation", "deep learning", "out-of-distribution", "graph neural networks", "deep learning theory"], "abstract": "We study how neural networks trained by gradient descent  extrapolate, i.e., what they learn outside the support of the training distribution. Previous works report mixed empirical results when extrapolating with neural networks: while feedforward neural networks, a.k.a. multilayer perceptrons (MLPs), do not extrapolate well in certain simple tasks, Graph Neural Networks (GNNs) -- structured networks with MLP modules -- have shown some success in more complex tasks.  Working towards a theoretical explanation, we identify conditions under which MLPs and GNNs extrapolate well. First, we quantify the observation that ReLU MLPs quickly converge to linear functions along any direction from the origin, which implies that ReLU MLPs do not extrapolate most nonlinear functions. But, they can provably learn a linear target function when the training distribution is sufficiently diverse. Second, in connection to analyzing the successes and limitations of GNNs, these results suggest a hypothesis for which we provide theoretical and empirical evidence: the success of GNNs in extrapolating algorithmic tasks to new data (e.g., larger graphs or edge weights) relies on encoding task-specific non-linearities in the architecture or features. Our theoretical analysis builds on a connection of over-parameterized networks to the neural tangent kernel.  Empirically, our theory holds across different training settings.", "one-sentence_summary": "We study how neural networks trained by gradient descent extrapolate.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "xu|how_neural_networks_extrapolate_from_feedforward_to_graph_neural_networks", "supplementary_material": "", "pdf": "/pdf/eb776544f1a0835881289e4dad2436f38f88269d.pdf", "venue": "ICLR 2021 Oral", "venueid": "ICLR.cc/2021/Conference", "_bibtex": "@inproceedings{\nxu2021how,\ntitle={How Neural Networks Extrapolate: From Feedforward to Graph Neural Networks},\nauthor={Keyulu Xu and Mozhi Zhang and Jingling Li and Simon Shaolei Du and Ken-Ichi Kawarabayashi and Stefanie Jegelka},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=UH-cmocLJC}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq . ***Please remember to file the Code-of-Ethics report. Once you submitted the review, a link to the report will be visible in the bottom right corner of your review.***", "required": true, "markdown": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}, "forum": "UH-cmocLJC", "replyto": "UH-cmocLJC", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"], "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper700/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1607428800000, "duedate": 1606752000000, "multiReply": false, "readers": ["everyone"], "tcdate": 1602538137063, "tmdate": 1606915768872, "super": "ICLR.cc/2021/Conference/-/Official_Review", "signatures": ["OpenReview.net"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Paper700/Reviewers", "OpenReview.net/Support"], "id": "ICLR.cc/2021/Conference/Paper700/-/Official_Review"}}}], "count": 14}