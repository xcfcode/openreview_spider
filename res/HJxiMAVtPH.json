{"notes": [{"id": "HJxiMAVtPH", "original": "rJg-0ZSdwS", "number": 1014, "cdate": 1569439251489, "ddate": null, "tcdate": 1569439251489, "tmdate": 1577168289627, "tddate": null, "forum": "HJxiMAVtPH", "replyto": null, "invitation": "ICLR.cc/2020/Conference/-/Blind_Submission", "content": {"title": "Multi-scale Attributed Node Embedding", "authors": ["Benedek Rozemberczki", "Carl Allen", "Rik Sarkar"], "authorids": ["benedek.rozemberczki@gmail.com", "carl.allen@ed.ac.uk", "rsarkar@inf.ed.ac.uk"], "keywords": ["network embedding", "graph embedding", "node embedding", "network science", "graph representation learning"], "TL;DR": "We develop efficient multi-scale approximate attributed network embedding procedures with provable properties.", "abstract": "We present network embedding algorithms that capture information about a node from the local distribution over node attributes around it, as observed over random walks following an approach similar to Skip-gram. Observations from neighborhoods of different sizes are either pooled (AE) or encoded distinctly in a multi-scale approach (MUSAE).  Capturing attribute-neighborhood relationships over multiple scales is useful for a diverse range of applications, including latent feature identification across disconnected networks with similar attributes. We prove theoretically that matrices of node-feature pointwise mutual information are implicitly factorized by the embeddings. Experiments show that our algorithms are robust, computationally efficient and outperform comparable models on social, web and citation network datasets.", "pdf": "/pdf/125239ee14eac85f8e0cff16d108f9e76d91b735.pdf", "code": "https://github.com/iclr2020/MUSAE/", "paperhash": "rozemberczki|multiscale_attributed_node_embedding", "original_pdf": "/attachment/eb44aa9a4c062a9f23c16496076fdcae8900dae0.pdf", "_bibtex": "@misc{\nrozemberczki2020multiscale,\ntitle={Multi-scale Attributed Node Embedding},\nauthor={Benedek Rozemberczki and Carl Allen and Rik Sarkar},\nyear={2020},\nurl={https://openreview.net/forum?id=HJxiMAVtPH}\n}"}, "signatures": ["ICLR.cc/2020/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference"], "details": {"replyCount": 9, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"reply": {"readers": {"values-regex": ".*"}, "writers": {"values": ["ICLR.cc/2020/Conference"]}, "signatures": {"values": ["ICLR.cc/2020/Conference"]}, "content": {"spotlight_video": {"value-regex": ".*"}, "full_presentation_video": {"value-regex": ".*"}, "original_pdf": {"required": false, "description": "Upload a PDF file that ends with .pdf", "value-regex": ".*"}, "appendix": {"value-regex": ".*"}, "authorids": {"values-regex": ".*"}, "poster": {"value-regex": ".*"}, "authors": {"values": ["Anonymous"]}, "slides": {"value-regex": ".*"}}}, "final": [], "signatures": ["ICLR.cc/2020/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference"], "noninvitees": [], "tcdate": 1569271260237, "tmdate": 1593459412141, "id": "ICLR.cc/2020/Conference/-/Blind_Submission"}}, "tauthor": "OpenReview.net"}, {"id": "534w7qBV3A", "original": null, "number": 1, "cdate": 1576798712293, "ddate": null, "tcdate": 1576798712293, "tmdate": 1576800924129, "tddate": null, "forum": "HJxiMAVtPH", "replyto": "HJxiMAVtPH", "invitation": "ICLR.cc/2020/Conference/Paper1014/-/Decision", "content": {"decision": "Reject", "comment": "This paper constitutes interesting progress on an important topic; the reviewers identify certain improvements and directions for future work, and I urge the authors to continue to develop refinements and extensions.", "title": "Paper Decision"}, "signatures": ["ICLR.cc/2020/Conference/Program_Chairs"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Program_Chairs"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Multi-scale Attributed Node Embedding", "authors": ["Benedek Rozemberczki", "Carl Allen", "Rik Sarkar"], "authorids": ["benedek.rozemberczki@gmail.com", "carl.allen@ed.ac.uk", "rsarkar@inf.ed.ac.uk"], "keywords": ["network embedding", "graph embedding", "node embedding", "network science", "graph representation learning"], "TL;DR": "We develop efficient multi-scale approximate attributed network embedding procedures with provable properties.", "abstract": "We present network embedding algorithms that capture information about a node from the local distribution over node attributes around it, as observed over random walks following an approach similar to Skip-gram. Observations from neighborhoods of different sizes are either pooled (AE) or encoded distinctly in a multi-scale approach (MUSAE).  Capturing attribute-neighborhood relationships over multiple scales is useful for a diverse range of applications, including latent feature identification across disconnected networks with similar attributes. We prove theoretically that matrices of node-feature pointwise mutual information are implicitly factorized by the embeddings. Experiments show that our algorithms are robust, computationally efficient and outperform comparable models on social, web and citation network datasets.", "pdf": "/pdf/125239ee14eac85f8e0cff16d108f9e76d91b735.pdf", "code": "https://github.com/iclr2020/MUSAE/", "paperhash": "rozemberczki|multiscale_attributed_node_embedding", "original_pdf": "/attachment/eb44aa9a4c062a9f23c16496076fdcae8900dae0.pdf", "_bibtex": "@misc{\nrozemberczki2020multiscale,\ntitle={Multi-scale Attributed Node Embedding},\nauthor={Benedek Rozemberczki and Carl Allen and Rik Sarkar},\nyear={2020},\nurl={https://openreview.net/forum?id=HJxiMAVtPH}\n}"}, "tags": [], "invitation": {"reply": {"writers": {"description": "How your identity will be displayed.", "values-regex": ["ICLR.cc/2020/Conference/Program_Chairs"]}, "signatures": {"values": ["ICLR.cc/2020/Conference/Program_Chairs"], "description": "How your identity will be displayed."}, "content": {"decision": {"value-radio": ["Accept (Spotlight)", "Accept (Talk)", "Accept (Poster)", "Reject"], "description": "Decision", "required": true, "order": 2}, "title": {"value": "Paper Decision", "required": true, "order": 1}, "comment": {"value-regex": "[\\S\\s]{0,5000}", "description": "", "required": false, "order": 3}}, "forum": "HJxiMAVtPH", "replyto": "HJxiMAVtPH", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}}, "expdate": 1576854540000, "duedate": 1576853940000, "multiReply": false, "readers": ["everyone"], "invitees": ["ICLR.cc/2020/Conference/Program_Chairs"], "tcdate": 1576795722110, "tmdate": 1576800273339, "super": "ICLR.cc/2020/Conference/-/Decision", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper1014/-/Decision"}}}, {"id": "HylFMo1DjH", "original": null, "number": 5, "cdate": 1573481232846, "ddate": null, "tcdate": 1573481232846, "tmdate": 1573481232846, "tddate": null, "forum": "HJxiMAVtPH", "replyto": "HJxiMAVtPH", "invitation": "ICLR.cc/2020/Conference/Paper1014/-/Official_Comment", "content": {"title": "Summary of changes made in the revised version", "comment": "We thank all reviewers for their valuable feedback. We have responded to most comments individually. The paper has been updated to include:\n\n- Low and high baseline for transfer learning."}, "signatures": ["ICLR.cc/2020/Conference/Paper1014/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1014/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Multi-scale Attributed Node Embedding", "authors": ["Benedek Rozemberczki", "Carl Allen", "Rik Sarkar"], "authorids": ["benedek.rozemberczki@gmail.com", "carl.allen@ed.ac.uk", "rsarkar@inf.ed.ac.uk"], "keywords": ["network embedding", "graph embedding", "node embedding", "network science", "graph representation learning"], "TL;DR": "We develop efficient multi-scale approximate attributed network embedding procedures with provable properties.", "abstract": "We present network embedding algorithms that capture information about a node from the local distribution over node attributes around it, as observed over random walks following an approach similar to Skip-gram. Observations from neighborhoods of different sizes are either pooled (AE) or encoded distinctly in a multi-scale approach (MUSAE).  Capturing attribute-neighborhood relationships over multiple scales is useful for a diverse range of applications, including latent feature identification across disconnected networks with similar attributes. We prove theoretically that matrices of node-feature pointwise mutual information are implicitly factorized by the embeddings. Experiments show that our algorithms are robust, computationally efficient and outperform comparable models on social, web and citation network datasets.", "pdf": "/pdf/125239ee14eac85f8e0cff16d108f9e76d91b735.pdf", "code": "https://github.com/iclr2020/MUSAE/", "paperhash": "rozemberczki|multiscale_attributed_node_embedding", "original_pdf": "/attachment/eb44aa9a4c062a9f23c16496076fdcae8900dae0.pdf", "_bibtex": "@misc{\nrozemberczki2020multiscale,\ntitle={Multi-scale Attributed Node Embedding},\nauthor={Benedek Rozemberczki and Carl Allen and Rik Sarkar},\nyear={2020},\nurl={https://openreview.net/forum?id=HJxiMAVtPH}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "HJxiMAVtPH", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper1014/Authors", "ICLR.cc/2020/Conference/Paper1014/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper1014/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper1014/Reviewers", "ICLR.cc/2020/Conference/Paper1014/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper1014/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper1014/Authors|ICLR.cc/2020/Conference/Paper1014/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504162607, "tmdate": 1576860531433, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper1014/Authors", "ICLR.cc/2020/Conference/Paper1014/Reviewers", "ICLR.cc/2020/Conference/Paper1014/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper1014/-/Official_Comment"}}}, {"id": "B1lKGEX8ir", "original": null, "number": 4, "cdate": 1573430288617, "ddate": null, "tcdate": 1573430288617, "tmdate": 1573430288617, "tddate": null, "forum": "HJxiMAVtPH", "replyto": "Skx3TcKRKB", "invitation": "ICLR.cc/2020/Conference/Paper1014/-/Official_Comment", "content": {"title": "Author Response to Reviewer #1 - Part #2", "comment": "\"Figure 2 shows that the presented two approaches just slightly better or equivalent, or sometimes worse than baseline methods. As mentioned earlier, it is not beneficial to randomly select features to propagate. \"\n\nResponse:\n\nWe agree with the reviewer that Figure 2 does not represent the results sufficiently clearly due to varying y-axis scales of the subplots. The first plot (Facebook dataset) shows that all 4 proposed algorithms materially outperform (by 10-20%) all other models except BANE, which is outperformed but less so. The second plot (Github dataset) shows similar significant outperformance of other models, but here TENE is the only close competitor. The third plot (Twitch dataset) shows much closer results for all models (ASNE shows slight improvement by c 2%, however, it is significantly outperformed on other datasets). We have updated the figure such that all subplots share the same y-axis. Whilst this loses detail on the third plot, more importantly, it allows performance to be clearly compared between datasets, showing that the Twitch dataset is more difficult for all models. Note that features are not randomly propagated as explained above.\n\nWe also emphasize that similar results are shown for fixed ratio train-test splits on these datasets (Appx G, Table 7), which also compare to end-to-end supervised methods. Results for citation graphs (Appx G, Table 6) again show that no other unsupervised method consistently outperforms our proposed models (e.g. AANE outperforms on Pubmed, but is outperformed on other datasets, particularly so on Cora).\n\n\"The experiments presented in Section 5.2 evaluate whether the learned embedding can be used for label inference in a different graph. But it is unknown how success the transferring is. There is no F1-score of a solution that does embedding of the target network itself independently, and then classify the target network nodes.\"\n\nResponse:\n\nWe agree with the reviewer\u2019s comment. We have added two baselines.  The first one is to make clear the relative benefit of transfer learning by independently learning features on the target network and a downstream logistic regression model using those (high baseline). Under the assumption of random guessing the labels with equal probability the micro F-1 score is 0.5 - we decided to use this as a low baseline. Note that it is possible that the high baseline could be outperformed by transfer learning, subject to the relative amount of data for each network. We added the low and high baselines to Figure 3."}, "signatures": ["ICLR.cc/2020/Conference/Paper1014/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1014/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Multi-scale Attributed Node Embedding", "authors": ["Benedek Rozemberczki", "Carl Allen", "Rik Sarkar"], "authorids": ["benedek.rozemberczki@gmail.com", "carl.allen@ed.ac.uk", "rsarkar@inf.ed.ac.uk"], "keywords": ["network embedding", "graph embedding", "node embedding", "network science", "graph representation learning"], "TL;DR": "We develop efficient multi-scale approximate attributed network embedding procedures with provable properties.", "abstract": "We present network embedding algorithms that capture information about a node from the local distribution over node attributes around it, as observed over random walks following an approach similar to Skip-gram. Observations from neighborhoods of different sizes are either pooled (AE) or encoded distinctly in a multi-scale approach (MUSAE).  Capturing attribute-neighborhood relationships over multiple scales is useful for a diverse range of applications, including latent feature identification across disconnected networks with similar attributes. We prove theoretically that matrices of node-feature pointwise mutual information are implicitly factorized by the embeddings. Experiments show that our algorithms are robust, computationally efficient and outperform comparable models on social, web and citation network datasets.", "pdf": "/pdf/125239ee14eac85f8e0cff16d108f9e76d91b735.pdf", "code": "https://github.com/iclr2020/MUSAE/", "paperhash": "rozemberczki|multiscale_attributed_node_embedding", "original_pdf": "/attachment/eb44aa9a4c062a9f23c16496076fdcae8900dae0.pdf", "_bibtex": "@misc{\nrozemberczki2020multiscale,\ntitle={Multi-scale Attributed Node Embedding},\nauthor={Benedek Rozemberczki and Carl Allen and Rik Sarkar},\nyear={2020},\nurl={https://openreview.net/forum?id=HJxiMAVtPH}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "HJxiMAVtPH", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper1014/Authors", "ICLR.cc/2020/Conference/Paper1014/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper1014/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper1014/Reviewers", "ICLR.cc/2020/Conference/Paper1014/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper1014/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper1014/Authors|ICLR.cc/2020/Conference/Paper1014/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504162607, "tmdate": 1576860531433, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper1014/Authors", "ICLR.cc/2020/Conference/Paper1014/Reviewers", "ICLR.cc/2020/Conference/Paper1014/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper1014/-/Official_Comment"}}}, {"id": "HygA2fQ8sS", "original": null, "number": 3, "cdate": 1573429942236, "ddate": null, "tcdate": 1573429942236, "tmdate": 1573430148423, "tddate": null, "forum": "HJxiMAVtPH", "replyto": "Skx3TcKRKB", "invitation": "ICLR.cc/2020/Conference/Paper1014/-/Official_Comment", "content": {"title": "Author Response to Reviewer #1 - Part #1", "comment": "\"This paper introduces Skip-gram style embedding algorithms that consider attribute distributions over local neighborhoods. Algorithm 1 and 2 shows that in fact they propagate randomly selected node features to neighbors. The reviewer doesn\u2019t think this random-walk way for selecting node feature is appropriate.  Node features describe node content. The features of neighboring nodes may complement each other. However, there is no benefit to select random features and then propagate, given that there already many approaches smartly combining node content in neighborhood.\"\n\nResponse:\n\nWe fully agree with the reviewer that node features describe node context. However, we would like to clarify that in our algorithm node features are not propagated randomly. As in many graph embedding models (e.g. Deepwalk, Walklets, Node2Vec), stochastic random walks are used to propagate information \u201cin expectation\u201d, since to compute all possible paths, equivalent to breadth-first search, is prohibitive for large graphs. However, ALL node pairs (up to a proximity $t$) are extracted from those paths and ALL features of each node pair propagated. We make this more clear in the paper by stating \u201cfor all $f \\in \\mathcal{F}$\u201d (e.g. Alg 1, line 6).\n\n\"The proof part follows Qiu et al (2018). But it is unclear, why $c^{\u22121}\\textbf{A}$ is the stationary joint distribution over consecutive nodes $p(w_j , w_{j+1})$.  and $c^{\u22121}\\textbf{D}\\textbf{F}$ describes the stationary joint distribution $p(f,w_j)$ over nodes and features. There needs more explanation. \"\n\nResponse:\n\nWe agree with the reviewer that this is not well explained (due to space) and will add the explanation below to the appendix. Note: we do not use these descriptions, but include them to aide intuition of the results/proofs. \nSince $(1/c)\\textbf{D}$ is a diagonal matrix of the stationary distribution over nodes $p(u)$ and $\\textbf{P}=\\textbf{D}^{-1}\\textbf{A}$ is the transition matrix of probabilities $p(v|u)$, then:\n  $$(1/c)\\textbf{A} = (1/c) \\times [\\textbf{D}\\times \\textbf{D}^{-1}] \\times \\textbf{A} = (1/c)\\textbf{D} \\times \\textbf{D}^{-1}\\textbf{A} = diag[p(u)] \\times [p(v|u)] = [p(u,v)],$$\na matrix of joint distributions of being in node $u$ and transitioning to node $v$. Since $p(u)$ is stationary, this joint distribution is the stationary distribution over consecutive node pairs.\n\nSimilarly, $(1/c)\\textbf{D} \\textbf{F} = (1/c)\\textbf{D} \\times \\textbf{F} = diag[p(u)] \\times [p(f|u)] = [p(u,f)]$, a matrix of joint distributions of being in node $u$ and observing feature $f$, which is again a stationary distribution as in expectation it will remain unchanged between time steps.\n\n\"The Remark 1 and 2 discuss the case AE with $\\textbf{F}=\\textbf{I}_{|V|}$,  which is in fact the case when there is no node attributes. In this case, the AE process naturally goes back to plain network embedding, where DeepWalk and WalkLets are proposed for. Therefore, these remarks are done by Qiu et al (2018) already, not make no much new contribution here. \"\n\nResponse:\n\nThe reviewer is correct that when the feature matrix $\\textbf{F}$ is the identity matrix, attributed network embedding becomes equivalent to unattributed network embedding. The work of Qiu relates to unattributed embedding only and hence our Remarks 1 and 2, which situate our method amongst others in the literature, also connect it to the work of Qiu, (some of) which we generalise to attributed networks."}, "signatures": ["ICLR.cc/2020/Conference/Paper1014/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1014/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Multi-scale Attributed Node Embedding", "authors": ["Benedek Rozemberczki", "Carl Allen", "Rik Sarkar"], "authorids": ["benedek.rozemberczki@gmail.com", "carl.allen@ed.ac.uk", "rsarkar@inf.ed.ac.uk"], "keywords": ["network embedding", "graph embedding", "node embedding", "network science", "graph representation learning"], "TL;DR": "We develop efficient multi-scale approximate attributed network embedding procedures with provable properties.", "abstract": "We present network embedding algorithms that capture information about a node from the local distribution over node attributes around it, as observed over random walks following an approach similar to Skip-gram. Observations from neighborhoods of different sizes are either pooled (AE) or encoded distinctly in a multi-scale approach (MUSAE).  Capturing attribute-neighborhood relationships over multiple scales is useful for a diverse range of applications, including latent feature identification across disconnected networks with similar attributes. We prove theoretically that matrices of node-feature pointwise mutual information are implicitly factorized by the embeddings. Experiments show that our algorithms are robust, computationally efficient and outperform comparable models on social, web and citation network datasets.", "pdf": "/pdf/125239ee14eac85f8e0cff16d108f9e76d91b735.pdf", "code": "https://github.com/iclr2020/MUSAE/", "paperhash": "rozemberczki|multiscale_attributed_node_embedding", "original_pdf": "/attachment/eb44aa9a4c062a9f23c16496076fdcae8900dae0.pdf", "_bibtex": "@misc{\nrozemberczki2020multiscale,\ntitle={Multi-scale Attributed Node Embedding},\nauthor={Benedek Rozemberczki and Carl Allen and Rik Sarkar},\nyear={2020},\nurl={https://openreview.net/forum?id=HJxiMAVtPH}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "HJxiMAVtPH", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper1014/Authors", "ICLR.cc/2020/Conference/Paper1014/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper1014/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper1014/Reviewers", "ICLR.cc/2020/Conference/Paper1014/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper1014/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper1014/Authors|ICLR.cc/2020/Conference/Paper1014/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504162607, "tmdate": 1576860531433, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper1014/Authors", "ICLR.cc/2020/Conference/Paper1014/Reviewers", "ICLR.cc/2020/Conference/Paper1014/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper1014/-/Official_Comment"}}}, {"id": "r1xh7AzIsS", "original": null, "number": 2, "cdate": 1573428771874, "ddate": null, "tcdate": 1573428771874, "tmdate": 1573428771874, "tddate": null, "forum": "HJxiMAVtPH", "replyto": "S1lMVC0pKr", "invitation": "ICLR.cc/2020/Conference/Paper1014/-/Official_Comment", "content": {"title": "Author Response to Reviewer #3", "comment": "1. In MUSAE, what is the intention that the tuples are added to different sub-corpus for source and target nodes? Besides, the D_r should be a corpus rather sub-corpus.\n\nResponse:\n\nIn AE, as in many W2V-inspired network embedding models, one central corpus $\\mathcal{D}$ is constructed containing information from node pairs over different proximities, i.e. the information is \u201cpooled\u201d. However, one intuitively expects the relationship between nodes to vary with proximity ($r$), hence rather than pooling all information together, MUSAE partitions it between \u201csub-corpora\u201d $\\mathcal{D}_r$. This gives down-stream tasks access to unpooled, and thus more fine-grained information, with the potential draw-back that, since more statistical information (i.e. for each proximity $r$) is estimated from the same dataset, those estimates are likely to contain more variance.\n \n2. In 5.2, I\u2019m not quite understand what do you mean by \u2018vanilla MUSAE and AE are inductive and can easily map nodes to the embedding space if the attributes across the source and target graph are shared\u2019.\n\nResponse:\n\nMUSAE and AE (as opposed to their EGO counterparts) learn node embeddings as a function of the features around them, as opposed to the nodes around them. If two networks share a common feature domain, then feature representations learned on one graph can be used to generate node representations on the other (on the assumption that nodes exhibit features for the same underlying latent reasons). However, since neighbourhood-based methods learn representations as a function of their node neighbourhood, nodes from separate graphs cannot be mapped to the embedding space using the same embedding function, a strong limitation compared to our method."}, "signatures": ["ICLR.cc/2020/Conference/Paper1014/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1014/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Multi-scale Attributed Node Embedding", "authors": ["Benedek Rozemberczki", "Carl Allen", "Rik Sarkar"], "authorids": ["benedek.rozemberczki@gmail.com", "carl.allen@ed.ac.uk", "rsarkar@inf.ed.ac.uk"], "keywords": ["network embedding", "graph embedding", "node embedding", "network science", "graph representation learning"], "TL;DR": "We develop efficient multi-scale approximate attributed network embedding procedures with provable properties.", "abstract": "We present network embedding algorithms that capture information about a node from the local distribution over node attributes around it, as observed over random walks following an approach similar to Skip-gram. Observations from neighborhoods of different sizes are either pooled (AE) or encoded distinctly in a multi-scale approach (MUSAE).  Capturing attribute-neighborhood relationships over multiple scales is useful for a diverse range of applications, including latent feature identification across disconnected networks with similar attributes. We prove theoretically that matrices of node-feature pointwise mutual information are implicitly factorized by the embeddings. Experiments show that our algorithms are robust, computationally efficient and outperform comparable models on social, web and citation network datasets.", "pdf": "/pdf/125239ee14eac85f8e0cff16d108f9e76d91b735.pdf", "code": "https://github.com/iclr2020/MUSAE/", "paperhash": "rozemberczki|multiscale_attributed_node_embedding", "original_pdf": "/attachment/eb44aa9a4c062a9f23c16496076fdcae8900dae0.pdf", "_bibtex": "@misc{\nrozemberczki2020multiscale,\ntitle={Multi-scale Attributed Node Embedding},\nauthor={Benedek Rozemberczki and Carl Allen and Rik Sarkar},\nyear={2020},\nurl={https://openreview.net/forum?id=HJxiMAVtPH}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "HJxiMAVtPH", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper1014/Authors", "ICLR.cc/2020/Conference/Paper1014/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper1014/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper1014/Reviewers", "ICLR.cc/2020/Conference/Paper1014/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper1014/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper1014/Authors|ICLR.cc/2020/Conference/Paper1014/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504162607, "tmdate": 1576860531433, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper1014/Authors", "ICLR.cc/2020/Conference/Paper1014/Reviewers", "ICLR.cc/2020/Conference/Paper1014/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper1014/-/Official_Comment"}}}, {"id": "Sye0HTfIjr", "original": null, "number": 1, "cdate": 1573428550485, "ddate": null, "tcdate": 1573428550485, "tmdate": 1573428550485, "tddate": null, "forum": "HJxiMAVtPH", "replyto": "ryxLNTmaYS", "invitation": "ICLR.cc/2020/Conference/Paper1014/-/Official_Comment", "content": {"title": "Author Response to Reviewer #2", "comment": "\"The proposed embedding methods are standard. The key contribution of this paper comes from the theoretical part, which establishes the equivalence between the proposed embedding methods and matrix factorization. It looks interesting, although there are several similar works before, as mentioned in the paper. I don\u2019t know how different your work is from the Qiu\u2019s paper.\"\n\nResponse: \n\nThe reviewer is correct that our work links into and builds on existing literature. In particular we extend the use of W2V-type algorithms to attributed networks (of which non attributed networks are a special case), which to our knowledge is novel. We also non-trivially extend the analysis that relates to those algorithms, e.g. that of Qiu. Note that we anticipate this to have important extensions as it unifies the embeddings of nodes with embeddings of node features, which are often words, and themselves can be embedded by W2V. Thus future work aims to unify attributed network embedding, where attributes are words, with word embeddings that can be learned from a vast independent corpus. \n\n\"The experimental results are not convincing. The node classification is a very standard task in the performance evaluation of network embedding, but you put the results into the appendix. I examine the results anyway, and I found the performance gain is very limited, and on some datasets, the proposed methods even perform inferiorly.\"\n\nResponse:\n\nWe agree with the reviewer that node classification is a standard task and we are reviewing how the results might be better represented (Tables 6, 7 in Appendix G) within the paper. However, it is important to note that our algorithms learn fully unsupervised node/feature representations and the results for end-to-end supervised methods (e.g. GCN, GAT, GraphSAGE, ClusterGCN, APPNP) are included for reference as a proxy upper-bound. As expected, our algorithms do not perform as well as fully supervised methods, but are the best performing unsupervised methods overall. The fixed ratio train-test split experiments show our methods outperform the best performing unsupervised method by: 0.9% (Facebook Page-Page), 0.5% (Github), 0.8% (Cora), 0.8% (Citeseer) (which can be seen to be significant considering standard error). Where our models are outperformed (Pubmed, Twitch Portugal), it is by a different model in each case and our models are in the top tier. We note also that the regression results predicting Wikipedia traffic (Appendix I), a related task to node classification, show a material benefit of our models over other unsupervised methods varies (1.5% - 6.0% $R^2$). We have highlighted that Table 7 includes fully supervised methods for greater clarity."}, "signatures": ["ICLR.cc/2020/Conference/Paper1014/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1014/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Multi-scale Attributed Node Embedding", "authors": ["Benedek Rozemberczki", "Carl Allen", "Rik Sarkar"], "authorids": ["benedek.rozemberczki@gmail.com", "carl.allen@ed.ac.uk", "rsarkar@inf.ed.ac.uk"], "keywords": ["network embedding", "graph embedding", "node embedding", "network science", "graph representation learning"], "TL;DR": "We develop efficient multi-scale approximate attributed network embedding procedures with provable properties.", "abstract": "We present network embedding algorithms that capture information about a node from the local distribution over node attributes around it, as observed over random walks following an approach similar to Skip-gram. Observations from neighborhoods of different sizes are either pooled (AE) or encoded distinctly in a multi-scale approach (MUSAE).  Capturing attribute-neighborhood relationships over multiple scales is useful for a diverse range of applications, including latent feature identification across disconnected networks with similar attributes. We prove theoretically that matrices of node-feature pointwise mutual information are implicitly factorized by the embeddings. Experiments show that our algorithms are robust, computationally efficient and outperform comparable models on social, web and citation network datasets.", "pdf": "/pdf/125239ee14eac85f8e0cff16d108f9e76d91b735.pdf", "code": "https://github.com/iclr2020/MUSAE/", "paperhash": "rozemberczki|multiscale_attributed_node_embedding", "original_pdf": "/attachment/eb44aa9a4c062a9f23c16496076fdcae8900dae0.pdf", "_bibtex": "@misc{\nrozemberczki2020multiscale,\ntitle={Multi-scale Attributed Node Embedding},\nauthor={Benedek Rozemberczki and Carl Allen and Rik Sarkar},\nyear={2020},\nurl={https://openreview.net/forum?id=HJxiMAVtPH}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "HJxiMAVtPH", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper1014/Authors", "ICLR.cc/2020/Conference/Paper1014/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper1014/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper1014/Reviewers", "ICLR.cc/2020/Conference/Paper1014/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper1014/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper1014/Authors|ICLR.cc/2020/Conference/Paper1014/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504162607, "tmdate": 1576860531433, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper1014/Authors", "ICLR.cc/2020/Conference/Paper1014/Reviewers", "ICLR.cc/2020/Conference/Paper1014/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper1014/-/Official_Comment"}}}, {"id": "ryxLNTmaYS", "original": null, "number": 1, "cdate": 1571794221544, "ddate": null, "tcdate": 1571794221544, "tmdate": 1572972523425, "tddate": null, "forum": "HJxiMAVtPH", "replyto": "HJxiMAVtPH", "invitation": "ICLR.cc/2020/Conference/Paper1014/-/Official_Review", "content": {"experience_assessment": "I have published one or two papers in this area.", "rating": "6: Weak Accept", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #2", "review_assessment:_checking_correctness_of_derivations_and_theory": "I did not assess the derivations or theory.", "review": "This paper proposed an attributed network embedding method by leveraging a node\u2019s local distribution over attributes. The neighborhood attribute distribution of a node is considered in both a pooled and a multi-scale way. The multi-scale embedding approach considers the neighborhood nodes with different distance to the interested node distinctly, providing more flexibilities to the model. Then, the paper proved theoretically that the proposed embedding methods, both the pooled and multi-scale versions, can be equivalently written the factorization of a node-feature pointwise mutual information matrix.\n\nThe proposed embedding methods are standard. The key contribution of this paper comes from the theoretical part, which establishes the equivalence between the proposed embedding methods and matrix factorization. It looks interesting, although there are several similar works before, as mentioned in the paper. I don\u2019t know how different your work is from the Qiu\u2019s paper.\n\nThe experimental results are not convincing. The node classification is a very standard task in the performance evaluation of network embedding, but you put the results into the appendix. I examine the results anyway, and I found the performance gain is very limited, and on some datasets, the proposed methods even perform inferiorly.\n"}, "signatures": ["ICLR.cc/2020/Conference/Paper1014/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1014/AnonReviewer2"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Multi-scale Attributed Node Embedding", "authors": ["Benedek Rozemberczki", "Carl Allen", "Rik Sarkar"], "authorids": ["benedek.rozemberczki@gmail.com", "carl.allen@ed.ac.uk", "rsarkar@inf.ed.ac.uk"], "keywords": ["network embedding", "graph embedding", "node embedding", "network science", "graph representation learning"], "TL;DR": "We develop efficient multi-scale approximate attributed network embedding procedures with provable properties.", "abstract": "We present network embedding algorithms that capture information about a node from the local distribution over node attributes around it, as observed over random walks following an approach similar to Skip-gram. Observations from neighborhoods of different sizes are either pooled (AE) or encoded distinctly in a multi-scale approach (MUSAE).  Capturing attribute-neighborhood relationships over multiple scales is useful for a diverse range of applications, including latent feature identification across disconnected networks with similar attributes. We prove theoretically that matrices of node-feature pointwise mutual information are implicitly factorized by the embeddings. Experiments show that our algorithms are robust, computationally efficient and outperform comparable models on social, web and citation network datasets.", "pdf": "/pdf/125239ee14eac85f8e0cff16d108f9e76d91b735.pdf", "code": "https://github.com/iclr2020/MUSAE/", "paperhash": "rozemberczki|multiscale_attributed_node_embedding", "original_pdf": "/attachment/eb44aa9a4c062a9f23c16496076fdcae8900dae0.pdf", "_bibtex": "@misc{\nrozemberczki2020multiscale,\ntitle={Multi-scale Attributed Node Embedding},\nauthor={Benedek Rozemberczki and Carl Allen and Rik Sarkar},\nyear={2020},\nurl={https://openreview.net/forum?id=HJxiMAVtPH}\n}"}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "HJxiMAVtPH", "replyto": "HJxiMAVtPH", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper1014/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper1014/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1574824171223, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper1014/Reviewers"], "noninvitees": [], "tcdate": 1570237743648, "tmdate": 1574824171235, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper1014/-/Official_Review"}}}, {"id": "S1lMVC0pKr", "original": null, "number": 2, "cdate": 1571839530119, "ddate": null, "tcdate": 1571839530119, "tmdate": 1572972523380, "tddate": null, "forum": "HJxiMAVtPH", "replyto": "HJxiMAVtPH", "invitation": "ICLR.cc/2020/Conference/Paper1014/-/Official_Review", "content": {"experience_assessment": "I do not know much about this area.", "rating": "6: Weak Accept", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #3", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "This manuscript introduces embedding algorithms that consider attribute distribution. To address the multi-scale attribute information, the multi-scale version of AE is derived (MUSAE). Then the proposed algorithms are proven theoretically to implicitly factorize the PMI matrix, which enhance their interpretability. The experiments are conducted on various scenarios including node classification, transfer learning, regression and link prediction. showing the quality of learned embeddings. The results show the benefits of multi-scaling and several conclusions are drawn.\nFollowing are some review\u2019s questions:\n1. In MUSAE, what is the intention that the tuples are added to different sub-corpus for source and target nodes? Besides, the D_r should be a corpus rather sub-corpus.\n2. In 5.2, I\u2019m not quite understand what do you mean by \u2018vanilla MUSAE and AE are inductive and can easily map nodes to the embedding space if the attributes across the source and target graph are shared\u2019."}, "signatures": ["ICLR.cc/2020/Conference/Paper1014/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1014/AnonReviewer3"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Multi-scale Attributed Node Embedding", "authors": ["Benedek Rozemberczki", "Carl Allen", "Rik Sarkar"], "authorids": ["benedek.rozemberczki@gmail.com", "carl.allen@ed.ac.uk", "rsarkar@inf.ed.ac.uk"], "keywords": ["network embedding", "graph embedding", "node embedding", "network science", "graph representation learning"], "TL;DR": "We develop efficient multi-scale approximate attributed network embedding procedures with provable properties.", "abstract": "We present network embedding algorithms that capture information about a node from the local distribution over node attributes around it, as observed over random walks following an approach similar to Skip-gram. Observations from neighborhoods of different sizes are either pooled (AE) or encoded distinctly in a multi-scale approach (MUSAE).  Capturing attribute-neighborhood relationships over multiple scales is useful for a diverse range of applications, including latent feature identification across disconnected networks with similar attributes. We prove theoretically that matrices of node-feature pointwise mutual information are implicitly factorized by the embeddings. Experiments show that our algorithms are robust, computationally efficient and outperform comparable models on social, web and citation network datasets.", "pdf": "/pdf/125239ee14eac85f8e0cff16d108f9e76d91b735.pdf", "code": "https://github.com/iclr2020/MUSAE/", "paperhash": "rozemberczki|multiscale_attributed_node_embedding", "original_pdf": "/attachment/eb44aa9a4c062a9f23c16496076fdcae8900dae0.pdf", "_bibtex": "@misc{\nrozemberczki2020multiscale,\ntitle={Multi-scale Attributed Node Embedding},\nauthor={Benedek Rozemberczki and Carl Allen and Rik Sarkar},\nyear={2020},\nurl={https://openreview.net/forum?id=HJxiMAVtPH}\n}"}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "HJxiMAVtPH", "replyto": "HJxiMAVtPH", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper1014/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper1014/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1574824171223, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper1014/Reviewers"], "noninvitees": [], "tcdate": 1570237743648, "tmdate": 1574824171235, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper1014/-/Official_Review"}}}, {"id": "Skx3TcKRKB", "original": null, "number": 3, "cdate": 1571883715752, "ddate": null, "tcdate": 1571883715752, "tmdate": 1572972523337, "tddate": null, "forum": "HJxiMAVtPH", "replyto": "HJxiMAVtPH", "invitation": "ICLR.cc/2020/Conference/Paper1014/-/Official_Review", "content": {"experience_assessment": "I have published in this field for several years.", "rating": "3: Weak Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #1", "review_assessment:_checking_correctness_of_derivations_and_theory": "I carefully checked the derivations and theory.", "review": "This paper introduces Skip-gram style embedding algorithms that consider attribute distributions over local neighborhoods. Algorithm 1 and 2 shows that in fact they propagate randomly selected node features to neighbors. The reviewer doesn\u2019t think this random-walk way for selecting node feature is appropriate.  Node features describe node content. The features of neighboring nodes may complement each other. However, there is no benefit to select random features and then propagate, given that there already many approaches smartly combining node content in neighborhood. \n\nThe proof part follows Qiu et al (2018). But it is unclear, why c^{\u22121}A is the stationary joint distribution over consecutive nodes p(wj , wj+1).  and c^{\u22121}DF describes the stationary joint distribution p(f,wj) over nodes and features. There needs more explanation. \n\nThe Remark 1 and 2 discuss the case AE with F=I_|V|,  which is in fact the case when there is no node attributes. In this case, the AE process naturally goes back to plain network embedding, where DeepWalk and WalkLets are proposed for. Therefore, these remarks are done by Qiu et al (2018) already, not make no much new contribution here. \n\nFigure 2 shows that the presented two approaches just slightly better or equivalent, or sometimes worse than baseline methods. As mentioned earlier, it is not beneficial to randomly select features to propagate. \n\nThe experiments presented in Section 5.2 evaluate whether the learned embedding can be used for label inference in a different graph. But it is unknown how success the transferring is. There is no F1-score of a solution that does embedding of the target network itself independently, and then classify the target network nodes. \n"}, "signatures": ["ICLR.cc/2020/Conference/Paper1014/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1014/AnonReviewer1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Multi-scale Attributed Node Embedding", "authors": ["Benedek Rozemberczki", "Carl Allen", "Rik Sarkar"], "authorids": ["benedek.rozemberczki@gmail.com", "carl.allen@ed.ac.uk", "rsarkar@inf.ed.ac.uk"], "keywords": ["network embedding", "graph embedding", "node embedding", "network science", "graph representation learning"], "TL;DR": "We develop efficient multi-scale approximate attributed network embedding procedures with provable properties.", "abstract": "We present network embedding algorithms that capture information about a node from the local distribution over node attributes around it, as observed over random walks following an approach similar to Skip-gram. Observations from neighborhoods of different sizes are either pooled (AE) or encoded distinctly in a multi-scale approach (MUSAE).  Capturing attribute-neighborhood relationships over multiple scales is useful for a diverse range of applications, including latent feature identification across disconnected networks with similar attributes. We prove theoretically that matrices of node-feature pointwise mutual information are implicitly factorized by the embeddings. Experiments show that our algorithms are robust, computationally efficient and outperform comparable models on social, web and citation network datasets.", "pdf": "/pdf/125239ee14eac85f8e0cff16d108f9e76d91b735.pdf", "code": "https://github.com/iclr2020/MUSAE/", "paperhash": "rozemberczki|multiscale_attributed_node_embedding", "original_pdf": "/attachment/eb44aa9a4c062a9f23c16496076fdcae8900dae0.pdf", "_bibtex": "@misc{\nrozemberczki2020multiscale,\ntitle={Multi-scale Attributed Node Embedding},\nauthor={Benedek Rozemberczki and Carl Allen and Rik Sarkar},\nyear={2020},\nurl={https://openreview.net/forum?id=HJxiMAVtPH}\n}"}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "HJxiMAVtPH", "replyto": "HJxiMAVtPH", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper1014/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper1014/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1574824171223, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper1014/Reviewers"], "noninvitees": [], "tcdate": 1570237743648, "tmdate": 1574824171235, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper1014/-/Official_Review"}}}], "count": 10}