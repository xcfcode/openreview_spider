{"notes": [{"tddate": null, "ddate": null, "cdate": null, "tmdate": 1486396412744, "tcdate": 1486396412744, "number": 1, "id": "rJHZnG8dg", "invitation": "ICLR.cc/2017/conference/-/paper173/acceptance", "forum": "ryh_8f9lg", "replyto": "ryh_8f9lg", "signatures": ["ICLR.cc/2017/pcs"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/pcs"], "content": {"decision": "Reject", "title": "ICLR committee final decision", "comment": "The paper explores neural-network learning on pairs of samples that are labeled as either similar or dissimilar. The proposed model appears to be different from standard siamese architectures, but it is poorly motivated. The experimental evaluation of the proposed model is very limited."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Classless Association using Neural Networks", "abstract": "The goal of this paper is to train a model based on the relation between two instances that represent the same unknown class.  This scenario is inspired by the Symbol Grounding Problem and the association learning in infants.  We propose a novel model called Classless Association.  It has two parallel Multilayer Perceptrons (MLP) that uses one network as a target of the other network, and vice versa.  In addition, the presented model is trained based on an EM-approach, in which the output vectors are matched against a statistical distribution.  We generate four classless datasets based on MNIST, where the input is two different instances of the same digit.  In addition,  the digits have a uniform distribution.  Furthermore, our classless association model is evaluated against two scenarios: totally supervised and totally unsupervised.  In the first scenario, our model reaches a good performance in terms of accuracy and the classless constraint.  In the second scenario, our model reaches better results against two clustering algorithms.\n", "pdf": "/pdf/788a4cffe22f661847498b56c09f13aadd311e8c.pdf", "TL;DR": "Learning based on the relation between two instances of the same unknown class", "paperhash": "raue|classless_association_using_neural_networks", "keywords": [], "conflicts": ["dfki.de", "uni-kl.de"], "authors": ["Federico Raue", "Sebastian Palacio", "Andreas Dengel", "Marcus Liwicki"], "authorids": ["federico.raue@dfki.de", "sebastian.palacio@dfki.de", "andreas.dengel@dfki.de", "liwicki@cs.uni-kl.de"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1486396413250, "id": "ICLR.cc/2017/conference/-/paper173/acceptance", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/pcs"], "noninvitees": ["ICLR.cc/2017/pcs"], "reply": {"forum": "ryh_8f9lg", "replyto": "ryh_8f9lg", "writers": {"values-regex": "ICLR.cc/2017/pcs"}, "signatures": {"values-regex": "ICLR.cc/2017/pcs", "description": "Your displayed identity associated with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your decision.", "value": "ICLR committee final decision"}, "comment": {"required": true, "order": 2, "description": "Decision comments.", "value-regex": "[\\S\\s]{1,5000}"}, "decision": {"required": true, "order": 3, "value-radio": ["Accept (Oral)", "Accept (Poster)", "Reject", "Invite to Workshop Track"]}}}, "nonreaders": [], "cdate": 1486396413250}}}, {"tddate": null, "tmdate": 1484351497720, "tcdate": 1484351497720, "number": 5, "id": "BkMGOJDUx", "invitation": "ICLR.cc/2017/conference/-/paper173/public/comment", "forum": "ryh_8f9lg", "replyto": "ryh_8f9lg", "signatures": ["~Federico_Raue1"], "readers": ["everyone"], "writers": ["~Federico_Raue1"], "content": {"title": "New revision", "comment": "We have updated our paper.  The changes are\n* We have improved the clarity and motivation of our model\n* We have evaluated our model to three more classless datasets (Rotated-90 MNIST, Inverted MNIST, and Random Rotation MNIST).\n* We have updated Figure 4 and 5 for showing some random output classification samples instead of the mean of all images.\n* We have added two more examples and demo as supplemental material "}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Classless Association using Neural Networks", "abstract": "The goal of this paper is to train a model based on the relation between two instances that represent the same unknown class.  This scenario is inspired by the Symbol Grounding Problem and the association learning in infants.  We propose a novel model called Classless Association.  It has two parallel Multilayer Perceptrons (MLP) that uses one network as a target of the other network, and vice versa.  In addition, the presented model is trained based on an EM-approach, in which the output vectors are matched against a statistical distribution.  We generate four classless datasets based on MNIST, where the input is two different instances of the same digit.  In addition,  the digits have a uniform distribution.  Furthermore, our classless association model is evaluated against two scenarios: totally supervised and totally unsupervised.  In the first scenario, our model reaches a good performance in terms of accuracy and the classless constraint.  In the second scenario, our model reaches better results against two clustering algorithms.\n", "pdf": "/pdf/788a4cffe22f661847498b56c09f13aadd311e8c.pdf", "TL;DR": "Learning based on the relation between two instances of the same unknown class", "paperhash": "raue|classless_association_using_neural_networks", "keywords": [], "conflicts": ["dfki.de", "uni-kl.de"], "authors": ["Federico Raue", "Sebastian Palacio", "Andreas Dengel", "Marcus Liwicki"], "authorids": ["federico.raue@dfki.de", "sebastian.palacio@dfki.de", "andreas.dengel@dfki.de", "liwicki@cs.uni-kl.de"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287700212, "id": "ICLR.cc/2017/conference/-/paper173/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "ryh_8f9lg", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper173/reviewers", "ICLR.cc/2017/conference/paper173/areachairs"], "cdate": 1485287700212}}}, {"tddate": null, "tmdate": 1484351009754, "tcdate": 1484351009754, "number": 4, "id": "BycX8kP8x", "invitation": "ICLR.cc/2017/conference/-/paper173/public/comment", "forum": "ryh_8f9lg", "replyto": "rkU9hAM4g", "signatures": ["~Federico_Raue1"], "readers": ["everyone"], "writers": ["~Federico_Raue1"], "content": {"title": "Rebuttal Answer", "comment": "We thank the anonymous reviewer for reading the paper and providing valuable feedback.  As a general remark, we have improved the clarity of the paper, mainly in the motivation behind the model.  In addition, we have extended the experimental setup with three more classless datasets based on MNIST (Rotated-90 MNIST, Inverted MNIST, and Random Rotation MNIST).  Our findings still hold for these datasets where our model reaches better results than clustering algorithms and promising results in relation with the supervised scenario.  Finally, we have added a few extra examples as supplemental material.\n\n\nRemark:  The previous version of the paper had a mistyping error about the MLP parameters.  We have reported the results of a model that has 200 neurons for each layer instead of two fully connected layers of 200 and 100 neurons, respectively.  We have already fixed this problem in the next version of our paper.  Note that the performance of both architectures is quite similar\n\n\n* We agree that the motivation of the model is not totally clear, and it is fixed in the next version of our paper.  Our constraint is inspired by the Symbol Grounding Problem and the association learning in infants.  The first part of our constraint is to learn without labeled data.  Thus, we have used the statistical distribution as an alternative mechanism for training MLPs.  The second part of our constraint forces us that different instances of the same unknown class must be classified with the same pseudo-class.  As a result, we have used one network as a target of the other network for converging to the same classification.\n\n* We have proposed our model in an optimal scenario where the dataset is balanced, and the number of classes is known.  We believe that our model can handle unknown prior distributions changing the size of the output vector z \\in R^d, where d is not the optimal number of ground-truth classes.  This can be seen as the number of clusters k in K-means.  In addition, the statistical distribution \\phi can be modified as well.\n\n\n* We have evaluated with different batch sizes (M) in our validation set, and the best result was presented in the paper.  Our assumptions are the training rule requires a big batch size for two reasons.  First, the more input samples, the closer to the statistical distribution.  Second, the model needs to learn slowly otherwise, all input samples would be concentrated in one.\n"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Classless Association using Neural Networks", "abstract": "The goal of this paper is to train a model based on the relation between two instances that represent the same unknown class.  This scenario is inspired by the Symbol Grounding Problem and the association learning in infants.  We propose a novel model called Classless Association.  It has two parallel Multilayer Perceptrons (MLP) that uses one network as a target of the other network, and vice versa.  In addition, the presented model is trained based on an EM-approach, in which the output vectors are matched against a statistical distribution.  We generate four classless datasets based on MNIST, where the input is two different instances of the same digit.  In addition,  the digits have a uniform distribution.  Furthermore, our classless association model is evaluated against two scenarios: totally supervised and totally unsupervised.  In the first scenario, our model reaches a good performance in terms of accuracy and the classless constraint.  In the second scenario, our model reaches better results against two clustering algorithms.\n", "pdf": "/pdf/788a4cffe22f661847498b56c09f13aadd311e8c.pdf", "TL;DR": "Learning based on the relation between two instances of the same unknown class", "paperhash": "raue|classless_association_using_neural_networks", "keywords": [], "conflicts": ["dfki.de", "uni-kl.de"], "authors": ["Federico Raue", "Sebastian Palacio", "Andreas Dengel", "Marcus Liwicki"], "authorids": ["federico.raue@dfki.de", "sebastian.palacio@dfki.de", "andreas.dengel@dfki.de", "liwicki@cs.uni-kl.de"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287700212, "id": "ICLR.cc/2017/conference/-/paper173/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "ryh_8f9lg", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper173/reviewers", "ICLR.cc/2017/conference/paper173/areachairs"], "cdate": 1485287700212}}}, {"tddate": null, "tmdate": 1484350900688, "tcdate": 1484350900688, "number": 3, "id": "rJa3HkPUl", "invitation": "ICLR.cc/2017/conference/-/paper173/public/comment", "forum": "ryh_8f9lg", "replyto": "r1uSbyMVx", "signatures": ["~Federico_Raue1"], "readers": ["everyone"], "writers": ["~Federico_Raue1"], "content": {"title": "Rebuttal Answer", "comment": "We thank the anonymous reviewer for their comments and time.  As a general remark, we have improved the clarity of the paper, mainly in the motivation behind the model.  In addition, we have extended the experimental setup with three more classless datasets based on MNIST (Rotated-90 MNIST, Inverted MNIST, and Random Rotation MNIST).  Our findings still hold for these datasets where our model reaches better results than clustering algorithms and promising results in relation with the supervised scenario.  Finally, we have added a few extra examples as supplemental material.\n\nRemark:  The previous version of the paper had a mistyping error about the MLP parameters.  We have reported the results of a model that has 200 neurons for each layer instead of two fully connected layers of 200 and 100 neurons, respectively.  We have already fixed this problem in the next version of our paper.  Note that the performance of both architectures is quite similar\n  \n* Thank you for pointing out that the motivation of the model is not clear.  We have improved the clarity of the paper.   Our model is motivated by the Symbol Grounding Problem and infants learning, mainly the binding between abstract concepts and the real world via sensory input signals and the association between the sensory streams via abstract concept.  Thus, an alternative training rule is required where the classes are unknown.  In this paper, we use a simple statistical constraint for learning the association between two streams of information.\n"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Classless Association using Neural Networks", "abstract": "The goal of this paper is to train a model based on the relation between two instances that represent the same unknown class.  This scenario is inspired by the Symbol Grounding Problem and the association learning in infants.  We propose a novel model called Classless Association.  It has two parallel Multilayer Perceptrons (MLP) that uses one network as a target of the other network, and vice versa.  In addition, the presented model is trained based on an EM-approach, in which the output vectors are matched against a statistical distribution.  We generate four classless datasets based on MNIST, where the input is two different instances of the same digit.  In addition,  the digits have a uniform distribution.  Furthermore, our classless association model is evaluated against two scenarios: totally supervised and totally unsupervised.  In the first scenario, our model reaches a good performance in terms of accuracy and the classless constraint.  In the second scenario, our model reaches better results against two clustering algorithms.\n", "pdf": "/pdf/788a4cffe22f661847498b56c09f13aadd311e8c.pdf", "TL;DR": "Learning based on the relation between two instances of the same unknown class", "paperhash": "raue|classless_association_using_neural_networks", "keywords": [], "conflicts": ["dfki.de", "uni-kl.de"], "authors": ["Federico Raue", "Sebastian Palacio", "Andreas Dengel", "Marcus Liwicki"], "authorids": ["federico.raue@dfki.de", "sebastian.palacio@dfki.de", "andreas.dengel@dfki.de", "liwicki@cs.uni-kl.de"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287700212, "id": "ICLR.cc/2017/conference/-/paper173/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "ryh_8f9lg", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper173/reviewers", "ICLR.cc/2017/conference/paper173/areachairs"], "cdate": 1485287700212}}}, {"tddate": null, "tmdate": 1484350809474, "tcdate": 1484350809474, "number": 2, "id": "BkWPBkDIe", "invitation": "ICLR.cc/2017/conference/-/paper173/public/comment", "forum": "ryh_8f9lg", "replyto": "Byq8VfUNl", "signatures": ["~Federico_Raue1"], "readers": ["everyone"], "writers": ["~Federico_Raue1"], "content": {"title": "Rebuttal Answer", "comment": "We thank the anonymous reviewer for their comments and time.  As a general remark, we have improved the clarity of the paper, mainly the motivation behind the model.  In addition, we have extended the experimental setup with three more classless datasets based on MNIST (Rotated-90 MNIST, Inverted MNIST, and Random Rotation MNIST).  Our findings still hold for these extra datasets where our model reaches better results than clustering algorithms and promising results in relation with the supervised scenario.  Finally, we have added a few extra examples as supplemental material.\n\nRemark:  The previous version of the paper had a mistyping error about the MLP parameters.  We have reported the results of a model that has 200 neurons for each layer instead of two fully connected layers of 200 and 100 neurons, respectively.  We have already fixed this problem in the next version of our paper.  Note that the performance of both architectures is quite similar\n\n\n* We would like to mention that our model relies on sample pairs of different instances of the same unknown class (\u2018link information\u2019).  However, the relation between two sample pairs is not available in our case (\u2018not-link information\u2019).  We clarify this in the next version of our paper. \n\n* Thank you for pointing out that some details of the model are not clear.  The output classification of the input samples is quite similar when the network is initialized.  For example, arg max_c z_i (i=1,...,m) might be classified as c=2.  The power function gives us the initial boost in order to separate the pseudo-classes since the first iterations. Finally, we agree that a more extensive analysis is useful for the future.\n\n* We agree that is not clear the motivation for using the uniform distribution and how to extend to different cases.  The new version of the paper includes the motivation.  We have selected an optimal case where the dataset is balanced (uniform distribution), and the number of classes is known.  Moreover, our model can be extended to more general cases where the input distribution and the number of classes are unknown.  One way is to change the size of the output vector z \\in R^d, where d is not the optimal number of classes according to the ground-truth.  This step can be seen as deciding the number of clusters k in k-means.\n\n* We are aware of semi-supervised learning with co-training[1,2,3]. However, the strict constraint of our challenge in Symbol Grounding is that the data is totally unlabeled. We agree that a small labeled dataset would improve the performance of our model, but we like to focus on the more challenging problem.\n\n[1] Blum, Avrim, and Tom Mitchell. \"Combining labeled and unlabeled data with co-training.\" Proceedings of the eleventh annual conference on Computational learning theory. ACM, 1998.\n\n[2] Tur, Gokhan. \"Co-adaptation: Adaptive co-training for semi-supervised learning.\" 2009 IEEE International Conference on Acoustics, Speech and Signal Processing. IEEE, 2009.\n\n[3] Sindhwani, Vikas, Partha Niyogi, and Mikhail Belkin. \"A co-regularization approach to semi-supervised learning with multiple views.\" Proceedings of ICML workshop on learning with multiple views. 2005.\n"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Classless Association using Neural Networks", "abstract": "The goal of this paper is to train a model based on the relation between two instances that represent the same unknown class.  This scenario is inspired by the Symbol Grounding Problem and the association learning in infants.  We propose a novel model called Classless Association.  It has two parallel Multilayer Perceptrons (MLP) that uses one network as a target of the other network, and vice versa.  In addition, the presented model is trained based on an EM-approach, in which the output vectors are matched against a statistical distribution.  We generate four classless datasets based on MNIST, where the input is two different instances of the same digit.  In addition,  the digits have a uniform distribution.  Furthermore, our classless association model is evaluated against two scenarios: totally supervised and totally unsupervised.  In the first scenario, our model reaches a good performance in terms of accuracy and the classless constraint.  In the second scenario, our model reaches better results against two clustering algorithms.\n", "pdf": "/pdf/788a4cffe22f661847498b56c09f13aadd311e8c.pdf", "TL;DR": "Learning based on the relation between two instances of the same unknown class", "paperhash": "raue|classless_association_using_neural_networks", "keywords": [], "conflicts": ["dfki.de", "uni-kl.de"], "authors": ["Federico Raue", "Sebastian Palacio", "Andreas Dengel", "Marcus Liwicki"], "authorids": ["federico.raue@dfki.de", "sebastian.palacio@dfki.de", "andreas.dengel@dfki.de", "liwicki@cs.uni-kl.de"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287700212, "id": "ICLR.cc/2017/conference/-/paper173/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "ryh_8f9lg", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper173/reviewers", "ICLR.cc/2017/conference/paper173/areachairs"], "cdate": 1485287700212}}}, {"tddate": null, "replyto": null, "ddate": null, "tmdate": 1484350583490, "tcdate": 1478268531618, "number": 173, "id": "ryh_8f9lg", "invitation": "ICLR.cc/2017/conference/-/submission", "forum": "ryh_8f9lg", "signatures": ["~Federico_Raue1"], "readers": ["everyone"], "content": {"title": "Classless Association using Neural Networks", "abstract": "The goal of this paper is to train a model based on the relation between two instances that represent the same unknown class.  This scenario is inspired by the Symbol Grounding Problem and the association learning in infants.  We propose a novel model called Classless Association.  It has two parallel Multilayer Perceptrons (MLP) that uses one network as a target of the other network, and vice versa.  In addition, the presented model is trained based on an EM-approach, in which the output vectors are matched against a statistical distribution.  We generate four classless datasets based on MNIST, where the input is two different instances of the same digit.  In addition,  the digits have a uniform distribution.  Furthermore, our classless association model is evaluated against two scenarios: totally supervised and totally unsupervised.  In the first scenario, our model reaches a good performance in terms of accuracy and the classless constraint.  In the second scenario, our model reaches better results against two clustering algorithms.\n", "pdf": "/pdf/788a4cffe22f661847498b56c09f13aadd311e8c.pdf", "TL;DR": "Learning based on the relation between two instances of the same unknown class", "paperhash": "raue|classless_association_using_neural_networks", "keywords": [], "conflicts": ["dfki.de", "uni-kl.de"], "authors": ["Federico Raue", "Sebastian Palacio", "Andreas Dengel", "Marcus Liwicki"], "authorids": ["federico.raue@dfki.de", "sebastian.palacio@dfki.de", "andreas.dengel@dfki.de", "liwicki@cs.uni-kl.de"]}, "writers": [], "nonreaders": [], "details": {"replyCount": 10, "writable": false, "overwriting": ["rkB_5hEKe"], "revisions": true, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1475686800000, "tmdate": 1478287705855, "id": "ICLR.cc/2017/conference/-/submission", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/pcs"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": null, "replyto": null, "writers": {"values-regex": "~.*"}, "signatures": {"values-regex": "~.*", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"pdf": {"required": true, "order": 5, "description": "Either upload a PDF file or provide a direct link to your PDF on ArXiv (link must begin with http(s) and end with .pdf)", "value-regex": "upload|(http|https):\\/\\/.+\\.pdf"}, "title": {"required": true, "order": 1, "description": "Title of paper.", "value-regex": ".{1,250}"}, "abstract": {"required": true, "order": 4, "description": "Abstract of paper.", "value-regex": "[\\S\\s]{1,5000}"}, "authors": {"required": true, "order": 2, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of author names, as they appear in the paper."}, "conflicts": {"required": true, "order": 100, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of email domains of people who would have a conflict of interest in reviewing this paper, (e.g., cs.umass.edu;google.com, etc.)."}, "keywords": {"order": 6, "description": "Comma separated list of keywords.", "values-dropdown": ["Theory", "Computer vision", "Speech", "Natural language processing", "Deep learning", "Unsupervised Learning", "Supervised Learning", "Semi-Supervised Learning", "Reinforcement Learning", "Transfer Learning", "Multi-modal learning", "Applications", "Optimization", "Structured prediction", "Games"]}, "TL;DR": {"required": false, "order": 3, "description": "\"Too Long; Didn't Read\": a short sentence describing your paper", "value-regex": "[^\\n]{0,250}"}, "authorids": {"required": true, "order": 3, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of author email addresses, in the same order as above."}}}, "nonreaders": [], "noninvitees": [], "expdate": 1483462800000, "cdate": 1478287705855}}}, {"tddate": null, "tmdate": 1482200953321, "tcdate": 1482200146294, "number": 3, "id": "Byq8VfUNl", "invitation": "ICLR.cc/2017/conference/-/paper173/official/review", "forum": "ryh_8f9lg", "replyto": "ryh_8f9lg", "signatures": ["ICLR.cc/2017/conference/paper173/AnonReviewer1"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/conference/paper173/AnonReviewer1"], "content": {"title": "Review", "rating": "5: Marginally below acceptance threshold", "review": "The paper presents an alternative way of supervising the training of neural network without explicitly using labels when only link/not-link information is available between pairs of examples. A pair of network is trained each of which is used to supervise the other one.\n\n\nThe presentation of the paper is not very clear, the writing can be improved.\nSome design choice are not explained: Why is the power function used in the E-step for approximating the distribution (section 2.1)? Why do the authors only consider a uniform distribution? I understand that using a different prior breaks the assumption that nothing is known about the classes. However I do not see a practical situations where the proposed setting/work would be useful.  \n\nAlso, there exist a large body of work in semi-supervised learning with co-training based on a similar idea. \n\nOverall, I think this work should be clarified and improved to be a good fit for this venue.", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Classless Association using Neural Networks", "abstract": "The goal of this paper is to train a model based on the relation between two instances that represent the same unknown class.  This scenario is inspired by the Symbol Grounding Problem and the association learning in infants.  We propose a novel model called Classless Association.  It has two parallel Multilayer Perceptrons (MLP) that uses one network as a target of the other network, and vice versa.  In addition, the presented model is trained based on an EM-approach, in which the output vectors are matched against a statistical distribution.  We generate four classless datasets based on MNIST, where the input is two different instances of the same digit.  In addition,  the digits have a uniform distribution.  Furthermore, our classless association model is evaluated against two scenarios: totally supervised and totally unsupervised.  In the first scenario, our model reaches a good performance in terms of accuracy and the classless constraint.  In the second scenario, our model reaches better results against two clustering algorithms.\n", "pdf": "/pdf/788a4cffe22f661847498b56c09f13aadd311e8c.pdf", "TL;DR": "Learning based on the relation between two instances of the same unknown class", "paperhash": "raue|classless_association_using_neural_networks", "keywords": [], "conflicts": ["dfki.de", "uni-kl.de"], "authors": ["Federico Raue", "Sebastian Palacio", "Andreas Dengel", "Marcus Liwicki"], "authorids": ["federico.raue@dfki.de", "sebastian.palacio@dfki.de", "andreas.dengel@dfki.de", "liwicki@cs.uni-kl.de"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1481932799000, "tmdate": 1482512674509, "id": "ICLR.cc/2017/conference/-/paper173/official/review", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/conference/paper173/reviewers"], "noninvitees": ["ICLR.cc/2017/conference/paper173/AnonReviewer2", "ICLR.cc/2017/conference/paper173/AnonReviewer3", "ICLR.cc/2017/conference/paper173/AnonReviewer1"], "reply": {"forum": "ryh_8f9lg", "replyto": "ryh_8f9lg", "writers": {"values-regex": "ICLR.cc/2017/conference/paper173/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/conference/paper173/AnonReviewer[0-9]+"}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "value-regex": "[\\S\\s]{1,20000}"}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1489708799000, "cdate": 1482512674509}}}, {"tddate": null, "tmdate": 1481989261675, "tcdate": 1481989261675, "number": 2, "id": "rkU9hAM4g", "invitation": "ICLR.cc/2017/conference/-/paper173/official/review", "forum": "ryh_8f9lg", "replyto": "ryh_8f9lg", "signatures": ["ICLR.cc/2017/conference/paper173/AnonReviewer3"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/conference/paper173/AnonReviewer3"], "content": {"title": "", "rating": "5: Marginally below acceptance threshold", "review": "The paper explores a new technique for classless association, a milder unsupervised learning where we do not know the class labels exactly, but we have a prior about the examples that belong to the same class. Authors proposed a two stream architecture with two neural networks, as streams process examples from the same class simultaneously. Both streams rely on the target (pseudo classes or cluster indices) of each other, and the outputs an intermediate representation z, which is forced to match with a statistical distribution (uniform in their case). The model is trained with EM where the E step obtains the current statistical distribution given output vectors z, and M step updates the weights of the architecture given z and pseudo-classes. Experimental results on re-organized MNIST exhibits better performance compared to classical clustering algorithms (in terms of association accuracy and purity). The authors further provide comparison against a supervised method, where proposed architecture expectedly performs worse but with promising results.\n\nThe basic motivation of the architecture apparently relies on unlabeled data and agreement of the same pseudo-labels generated by two streams. But the paper is hard to follow and the motivation for the proposed architecture itself, is hidden in details. What is trying to be achieved by matching distributions and using the pseudo-targets of the each other? Perhaps the statistical distribution of the classes is assumed to be uniform but how will it extend to other priors, or even the case where we do not assume that we know the prior? The current setup needs justifications. \n\nWhat would be very interesting is to see two examples having the same class but one from MNIST, the other from Rotated-MNIST or Background-MNIST. Because it is hard to guess how different the examples in two streams. \n\nAt the end, I feel like the authors have found a very interesting approach for classless association which can be extended to lots of many-to-one problems. This is a good catch. I would like to see the idea in the future with some extensive experiments on large scale datasets and tasks. But the current version lacks the theoretical motivations and convincing experiments. I would definitely recommend this paper to be presented in ICLR workshop.\n\nFew more points:\nTypo: Figure1. second line in the caption \"that\" -> \"than\"\nNecessity of Equation 2 is not clear\nBatch size M is enormous compared to classical models, there is no explanation for this\nWhy uniform? should be clarified (of course it is the simplest prior to pick but just a few words about it would be good for completeness)\nTypo: Page 6, second paragraph line 3: \"that\" -> \"than\"", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Classless Association using Neural Networks", "abstract": "The goal of this paper is to train a model based on the relation between two instances that represent the same unknown class.  This scenario is inspired by the Symbol Grounding Problem and the association learning in infants.  We propose a novel model called Classless Association.  It has two parallel Multilayer Perceptrons (MLP) that uses one network as a target of the other network, and vice versa.  In addition, the presented model is trained based on an EM-approach, in which the output vectors are matched against a statistical distribution.  We generate four classless datasets based on MNIST, where the input is two different instances of the same digit.  In addition,  the digits have a uniform distribution.  Furthermore, our classless association model is evaluated against two scenarios: totally supervised and totally unsupervised.  In the first scenario, our model reaches a good performance in terms of accuracy and the classless constraint.  In the second scenario, our model reaches better results against two clustering algorithms.\n", "pdf": "/pdf/788a4cffe22f661847498b56c09f13aadd311e8c.pdf", "TL;DR": "Learning based on the relation between two instances of the same unknown class", "paperhash": "raue|classless_association_using_neural_networks", "keywords": [], "conflicts": ["dfki.de", "uni-kl.de"], "authors": ["Federico Raue", "Sebastian Palacio", "Andreas Dengel", "Marcus Liwicki"], "authorids": ["federico.raue@dfki.de", "sebastian.palacio@dfki.de", "andreas.dengel@dfki.de", "liwicki@cs.uni-kl.de"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1481932799000, "tmdate": 1482512674509, "id": "ICLR.cc/2017/conference/-/paper173/official/review", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/conference/paper173/reviewers"], "noninvitees": ["ICLR.cc/2017/conference/paper173/AnonReviewer2", "ICLR.cc/2017/conference/paper173/AnonReviewer3", "ICLR.cc/2017/conference/paper173/AnonReviewer1"], "reply": {"forum": "ryh_8f9lg", "replyto": "ryh_8f9lg", "writers": {"values-regex": "ICLR.cc/2017/conference/paper173/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/conference/paper173/AnonReviewer[0-9]+"}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "value-regex": "[\\S\\s]{1,20000}"}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1489708799000, "cdate": 1482512674509}}}, {"tddate": null, "tmdate": 1481924927713, "tcdate": 1481924927713, "number": 1, "id": "r1uSbyMVx", "invitation": "ICLR.cc/2017/conference/-/paper173/official/review", "forum": "ryh_8f9lg", "replyto": "ryh_8f9lg", "signatures": ["ICLR.cc/2017/conference/paper173/AnonReviewer2"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/conference/paper173/AnonReviewer2"], "content": {"title": "Classes association", "rating": "6: Marginally above acceptance threshold", "review": "The paper looks correct but still i am not convinced about the experimentation performed. Perhaps another experiment with more challenging data would be welcome. Honestly i don't find a clear motivation for this work however it could have some potential and it would be interested to be presented in conference.\n", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Classless Association using Neural Networks", "abstract": "The goal of this paper is to train a model based on the relation between two instances that represent the same unknown class.  This scenario is inspired by the Symbol Grounding Problem and the association learning in infants.  We propose a novel model called Classless Association.  It has two parallel Multilayer Perceptrons (MLP) that uses one network as a target of the other network, and vice versa.  In addition, the presented model is trained based on an EM-approach, in which the output vectors are matched against a statistical distribution.  We generate four classless datasets based on MNIST, where the input is two different instances of the same digit.  In addition,  the digits have a uniform distribution.  Furthermore, our classless association model is evaluated against two scenarios: totally supervised and totally unsupervised.  In the first scenario, our model reaches a good performance in terms of accuracy and the classless constraint.  In the second scenario, our model reaches better results against two clustering algorithms.\n", "pdf": "/pdf/788a4cffe22f661847498b56c09f13aadd311e8c.pdf", "TL;DR": "Learning based on the relation between two instances of the same unknown class", "paperhash": "raue|classless_association_using_neural_networks", "keywords": [], "conflicts": ["dfki.de", "uni-kl.de"], "authors": ["Federico Raue", "Sebastian Palacio", "Andreas Dengel", "Marcus Liwicki"], "authorids": ["federico.raue@dfki.de", "sebastian.palacio@dfki.de", "andreas.dengel@dfki.de", "liwicki@cs.uni-kl.de"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1481932799000, "tmdate": 1482512674509, "id": "ICLR.cc/2017/conference/-/paper173/official/review", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/conference/paper173/reviewers"], "noninvitees": ["ICLR.cc/2017/conference/paper173/AnonReviewer2", "ICLR.cc/2017/conference/paper173/AnonReviewer3", "ICLR.cc/2017/conference/paper173/AnonReviewer1"], "reply": {"forum": "ryh_8f9lg", "replyto": "ryh_8f9lg", "writers": {"values-regex": "ICLR.cc/2017/conference/paper173/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/conference/paper173/AnonReviewer[0-9]+"}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "value-regex": "[\\S\\s]{1,20000}"}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1489708799000, "cdate": 1482512674509}}}, {"tddate": null, "tmdate": 1480946170567, "tcdate": 1480946170562, "number": 1, "id": "SymWGl7Qe", "invitation": "ICLR.cc/2017/conference/-/paper173/public/comment", "forum": "ryh_8f9lg", "replyto": "SyQuQDk7l", "signatures": ["~Federico_Raue1"], "readers": ["everyone"], "writers": ["~Federico_Raue1"], "content": {"title": "RE: Any prior info?", "comment": "Thank you very much for your question.\nOur model relies on the distribution of the classes  i.e., for a given dataset, the distribution should be known in advance.\nFor the paper, we made experiments assuming a uniform distribution.\nHowever, it is perfectly possible to work with a different distribution (e.g., Gaussian, Zipf).\nChoosing another distribution affects the way we define \\phi (and should be adjusted accordingly).\nFurthermore, we are thinking (as part of the future work) on different strategies where even the prior distribution is unknown."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Classless Association using Neural Networks", "abstract": "The goal of this paper is to train a model based on the relation between two instances that represent the same unknown class.  This scenario is inspired by the Symbol Grounding Problem and the association learning in infants.  We propose a novel model called Classless Association.  It has two parallel Multilayer Perceptrons (MLP) that uses one network as a target of the other network, and vice versa.  In addition, the presented model is trained based on an EM-approach, in which the output vectors are matched against a statistical distribution.  We generate four classless datasets based on MNIST, where the input is two different instances of the same digit.  In addition,  the digits have a uniform distribution.  Furthermore, our classless association model is evaluated against two scenarios: totally supervised and totally unsupervised.  In the first scenario, our model reaches a good performance in terms of accuracy and the classless constraint.  In the second scenario, our model reaches better results against two clustering algorithms.\n", "pdf": "/pdf/788a4cffe22f661847498b56c09f13aadd311e8c.pdf", "TL;DR": "Learning based on the relation between two instances of the same unknown class", "paperhash": "raue|classless_association_using_neural_networks", "keywords": [], "conflicts": ["dfki.de", "uni-kl.de"], "authors": ["Federico Raue", "Sebastian Palacio", "Andreas Dengel", "Marcus Liwicki"], "authorids": ["federico.raue@dfki.de", "sebastian.palacio@dfki.de", "andreas.dengel@dfki.de", "liwicki@cs.uni-kl.de"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287700212, "id": "ICLR.cc/2017/conference/-/paper173/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "ryh_8f9lg", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper173/reviewers", "ICLR.cc/2017/conference/paper173/areachairs"], "cdate": 1485287700212}}}, {"tddate": null, "tmdate": 1480713067528, "tcdate": 1480713067525, "number": 1, "id": "SyQuQDk7l", "invitation": "ICLR.cc/2017/conference/-/paper173/pre-review/question", "forum": "ryh_8f9lg", "replyto": "ryh_8f9lg", "signatures": ["ICLR.cc/2017/conference/paper173/AnonReviewer2"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/conference/paper173/AnonReviewer2"], "content": {"title": "Any prior info?", "question": "Interesting paper, but still i do not understand how to define the  \"target distribution (E[z1 , . . . , zm ] \u223c \u03c6 \u2208 Rc )\" why it should be \"uniform\", should we know the prior of the different classes?\n\n"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Classless Association using Neural Networks", "abstract": "The goal of this paper is to train a model based on the relation between two instances that represent the same unknown class.  This scenario is inspired by the Symbol Grounding Problem and the association learning in infants.  We propose a novel model called Classless Association.  It has two parallel Multilayer Perceptrons (MLP) that uses one network as a target of the other network, and vice versa.  In addition, the presented model is trained based on an EM-approach, in which the output vectors are matched against a statistical distribution.  We generate four classless datasets based on MNIST, where the input is two different instances of the same digit.  In addition,  the digits have a uniform distribution.  Furthermore, our classless association model is evaluated against two scenarios: totally supervised and totally unsupervised.  In the first scenario, our model reaches a good performance in terms of accuracy and the classless constraint.  In the second scenario, our model reaches better results against two clustering algorithms.\n", "pdf": "/pdf/788a4cffe22f661847498b56c09f13aadd311e8c.pdf", "TL;DR": "Learning based on the relation between two instances of the same unknown class", "paperhash": "raue|classless_association_using_neural_networks", "keywords": [], "conflicts": ["dfki.de", "uni-kl.de"], "authors": ["Federico Raue", "Sebastian Palacio", "Andreas Dengel", "Marcus Liwicki"], "authorids": ["federico.raue@dfki.de", "sebastian.palacio@dfki.de", "andreas.dengel@dfki.de", "liwicki@cs.uni-kl.de"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1480741199000, "tmdate": 1480959424416, "id": "ICLR.cc/2017/conference/-/paper173/pre-review/question", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/conference/paper173/reviewers"], "noninvitees": ["ICLR.cc/2017/conference/paper173/AnonReviewer2"], "reply": {"forum": "ryh_8f9lg", "replyto": "ryh_8f9lg", "writers": {"values-regex": "ICLR.cc/2017/conference/paper173/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/conference/paper173/AnonReviewer[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your question.", "value-regex": ".{1,500}"}, "question": {"order": 2, "description": "Your question", "value-regex": "[\\S\\s]{1,5000}"}}}, "nonreaders": [], "expdate": 1488517199000, "cdate": 1480959424416}}}], "count": 11}