{"notes": [{"tddate": null, "ddate": null, "cdate": null, "tmdate": 1486396474794, "tcdate": 1486396474794, "number": 1, "id": "ry7r3z8de", "invitation": "ICLR.cc/2017/conference/-/paper275/acceptance", "forum": "HyWG0H5ge", "replyto": "HyWG0H5ge", "signatures": ["ICLR.cc/2017/pcs"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/pcs"], "content": {"title": "ICLR committee final decision", "comment": "The paper presents a theoretical analysis of the convergence of the training error. The presented result is rather general and can potentially apply to many neural networks. \n \n Reviewers pointed out several important concerns regarding the mathematical rigor and precision of the claims. The authors' response partially addressed concerns about the scope of the claims and unclear arguments of the proofs. \n \n We invite the authors to submit a revision of the paper, where all statements and proofs are mathematically clear, to the workshop track.", "decision": "Invite to Workshop Track"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Neural Taylor Approximations: Convergence and Exploration in Rectifier Networks", "abstract": "Modern convolutional networks, incorporating rectifiers and max-pooling, are neither smooth nor convex. Standard guarantees therefore do not apply. Nevertheless, methods from convex optimization such as gradient descent and Adam are widely used as building blocks for deep learning algorithms. This paper provides the first convergence guarantee applicable to modern convnets. The guarantee matches a lower bound for convex nonsmooth functions. The key technical tool is the neural Taylor approximation -- a straightforward application of Taylor expansions to neural networks -- and the associated Taylor loss. Experiments on a range of optimizers, layers, and tasks provide evidence that the analysis accurately captures the dynamics of neural optimization.\n\nThe second half of the paper applies the Taylor approximation to isolate the main difficulty in training rectifier nets: that gradients are shattered. We investigate the hypothesis that, by exploring the space of activation configurations more thoroughly, adaptive optimizers such as RMSProp and Adam are able to converge to better solutions.", "pdf": "/pdf/b27fb3966106d9294b0c28e06eea848b5d0fcb92.pdf", "TL;DR": "We provide the first convergence result for rectifier neural networks and investigate implications for exploration in shattered landscapes.", "paperhash": "balduzzi|neural_taylor_approximations_convergence_and_exploration_in_rectifier_networks", "authorids": ["david.balduzzi@vuw.ac.nz", "brian@disneyresearch.com", "butlertony@ecs.vuw.ac.nz"], "keywords": ["Deep learning", "Optimization", "Theory", "Supervised Learning"], "conflicts": ["mpg.de", "ethz.ch", "disneyresearch.com", "vuw.ac.nz"], "authors": ["David Balduzzi", "Brian McWilliams", "Tony Butler-Yeoman"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1486396475306, "id": "ICLR.cc/2017/conference/-/paper275/acceptance", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/pcs"], "noninvitees": ["ICLR.cc/2017/pcs"], "reply": {"forum": "HyWG0H5ge", "replyto": "HyWG0H5ge", "writers": {"values-regex": "ICLR.cc/2017/pcs"}, "signatures": {"values-regex": "ICLR.cc/2017/pcs", "description": "Your displayed identity associated with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your decision.", "value": "ICLR committee final decision"}, "comment": {"required": true, "order": 2, "description": "Decision comments.", "value-regex": "[\\S\\s]{1,5000}"}, "decision": {"required": true, "order": 3, "value-radio": ["Accept (Oral)", "Accept (Poster)", "Reject", "Invite to Workshop Track"]}}}, "nonreaders": [], "cdate": 1486396475306}}}, {"tddate": null, "tmdate": 1482348789147, "tcdate": 1482348789147, "number": 4, "id": "BJaxt8dNg", "invitation": "ICLR.cc/2017/conference/-/paper275/public/comment", "forum": "HyWG0H5ge", "replyto": "SJivDoD4l", "signatures": ["~David_Balduzzi1"], "readers": ["everyone"], "writers": ["~David_Balduzzi1"], "content": {"title": "Second response to AR3", "comment": "We thank the reviewer for their quick, detailed and informed response. We sincerely appreciate the criticism and the reviewer\u2019s openness to discussion.\n\nFirst, there is a misunderstanding. The previous response did not claim the Taylor optima converge -- only that they are bounded.\n\n\nResetting expectations\n-----------------------\nRectifier networks are complicated. Some of the reviewers expectations about what can and cannot be proved are unrealistic.\n\n1. AR3 remarks \u201cif the running average is bounded by a \u2018meaningful\u2019 constant (e.g. the optimum of the true loss)\u201d.  The reviewer is overly optimistic. RECTIFIER NEURAL NETWORKS ARE NOT CONVEX. It is unrealistic to hope for bounds relative to the global optimum. Bad local optima exist and NNs can and do converge to them (fortunately this doesn\u2019t happen often -- explaining why is an active area of research beyond the scope of the paper).\n\n2. AR3 continues in the same sentence \u201cgood performance of the algorithms could be possible, under further assumptions like smooth loss function\u201d. The reviewer has fundamentally missed the point of the paper. RECTIFIER NEURAL NETWORKS ARE NOT SMOOTH. Nevertheless, they are the dominant feedforward NN architecture, e.g. winning the ImageNet classification challenge every year since 2012. If we as a community are interested in theoretical guarantees at all then we should not only prove strong theorems about toy algorithms but should also prove (potentially weaker) theorems about the algorithms that are actually used in practice.\n\nTo the best of our knowledge there are no convergence results for rectifier neural networks in the literature. The problem is difficult and unlikely to be definitively solved in an 8-page+appendix conference paper. It is therefore to be expected that, despite making substantial progress, the paper also leaves important questions open.\n\n\nMeaningfulness of the Taylor optimum\n---------------------------------------\nAR3\u2019s core criticism is that the RHS of the bound is not meaningful. It underlies points 2+3 of \u201cconvergence to the Taylor optimum\u201d and points 2+3 of \u201cregret for the running average\u201d.  \n\nTo illustrate the point that just having an upper bound is not good enough, AR3 writes \u201cConsider a training error sequence: 0, 1, 0, 1 \u2026 . It is running average is bounded and converges to 0. But in practice, it won\u2019t be treated as a good behaviour.\u201d Further, \u201c[if] the loss function [were] bounded [then] an upper bound on the running average training error is straightforward. \u201c\n\nWe agree. Having just any upper bound is not good enough. It would be nice to prove no-regret relative to the global optimum but this is impossible since we know neural networks don\u2019t necessarily converge to the global optimum. The question then is whether the Taylor optima are meaningful bounds or vacuous. \n\nThe Taylor optimum is the optimal solution to a convex problem. It is not the optimal solution to an arbitrary convex problem or to a problem designed to provide a \"safe\" upper bound. It is the optimal solution to the Taylor losses, which are the best convex approximations to the actual losses; best in the sense that they have the same value and have the same gradient for the encountered weights. The Taylor optimum is not pessimistic and it is not arbitrary. \n\nThe paper bounds the losses arising when optimizing a nonsmooth nonconvex optimization objective with the optimal solution to convex problems that arise naturally during gradient descent. We believe this is significant progress: we have replaced a seemingly intractable problem with a sequence of convex problems. \n\nProving convergence of the Taylor optima is an important loose end. However, it\u2019s worth recalling that the paper extensively investigates the empirical behavior of the Taylor optima and regret, showing that the Taylor optimum is a \u201ctough target\u201d in practice and that the regret behaves as predicted by the theory for: MNIST and CIFAR10; supervised and unsupervised learning; on a variety of optimizers (Adam, SGD, RMSProp). The experiments looked at the behavior of both individual neurons and entire layers. \n\n\nAdam\n------\nThe main theorem of the Adam paper assumes a series of convex losses provided by an adversary (adagrad assumes the same), see second sentence of section 4 and theorem 4.1 itself in version 8 on arxiv. The theorem does not assume the functions f_t are realizations of the same function f, even if this was the intended application.\n"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Neural Taylor Approximations: Convergence and Exploration in Rectifier Networks", "abstract": "Modern convolutional networks, incorporating rectifiers and max-pooling, are neither smooth nor convex. Standard guarantees therefore do not apply. Nevertheless, methods from convex optimization such as gradient descent and Adam are widely used as building blocks for deep learning algorithms. This paper provides the first convergence guarantee applicable to modern convnets. The guarantee matches a lower bound for convex nonsmooth functions. The key technical tool is the neural Taylor approximation -- a straightforward application of Taylor expansions to neural networks -- and the associated Taylor loss. Experiments on a range of optimizers, layers, and tasks provide evidence that the analysis accurately captures the dynamics of neural optimization.\n\nThe second half of the paper applies the Taylor approximation to isolate the main difficulty in training rectifier nets: that gradients are shattered. We investigate the hypothesis that, by exploring the space of activation configurations more thoroughly, adaptive optimizers such as RMSProp and Adam are able to converge to better solutions.", "pdf": "/pdf/b27fb3966106d9294b0c28e06eea848b5d0fcb92.pdf", "TL;DR": "We provide the first convergence result for rectifier neural networks and investigate implications for exploration in shattered landscapes.", "paperhash": "balduzzi|neural_taylor_approximations_convergence_and_exploration_in_rectifier_networks", "authorids": ["david.balduzzi@vuw.ac.nz", "brian@disneyresearch.com", "butlertony@ecs.vuw.ac.nz"], "keywords": ["Deep learning", "Optimization", "Theory", "Supervised Learning"], "conflicts": ["mpg.de", "ethz.ch", "disneyresearch.com", "vuw.ac.nz"], "authors": ["David Balduzzi", "Brian McWilliams", "Tony Butler-Yeoman"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287645318, "id": "ICLR.cc/2017/conference/-/paper275/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "HyWG0H5ge", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper275/reviewers", "ICLR.cc/2017/conference/paper275/areachairs"], "cdate": 1485287645318}}}, {"tddate": null, "tmdate": 1482303331151, "tcdate": 1482303331151, "number": 1, "id": "SJivDoD4l", "invitation": "ICLR.cc/2017/conference/-/paper275/official/comment", "forum": "HyWG0H5ge", "replyto": "Bknnet84e", "signatures": ["ICLR.cc/2017/conference/paper275/AnonReviewer3"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/conference/paper275/AnonReviewer3"], "content": {"title": "About the response", "comment": "About the convergence of the Taylor optimum:\n1. A bounded difference between two sequential training errors is still not sufficient to guarantee the convergence of the Taylor optimum. \n2. Why care about the convergence of the Taylor optimum? Because (1) How the Taylor optimum relates to the performance of the training procedure is not clear. (2) Without the convergence, why is the Taylor optimum bounded? The loss function is assumed to be bounded? But under this assumption, an upper bound on the running average training error is straightforward. The result of the paper is also much less interesting. Also see the second paragraph of this post for further comments.\n3. Compared to the regret bound in the paper of Adam: the regret bound in the paper of Adam is proved under a different context. In particular, it is proved for optimizing a noisy objective function f(\\theta). f_1, f_2, \u2026, f_T are realization of a same function f, and thus \\sum f_i(\\theta^*) makes its sense (and of course converges under reasonable assumptions to f): Given a large T, the upper bound is expected to be close to the optimum of the true objective function, and thus the lefthand side is close to the optimum of the true objective function.\n\nAbout the comments on the meaningfulness of proving a regret for the running average:\n1. From my prospective, the main contribution of the paper of Adam is about a new algorithm with better performance in practice. Although a regret bound is proved in the paper, it is only secondary. \n2. On one hand, I still insist my opinion that solely an upper bound on the running average does not say much. Consider a training error sequence: 0, 1, 0, 1 \u2026 . It is running average is bounded and converges to 0. But in practice, it won\u2019t be treated as a good behaviour. \n3. On the other hand, if the running average is bounded by a \u2018meaningful\u2019 constant (e.g. the optimum of the true loss), then some meaningful discussions about how such boundedness on the running average leads to good performance of the algorithms could be possible, under further assumptions like smooth loss function etc.\n\nAbout finite-time performance guarantees and asymptotic results:\n1. Arguably finite-time performance is the main concern in the literature of online learning. But the reason such guarantee is preferred is that it does not require the condition that T is large enough for the results to hold, not that it does not care about the convergence. In fact, in many situations the convergence is required for the result to make sense. For example, in the stochastic setting, or under some non-stationary assumptions. Moreover, in practice, we indeed care about the convergence of the training error, either finite time or for a long run (which is still finite time in fact).    \n\nAbout the comment that typical results are proved in expectation:\n2. In the literature of online learning, adversary regret bound does not have to come with the \u2018in expectation\u2019  (or in high probability). For example, see the analysis of the Follow-the-Regularized-Leader algorithm. The need of taking expectation for the error usually comes for two reasons: (1) the algorithm itself is randomized, e.g. the weighted majority algorithm and the Follow-the-Perturbed-Leader algorithm;  (2) The objective function is noisy (as the context of Adam or the minibatch setting), and one would like to analyze its performance on the true function, e.g. online-to-batch conversions. If one is only interested in the average loss, the expectation is not needed. \n"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Neural Taylor Approximations: Convergence and Exploration in Rectifier Networks", "abstract": "Modern convolutional networks, incorporating rectifiers and max-pooling, are neither smooth nor convex. Standard guarantees therefore do not apply. Nevertheless, methods from convex optimization such as gradient descent and Adam are widely used as building blocks for deep learning algorithms. This paper provides the first convergence guarantee applicable to modern convnets. The guarantee matches a lower bound for convex nonsmooth functions. The key technical tool is the neural Taylor approximation -- a straightforward application of Taylor expansions to neural networks -- and the associated Taylor loss. Experiments on a range of optimizers, layers, and tasks provide evidence that the analysis accurately captures the dynamics of neural optimization.\n\nThe second half of the paper applies the Taylor approximation to isolate the main difficulty in training rectifier nets: that gradients are shattered. We investigate the hypothesis that, by exploring the space of activation configurations more thoroughly, adaptive optimizers such as RMSProp and Adam are able to converge to better solutions.", "pdf": "/pdf/b27fb3966106d9294b0c28e06eea848b5d0fcb92.pdf", "TL;DR": "We provide the first convergence result for rectifier neural networks and investigate implications for exploration in shattered landscapes.", "paperhash": "balduzzi|neural_taylor_approximations_convergence_and_exploration_in_rectifier_networks", "authorids": ["david.balduzzi@vuw.ac.nz", "brian@disneyresearch.com", "butlertony@ecs.vuw.ac.nz"], "keywords": ["Deep learning", "Optimization", "Theory", "Supervised Learning"], "conflicts": ["mpg.de", "ethz.ch", "disneyresearch.com", "vuw.ac.nz"], "authors": ["David Balduzzi", "Brian McWilliams", "Tony Butler-Yeoman"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287645191, "id": "ICLR.cc/2017/conference/-/paper275/official/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "reply": {"forum": "HyWG0H5ge", "writers": {"values-regex": "ICLR.cc/2017/conference/paper275/(AnonReviewer|areachair)[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/conference/paper275/(AnonReviewer|areachair)[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": [], "invitees": ["ICLR.cc/2017/conference/paper275/reviewers", "ICLR.cc/2017/conference/paper275/areachairs"], "cdate": 1485287645191}}}, {"tddate": null, "tmdate": 1482227892110, "tcdate": 1482227892110, "number": 3, "id": "Bknnet84e", "invitation": "ICLR.cc/2017/conference/-/paper275/public/comment", "forum": "HyWG0H5ge", "replyto": "ByUX0ABNl", "signatures": ["~David_Balduzzi1"], "readers": ["everyone"], "writers": ["~David_Balduzzi1"], "content": {"title": "Response to AR3", "comment": "We thank the reviewer for their detailed comments.  \n\nFirst, we emphasize that Theorem 2 is correct as stated. The formulas are correct as is. However, the underbrace on the LHS of Eq. (3) has been relabeled \u201crunning average of training errors\u201d instead of \u201ctraining error\u201d. \n\nThe reviewer\u2019s points concern the ASYMPTOTIC BEHAVIOR of the left and right hand sides of Eq. (3). The paper analyses the behavior of gradient descent under a FINITE NUMBER OF ITERATIONS. The main contribution is to show: \n    a) the first convergence rate for rectifier nets\n    b) relative to a sequence of convex losses capturing the geometry of backprop\n    c) that is meaningful in practice (i.e for finite iterations)\nAlthough asymptotic results are valuable, in practice NNs are trained using a finite number of iterations.\n\nResponses to comments:\n\n1. Convergence of Taylor optimum.\nThe reviewer is correct. We showed ||a_n-a_{n+1}|| approaches 0 instead of ||a_n-a_m|| for arbitrary m > n. This was a sloppy mistake made in a rush in response to the reviewer\u2019s initial question. Fortunately, all that we require is that the Taylor optima are bounded so we have removed the discussion of Taylor optima from the appendix.\n\n2. LHS is not equivalent to training error.\nThe reviewer is correct. The LHS is better termed the \u201crunning average of errors during training\u201d or the \u201c(average) cumulative loss\u201d: it averages the entire loss curve during training rather than the final point on the curve (i.e. the training error of the final weights). \n\nAnalysing the cumulative loss is standard. The reviewer\u2019s criticism applies equally to, for example, the theorems provided for AdaGrad by Duchi et al and for Adam by Kingma and Ba in the original papers introducing the respective algorithms. \n\nOur results have a different flavor from results on stochastic gradient descent where convergence is shown in expectation. Eq. (3) is much stronger than a bound that holds in expectation since it always holds as is. It is for this reason that we (and Duchi and Kingma) use what we are calling the running average of errors. \n"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Neural Taylor Approximations: Convergence and Exploration in Rectifier Networks", "abstract": "Modern convolutional networks, incorporating rectifiers and max-pooling, are neither smooth nor convex. Standard guarantees therefore do not apply. Nevertheless, methods from convex optimization such as gradient descent and Adam are widely used as building blocks for deep learning algorithms. This paper provides the first convergence guarantee applicable to modern convnets. The guarantee matches a lower bound for convex nonsmooth functions. The key technical tool is the neural Taylor approximation -- a straightforward application of Taylor expansions to neural networks -- and the associated Taylor loss. Experiments on a range of optimizers, layers, and tasks provide evidence that the analysis accurately captures the dynamics of neural optimization.\n\nThe second half of the paper applies the Taylor approximation to isolate the main difficulty in training rectifier nets: that gradients are shattered. We investigate the hypothesis that, by exploring the space of activation configurations more thoroughly, adaptive optimizers such as RMSProp and Adam are able to converge to better solutions.", "pdf": "/pdf/b27fb3966106d9294b0c28e06eea848b5d0fcb92.pdf", "TL;DR": "We provide the first convergence result for rectifier neural networks and investigate implications for exploration in shattered landscapes.", "paperhash": "balduzzi|neural_taylor_approximations_convergence_and_exploration_in_rectifier_networks", "authorids": ["david.balduzzi@vuw.ac.nz", "brian@disneyresearch.com", "butlertony@ecs.vuw.ac.nz"], "keywords": ["Deep learning", "Optimization", "Theory", "Supervised Learning"], "conflicts": ["mpg.de", "ethz.ch", "disneyresearch.com", "vuw.ac.nz"], "authors": ["David Balduzzi", "Brian McWilliams", "Tony Butler-Yeoman"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287645318, "id": "ICLR.cc/2017/conference/-/paper275/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "HyWG0H5ge", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper275/reviewers", "ICLR.cc/2017/conference/paper275/areachairs"], "cdate": 1485287645318}}}, {"tddate": null, "replyto": null, "ddate": null, "tmdate": 1482227733860, "tcdate": 1478282760613, "number": 275, "id": "HyWG0H5ge", "invitation": "ICLR.cc/2017/conference/-/submission", "forum": "HyWG0H5ge", "signatures": ["~David_Balduzzi1"], "readers": ["everyone"], "content": {"title": "Neural Taylor Approximations: Convergence and Exploration in Rectifier Networks", "abstract": "Modern convolutional networks, incorporating rectifiers and max-pooling, are neither smooth nor convex. Standard guarantees therefore do not apply. Nevertheless, methods from convex optimization such as gradient descent and Adam are widely used as building blocks for deep learning algorithms. This paper provides the first convergence guarantee applicable to modern convnets. The guarantee matches a lower bound for convex nonsmooth functions. The key technical tool is the neural Taylor approximation -- a straightforward application of Taylor expansions to neural networks -- and the associated Taylor loss. Experiments on a range of optimizers, layers, and tasks provide evidence that the analysis accurately captures the dynamics of neural optimization.\n\nThe second half of the paper applies the Taylor approximation to isolate the main difficulty in training rectifier nets: that gradients are shattered. We investigate the hypothesis that, by exploring the space of activation configurations more thoroughly, adaptive optimizers such as RMSProp and Adam are able to converge to better solutions.", "pdf": "/pdf/b27fb3966106d9294b0c28e06eea848b5d0fcb92.pdf", "TL;DR": "We provide the first convergence result for rectifier neural networks and investigate implications for exploration in shattered landscapes.", "paperhash": "balduzzi|neural_taylor_approximations_convergence_and_exploration_in_rectifier_networks", "authorids": ["david.balduzzi@vuw.ac.nz", "brian@disneyresearch.com", "butlertony@ecs.vuw.ac.nz"], "keywords": ["Deep learning", "Optimization", "Theory", "Supervised Learning"], "conflicts": ["mpg.de", "ethz.ch", "disneyresearch.com", "vuw.ac.nz"], "authors": ["David Balduzzi", "Brian McWilliams", "Tony Butler-Yeoman"]}, "writers": [], "nonreaders": [], "details": {"replyCount": 10, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1475686800000, "tmdate": 1478287705855, "id": "ICLR.cc/2017/conference/-/submission", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/pcs"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": null, "replyto": null, "writers": {"values-regex": "~.*"}, "signatures": {"values-regex": "~.*", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"pdf": {"required": true, "order": 5, "description": "Either upload a PDF file or provide a direct link to your PDF on ArXiv (link must begin with http(s) and end with .pdf)", "value-regex": "upload|(http|https):\\/\\/.+\\.pdf"}, "title": {"required": true, "order": 1, "description": "Title of paper.", "value-regex": ".{1,250}"}, "abstract": {"required": true, "order": 4, "description": "Abstract of paper.", "value-regex": "[\\S\\s]{1,5000}"}, "authors": {"required": true, "order": 2, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of author names, as they appear in the paper."}, "conflicts": {"required": true, "order": 100, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of email domains of people who would have a conflict of interest in reviewing this paper, (e.g., cs.umass.edu;google.com, etc.)."}, "keywords": {"order": 6, "description": "Comma separated list of keywords.", "values-dropdown": ["Theory", "Computer vision", "Speech", "Natural language processing", "Deep learning", "Unsupervised Learning", "Supervised Learning", "Semi-Supervised Learning", "Reinforcement Learning", "Transfer Learning", "Multi-modal learning", "Applications", "Optimization", "Structured prediction", "Games"]}, "TL;DR": {"required": false, "order": 3, "description": "\"Too Long; Didn't Read\": a short sentence describing your paper", "value-regex": "[^\\n]{0,250}"}, "authorids": {"required": true, "order": 3, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of author email addresses, in the same order as above."}}}, "nonreaders": [], "noninvitees": [], "expdate": 1483462800000, "cdate": 1478287705855}}}, {"tddate": null, "tmdate": 1482186321743, "tcdate": 1482186269820, "number": 3, "id": "ByUX0ABNl", "invitation": "ICLR.cc/2017/conference/-/paper275/official/review", "forum": "HyWG0H5ge", "replyto": "HyWG0H5ge", "signatures": ["ICLR.cc/2017/conference/paper275/AnonReviewer3"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/conference/paper275/AnonReviewer3"], "content": {"title": "Good Novelty. But the main theorem of the paper is problematic.", "rating": "3: Clear rejection", "review": "This paper develops a theoretical guarantee for the convergence of the training error. The result is quite general that covers the training of a wide range of neural network models. The key idea of the paper is approximate the training loss by its linear approximation. Since its linearity in the variables (thus convex), the authors plug in results that has been developed in the literature of online learning. \n\nThis paper has good novelty in using the Taylor approximation thus greatly simplifying the analysis of the behaviour of the model. However, there are two problems about the main result of this paper, Theorem 2.\n\n1. It is not clear if the Taylor optimum would converge or not. \nAs noticed by the authors, the upper bound is path dependent. Appendix 3 tries to claim that this Taylor optimum indeed converges, but the proof is buggy. In the proof of Lemma 2, it is proved that the difference between two sequential Taylor optimum is approaching 0. Note that this is actually weaker than being Cauchy sequence and insufficient to guarantee convergence.\n\n2. The lefthand side of Equation (3) (I will denote it by L3 in this review) is not equivalent to training error. \nAn upper bound on this average error is not sufficient to guarantee the convergence of the training error neither. Take the gradient descent for example (thus each minibatch x_0^n is the whole training set), the convergence of the training error should be lim_{n -> \\infty} l(f_{w^n}(x_0^n), y^n). The convergence of L3 is necessary but not sufficient to imply the convergence of the training error.\n\nAnother concern about Theorem 2 (but it is minor compared to the two problems mentioned above) is that to achieve the O(1/\\sqrt{n}) rate, the algorithm has to pick a particular learning rate. Larger or smaller learning rate (in the order of n) will lead to significantly worse regret. But in the experiments of the paper, the learning rates are not picked according to the theorem.\n\nOverall, this paper has a good motivation and good novelty. It could be further developed into a good paper. But due to the two problems and a buggy proof mentioned above, I think it is not ready for publish yet.\n", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Neural Taylor Approximations: Convergence and Exploration in Rectifier Networks", "abstract": "Modern convolutional networks, incorporating rectifiers and max-pooling, are neither smooth nor convex. Standard guarantees therefore do not apply. Nevertheless, methods from convex optimization such as gradient descent and Adam are widely used as building blocks for deep learning algorithms. This paper provides the first convergence guarantee applicable to modern convnets. The guarantee matches a lower bound for convex nonsmooth functions. The key technical tool is the neural Taylor approximation -- a straightforward application of Taylor expansions to neural networks -- and the associated Taylor loss. Experiments on a range of optimizers, layers, and tasks provide evidence that the analysis accurately captures the dynamics of neural optimization.\n\nThe second half of the paper applies the Taylor approximation to isolate the main difficulty in training rectifier nets: that gradients are shattered. We investigate the hypothesis that, by exploring the space of activation configurations more thoroughly, adaptive optimizers such as RMSProp and Adam are able to converge to better solutions.", "pdf": "/pdf/b27fb3966106d9294b0c28e06eea848b5d0fcb92.pdf", "TL;DR": "We provide the first convergence result for rectifier neural networks and investigate implications for exploration in shattered landscapes.", "paperhash": "balduzzi|neural_taylor_approximations_convergence_and_exploration_in_rectifier_networks", "authorids": ["david.balduzzi@vuw.ac.nz", "brian@disneyresearch.com", "butlertony@ecs.vuw.ac.nz"], "keywords": ["Deep learning", "Optimization", "Theory", "Supervised Learning"], "conflicts": ["mpg.de", "ethz.ch", "disneyresearch.com", "vuw.ac.nz"], "authors": ["David Balduzzi", "Brian McWilliams", "Tony Butler-Yeoman"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1481932799000, "tmdate": 1482512641459, "id": "ICLR.cc/2017/conference/-/paper275/official/review", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/conference/paper275/reviewers"], "noninvitees": ["ICLR.cc/2017/conference/paper275/AnonReviewer1", "ICLR.cc/2017/conference/paper275/AnonReviewer2", "ICLR.cc/2017/conference/paper275/AnonReviewer3"], "reply": {"forum": "HyWG0H5ge", "replyto": "HyWG0H5ge", "writers": {"values-regex": "ICLR.cc/2017/conference/paper275/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/conference/paper275/AnonReviewer[0-9]+"}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "value-regex": "[\\S\\s]{1,20000}"}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1489708799000, "cdate": 1482512641459}}}, {"tddate": null, "tmdate": 1482174501752, "tcdate": 1482174501752, "number": 2, "id": "BkAme3S4e", "invitation": "ICLR.cc/2017/conference/-/paper275/public/comment", "forum": "HyWG0H5ge", "replyto": "r1mUvnfVe", "signatures": ["~David_Balduzzi1"], "readers": ["everyone"], "writers": ["~David_Balduzzi1"], "content": {"title": "response to AR1", "comment": "We thank the reviewer for their comments.\n\n1. While SGD typically shows improved performance when used with annealed learning rates and momentum, it is unclear how any improvements due to these factors would be due to increased exploration. The comparison between RMS and SGD shows that it is the adaptivity and not the learning rate which encourages exploration which is made clear in observation 3 of the paper.\n\n2. Generalization. \nWe make two remarks. Firstly, despite its importance, generalization performance is beyond the scope of the paper. The main contribution is a fundamental result about optimizing neural networks. Rectifier nets are the most commonly used feedforward architecture and yet prior to our work there were no convergence guarantees available. \n\nSecondly, there has been exciting recent work connecting the convergence rate of SGD to generalization performance, see: Hardt, Recht, Singer \u201cTrain faster, generalize better: Stability of stochastic gradient descent\u201d in ICML 2016. Unfortunately, they require smoothness so their result do not apply to rectifier nets. An possible future direction is to investigate generalization in rectifier networks by applying the methods in Hardt et al to the Taylor losses (which are smooth whenever the loss is a smooth function of the network\u2019s output -- i.e. in almost all cases).\n\nMore generally, the Taylor losses provide a bridge between rectifier nets and the vast literature on smooth and convex problems.\n\n3. Why does the Jacobian change to a_l in the <Gl,V> definition?\nThis was a typo, now corrected. Thanks."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Neural Taylor Approximations: Convergence and Exploration in Rectifier Networks", "abstract": "Modern convolutional networks, incorporating rectifiers and max-pooling, are neither smooth nor convex. Standard guarantees therefore do not apply. Nevertheless, methods from convex optimization such as gradient descent and Adam are widely used as building blocks for deep learning algorithms. This paper provides the first convergence guarantee applicable to modern convnets. The guarantee matches a lower bound for convex nonsmooth functions. The key technical tool is the neural Taylor approximation -- a straightforward application of Taylor expansions to neural networks -- and the associated Taylor loss. Experiments on a range of optimizers, layers, and tasks provide evidence that the analysis accurately captures the dynamics of neural optimization.\n\nThe second half of the paper applies the Taylor approximation to isolate the main difficulty in training rectifier nets: that gradients are shattered. We investigate the hypothesis that, by exploring the space of activation configurations more thoroughly, adaptive optimizers such as RMSProp and Adam are able to converge to better solutions.", "pdf": "/pdf/b27fb3966106d9294b0c28e06eea848b5d0fcb92.pdf", "TL;DR": "We provide the first convergence result for rectifier neural networks and investigate implications for exploration in shattered landscapes.", "paperhash": "balduzzi|neural_taylor_approximations_convergence_and_exploration_in_rectifier_networks", "authorids": ["david.balduzzi@vuw.ac.nz", "brian@disneyresearch.com", "butlertony@ecs.vuw.ac.nz"], "keywords": ["Deep learning", "Optimization", "Theory", "Supervised Learning"], "conflicts": ["mpg.de", "ethz.ch", "disneyresearch.com", "vuw.ac.nz"], "authors": ["David Balduzzi", "Brian McWilliams", "Tony Butler-Yeoman"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287645318, "id": "ICLR.cc/2017/conference/-/paper275/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "HyWG0H5ge", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper275/reviewers", "ICLR.cc/2017/conference/paper275/areachairs"], "cdate": 1485287645318}}}, {"tddate": null, "tmdate": 1481986889917, "tcdate": 1481986889917, "number": 2, "id": "ryMUmCGVx", "invitation": "ICLR.cc/2017/conference/-/paper275/official/review", "forum": "HyWG0H5ge", "replyto": "HyWG0H5ge", "signatures": ["ICLR.cc/2017/conference/paper275/AnonReviewer2"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/conference/paper275/AnonReviewer2"], "content": {"title": "Review", "rating": "7: Good paper, accept", "review": "This paper adopts Taylor approximations of neural nets for separating convex and non-convex components of the optimization. This enables them to bound the training error by the Taylor optimum and regret (theorem 2). This is a nice theoretical result applicable to popular deep nets. The empirical studies back up the theoretical claim.", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Neural Taylor Approximations: Convergence and Exploration in Rectifier Networks", "abstract": "Modern convolutional networks, incorporating rectifiers and max-pooling, are neither smooth nor convex. Standard guarantees therefore do not apply. Nevertheless, methods from convex optimization such as gradient descent and Adam are widely used as building blocks for deep learning algorithms. This paper provides the first convergence guarantee applicable to modern convnets. The guarantee matches a lower bound for convex nonsmooth functions. The key technical tool is the neural Taylor approximation -- a straightforward application of Taylor expansions to neural networks -- and the associated Taylor loss. Experiments on a range of optimizers, layers, and tasks provide evidence that the analysis accurately captures the dynamics of neural optimization.\n\nThe second half of the paper applies the Taylor approximation to isolate the main difficulty in training rectifier nets: that gradients are shattered. We investigate the hypothesis that, by exploring the space of activation configurations more thoroughly, adaptive optimizers such as RMSProp and Adam are able to converge to better solutions.", "pdf": "/pdf/b27fb3966106d9294b0c28e06eea848b5d0fcb92.pdf", "TL;DR": "We provide the first convergence result for rectifier neural networks and investigate implications for exploration in shattered landscapes.", "paperhash": "balduzzi|neural_taylor_approximations_convergence_and_exploration_in_rectifier_networks", "authorids": ["david.balduzzi@vuw.ac.nz", "brian@disneyresearch.com", "butlertony@ecs.vuw.ac.nz"], "keywords": ["Deep learning", "Optimization", "Theory", "Supervised Learning"], "conflicts": ["mpg.de", "ethz.ch", "disneyresearch.com", "vuw.ac.nz"], "authors": ["David Balduzzi", "Brian McWilliams", "Tony Butler-Yeoman"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1481932799000, "tmdate": 1482512641459, "id": "ICLR.cc/2017/conference/-/paper275/official/review", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/conference/paper275/reviewers"], "noninvitees": ["ICLR.cc/2017/conference/paper275/AnonReviewer1", "ICLR.cc/2017/conference/paper275/AnonReviewer2", "ICLR.cc/2017/conference/paper275/AnonReviewer3"], "reply": {"forum": "HyWG0H5ge", "replyto": "HyWG0H5ge", "writers": {"values-regex": "ICLR.cc/2017/conference/paper275/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/conference/paper275/AnonReviewer[0-9]+"}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "value-regex": "[\\S\\s]{1,20000}"}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1489708799000, "cdate": 1482512641459}}}, {"tddate": null, "tmdate": 1481979723586, "tcdate": 1481979723586, "number": 1, "id": "r1mUvnfVe", "invitation": "ICLR.cc/2017/conference/-/paper275/official/review", "forum": "HyWG0H5ge", "replyto": "HyWG0H5ge", "signatures": ["ICLR.cc/2017/conference/paper275/AnonReviewer1"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/conference/paper275/AnonReviewer1"], "content": {"title": "Authors make use of a first order Taylor expansion to reach a first order approximation to the output of a neural network with convex loss function using the backpropagated gradients. Shows that difference in actual training loss and Taylor loss satisfies a regret bound. Exploration of the optimization surface is discussed", "rating": "7: Good paper, accept", "review": "It is interesting to derive such a bound and show it satisfies a regret bound along with empirical evidence on the CIFAR-10 for cross entropy loss and auto encoder for MSE loss. At least empirically, by comparing the observed training loss and taylor loss, the better a particular optimizer performs (training loss statement, not a validation or observed test statement) the smaller the difference between these two. Also shown is the regret loss is satisfied at different scales of the network, by layer, neuron and whole network. \n\nThe Taylor approximation can be used to investigate activation configurations of the network, and used to connect this to difficulty in optimizing  at kinks in the loss surface, along with an empirical study of exploration of activation surface of the SGD/Adam/RMSprop optimizers, the more exploration the better the resulting training loss.\n\nNot that it impacts the paper but the weaker performance of the SGD could be related to the fixed learning rate, if we anneal this learning rate, which should improve performance, does this translate to more exploration and tightening between the actual loss and the Taylor loss? \n\n- It might be useful to use a cross validation set for some of the empirical studies, in the end we would like to say something about generalization of the resulting network\n\n- Is there a reason the subscript on the Jacobian changes to a_l in the <Gl,V> definition?\n", "confidence": "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Neural Taylor Approximations: Convergence and Exploration in Rectifier Networks", "abstract": "Modern convolutional networks, incorporating rectifiers and max-pooling, are neither smooth nor convex. Standard guarantees therefore do not apply. Nevertheless, methods from convex optimization such as gradient descent and Adam are widely used as building blocks for deep learning algorithms. This paper provides the first convergence guarantee applicable to modern convnets. The guarantee matches a lower bound for convex nonsmooth functions. The key technical tool is the neural Taylor approximation -- a straightforward application of Taylor expansions to neural networks -- and the associated Taylor loss. Experiments on a range of optimizers, layers, and tasks provide evidence that the analysis accurately captures the dynamics of neural optimization.\n\nThe second half of the paper applies the Taylor approximation to isolate the main difficulty in training rectifier nets: that gradients are shattered. We investigate the hypothesis that, by exploring the space of activation configurations more thoroughly, adaptive optimizers such as RMSProp and Adam are able to converge to better solutions.", "pdf": "/pdf/b27fb3966106d9294b0c28e06eea848b5d0fcb92.pdf", "TL;DR": "We provide the first convergence result for rectifier neural networks and investigate implications for exploration in shattered landscapes.", "paperhash": "balduzzi|neural_taylor_approximations_convergence_and_exploration_in_rectifier_networks", "authorids": ["david.balduzzi@vuw.ac.nz", "brian@disneyresearch.com", "butlertony@ecs.vuw.ac.nz"], "keywords": ["Deep learning", "Optimization", "Theory", "Supervised Learning"], "conflicts": ["mpg.de", "ethz.ch", "disneyresearch.com", "vuw.ac.nz"], "authors": ["David Balduzzi", "Brian McWilliams", "Tony Butler-Yeoman"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1481932799000, "tmdate": 1482512641459, "id": "ICLR.cc/2017/conference/-/paper275/official/review", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/conference/paper275/reviewers"], "noninvitees": ["ICLR.cc/2017/conference/paper275/AnonReviewer1", "ICLR.cc/2017/conference/paper275/AnonReviewer2", "ICLR.cc/2017/conference/paper275/AnonReviewer3"], "reply": {"forum": "HyWG0H5ge", "replyto": "HyWG0H5ge", "writers": {"values-regex": "ICLR.cc/2017/conference/paper275/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/conference/paper275/AnonReviewer[0-9]+"}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "value-regex": "[\\S\\s]{1,20000}"}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1489708799000, "cdate": 1482512641459}}}, {"tddate": null, "tmdate": 1481535102007, "tcdate": 1481535102003, "number": 1, "id": "HkIKCJ37l", "invitation": "ICLR.cc/2017/conference/-/paper275/public/comment", "forum": "HyWG0H5ge", "replyto": "rkcUQd1Xg", "signatures": ["~David_Balduzzi1"], "readers": ["everyone"], "writers": ["~David_Balduzzi1"], "content": {"title": "Convergence of Taylor optimum", "comment": "Good question.We\u2019ve added Section A.3 to the appendix explaining convergence of the Taylor optima (under a very weak assumption)\u00a0in detail. In short, we show that the Taylor optima form a Cauchy sequence, and therefore must converge.\n"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Neural Taylor Approximations: Convergence and Exploration in Rectifier Networks", "abstract": "Modern convolutional networks, incorporating rectifiers and max-pooling, are neither smooth nor convex. Standard guarantees therefore do not apply. Nevertheless, methods from convex optimization such as gradient descent and Adam are widely used as building blocks for deep learning algorithms. This paper provides the first convergence guarantee applicable to modern convnets. The guarantee matches a lower bound for convex nonsmooth functions. The key technical tool is the neural Taylor approximation -- a straightforward application of Taylor expansions to neural networks -- and the associated Taylor loss. Experiments on a range of optimizers, layers, and tasks provide evidence that the analysis accurately captures the dynamics of neural optimization.\n\nThe second half of the paper applies the Taylor approximation to isolate the main difficulty in training rectifier nets: that gradients are shattered. We investigate the hypothesis that, by exploring the space of activation configurations more thoroughly, adaptive optimizers such as RMSProp and Adam are able to converge to better solutions.", "pdf": "/pdf/b27fb3966106d9294b0c28e06eea848b5d0fcb92.pdf", "TL;DR": "We provide the first convergence result for rectifier neural networks and investigate implications for exploration in shattered landscapes.", "paperhash": "balduzzi|neural_taylor_approximations_convergence_and_exploration_in_rectifier_networks", "authorids": ["david.balduzzi@vuw.ac.nz", "brian@disneyresearch.com", "butlertony@ecs.vuw.ac.nz"], "keywords": ["Deep learning", "Optimization", "Theory", "Supervised Learning"], "conflicts": ["mpg.de", "ethz.ch", "disneyresearch.com", "vuw.ac.nz"], "authors": ["David Balduzzi", "Brian McWilliams", "Tony Butler-Yeoman"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287645318, "id": "ICLR.cc/2017/conference/-/paper275/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "HyWG0H5ge", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper275/reviewers", "ICLR.cc/2017/conference/paper275/areachairs"], "cdate": 1485287645318}}}, {"tddate": null, "tmdate": 1480717137942, "tcdate": 1480717137938, "number": 1, "id": "rkcUQd1Xg", "invitation": "ICLR.cc/2017/conference/-/paper275/pre-review/question", "forum": "HyWG0H5ge", "replyto": "HyWG0H5ge", "signatures": ["ICLR.cc/2017/conference/paper275/AnonReviewer3"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/conference/paper275/AnonReviewer3"], "content": {"title": "The convergence of the Taylor optimum", "question": "Hi,\n\nIn the paper, it is pointed out that the Taylor optimum is path-dependent. Theoretically, is it possible that the Taylor optimum does not converge at all? In the experiment, it seems not the case, but do we have theoretical guarantee?"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Neural Taylor Approximations: Convergence and Exploration in Rectifier Networks", "abstract": "Modern convolutional networks, incorporating rectifiers and max-pooling, are neither smooth nor convex. Standard guarantees therefore do not apply. Nevertheless, methods from convex optimization such as gradient descent and Adam are widely used as building blocks for deep learning algorithms. This paper provides the first convergence guarantee applicable to modern convnets. The guarantee matches a lower bound for convex nonsmooth functions. The key technical tool is the neural Taylor approximation -- a straightforward application of Taylor expansions to neural networks -- and the associated Taylor loss. Experiments on a range of optimizers, layers, and tasks provide evidence that the analysis accurately captures the dynamics of neural optimization.\n\nThe second half of the paper applies the Taylor approximation to isolate the main difficulty in training rectifier nets: that gradients are shattered. We investigate the hypothesis that, by exploring the space of activation configurations more thoroughly, adaptive optimizers such as RMSProp and Adam are able to converge to better solutions.", "pdf": "/pdf/b27fb3966106d9294b0c28e06eea848b5d0fcb92.pdf", "TL;DR": "We provide the first convergence result for rectifier neural networks and investigate implications for exploration in shattered landscapes.", "paperhash": "balduzzi|neural_taylor_approximations_convergence_and_exploration_in_rectifier_networks", "authorids": ["david.balduzzi@vuw.ac.nz", "brian@disneyresearch.com", "butlertony@ecs.vuw.ac.nz"], "keywords": ["Deep learning", "Optimization", "Theory", "Supervised Learning"], "conflicts": ["mpg.de", "ethz.ch", "disneyresearch.com", "vuw.ac.nz"], "authors": ["David Balduzzi", "Brian McWilliams", "Tony Butler-Yeoman"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1480741199000, "tmdate": 1480959367434, "id": "ICLR.cc/2017/conference/-/paper275/pre-review/question", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/conference/paper275/reviewers"], "noninvitees": ["ICLR.cc/2017/conference/paper275/AnonReviewer3"], "reply": {"forum": "HyWG0H5ge", "replyto": "HyWG0H5ge", "writers": {"values-regex": "ICLR.cc/2017/conference/paper275/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/conference/paper275/AnonReviewer[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your question.", "value-regex": ".{1,500}"}, "question": {"order": 2, "description": "Your question", "value-regex": "[\\S\\s]{1,5000}"}}}, "nonreaders": [], "expdate": 1488517199000, "cdate": 1480959367434}}}], "count": 11}