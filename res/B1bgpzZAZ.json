{"notes": [{"tddate": null, "ddate": null, "tmdate": 1518730159601, "tcdate": 1509137645974, "number": 990, "cdate": 1518730159590, "id": "B1bgpzZAZ", "invitation": "ICLR.cc/2018/Conference/-/Blind_Submission", "forum": "B1bgpzZAZ", "original": "Sk1ChMWR-", "signatures": ["ICLR.cc/2018/Conference"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Conference"], "content": {"title": "ElimiNet: A Model for Eliminating Options for Reading Comprehension with Multiple Choice Questions", "abstract": "The task of Reading Comprehension with Multiple Choice Questions, requires a human (or machine) to read a given \\{\\textit{passage, question}\\} pair and select one of the $n$ given options. The current state of the art model for this task first computes a query-aware representation for the passage and then \\textit{selects} the option which has the maximum similarity with this representation. However, when humans perform this task they do not just focus on option selection but use a combination of \\textit{elimination} and \\textit{selection}. Specifically, a human would first try to eliminate the most irrelevant option and then read the document again in the light of this new information (and perhaps ignore portions corresponding to the eliminated option). This process could be repeated multiple times till the reader is finally ready to select the correct option. We propose \\textit{ElimiNet}, a neural network based model which tries to mimic this process. Specifically, it has gates which decide whether an option can be eliminated given the \\{\\textit{document, question}\\} pair and if so it tries to make the document representation orthogonal to this eliminatedd option (akin to ignoring portions of the document corresponding to the eliminated option). The model makes multiple rounds of partial elimination to refine the document representation and finally uses a selection module to pick the best option. We evaluate our model on the recently released large scale RACE dataset and show that it outperforms the current state of the art model on 7 out of the 13 question types in this dataset. Further we show that taking an ensemble of our \\textit{elimination-selection} based method with a \\textit{selection} based method gives us an improvement of 7\\% (relative) over the best reported performance on this dataset.    \n", "pdf": "/pdf/ec9693345d75f670ab35c40974afc583f0f4d12f.pdf", "TL;DR": "A model combining elimination and selection for answering multiple choice questions", "paperhash": "parikh|eliminet_a_model_for_eliminating_options_for_reading_comprehension_with_multiple_choice_questions", "_bibtex": "@misc{\nparikh2018eliminet,\ntitle={ElimiNet: A Model for Eliminating Options for Reading Comprehension with Multiple Choice Questions},\nauthor={Soham Parikh and Ananya Sai and Preksha Nema and Mitesh M Khapra},\nyear={2018},\nurl={https://openreview.net/forum?id=B1bgpzZAZ},\n}", "keywords": ["Reading Comprehension", "Answering Multiple Choice Questions"], "authors": ["Soham Parikh", "Ananya Sai", "Preksha Nema", "Mitesh M Khapra"], "authorids": ["sohamp@cse.iitm.ac.in", "ananyasb@cse.iitm.ac.in", "preksha@cse.iitm.ac.in", "miteshk@cse.iitm.ac.in"]}, "nonreaders": [], "details": {"replyCount": 4, "writable": false, "overwriting": [], "revisions": false, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "tmdate": 1506717071958, "id": "ICLR.cc/2018/Conference/-/Blind_Submission", "writers": ["ICLR.cc/2018/Conference"], "signatures": ["ICLR.cc/2018/Conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2018/Conference"], "reply": {"forum": null, "replyto": null, "writers": {"values": ["ICLR.cc/2018/Conference"]}, "signatures": {"description": "How your identity will be displayed with the above content.", "values": ["ICLR.cc/2018/Conference"]}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"authors": {"required": false, "order": 1, "values-regex": ".*", "description": "Comma separated list of author names, as they appear in the paper."}, "authorids": {"required": false, "order": 2, "values-regex": ".*", "description": "Comma separated list of author email addresses, in the same order as above."}}}, "nonreaders": [], "noninvitees": [], "cdate": 1506717071958}}, "tauthor": "ICLR.cc/2018/Conference"}, {"tddate": null, "ddate": null, "original": null, "tmdate": 1517260076725, "tcdate": 1517250195701, "number": 847, "cdate": 1517250195686, "id": "By2qL1TSG", "invitation": "ICLR.cc/2018/Conference/-/Acceptance_Decision", "forum": "B1bgpzZAZ", "replyto": "B1bgpzZAZ", "signatures": ["ICLR.cc/2018/Conference/Program_Chairs"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Conference/Program_Chairs"], "content": {"decision": "Reject", "title": "ICLR 2018 Conference Acceptance Decision", "comment": "This paper provides a method for eliminating options in multiple-answer reading comprehension tasks, based on the contents of the text, in order to reduce the \"answer space\" a machine reading model must consider. While there's nothing wrong with this, conceptually, reviewers have questioned whether or not this is a particularly useful process to include in a machine reading pipeline, versus having agents that understand the text well enough to select the correct answer (which is, after all, the primary goal of machine reading). Some reviewers were uncomfortable with the choice of dataset, suggesting SQuAD might be a better alternative), and why I am not sure I agree with that recommendation, it would be good to see stronger positive results on more than one dataset. At the end of the day, it is the lack of convincing experimental results showing that this method yields substantial improvements over comparable baselines which does the most harm to this well written paper, and I must recommend rejection."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "ElimiNet: A Model for Eliminating Options for Reading Comprehension with Multiple Choice Questions", "abstract": "The task of Reading Comprehension with Multiple Choice Questions, requires a human (or machine) to read a given \\{\\textit{passage, question}\\} pair and select one of the $n$ given options. The current state of the art model for this task first computes a query-aware representation for the passage and then \\textit{selects} the option which has the maximum similarity with this representation. However, when humans perform this task they do not just focus on option selection but use a combination of \\textit{elimination} and \\textit{selection}. Specifically, a human would first try to eliminate the most irrelevant option and then read the document again in the light of this new information (and perhaps ignore portions corresponding to the eliminated option). This process could be repeated multiple times till the reader is finally ready to select the correct option. We propose \\textit{ElimiNet}, a neural network based model which tries to mimic this process. Specifically, it has gates which decide whether an option can be eliminated given the \\{\\textit{document, question}\\} pair and if so it tries to make the document representation orthogonal to this eliminatedd option (akin to ignoring portions of the document corresponding to the eliminated option). The model makes multiple rounds of partial elimination to refine the document representation and finally uses a selection module to pick the best option. We evaluate our model on the recently released large scale RACE dataset and show that it outperforms the current state of the art model on 7 out of the 13 question types in this dataset. Further we show that taking an ensemble of our \\textit{elimination-selection} based method with a \\textit{selection} based method gives us an improvement of 7\\% (relative) over the best reported performance on this dataset.    \n", "pdf": "/pdf/ec9693345d75f670ab35c40974afc583f0f4d12f.pdf", "TL;DR": "A model combining elimination and selection for answering multiple choice questions", "paperhash": "parikh|eliminet_a_model_for_eliminating_options_for_reading_comprehension_with_multiple_choice_questions", "_bibtex": "@misc{\nparikh2018eliminet,\ntitle={ElimiNet: A Model for Eliminating Options for Reading Comprehension with Multiple Choice Questions},\nauthor={Soham Parikh and Ananya Sai and Preksha Nema and Mitesh M Khapra},\nyear={2018},\nurl={https://openreview.net/forum?id=B1bgpzZAZ},\n}", "keywords": ["Reading Comprehension", "Answering Multiple Choice Questions"], "authors": ["Soham Parikh", "Ananya Sai", "Preksha Nema", "Mitesh M Khapra"], "authorids": ["sohamp@cse.iitm.ac.in", "ananyasb@cse.iitm.ac.in", "preksha@cse.iitm.ac.in", "miteshk@cse.iitm.ac.in"]}, "tags": [], "invitation": {"id": "ICLR.cc/2018/Conference/-/Acceptance_Decision", "rdate": null, "ddate": null, "expdate": 1541175629000, "duedate": null, "tmdate": 1541177635767, "tddate": null, "super": null, "final": null, "reply": {"forum": null, "replyto": null, "invitation": "ICLR.cc/2018/Conference/-/Blind_Submission", "writers": {"values": ["ICLR.cc/2018/Conference/Program_Chairs"]}, "signatures": {"description": "How your identity will be displayed with the above content.", "values": ["ICLR.cc/2018/Conference/Program_Chairs"]}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["ICLR.cc/2018/Conference/Program_Chairs", "everyone"]}, "content": {"title": {"required": true, "order": 1, "value": "ICLR 2018 Conference Acceptance Decision"}, "comment": {"required": false, "order": 3, "description": "(optional) Comment on this decision.", "value-regex": "[\\S\\s]{0,5000}"}, "decision": {"required": true, "order": 2, "value-dropdown": ["Accept (Oral)", "Accept (Poster)", "Reject", "Invite to Workshop Track"]}}}, "signatures": ["ICLR.cc/2018/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": [], "noninvitees": [], "writers": ["ICLR.cc/2018/Conference"], "multiReply": null, "taskCompletionCount": null, "transform": null, "cdate": 1541177635767}}}, {"tddate": null, "ddate": null, "original": null, "tmdate": 1515857718627, "tcdate": 1511799642337, "number": 2, "cdate": 1511799642337, "id": "SyfPjhYef", "invitation": "ICLR.cc/2018/Conference/-/Paper990/Official_Review", "forum": "B1bgpzZAZ", "replyto": "B1bgpzZAZ", "signatures": ["ICLR.cc/2018/Conference/Paper990/AnonReviewer2"], "readers": ["everyone"], "content": {"title": "Competent elaboration of the Gated Attention Reader", "rating": "5: Marginally below acceptance threshold", "review": "This paper gives an elaboration on the Gated Attention Reader (GAR) adding gates based on answer elimination in multiple choice reading comprehension.  I found the formal presentation of the model reasonably clear the the empirical evaluation reasonably compelling.\n\nIn my opinion the main weakness of the paper is the focus on the RACE dataset.  This dataset has not attracted much attention and most work in reading comprehension has now moved to the SQUAD dataset for which there is an active leader board.  I realize that SQUAD is not explicitly multiple choice and that this is a challenge for an answer elimination architecture.  However, it seems that answer elimination might be applied to each choice of the initial position of a possible answer span.  In any case, competing with an active leader board would be much more compelling.", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "writers": [], "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": true, "forumContent": {"title": "ElimiNet: A Model for Eliminating Options for Reading Comprehension with Multiple Choice Questions", "abstract": "The task of Reading Comprehension with Multiple Choice Questions, requires a human (or machine) to read a given \\{\\textit{passage, question}\\} pair and select one of the $n$ given options. The current state of the art model for this task first computes a query-aware representation for the passage and then \\textit{selects} the option which has the maximum similarity with this representation. However, when humans perform this task they do not just focus on option selection but use a combination of \\textit{elimination} and \\textit{selection}. Specifically, a human would first try to eliminate the most irrelevant option and then read the document again in the light of this new information (and perhaps ignore portions corresponding to the eliminated option). This process could be repeated multiple times till the reader is finally ready to select the correct option. We propose \\textit{ElimiNet}, a neural network based model which tries to mimic this process. Specifically, it has gates which decide whether an option can be eliminated given the \\{\\textit{document, question}\\} pair and if so it tries to make the document representation orthogonal to this eliminatedd option (akin to ignoring portions of the document corresponding to the eliminated option). The model makes multiple rounds of partial elimination to refine the document representation and finally uses a selection module to pick the best option. We evaluate our model on the recently released large scale RACE dataset and show that it outperforms the current state of the art model on 7 out of the 13 question types in this dataset. Further we show that taking an ensemble of our \\textit{elimination-selection} based method with a \\textit{selection} based method gives us an improvement of 7\\% (relative) over the best reported performance on this dataset.    \n", "pdf": "/pdf/ec9693345d75f670ab35c40974afc583f0f4d12f.pdf", "TL;DR": "A model combining elimination and selection for answering multiple choice questions", "paperhash": "parikh|eliminet_a_model_for_eliminating_options_for_reading_comprehension_with_multiple_choice_questions", "_bibtex": "@misc{\nparikh2018eliminet,\ntitle={ElimiNet: A Model for Eliminating Options for Reading Comprehension with Multiple Choice Questions},\nauthor={Soham Parikh and Ananya Sai and Preksha Nema and Mitesh M Khapra},\nyear={2018},\nurl={https://openreview.net/forum?id=B1bgpzZAZ},\n}", "keywords": ["Reading Comprehension", "Answering Multiple Choice Questions"], "authors": ["Soham Parikh", "Ananya Sai", "Preksha Nema", "Mitesh M Khapra"], "authorids": ["sohamp@cse.iitm.ac.in", "ananyasb@cse.iitm.ac.in", "preksha@cse.iitm.ac.in", "miteshk@cse.iitm.ac.in"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1511845199000, "tmdate": 1515642538489, "id": "ICLR.cc/2018/Conference/-/Paper990/Official_Review", "writers": ["ICLR.cc/2018/Conference"], "signatures": ["ICLR.cc/2018/Conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2018/Conference/Paper990/Reviewers"], "noninvitees": ["ICLR.cc/2018/Conference/Paper990/AnonReviewer3", "ICLR.cc/2018/Conference/Paper990/AnonReviewer2", "ICLR.cc/2018/Conference/Paper990/AnonReviewer1"], "reply": {"forum": "B1bgpzZAZ", "replyto": "B1bgpzZAZ", "writers": {"values": []}, "signatures": {"values-regex": "ICLR.cc/2018/Conference/Paper990/AnonReviewer[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"required": true, "order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"required": true, "order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "value-regex": "[\\S\\s]{1,200000}"}, "rating": {"required": true, "order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"required": true, "order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1519621199000, "cdate": 1515642538489}}}, {"tddate": null, "ddate": null, "original": null, "tmdate": 1515642538579, "tcdate": 1511663116782, "number": 1, "cdate": 1511663116782, "id": "HkHGUsPef", "invitation": "ICLR.cc/2018/Conference/-/Paper990/Official_Review", "forum": "B1bgpzZAZ", "replyto": "B1bgpzZAZ", "signatures": ["ICLR.cc/2018/Conference/Paper990/AnonReviewer3"], "readers": ["everyone"], "content": {"title": "Interesting problem but the results are not so good, hope the methods could be further improved in the future.", "rating": "5: Marginally below acceptance threshold", "review": "In this paper, a model is built for reading comprehension with multiple choices. The model consists of three modules: encoder, interaction module and elimination module. The major contributions are two folds: firstly, proposing the interesting option elimination problem for multi-step reading comprehension;  and secondly, proposing the elimination module where a eliminate gate is used to select different orthogonal factors from the document representations. Intuitively, one answer option can be viewed as eliminated if the document representation vector has its factor along the option vector ignored.\n\nThe elimination module is interesting, but the usefulness of \u201celimination\u201d is not well justified for two reasons. First, the improvement of the proposed model over the previous state of the art is limited. Second, the model is built upon GAR until the elimination module, then according to Table 1 it seems to indicate that the elimination module does not help significantly (0.4% improvement). \n\nIn order to show the usefulness of the elimination module, the model should be exactly built on the GAR with an additional elimination module (i.e. after removing the elimination module, the performance should be similar to GAR but not something significantly worse with a 42.58% accuracy). Then we can explicitly compare the performance between GAR and the GAR w/ elimination module to tell how much the new module helps.\n\nOther issues:\n\n1) Is there any difference to directly use $x$ and $h^z$ instead of $x^e$ and $x^r$ to compute $\\tilde{x}_i$? Even though the authors find the orthogonal vectors, they\u2019re gated summed together very soon. It would be better to show how much \u201celimination\u201d and \u201csubtraction\u201d effect the final performance, besides the effect of subtraction gate.\n\n2) A figure showing the model architecture and the corresponding QA process will better help the readers understand the proposed model.\n\n3) $c_i$ in page 5 is not defined. What\u2019s the performance of only using $s_i$ for answer selection or replacing $x^L$ with $s_i$ in score function?\n\n4) It would be better to have the experiments trained with different $n$ to show how multi-hop effects the final performance, besides the case study in Figure 3.\n\nMinor issues:\n\n1) In Eqn. (4), it would be better to use a vector as the input of softmax.\n\n2) It would be easier for discussion if the authors could assign numbers to every equation.", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "writers": [], "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "ElimiNet: A Model for Eliminating Options for Reading Comprehension with Multiple Choice Questions", "abstract": "The task of Reading Comprehension with Multiple Choice Questions, requires a human (or machine) to read a given \\{\\textit{passage, question}\\} pair and select one of the $n$ given options. The current state of the art model for this task first computes a query-aware representation for the passage and then \\textit{selects} the option which has the maximum similarity with this representation. However, when humans perform this task they do not just focus on option selection but use a combination of \\textit{elimination} and \\textit{selection}. Specifically, a human would first try to eliminate the most irrelevant option and then read the document again in the light of this new information (and perhaps ignore portions corresponding to the eliminated option). This process could be repeated multiple times till the reader is finally ready to select the correct option. We propose \\textit{ElimiNet}, a neural network based model which tries to mimic this process. Specifically, it has gates which decide whether an option can be eliminated given the \\{\\textit{document, question}\\} pair and if so it tries to make the document representation orthogonal to this eliminatedd option (akin to ignoring portions of the document corresponding to the eliminated option). The model makes multiple rounds of partial elimination to refine the document representation and finally uses a selection module to pick the best option. We evaluate our model on the recently released large scale RACE dataset and show that it outperforms the current state of the art model on 7 out of the 13 question types in this dataset. Further we show that taking an ensemble of our \\textit{elimination-selection} based method with a \\textit{selection} based method gives us an improvement of 7\\% (relative) over the best reported performance on this dataset.    \n", "pdf": "/pdf/ec9693345d75f670ab35c40974afc583f0f4d12f.pdf", "TL;DR": "A model combining elimination and selection for answering multiple choice questions", "paperhash": "parikh|eliminet_a_model_for_eliminating_options_for_reading_comprehension_with_multiple_choice_questions", "_bibtex": "@misc{\nparikh2018eliminet,\ntitle={ElimiNet: A Model for Eliminating Options for Reading Comprehension with Multiple Choice Questions},\nauthor={Soham Parikh and Ananya Sai and Preksha Nema and Mitesh M Khapra},\nyear={2018},\nurl={https://openreview.net/forum?id=B1bgpzZAZ},\n}", "keywords": ["Reading Comprehension", "Answering Multiple Choice Questions"], "authors": ["Soham Parikh", "Ananya Sai", "Preksha Nema", "Mitesh M Khapra"], "authorids": ["sohamp@cse.iitm.ac.in", "ananyasb@cse.iitm.ac.in", "preksha@cse.iitm.ac.in", "miteshk@cse.iitm.ac.in"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1511845199000, "tmdate": 1515642538489, "id": "ICLR.cc/2018/Conference/-/Paper990/Official_Review", "writers": ["ICLR.cc/2018/Conference"], "signatures": ["ICLR.cc/2018/Conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2018/Conference/Paper990/Reviewers"], "noninvitees": ["ICLR.cc/2018/Conference/Paper990/AnonReviewer3", "ICLR.cc/2018/Conference/Paper990/AnonReviewer2", "ICLR.cc/2018/Conference/Paper990/AnonReviewer1"], "reply": {"forum": "B1bgpzZAZ", "replyto": "B1bgpzZAZ", "writers": {"values": []}, "signatures": {"values-regex": "ICLR.cc/2018/Conference/Paper990/AnonReviewer[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"required": true, "order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"required": true, "order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "value-regex": "[\\S\\s]{1,200000}"}, "rating": {"required": true, "order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"required": true, "order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1519621199000, "cdate": 1515642538489}}}, {"tddate": null, "ddate": null, "original": null, "tmdate": 1515642538505, "tcdate": 1511851163677, "number": 3, "cdate": 1511851163677, "id": "HJViVF5gf", "invitation": "ICLR.cc/2018/Conference/-/Paper990/Official_Review", "forum": "B1bgpzZAZ", "replyto": "B1bgpzZAZ", "signatures": ["ICLR.cc/2018/Conference/Paper990/AnonReviewer1"], "readers": ["everyone"], "content": {"title": "Official review", "rating": "4: Ok but not good enough - rejection", "review": "This paper proposes a new reading comprehension model for multi-choice questions and the main motivation is that some options should be eliminated first to infer better passage/question representations.\n\nIt is a well-written paper, however, I am not very convinced by its motivation, the proposed model and the experimental results. \n\nFirst of all, the improvement is rather limited. It is only 0.4 improvement overall on the RACE dataset; although it outperforms GAR on 7 out of 13 categories; but why is it worse on the other 6 categories? I don\u2019t see any convincing explanations here.\n\nSecondly, in terms of the development of reading comprehension models, I don\u2019t see why we need to care about eliminating the irrelevant options. It is hard to generalize to any other RC/QA tasks. If the point is that the options can add useful information to induce better representations for passage/question, there should be some simple baselines in the middle that this paper should compare to. The two baselines SAR and GAR both only induce a representation from paragraph/question, and finally compare to the representation of each option. Maybe a simple baseline is to merge the question and all the options and see if a better document representation can be defined. \n\nSome visualizations/motivational examples could be also useful to understand how some options are eliminated and how the document representation has been changed based on that.\n", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "writers": [], "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": true, "forumContent": {"title": "ElimiNet: A Model for Eliminating Options for Reading Comprehension with Multiple Choice Questions", "abstract": "The task of Reading Comprehension with Multiple Choice Questions, requires a human (or machine) to read a given \\{\\textit{passage, question}\\} pair and select one of the $n$ given options. The current state of the art model for this task first computes a query-aware representation for the passage and then \\textit{selects} the option which has the maximum similarity with this representation. However, when humans perform this task they do not just focus on option selection but use a combination of \\textit{elimination} and \\textit{selection}. Specifically, a human would first try to eliminate the most irrelevant option and then read the document again in the light of this new information (and perhaps ignore portions corresponding to the eliminated option). This process could be repeated multiple times till the reader is finally ready to select the correct option. We propose \\textit{ElimiNet}, a neural network based model which tries to mimic this process. Specifically, it has gates which decide whether an option can be eliminated given the \\{\\textit{document, question}\\} pair and if so it tries to make the document representation orthogonal to this eliminatedd option (akin to ignoring portions of the document corresponding to the eliminated option). The model makes multiple rounds of partial elimination to refine the document representation and finally uses a selection module to pick the best option. We evaluate our model on the recently released large scale RACE dataset and show that it outperforms the current state of the art model on 7 out of the 13 question types in this dataset. Further we show that taking an ensemble of our \\textit{elimination-selection} based method with a \\textit{selection} based method gives us an improvement of 7\\% (relative) over the best reported performance on this dataset.    \n", "pdf": "/pdf/ec9693345d75f670ab35c40974afc583f0f4d12f.pdf", "TL;DR": "A model combining elimination and selection for answering multiple choice questions", "paperhash": "parikh|eliminet_a_model_for_eliminating_options_for_reading_comprehension_with_multiple_choice_questions", "_bibtex": "@misc{\nparikh2018eliminet,\ntitle={ElimiNet: A Model for Eliminating Options for Reading Comprehension with Multiple Choice Questions},\nauthor={Soham Parikh and Ananya Sai and Preksha Nema and Mitesh M Khapra},\nyear={2018},\nurl={https://openreview.net/forum?id=B1bgpzZAZ},\n}", "keywords": ["Reading Comprehension", "Answering Multiple Choice Questions"], "authors": ["Soham Parikh", "Ananya Sai", "Preksha Nema", "Mitesh M Khapra"], "authorids": ["sohamp@cse.iitm.ac.in", "ananyasb@cse.iitm.ac.in", "preksha@cse.iitm.ac.in", "miteshk@cse.iitm.ac.in"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1511845199000, "tmdate": 1515642538489, "id": "ICLR.cc/2018/Conference/-/Paper990/Official_Review", "writers": ["ICLR.cc/2018/Conference"], "signatures": ["ICLR.cc/2018/Conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2018/Conference/Paper990/Reviewers"], "noninvitees": ["ICLR.cc/2018/Conference/Paper990/AnonReviewer3", "ICLR.cc/2018/Conference/Paper990/AnonReviewer2", "ICLR.cc/2018/Conference/Paper990/AnonReviewer1"], "reply": {"forum": "B1bgpzZAZ", "replyto": "B1bgpzZAZ", "writers": {"values": []}, "signatures": {"values-regex": "ICLR.cc/2018/Conference/Paper990/AnonReviewer[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"required": true, "order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"required": true, "order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "value-regex": "[\\S\\s]{1,200000}"}, "rating": {"required": true, "order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"required": true, "order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1519621199000, "cdate": 1515642538489}}}], "count": 5}