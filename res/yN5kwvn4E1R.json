{"notes": [{"id": "yN5kwvn4E1R", "original": "QyvRB10faJ0", "number": 155, "cdate": 1601308026025, "ddate": null, "tcdate": 1601308026025, "tmdate": 1614985661142, "tddate": null, "forum": "yN5kwvn4E1R", "replyto": null, "invitation": "ICLR.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Dual Graph Complementary Network", "authorids": ["liuchh20@lzu.edu.cn", "~Kun_Zhan1"], "authors": ["Chenhua Liu", "Kun Zhan"], "keywords": [], "abstract": "As a powerful representation learning method on graph data, graph neural networks (GNNs) have shown great popularity in tackling graph analytic problems. Although many attempts have been made in literatures to find strategies about extracting better embedding of the target nodes, few of them consider this issue from a comprehensive perspective. Most of current GNNs usually employ some single method which can commendably extract a certain kind of feature but some equally important features are often ignored. In this paper, we develop a novel dual graph complementary network (DGCN) to learn representation complementarily. We use two different branches, and inputs of the two branches are the same, which are composed of structure and feature information. At the same time, there is also a complementary relationship between the two branches. Beyond that, our extensive experiments show that DGCN outperforms state-of-the-art methods on five public benchmark datasets.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "liu|dual_graph_complementary_network", "supplementary_material": "/attachment/a4cc38571664aa9f6c008cb1772d15eb77acc5d8.zip", "pdf": "/pdf/49cbb83bfb8130ff924168fcbc9f67087543b947.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=TMGnOcS7OT", "_bibtex": "@misc{\nliu2021dual,\ntitle={Dual Graph Complementary Network},\nauthor={Chenhua Liu and Kun Zhan},\nyear={2021},\nurl={https://openreview.net/forum?id=yN5kwvn4E1R}\n}"}, "signatures": ["ICLR.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference"], "details": {"replyCount": 9, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"reply": {"readers": {"values-regex": ".*"}, "writers": {"values": ["ICLR.cc/2021/Conference"]}, "signatures": {"values": ["ICLR.cc/2021/Conference"]}, "content": {"authors": {"values": ["Anonymous"]}, "authorids": {"values-regex": ".*"}, "reviewed_version_(pdf)": {"required": false, "description": "Upload a PDF file that ends with .pdf", "value-regex": ".*"}}}, "signatures": ["ICLR.cc/2021/Conference"], "readers": ["everyone"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["~", "OpenReview.net/Support"], "tcdate": 1601308008205, "tmdate": 1614984599368, "id": "ICLR.cc/2021/Conference/-/Blind_Submission"}}, "tauthor": "OpenReview.net"}, {"id": "Iw9ZZMHvJGe", "original": null, "number": 1, "cdate": 1610040500732, "ddate": null, "tcdate": 1610040500732, "tmdate": 1610474107418, "tddate": null, "forum": "yN5kwvn4E1R", "replyto": "yN5kwvn4E1R", "invitation": "ICLR.cc/2021/Conference/Paper155/-/Decision", "content": {"title": "Final Decision", "decision": "Reject", "comment": "All four reviewers expressed very significant and consistent concerns on this submission during review. No reviewer is willing to support this submission during discussion. It is clear this submission does not make the bar of ICLR."}, "signatures": ["ICLR.cc/2021/Conference/Program_Chairs"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference/Program_Chairs"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Dual Graph Complementary Network", "authorids": ["liuchh20@lzu.edu.cn", "~Kun_Zhan1"], "authors": ["Chenhua Liu", "Kun Zhan"], "keywords": [], "abstract": "As a powerful representation learning method on graph data, graph neural networks (GNNs) have shown great popularity in tackling graph analytic problems. Although many attempts have been made in literatures to find strategies about extracting better embedding of the target nodes, few of them consider this issue from a comprehensive perspective. Most of current GNNs usually employ some single method which can commendably extract a certain kind of feature but some equally important features are often ignored. In this paper, we develop a novel dual graph complementary network (DGCN) to learn representation complementarily. We use two different branches, and inputs of the two branches are the same, which are composed of structure and feature information. At the same time, there is also a complementary relationship between the two branches. Beyond that, our extensive experiments show that DGCN outperforms state-of-the-art methods on five public benchmark datasets.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "liu|dual_graph_complementary_network", "supplementary_material": "/attachment/a4cc38571664aa9f6c008cb1772d15eb77acc5d8.zip", "pdf": "/pdf/49cbb83bfb8130ff924168fcbc9f67087543b947.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=TMGnOcS7OT", "_bibtex": "@misc{\nliu2021dual,\ntitle={Dual Graph Complementary Network},\nauthor={Chenhua Liu and Kun Zhan},\nyear={2021},\nurl={https://openreview.net/forum?id=yN5kwvn4E1R}\n}"}, "tags": [], "invitation": {"reply": {"forum": "yN5kwvn4E1R", "replyto": "yN5kwvn4E1R", "readers": {"values": ["everyone"]}, "writers": {"values": ["ICLR.cc/2021/Conference/Program_Chairs"]}, "signatures": {"values": ["ICLR.cc/2021/Conference/Program_Chairs"]}, "content": {"title": {"value": "Final Decision"}, "decision": {"value-radio": ["Accept (Oral)", "Accept (Spotlight)", "Accept (Poster)", "Reject"]}, "comment": {"value-regex": "[\\S\\s]{0,50000}", "markdown": true}}}, "multiReply": false, "signatures": ["ICLR.cc/2021/Conference"], "readers": ["everyone"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Program_Chairs"], "tcdate": 1610040500716, "tmdate": 1610474107402, "id": "ICLR.cc/2021/Conference/Paper155/-/Decision"}}}, {"id": "K-5yHXq05xU", "original": null, "number": 5, "cdate": 1605547901264, "ddate": null, "tcdate": 1605547901264, "tmdate": 1605547901264, "tddate": null, "forum": "yN5kwvn4E1R", "replyto": "8sriY-EOBYD", "invitation": "ICLR.cc/2021/Conference/Paper155/-/Official_Comment", "content": {"title": "To Reviewer2", "comment": "Thank you for taking the time to review our paper and we appreciate the positive and constructive feedback. In response to some of your concerns, we have made the following responses\uff1a\n\nQuote 1: \u201cThe paper keeps arguing traditional GNNs only use one-side information, but they are actually leverage both node features and graph structures by propagating nodes features over the graph structure. \u201d\n\nWe have always admitted that traditional GNNs can leverage both node features and graph structures. Actually, the main idea in our paper is that traditional GNNs only uses one graph to \npropagate nodes features. And We believe that graphs also have attributes. Take the citation network as an example. If nodes refer to papers, graph 1 thinks that nodes belonging to the same author should be connected, while graph 2 thinks that nodes with citation relationships should be connected. Obviously, if GNNs use only one graph, some implicit information may be ignored.\n\nQuote 2: \u201cThe paper claims that different node attributes contribute in different ways that should be sufficiently leveraged .....\u201d\n\nIn fact, as mentioned above, we believe that graph actually reflects whether there is a certain relationship between different nodes (such as citation, same author, etc.). The reason for the success of GNNs lies in their ability to propagating nodes features over the graph structure. And, considering different graphs at the same time may be helpful for us to obtain more sufficient information. Taking the citation network as an example, we believe that if a node can obtain the information of the node belonging to the same author and the information of the node cited by it at the same time, it will get more information.\nBut we still need to admit that the graphs we currently use only include the original graph in the dataset and the graph constructed by features. How to get more different graphs is still a problem.\n\n\nQuote 3:\u201cFor this new splitting way, no hyperparameters are report for both the model here and previous models. \u201d\n\nWe will submit model parameters in supplementary materials later.\n\nQuote 4:\u201cThere are quite a few errors in grammar.\u201d\n\nThanks for your suggestion, we will check the grammar of the paper.\n"}, "signatures": ["ICLR.cc/2021/Conference/Paper155/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper155/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Dual Graph Complementary Network", "authorids": ["liuchh20@lzu.edu.cn", "~Kun_Zhan1"], "authors": ["Chenhua Liu", "Kun Zhan"], "keywords": [], "abstract": "As a powerful representation learning method on graph data, graph neural networks (GNNs) have shown great popularity in tackling graph analytic problems. Although many attempts have been made in literatures to find strategies about extracting better embedding of the target nodes, few of them consider this issue from a comprehensive perspective. Most of current GNNs usually employ some single method which can commendably extract a certain kind of feature but some equally important features are often ignored. In this paper, we develop a novel dual graph complementary network (DGCN) to learn representation complementarily. We use two different branches, and inputs of the two branches are the same, which are composed of structure and feature information. At the same time, there is also a complementary relationship between the two branches. Beyond that, our extensive experiments show that DGCN outperforms state-of-the-art methods on five public benchmark datasets.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "liu|dual_graph_complementary_network", "supplementary_material": "/attachment/a4cc38571664aa9f6c008cb1772d15eb77acc5d8.zip", "pdf": "/pdf/49cbb83bfb8130ff924168fcbc9f67087543b947.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=TMGnOcS7OT", "_bibtex": "@misc{\nliu2021dual,\ntitle={Dual Graph Complementary Network},\nauthor={Chenhua Liu and Kun Zhan},\nyear={2021},\nurl={https://openreview.net/forum?id=yN5kwvn4E1R}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "yN5kwvn4E1R", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper155/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper155/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper155/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper155/Authors|ICLR.cc/2021/Conference/Paper155/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper155/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923874036, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper155/-/Official_Comment"}}}, {"id": "kM7bDdOZ9XW", "original": null, "number": 4, "cdate": 1605547867137, "ddate": null, "tcdate": 1605547867137, "tmdate": 1605547867137, "tddate": null, "forum": "yN5kwvn4E1R", "replyto": "x8wVahzvXdE", "invitation": "ICLR.cc/2021/Conference/Paper155/-/Official_Comment", "content": {"title": "To Reviewer1", "comment": "Thank you for taking the time to review our paper and we appreciate the positive and constructive feedback. In response to some of your concerns, we have made the following responses\uff1a\n\n1\u3001We want to point out that our DGCN uses two different network branches to extract features (GCN and GAT are used in the paper), and the input of these two branches is exactly the same (Extract feature information and structural information at the same time in a forward pass) . Therefore, there is no situation where two GCNs are used to extract structural information and characteristic information and then two GATs are used to extract structural information and characteristic information.\n\n2\u3001About motivation, the original meaning of \"Most of the traditional GNNs only consider the single connection between nodes and ignore other implicit information\" is as follows:\nGNNs use graph as the basis of aggregation (that is, if and only if two nodes are connected, they can be aggregated to update representation.). Graph has attributes. Take the citation network as an example. If nodes refer to papers, Graph 1 thinks that nodes belonging to the same author should be connected, while Graph 2 thinks that nodes with citation relationships should be connected. Obviously, if GNNs use only one graph, some implicit information may be ignored. In general, \"the single connection\" refers to a single graph, and our paper does not use the knowledge of hyper-graphs.\n\n3\u3001We will submit model parameters in supplementary materials later.\n"}, "signatures": ["ICLR.cc/2021/Conference/Paper155/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper155/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Dual Graph Complementary Network", "authorids": ["liuchh20@lzu.edu.cn", "~Kun_Zhan1"], "authors": ["Chenhua Liu", "Kun Zhan"], "keywords": [], "abstract": "As a powerful representation learning method on graph data, graph neural networks (GNNs) have shown great popularity in tackling graph analytic problems. Although many attempts have been made in literatures to find strategies about extracting better embedding of the target nodes, few of them consider this issue from a comprehensive perspective. Most of current GNNs usually employ some single method which can commendably extract a certain kind of feature but some equally important features are often ignored. In this paper, we develop a novel dual graph complementary network (DGCN) to learn representation complementarily. We use two different branches, and inputs of the two branches are the same, which are composed of structure and feature information. At the same time, there is also a complementary relationship between the two branches. Beyond that, our extensive experiments show that DGCN outperforms state-of-the-art methods on five public benchmark datasets.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "liu|dual_graph_complementary_network", "supplementary_material": "/attachment/a4cc38571664aa9f6c008cb1772d15eb77acc5d8.zip", "pdf": "/pdf/49cbb83bfb8130ff924168fcbc9f67087543b947.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=TMGnOcS7OT", "_bibtex": "@misc{\nliu2021dual,\ntitle={Dual Graph Complementary Network},\nauthor={Chenhua Liu and Kun Zhan},\nyear={2021},\nurl={https://openreview.net/forum?id=yN5kwvn4E1R}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "yN5kwvn4E1R", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper155/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper155/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper155/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper155/Authors|ICLR.cc/2021/Conference/Paper155/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper155/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923874036, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper155/-/Official_Comment"}}}, {"id": "hRbRXROOMZf", "original": null, "number": 3, "cdate": 1605547770801, "ddate": null, "tcdate": 1605547770801, "tmdate": 1605547807468, "tddate": null, "forum": "yN5kwvn4E1R", "replyto": "VAK0BPiSBO", "invitation": "ICLR.cc/2021/Conference/Paper155/-/Official_Comment", "content": {"title": "To Reviewer4", "comment": "Thank you for taking the time to review our paper and we appreciate the positive and constructive feedback. \n\n\nQuote 1: \u201c The reason why two branches of GConv nets are used is not clear. I am especially not clear how the proposed DGCN differs from dual-channeled GAT, why the diversity loss is not employed on attention heads, and how does the embedding learnt by GCN supplement the information of that by GAT. More elaborations are needed.\u201d\n\nThe core of our model is that the networks selected by the two branches are different, so that more complementary information can be extracted. In addition, our network uses graph in the dataset and graph constructed from features to extract richer information at the same time. We use the diversity loss to expand the differences between branches, and then the attention mechanism combines the embedded information of GCN with the embedded information of GAT to obtain more abundant information. \n\n \nQuote 2: \u201cInconsistency between GCN and KNN-GCN. It seems that on UAI2010, BlogCatelog, and Flickr kNN-GCN is significantly better than GCN, but the opposite holds for the other two datasets. It should be noted why the two methods show such different performance on different datasets.\u201d\n\nThe difference between the two networks in different datasets should come from the use of different graphs.\nThe main difference between GCN and KNN-GCN is that the structure graph and cosine graph are used respectively. Graph essentially reflects the correlation degree of nodes in a certain attribute. Taking citation network as an example, if nodes refer to papers, graph 1 thinks that nodes belonging to the same author should be connected, while graph 2 thinks that nodes with reference relationship should be connected. In the real world, there are cases where the same author writes different kinds of papers and a paper quotes different kinds of papers. In extreme cases, if on Graph 1, nodes with the same label are connected to each other;In Graph 2, nodes belonging to different classes are connected with each other. Obviously, graph 1 has a better learning effect than Graph 2. In fact, although the above situation is difficult to occur, different graph attributes obviously affect the performance of the model. Therefore, for a dataset, a graph that is more relevant to its classification goal will perform better.\n\nQuote 3: \u201cThe authors should especially pay attention to network embedding techniques.\u201d\n\nThank you very much for your comments, we will continue to improve in this regard.\n\n\nQuote 4: \u201cMathematical expressions are in chaotic forms, which makes the readability poor.\nCDAN -> DGCN?\u201d\n\nThank you very much for your comments. We will correct the typing errors and further improve the mathematical expressions.\n"}, "signatures": ["ICLR.cc/2021/Conference/Paper155/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper155/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Dual Graph Complementary Network", "authorids": ["liuchh20@lzu.edu.cn", "~Kun_Zhan1"], "authors": ["Chenhua Liu", "Kun Zhan"], "keywords": [], "abstract": "As a powerful representation learning method on graph data, graph neural networks (GNNs) have shown great popularity in tackling graph analytic problems. Although many attempts have been made in literatures to find strategies about extracting better embedding of the target nodes, few of them consider this issue from a comprehensive perspective. Most of current GNNs usually employ some single method which can commendably extract a certain kind of feature but some equally important features are often ignored. In this paper, we develop a novel dual graph complementary network (DGCN) to learn representation complementarily. We use two different branches, and inputs of the two branches are the same, which are composed of structure and feature information. At the same time, there is also a complementary relationship between the two branches. Beyond that, our extensive experiments show that DGCN outperforms state-of-the-art methods on five public benchmark datasets.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "liu|dual_graph_complementary_network", "supplementary_material": "/attachment/a4cc38571664aa9f6c008cb1772d15eb77acc5d8.zip", "pdf": "/pdf/49cbb83bfb8130ff924168fcbc9f67087543b947.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=TMGnOcS7OT", "_bibtex": "@misc{\nliu2021dual,\ntitle={Dual Graph Complementary Network},\nauthor={Chenhua Liu and Kun Zhan},\nyear={2021},\nurl={https://openreview.net/forum?id=yN5kwvn4E1R}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "yN5kwvn4E1R", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper155/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper155/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper155/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper155/Authors|ICLR.cc/2021/Conference/Paper155/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper155/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923874036, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper155/-/Official_Comment"}}}, {"id": "J8bjZNPSCpw", "original": null, "number": 2, "cdate": 1605547715639, "ddate": null, "tcdate": 1605547715639, "tmdate": 1605547715639, "tddate": null, "forum": "yN5kwvn4E1R", "replyto": "oQg1LB0ppPk", "invitation": "ICLR.cc/2021/Conference/Paper155/-/Official_Comment", "content": {"title": "To Reviewer3", "comment": "Thank you for taking the time to review our paper and we appreciate the positive and constructive feedback. \n\nQuote 1: \u201cThe choice of GCN and GAT as the building blocks are not well justified. It is also possible to try other kinds of GNNs.\u201d\n\nWe admit that branches can use other networks, but the core of our model is that the networks selected by the two branches are different, so that more complementary information can be extracted. In addition, we found that even with the same network, when we change the input, we can still get comparable results. We will submit supplementary experiments to prove the validity of our views later.\n\nQuote 2: \u201cThe statement on GAT \"ignores the inherent structure of the graph space\" on page 4 is confusing since it learns weights based on the graph structures. \u201d\n\nI'm sorry that our expression made you misunderstand: our original meaning is that compared with GCN, the degree of central node and neighbor node is more considered in aggregation. GAT adopts completely different operation in aggregation, and ignores the influence of degree attribute of node on aggregation.\n"}, "signatures": ["ICLR.cc/2021/Conference/Paper155/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper155/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Dual Graph Complementary Network", "authorids": ["liuchh20@lzu.edu.cn", "~Kun_Zhan1"], "authors": ["Chenhua Liu", "Kun Zhan"], "keywords": [], "abstract": "As a powerful representation learning method on graph data, graph neural networks (GNNs) have shown great popularity in tackling graph analytic problems. Although many attempts have been made in literatures to find strategies about extracting better embedding of the target nodes, few of them consider this issue from a comprehensive perspective. Most of current GNNs usually employ some single method which can commendably extract a certain kind of feature but some equally important features are often ignored. In this paper, we develop a novel dual graph complementary network (DGCN) to learn representation complementarily. We use two different branches, and inputs of the two branches are the same, which are composed of structure and feature information. At the same time, there is also a complementary relationship between the two branches. Beyond that, our extensive experiments show that DGCN outperforms state-of-the-art methods on five public benchmark datasets.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "liu|dual_graph_complementary_network", "supplementary_material": "/attachment/a4cc38571664aa9f6c008cb1772d15eb77acc5d8.zip", "pdf": "/pdf/49cbb83bfb8130ff924168fcbc9f67087543b947.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=TMGnOcS7OT", "_bibtex": "@misc{\nliu2021dual,\ntitle={Dual Graph Complementary Network},\nauthor={Chenhua Liu and Kun Zhan},\nyear={2021},\nurl={https://openreview.net/forum?id=yN5kwvn4E1R}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "yN5kwvn4E1R", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper155/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper155/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper155/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper155/Authors|ICLR.cc/2021/Conference/Paper155/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper155/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923874036, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper155/-/Official_Comment"}}}, {"id": "8sriY-EOBYD", "original": null, "number": 1, "cdate": 1603596020448, "ddate": null, "tcdate": 1603596020448, "tmdate": 1605024752145, "tddate": null, "forum": "yN5kwvn4E1R", "replyto": "yN5kwvn4E1R", "invitation": "ICLR.cc/2021/Conference/Paper155/-/Official_Review", "content": {"title": "Heuristic idea without much insight, unfair evaluation ", "review": "This work proposes a new method by combining GCN and GAT to perform node semi-supervised classification task. The new model uses node features to build another graph, uses GCN and GAT on the original graph and the new graph, and also adds a loss term to reduce the similarity of the final node representations.  \n\n1. The idea is very heuristic without much insight. The paper keeps arguing traditional GNNs only use one-side information, but they are actually leverage both node features and graph structures by propagating nodes features over the graph structure. So the statement is not correct. The paper claims that different node attributes contribute in different ways that should be sufficiently leveraged, but this is a very confusing argument if not paired with empirical justification. In the proposed model, it seems the authors try to resolve the above confusing issue via using another graph structure built only based on only node attributes. There is very unclear connection showing why this method resolves the problem they proposed. \n\n2. The experiment parts are not in a fair comparison too, as the paper does not use the standard way to perform dataset splitting. For this new splitting way, no hyperparameters are report for both the model here and previous models. Some benchmark datasets for semi-supervise learning are also not used, e.g., cora, pubmed,... \n\n3. There are quite a few errors in grammar. I suggest authors to perform some grammar checking. ", "rating": "3: Clear rejection", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}, "signatures": ["ICLR.cc/2021/Conference/Paper155/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper155/AnonReviewer2"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Dual Graph Complementary Network", "authorids": ["liuchh20@lzu.edu.cn", "~Kun_Zhan1"], "authors": ["Chenhua Liu", "Kun Zhan"], "keywords": [], "abstract": "As a powerful representation learning method on graph data, graph neural networks (GNNs) have shown great popularity in tackling graph analytic problems. Although many attempts have been made in literatures to find strategies about extracting better embedding of the target nodes, few of them consider this issue from a comprehensive perspective. Most of current GNNs usually employ some single method which can commendably extract a certain kind of feature but some equally important features are often ignored. In this paper, we develop a novel dual graph complementary network (DGCN) to learn representation complementarily. We use two different branches, and inputs of the two branches are the same, which are composed of structure and feature information. At the same time, there is also a complementary relationship between the two branches. Beyond that, our extensive experiments show that DGCN outperforms state-of-the-art methods on five public benchmark datasets.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "liu|dual_graph_complementary_network", "supplementary_material": "/attachment/a4cc38571664aa9f6c008cb1772d15eb77acc5d8.zip", "pdf": "/pdf/49cbb83bfb8130ff924168fcbc9f67087543b947.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=TMGnOcS7OT", "_bibtex": "@misc{\nliu2021dual,\ntitle={Dual Graph Complementary Network},\nauthor={Chenhua Liu and Kun Zhan},\nyear={2021},\nurl={https://openreview.net/forum?id=yN5kwvn4E1R}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq . ***Please remember to file the Code-of-Ethics report. Once you submitted the review, a link to the report will be visible in the bottom right corner of your review.***", "required": true, "markdown": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}, "forum": "yN5kwvn4E1R", "replyto": "yN5kwvn4E1R", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"], "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper155/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1607428800000, "duedate": 1606752000000, "multiReply": false, "readers": ["everyone"], "tcdate": 1602538149228, "tmdate": 1606915800324, "super": "ICLR.cc/2021/Conference/-/Official_Review", "signatures": ["OpenReview.net"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Paper155/Reviewers", "OpenReview.net/Support"], "id": "ICLR.cc/2021/Conference/Paper155/-/Official_Review"}}}, {"id": "VAK0BPiSBO", "original": null, "number": 3, "cdate": 1603729935527, "ddate": null, "tcdate": 1603729935527, "tmdate": 1605024752083, "tddate": null, "forum": "yN5kwvn4E1R", "replyto": "yN5kwvn4E1R", "invitation": "ICLR.cc/2021/Conference/Paper155/-/Official_Review", "content": {"title": "Official review", "review": "This paper presents a dual complementary network framework for graph representation learning. Two graphs representing topology and features respectively are first constructed. Then, two branches leveraging the two graphs are proposed to explore different aspects of the original graph. Finally, a diversity loss is presented to capture the rich information of node features.\nTo me, the overall presentation is barely satisfactory, with many proposals not well-motivated. Also, the novelty is limited given the large body of existing work on exploring dual aspects of graphs. Moreover, the experiments are not convincing.\n\nDetailed comments:\n* The reason why two branches of GConv nets are used is not clear. I am especially not clear how the proposed DGCN differs from dual-channeled GAT, why the diversity loss is not employed on attention heads, and how does the embedding learnt by GCN supplement the information of that by GAT. More elaborations are needed.\n* Experiments are not convincing; the result analysis of this paper is rather superficial.\n  * Since DGCN uses two branches of GConv nets, large-scale datasets are necessary to evaluate the performance and efficiency.\n  * Inconsistency between GCN and kNN-GCN. It seems that on UAI2010, BlogCatelog, and Flickr kNN-GCN is significantly better than GCN, but the opposite holds for the other two datasets. It should be noted why the two methods show such different performance on different datasets.\n* Given the large amount of existing literature regarding dual networks, many related methods are missing. The authors should especially pay attention to network embedding techniques, e.g., [1].\n\nMinor:\n* Mathematical expressions are in chaotic forms, which makes the readability poor.\n* Page 5: CDAN -> DGCN?\n\n[1]\tZ. Meng, S. Liang, H. Bao, and X. Zhang, Co-Embedding Attributed Networks, in WSDM, 2019, pp. 393\u2013401.", "rating": "2: Strong rejection", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["ICLR.cc/2021/Conference/Paper155/AnonReviewer4"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper155/AnonReviewer4"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Dual Graph Complementary Network", "authorids": ["liuchh20@lzu.edu.cn", "~Kun_Zhan1"], "authors": ["Chenhua Liu", "Kun Zhan"], "keywords": [], "abstract": "As a powerful representation learning method on graph data, graph neural networks (GNNs) have shown great popularity in tackling graph analytic problems. Although many attempts have been made in literatures to find strategies about extracting better embedding of the target nodes, few of them consider this issue from a comprehensive perspective. Most of current GNNs usually employ some single method which can commendably extract a certain kind of feature but some equally important features are often ignored. In this paper, we develop a novel dual graph complementary network (DGCN) to learn representation complementarily. We use two different branches, and inputs of the two branches are the same, which are composed of structure and feature information. At the same time, there is also a complementary relationship between the two branches. Beyond that, our extensive experiments show that DGCN outperforms state-of-the-art methods on five public benchmark datasets.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "liu|dual_graph_complementary_network", "supplementary_material": "/attachment/a4cc38571664aa9f6c008cb1772d15eb77acc5d8.zip", "pdf": "/pdf/49cbb83bfb8130ff924168fcbc9f67087543b947.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=TMGnOcS7OT", "_bibtex": "@misc{\nliu2021dual,\ntitle={Dual Graph Complementary Network},\nauthor={Chenhua Liu and Kun Zhan},\nyear={2021},\nurl={https://openreview.net/forum?id=yN5kwvn4E1R}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq . ***Please remember to file the Code-of-Ethics report. Once you submitted the review, a link to the report will be visible in the bottom right corner of your review.***", "required": true, "markdown": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}, "forum": "yN5kwvn4E1R", "replyto": "yN5kwvn4E1R", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"], "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper155/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1607428800000, "duedate": 1606752000000, "multiReply": false, "readers": ["everyone"], "tcdate": 1602538149228, "tmdate": 1606915800324, "super": "ICLR.cc/2021/Conference/-/Official_Review", "signatures": ["OpenReview.net"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Paper155/Reviewers", "OpenReview.net/Support"], "id": "ICLR.cc/2021/Conference/Paper155/-/Official_Review"}}}, {"id": "oQg1LB0ppPk", "original": null, "number": 4, "cdate": 1603811546905, "ddate": null, "tcdate": 1603811546905, "tmdate": 1605024752021, "tddate": null, "forum": "yN5kwvn4E1R", "replyto": "yN5kwvn4E1R", "invitation": "ICLR.cc/2021/Conference/Paper155/-/Official_Review", "content": {"title": "This paper introduces a method that combines GCN and GAT to extract features from two views of each graph for semi-supervised classification. The framework makes sense in terms of learning comprehensive features, but the method is an incremental and straightforward development on existing methods.", "review": "This paper introduces a method on semi-supervised graph classification. For each graph, the method first constructs another view based on the cosine similarity between nodes' features, and from the two views (topology and feature similarity), GCN and GAT are applied to extract representations. All node representations are further combined via two layers of attentions. A diversity loss that encourages dissimilarity between the learned representations of GCN and GAT is introduced to the cross-entropy loss for joint optimization. The whole framework makes sense in terms of learning meaningful node representations for classification. However, the method lacks novelty, it is an incremental development on the existing graph neural networks. The choice of GCN and GAT as the building blocks are not well justified. It is also possible to try other kinds of GNNs. The statement on GAT \"ignores the inherent structure of the graph space\" on page 4 is confusing since it learns weights based on the graph structures. The experimental results show the better performance of the proposed method, but are not well analyzed. It may be better to compare with other multi-graph methods such as\nYu Shi, Fangqiu Han, Xinwei He, Xinran He, Carl Yang, Jie Luo, and Jiawei Han. \"mvn2vec: Preservation and collaboration in multi-view network embedding.\" arXiv preprint arXiv:1801.06597 (2018).\nAlso, it seems AM-GCN in the experiments also works on multi-view of graphs. The superiority of the proposed method compared to AM-GCN is not clearly described in the paper.\n", "rating": "4: Ok but not good enough - rejection", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}, "signatures": ["ICLR.cc/2021/Conference/Paper155/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper155/AnonReviewer3"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Dual Graph Complementary Network", "authorids": ["liuchh20@lzu.edu.cn", "~Kun_Zhan1"], "authors": ["Chenhua Liu", "Kun Zhan"], "keywords": [], "abstract": "As a powerful representation learning method on graph data, graph neural networks (GNNs) have shown great popularity in tackling graph analytic problems. Although many attempts have been made in literatures to find strategies about extracting better embedding of the target nodes, few of them consider this issue from a comprehensive perspective. Most of current GNNs usually employ some single method which can commendably extract a certain kind of feature but some equally important features are often ignored. In this paper, we develop a novel dual graph complementary network (DGCN) to learn representation complementarily. We use two different branches, and inputs of the two branches are the same, which are composed of structure and feature information. At the same time, there is also a complementary relationship between the two branches. Beyond that, our extensive experiments show that DGCN outperforms state-of-the-art methods on five public benchmark datasets.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "liu|dual_graph_complementary_network", "supplementary_material": "/attachment/a4cc38571664aa9f6c008cb1772d15eb77acc5d8.zip", "pdf": "/pdf/49cbb83bfb8130ff924168fcbc9f67087543b947.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=TMGnOcS7OT", "_bibtex": "@misc{\nliu2021dual,\ntitle={Dual Graph Complementary Network},\nauthor={Chenhua Liu and Kun Zhan},\nyear={2021},\nurl={https://openreview.net/forum?id=yN5kwvn4E1R}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq . ***Please remember to file the Code-of-Ethics report. Once you submitted the review, a link to the report will be visible in the bottom right corner of your review.***", "required": true, "markdown": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}, "forum": "yN5kwvn4E1R", "replyto": "yN5kwvn4E1R", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"], "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper155/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1607428800000, "duedate": 1606752000000, "multiReply": false, "readers": ["everyone"], "tcdate": 1602538149228, "tmdate": 1606915800324, "super": "ICLR.cc/2021/Conference/-/Official_Review", "signatures": ["OpenReview.net"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Paper155/Reviewers", "OpenReview.net/Support"], "id": "ICLR.cc/2021/Conference/Paper155/-/Official_Review"}}}, {"id": "x8wVahzvXdE", "original": null, "number": 2, "cdate": 1603726402116, "ddate": null, "tcdate": 1603726402116, "tmdate": 1605024751962, "tddate": null, "forum": "yN5kwvn4E1R", "replyto": "yN5kwvn4E1R", "invitation": "ICLR.cc/2021/Conference/Paper155/-/Official_Review", "content": {"title": "The work is incremental and straightforward", "review": "The paper presents a GNN model to jointly encode both topology and feature graphs to enhance node representations' quality. In particular, the model DGCN uses two GCNs to learn and propagate two different types of node representations on the topology graph, respectively. The model also utilizes two GATs to learn and propagate two different types of node representations on the feature graph, respectively. Finally, the model leverages attention mechanisms on these four types of node representations to produce the final node embeddings.\n\nPros: \n+ The model obtains promising results.\n\nCons:\n\n+ The motivation in the second paragraph of the introduction makes confusion. The quote sentence - \"Most of the traditional GNNs only consider the single connection between nodes and ignore other implicit information\" - leads to why not considering multiple connections between nodes as there are GNN works on hyper-graphs such as [2].\n+ The intuition in the third paragraph of the introduction is not clear as the paper does not have any ablation study for this intuition. \n\"Network performance is largely related to the quality of the graph, which usually emphasizes the relevance of an attribute of instances\", so which references for this intuition? What are the attributes of instances?\n+ Using v=1 for A_1 to denote the topology graph and v = 2 for A_2 to denote the feature graph makes the paper harder to read.\n+ The paper is not well written as it does not include any descriptions about model parameters in both the paper and the supplementary material. So it's hard to understand how to train DGCN and the baselines and how to analyze the model and ablation studies.\n+ The most important one is that, regarding the model architecture, DGCN is precisely similar to AM-GCN. In particular, DGCN changes from using two GCNs for the feature graph in AM-GCN [1] to using two GATs. Therefore, DGCN is straightforward and incremental (i.e., lacking novelty).\n\n[1] AM-GCN: Adaptive Multi-channel Graph Convolutional Networks. KDD 2020.\n\n[2] Hyper-SAGNN: a self-attention based graph neural network for hypergraphs. ICLR 2020.\n", "rating": "4: Ok but not good enough - rejection", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}, "signatures": ["ICLR.cc/2021/Conference/Paper155/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper155/AnonReviewer1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Dual Graph Complementary Network", "authorids": ["liuchh20@lzu.edu.cn", "~Kun_Zhan1"], "authors": ["Chenhua Liu", "Kun Zhan"], "keywords": [], "abstract": "As a powerful representation learning method on graph data, graph neural networks (GNNs) have shown great popularity in tackling graph analytic problems. Although many attempts have been made in literatures to find strategies about extracting better embedding of the target nodes, few of them consider this issue from a comprehensive perspective. Most of current GNNs usually employ some single method which can commendably extract a certain kind of feature but some equally important features are often ignored. In this paper, we develop a novel dual graph complementary network (DGCN) to learn representation complementarily. We use two different branches, and inputs of the two branches are the same, which are composed of structure and feature information. At the same time, there is also a complementary relationship between the two branches. Beyond that, our extensive experiments show that DGCN outperforms state-of-the-art methods on five public benchmark datasets.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "liu|dual_graph_complementary_network", "supplementary_material": "/attachment/a4cc38571664aa9f6c008cb1772d15eb77acc5d8.zip", "pdf": "/pdf/49cbb83bfb8130ff924168fcbc9f67087543b947.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=TMGnOcS7OT", "_bibtex": "@misc{\nliu2021dual,\ntitle={Dual Graph Complementary Network},\nauthor={Chenhua Liu and Kun Zhan},\nyear={2021},\nurl={https://openreview.net/forum?id=yN5kwvn4E1R}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq . ***Please remember to file the Code-of-Ethics report. Once you submitted the review, a link to the report will be visible in the bottom right corner of your review.***", "required": true, "markdown": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}, "forum": "yN5kwvn4E1R", "replyto": "yN5kwvn4E1R", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"], "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper155/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1607428800000, "duedate": 1606752000000, "multiReply": false, "readers": ["everyone"], "tcdate": 1602538149228, "tmdate": 1606915800324, "super": "ICLR.cc/2021/Conference/-/Official_Review", "signatures": ["OpenReview.net"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Paper155/Reviewers", "OpenReview.net/Support"], "id": "ICLR.cc/2021/Conference/Paper155/-/Official_Review"}}}], "count": 10}