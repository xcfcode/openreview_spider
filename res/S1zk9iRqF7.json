{"notes": [{"id": "SyxBS7VDnE", "original": null, "number": 5, "cdate": 1557771069407, "ddate": null, "tcdate": 1557771069407, "tmdate": 1557771069407, "tddate": null, "forum": "S1zk9iRqF7", "replyto": "S1zk9iRqF7", "invitation": "ICLR.cc/2019/Conference/-/Paper498/Public_Comment", "content": {"comment": "Thank you for the great work! \n\nWe are very interested in this work and are working on reproducing the experiments since authors did not open source their code. However, we found that some experiment details are not very clear in the paper. Could you please share the following details about the experiments?\n\n1. What are the structures and hyperparmeters for GAN benchmark? Are they the same as the structures and parameters for DP-GAN (listed in the Appendix)? \n\n2. What are the training epochs for GAN, DP-GAN, and PATE-GAN respectively? \n\n3. What are the hyper-parameters used in the 12 predictive models? Are they all default values in sklearn?\n\n4. Have you resampled the synthetic data to guarantee that \"the label distribution of the generated synthetic datasets are exactly the same as the size of the training datasets\"? If so, is the label distribution of the private dataset assumed to be public information? \n\n", "title": "Sharing hyper-parameters for reproducing the experiments"}, "signatures": ["~Yunhui_Long1"], "readers": ["everyone"], "nonreaders": [], "writers": ["~Yunhui_Long1", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "PATE-GAN: Generating Synthetic Data with Differential Privacy Guarantees", "abstract": "Machine learning has the potential to assist many communities in using the large datasets that are becoming more and more available. Unfortunately, much of that potential is not being realized because it would require sharing data in a way that compromises privacy. In this paper, we investigate a method for ensuring (differential) privacy of the generator of the Generative Adversarial Nets (GAN) framework. The resulting model can be used for generating synthetic data on which algorithms can be trained and validated, and on which competitions can be conducted, without compromising the privacy of the original dataset. Our method modifies the Private Aggregation of Teacher Ensembles (PATE) framework and applies it to GANs. Our modified framework (which we call PATE-GAN) allows us to tightly bound the influence of any individual sample on the model, resulting in tight differential privacy guarantees and thus an improved performance over models with the same guarantees. We also look at measuring the quality of synthetic data from a new angle; we assert that for the synthetic data to be useful for machine learning researchers, the relative performance of two algorithms (trained and tested) on the synthetic dataset should be the same as their relative performance (when trained and tested) on the original dataset. Our experiments, on various datasets, demonstrate that PATE-GAN consistently outperforms the state-of-the-art method with respect to this and other notions of synthetic data quality.", "keywords": ["Synthetic data generation", "Differential privacy", "Generative adversarial networks", "Private Aggregation of Teacher ensembles"], "authorids": ["james.jordon@wolfson.ox.ac.uk", "jsyoon0823@gmail.com", "mihaela.vanderschaar@eng.ox.ac.uk"], "authors": ["James Jordon", "Jinsung Yoon", "Mihaela van der Schaar"], "pdf": "/pdf/9bef793ee88e366d6fb82472f8bb87690c8cf96f.pdf", "paperhash": "jordon|pategan_generating_synthetic_data_with_differential_privacy_guarantees", "_bibtex": "@inproceedings{\nyoon2018pategan,\ntitle={{PATE}-{GAN}: Generating Synthetic Data with Differential Privacy Guarantees},\nauthor={Jinsung Yoon and James Jordon and Mihaela van der Schaar},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=S1zk9iRqF7},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper498/Public_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1542311826283, "tddate": null, "super": null, "final": null, "reply": {"signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed."}, "nonreaders": {"values": []}, "forum": "S1zk9iRqF7", "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper498/Authors", "ICLR.cc/2019/Conference/Paper498/Reviewers", "ICLR.cc/2019/Conference/Paper498/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "replyto": null, "content": {"comment": {"value-regex": "[\\S\\s]{1,5000}", "required": true, "order": 1, "description": "Your comment or reply (max 5000 characters)."}, "title": {"value-regex": ".{1,500}", "required": true, "order": 0, "description": "Brief summary of your comment."}}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["~"], "noninvitees": ["ICLR.cc/2019/Conference/Paper498/Authors", "ICLR.cc/2019/Conference/Paper498/Reviewers", "ICLR.cc/2019/Conference/Paper498/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1542311826283}}}, {"id": "S1zk9iRqF7", "original": "BJeVxRbKFm", "number": 498, "cdate": 1538087814955, "ddate": null, "tcdate": 1538087814955, "tmdate": 1549659169317, "tddate": null, "forum": "S1zk9iRqF7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "PATE-GAN: Generating Synthetic Data with Differential Privacy Guarantees", "abstract": "Machine learning has the potential to assist many communities in using the large datasets that are becoming more and more available. Unfortunately, much of that potential is not being realized because it would require sharing data in a way that compromises privacy. In this paper, we investigate a method for ensuring (differential) privacy of the generator of the Generative Adversarial Nets (GAN) framework. The resulting model can be used for generating synthetic data on which algorithms can be trained and validated, and on which competitions can be conducted, without compromising the privacy of the original dataset. Our method modifies the Private Aggregation of Teacher Ensembles (PATE) framework and applies it to GANs. Our modified framework (which we call PATE-GAN) allows us to tightly bound the influence of any individual sample on the model, resulting in tight differential privacy guarantees and thus an improved performance over models with the same guarantees. We also look at measuring the quality of synthetic data from a new angle; we assert that for the synthetic data to be useful for machine learning researchers, the relative performance of two algorithms (trained and tested) on the synthetic dataset should be the same as their relative performance (when trained and tested) on the original dataset. Our experiments, on various datasets, demonstrate that PATE-GAN consistently outperforms the state-of-the-art method with respect to this and other notions of synthetic data quality.", "keywords": ["Synthetic data generation", "Differential privacy", "Generative adversarial networks", "Private Aggregation of Teacher ensembles"], "authorids": ["james.jordon@wolfson.ox.ac.uk", "jsyoon0823@gmail.com", "mihaela.vanderschaar@eng.ox.ac.uk"], "authors": ["James Jordon", "Jinsung Yoon", "Mihaela van der Schaar"], "pdf": "/pdf/9bef793ee88e366d6fb82472f8bb87690c8cf96f.pdf", "paperhash": "jordon|pategan_generating_synthetic_data_with_differential_privacy_guarantees", "_bibtex": "@inproceedings{\nyoon2018pategan,\ntitle={{PATE}-{GAN}: Generating Synthetic Data with Differential Privacy Guarantees},\nauthor={Jinsung Yoon and James Jordon and Mihaela van der Schaar},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=S1zk9iRqF7},\n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"replyCount": 16, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Blind_Submission", "rdate": null, "ddate": null, "expdate": null, "duedate": 1538085600000, "tmdate": 1538142958393, "tddate": null, "super": null, "final": null, "reply": {"signatures": {"values": ["ICLR.cc/2019/Conference"]}, "forum": null, "readers": {"values": ["everyone"]}, "replyto": null, "content": {"authorids": {"values-regex": ".*"}, "authors": {"values": ["Anonymous"]}}, "writers": {"values": ["ICLR.cc/2019/Conference"]}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["~"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": null, "taskCompletionCount": null, "transform": null, "cdate": 1538142958393}}, "tauthor": "OpenReview.net"}, {"id": "HyeEw79Vl4", "original": null, "number": 1, "cdate": 1545016155605, "ddate": null, "tcdate": 1545016155605, "tmdate": 1545354485892, "tddate": null, "forum": "S1zk9iRqF7", "replyto": "S1zk9iRqF7", "invitation": "ICLR.cc/2019/Conference/-/Paper498/Meta_Review", "content": {"metareview": "This paper improves upon the PATE-GAN framework for differentially-private synthetic data generation. They eliminate the need for public data samples for training the GAN, by providing a distribution which can be sampled from instead.\n\nThe authors were unanimous in their vote to accept.", "confidence": "4: The area chair is confident but not absolutely certain", "recommendation": "Accept (Poster)", "title": "Advances in differentially-private data generation"}, "signatures": ["ICLR.cc/2019/Conference/Paper498/Area_Chair1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference/Paper498/Area_Chair1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "PATE-GAN: Generating Synthetic Data with Differential Privacy Guarantees", "abstract": "Machine learning has the potential to assist many communities in using the large datasets that are becoming more and more available. Unfortunately, much of that potential is not being realized because it would require sharing data in a way that compromises privacy. In this paper, we investigate a method for ensuring (differential) privacy of the generator of the Generative Adversarial Nets (GAN) framework. The resulting model can be used for generating synthetic data on which algorithms can be trained and validated, and on which competitions can be conducted, without compromising the privacy of the original dataset. Our method modifies the Private Aggregation of Teacher Ensembles (PATE) framework and applies it to GANs. Our modified framework (which we call PATE-GAN) allows us to tightly bound the influence of any individual sample on the model, resulting in tight differential privacy guarantees and thus an improved performance over models with the same guarantees. We also look at measuring the quality of synthetic data from a new angle; we assert that for the synthetic data to be useful for machine learning researchers, the relative performance of two algorithms (trained and tested) on the synthetic dataset should be the same as their relative performance (when trained and tested) on the original dataset. Our experiments, on various datasets, demonstrate that PATE-GAN consistently outperforms the state-of-the-art method with respect to this and other notions of synthetic data quality.", "keywords": ["Synthetic data generation", "Differential privacy", "Generative adversarial networks", "Private Aggregation of Teacher ensembles"], "authorids": ["james.jordon@wolfson.ox.ac.uk", "jsyoon0823@gmail.com", "mihaela.vanderschaar@eng.ox.ac.uk"], "authors": ["James Jordon", "Jinsung Yoon", "Mihaela van der Schaar"], "pdf": "/pdf/9bef793ee88e366d6fb82472f8bb87690c8cf96f.pdf", "paperhash": "jordon|pategan_generating_synthetic_data_with_differential_privacy_guarantees", "_bibtex": "@inproceedings{\nyoon2018pategan,\ntitle={{PATE}-{GAN}: Generating Synthetic Data with Differential Privacy Guarantees},\nauthor={Jinsung Yoon and James Jordon and Mihaela van der Schaar},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=S1zk9iRqF7},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper498/Meta_Review", "rdate": null, "ddate": null, "expdate": null, "duedate": 1541548800000, "tmdate": 1545353194678, "tddate": null, "super": null, "final": null, "reply": {"forum": "S1zk9iRqF7", "replyto": "S1zk9iRqF7", "readers": {"description": "Select all user groups that should be able to read this comment. Selecting 'All Users' will allow paper authors, reviewers, area chairs, and program chairs to view this comment.", "values": ["everyone"]}, "signatures": {"description": "How your identity will be displayed with the above content.", "values-regex": "ICLR.cc/2019/Conference/Paper498/Area_Chair[0-9]+"}, "writers": {"description": "Users that may modify this record.", "values-regex": "ICLR.cc/2019/Conference/Paper498/Area_Chair[0-9]+"}, "content": {"title": {"order": 1, "value-regex": ".{1,500}", "description": "Brief summary of your review.", "required": true}, "metareview": {"order": 2, "value-regex": "[\\S\\s]{1,5000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "required": true}, "recommendation": {"order": 3, "value-dropdown": ["Accept (Oral)", "Accept (Poster)", "Reject"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The area chair is absolutely certain", "4: The area chair is confident but not absolutely certain", "3: The area chair is somewhat confident", "2: The area chair is not sure", "1: The area chair's evaluation is an educated guess"], "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper498/Area_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": false, "taskCompletionCount": null, "transform": null, "cdate": 1545353194678}}}, {"id": "ryxVTXd62X", "original": null, "number": 2, "cdate": 1541403580047, "ddate": null, "tcdate": 1541403580047, "tmdate": 1543300153768, "tddate": null, "forum": "S1zk9iRqF7", "replyto": "S1zk9iRqF7", "invitation": "ICLR.cc/2019/Conference/-/Paper498/Official_Review", "content": {"title": "Need improvement", "review": "[Post revision update] The authors' comments addressed my concerns, especially on the experiment side. I changed the score.\n\nThis paper applies the PATE framework to GAN, and evaluates the quality of the generated data with some predictive tasks. The experimental results on some real datasets show that the proposed algorithm outperforms DPGAN, and the generated synthetic data is quite useful in comparison with real data.\nThe presentation is clear and easy to follow. However, I think the paper needs to be improved in its novelty, and the techniques and experiments need to be more thorough.\n\nMore details:\n- It might be necessary to consider using Gaussian noise[24] in replace of the Laplace noise, which, according to [24], would improve privacy and accuracy.\n- This paper:\n\u201cPrivacy-preserving generative deep neural networks support clinical data sharing\u201d by Brett K. Beaulieu-Jones, Zhiwei Steven Wu, Chris Williams, Casey S. Greene\nseems quite relevant. If so, you may want to add some discussion in the related work section or compare with their result.\n- The last paragraph of the related works section mentioned some related work with shortcomings as working only on low-dimensional data and features of specific types, yet the experiments are also mostly done on low-dimensional datasets. I think it would be better to do a thorough evaluation on data of different kinds, such as image data. \n- If the two evaluation metrics for private GAN is considered an important contribution of the paper, it might be better to make it a separate section and elaborate more on the motivation and method.  \n- It might be better to move some details (for example, instead of presenting the results of the 12 predictive models, presenting only the average, as it\u2019s not very important how each of them performs) of the credit card fraud detection dataset to the appendix and bring the results of the other datasets to the main body. \n", "rating": "6: Marginally above acceptance threshold", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["ICLR.cc/2019/Conference/Paper498/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": true, "forumContent": {"title": "PATE-GAN: Generating Synthetic Data with Differential Privacy Guarantees", "abstract": "Machine learning has the potential to assist many communities in using the large datasets that are becoming more and more available. Unfortunately, much of that potential is not being realized because it would require sharing data in a way that compromises privacy. In this paper, we investigate a method for ensuring (differential) privacy of the generator of the Generative Adversarial Nets (GAN) framework. The resulting model can be used for generating synthetic data on which algorithms can be trained and validated, and on which competitions can be conducted, without compromising the privacy of the original dataset. Our method modifies the Private Aggregation of Teacher Ensembles (PATE) framework and applies it to GANs. Our modified framework (which we call PATE-GAN) allows us to tightly bound the influence of any individual sample on the model, resulting in tight differential privacy guarantees and thus an improved performance over models with the same guarantees. We also look at measuring the quality of synthetic data from a new angle; we assert that for the synthetic data to be useful for machine learning researchers, the relative performance of two algorithms (trained and tested) on the synthetic dataset should be the same as their relative performance (when trained and tested) on the original dataset. Our experiments, on various datasets, demonstrate that PATE-GAN consistently outperforms the state-of-the-art method with respect to this and other notions of synthetic data quality.", "keywords": ["Synthetic data generation", "Differential privacy", "Generative adversarial networks", "Private Aggregation of Teacher ensembles"], "authorids": ["james.jordon@wolfson.ox.ac.uk", "jsyoon0823@gmail.com", "mihaela.vanderschaar@eng.ox.ac.uk"], "authors": ["James Jordon", "Jinsung Yoon", "Mihaela van der Schaar"], "pdf": "/pdf/9bef793ee88e366d6fb82472f8bb87690c8cf96f.pdf", "paperhash": "jordon|pategan_generating_synthetic_data_with_differential_privacy_guarantees", "_bibtex": "@inproceedings{\nyoon2018pategan,\ntitle={{PATE}-{GAN}: Generating Synthetic Data with Differential Privacy Guarantees},\nauthor={Jinsung Yoon and James Jordon and Mihaela van der Schaar},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=S1zk9iRqF7},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper498/Official_Review", "cdate": 1542234447583, "expdate": 1552335264000, "duedate": 1541196000000, "reply": {"forum": "S1zk9iRqF7", "replyto": "S1zk9iRqF7", "readers": {"description": "The users who will be allowed to read the reply content.", "values": ["everyone"]}, "nonreaders": {"values": []}, "signatures": {"description": "How your identity will be displayed with the above content.", "values-regex": "ICLR.cc/2019/Conference/Paper498/AnonReviewer[0-9]+"}, "writers": {"description": "Users that may modify this record.", "values": ["ICLR.cc/2019/Conference"]}, "content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "required": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}}, "multiReply": false, "tcdate": 1552335737924, "tmdate": 1552335737924, "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "invitees": ["ICLR.cc/2019/Conference/Paper498/Reviewers"], "noninvitees": [], "signatures": ["ICLR.cc/2019/Conference"]}}}, {"id": "r1g49cO_CX", "original": null, "number": 7, "cdate": 1543174795711, "ddate": null, "tcdate": 1543174795711, "tmdate": 1543174795711, "tddate": null, "forum": "S1zk9iRqF7", "replyto": "B1x60Mr0aQ", "invitation": "ICLR.cc/2019/Conference/-/Paper498/Official_Comment", "content": {"title": "RE: Surprising differences in Kaggle Credit", "comment": "\nAnswer: Note that the Kaggle Credit dataset is highly unbalanced (only 0.2% are positive labels). Therefore, AUPRC can be highly variable in this setting. "}, "signatures": ["ICLR.cc/2019/Conference/Paper498/Authors"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper498/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper498/Authors", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "PATE-GAN: Generating Synthetic Data with Differential Privacy Guarantees", "abstract": "Machine learning has the potential to assist many communities in using the large datasets that are becoming more and more available. Unfortunately, much of that potential is not being realized because it would require sharing data in a way that compromises privacy. In this paper, we investigate a method for ensuring (differential) privacy of the generator of the Generative Adversarial Nets (GAN) framework. The resulting model can be used for generating synthetic data on which algorithms can be trained and validated, and on which competitions can be conducted, without compromising the privacy of the original dataset. Our method modifies the Private Aggregation of Teacher Ensembles (PATE) framework and applies it to GANs. Our modified framework (which we call PATE-GAN) allows us to tightly bound the influence of any individual sample on the model, resulting in tight differential privacy guarantees and thus an improved performance over models with the same guarantees. We also look at measuring the quality of synthetic data from a new angle; we assert that for the synthetic data to be useful for machine learning researchers, the relative performance of two algorithms (trained and tested) on the synthetic dataset should be the same as their relative performance (when trained and tested) on the original dataset. Our experiments, on various datasets, demonstrate that PATE-GAN consistently outperforms the state-of-the-art method with respect to this and other notions of synthetic data quality.", "keywords": ["Synthetic data generation", "Differential privacy", "Generative adversarial networks", "Private Aggregation of Teacher ensembles"], "authorids": ["james.jordon@wolfson.ox.ac.uk", "jsyoon0823@gmail.com", "mihaela.vanderschaar@eng.ox.ac.uk"], "authors": ["James Jordon", "Jinsung Yoon", "Mihaela van der Schaar"], "pdf": "/pdf/9bef793ee88e366d6fb82472f8bb87690c8cf96f.pdf", "paperhash": "jordon|pategan_generating_synthetic_data_with_differential_privacy_guarantees", "_bibtex": "@inproceedings{\nyoon2018pategan,\ntitle={{PATE}-{GAN}: Generating Synthetic Data with Differential Privacy Guarantees},\nauthor={Jinsung Yoon and James Jordon and Mihaela van der Schaar},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=S1zk9iRqF7},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper498/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621612843, "tddate": null, "super": null, "final": null, "reply": {"forum": "S1zk9iRqF7", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper498/Authors", "ICLR.cc/2019/Conference/Paper498/Reviewers", "ICLR.cc/2019/Conference/Paper498/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper498/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper498/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper498/Authors|ICLR.cc/2019/Conference/Paper498/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper498/Reviewers", "ICLR.cc/2019/Conference/Paper498/Authors", "ICLR.cc/2019/Conference/Paper498/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621612843}}}, {"id": "B1glPc_dRQ", "original": null, "number": 6, "cdate": 1543174744398, "ddate": null, "tcdate": 1543174744398, "tmdate": 1543174765356, "tddate": null, "forum": "S1zk9iRqF7", "replyto": "S1gY5Z8saQ", "invitation": "ICLR.cc/2019/Conference/-/Paper498/Official_Comment", "content": {"title": "RE: Further concerns", "comment": "\nA1: In high-dimensional settings (such as in the UCI ISOLET dataset), the performance of DPGAN with (epsilon, delta) = (1,10^-5) is in fact close to random guessing (AUROC < 0.6). Our task in the datasets we perform experiments on is binary classification, and therefore aligns with the DPGAN two-digit classification (rather than all 10 generated digits). Again, we feel our results for DPGAN are consistent with the findings in DPGAN.\n\nA2: We have provided results for epsilon=1 (with delta = 10^-5) for both UCI ISOLET dataset and UCI Epileptic Seizure Recognition dataset in the revised manuscript.\n\nA3 & A4: Okay. \n\nA5: We feel that visual results would be qualitative at best, and do not allow for a meaningful comparison between methods. By using quantitative measure of performance we are able to directly, and fairly, compare PATEGAN and DPGAN."}, "signatures": ["ICLR.cc/2019/Conference/Paper498/Authors"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper498/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper498/Authors", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "PATE-GAN: Generating Synthetic Data with Differential Privacy Guarantees", "abstract": "Machine learning has the potential to assist many communities in using the large datasets that are becoming more and more available. Unfortunately, much of that potential is not being realized because it would require sharing data in a way that compromises privacy. In this paper, we investigate a method for ensuring (differential) privacy of the generator of the Generative Adversarial Nets (GAN) framework. The resulting model can be used for generating synthetic data on which algorithms can be trained and validated, and on which competitions can be conducted, without compromising the privacy of the original dataset. Our method modifies the Private Aggregation of Teacher Ensembles (PATE) framework and applies it to GANs. Our modified framework (which we call PATE-GAN) allows us to tightly bound the influence of any individual sample on the model, resulting in tight differential privacy guarantees and thus an improved performance over models with the same guarantees. We also look at measuring the quality of synthetic data from a new angle; we assert that for the synthetic data to be useful for machine learning researchers, the relative performance of two algorithms (trained and tested) on the synthetic dataset should be the same as their relative performance (when trained and tested) on the original dataset. Our experiments, on various datasets, demonstrate that PATE-GAN consistently outperforms the state-of-the-art method with respect to this and other notions of synthetic data quality.", "keywords": ["Synthetic data generation", "Differential privacy", "Generative adversarial networks", "Private Aggregation of Teacher ensembles"], "authorids": ["james.jordon@wolfson.ox.ac.uk", "jsyoon0823@gmail.com", "mihaela.vanderschaar@eng.ox.ac.uk"], "authors": ["James Jordon", "Jinsung Yoon", "Mihaela van der Schaar"], "pdf": "/pdf/9bef793ee88e366d6fb82472f8bb87690c8cf96f.pdf", "paperhash": "jordon|pategan_generating_synthetic_data_with_differential_privacy_guarantees", "_bibtex": "@inproceedings{\nyoon2018pategan,\ntitle={{PATE}-{GAN}: Generating Synthetic Data with Differential Privacy Guarantees},\nauthor={Jinsung Yoon and James Jordon and Mihaela van der Schaar},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=S1zk9iRqF7},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper498/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621612843, "tddate": null, "super": null, "final": null, "reply": {"forum": "S1zk9iRqF7", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper498/Authors", "ICLR.cc/2019/Conference/Paper498/Reviewers", "ICLR.cc/2019/Conference/Paper498/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper498/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper498/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper498/Authors|ICLR.cc/2019/Conference/Paper498/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper498/Reviewers", "ICLR.cc/2019/Conference/Paper498/Authors", "ICLR.cc/2019/Conference/Paper498/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621612843}}}, {"id": "B1x60Mr0aQ", "original": null, "number": 4, "cdate": 1542505173465, "ddate": null, "tcdate": 1542505173465, "tmdate": 1542505173465, "tddate": null, "forum": "S1zk9iRqF7", "replyto": "Hyg0gt1q6Q", "invitation": "ICLR.cc/2019/Conference/-/Paper498/Public_Comment", "content": {"comment": "Surprisingly the biggest difference is in Kaggle Credit, which is the largest dataset. GAN only achieves 0.3453 AUPR while the original dataset has around 0.7020. Anyway thank you for your great work!", "title": "Surprising differences in Kaggle Credit"}, "signatures": ["~Chun-Hao_Chang1"], "readers": ["everyone"], "nonreaders": [], "writers": ["~Chun-Hao_Chang1", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "PATE-GAN: Generating Synthetic Data with Differential Privacy Guarantees", "abstract": "Machine learning has the potential to assist many communities in using the large datasets that are becoming more and more available. Unfortunately, much of that potential is not being realized because it would require sharing data in a way that compromises privacy. In this paper, we investigate a method for ensuring (differential) privacy of the generator of the Generative Adversarial Nets (GAN) framework. The resulting model can be used for generating synthetic data on which algorithms can be trained and validated, and on which competitions can be conducted, without compromising the privacy of the original dataset. Our method modifies the Private Aggregation of Teacher Ensembles (PATE) framework and applies it to GANs. Our modified framework (which we call PATE-GAN) allows us to tightly bound the influence of any individual sample on the model, resulting in tight differential privacy guarantees and thus an improved performance over models with the same guarantees. We also look at measuring the quality of synthetic data from a new angle; we assert that for the synthetic data to be useful for machine learning researchers, the relative performance of two algorithms (trained and tested) on the synthetic dataset should be the same as their relative performance (when trained and tested) on the original dataset. Our experiments, on various datasets, demonstrate that PATE-GAN consistently outperforms the state-of-the-art method with respect to this and other notions of synthetic data quality.", "keywords": ["Synthetic data generation", "Differential privacy", "Generative adversarial networks", "Private Aggregation of Teacher ensembles"], "authorids": ["james.jordon@wolfson.ox.ac.uk", "jsyoon0823@gmail.com", "mihaela.vanderschaar@eng.ox.ac.uk"], "authors": ["James Jordon", "Jinsung Yoon", "Mihaela van der Schaar"], "pdf": "/pdf/9bef793ee88e366d6fb82472f8bb87690c8cf96f.pdf", "paperhash": "jordon|pategan_generating_synthetic_data_with_differential_privacy_guarantees", "_bibtex": "@inproceedings{\nyoon2018pategan,\ntitle={{PATE}-{GAN}: Generating Synthetic Data with Differential Privacy Guarantees},\nauthor={Jinsung Yoon and James Jordon and Mihaela van der Schaar},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=S1zk9iRqF7},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper498/Public_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1542311826283, "tddate": null, "super": null, "final": null, "reply": {"signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed."}, "nonreaders": {"values": []}, "forum": "S1zk9iRqF7", "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper498/Authors", "ICLR.cc/2019/Conference/Paper498/Reviewers", "ICLR.cc/2019/Conference/Paper498/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "replyto": null, "content": {"comment": {"value-regex": "[\\S\\s]{1,5000}", "required": true, "order": 1, "description": "Your comment or reply (max 5000 characters)."}, "title": {"value-regex": ".{1,500}", "required": true, "order": 0, "description": "Brief summary of your comment."}}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["~"], "noninvitees": ["ICLR.cc/2019/Conference/Paper498/Authors", "ICLR.cc/2019/Conference/Paper498/Reviewers", "ICLR.cc/2019/Conference/Paper498/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1542311826283}}}, {"id": "S1gY5Z8saQ", "original": null, "number": 3, "cdate": 1542312337476, "ddate": null, "tcdate": 1542312337476, "tmdate": 1542312876991, "tddate": null, "forum": "S1zk9iRqF7", "replyto": "r1gKFckcaX", "invitation": "ICLR.cc/2019/Conference/-/Paper498/Public_Comment", "content": {"comment": "I thank the authors for the detailed point-wise response.\n\nA1. \nI see the decline, but it still is within 4-8% of PATE-GAN and the difference surprisingly decreases with lower epsilon with DPGAN maintaining AUROC of >0.6 at the minimum epsilon. I would have expected DPGAN to be closer to random guessing at that point (based on the noise levels required for that level of privacy and DPGAN results from the manuscript). Same is true for Table 2 up to epsilon 0.1. DPGAN figure 3 doesn't really show the full picture. Binary comparison of 0,1; 2,3 and 4,5 is far from covering generator's full domain(more satisfactory would be the classification accuracy on all 10 generated digits in a single model).\n\nA2.\nThank you for providing these results. I am concerned about the epsilon used here (epsilon=10). At this level, differential privacy effectively doesn't provide much of a privacy protection. One can see the significant difference exp(10) makes in distinguishing two answers. Are the results available for epsilon<1?\n\nA3. \nI have followed the source before without any luck and have emailed the authors as well in recent past(author's response was that they don't plan to release the code yet.).\n\nA4.\nI understand, I was referring to the pre-training of student where Supp(P_U), Supp(P_G) is involved.\n\n\nI still do think some visual results will be really helpful at different epsilon values(such as figure 1 in DPSGD).\n\n\n\n\n\n", "title": "Further concerns"}, "signatures": ["~Lovedeep_Gondara1"], "readers": ["everyone"], "nonreaders": [], "writers": ["~Lovedeep_Gondara1", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "PATE-GAN: Generating Synthetic Data with Differential Privacy Guarantees", "abstract": "Machine learning has the potential to assist many communities in using the large datasets that are becoming more and more available. Unfortunately, much of that potential is not being realized because it would require sharing data in a way that compromises privacy. In this paper, we investigate a method for ensuring (differential) privacy of the generator of the Generative Adversarial Nets (GAN) framework. The resulting model can be used for generating synthetic data on which algorithms can be trained and validated, and on which competitions can be conducted, without compromising the privacy of the original dataset. Our method modifies the Private Aggregation of Teacher Ensembles (PATE) framework and applies it to GANs. Our modified framework (which we call PATE-GAN) allows us to tightly bound the influence of any individual sample on the model, resulting in tight differential privacy guarantees and thus an improved performance over models with the same guarantees. We also look at measuring the quality of synthetic data from a new angle; we assert that for the synthetic data to be useful for machine learning researchers, the relative performance of two algorithms (trained and tested) on the synthetic dataset should be the same as their relative performance (when trained and tested) on the original dataset. Our experiments, on various datasets, demonstrate that PATE-GAN consistently outperforms the state-of-the-art method with respect to this and other notions of synthetic data quality.", "keywords": ["Synthetic data generation", "Differential privacy", "Generative adversarial networks", "Private Aggregation of Teacher ensembles"], "authorids": ["james.jordon@wolfson.ox.ac.uk", "jsyoon0823@gmail.com", "mihaela.vanderschaar@eng.ox.ac.uk"], "authors": ["James Jordon", "Jinsung Yoon", "Mihaela van der Schaar"], "pdf": "/pdf/9bef793ee88e366d6fb82472f8bb87690c8cf96f.pdf", "paperhash": "jordon|pategan_generating_synthetic_data_with_differential_privacy_guarantees", "_bibtex": "@inproceedings{\nyoon2018pategan,\ntitle={{PATE}-{GAN}: Generating Synthetic Data with Differential Privacy Guarantees},\nauthor={Jinsung Yoon and James Jordon and Mihaela van der Schaar},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=S1zk9iRqF7},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper498/Public_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1542311826283, "tddate": null, "super": null, "final": null, "reply": {"signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed."}, "nonreaders": {"values": []}, "forum": "S1zk9iRqF7", "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper498/Authors", "ICLR.cc/2019/Conference/Paper498/Reviewers", "ICLR.cc/2019/Conference/Paper498/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "replyto": null, "content": {"comment": {"value-regex": "[\\S\\s]{1,5000}", "required": true, "order": 1, "description": "Your comment or reply (max 5000 characters)."}, "title": {"value-regex": ".{1,500}", "required": true, "order": 0, "description": "Brief summary of your comment."}}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["~"], "noninvitees": ["ICLR.cc/2019/Conference/Paper498/Authors", "ICLR.cc/2019/Conference/Paper498/Reviewers", "ICLR.cc/2019/Conference/Paper498/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1542311826283}}}, {"id": "r1gVLn1qaQ", "original": null, "number": 5, "cdate": 1542220875720, "ddate": null, "tcdate": 1542220875720, "tmdate": 1542220875720, "tddate": null, "forum": "S1zk9iRqF7", "replyto": "HyxXmnTC27", "invitation": "ICLR.cc/2019/Conference/-/Paper498/Official_Comment", "content": {"title": "RE: Add Interesting setup, surprising that it works", "comment": "Thank you for your insightful comments.\n\nA1: We note that the generator need only generate samples that are \u201csomewhat\u201d more realistic than other samples, thus providing the discriminator with some side information about what direction to guide the generator in. We also considered starting the student training using uniformly drawn samples from [0,1]^d and then transitioning to generator-only samples after the generator had a chance to start generating realistic samples but found this to be unnecessary. To further demonstrate this, we have now included results for higher-dimensional data in which it would be harder for the generator to do this \u201cby chance\u201d, and continue to show high performance.\n\nSpecifically, we used two UCI datasets (UCI ISOLET dataset (dimensions: 617, no of samples: 7797, task: classify consonant vs vowel) and UCI Epileptic Seizure Recognition dataset (dimensions: 179, no of samples: 11500, task: classify seizure activity)) and varied the dimensionality to demonstrate the scalability of our method. The results on the full dataset (all 617 features and 179 features) can be seen in the following tables.\n\n(1) UCI ISOLET Dataset\n--------------------------------------------------------------------------------------------------\n(epsilon, delta) = (10, 10^-5) |      GAN     |     PATE-GAN     |     DPGAN    |\n--------------------------------------------------------------------------------------------------\n               AUROC                       |     0.817     |        0.769          |       0.739      |\n               AUPRC                       |     0.556     |        0.473          |       0.383      |\n--------------------------------------------------------------------------------------------------\n\n(2) UCI Epileptic Seizure Recognition Dataset\n--------------------------------------------------------------------------------------------------\n(epsilon, delta) = (10, 10^-5) |      GAN     |     PATE-GAN     |     DPGAN    |\n--------------------------------------------------------------------------------------------------\n               AUROC                       |     0.917     |        0.872          |       0.819      |\n               AUPRC                       |     0.813      |        0.766          |       0.720      |\n--------------------------------------------------------------------------------------------------\n\nAs can be seen in the tables, PATE-GAN works well in high-dimensional data continuing to outperform DPGAN. Detailed results will be added to the revised manuscript.\n\nA2: We will add the following line to the end of the related works section:\n\u201cFinally, it is worth remarking that it is known to be hard in the worst-case to generate private synthetic data [the above-mentioned paper] and techniques such as GANs are necessary to address this challenge."}, "signatures": ["ICLR.cc/2019/Conference/Paper498/Authors"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper498/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper498/Authors", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "PATE-GAN: Generating Synthetic Data with Differential Privacy Guarantees", "abstract": "Machine learning has the potential to assist many communities in using the large datasets that are becoming more and more available. Unfortunately, much of that potential is not being realized because it would require sharing data in a way that compromises privacy. In this paper, we investigate a method for ensuring (differential) privacy of the generator of the Generative Adversarial Nets (GAN) framework. The resulting model can be used for generating synthetic data on which algorithms can be trained and validated, and on which competitions can be conducted, without compromising the privacy of the original dataset. Our method modifies the Private Aggregation of Teacher Ensembles (PATE) framework and applies it to GANs. Our modified framework (which we call PATE-GAN) allows us to tightly bound the influence of any individual sample on the model, resulting in tight differential privacy guarantees and thus an improved performance over models with the same guarantees. We also look at measuring the quality of synthetic data from a new angle; we assert that for the synthetic data to be useful for machine learning researchers, the relative performance of two algorithms (trained and tested) on the synthetic dataset should be the same as their relative performance (when trained and tested) on the original dataset. Our experiments, on various datasets, demonstrate that PATE-GAN consistently outperforms the state-of-the-art method with respect to this and other notions of synthetic data quality.", "keywords": ["Synthetic data generation", "Differential privacy", "Generative adversarial networks", "Private Aggregation of Teacher ensembles"], "authorids": ["james.jordon@wolfson.ox.ac.uk", "jsyoon0823@gmail.com", "mihaela.vanderschaar@eng.ox.ac.uk"], "authors": ["James Jordon", "Jinsung Yoon", "Mihaela van der Schaar"], "pdf": "/pdf/9bef793ee88e366d6fb82472f8bb87690c8cf96f.pdf", "paperhash": "jordon|pategan_generating_synthetic_data_with_differential_privacy_guarantees", "_bibtex": "@inproceedings{\nyoon2018pategan,\ntitle={{PATE}-{GAN}: Generating Synthetic Data with Differential Privacy Guarantees},\nauthor={Jinsung Yoon and James Jordon and Mihaela van der Schaar},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=S1zk9iRqF7},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper498/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621612843, "tddate": null, "super": null, "final": null, "reply": {"forum": "S1zk9iRqF7", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper498/Authors", "ICLR.cc/2019/Conference/Paper498/Reviewers", "ICLR.cc/2019/Conference/Paper498/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper498/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper498/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper498/Authors|ICLR.cc/2019/Conference/Paper498/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper498/Reviewers", "ICLR.cc/2019/Conference/Paper498/Authors", "ICLR.cc/2019/Conference/Paper498/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621612843}}}, {"id": "rylIwo19aQ", "original": null, "number": 3, "cdate": 1542220638042, "ddate": null, "tcdate": 1542220638042, "tmdate": 1542220766881, "tddate": null, "forum": "S1zk9iRqF7", "replyto": "ryxVTXd62X", "invitation": "ICLR.cc/2019/Conference/-/Paper498/Official_Comment", "content": {"title": "RE: Need improvement", "comment": "Thank you for your insightful comments.\n\nA1: Our key contribution is in building on PATE, and developing a new framework which can be used in the GAN setting. While using Gaussian noise may indeed improve our results further, the additional analysis required to use Gaussian noise for PATE is more involved (as noted in [24]), and its inclusion may therefore distract the reader from the main contribution of our paper.\n\nA2: The method proposed in this paper is very similar to (if not the same as) DPGAN. We will modify the related works section to read:\n\u201c\u2026 The key idea is that noise is added to the gradient of the discriminator during training to create differential privacy guarantees. These ideas are also used in [Privacy-preserving generative deep neural networks support clinical data sharing]. Our method\u2026\u201d\n\nA3: A key difference between our work and these works, which we will highlight in the paper, is that they do not use differential privacy. In addition, we have performed simulations using higher-dimensional data which we will include in the paper. Specifically, we used two UCI datasets (UCI ISOLET dataset (dimensions: 617, no of samples: 7797, task: classify consonant vs vowel) and UCI Epileptic Seizure Recognition dataset (dimensions: 179, no of samples: 11500, task: classify seizure activity)) and varied the dimensionality to demonstrate the scalability of our method. The results on the full dataset (all 617 features and 179 features) can be seen in the following tables.\n\n(1) UCI ISOLET Dataset\n--------------------------------------------------------------------------------------------------\n(epsilon, delta) = (10, 10^-5) |      GAN     |     PATE-GAN     |     DPGAN    |\n--------------------------------------------------------------------------------------------------\n               AUROC                       |     0.817     |        0.769          |       0.739      |\n               AUPRC                       |     0.556     |        0.473          |       0.383      |\n--------------------------------------------------------------------------------------------------\n\n(2) UCI Epileptic Seizure Recognition Dataset\n--------------------------------------------------------------------------------------------------\n(epsilon, delta) = (10, 10^-5) |      GAN     |     PATE-GAN     |     DPGAN    |\n--------------------------------------------------------------------------------------------------\n               AUROC                       |     0.917     |        0.872          |       0.819      |\n               AUPRC                       |     0.813      |        0.766          |       0.720      |\n--------------------------------------------------------------------------------------------------\n\nAs can be seen in the tables, PATE-GAN works well also in high-dimensional data and continues to outperform DPGAN. Detailed results will be added to the revised manuscript.\n\nA4: Thank you for the suggestion, the new metric that we are proposing is the agreed ranking probability of section 5.4. To highlight this we will move its introduction to the end of section 4, highlighting that it is one of our contributions.\n\nA5: Thank you for this suggestion, we will move the average results for the other datasets into the main manuscript. We will keep the 12 predictive models in the main manuscript for the Kaggle credit card fraud dataset, as we feel it gives a more complete picture of our results."}, "signatures": ["ICLR.cc/2019/Conference/Paper498/Authors"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper498/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper498/Authors", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "PATE-GAN: Generating Synthetic Data with Differential Privacy Guarantees", "abstract": "Machine learning has the potential to assist many communities in using the large datasets that are becoming more and more available. Unfortunately, much of that potential is not being realized because it would require sharing data in a way that compromises privacy. In this paper, we investigate a method for ensuring (differential) privacy of the generator of the Generative Adversarial Nets (GAN) framework. The resulting model can be used for generating synthetic data on which algorithms can be trained and validated, and on which competitions can be conducted, without compromising the privacy of the original dataset. Our method modifies the Private Aggregation of Teacher Ensembles (PATE) framework and applies it to GANs. Our modified framework (which we call PATE-GAN) allows us to tightly bound the influence of any individual sample on the model, resulting in tight differential privacy guarantees and thus an improved performance over models with the same guarantees. We also look at measuring the quality of synthetic data from a new angle; we assert that for the synthetic data to be useful for machine learning researchers, the relative performance of two algorithms (trained and tested) on the synthetic dataset should be the same as their relative performance (when trained and tested) on the original dataset. Our experiments, on various datasets, demonstrate that PATE-GAN consistently outperforms the state-of-the-art method with respect to this and other notions of synthetic data quality.", "keywords": ["Synthetic data generation", "Differential privacy", "Generative adversarial networks", "Private Aggregation of Teacher ensembles"], "authorids": ["james.jordon@wolfson.ox.ac.uk", "jsyoon0823@gmail.com", "mihaela.vanderschaar@eng.ox.ac.uk"], "authors": ["James Jordon", "Jinsung Yoon", "Mihaela van der Schaar"], "pdf": "/pdf/9bef793ee88e366d6fb82472f8bb87690c8cf96f.pdf", "paperhash": "jordon|pategan_generating_synthetic_data_with_differential_privacy_guarantees", "_bibtex": "@inproceedings{\nyoon2018pategan,\ntitle={{PATE}-{GAN}: Generating Synthetic Data with Differential Privacy Guarantees},\nauthor={Jinsung Yoon and James Jordon and Mihaela van der Schaar},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=S1zk9iRqF7},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper498/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621612843, "tddate": null, "super": null, "final": null, "reply": {"forum": "S1zk9iRqF7", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper498/Authors", "ICLR.cc/2019/Conference/Paper498/Reviewers", "ICLR.cc/2019/Conference/Paper498/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper498/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper498/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper498/Authors|ICLR.cc/2019/Conference/Paper498/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper498/Reviewers", "ICLR.cc/2019/Conference/Paper498/Authors", "ICLR.cc/2019/Conference/Paper498/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621612843}}}, {"id": "HJeqCskq6m", "original": null, "number": 4, "cdate": 1542220754167, "ddate": null, "tcdate": 1542220754167, "tmdate": 1542220754167, "tddate": null, "forum": "S1zk9iRqF7", "replyto": "HygVgKtjn7", "invitation": "ICLR.cc/2019/Conference/-/Paper498/Official_Comment", "content": {"title": "RE: Differenntially private synthetic data set generation via combining the PATE framework and GAN", "comment": "Thank you for your insightful comments.\n\nA1: We have performed simulations using higher-dimensional data which we will include in the paper. Specifically, we used two UCI datasets (UCI ISOLET dataset (dimensions: 617, no of samples: 7797, task: classify consonant vs vowel) and UCI Epileptic Seizure Recognition dataset (dimensions: 179, no of samples: 11500, task: classify seizure activity)) and varied the dimensionality to demonstrate the scalability of our method. The results on the full dataset (all 617 features and 179 features) can be seen in the following tables:\n\n(1) UCI ISOLET Dataset\n--------------------------------------------------------------------------------------------------\n(epsilon, delta) = (10, 10^-5) |      GAN     |     PATE-GAN     |     DPGAN    |\n--------------------------------------------------------------------------------------------------\n               AUROC                       |     0.817     |        0.769          |       0.739      |\n               AUPRC                       |     0.556     |        0.473          |       0.383      |\n--------------------------------------------------------------------------------------------------\n\n(2) UCI Epileptic Seizure Recognition Dataset\n--------------------------------------------------------------------------------------------------\n(epsilon, delta) = (10, 10^-5) |      GAN     |     PATE-GAN     |     DPGAN    |\n--------------------------------------------------------------------------------------------------\n               AUROC                       |     0.917     |        0.872          |       0.819      |\n               AUPRC                       |     0.813      |        0.766          |       0.720      |\n--------------------------------------------------------------------------------------------------\n\nAs can be seen in the table, PATE-GAN works well in high-dimensional data continuing to outperform DPGAN. Detailed results with various dimensionalities will be added to the revised manuscript."}, "signatures": ["ICLR.cc/2019/Conference/Paper498/Authors"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper498/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper498/Authors", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "PATE-GAN: Generating Synthetic Data with Differential Privacy Guarantees", "abstract": "Machine learning has the potential to assist many communities in using the large datasets that are becoming more and more available. Unfortunately, much of that potential is not being realized because it would require sharing data in a way that compromises privacy. In this paper, we investigate a method for ensuring (differential) privacy of the generator of the Generative Adversarial Nets (GAN) framework. The resulting model can be used for generating synthetic data on which algorithms can be trained and validated, and on which competitions can be conducted, without compromising the privacy of the original dataset. Our method modifies the Private Aggregation of Teacher Ensembles (PATE) framework and applies it to GANs. Our modified framework (which we call PATE-GAN) allows us to tightly bound the influence of any individual sample on the model, resulting in tight differential privacy guarantees and thus an improved performance over models with the same guarantees. We also look at measuring the quality of synthetic data from a new angle; we assert that for the synthetic data to be useful for machine learning researchers, the relative performance of two algorithms (trained and tested) on the synthetic dataset should be the same as their relative performance (when trained and tested) on the original dataset. Our experiments, on various datasets, demonstrate that PATE-GAN consistently outperforms the state-of-the-art method with respect to this and other notions of synthetic data quality.", "keywords": ["Synthetic data generation", "Differential privacy", "Generative adversarial networks", "Private Aggregation of Teacher ensembles"], "authorids": ["james.jordon@wolfson.ox.ac.uk", "jsyoon0823@gmail.com", "mihaela.vanderschaar@eng.ox.ac.uk"], "authors": ["James Jordon", "Jinsung Yoon", "Mihaela van der Schaar"], "pdf": "/pdf/9bef793ee88e366d6fb82472f8bb87690c8cf96f.pdf", "paperhash": "jordon|pategan_generating_synthetic_data_with_differential_privacy_guarantees", "_bibtex": "@inproceedings{\nyoon2018pategan,\ntitle={{PATE}-{GAN}: Generating Synthetic Data with Differential Privacy Guarantees},\nauthor={Jinsung Yoon and James Jordon and Mihaela van der Schaar},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=S1zk9iRqF7},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper498/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621612843, "tddate": null, "super": null, "final": null, "reply": {"forum": "S1zk9iRqF7", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper498/Authors", "ICLR.cc/2019/Conference/Paper498/Reviewers", "ICLR.cc/2019/Conference/Paper498/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper498/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper498/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper498/Authors|ICLR.cc/2019/Conference/Paper498/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper498/Reviewers", "ICLR.cc/2019/Conference/Paper498/Authors", "ICLR.cc/2019/Conference/Paper498/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621612843}}}, {"id": "r1gKFckcaX", "original": null, "number": 2, "cdate": 1542220417492, "ddate": null, "tcdate": 1542220417492, "tmdate": 1542220417492, "tddate": null, "forum": "S1zk9iRqF7", "replyto": "Bkgo4YlMaQ", "invitation": "ICLR.cc/2019/Conference/-/Paper498/Official_Comment", "content": {"title": "RE: Some questions to authors ", "comment": "Thank you for your comments. \n\nA1: First, as can be seen in Figure 1 in the manuscript, the performance of DPGAN significantly decreases when epsilon is smaller than 1. You can also check this in Table 2 in the manuscript. \nMoreover, in figure 3 in DPGAN the authors investigated epsilon = 11.5, 3.2, 0.96, 0.72, and show that for digits 0 and 1, and digits 4 and 5 that their accuracy for epsilon = 0.96 is above 0.8. We believe this to be consistent with our findings. The metric they use on MIMIC is the dimension-wise prediction (DWP) which is not comparable with the metrics we use. \n\nA2: Thank you for your suggestion. We have obtained results on two higher-dimensional UCI datasets (UCI ISOLET dataset (dimensions: 617, no of samples: 7797, task: classify consonant vs vowel) and UCI Epileptic Seizure Recognition dataset (dimensions: 179, no of samples: 11500, task: classify seizure activity)) which will be included in the revised manuscript.\n\n(1) UCI ISOLET Dataset\n--------------------------------------------------------------------------------------------------\n(epsilon, delta) = (10, 10^-5) |      GAN     |     PATE-GAN     |     DPGAN    |\n--------------------------------------------------------------------------------------------------\n               AUROC                       |     0.817     |        0.769          |       0.739      |\n               AUPRC                       |     0.556     |        0.473          |       0.383      |\n--------------------------------------------------------------------------------------------------\n\n(2) UCI Epileptic Seizure Recognition Dataset\n--------------------------------------------------------------------------------------------------\n(epsilon, delta) = (10, 10^-5) |      GAN     |     PATE-GAN     |     DPGAN    |\n--------------------------------------------------------------------------------------------------\n               AUROC                       |     0.917     |        0.872          |       0.819      |\n               AUPRC                       |     0.813      |        0.766          |       0.720      |\n--------------------------------------------------------------------------------------------------\n\nA3: The implementation used the code that was published in https://github.com/illidanlab/dpgan (which was the source cited by the original DPGAN paper). Currently the DPGAN authors may be revising the code; it is not currently accessible (we do not know why). You can directly ask the DPGAN authors to share the code, but we assure you we used the code provided there.\n\nA4: We are not sure what you mean by \u201cpre-training\u201d. In the PATE-GAN framework, we do not \u201cpre-train\u201d the student discriminator. Upon an acceptance decision, we will publish our code, though we do not wish to do so until then to preserve our anonymity.\n\nA5: The sample sizes and the label distribution of the generated synthetic datasets are exactly the same as the size of the training datasets. The sample size and the label distribution of the training datasets can be found in the page 12 in the manuscript. Furthermore, we were aware that AUROC is not sufficient for imbalanced data and thus, we included AUPRC to address this problem. "}, "signatures": ["ICLR.cc/2019/Conference/Paper498/Authors"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper498/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper498/Authors", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "PATE-GAN: Generating Synthetic Data with Differential Privacy Guarantees", "abstract": "Machine learning has the potential to assist many communities in using the large datasets that are becoming more and more available. Unfortunately, much of that potential is not being realized because it would require sharing data in a way that compromises privacy. In this paper, we investigate a method for ensuring (differential) privacy of the generator of the Generative Adversarial Nets (GAN) framework. The resulting model can be used for generating synthetic data on which algorithms can be trained and validated, and on which competitions can be conducted, without compromising the privacy of the original dataset. Our method modifies the Private Aggregation of Teacher Ensembles (PATE) framework and applies it to GANs. Our modified framework (which we call PATE-GAN) allows us to tightly bound the influence of any individual sample on the model, resulting in tight differential privacy guarantees and thus an improved performance over models with the same guarantees. We also look at measuring the quality of synthetic data from a new angle; we assert that for the synthetic data to be useful for machine learning researchers, the relative performance of two algorithms (trained and tested) on the synthetic dataset should be the same as their relative performance (when trained and tested) on the original dataset. Our experiments, on various datasets, demonstrate that PATE-GAN consistently outperforms the state-of-the-art method with respect to this and other notions of synthetic data quality.", "keywords": ["Synthetic data generation", "Differential privacy", "Generative adversarial networks", "Private Aggregation of Teacher ensembles"], "authorids": ["james.jordon@wolfson.ox.ac.uk", "jsyoon0823@gmail.com", "mihaela.vanderschaar@eng.ox.ac.uk"], "authors": ["James Jordon", "Jinsung Yoon", "Mihaela van der Schaar"], "pdf": "/pdf/9bef793ee88e366d6fb82472f8bb87690c8cf96f.pdf", "paperhash": "jordon|pategan_generating_synthetic_data_with_differential_privacy_guarantees", "_bibtex": "@inproceedings{\nyoon2018pategan,\ntitle={{PATE}-{GAN}: Generating Synthetic Data with Differential Privacy Guarantees},\nauthor={Jinsung Yoon and James Jordon and Mihaela van der Schaar},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=S1zk9iRqF7},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper498/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621612843, "tddate": null, "super": null, "final": null, "reply": {"forum": "S1zk9iRqF7", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper498/Authors", "ICLR.cc/2019/Conference/Paper498/Reviewers", "ICLR.cc/2019/Conference/Paper498/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper498/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper498/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper498/Authors|ICLR.cc/2019/Conference/Paper498/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper498/Reviewers", "ICLR.cc/2019/Conference/Paper498/Authors", "ICLR.cc/2019/Conference/Paper498/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621612843}}}, {"id": "Hyg0gt1q6Q", "original": null, "number": 1, "cdate": 1542220022483, "ddate": null, "tcdate": 1542220022483, "tmdate": 1542220022483, "tddate": null, "forum": "S1zk9iRqF7", "replyto": "rylkWx4-aQ", "invitation": "ICLR.cc/2019/Conference/-/Paper498/Official_Comment", "content": {"title": "RE: Missing setting A performance", "comment": "Thank you for the comments. \n\nPlease see the table below, containing the performance of setting A across all 4 experiments (average performance across all 12 predictive models). You can compare the below with Table 1, 5, 6, and 7 in Setting B.\n-------------------------------------------------------------------------------------\nSetting A Performance | No of samples  |  AUROC  |  AUPRC | \n-------------------------------------------------------------------------------------\n        Kaggle Credit          |        284,807       |  0.9438   |  0.7020  |\n           MAGGIC                |        30,389         |  0.7069   |  0.3638  |\n             UNOS                  |        23,706          |  0.6416   |  0.6677  |\n        Kaggle Cervical       |         858              |  0.9354   |  0.6314  |\n------------------------------------------------------------------------------------"}, "signatures": ["ICLR.cc/2019/Conference/Paper498/Authors"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper498/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper498/Authors", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "PATE-GAN: Generating Synthetic Data with Differential Privacy Guarantees", "abstract": "Machine learning has the potential to assist many communities in using the large datasets that are becoming more and more available. Unfortunately, much of that potential is not being realized because it would require sharing data in a way that compromises privacy. In this paper, we investigate a method for ensuring (differential) privacy of the generator of the Generative Adversarial Nets (GAN) framework. The resulting model can be used for generating synthetic data on which algorithms can be trained and validated, and on which competitions can be conducted, without compromising the privacy of the original dataset. Our method modifies the Private Aggregation of Teacher Ensembles (PATE) framework and applies it to GANs. Our modified framework (which we call PATE-GAN) allows us to tightly bound the influence of any individual sample on the model, resulting in tight differential privacy guarantees and thus an improved performance over models with the same guarantees. We also look at measuring the quality of synthetic data from a new angle; we assert that for the synthetic data to be useful for machine learning researchers, the relative performance of two algorithms (trained and tested) on the synthetic dataset should be the same as their relative performance (when trained and tested) on the original dataset. Our experiments, on various datasets, demonstrate that PATE-GAN consistently outperforms the state-of-the-art method with respect to this and other notions of synthetic data quality.", "keywords": ["Synthetic data generation", "Differential privacy", "Generative adversarial networks", "Private Aggregation of Teacher ensembles"], "authorids": ["james.jordon@wolfson.ox.ac.uk", "jsyoon0823@gmail.com", "mihaela.vanderschaar@eng.ox.ac.uk"], "authors": ["James Jordon", "Jinsung Yoon", "Mihaela van der Schaar"], "pdf": "/pdf/9bef793ee88e366d6fb82472f8bb87690c8cf96f.pdf", "paperhash": "jordon|pategan_generating_synthetic_data_with_differential_privacy_guarantees", "_bibtex": "@inproceedings{\nyoon2018pategan,\ntitle={{PATE}-{GAN}: Generating Synthetic Data with Differential Privacy Guarantees},\nauthor={Jinsung Yoon and James Jordon and Mihaela van der Schaar},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=S1zk9iRqF7},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper498/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621612843, "tddate": null, "super": null, "final": null, "reply": {"forum": "S1zk9iRqF7", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper498/Authors", "ICLR.cc/2019/Conference/Paper498/Reviewers", "ICLR.cc/2019/Conference/Paper498/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper498/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper498/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper498/Authors|ICLR.cc/2019/Conference/Paper498/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper498/Reviewers", "ICLR.cc/2019/Conference/Paper498/Authors", "ICLR.cc/2019/Conference/Paper498/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621612843}}}, {"id": "Bkgo4YlMaQ", "original": null, "number": 2, "cdate": 1541699890789, "ddate": null, "tcdate": 1541699890789, "tmdate": 1541699890789, "tddate": null, "forum": "S1zk9iRqF7", "replyto": "S1zk9iRqF7", "invitation": "ICLR.cc/2019/Conference/-/Paper498/Public_Comment", "content": {"comment": "It is an interesting work and my apologies for posting the questions at this stage. I just recently came across this work.\n\nI see DPGAN performing reasonably well with smaller epsilon(<=1) in most cases. In original DPGAN paper however, the authors only investigated epsilon >=9 and still found it performing not so good. Especially on structured data (MIMIC-III), where they had to use epsilon >> 10 to get reasonable results. How does this implementation achieves these results? Even if one can argue the datasets are different, but still this is a consistent and significant improvement.\n\nI really think some results on visual datasets (MNIST,LSUN) and datasets that have been previously used (such as MIMIC-III) might help shed some light on this peculiar phenomenon. It will also solidify the proposed method on reasonably high dimensional inputs. Maximum dimensionality in current paper is 35 (dataset in appendix).\n\nPaper states that the code for DPGAN is used from \u201chttps://github.com/illidanlab\u201d. I cannot find any DPGAN implementation in that repository. I also struggle to understand the \u201cpre-training\u201d of student discriminator. I think most of my above questions can be answered if authors share the implementation details of PATE-GAN.\n\nAlso, what are the sample sizes of generated synthetic data used for evaluation? I think providing a class(label) distribution in generated data would be helpful as well. Another side-point, in an imbalanced dataset such as Kaggle credit card fraud detection dataset, AUROC might not  be the most informative measure for evaluation.", "title": "Some questions to authors"}, "signatures": ["~Lovedeep_Gondara1"], "readers": ["everyone"], "nonreaders": [], "writers": ["~Lovedeep_Gondara1", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "PATE-GAN: Generating Synthetic Data with Differential Privacy Guarantees", "abstract": "Machine learning has the potential to assist many communities in using the large datasets that are becoming more and more available. Unfortunately, much of that potential is not being realized because it would require sharing data in a way that compromises privacy. In this paper, we investigate a method for ensuring (differential) privacy of the generator of the Generative Adversarial Nets (GAN) framework. The resulting model can be used for generating synthetic data on which algorithms can be trained and validated, and on which competitions can be conducted, without compromising the privacy of the original dataset. Our method modifies the Private Aggregation of Teacher Ensembles (PATE) framework and applies it to GANs. Our modified framework (which we call PATE-GAN) allows us to tightly bound the influence of any individual sample on the model, resulting in tight differential privacy guarantees and thus an improved performance over models with the same guarantees. We also look at measuring the quality of synthetic data from a new angle; we assert that for the synthetic data to be useful for machine learning researchers, the relative performance of two algorithms (trained and tested) on the synthetic dataset should be the same as their relative performance (when trained and tested) on the original dataset. Our experiments, on various datasets, demonstrate that PATE-GAN consistently outperforms the state-of-the-art method with respect to this and other notions of synthetic data quality.", "keywords": ["Synthetic data generation", "Differential privacy", "Generative adversarial networks", "Private Aggregation of Teacher ensembles"], "authorids": ["james.jordon@wolfson.ox.ac.uk", "jsyoon0823@gmail.com", "mihaela.vanderschaar@eng.ox.ac.uk"], "authors": ["James Jordon", "Jinsung Yoon", "Mihaela van der Schaar"], "pdf": "/pdf/9bef793ee88e366d6fb82472f8bb87690c8cf96f.pdf", "paperhash": "jordon|pategan_generating_synthetic_data_with_differential_privacy_guarantees", "_bibtex": "@inproceedings{\nyoon2018pategan,\ntitle={{PATE}-{GAN}: Generating Synthetic Data with Differential Privacy Guarantees},\nauthor={Jinsung Yoon and James Jordon and Mihaela van der Schaar},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=S1zk9iRqF7},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper498/Public_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1542311826283, "tddate": null, "super": null, "final": null, "reply": {"signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed."}, "nonreaders": {"values": []}, "forum": "S1zk9iRqF7", "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper498/Authors", "ICLR.cc/2019/Conference/Paper498/Reviewers", "ICLR.cc/2019/Conference/Paper498/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "replyto": null, "content": {"comment": {"value-regex": "[\\S\\s]{1,5000}", "required": true, "order": 1, "description": "Your comment or reply (max 5000 characters)."}, "title": {"value-regex": ".{1,500}", "required": true, "order": 0, "description": "Brief summary of your comment."}}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["~"], "noninvitees": ["ICLR.cc/2019/Conference/Paper498/Authors", "ICLR.cc/2019/Conference/Paper498/Reviewers", "ICLR.cc/2019/Conference/Paper498/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1542311826283}}}, {"id": "rylkWx4-aQ", "original": null, "number": 1, "cdate": 1541648375044, "ddate": null, "tcdate": 1541648375044, "tmdate": 1541648375044, "tddate": null, "forum": "S1zk9iRqF7", "replyto": "S1zk9iRqF7", "invitation": "ICLR.cc/2019/Conference/-/Paper498/Public_Comment", "content": {"comment": "Thank you for this great work!\n\nI am wondering what's the performance of setting A (train in real training set, evaluate in real test set) across all 4 experiments. Paper only shows the ranking compared to setting C. It definitely helps the reader to evaluate if this privacy GAN actually capture the real characteristics of the original dataset, especially in 4 different experients with varying size of dataset. I will expect the gap between setting A and C should go larger as the dataset gets smaller.", "title": "Missing setting A performance"}, "signatures": ["~Chun-Hao_Chang1"], "readers": ["everyone"], "nonreaders": [], "writers": ["~Chun-Hao_Chang1", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "PATE-GAN: Generating Synthetic Data with Differential Privacy Guarantees", "abstract": "Machine learning has the potential to assist many communities in using the large datasets that are becoming more and more available. Unfortunately, much of that potential is not being realized because it would require sharing data in a way that compromises privacy. In this paper, we investigate a method for ensuring (differential) privacy of the generator of the Generative Adversarial Nets (GAN) framework. The resulting model can be used for generating synthetic data on which algorithms can be trained and validated, and on which competitions can be conducted, without compromising the privacy of the original dataset. Our method modifies the Private Aggregation of Teacher Ensembles (PATE) framework and applies it to GANs. Our modified framework (which we call PATE-GAN) allows us to tightly bound the influence of any individual sample on the model, resulting in tight differential privacy guarantees and thus an improved performance over models with the same guarantees. We also look at measuring the quality of synthetic data from a new angle; we assert that for the synthetic data to be useful for machine learning researchers, the relative performance of two algorithms (trained and tested) on the synthetic dataset should be the same as their relative performance (when trained and tested) on the original dataset. Our experiments, on various datasets, demonstrate that PATE-GAN consistently outperforms the state-of-the-art method with respect to this and other notions of synthetic data quality.", "keywords": ["Synthetic data generation", "Differential privacy", "Generative adversarial networks", "Private Aggregation of Teacher ensembles"], "authorids": ["james.jordon@wolfson.ox.ac.uk", "jsyoon0823@gmail.com", "mihaela.vanderschaar@eng.ox.ac.uk"], "authors": ["James Jordon", "Jinsung Yoon", "Mihaela van der Schaar"], "pdf": "/pdf/9bef793ee88e366d6fb82472f8bb87690c8cf96f.pdf", "paperhash": "jordon|pategan_generating_synthetic_data_with_differential_privacy_guarantees", "_bibtex": "@inproceedings{\nyoon2018pategan,\ntitle={{PATE}-{GAN}: Generating Synthetic Data with Differential Privacy Guarantees},\nauthor={Jinsung Yoon and James Jordon and Mihaela van der Schaar},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=S1zk9iRqF7},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper498/Public_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1542311826283, "tddate": null, "super": null, "final": null, "reply": {"signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed."}, "nonreaders": {"values": []}, "forum": "S1zk9iRqF7", "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper498/Authors", "ICLR.cc/2019/Conference/Paper498/Reviewers", "ICLR.cc/2019/Conference/Paper498/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "replyto": null, "content": {"comment": {"value-regex": "[\\S\\s]{1,5000}", "required": true, "order": 1, "description": "Your comment or reply (max 5000 characters)."}, "title": {"value-regex": ".{1,500}", "required": true, "order": 0, "description": "Brief summary of your comment."}}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["~"], "noninvitees": ["ICLR.cc/2019/Conference/Paper498/Authors", "ICLR.cc/2019/Conference/Paper498/Reviewers", "ICLR.cc/2019/Conference/Paper498/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1542311826283}}}, {"id": "HyxXmnTC27", "original": null, "number": 3, "cdate": 1541491738872, "ddate": null, "tcdate": 1541491738872, "tmdate": 1541533944143, "tddate": null, "forum": "S1zk9iRqF7", "replyto": "S1zk9iRqF7", "invitation": "ICLR.cc/2019/Conference/-/Paper498/Official_Review", "content": {"title": "Interesting setup, surprising that it works", "review": "This paper considers using a GAN to generate synthetic data in a differentially private manner [see also https://www.biorxiv.org/content/early/2018/06/05/159756 ]. The key novelty is the integration of the PATE differential privacy framework from recent work. Specifically, rather than a single distinguisher as is usual in a GAN, there is a \"student distinguisher\" and several \"teacher distinguishers\". The student distinguisher is used as usual except that it does not have access to the real data, only the teacher distinguishers have access to the real data (as well as the synthetic data). The data is partitioned amongst the teacher distinguishers and their output is aggregated in a differentially private manner (and gradients are not revealed). The role of the teacher distinguishers is solely to correct the student distinguisher when it errs.\n\nWhat is strange about this setup is that the generator's only feedback is from the gradients of the student distinguisher, which is never exposed to the real data. The entire training process relies on the generator producing realistic data by chance at which point the teacher distinguishers can provide positive feedback. (The paper remarks about this in the middle of page 5.) It's surprising that this works, but there are experimental results to back it up.\n\nI think it would be appropriate to remark that generating private synthetic data is known to be hard in the worst case [ https://eccc.weizmann.ac.il/report/2010/017/ ] and therefore it is necessary to use techniques like GANs.\n\nOverall, I think the paper is interesting, well written, novel, and therefore appropriate for ICLR.", "rating": "7: Good paper, accept", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["ICLR.cc/2019/Conference/Paper498/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "PATE-GAN: Generating Synthetic Data with Differential Privacy Guarantees", "abstract": "Machine learning has the potential to assist many communities in using the large datasets that are becoming more and more available. Unfortunately, much of that potential is not being realized because it would require sharing data in a way that compromises privacy. In this paper, we investigate a method for ensuring (differential) privacy of the generator of the Generative Adversarial Nets (GAN) framework. The resulting model can be used for generating synthetic data on which algorithms can be trained and validated, and on which competitions can be conducted, without compromising the privacy of the original dataset. Our method modifies the Private Aggregation of Teacher Ensembles (PATE) framework and applies it to GANs. Our modified framework (which we call PATE-GAN) allows us to tightly bound the influence of any individual sample on the model, resulting in tight differential privacy guarantees and thus an improved performance over models with the same guarantees. We also look at measuring the quality of synthetic data from a new angle; we assert that for the synthetic data to be useful for machine learning researchers, the relative performance of two algorithms (trained and tested) on the synthetic dataset should be the same as their relative performance (when trained and tested) on the original dataset. Our experiments, on various datasets, demonstrate that PATE-GAN consistently outperforms the state-of-the-art method with respect to this and other notions of synthetic data quality.", "keywords": ["Synthetic data generation", "Differential privacy", "Generative adversarial networks", "Private Aggregation of Teacher ensembles"], "authorids": ["james.jordon@wolfson.ox.ac.uk", "jsyoon0823@gmail.com", "mihaela.vanderschaar@eng.ox.ac.uk"], "authors": ["James Jordon", "Jinsung Yoon", "Mihaela van der Schaar"], "pdf": "/pdf/9bef793ee88e366d6fb82472f8bb87690c8cf96f.pdf", "paperhash": "jordon|pategan_generating_synthetic_data_with_differential_privacy_guarantees", "_bibtex": "@inproceedings{\nyoon2018pategan,\ntitle={{PATE}-{GAN}: Generating Synthetic Data with Differential Privacy Guarantees},\nauthor={Jinsung Yoon and James Jordon and Mihaela van der Schaar},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=S1zk9iRqF7},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper498/Official_Review", "cdate": 1542234447583, "expdate": 1552335264000, "duedate": 1541196000000, "reply": {"forum": "S1zk9iRqF7", "replyto": "S1zk9iRqF7", "readers": {"description": "The users who will be allowed to read the reply content.", "values": ["everyone"]}, "nonreaders": {"values": []}, "signatures": {"description": "How your identity will be displayed with the above content.", "values-regex": "ICLR.cc/2019/Conference/Paper498/AnonReviewer[0-9]+"}, "writers": {"description": "Users that may modify this record.", "values": ["ICLR.cc/2019/Conference"]}, "content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "required": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}}, "multiReply": false, "tcdate": 1552335737924, "tmdate": 1552335737924, "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "invitees": ["ICLR.cc/2019/Conference/Paper498/Reviewers"], "noninvitees": [], "signatures": ["ICLR.cc/2019/Conference"]}}}, {"id": "HygVgKtjn7", "original": null, "number": 1, "cdate": 1541277932415, "ddate": null, "tcdate": 1541277932415, "tmdate": 1541533943735, "tddate": null, "forum": "S1zk9iRqF7", "replyto": "S1zk9iRqF7", "invitation": "ICLR.cc/2019/Conference/-/Paper498/Official_Review", "content": {"title": "Differenntially  private synthetic data set generation via combining the PATE framework and GAN", "review": "The paper studies the problem of generating synthetic datasets (while ensuring differential privacy) via training a GAN. One natural approach is the teacher-student framework considered in the PATE framework.  In the original PATE framework, while the teachers are ensured to preserve differential privacy, the student model (typically a GAN) requires the presence of publicly data samples. The main contribution of this paper is to get around the requirement of public data via using uniformly random samples in [0,1]^d.\n\nDifferentially private synthetic data generation is clearly an important and a long-standing open problem. Recently, there has been some work on exploiting differentially private variants of GANs to generate synthetic data. However, the scale of these results is far from satisfactory. The current paper claims to bypass this issue by using the PATE-GAN approach.\n\nI am not an expert on deep learning. The idea of bypassing the use of public data by taking uniformly random samples seems interesting. In my view, these random vectors are used in the GAN as some sort of a basis. It is interesting to see if this result extends to high-dimensional settings (i.e., where d  is very large).", "rating": "7: Good paper, accept", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "signatures": ["ICLR.cc/2019/Conference/Paper498/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "PATE-GAN: Generating Synthetic Data with Differential Privacy Guarantees", "abstract": "Machine learning has the potential to assist many communities in using the large datasets that are becoming more and more available. Unfortunately, much of that potential is not being realized because it would require sharing data in a way that compromises privacy. In this paper, we investigate a method for ensuring (differential) privacy of the generator of the Generative Adversarial Nets (GAN) framework. The resulting model can be used for generating synthetic data on which algorithms can be trained and validated, and on which competitions can be conducted, without compromising the privacy of the original dataset. Our method modifies the Private Aggregation of Teacher Ensembles (PATE) framework and applies it to GANs. Our modified framework (which we call PATE-GAN) allows us to tightly bound the influence of any individual sample on the model, resulting in tight differential privacy guarantees and thus an improved performance over models with the same guarantees. We also look at measuring the quality of synthetic data from a new angle; we assert that for the synthetic data to be useful for machine learning researchers, the relative performance of two algorithms (trained and tested) on the synthetic dataset should be the same as their relative performance (when trained and tested) on the original dataset. Our experiments, on various datasets, demonstrate that PATE-GAN consistently outperforms the state-of-the-art method with respect to this and other notions of synthetic data quality.", "keywords": ["Synthetic data generation", "Differential privacy", "Generative adversarial networks", "Private Aggregation of Teacher ensembles"], "authorids": ["james.jordon@wolfson.ox.ac.uk", "jsyoon0823@gmail.com", "mihaela.vanderschaar@eng.ox.ac.uk"], "authors": ["James Jordon", "Jinsung Yoon", "Mihaela van der Schaar"], "pdf": "/pdf/9bef793ee88e366d6fb82472f8bb87690c8cf96f.pdf", "paperhash": "jordon|pategan_generating_synthetic_data_with_differential_privacy_guarantees", "_bibtex": "@inproceedings{\nyoon2018pategan,\ntitle={{PATE}-{GAN}: Generating Synthetic Data with Differential Privacy Guarantees},\nauthor={Jinsung Yoon and James Jordon and Mihaela van der Schaar},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=S1zk9iRqF7},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper498/Official_Review", "cdate": 1542234447583, "expdate": 1552335264000, "duedate": 1541196000000, "reply": {"forum": "S1zk9iRqF7", "replyto": "S1zk9iRqF7", "readers": {"description": "The users who will be allowed to read the reply content.", "values": ["everyone"]}, "nonreaders": {"values": []}, "signatures": {"description": "How your identity will be displayed with the above content.", "values-regex": "ICLR.cc/2019/Conference/Paper498/AnonReviewer[0-9]+"}, "writers": {"description": "Users that may modify this record.", "values": ["ICLR.cc/2019/Conference"]}, "content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "required": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}}, "multiReply": false, "tcdate": 1552335737924, "tmdate": 1552335737924, "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "invitees": ["ICLR.cc/2019/Conference/Paper498/Reviewers"], "noninvitees": [], "signatures": ["ICLR.cc/2019/Conference"]}}}], "count": 17}