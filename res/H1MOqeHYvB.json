{"notes": [{"id": "H1MOqeHYvB", "original": "H1g9gJ-tvB", "number": 2478, "cdate": 1569439888494, "ddate": null, "tcdate": 1569439888494, "tmdate": 1577168264332, "tddate": null, "forum": "H1MOqeHYvB", "replyto": null, "invitation": "ICLR.cc/2020/Conference/-/Blind_Submission", "content": {"authorids": ["amitmoryossef@gmail.com", "yanaiela@gmail.com", "yoav.goldberg@gmail.com"], "title": "At Your Fingertips: Automatic Piano Fingering Detection", "authors": ["Amit Moryossef", "Yanai Elazar", "Yoav Goldberg"], "pdf": "/pdf/654848b30a3510f4595c174bae1079a26b1367fe.pdf", "TL;DR": "We automatically extract fingering information from videos of piano performances, to be used in automatic fingering prediction models.", "abstract": "Automatic Piano Fingering is a hard task which computers can learn using data. As data collection is hard and expensive, we propose to automate this process by automatically extracting fingerings from public videos and MIDI files, using computer-vision techniques. Running this process on 90 videos results in the largest dataset for piano fingering with more than 150K notes. We show that when running a previously proposed model for automatic piano fingering on our dataset and then fine-tuning it on manually labeled piano fingering data, we achieve state-of-the-art results.\nIn addition to the fingering extraction method, we also introduce a novel method for transferring deep-learning computer-vision models to work on out-of-domain data, by fine-tuning it on out-of-domain augmentation proposed by a Generative Adversarial Network (GAN).\n\nFor demonstration, we anonymously release a visualization of the output of our process for a single video on https://youtu.be/Gfs1UWQhr5Q", "code": "https://drive.google.com/file/d/1kDPZSA7ppOaup9Q1Dab7bW4OXNh9mAQA/view?usp=sharing", "keywords": ["piano", "fingering", "dataset"], "paperhash": "moryossef|at_your_fingertips_automatic_piano_fingering_detection", "original_pdf": "/attachment/654848b30a3510f4595c174bae1079a26b1367fe.pdf", "_bibtex": "@misc{\nmoryossef2020at,\ntitle={At Your Fingertips: Automatic Piano Fingering Detection},\nauthor={Amit Moryossef and Yanai Elazar and Yoav Goldberg},\nyear={2020},\nurl={https://openreview.net/forum?id=H1MOqeHYvB}\n}"}, "signatures": ["ICLR.cc/2020/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference"], "details": {"replyCount": 6, "writable": false, "overwriting": [], "revisions": false, "tags": [], "invitation": {"reply": {"readers": {"values-regex": ".*"}, "writers": {"values": ["ICLR.cc/2020/Conference"]}, "signatures": {"values": ["ICLR.cc/2020/Conference"]}, "content": {"spotlight_video": {"value-regex": ".*"}, "full_presentation_video": {"value-regex": ".*"}, "original_pdf": {"required": false, "description": "Upload a PDF file that ends with .pdf", "value-regex": ".*"}, "appendix": {"value-regex": ".*"}, "authorids": {"values-regex": ".*"}, "poster": {"value-regex": ".*"}, "authors": {"values": ["Anonymous"]}, "slides": {"value-regex": ".*"}}}, "final": [], "signatures": ["ICLR.cc/2020/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference"], "noninvitees": [], "tcdate": 1569271260237, "tmdate": 1593459412141, "id": "ICLR.cc/2020/Conference/-/Blind_Submission"}}, "tauthor": "OpenReview.net"}, {"id": "ZkfLnoKAp", "original": null, "number": 1, "cdate": 1576798749976, "ddate": null, "tcdate": 1576798749976, "tmdate": 1576800885880, "tddate": null, "forum": "H1MOqeHYvB", "replyto": "H1MOqeHYvB", "invitation": "ICLR.cc/2020/Conference/Paper2478/-/Decision", "content": {"decision": "Reject", "comment": "The paper shows an automatic piano fingering algorithm. The idea is good. But the reviewers find that the novelty is limited and it is an incremental work. All the reivewers agree to reject.", "title": "Paper Decision"}, "signatures": ["ICLR.cc/2020/Conference/Program_Chairs"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Program_Chairs"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["amitmoryossef@gmail.com", "yanaiela@gmail.com", "yoav.goldberg@gmail.com"], "title": "At Your Fingertips: Automatic Piano Fingering Detection", "authors": ["Amit Moryossef", "Yanai Elazar", "Yoav Goldberg"], "pdf": "/pdf/654848b30a3510f4595c174bae1079a26b1367fe.pdf", "TL;DR": "We automatically extract fingering information from videos of piano performances, to be used in automatic fingering prediction models.", "abstract": "Automatic Piano Fingering is a hard task which computers can learn using data. As data collection is hard and expensive, we propose to automate this process by automatically extracting fingerings from public videos and MIDI files, using computer-vision techniques. Running this process on 90 videos results in the largest dataset for piano fingering with more than 150K notes. We show that when running a previously proposed model for automatic piano fingering on our dataset and then fine-tuning it on manually labeled piano fingering data, we achieve state-of-the-art results.\nIn addition to the fingering extraction method, we also introduce a novel method for transferring deep-learning computer-vision models to work on out-of-domain data, by fine-tuning it on out-of-domain augmentation proposed by a Generative Adversarial Network (GAN).\n\nFor demonstration, we anonymously release a visualization of the output of our process for a single video on https://youtu.be/Gfs1UWQhr5Q", "code": "https://drive.google.com/file/d/1kDPZSA7ppOaup9Q1Dab7bW4OXNh9mAQA/view?usp=sharing", "keywords": ["piano", "fingering", "dataset"], "paperhash": "moryossef|at_your_fingertips_automatic_piano_fingering_detection", "original_pdf": "/attachment/654848b30a3510f4595c174bae1079a26b1367fe.pdf", "_bibtex": "@misc{\nmoryossef2020at,\ntitle={At Your Fingertips: Automatic Piano Fingering Detection},\nauthor={Amit Moryossef and Yanai Elazar and Yoav Goldberg},\nyear={2020},\nurl={https://openreview.net/forum?id=H1MOqeHYvB}\n}"}, "tags": [], "invitation": {"reply": {"writers": {"description": "How your identity will be displayed.", "values-regex": ["ICLR.cc/2020/Conference/Program_Chairs"]}, "signatures": {"values": ["ICLR.cc/2020/Conference/Program_Chairs"], "description": "How your identity will be displayed."}, "content": {"decision": {"value-radio": ["Accept (Spotlight)", "Accept (Talk)", "Accept (Poster)", "Reject"], "description": "Decision", "required": true, "order": 2}, "title": {"value": "Paper Decision", "required": true, "order": 1}, "comment": {"value-regex": "[\\S\\s]{0,5000}", "description": "", "required": false, "order": 3}}, "forum": "H1MOqeHYvB", "replyto": "H1MOqeHYvB", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}}, "expdate": 1576854540000, "duedate": 1576853940000, "multiReply": false, "readers": ["everyone"], "invitees": ["ICLR.cc/2020/Conference/Program_Chairs"], "tcdate": 1576795724717, "tmdate": 1576800276410, "super": "ICLR.cc/2020/Conference/-/Decision", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper2478/-/Decision"}}}, {"id": "BJxPvjsJjr", "original": null, "number": 2, "cdate": 1573006175510, "ddate": null, "tcdate": 1573006175510, "tmdate": 1573006239624, "tddate": null, "forum": "H1MOqeHYvB", "replyto": "rkxDbgiWYS", "invitation": "ICLR.cc/2020/Conference/Paper2478/-/Official_Comment", "content": {"title": "Main reply to Review #1", "comment": "Thank you for your review.\n\nWe would like to address your review:\n1. We are not aware of any works using CycleGAN for pose estimation, or any works using sim2real in that manner (of fine-tuning the algorithms). It would be great to get some citations.\nRegarding the novelty of our method, here is a list of what we think are the core novel ideas of our method:\na. We show how it is possible to segment each key of the piano.\nb. We show the failures of current pose detection models, and devise a new, general way to address such failures, that we show is robust - and for us, reduces 50% of the accumulative error.\nc. We design a new way to align between MIDI and piano video recordings, which is accurate up to the video sampling rate.\nd. We design an algorithm to assume \"collisions\" between the detected fingers in multiple frames, and the piano keys, from very noisy data.\n\n2. While we agree more baselines are better to have, in our experiments we aim to convince the reader that our data is indeed valuable, and not just noise, and we think it manages to show that. We do not aim to create a new method for automatic fingering in this work.\nWhile indeed the proposed approach trained on the PIG dataset gets slightly worse results from the SOTA on the PIG dataset, the case we are trying to make is not that our method is better, it is that our data is good and valuable, and can be used for future developed methods.\n\n\nAgain, we would like to thank you, and perhaps get your feedback on what should be improved in this paper? What experiments/analysis you would like to see?\n"}, "signatures": ["ICLR.cc/2020/Conference/Paper2478/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper2478/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["amitmoryossef@gmail.com", "yanaiela@gmail.com", "yoav.goldberg@gmail.com"], "title": "At Your Fingertips: Automatic Piano Fingering Detection", "authors": ["Amit Moryossef", "Yanai Elazar", "Yoav Goldberg"], "pdf": "/pdf/654848b30a3510f4595c174bae1079a26b1367fe.pdf", "TL;DR": "We automatically extract fingering information from videos of piano performances, to be used in automatic fingering prediction models.", "abstract": "Automatic Piano Fingering is a hard task which computers can learn using data. As data collection is hard and expensive, we propose to automate this process by automatically extracting fingerings from public videos and MIDI files, using computer-vision techniques. Running this process on 90 videos results in the largest dataset for piano fingering with more than 150K notes. We show that when running a previously proposed model for automatic piano fingering on our dataset and then fine-tuning it on manually labeled piano fingering data, we achieve state-of-the-art results.\nIn addition to the fingering extraction method, we also introduce a novel method for transferring deep-learning computer-vision models to work on out-of-domain data, by fine-tuning it on out-of-domain augmentation proposed by a Generative Adversarial Network (GAN).\n\nFor demonstration, we anonymously release a visualization of the output of our process for a single video on https://youtu.be/Gfs1UWQhr5Q", "code": "https://drive.google.com/file/d/1kDPZSA7ppOaup9Q1Dab7bW4OXNh9mAQA/view?usp=sharing", "keywords": ["piano", "fingering", "dataset"], "paperhash": "moryossef|at_your_fingertips_automatic_piano_fingering_detection", "original_pdf": "/attachment/654848b30a3510f4595c174bae1079a26b1367fe.pdf", "_bibtex": "@misc{\nmoryossef2020at,\ntitle={At Your Fingertips: Automatic Piano Fingering Detection},\nauthor={Amit Moryossef and Yanai Elazar and Yoav Goldberg},\nyear={2020},\nurl={https://openreview.net/forum?id=H1MOqeHYvB}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "H1MOqeHYvB", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper2478/Authors", "ICLR.cc/2020/Conference/Paper2478/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper2478/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper2478/Reviewers", "ICLR.cc/2020/Conference/Paper2478/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper2478/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper2478/Authors|ICLR.cc/2020/Conference/Paper2478/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504140755, "tmdate": 1576860541409, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper2478/Authors", "ICLR.cc/2020/Conference/Paper2478/Reviewers", "ICLR.cc/2020/Conference/Paper2478/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper2478/-/Official_Comment"}}}, {"id": "S1lelcj1iS", "original": null, "number": 1, "cdate": 1573005800513, "ddate": null, "tcdate": 1573005800513, "tmdate": 1573005800513, "tddate": null, "forum": "H1MOqeHYvB", "replyto": "ryeHZxXPYB", "invitation": "ICLR.cc/2020/Conference/Paper2478/-/Official_Comment", "content": {"title": "Main reply to Review #2", "comment": "Thank you for your review.\n\nWe would like to address your review:\n- **... the rest of the paper is somewhat incremental/engineering piece ...** - while true, that engineering was involved, we think that in most steps of our pipeline we introduce new, novel methods / usages to tackle different issues. (described further in the rest of this comment).\n- **... which depends somehow on previous works (see Nakamura,2019)** - We don't see what you are referring to, as in their work they release a manually annotated dataset, while in this work we devise an unsupervised method to extract such annotations from videos and MIDI files.\n- **I fail to see much novel scientific contribution to the area of research (apart from the dataset) and I\u2019m not sure whether there are enough scientific technical advancements.** - I will now list the novel parts of this work, that were used in order to get a good dataset:\n1. We show how it is possible to segment each key of the piano.\n2. We show the failures of current pose detection models, and devise a new, general way to address such failures, that we show is robust - and for us, reduces 50% of the accumulative error.\n3. We design a new way to align between MIDI and piano video recordings, which is accurate up to the video sampling rate.\n4. We design an algorithm to assume \"collisions\" between the detected fingers in multiple frames, and the piano keys, from very noisy data.\n\n- **Furthermore, the experimental setting is somewhat limited, and it is not clear whether results are statistically significant.** - You are correct that we did not perform a statistical significance test, we will do such for the final version of the paper. We show 50% error reduction between previous SOTA and human agreement results. The experimental is not meant to devise a new method for piano fingering, instead, it is design to convince the reader that our data is indeed valuable, and not just noise, and we think it manages to show that.\n\nAgain, we would like to thank you, and perhaps get your feedback on what should be improved in this paper? What experiments/analysis you would like to see?"}, "signatures": ["ICLR.cc/2020/Conference/Paper2478/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper2478/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["amitmoryossef@gmail.com", "yanaiela@gmail.com", "yoav.goldberg@gmail.com"], "title": "At Your Fingertips: Automatic Piano Fingering Detection", "authors": ["Amit Moryossef", "Yanai Elazar", "Yoav Goldberg"], "pdf": "/pdf/654848b30a3510f4595c174bae1079a26b1367fe.pdf", "TL;DR": "We automatically extract fingering information from videos of piano performances, to be used in automatic fingering prediction models.", "abstract": "Automatic Piano Fingering is a hard task which computers can learn using data. As data collection is hard and expensive, we propose to automate this process by automatically extracting fingerings from public videos and MIDI files, using computer-vision techniques. Running this process on 90 videos results in the largest dataset for piano fingering with more than 150K notes. We show that when running a previously proposed model for automatic piano fingering on our dataset and then fine-tuning it on manually labeled piano fingering data, we achieve state-of-the-art results.\nIn addition to the fingering extraction method, we also introduce a novel method for transferring deep-learning computer-vision models to work on out-of-domain data, by fine-tuning it on out-of-domain augmentation proposed by a Generative Adversarial Network (GAN).\n\nFor demonstration, we anonymously release a visualization of the output of our process for a single video on https://youtu.be/Gfs1UWQhr5Q", "code": "https://drive.google.com/file/d/1kDPZSA7ppOaup9Q1Dab7bW4OXNh9mAQA/view?usp=sharing", "keywords": ["piano", "fingering", "dataset"], "paperhash": "moryossef|at_your_fingertips_automatic_piano_fingering_detection", "original_pdf": "/attachment/654848b30a3510f4595c174bae1079a26b1367fe.pdf", "_bibtex": "@misc{\nmoryossef2020at,\ntitle={At Your Fingertips: Automatic Piano Fingering Detection},\nauthor={Amit Moryossef and Yanai Elazar and Yoav Goldberg},\nyear={2020},\nurl={https://openreview.net/forum?id=H1MOqeHYvB}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "H1MOqeHYvB", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper2478/Authors", "ICLR.cc/2020/Conference/Paper2478/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper2478/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper2478/Reviewers", "ICLR.cc/2020/Conference/Paper2478/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper2478/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper2478/Authors|ICLR.cc/2020/Conference/Paper2478/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504140755, "tmdate": 1576860541409, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper2478/Authors", "ICLR.cc/2020/Conference/Paper2478/Reviewers", "ICLR.cc/2020/Conference/Paper2478/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper2478/-/Official_Comment"}}}, {"id": "rkxDbgiWYS", "original": null, "number": 1, "cdate": 1571037182839, "ddate": null, "tcdate": 1571037182839, "tmdate": 1572972333154, "tddate": null, "forum": "H1MOqeHYvB", "replyto": "H1MOqeHYvB", "invitation": "ICLR.cc/2020/Conference/Paper2478/-/Official_Review", "content": {"rating": "1: Reject", "experience_assessment": "I have published in this field for several years.", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #2478", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review": "<Strengths> \n+ This paper addresses an interesting and practically important problem: detection of piano fingering from videos and MIDI files. Fingering is a valuable source for piano learners and has to be manually annotated otherwise. The proposed approach is automatic and low-cost from playing videos. \n+ This paper collects a large-scale dataset for piano-fingering named APFD, including 90 finger-tagged pieces with 155K notes.\n+ The paper reads very well.\n\n\n<Weakness>\n1. One major weakness of this work is lack of technical novelty. \n- As described in section 3 in detail, the proposed approach consists of a sequence of well-known techniques (e.g. Faster R-CNN for hand detection and CycleGAN for finger pose estimation) and is largely based on lots of heuristics in every step of the procedure. \n- Thus, the method may be practically viable but bear little technical novelty.\n\n2. Experimental results are rather weak. \n- Only a single baseline is used in the existing PIG dataset, while no baseline method is compared for the new APFD dataset,  for which more baselines may need to be implemented and compared. \n- The proposed approach (64.1) is slightly worse than the previous SOTA (64.5) in the PIG dataset, although it is improved by fine-tuning with the APFD data that are not available for the previous SOTA. Thus, no experimental evidence is presented in the paper to convince that the proposed approach is better than existing ones.\n\n<Conclusion>\nAlthough this work is practically promising, my initial decision is \u2018reject\u2019 mainly due to lack of technical novelty and limited experiments. "}, "signatures": ["ICLR.cc/2020/Conference/Paper2478/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper2478/AnonReviewer1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["amitmoryossef@gmail.com", "yanaiela@gmail.com", "yoav.goldberg@gmail.com"], "title": "At Your Fingertips: Automatic Piano Fingering Detection", "authors": ["Amit Moryossef", "Yanai Elazar", "Yoav Goldberg"], "pdf": "/pdf/654848b30a3510f4595c174bae1079a26b1367fe.pdf", "TL;DR": "We automatically extract fingering information from videos of piano performances, to be used in automatic fingering prediction models.", "abstract": "Automatic Piano Fingering is a hard task which computers can learn using data. As data collection is hard and expensive, we propose to automate this process by automatically extracting fingerings from public videos and MIDI files, using computer-vision techniques. Running this process on 90 videos results in the largest dataset for piano fingering with more than 150K notes. We show that when running a previously proposed model for automatic piano fingering on our dataset and then fine-tuning it on manually labeled piano fingering data, we achieve state-of-the-art results.\nIn addition to the fingering extraction method, we also introduce a novel method for transferring deep-learning computer-vision models to work on out-of-domain data, by fine-tuning it on out-of-domain augmentation proposed by a Generative Adversarial Network (GAN).\n\nFor demonstration, we anonymously release a visualization of the output of our process for a single video on https://youtu.be/Gfs1UWQhr5Q", "code": "https://drive.google.com/file/d/1kDPZSA7ppOaup9Q1Dab7bW4OXNh9mAQA/view?usp=sharing", "keywords": ["piano", "fingering", "dataset"], "paperhash": "moryossef|at_your_fingertips_automatic_piano_fingering_detection", "original_pdf": "/attachment/654848b30a3510f4595c174bae1079a26b1367fe.pdf", "_bibtex": "@misc{\nmoryossef2020at,\ntitle={At Your Fingertips: Automatic Piano Fingering Detection},\nauthor={Amit Moryossef and Yanai Elazar and Yoav Goldberg},\nyear={2020},\nurl={https://openreview.net/forum?id=H1MOqeHYvB}\n}"}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "H1MOqeHYvB", "replyto": "H1MOqeHYvB", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper2478/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper2478/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1574947338260, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper2478/Reviewers"], "noninvitees": [], "tcdate": 1570237722265, "tmdate": 1574947338271, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper2478/-/Official_Review"}}}, {"id": "ryeHZxXPYB", "original": null, "number": 2, "cdate": 1571397629506, "ddate": null, "tcdate": 1571397629506, "tmdate": 1572972333066, "tddate": null, "forum": "H1MOqeHYvB", "replyto": "H1MOqeHYvB", "invitation": "ICLR.cc/2020/Conference/Paper2478/-/Official_Review", "content": {"rating": "3: Weak Reject", "experience_assessment": "I have read many papers in this area.", "review_assessment:_checking_correctness_of_derivations_and_theory": "N/A", "review_assessment:_checking_correctness_of_experiments": "N/A", "title": "Official Blind Review #2", "review_assessment:_thoroughness_in_paper_reading": "N/A", "review": "The paper is a nice piece of works which clearly articulates the objective and the subsequent discussion. The focus of the paper--i.e. disclose the difficulties of piano fingering data annotation and the proposal of automating this process by automatically extracting fingerings from public videos and MIDI files, using  computer-vision DNN-based algorithms \u2014although not really mainstream, it does provide some practical insights using a couple of experimental settings (piano fingering model and prediction) to help the readers. \n\nI really enjoyed reading this paper. I think that it can be considered a relevant and interesting piece of work, very well written and clear. Furthermore, providing new benchmarks/datasets/competitions for the AI community is always refreshing. Also, the results seem believable and solid, and potentially useful. \n\nMy only concern is that, although the rationale and utility of the paper is clear, the rest of the paper is somewhat incremental/engineering piece which depends somehow on previous works (see Nakamura,2019). I fail to see much novel scientific contribution to the area of research (apart from the dataset) and I\u2019m not sure whether there are enough scientific technical advancements. Furthermore, the experimental setting is somewhat limited, and it is not clear whether results are statistically significant.\n"}, "signatures": ["ICLR.cc/2020/Conference/Paper2478/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper2478/AnonReviewer2"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["amitmoryossef@gmail.com", "yanaiela@gmail.com", "yoav.goldberg@gmail.com"], "title": "At Your Fingertips: Automatic Piano Fingering Detection", "authors": ["Amit Moryossef", "Yanai Elazar", "Yoav Goldberg"], "pdf": "/pdf/654848b30a3510f4595c174bae1079a26b1367fe.pdf", "TL;DR": "We automatically extract fingering information from videos of piano performances, to be used in automatic fingering prediction models.", "abstract": "Automatic Piano Fingering is a hard task which computers can learn using data. As data collection is hard and expensive, we propose to automate this process by automatically extracting fingerings from public videos and MIDI files, using computer-vision techniques. Running this process on 90 videos results in the largest dataset for piano fingering with more than 150K notes. We show that when running a previously proposed model for automatic piano fingering on our dataset and then fine-tuning it on manually labeled piano fingering data, we achieve state-of-the-art results.\nIn addition to the fingering extraction method, we also introduce a novel method for transferring deep-learning computer-vision models to work on out-of-domain data, by fine-tuning it on out-of-domain augmentation proposed by a Generative Adversarial Network (GAN).\n\nFor demonstration, we anonymously release a visualization of the output of our process for a single video on https://youtu.be/Gfs1UWQhr5Q", "code": "https://drive.google.com/file/d/1kDPZSA7ppOaup9Q1Dab7bW4OXNh9mAQA/view?usp=sharing", "keywords": ["piano", "fingering", "dataset"], "paperhash": "moryossef|at_your_fingertips_automatic_piano_fingering_detection", "original_pdf": "/attachment/654848b30a3510f4595c174bae1079a26b1367fe.pdf", "_bibtex": "@misc{\nmoryossef2020at,\ntitle={At Your Fingertips: Automatic Piano Fingering Detection},\nauthor={Amit Moryossef and Yanai Elazar and Yoav Goldberg},\nyear={2020},\nurl={https://openreview.net/forum?id=H1MOqeHYvB}\n}"}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "H1MOqeHYvB", "replyto": "H1MOqeHYvB", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper2478/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper2478/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1574947338260, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper2478/Reviewers"], "noninvitees": [], "tcdate": 1570237722265, "tmdate": 1574947338271, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper2478/-/Official_Review"}}}, {"id": "BJevc4E2tS", "original": null, "number": 3, "cdate": 1571730574570, "ddate": null, "tcdate": 1571730574570, "tmdate": 1572972333029, "tddate": null, "forum": "H1MOqeHYvB", "replyto": "H1MOqeHYvB", "invitation": "ICLR.cc/2020/Conference/Paper2478/-/Official_Review", "content": {"rating": "1: Reject", "experience_assessment": "I do not know much about this area.", "review_assessment:_checking_correctness_of_derivations_and_theory": "N/A", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #3", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review": "In this paper, the authors proposed an automatic piano fingering algorithm, that accepts YouTube videos and corresponding MIDI files and outputs fingering prediction for each note. The claimed contribution is two-fold: First, they proposed the algorithm, and second, they claim that the algorithm can be used to automatically generate large datasets for piano fingering problems. The motivation is clearly stated and convincing. The overall algorithm is mainly described. \n\nHowever, I would like to reject this paper. Major issues:\n\n* Some key information is missing in Section 3.6, which is the only section that shows technical details: What is X_{n_k}? How is that related to the estimated finger poses? What is the function f in the definition of function g? (Also, it would be helpful to label the equations for clarification.) Are you doing Bayesian inference? With the key information missing, it is hard to fully understand the remaining technical details in this section. \n* Their experimental results cannot properly support their claims. In Section 4.2, the authors try to show the strength of their proposed piano fingering algorithm by comparing their automatically annotated dataset APFD with an existing manually annotated dataset PIG. The authors showed the evaluation results of models trained and fine-tuned with different datasets. However, this is not an acceptable comparison for me, due to several reasons.\nFirst, in order to show the strength of automatic piano fingering prediction, it is much better to directly run the prediction algorithm on datasets with known labels. According to the related work section, there is at least one existing work by Takegawa et al. that uses videos and MIDI files to detect piano fingering. Can you compare your algorithm with theirs? \nSecond, it is essentially unreliable to compare two datasets by comparing the performance of two prediction models, as there are too many implementation details that are almost impossible to control. \nThird, it is not clear how we should compare the testing errors in Table 2. Yes, a model initially trained on PIG and fine-tuned on APFD may perform better than a model trained merely on APFD, but does that suggest anything (and the advantage is just 0.4%)? Similarly, the experimental result that an MLP model initially trained on APFD then fine-tuned with PIG works better than an HMM model that is trained with PIG data alone cannot prove anything. There are too many possible reasons that may lead to this experimental result. \n* How is this method more attractable than the existing ones? There are neither experimental comparisons nor high-level justifications of why the existing algorithms are not applicable to the given scenario. In Section 2, although the authors described a good number of existing work on piano-fingering and their drawbacks, they failed to point out the strength of their paper as a comparison. As a result, the strength of this paper is still unclear after reading this section. How does this paper avoid the drawbacks of these previous papers? \n* The writing of this paper needs to be greatly improved. It takes a lot of effort to literally understand this paper: There may be missing parts, misplaced clauses, and broken logic between sentences. I have listed several examples in the minor issues part. \n\n\nMinor issues:\n* In the first paragraph of Section 1: The sentence before 'In practice ...' is incomplete. \n* In the last paragraph of Section 1: Missing brackets for \\textsection 3.3 and \\textsection 3.4. Also, 'on A new dataset we introduce' should be 'on THE new dataset we introduce'. \n* On page 3, the sentence 'In this work, we continue the transition of search-based methods that optimize a set of constraints with learning methods that ...' is not making sense to me. Do you mean that your work is an extension of search-based methods, or do you mean that your work is not a search-based method? Also, are you optimizing a set of constraints, or optimizing with a set of constraints? \n* On page 3, the last sentence in Section 2: '... and adapt their model to compare TO our ...' should be '... and adapt their model to compare WITH our ...'. The last part of this sentence is also a bit confusing: How do you compare a model with a dataset?\n* On page 4, the paragraph starting with 'MIDI files': The first two sentences are almost the same; the period between them is missing. I guess one of them should be deleted. The following sentences in this paragraph are also subject to grammatical errors. For example, the sentence 'It consists of a sequence of events ... to carry out, WHEN, and allows for ...' is not a complete sentence. 'We only use videos that come along with a MIDI file' -> 'We only use videos that come along with MIDI files'. \n* On page 5, last paragraph in Section 3.3: 'highest probability defections' -> 'highest probability detections'.\n* The last paragraph on Page 5: 'Using off-the-shelve ...' -> 'Use off-the-shelf ...'.\n* In Section 4.2.1, the corresponding result is Table 2, instead of Table 1. "}, "signatures": ["ICLR.cc/2020/Conference/Paper2478/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper2478/AnonReviewer3"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["amitmoryossef@gmail.com", "yanaiela@gmail.com", "yoav.goldberg@gmail.com"], "title": "At Your Fingertips: Automatic Piano Fingering Detection", "authors": ["Amit Moryossef", "Yanai Elazar", "Yoav Goldberg"], "pdf": "/pdf/654848b30a3510f4595c174bae1079a26b1367fe.pdf", "TL;DR": "We automatically extract fingering information from videos of piano performances, to be used in automatic fingering prediction models.", "abstract": "Automatic Piano Fingering is a hard task which computers can learn using data. As data collection is hard and expensive, we propose to automate this process by automatically extracting fingerings from public videos and MIDI files, using computer-vision techniques. Running this process on 90 videos results in the largest dataset for piano fingering with more than 150K notes. We show that when running a previously proposed model for automatic piano fingering on our dataset and then fine-tuning it on manually labeled piano fingering data, we achieve state-of-the-art results.\nIn addition to the fingering extraction method, we also introduce a novel method for transferring deep-learning computer-vision models to work on out-of-domain data, by fine-tuning it on out-of-domain augmentation proposed by a Generative Adversarial Network (GAN).\n\nFor demonstration, we anonymously release a visualization of the output of our process for a single video on https://youtu.be/Gfs1UWQhr5Q", "code": "https://drive.google.com/file/d/1kDPZSA7ppOaup9Q1Dab7bW4OXNh9mAQA/view?usp=sharing", "keywords": ["piano", "fingering", "dataset"], "paperhash": "moryossef|at_your_fingertips_automatic_piano_fingering_detection", "original_pdf": "/attachment/654848b30a3510f4595c174bae1079a26b1367fe.pdf", "_bibtex": "@misc{\nmoryossef2020at,\ntitle={At Your Fingertips: Automatic Piano Fingering Detection},\nauthor={Amit Moryossef and Yanai Elazar and Yoav Goldberg},\nyear={2020},\nurl={https://openreview.net/forum?id=H1MOqeHYvB}\n}"}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "H1MOqeHYvB", "replyto": "H1MOqeHYvB", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper2478/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper2478/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1574947338260, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper2478/Reviewers"], "noninvitees": [], "tcdate": 1570237722265, "tmdate": 1574947338271, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper2478/-/Official_Review"}}}], "count": 7}