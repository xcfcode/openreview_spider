{"notes": [{"tddate": null, "replyto": null, "ddate": null, "tmdate": 1528124442516, "tcdate": 1518470675572, "number": 285, "cdate": 1518470675572, "id": "S1nzIYJvz", "invitation": "ICLR.cc/2018/Workshop/-/Submission", "forum": "S1nzIYJvz", "signatures": ["~Tian_Guo2"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Workshop"], "content": {"title": "An interpretable LSTM neural network for autoregressive exogenous model", "abstract": "In this paper, we propose an interpretable LSTM recurrent neural network, i.e., multi-variable LSTM for time series with exogenous variables. Currently, widely used attention mechanism in recurrent neural networks mostly focuses on the temporal aspect of data and falls short of characterizing variable importance. To this end, our multi-variable LSTM equipped with tensorized hidden states is developed to learn variable specific representations, which give rise to both temporal and variable level attention. Preliminary experiments demonstrate comparable prediction performance of multi-variable LSTM w.r.t. encoder-decoder based baselines. More interestingly, variable importance in real datasets characterized by the variable attention is highly in line with that determined by statistical Granger causality test, which exhibits the prospect of multi-variable LSTM as a simple and uniform end-to-end framework for both forecasting and knowledge discovery.", "paperhash": "guo|an_interpretable_lstm_neural_network_for_autoregressive_exogenous_model", "_bibtex": "@misc{\n  guo2018an,\n  title={An interpretable LSTM neural network for autoregressive exogenous model},\n  author={Tian Guo and Tao Lin and Yao Lu},\n  year={2018},\n  url={https://openreview.net/forum?id=S1nzIYJvz}\n}", "authorids": ["tian.guo@gess.ethz.ch", "tao.lin@epfl.ch", "yao.lu@tendcloud.com"], "authors": ["Tian Guo", "Tao Lin", "Yao Lu"], "keywords": [], "pdf": "/pdf/456e73594f71eb99ef06b3c57778a32e42d00f79.pdf"}, "nonreaders": [], "details": {"replyCount": 4, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1518472800000, "tmdate": 1518474081690, "id": "ICLR.cc/2018/Workshop/-/Submission", "writers": ["ICLR.cc/2018/Workshop"], "signatures": ["ICLR.cc/2018/Workshop"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": null, "replyto": null, "writers": {"values": ["ICLR.cc/2018/Workshop"]}, "signatures": {"values-regex": "~.*|ICLR.cc/2018/Workshop", "description": "Your authorized identity to be associated with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"pdf": {"required": true, "order": 9, "value-regex": "upload", "description": "Upload a PDF file that ends with .pdf"}, "title": {"required": true, "order": 1, "description": "Title of paper.", "value-regex": ".{1,250}"}, "abstract": {"required": true, "order": 8, "description": "Abstract of paper.", "value-regex": "[\\S\\s]{1,5000}"}, "authors": {"required": true, "order": 2, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of author names. Please provide real names; identities will be anonymized."}, "keywords": {"order": 6, "values-regex": "(^$)|[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of keywords."}, "TL;DR": {"required": false, "order": 7, "description": "\"Too Long; Didn't Read\": a short sentence describing your paper", "value-regex": "[^\\n]{0,500}"}, "authorids": {"required": true, "order": 3, "values-regex": "([a-z0-9_\\-\\.]{2,}@[a-z0-9_\\-\\.]{2,}\\.[a-z]{2,},){0,}([a-z0-9_\\-\\.]{2,}@[a-z0-9_\\-\\.]{2,}\\.[a-z]{2,})", "description": "Comma separated list of author email addresses, lowercased, in the same order as above. For authors with existing OpenReview accounts, please make sure that the provided email address(es) match those listed in the author's profile. Please provide real emails; identities will be anonymized."}}}, "nonreaders": [], "noninvitees": [], "expdate": 1526248800000, "cdate": 1518474081690}}}, {"tddate": null, "ddate": null, "original": null, "tmdate": 1521582732445, "tcdate": 1520669715404, "number": 1, "cdate": 1520669715404, "id": "Bksf4M-Fz", "invitation": "ICLR.cc/2018/Workshop/-/Paper285/Official_Review", "forum": "S1nzIYJvz", "replyto": "S1nzIYJvz", "signatures": ["ICLR.cc/2018/Workshop/Paper285/AnonReviewer2"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Workshop/Paper285/AnonReviewer2"], "content": {"title": "Better model for exogenous time series", "rating": "7: Good paper, accept", "review": "The paper is focused on sequential data with exogenous time series. Previous attention-based models on this kind of dataset used multiple RNNs for each time series (Choi et al., 2016; Qin et al., 2017). The paper instead proposes to use single RNN to model the data by decomposing the hidden state of the RNN into several sub-states, each of which corresponding to each time series, which are individually attended but concatenated for the recurrent update. The paper shows statistically significant error reduction compared to the baselines on two datasets. The visualization also seems to be convincing. The validity of the paper's hypothesis on the model could be stronger if the model is tested on benchmarked datasets (it seems the datasets used in the paper are not used by previous papers?).\n", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "An interpretable LSTM neural network for autoregressive exogenous model", "abstract": "In this paper, we propose an interpretable LSTM recurrent neural network, i.e., multi-variable LSTM for time series with exogenous variables. Currently, widely used attention mechanism in recurrent neural networks mostly focuses on the temporal aspect of data and falls short of characterizing variable importance. To this end, our multi-variable LSTM equipped with tensorized hidden states is developed to learn variable specific representations, which give rise to both temporal and variable level attention. Preliminary experiments demonstrate comparable prediction performance of multi-variable LSTM w.r.t. encoder-decoder based baselines. More interestingly, variable importance in real datasets characterized by the variable attention is highly in line with that determined by statistical Granger causality test, which exhibits the prospect of multi-variable LSTM as a simple and uniform end-to-end framework for both forecasting and knowledge discovery.", "paperhash": "guo|an_interpretable_lstm_neural_network_for_autoregressive_exogenous_model", "_bibtex": "@misc{\n  guo2018an,\n  title={An interpretable LSTM neural network for autoregressive exogenous model},\n  author={Tian Guo and Tao Lin and Yao Lu},\n  year={2018},\n  url={https://openreview.net/forum?id=S1nzIYJvz}\n}", "authorids": ["tian.guo@gess.ethz.ch", "tao.lin@epfl.ch", "yao.lu@tendcloud.com"], "authors": ["Tian Guo", "Tao Lin", "Yao Lu"], "keywords": [], "pdf": "/pdf/456e73594f71eb99ef06b3c57778a32e42d00f79.pdf"}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1520657999000, "tmdate": 1521582732240, "id": "ICLR.cc/2018/Workshop/-/Paper285/Official_Review", "writers": ["ICLR.cc/2018/Workshop"], "signatures": ["ICLR.cc/2018/Workshop"], "readers": ["everyone"], "invitees": ["ICLR.cc/2018/Workshop/Paper285/Reviewers"], "noninvitees": ["ICLR.cc/2018/Workshop/Paper285/AnonReviewer2", "ICLR.cc/2018/Workshop/Paper285/AnonReviewer3", "ICLR.cc/2018/Workshop/Paper285/AnonReviewer1"], "reply": {"forum": "S1nzIYJvz", "replyto": "S1nzIYJvz", "writers": {"values-regex": "ICLR.cc/2018/Workshop/Paper285/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2018/Workshop/Paper285/AnonReviewer[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"required": true, "order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"required": true, "order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "value-regex": "[\\S\\s]{1,200000}"}, "rating": {"required": true, "order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"required": true, "order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1528433999000, "cdate": 1521582732240}}}, {"tddate": null, "ddate": null, "original": null, "tmdate": 1521582717607, "tcdate": 1520685616880, "number": 2, "cdate": 1520685616880, "id": "ByF4f8-Kz", "invitation": "ICLR.cc/2018/Workshop/-/Paper285/Official_Review", "forum": "S1nzIYJvz", "replyto": "S1nzIYJvz", "signatures": ["ICLR.cc/2018/Workshop/Paper285/AnonReviewer3"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Workshop/Paper285/AnonReviewer3"], "content": {"title": "Multivariate LSTM for time-series prediction", "rating": "7: Good paper, accept", "review": "The paper studies the problem of time-series prediction given auxiliary variables. Instead of joining variables together as in standard RNNs, the paper allocates states and parameters per variable, and at the same time allows for cross-correlation among variables. This makes attention to variable importance easier to model. Experiments demonstrate the effectiveness of the proposed approach.\n\nOverall the paper is presented relatively well, and there are elements of novelty in the model architecture in the context of time-series prediction. A figure of the multivariate LSTM may assist readers a bit more. A related work is matrix-centric RNN, studied in: https://arxiv.org/abs/1703.01454\n", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "An interpretable LSTM neural network for autoregressive exogenous model", "abstract": "In this paper, we propose an interpretable LSTM recurrent neural network, i.e., multi-variable LSTM for time series with exogenous variables. Currently, widely used attention mechanism in recurrent neural networks mostly focuses on the temporal aspect of data and falls short of characterizing variable importance. To this end, our multi-variable LSTM equipped with tensorized hidden states is developed to learn variable specific representations, which give rise to both temporal and variable level attention. Preliminary experiments demonstrate comparable prediction performance of multi-variable LSTM w.r.t. encoder-decoder based baselines. More interestingly, variable importance in real datasets characterized by the variable attention is highly in line with that determined by statistical Granger causality test, which exhibits the prospect of multi-variable LSTM as a simple and uniform end-to-end framework for both forecasting and knowledge discovery.", "paperhash": "guo|an_interpretable_lstm_neural_network_for_autoregressive_exogenous_model", "_bibtex": "@misc{\n  guo2018an,\n  title={An interpretable LSTM neural network for autoregressive exogenous model},\n  author={Tian Guo and Tao Lin and Yao Lu},\n  year={2018},\n  url={https://openreview.net/forum?id=S1nzIYJvz}\n}", "authorids": ["tian.guo@gess.ethz.ch", "tao.lin@epfl.ch", "yao.lu@tendcloud.com"], "authors": ["Tian Guo", "Tao Lin", "Yao Lu"], "keywords": [], "pdf": "/pdf/456e73594f71eb99ef06b3c57778a32e42d00f79.pdf"}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1520657999000, "tmdate": 1521582732240, "id": "ICLR.cc/2018/Workshop/-/Paper285/Official_Review", "writers": ["ICLR.cc/2018/Workshop"], "signatures": ["ICLR.cc/2018/Workshop"], "readers": ["everyone"], "invitees": ["ICLR.cc/2018/Workshop/Paper285/Reviewers"], "noninvitees": ["ICLR.cc/2018/Workshop/Paper285/AnonReviewer2", "ICLR.cc/2018/Workshop/Paper285/AnonReviewer3", "ICLR.cc/2018/Workshop/Paper285/AnonReviewer1"], "reply": {"forum": "S1nzIYJvz", "replyto": "S1nzIYJvz", "writers": {"values-regex": "ICLR.cc/2018/Workshop/Paper285/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2018/Workshop/Paper285/AnonReviewer[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"required": true, "order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"required": true, "order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "value-regex": "[\\S\\s]{1,200000}"}, "rating": {"required": true, "order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"required": true, "order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1528433999000, "cdate": 1521582732240}}}, {"tddate": null, "ddate": null, "original": null, "tmdate": 1521582677888, "tcdate": 1520734593549, "number": 3, "cdate": 1520734593549, "id": "r1FFbzGKM", "invitation": "ICLR.cc/2018/Workshop/-/Paper285/Official_Review", "forum": "S1nzIYJvz", "replyto": "S1nzIYJvz", "signatures": ["ICLR.cc/2018/Workshop/Paper285/AnonReviewer1"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Workshop/Paper285/AnonReviewer1"], "content": {"title": "interesting idea, but hard to follow in section 3", "rating": "4: Ok but not good enough - rejection", "review": "Although I am not familiar with the ARX problem, but I agree on the limitation of LSTM mentioned in this paper. To my understanding, the idea of this paper is interesting. \n\nOn the other hand, I find it is really hard to follow the technical detail in section 3, especially the explanation of the equation of computing j_t. Without a good understanding of the technical part, I am not sure I can appreciate the value of the modeling part. ", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "An interpretable LSTM neural network for autoregressive exogenous model", "abstract": "In this paper, we propose an interpretable LSTM recurrent neural network, i.e., multi-variable LSTM for time series with exogenous variables. Currently, widely used attention mechanism in recurrent neural networks mostly focuses on the temporal aspect of data and falls short of characterizing variable importance. To this end, our multi-variable LSTM equipped with tensorized hidden states is developed to learn variable specific representations, which give rise to both temporal and variable level attention. Preliminary experiments demonstrate comparable prediction performance of multi-variable LSTM w.r.t. encoder-decoder based baselines. More interestingly, variable importance in real datasets characterized by the variable attention is highly in line with that determined by statistical Granger causality test, which exhibits the prospect of multi-variable LSTM as a simple and uniform end-to-end framework for both forecasting and knowledge discovery.", "paperhash": "guo|an_interpretable_lstm_neural_network_for_autoregressive_exogenous_model", "_bibtex": "@misc{\n  guo2018an,\n  title={An interpretable LSTM neural network for autoregressive exogenous model},\n  author={Tian Guo and Tao Lin and Yao Lu},\n  year={2018},\n  url={https://openreview.net/forum?id=S1nzIYJvz}\n}", "authorids": ["tian.guo@gess.ethz.ch", "tao.lin@epfl.ch", "yao.lu@tendcloud.com"], "authors": ["Tian Guo", "Tao Lin", "Yao Lu"], "keywords": [], "pdf": "/pdf/456e73594f71eb99ef06b3c57778a32e42d00f79.pdf"}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1520657999000, "tmdate": 1521582732240, "id": "ICLR.cc/2018/Workshop/-/Paper285/Official_Review", "writers": ["ICLR.cc/2018/Workshop"], "signatures": ["ICLR.cc/2018/Workshop"], "readers": ["everyone"], "invitees": ["ICLR.cc/2018/Workshop/Paper285/Reviewers"], "noninvitees": ["ICLR.cc/2018/Workshop/Paper285/AnonReviewer2", "ICLR.cc/2018/Workshop/Paper285/AnonReviewer3", "ICLR.cc/2018/Workshop/Paper285/AnonReviewer1"], "reply": {"forum": "S1nzIYJvz", "replyto": "S1nzIYJvz", "writers": {"values-regex": "ICLR.cc/2018/Workshop/Paper285/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2018/Workshop/Paper285/AnonReviewer[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"required": true, "order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"required": true, "order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "value-regex": "[\\S\\s]{1,200000}"}, "rating": {"required": true, "order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"required": true, "order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1528433999000, "cdate": 1521582732240}}}, {"tddate": null, "ddate": null, "original": null, "tmdate": 1521573559373, "tcdate": 1521573559373, "number": 72, "cdate": 1521573559045, "id": "r11aC00YM", "invitation": "ICLR.cc/2018/Workshop/-/Acceptance_Decision", "forum": "S1nzIYJvz", "replyto": "S1nzIYJvz", "signatures": ["ICLR.cc/2018/Workshop/Program_Chairs"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Workshop/Program_Chairs"], "content": {"decision": "Accept", "title": "ICLR 2018 Workshop Acceptance Decision", "comment": "Congratulations, your paper was accepted to the ICLR workshop."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "An interpretable LSTM neural network for autoregressive exogenous model", "abstract": "In this paper, we propose an interpretable LSTM recurrent neural network, i.e., multi-variable LSTM for time series with exogenous variables. Currently, widely used attention mechanism in recurrent neural networks mostly focuses on the temporal aspect of data and falls short of characterizing variable importance. To this end, our multi-variable LSTM equipped with tensorized hidden states is developed to learn variable specific representations, which give rise to both temporal and variable level attention. Preliminary experiments demonstrate comparable prediction performance of multi-variable LSTM w.r.t. encoder-decoder based baselines. More interestingly, variable importance in real datasets characterized by the variable attention is highly in line with that determined by statistical Granger causality test, which exhibits the prospect of multi-variable LSTM as a simple and uniform end-to-end framework for both forecasting and knowledge discovery.", "paperhash": "guo|an_interpretable_lstm_neural_network_for_autoregressive_exogenous_model", "_bibtex": "@misc{\n  guo2018an,\n  title={An interpretable LSTM neural network for autoregressive exogenous model},\n  author={Tian Guo and Tao Lin and Yao Lu},\n  year={2018},\n  url={https://openreview.net/forum?id=S1nzIYJvz}\n}", "authorids": ["tian.guo@gess.ethz.ch", "tao.lin@epfl.ch", "yao.lu@tendcloud.com"], "authors": ["Tian Guo", "Tao Lin", "Yao Lu"], "keywords": [], "pdf": "/pdf/456e73594f71eb99ef06b3c57778a32e42d00f79.pdf"}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "tmdate": 1518629844880, "id": "ICLR.cc/2018/Workshop/-/Acceptance_Decision", "writers": ["ICLR.cc/2018/Workshop"], "signatures": ["ICLR.cc/2018/Workshop"], "readers": ["everyone"], "invitees": ["ICLR.cc/2018/Workshop/Program_Chairs"], "reply": {"forum": null, "replyto": null, "invitation": "ICLR.cc/2018/Workshop/-/Submission", "writers": {"values": ["ICLR.cc/2018/Workshop/Program_Chairs"]}, "signatures": {"description": "How your identity will be displayed with the above content.", "values": ["ICLR.cc/2018/Workshop/Program_Chairs"]}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["ICLR.cc/2018/Workshop/Program_Chairs", "everyone"]}, "content": {"title": {"required": true, "order": 1, "value": "ICLR 2018 Workshop Acceptance Decision"}, "comment": {"required": false, "order": 3, "description": "(optional) Comment on this decision.", "value-regex": "[\\S\\s]{0,5000}"}, "decision": {"required": true, "order": 2, "value-dropdown": ["Accept", "Reject"]}}}, "nonreaders": [], "noninvitees": [], "cdate": 1518629844880}}}], "count": 5}