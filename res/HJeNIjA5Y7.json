{"notes": [{"id": "HJeNIjA5Y7", "original": "SyeSC4f5FX", "number": 167, "cdate": 1538087756180, "ddate": null, "tcdate": 1538087756180, "tmdate": 1545355399324, "tddate": null, "forum": "HJeNIjA5Y7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Image Score: how to select useful samples", "abstract": "There has long been debates on how we could interpret neural networks and understand the decisions our models make. Specifically, why deep neural networks tend to be error-prone when dealing with samples that output low softmax scores. We present an efficient approach to measure the confidence of decision-making steps by statistically investigating each unit's contribution to that decision. Instead of focusing on how the models react on datasets, we study the datasets themselves given a pre-trained model. Our approach is capable of assigning a score to each sample within a dataset that measures the frequency of occurrence of that sample's chain of activation. We demonstrate with experiments that our method could select useful samples to improve deep neural networks in a semi-supervised leaning setting.", "keywords": [], "authorids": ["zsmx1996@utexas.edu", "jialinwu@utexas.edu"], "authors": ["Simiao Zuo", "Jialin Wu"], "pdf": "/pdf/e953f47303981df37fea48b61d25b82f968726cb.pdf", "paperhash": "zuo|image_score_how_to_select_useful_samples", "_bibtex": "@misc{\nzuo2019image,\ntitle={Image Score: how to select useful samples},\nauthor={Simiao Zuo and Jialin Wu},\nyear={2019},\nurl={https://openreview.net/forum?id=HJeNIjA5Y7},\n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"replyCount": 4, "writable": false, "overwriting": [], "revisions": false, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Blind_Submission", "rdate": null, "ddate": null, "expdate": null, "duedate": 1538085600000, "tmdate": 1538142958393, "tddate": null, "super": null, "final": null, "reply": {"signatures": {"values": ["ICLR.cc/2019/Conference"]}, "forum": null, "readers": {"values": ["everyone"]}, "replyto": null, "content": {"authorids": {"values-regex": ".*"}, "authors": {"values": ["Anonymous"]}}, "writers": {"values": ["ICLR.cc/2019/Conference"]}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["~"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": null, "taskCompletionCount": null, "transform": null, "cdate": 1538142958393}}, "tauthor": "OpenReview.net"}, {"id": "rkl-Umrle4", "original": null, "number": 1, "cdate": 1544733513393, "ddate": null, "tcdate": 1544733513393, "tmdate": 1545354512980, "tddate": null, "forum": "HJeNIjA5Y7", "replyto": "HJeNIjA5Y7", "invitation": "ICLR.cc/2019/Conference/-/Paper167/Meta_Review", "content": {"metareview": "Reviewers are in full agreement for rejection.", "confidence": "4: The area chair is confident but not absolutely certain", "recommendation": "Reject", "title": "Clear ratings of reject from reviewers"}, "signatures": ["ICLR.cc/2019/Conference/Paper167/Area_Chair1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference/Paper167/Area_Chair1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Image Score: how to select useful samples", "abstract": "There has long been debates on how we could interpret neural networks and understand the decisions our models make. Specifically, why deep neural networks tend to be error-prone when dealing with samples that output low softmax scores. We present an efficient approach to measure the confidence of decision-making steps by statistically investigating each unit's contribution to that decision. Instead of focusing on how the models react on datasets, we study the datasets themselves given a pre-trained model. Our approach is capable of assigning a score to each sample within a dataset that measures the frequency of occurrence of that sample's chain of activation. We demonstrate with experiments that our method could select useful samples to improve deep neural networks in a semi-supervised leaning setting.", "keywords": [], "authorids": ["zsmx1996@utexas.edu", "jialinwu@utexas.edu"], "authors": ["Simiao Zuo", "Jialin Wu"], "pdf": "/pdf/e953f47303981df37fea48b61d25b82f968726cb.pdf", "paperhash": "zuo|image_score_how_to_select_useful_samples", "_bibtex": "@misc{\nzuo2019image,\ntitle={Image Score: how to select useful samples},\nauthor={Simiao Zuo and Jialin Wu},\nyear={2019},\nurl={https://openreview.net/forum?id=HJeNIjA5Y7},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper167/Meta_Review", "rdate": null, "ddate": null, "expdate": null, "duedate": 1541548800000, "tmdate": 1545353312942, "tddate": null, "super": null, "final": null, "reply": {"forum": "HJeNIjA5Y7", "replyto": "HJeNIjA5Y7", "readers": {"description": "Select all user groups that should be able to read this comment. Selecting 'All Users' will allow paper authors, reviewers, area chairs, and program chairs to view this comment.", "values": ["everyone"]}, "signatures": {"description": "How your identity will be displayed with the above content.", "values-regex": "ICLR.cc/2019/Conference/Paper167/Area_Chair[0-9]+"}, "writers": {"description": "Users that may modify this record.", "values-regex": "ICLR.cc/2019/Conference/Paper167/Area_Chair[0-9]+"}, "content": {"title": {"order": 1, "value-regex": ".{1,500}", "description": "Brief summary of your review.", "required": true}, "metareview": {"order": 2, "value-regex": "[\\S\\s]{1,5000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "required": true}, "recommendation": {"order": 3, "value-dropdown": ["Accept (Oral)", "Accept (Poster)", "Reject"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The area chair is absolutely certain", "4: The area chair is confident but not absolutely certain", "3: The area chair is somewhat confident", "2: The area chair is not sure", "1: The area chair's evaluation is an educated guess"], "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper167/Area_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": false, "taskCompletionCount": null, "transform": null, "cdate": 1545353312942}}}, {"id": "SJexKHwa3Q", "original": null, "number": 3, "cdate": 1541399928324, "ddate": null, "tcdate": 1541399928324, "tmdate": 1541534226848, "tddate": null, "forum": "HJeNIjA5Y7", "replyto": "HJeNIjA5Y7", "invitation": "ICLR.cc/2019/Conference/-/Paper167/Official_Review", "content": {"title": "Intresting work, but the effectiveness of the proposed method is not validated", "review": "The idea of calculating a score to indicate the usefulness of a sample for training deep networks by analyzing the neural activations in semi-supervised learning is interesting.\n\nHowever, the effectiveness of the proposed method is not validated. In the cifar-10 semi-supervised image classification experiment, other semi-supervised learning methods are not compared. In my experiments, simply applying the trained model in the labeled data to obtain pseudo labels on the unlabeled data can obtain significant improvements.\n\nTheoretically, the proposed scoring method uses the pre-trained model to obtain correct activations that has two problems: (1) The evolving power that may be produced by the unlabeled data is constrained. (2) If there are a few numbers of labeled examples, it is very hard to learn a network; thus, the correct activation is not reliable. ", "rating": "4: Ok but not good enough - rejection", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "signatures": ["ICLR.cc/2019/Conference/Paper167/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Image Score: how to select useful samples", "abstract": "There has long been debates on how we could interpret neural networks and understand the decisions our models make. Specifically, why deep neural networks tend to be error-prone when dealing with samples that output low softmax scores. We present an efficient approach to measure the confidence of decision-making steps by statistically investigating each unit's contribution to that decision. Instead of focusing on how the models react on datasets, we study the datasets themselves given a pre-trained model. Our approach is capable of assigning a score to each sample within a dataset that measures the frequency of occurrence of that sample's chain of activation. We demonstrate with experiments that our method could select useful samples to improve deep neural networks in a semi-supervised leaning setting.", "keywords": [], "authorids": ["zsmx1996@utexas.edu", "jialinwu@utexas.edu"], "authors": ["Simiao Zuo", "Jialin Wu"], "pdf": "/pdf/e953f47303981df37fea48b61d25b82f968726cb.pdf", "paperhash": "zuo|image_score_how_to_select_useful_samples", "_bibtex": "@misc{\nzuo2019image,\ntitle={Image Score: how to select useful samples},\nauthor={Simiao Zuo and Jialin Wu},\nyear={2019},\nurl={https://openreview.net/forum?id=HJeNIjA5Y7},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper167/Official_Review", "cdate": 1542234523467, "expdate": 1552335264000, "duedate": 1541196000000, "reply": {"forum": "HJeNIjA5Y7", "replyto": "HJeNIjA5Y7", "readers": {"description": "The users who will be allowed to read the reply content.", "values": ["everyone"]}, "nonreaders": {"values": []}, "signatures": {"description": "How your identity will be displayed with the above content.", "values-regex": "ICLR.cc/2019/Conference/Paper167/AnonReviewer[0-9]+"}, "writers": {"description": "Users that may modify this record.", "values": ["ICLR.cc/2019/Conference"]}, "content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "required": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}}, "multiReply": false, "tcdate": 1552335663591, "tmdate": 1552335663591, "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "invitees": ["ICLR.cc/2019/Conference/Paper167/Reviewers"], "noninvitees": [], "signatures": ["ICLR.cc/2019/Conference"]}}}, {"id": "BklebLM2h7", "original": null, "number": 2, "cdate": 1541314039792, "ddate": null, "tcdate": 1541314039792, "tmdate": 1541534226640, "tddate": null, "forum": "HJeNIjA5Y7", "replyto": "HJeNIjA5Y7", "invitation": "ICLR.cc/2019/Conference/-/Paper167/Official_Review", "content": {"title": "Not likely to be significant enough", "review": "This paper proposes image score, to use the amount of strong activations in each single image compared with the average activation on the entire dataset as a metric of how well the image is interpreted by a particular deep model. I am not sure whether that intuition makes sense, and there seem to be a lot of ways the simplistic equation can be broken. Section 2.3 shows some intuition of a higher score corresponding to higher testing accuracy, but somehow is done only on 1 class in CIFAR and I don't think that is generalizable to other classes and especially other classification problems.\n\nThe paper claims interpretability but I don't see any experiments verifying interpretability. The experiments are done on a semi-supervised learning task, where the \"image score\" is used to select some unlabeled examples as labeled by trusting a partially trained classifier. Hence we would have to evaluate it as a semi-supervised deep learning paper. Note that the amount of labeled examples in this paper is significantly higher than most semi-supervised approaches, which leaves the question that if extremely few supervised examples have been used, whether this approach will already fail. Although the model showed some improvements over the baseline, there has been no comparison at all with any existing semi-supervised deep learning approaches. Any semi-supervised learning approach usually outperforms the supervised baseline (used in this paper) by a bit, so I don't quite seem to believe that the results reported in this paper is significant enough. One can refer to the following paper for a few relatively new semi-supervised learning approaches:\n\nhttps://arxiv.org/pdf/1804.09170.pdf\n\nTable 4 is more baffling and less convincing. Because deep networks are volatile, it is hard to show this kind of result and hope people will be convinced. I would rather the author has trained both approaches to completion and then compare the end result. Also we still need comparisons with state-of-the-art semi-supervised learning approaches.", "rating": "4: Ok but not good enough - rejection", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["ICLR.cc/2019/Conference/Paper167/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Image Score: how to select useful samples", "abstract": "There has long been debates on how we could interpret neural networks and understand the decisions our models make. Specifically, why deep neural networks tend to be error-prone when dealing with samples that output low softmax scores. We present an efficient approach to measure the confidence of decision-making steps by statistically investigating each unit's contribution to that decision. Instead of focusing on how the models react on datasets, we study the datasets themselves given a pre-trained model. Our approach is capable of assigning a score to each sample within a dataset that measures the frequency of occurrence of that sample's chain of activation. We demonstrate with experiments that our method could select useful samples to improve deep neural networks in a semi-supervised leaning setting.", "keywords": [], "authorids": ["zsmx1996@utexas.edu", "jialinwu@utexas.edu"], "authors": ["Simiao Zuo", "Jialin Wu"], "pdf": "/pdf/e953f47303981df37fea48b61d25b82f968726cb.pdf", "paperhash": "zuo|image_score_how_to_select_useful_samples", "_bibtex": "@misc{\nzuo2019image,\ntitle={Image Score: how to select useful samples},\nauthor={Simiao Zuo and Jialin Wu},\nyear={2019},\nurl={https://openreview.net/forum?id=HJeNIjA5Y7},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper167/Official_Review", "cdate": 1542234523467, "expdate": 1552335264000, "duedate": 1541196000000, "reply": {"forum": "HJeNIjA5Y7", "replyto": "HJeNIjA5Y7", "readers": {"description": "The users who will be allowed to read the reply content.", "values": ["everyone"]}, "nonreaders": {"values": []}, "signatures": {"description": "How your identity will be displayed with the above content.", "values-regex": "ICLR.cc/2019/Conference/Paper167/AnonReviewer[0-9]+"}, "writers": {"description": "Users that may modify this record.", "values": ["ICLR.cc/2019/Conference"]}, "content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "required": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}}, "multiReply": false, "tcdate": 1552335663591, "tmdate": 1552335663591, "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "invitees": ["ICLR.cc/2019/Conference/Paper167/Reviewers"], "noninvitees": [], "signatures": ["ICLR.cc/2019/Conference"]}}}, {"id": "B1gpZNU9nQ", "original": null, "number": 1, "cdate": 1541198852736, "ddate": null, "tcdate": 1541198852736, "tmdate": 1541534226430, "tddate": null, "forum": "HJeNIjA5Y7", "replyto": "HJeNIjA5Y7", "invitation": "ICLR.cc/2019/Conference/-/Paper167/Official_Review", "content": {"title": "A semi-supervised learning paper, lacking thorough experimentation", "review": "This paper proposes a new metric called the image score that compares the similarity of activation between a given image with a pool of groundtruth images. The paper finds it useful for semi-supervised learning with self-teaching, where the network picks the most confident sample and use the network prediction as the label. It finds that the proposed method is better than 1) not using the unlabeled data and 2) using softmax as an indicator for model prediction certainty.\n\nMotivation: The introduction begins by motivating the interpretability story of deep learning, but I don\u2019t see gaining any more interpretability by reading the rest of the paper. The paper proposes to improve interpretability by assigning a score to each individual example, but then the obtained scores are not properly analyzed in the paper, and only final classification accuracy is evaluated. What are the training samples that makes the model make certain decision at test time? How to measure the correlation between the usefulness of training samples and the proposed image score? These questions left unanswered in the paper. Figure 1 helps a little bit, but then the top row is not necessarily the bad images, but maybe hard examples that needs extra attention to learn. Therefore, I think the end results presented in the experiments do not align with the motivation. Rather than shooting for interpretability, this is just another semi-supervised learning paper.\n\nModels: The major issue of this paper is the model formulation that is not well motivated. The intuition of how the authors come up with the equation for computing the image score is not well explained. Hence the formulation seems very ad-hoc, and it is unclear why this is the selected method.\n\nExperiments: As a semi-supervised learning paper, a common setting for CIFAR-10 is to use 4k labeled images. Here, the method uses 30k, which is 7.5x the size of the usual setting. It also does not compare to prior semi-supervised learning work (e.g. one of the recent one is: https://arxiv.org/abs/1711.00258). The only two baselines discussed here are weak. Also the improvement from the baselines by using the proposed method is not very significant.\n\nComparison: Figure 2-4 shows some positive correlation between the accuracy and score, which is fair, but it doesn\u2019t compare to any baselines--the only one we have is softmax baseline and it is not shown in the figure.\n\nIn conclusion, I couldn\u2019t see how the paper improves interpretability as claimed in the introduction. The proposed method seems ad-hoc, without any justification. Being considered as a semi-supervised learning paper, it lack significant amount of comparison to prior work and adopting a common semi-supervised benchmark. Due to the above reasons, I recommend reject.\n\n---\nMinor points:\n\u201c...almost all of the existed works investigate only the models and ignore the relationship between models and samples\u201d. This is over-exaggerated. I believe most of the visualization techniques are dependent on the actual input samples. It is true to say about \u201ctraining samples\u201d not \u201csamples\u201d in general.\n\n\u201call correctly classified images should have similar chain of activation, while incorrectly classified images should have very different activations both within themselves and with correctly classified images\u201d. This claim seems not backed up. How do you know it is the case for \u201call\u201d correctly classified images? What defines similar/different?", "rating": "3: Clear rejection", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "signatures": ["ICLR.cc/2019/Conference/Paper167/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Image Score: how to select useful samples", "abstract": "There has long been debates on how we could interpret neural networks and understand the decisions our models make. Specifically, why deep neural networks tend to be error-prone when dealing with samples that output low softmax scores. We present an efficient approach to measure the confidence of decision-making steps by statistically investigating each unit's contribution to that decision. Instead of focusing on how the models react on datasets, we study the datasets themselves given a pre-trained model. Our approach is capable of assigning a score to each sample within a dataset that measures the frequency of occurrence of that sample's chain of activation. We demonstrate with experiments that our method could select useful samples to improve deep neural networks in a semi-supervised leaning setting.", "keywords": [], "authorids": ["zsmx1996@utexas.edu", "jialinwu@utexas.edu"], "authors": ["Simiao Zuo", "Jialin Wu"], "pdf": "/pdf/e953f47303981df37fea48b61d25b82f968726cb.pdf", "paperhash": "zuo|image_score_how_to_select_useful_samples", "_bibtex": "@misc{\nzuo2019image,\ntitle={Image Score: how to select useful samples},\nauthor={Simiao Zuo and Jialin Wu},\nyear={2019},\nurl={https://openreview.net/forum?id=HJeNIjA5Y7},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper167/Official_Review", "cdate": 1542234523467, "expdate": 1552335264000, "duedate": 1541196000000, "reply": {"forum": "HJeNIjA5Y7", "replyto": "HJeNIjA5Y7", "readers": {"description": "The users who will be allowed to read the reply content.", "values": ["everyone"]}, "nonreaders": {"values": []}, "signatures": {"description": "How your identity will be displayed with the above content.", "values-regex": "ICLR.cc/2019/Conference/Paper167/AnonReviewer[0-9]+"}, "writers": {"description": "Users that may modify this record.", "values": ["ICLR.cc/2019/Conference"]}, "content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "required": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}}, "multiReply": false, "tcdate": 1552335663591, "tmdate": 1552335663591, "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "invitees": ["ICLR.cc/2019/Conference/Paper167/Reviewers"], "noninvitees": [], "signatures": ["ICLR.cc/2019/Conference"]}}}], "count": 5}