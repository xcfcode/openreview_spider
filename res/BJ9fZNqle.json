{"notes": [{"tddate": null, "ddate": null, "cdate": null, "tmdate": 1486396430694, "tcdate": 1486396430694, "number": 1, "id": "BJPMnGLOx", "invitation": "ICLR.cc/2017/conference/-/paper204/acceptance", "forum": "BJ9fZNqle", "replyto": "BJ9fZNqle", "signatures": ["ICLR.cc/2017/pcs"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/pcs"], "content": {"decision": "Reject", "title": "ICLR committee final decision", "comment": "This paper explores a variational autoencoder variant.\n \n ICLR gives authors some respect that other conferences don't. It is flexible about the length of the paper, and allows revisions to be submitted. The understanding should be that authors should in turn treat reviewers with respect. The paper should still be finished. Reviewers can't be expected to read a churn of large revisions. The final paper should be roughly the right length, unless with very good reason.\n \n This paper was clearly not finished, and now is too long, with issues remaining. I hope that it will be submitted again, but not until it is actually ready."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Multi-modal Variational Encoder-Decoders", "abstract": "Recent advances in neural variational inference have facilitated efficient training of powerful directed graphical models with continuous latent variables, such as variational autoencoders. However, these models usually assume simple, uni-modal priors \u2014 such as the multivariate Gaussian distribution \u2014 yet many real-world data distributions are highly complex and multi-modal. Examples of complex and multi-modal distributions range from topics in newswire text to conversational dialogue responses. When such latent variable models are applied to these domains, the restriction of the simple, uni-modal prior hinders the overall expressivity of the learned model as it cannot possibly capture more complex aspects of the data distribution. To overcome this critical restriction, we propose a flexible, simple prior distribution which can be learned efficiently and potentially capture an exponential number of modes of a target distribution. We develop the multi-modal variational encoder-decoder framework and investigate the effectiveness of the proposed prior in several natural language processing modeling tasks, including document modeling and dialogue modeling.", "pdf": "/pdf/071718de067f86d033a26cee3d6f7bd1e96215db.pdf", "TL;DR": "Learning continuous multimodal latent variables in the variational auto-encoder framework for text processing applications.", "paperhash": "serban|multimodal_variational_encoderdecoders", "keywords": ["Deep learning", "Structured prediction", "Natural language processing"], "conflicts": ["umontreal.ca", "psu.edu", "cs.mcgill.ca"], "authors": ["Iulian V. Serban", "Alexander G. Ororbia II", "Joelle Pineau", "Aaron Courville"], "authorids": ["julianserban@gmail.com", "ago109@psu.edu", "jpineau@cs.mcgill.ca", "aaron.courville@umontreal.ca"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1486396431244, "id": "ICLR.cc/2017/conference/-/paper204/acceptance", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/pcs"], "noninvitees": ["ICLR.cc/2017/pcs"], "reply": {"forum": "BJ9fZNqle", "replyto": "BJ9fZNqle", "writers": {"values-regex": "ICLR.cc/2017/pcs"}, "signatures": {"values-regex": "ICLR.cc/2017/pcs", "description": "Your displayed identity associated with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your decision.", "value": "ICLR committee final decision"}, "comment": {"required": true, "order": 2, "description": "Decision comments.", "value-regex": "[\\S\\s]{1,5000}"}, "decision": {"required": true, "order": 3, "value-radio": ["Accept (Oral)", "Accept (Poster)", "Reject", "Invite to Workshop Track"]}}}, "nonreaders": [], "cdate": 1486396431244}}}, {"tddate": null, "tmdate": 1482344256108, "tcdate": 1481923896261, "number": 1, "id": "HJeBaC-Vl", "invitation": "ICLR.cc/2017/conference/-/paper204/official/review", "forum": "BJ9fZNqle", "replyto": "BJ9fZNqle", "signatures": ["ICLR.cc/2017/conference/paper204/AnonReviewer1"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/conference/paper204/AnonReviewer1"], "content": {"title": "Review: Multi-modal Variational Encoder-Decoders", "rating": "3: Clear rejection", "review": "UPDATE: I have read the authors' rebuttal and also the other comments in this paper's thread. My thoughts have not changed.\n\nThe authors propose using a mixture prior rather than a uni-modal\nprior for variational auto-encoders. They argue that the simple\nuni-modal prior \"hinders the overall expressivity of the learned model\nas it cannot possibly capture more complex aspects of the data\ndistribution.\"\n\nI find the motivation of the paper suspicious because while the prior\nmay be uni-modal, the posterior distribution is certainly not.\nFurthermore, a uni-modal distribution on the latent variable space can\ncertainly still lead to the capturing of complex, multi-modal data\ndistributions. (As the most trivial case, take the latent variable\nspace to be a uniform distribution; take the likelihood to be a\npoint mass given by applying the true data distribution's inverse CDF\nto the uniform. Such a model can capture any distribution.)\n\nIn addition, multi-modality is arguably an overfocused concept in the\nliterature, where the (latent variable) space is hardly anymore worth\ncapturing from a mixture of simple distributions when it is often a\ncomplex nonlinear space. It is unclear from the experiments how much\nthe influence of the prior's multimodality influences the posterior to\ncapture more complex phenomena, and whether this is any better than\nconsidering a more complex (but still reparameterizable) distribution\non the latent space.\n\nI recommend that this paper be rejected, and encourage the authors to\nmore extensively study the effect of different priors.\n\nI'd also like to make two additional comments:\n\nWhile there is no length restriction at ICLR, the 14 page document can\nbe significantly condensed without loss of describing their innovation\nor clarity. I recommend the authors do so.\n\nFinally, I think it's important to note the controversy in this paper.\nIt was submitted with many significant incomplete details (e.g., no experiments,\nmany missing citations, a figure placed inside that was pencilled in\nby hand, and several missing paragraphs). These details were not\ncompleted until roughly a week(?) later. I recommend the chairs discuss\nthis in light of what should be allowed next year.", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Multi-modal Variational Encoder-Decoders", "abstract": "Recent advances in neural variational inference have facilitated efficient training of powerful directed graphical models with continuous latent variables, such as variational autoencoders. However, these models usually assume simple, uni-modal priors \u2014 such as the multivariate Gaussian distribution \u2014 yet many real-world data distributions are highly complex and multi-modal. Examples of complex and multi-modal distributions range from topics in newswire text to conversational dialogue responses. When such latent variable models are applied to these domains, the restriction of the simple, uni-modal prior hinders the overall expressivity of the learned model as it cannot possibly capture more complex aspects of the data distribution. To overcome this critical restriction, we propose a flexible, simple prior distribution which can be learned efficiently and potentially capture an exponential number of modes of a target distribution. We develop the multi-modal variational encoder-decoder framework and investigate the effectiveness of the proposed prior in several natural language processing modeling tasks, including document modeling and dialogue modeling.", "pdf": "/pdf/071718de067f86d033a26cee3d6f7bd1e96215db.pdf", "TL;DR": "Learning continuous multimodal latent variables in the variational auto-encoder framework for text processing applications.", "paperhash": "serban|multimodal_variational_encoderdecoders", "keywords": ["Deep learning", "Structured prediction", "Natural language processing"], "conflicts": ["umontreal.ca", "psu.edu", "cs.mcgill.ca"], "authors": ["Iulian V. Serban", "Alexander G. Ororbia II", "Joelle Pineau", "Aaron Courville"], "authorids": ["julianserban@gmail.com", "ago109@psu.edu", "jpineau@cs.mcgill.ca", "aaron.courville@umontreal.ca"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1481932799000, "tmdate": 1482512664757, "id": "ICLR.cc/2017/conference/-/paper204/official/review", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/conference/paper204/reviewers"], "noninvitees": ["ICLR.cc/2017/conference/paper204/AnonReviewer1", "ICLR.cc/2017/conference/paper204/AnonReviewer3", "ICLR.cc/2017/conference/paper204/AnonReviewer4"], "reply": {"forum": "BJ9fZNqle", "replyto": "BJ9fZNqle", "writers": {"values-regex": "ICLR.cc/2017/conference/paper204/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/conference/paper204/AnonReviewer[0-9]+"}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "value-regex": "[\\S\\s]{1,20000}"}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1489708799000, "cdate": 1482512664757}}}, {"tddate": null, "tmdate": 1482277185622, "tcdate": 1482005211433, "number": 15, "id": "HJmyjGmVx", "invitation": "ICLR.cc/2017/conference/-/paper204/public/comment", "forum": "BJ9fZNqle", "replyto": "HJeBaC-Vl", "signatures": ["~Alexander_G_Ororbia_II1"], "readers": ["everyone"], "writers": ["~Alexander_G_Ororbia_II1"], "content": {"title": "Rebuttal: Reviewer #1", "comment": "\nThank you for your review\n\n> I find the motivation of the paper suspicious...\n\nIndeed, it may appear that many researchers now focus on multi-modality, but we believe it is an important area of research. In fact, our quantitative results on the document modeling tasks strongly support this claim, where the multi-modal latent variable models significantly outperform the uni-modal Gaussian latent variable models across three different tasks.\n\nIn fact, multi-modality is one of the major motivations for incorporating discrete latent variables into VAEs, which is what at least 3 other ICLR submissions focus on:\n\u201cDiscrete Variational Autoencoders\u201d by Rolfe\nThe Concrete Distribution: A Continuous Relaxation of Discrete Random Variables\u201d by Maddison et al.\n\u201cCategorical Reparameterization with Gumbel-Softmax\u201d by Jang et al.\n\nOf course, our approach differs from these, because our goal is to learn continuous latent variables with multi-modal probability density functions.\n\nFor a lot of NLP applications, there are plenty of intuitive arguments for why one would like multi-modality in the latent variable space. Suppose we have a generative model over sports articles. Some of the generated articles might be related to football and others to hockey. But clearly there exists no sport that lies in between football and hockey (at least not yet!), so if the latent variable contains different regions for football and hockey articles, then there must be a region of low probability mass between them. By definition, such a probability density is multi-modal and cannot be represented by a uni-modal Gaussian variable. In theory, it could be captured in the decoder module which takes as input a uni-modal latent variable sample, but in practice this is going to be very difficult to learn as our experiments have shown.\n\n> the 14 page document can be significantly condensed without loss\n\nWe agree, and will shorten the paper for the camera-ready version (see our response to Reviewer #3 above).\n\n> It was submitted with many significant incomplete details\n\nWe sincerely apologize for the incomplete submission. We did not plan for this, but found bugs in our experiments and had to re-launch several of them just before the deadline, which is why it took a whole week extra before we had the final results.\n\n\n-Alex And Iulian\n"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Multi-modal Variational Encoder-Decoders", "abstract": "Recent advances in neural variational inference have facilitated efficient training of powerful directed graphical models with continuous latent variables, such as variational autoencoders. However, these models usually assume simple, uni-modal priors \u2014 such as the multivariate Gaussian distribution \u2014 yet many real-world data distributions are highly complex and multi-modal. Examples of complex and multi-modal distributions range from topics in newswire text to conversational dialogue responses. When such latent variable models are applied to these domains, the restriction of the simple, uni-modal prior hinders the overall expressivity of the learned model as it cannot possibly capture more complex aspects of the data distribution. To overcome this critical restriction, we propose a flexible, simple prior distribution which can be learned efficiently and potentially capture an exponential number of modes of a target distribution. We develop the multi-modal variational encoder-decoder framework and investigate the effectiveness of the proposed prior in several natural language processing modeling tasks, including document modeling and dialogue modeling.", "pdf": "/pdf/071718de067f86d033a26cee3d6f7bd1e96215db.pdf", "TL;DR": "Learning continuous multimodal latent variables in the variational auto-encoder framework for text processing applications.", "paperhash": "serban|multimodal_variational_encoderdecoders", "keywords": ["Deep learning", "Structured prediction", "Natural language processing"], "conflicts": ["umontreal.ca", "psu.edu", "cs.mcgill.ca"], "authors": ["Iulian V. Serban", "Alexander G. Ororbia II", "Joelle Pineau", "Aaron Courville"], "authorids": ["julianserban@gmail.com", "ago109@psu.edu", "jpineau@cs.mcgill.ca", "aaron.courville@umontreal.ca"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287686689, "id": "ICLR.cc/2017/conference/-/paper204/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "BJ9fZNqle", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper204/reviewers", "ICLR.cc/2017/conference/paper204/areachairs"], "cdate": 1485287686689}}}, {"tddate": null, "tmdate": 1482277172849, "tcdate": 1482005509554, "number": 16, "id": "r1p-nzmVg", "invitation": "ICLR.cc/2017/conference/-/paper204/public/comment", "forum": "BJ9fZNqle", "replyto": "BJw-pyfVe", "signatures": ["~Alexander_G_Ororbia_II1"], "readers": ["everyone"], "writers": ["~Alexander_G_Ororbia_II1"], "content": {"title": "Rebuttal: Reviewer #3", "comment": "\nThank you for your detailed review.\n\n> paper is not well-written (even 14 pages long)\n\nWe agree that the paper is too long. We aim to shorten it by moving the mathematical derivations and the equations for the NVDM and VHRED models to the appendix. Hopefully, this will also make the ideas more clear.\n\n> the experiments fails to demonstrate the most of the claims \u2026\n\nWe disagree with this conclusion. We have carried out experiments on four different tasks (20-Newsgroup, RCV1, CADE, and Twitter dialogues), while comparing to the most competitive baseline model (a similar model with multivariate Gaussian latent variables). On all document modeling tasks, we demonstrate significant performance improvements w.r.t. perplexity. On the document modeling tasks we further demonstrate the utility of the piecewise constant variables through word query similarity and gradient analysis. On the dialogue task, we demonstrate their utility through gradient analysis and qualitatively using examples.\n\nWe believe our experimental evaluations are at least as well-designed and conclusive --- if not more conclusive --- compared to several other ICLR submissions. OUR EXPERIMENTS ARE ON COMPLEX, REAL-WORLD TEXT DATASETS, which contain plenty of MULTI-MODAL STRUCTURE. Most of these experiments took several days (sometimes weeks) to execute on machines with TitanX GPUs. Please compare the impact and computational complexity of these experiments to other ICLR submissions such as: \u201cThe Concrete Distribution: A Continuous Relaxation of Discrete Random Variables\u201d and \u201cCategorical Reparameterization with Gumbel-Softmax\u201d. These submissions focus their experiments on MNIST and OMNIGLOT, which their reviewers seem to be satisfied with.\n\n> However, z=<z_gaussian1, z_gaussian2> can be multimodal as well...\n\nAll Gaussian distributions are uni-modal by definition, so concatenating two samples from multivariate Gaussian distributions is still uni-modal. Therefore, z=<z_gaussian1, z_gaussian2> cannot be multi-modal.\n\n> a fair comparison would at least be z=<z_gaussian, z_piecewise> and z=<z_gaussian1, z_gaussian2> which equals to a double sized z_gaussian. \n\nWe did take this into account during hyper-parameter search. For the G-NVDM model, we experimented with up to 200 latent Gaussians variables, but found that this performed worse due to overfitting.\n\n> The results shown in Table 3 are implausible\u2026\n\nResearchers routinely analyse hidden unit activations in neural network models. For example, see Miao et al (2015) and Karpathy et al. (2015). In our case, we were interested in seeing how much changing a word would affect the latent variable models, which is why we compute the gradient w.r.t. the word embedding. Of course, this does not yield quantitative evidence showing how well the model performs on different tasks, but it does illustrate what words the latent variables are sensitive to which, in turn, shows what they have learned to encode.\n\nReferences\n\nMiao et al, Neural Variational Inference for Text Processing. 2015.\n\nKarpathy et al, Visualizing and Understanding Recurrent Networks, 2015.\n\n\n- Alex And Iulian"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Multi-modal Variational Encoder-Decoders", "abstract": "Recent advances in neural variational inference have facilitated efficient training of powerful directed graphical models with continuous latent variables, such as variational autoencoders. However, these models usually assume simple, uni-modal priors \u2014 such as the multivariate Gaussian distribution \u2014 yet many real-world data distributions are highly complex and multi-modal. Examples of complex and multi-modal distributions range from topics in newswire text to conversational dialogue responses. When such latent variable models are applied to these domains, the restriction of the simple, uni-modal prior hinders the overall expressivity of the learned model as it cannot possibly capture more complex aspects of the data distribution. To overcome this critical restriction, we propose a flexible, simple prior distribution which can be learned efficiently and potentially capture an exponential number of modes of a target distribution. We develop the multi-modal variational encoder-decoder framework and investigate the effectiveness of the proposed prior in several natural language processing modeling tasks, including document modeling and dialogue modeling.", "pdf": "/pdf/071718de067f86d033a26cee3d6f7bd1e96215db.pdf", "TL;DR": "Learning continuous multimodal latent variables in the variational auto-encoder framework for text processing applications.", "paperhash": "serban|multimodal_variational_encoderdecoders", "keywords": ["Deep learning", "Structured prediction", "Natural language processing"], "conflicts": ["umontreal.ca", "psu.edu", "cs.mcgill.ca"], "authors": ["Iulian V. Serban", "Alexander G. Ororbia II", "Joelle Pineau", "Aaron Courville"], "authorids": ["julianserban@gmail.com", "ago109@psu.edu", "jpineau@cs.mcgill.ca", "aaron.courville@umontreal.ca"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287686689, "id": "ICLR.cc/2017/conference/-/paper204/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "BJ9fZNqle", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper204/reviewers", "ICLR.cc/2017/conference/paper204/areachairs"], "cdate": 1485287686689}}}, {"tddate": null, "tmdate": 1482277157107, "tcdate": 1482277145406, "number": 19, "id": "HkZQbrvVx", "invitation": "ICLR.cc/2017/conference/-/paper204/public/comment", "forum": "BJ9fZNqle", "replyto": "SyrSisIVl", "signatures": ["~Alexander_G_Ororbia_II1"], "readers": ["everyone"], "writers": ["~Alexander_G_Ororbia_II1"], "content": {"title": "Rebuttal: Reviewer #4", "comment": "\n> \"The original abstract is overly strong in its assertion that a unimodal latent prior p(z) cannot fit a multimodal marginal int_z p(x|z)p(x)dz\"\n\nWe did not argue for multi-modality of the output space. Naturally, with a powerful decoder, the marginal p(x) and the conditional p(x|z) could potentially be multi-modal. However, using a Gaussian prior, by definition the latent variable prior p(z) is uni-modal. This could in principle hurt the representations learned. If the latent factors are truly multi-modal, trying to represent them or compress them down to a uni-modal space will act as a strong regularization and make the training process more difficult. That's why our goal is to learn a multi-modal prior p(z).\n\nWe will clarify this distinction in the final version of the paper.\n\n> \"I found it surprising that the learned variance and mean for the Gaussian prior helps so dramatically with G-NVDM likelihood\"\n\nThere are other differences between NVDM and G-NVDM beyond learning the prior parameters. One important difference is the gating mechanism which allows the model to interpolate between the posterior and prior in order to calculate the final generated posterior parameters (beyond minor details such as different activation functions, technical modifications, etc. as mentioned in the paper). This is simply something that we found helped improve performance in preliminary experiments (as well as in some experiments in the past).  We felt that a fairer comparison would be to first improve the baseline model (i.e., the NVDM) and then compare our proposed hybrid models against the improved baseline (as opposed to only/exclusively reporting a previously published as is commonly done). This was especially important given that we intended to jointly learn the priors and use the gating mechanism in the proposed models as well.\n\nThe mission of the paper was to show that the proposed prior improved the encoder-decoder models in the challenging text problems we chose to explore (or at least uncovered interesting information using the piecewise variables).  Many of the models trained in the paper (especially the dialogue models) are fairly expensive to train, and we further felt that reporting various degradations of the models would clutter the paper and detract from focusing on the piecewise variables themselves.  However, we do agree that an ablation test would be appropriate and will add an appendix in the final version exploring the effects of each modification.\n\n> \"... a hypercube-based tiling of latent code space is a sensible idea.\"\n\nWe appreciate this interpretation, and will give it more thought.\n\n> \"I also found it unsatisfactory that the piecewise variable analysis did not show different components of the multi-modal prior corresponding to different words\"\n\nThis is exactly what our analysis using gradients was aimed at.\n\nWe will try to visualize the impact of the latent variable components in another way.\n\n> \"The experiments on dialog modeling are mostly negative results\"\n\nThat is not accurate. The standard G-VHRED model is neither better than nor worse than the H-VHRED. Human subjects simply cannot tell them apart.\n\n-Alex And Iulian"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Multi-modal Variational Encoder-Decoders", "abstract": "Recent advances in neural variational inference have facilitated efficient training of powerful directed graphical models with continuous latent variables, such as variational autoencoders. However, these models usually assume simple, uni-modal priors \u2014 such as the multivariate Gaussian distribution \u2014 yet many real-world data distributions are highly complex and multi-modal. Examples of complex and multi-modal distributions range from topics in newswire text to conversational dialogue responses. When such latent variable models are applied to these domains, the restriction of the simple, uni-modal prior hinders the overall expressivity of the learned model as it cannot possibly capture more complex aspects of the data distribution. To overcome this critical restriction, we propose a flexible, simple prior distribution which can be learned efficiently and potentially capture an exponential number of modes of a target distribution. We develop the multi-modal variational encoder-decoder framework and investigate the effectiveness of the proposed prior in several natural language processing modeling tasks, including document modeling and dialogue modeling.", "pdf": "/pdf/071718de067f86d033a26cee3d6f7bd1e96215db.pdf", "TL;DR": "Learning continuous multimodal latent variables in the variational auto-encoder framework for text processing applications.", "paperhash": "serban|multimodal_variational_encoderdecoders", "keywords": ["Deep learning", "Structured prediction", "Natural language processing"], "conflicts": ["umontreal.ca", "psu.edu", "cs.mcgill.ca"], "authors": ["Iulian V. Serban", "Alexander G. Ororbia II", "Joelle Pineau", "Aaron Courville"], "authorids": ["julianserban@gmail.com", "ago109@psu.edu", "jpineau@cs.mcgill.ca", "aaron.courville@umontreal.ca"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287686689, "id": "ICLR.cc/2017/conference/-/paper204/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "BJ9fZNqle", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper204/reviewers", "ICLR.cc/2017/conference/paper204/areachairs"], "cdate": 1485287686689}}}, {"tddate": null, "tmdate": 1482238781078, "tcdate": 1482238781078, "number": 3, "id": "SyrSisIVl", "invitation": "ICLR.cc/2017/conference/-/paper204/official/review", "forum": "BJ9fZNqle", "replyto": "BJ9fZNqle", "signatures": ["ICLR.cc/2017/conference/paper204/AnonReviewer4"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/conference/paper204/AnonReviewer4"], "content": {"title": "Review", "rating": "4: Ok but not good enough - rejection", "review": "The authors introduce some new prior and approximate posterior families for variational autoencoders, which are compatible with the reparameterization trick, as well as being capable of expressing multiple modes. They also introduce a gating mechanism between prior and posterior. They show improvements on bag of words document modeling, and dialogue response generation. The original abstract is overly strong in its assertion that a unimodal latent prior p(z) cannot fit a multimodal marginal int_z p(x|z)p(x)dz with a DNN response model p(x|z) (\"it cannot possibly capture more complex aspects of the data distribution\", \"critical restriction\", etc).\n\nWhile the assertion that a unimodal latent prior is necessary to model multimodal observations is false, there are sensible motivations for the piecewise constant prior and posterior. For example, if we think of a VAE as a sort of regularized autoencoder where codes are constrained to \"fill up\" parts of the prior latent space, then there is a sphere-packing argument to be made that filling a Gaussian prior with Gaussian posteriors is a bad use of code space. Although the authors don't explore this much, a hypercube-based tiling of latent code space is a sensible idea.\n\nAs stated, I found the message of the paper to be quite sloppy with respect to the concept of \"multi-modality.\" There are 3 types of multimodality at play here: multimodality in the observed marginal distribution p(x), which can be captured by any deep latent Gaussian model, multimodality in the prior p(z), which makes sense in some situations (e.g. a model of MNIST digits could have 10 prior modes corresponding to latent codes for each digit class), and multimodality in the posterior z for a given observation x_i, q(z_i|x_i). The final type of multimodality is harder to argue for, except in so far as it allows the expression of flexibly shaped distributions without highly separated modes. I believe flexible posterior approximations are important to enable fine-grained and efficient tiling of latent space, but I don't think these need to have multiple strong modes. I would be interested to see experiments demonstrating otherwise for real world data.\n\nI think this paper should be more clear about the different types of multi-modality and which parts of their analysis demonstrate which ones. I also found it unsatisfactory that the piecewise variable analysis did not show different components of the multi-modal prior corresponding to different words, but rather just a separation between the Gaussian and the piecewise variables.\n\nAs I mention in my earlier questions, I found it surprising that the learned variance and mean for the Gaussian prior helps so dramatically with G-NVDM likelihood when the powerful networks transforming to and from latent space should make it scale-invariant. Explicitly separating out the contributions of a reimplemented base model, prior-posterior interpolation and the learned prior parameters would strengthen these experiments. Overall, the very strong improvements on the text modeling task over NVDM seem hard to understand, and I would like to see an ablation analysis of all the differences between that model and the proposed one.\n\nThe fact that adding more constant components helps for document modeling is interesting, and it would be nice to see more qualitative analysis of what the prior modes represent. I also would be surprised if posterior modes were highly separated, and if they were it would be interesting to explore if they corresponded to e.g. ambiguous word-senses.\n\nThe experiments on dialog modeling are mostly negative results, quantitatively. The observation that the the piecewise constant variables encode time-related words and the Gaussian variables encode sentiment is interesting, especially since it occurs in both sets of experiments. This is actually quite interesting, and I would be interested in seeing analysis of why this is the case. As above, I would like to see an analysis of the sorts of words that are encoded in the different prior modes and whether they correspond to e.g. groups of similar holidays or days.\n\nIn conclusion, I think the piecewise constant variational family is a good idea, although it is not well-motivated by the paper. The experimental results are very good for document modeling, but without ablation analysis against the baseline it is hard to see why they should be with such a small modification in G-NVDM. The fact that H-NVDM performs better is interesting, though. This paper should better motivate the need for different types of multi-modality, and demonstrate that those sorts of things are actually being captured by the model. As it is, the paper introduces an interesting variational family and shows that it performs better for some tasks, but the motivation and analysis is not clearly focused. To demonstrate that this is a broadly applicable family, it would also be good to do experiments on a more standard datasets like MNIST. Even without an absolute log-likelihood improvement, if the method yielded interpretable multiple modes this would be a valuable contribution.", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Multi-modal Variational Encoder-Decoders", "abstract": "Recent advances in neural variational inference have facilitated efficient training of powerful directed graphical models with continuous latent variables, such as variational autoencoders. However, these models usually assume simple, uni-modal priors \u2014 such as the multivariate Gaussian distribution \u2014 yet many real-world data distributions are highly complex and multi-modal. Examples of complex and multi-modal distributions range from topics in newswire text to conversational dialogue responses. When such latent variable models are applied to these domains, the restriction of the simple, uni-modal prior hinders the overall expressivity of the learned model as it cannot possibly capture more complex aspects of the data distribution. To overcome this critical restriction, we propose a flexible, simple prior distribution which can be learned efficiently and potentially capture an exponential number of modes of a target distribution. We develop the multi-modal variational encoder-decoder framework and investigate the effectiveness of the proposed prior in several natural language processing modeling tasks, including document modeling and dialogue modeling.", "pdf": "/pdf/071718de067f86d033a26cee3d6f7bd1e96215db.pdf", "TL;DR": "Learning continuous multimodal latent variables in the variational auto-encoder framework for text processing applications.", "paperhash": "serban|multimodal_variational_encoderdecoders", "keywords": ["Deep learning", "Structured prediction", "Natural language processing"], "conflicts": ["umontreal.ca", "psu.edu", "cs.mcgill.ca"], "authors": ["Iulian V. Serban", "Alexander G. Ororbia II", "Joelle Pineau", "Aaron Courville"], "authorids": ["julianserban@gmail.com", "ago109@psu.edu", "jpineau@cs.mcgill.ca", "aaron.courville@umontreal.ca"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1481932799000, "tmdate": 1482512664757, "id": "ICLR.cc/2017/conference/-/paper204/official/review", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/conference/paper204/reviewers"], "noninvitees": ["ICLR.cc/2017/conference/paper204/AnonReviewer1", "ICLR.cc/2017/conference/paper204/AnonReviewer3", "ICLR.cc/2017/conference/paper204/AnonReviewer4"], "reply": {"forum": "BJ9fZNqle", "replyto": "BJ9fZNqle", "writers": {"values-regex": "ICLR.cc/2017/conference/paper204/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/conference/paper204/AnonReviewer[0-9]+"}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "value-regex": "[\\S\\s]{1,20000}"}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1489708799000, "cdate": 1482512664757}}}, {"tddate": null, "ddate": null, "writable": true, "revisions": false, "tmdate": 1482034841358, "tcdate": 1482034519725, "number": 18, "replyCount": 0, "id": "SkgDpKXVx", "invitation": "ICLR.cc/2017/conference/-/paper204/public/comment", "forum": "BJ9fZNqle", "replyto": "SkmTNVmVl", "signatures": ["~Alexander_G_Ororbia_II1"], "readers": ["everyone"], "writers": ["~Alexander_G_Ororbia_II1"], "content": {"title": "RE: experiments", "comment": "We agree that some of the language in the experiments can be revised to address your concern (and make some of the claims less vague) and will do so for the final version. (See response to second comment as well as these two are related.)\n\n-Alex And Iulian"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Multi-modal Variational Encoder-Decoders", "abstract": "Recent advances in neural variational inference have facilitated efficient training of powerful directed graphical models with continuous latent variables, such as variational autoencoders. However, these models usually assume simple, uni-modal priors \u2014 such as the multivariate Gaussian distribution \u2014 yet many real-world data distributions are highly complex and multi-modal. Examples of complex and multi-modal distributions range from topics in newswire text to conversational dialogue responses. When such latent variable models are applied to these domains, the restriction of the simple, uni-modal prior hinders the overall expressivity of the learned model as it cannot possibly capture more complex aspects of the data distribution. To overcome this critical restriction, we propose a flexible, simple prior distribution which can be learned efficiently and potentially capture an exponential number of modes of a target distribution. We develop the multi-modal variational encoder-decoder framework and investigate the effectiveness of the proposed prior in several natural language processing modeling tasks, including document modeling and dialogue modeling.", "pdf": "/pdf/071718de067f86d033a26cee3d6f7bd1e96215db.pdf", "TL;DR": "Learning continuous multimodal latent variables in the variational auto-encoder framework for text processing applications.", "paperhash": "serban|multimodal_variational_encoderdecoders", "keywords": ["Deep learning", "Structured prediction", "Natural language processing"], "conflicts": ["umontreal.ca", "psu.edu", "cs.mcgill.ca"], "authors": ["Iulian V. Serban", "Alexander G. Ororbia II", "Joelle Pineau", "Aaron Courville"], "authorids": ["julianserban@gmail.com", "ago109@psu.edu", "jpineau@cs.mcgill.ca", "aaron.courville@umontreal.ca"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287686689, "id": "ICLR.cc/2017/conference/-/paper204/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "BJ9fZNqle", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper204/reviewers", "ICLR.cc/2017/conference/paper204/areachairs"], "cdate": 1485287686689}}}, {"tddate": null, "tmdate": 1482034126717, "tcdate": 1482034126717, "number": 17, "id": "ryvAit74g", "invitation": "ICLR.cc/2017/conference/-/paper204/public/comment", "forum": "BJ9fZNqle", "replyto": "SkT0lEXNe", "signatures": ["~Alexander_G_Ororbia_II1"], "readers": ["everyone"], "writers": ["~Alexander_G_Ororbia_II1"], "content": {"title": "RE: operations of z", "comment": "Yes, in theory, the lower levels of the decoder could potentially learn to represent multi-modal latent variables. However, this is very difficult to learn through SGD optimization. On the other hand, the piecewise constant latent variables can represent multi-modal random variables directly (e.g. for each dimension, the model has n=3 or n=5 specific parameters controlling one multi-modal distribution). This makes it a lot easier to learn multi-modal aspects of the data, which is why the piecewise constant latent variables achieve substantially better results on our 3 document modeling tasks, and the reason why they qualitatively encode different aspects of the data distribution.\n\n-Alex And Iulian"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Multi-modal Variational Encoder-Decoders", "abstract": "Recent advances in neural variational inference have facilitated efficient training of powerful directed graphical models with continuous latent variables, such as variational autoencoders. However, these models usually assume simple, uni-modal priors \u2014 such as the multivariate Gaussian distribution \u2014 yet many real-world data distributions are highly complex and multi-modal. Examples of complex and multi-modal distributions range from topics in newswire text to conversational dialogue responses. When such latent variable models are applied to these domains, the restriction of the simple, uni-modal prior hinders the overall expressivity of the learned model as it cannot possibly capture more complex aspects of the data distribution. To overcome this critical restriction, we propose a flexible, simple prior distribution which can be learned efficiently and potentially capture an exponential number of modes of a target distribution. We develop the multi-modal variational encoder-decoder framework and investigate the effectiveness of the proposed prior in several natural language processing modeling tasks, including document modeling and dialogue modeling.", "pdf": "/pdf/071718de067f86d033a26cee3d6f7bd1e96215db.pdf", "TL;DR": "Learning continuous multimodal latent variables in the variational auto-encoder framework for text processing applications.", "paperhash": "serban|multimodal_variational_encoderdecoders", "keywords": ["Deep learning", "Structured prediction", "Natural language processing"], "conflicts": ["umontreal.ca", "psu.edu", "cs.mcgill.ca"], "authors": ["Iulian V. Serban", "Alexander G. Ororbia II", "Joelle Pineau", "Aaron Courville"], "authorids": ["julianserban@gmail.com", "ago109@psu.edu", "jpineau@cs.mcgill.ca", "aaron.courville@umontreal.ca"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287686689, "id": "ICLR.cc/2017/conference/-/paper204/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "BJ9fZNqle", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper204/reviewers", "ICLR.cc/2017/conference/paper204/areachairs"], "cdate": 1485287686689}}}, {"tddate": null, "tmdate": 1482011835160, "tcdate": 1482011835160, "number": 2, "id": "SkmTNVmVl", "invitation": "ICLR.cc/2017/conference/-/paper204/official/comment", "forum": "BJ9fZNqle", "replyto": "r1p-nzmVg", "signatures": ["ICLR.cc/2017/conference/paper204/AnonReviewer3"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/conference/paper204/AnonReviewer3"], "content": {"title": "experiments", "comment": "The improvement on perplexity is significant, which is also very exciting. And I do believe the piecewise constant might be promising for VAEs. However, what I was questioning here is the careless claims made by the author without evidence. I would recommend the author to spend more time on rewriting the paper.  "}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Multi-modal Variational Encoder-Decoders", "abstract": "Recent advances in neural variational inference have facilitated efficient training of powerful directed graphical models with continuous latent variables, such as variational autoencoders. However, these models usually assume simple, uni-modal priors \u2014 such as the multivariate Gaussian distribution \u2014 yet many real-world data distributions are highly complex and multi-modal. Examples of complex and multi-modal distributions range from topics in newswire text to conversational dialogue responses. When such latent variable models are applied to these domains, the restriction of the simple, uni-modal prior hinders the overall expressivity of the learned model as it cannot possibly capture more complex aspects of the data distribution. To overcome this critical restriction, we propose a flexible, simple prior distribution which can be learned efficiently and potentially capture an exponential number of modes of a target distribution. We develop the multi-modal variational encoder-decoder framework and investigate the effectiveness of the proposed prior in several natural language processing modeling tasks, including document modeling and dialogue modeling.", "pdf": "/pdf/071718de067f86d033a26cee3d6f7bd1e96215db.pdf", "TL;DR": "Learning continuous multimodal latent variables in the variational auto-encoder framework for text processing applications.", "paperhash": "serban|multimodal_variational_encoderdecoders", "keywords": ["Deep learning", "Structured prediction", "Natural language processing"], "conflicts": ["umontreal.ca", "psu.edu", "cs.mcgill.ca"], "authors": ["Iulian V. Serban", "Alexander G. Ororbia II", "Joelle Pineau", "Aaron Courville"], "authorids": ["julianserban@gmail.com", "ago109@psu.edu", "jpineau@cs.mcgill.ca", "aaron.courville@umontreal.ca"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287686563, "id": "ICLR.cc/2017/conference/-/paper204/official/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "reply": {"forum": "BJ9fZNqle", "writers": {"values-regex": "ICLR.cc/2017/conference/paper204/(AnonReviewer|areachair)[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/conference/paper204/(AnonReviewer|areachair)[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": [], "invitees": ["ICLR.cc/2017/conference/paper204/reviewers", "ICLR.cc/2017/conference/paper204/areachairs"], "cdate": 1485287686563}}}, {"tddate": null, "tmdate": 1482010878327, "tcdate": 1482010837063, "number": 1, "id": "SkT0lEXNe", "invitation": "ICLR.cc/2017/conference/-/paper204/official/comment", "forum": "BJ9fZNqle", "replyto": "r1p-nzmVg", "signatures": ["ICLR.cc/2017/conference/paper204/AnonReviewer3"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/conference/paper204/AnonReviewer3"], "content": {"title": "operations of z", "comment": "I apologize for that I missed the footnote about the operation of z, and I thought it is an MLP. However, it doesn't affect my question. What I wanted to emphasize here is that a simple nonlinearity after gaussian latent variables can be multimodal. Do we really need to have a hybrid gaussian piecewise constant distribution as the multimodal prior? If the mutimodality of z is critical, we can still have it by using an unimodal gaussian prior. In this case, \"it appears that the piecewise variables affect what is uncovered by the model with respect to the data, as each model returns different, but relevant results with respect to the query word ...\" doesn't make sense. "}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Multi-modal Variational Encoder-Decoders", "abstract": "Recent advances in neural variational inference have facilitated efficient training of powerful directed graphical models with continuous latent variables, such as variational autoencoders. However, these models usually assume simple, uni-modal priors \u2014 such as the multivariate Gaussian distribution \u2014 yet many real-world data distributions are highly complex and multi-modal. Examples of complex and multi-modal distributions range from topics in newswire text to conversational dialogue responses. When such latent variable models are applied to these domains, the restriction of the simple, uni-modal prior hinders the overall expressivity of the learned model as it cannot possibly capture more complex aspects of the data distribution. To overcome this critical restriction, we propose a flexible, simple prior distribution which can be learned efficiently and potentially capture an exponential number of modes of a target distribution. We develop the multi-modal variational encoder-decoder framework and investigate the effectiveness of the proposed prior in several natural language processing modeling tasks, including document modeling and dialogue modeling.", "pdf": "/pdf/071718de067f86d033a26cee3d6f7bd1e96215db.pdf", "TL;DR": "Learning continuous multimodal latent variables in the variational auto-encoder framework for text processing applications.", "paperhash": "serban|multimodal_variational_encoderdecoders", "keywords": ["Deep learning", "Structured prediction", "Natural language processing"], "conflicts": ["umontreal.ca", "psu.edu", "cs.mcgill.ca"], "authors": ["Iulian V. Serban", "Alexander G. Ororbia II", "Joelle Pineau", "Aaron Courville"], "authorids": ["julianserban@gmail.com", "ago109@psu.edu", "jpineau@cs.mcgill.ca", "aaron.courville@umontreal.ca"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287686563, "id": "ICLR.cc/2017/conference/-/paper204/official/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "reply": {"forum": "BJ9fZNqle", "writers": {"values-regex": "ICLR.cc/2017/conference/paper204/(AnonReviewer|areachair)[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/conference/paper204/(AnonReviewer|areachair)[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": [], "invitees": ["ICLR.cc/2017/conference/paper204/reviewers", "ICLR.cc/2017/conference/paper204/areachairs"], "cdate": 1485287686563}}}, {"tddate": null, "tmdate": 1481934262334, "tcdate": 1481927935398, "number": 2, "id": "BJw-pyfVe", "invitation": "ICLR.cc/2017/conference/-/paper204/official/review", "forum": "BJ9fZNqle", "replyto": "BJ9fZNqle", "signatures": ["ICLR.cc/2017/conference/paper204/AnonReviewer3"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/conference/paper204/AnonReviewer3"], "content": {"title": "Official Review", "rating": "4: Ok but not good enough - rejection", "review": "This paper proposes a piecewise constant parameterisation for neural variational models so that it could explore the multi-modality of the latent variables and develop more powerful neural models. \nThe experiments of neural variational document models and variational hierarchical recurrent encoder-decoder models show that the introduction of the piecewise constant distribution helps achieve better perplexity on modelling documents and seemly better performance on modelling dialogues.\nThe idea of having a piecewise constant prior for latent variables is interesting, but the paper is not well-written (even 14 pages long) and the design of the experiments fails to demonstrate the most of the claims.  \n\nThe detailed comments are as follows:\n\n--The author explains the limitations of the VAEs with standard Gaussian prior in the last paragraph of 3.1 and the last paragraph of 5.1. Hence, a multimodal prior would help the VAEs overcome the issues of optimisation. However, there is a lack of evidence showing the multimodality of the prior helps break the bottleneck. \n\n--In the last paragraph of 6.1, the author claimed the decoder parameter matrix is directly affected by the latent variables. But what the connects the decoder is a combination of a piecewise constant and Gaussian latent variables. No matter what is discovered in the experiments, it only shows z=<z_gaussian, z_piecewise> is multimodal. However, z=<z_gaussian1, z_gaussian2> can be multimodal as well. None of the claims in this paragraph stands.\n\n--In the quantitative evaluation of NVDM, there is an incremental model from z=z_gaussian to z=<z_gaussian, z_piecewise>. As the prior is learned together with the variational posterior, a more flexible prior would alleviate the regularisation imposed by the KL term. Certainly, more parameters are applied as well, so a fair comparison would at least be z=<z_gaussian, z_piecewise> and z=<z_gaussian1, z_gaussian2> which equals to a double sized z_gaussian. \n\n--The results shown in Table 3 are implausible. I cannot believe the author used gradients to evaluate the model. \n\n--Eq. 5 is confusing, adding a multiplication sign might help.\n\n--3.1 can be deleted because people attending ICLR are familiar with VAEs.\n\nTypos:\nas well as the well as the generated prior->  as well as the generated prior", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Multi-modal Variational Encoder-Decoders", "abstract": "Recent advances in neural variational inference have facilitated efficient training of powerful directed graphical models with continuous latent variables, such as variational autoencoders. However, these models usually assume simple, uni-modal priors \u2014 such as the multivariate Gaussian distribution \u2014 yet many real-world data distributions are highly complex and multi-modal. Examples of complex and multi-modal distributions range from topics in newswire text to conversational dialogue responses. When such latent variable models are applied to these domains, the restriction of the simple, uni-modal prior hinders the overall expressivity of the learned model as it cannot possibly capture more complex aspects of the data distribution. To overcome this critical restriction, we propose a flexible, simple prior distribution which can be learned efficiently and potentially capture an exponential number of modes of a target distribution. We develop the multi-modal variational encoder-decoder framework and investigate the effectiveness of the proposed prior in several natural language processing modeling tasks, including document modeling and dialogue modeling.", "pdf": "/pdf/071718de067f86d033a26cee3d6f7bd1e96215db.pdf", "TL;DR": "Learning continuous multimodal latent variables in the variational auto-encoder framework for text processing applications.", "paperhash": "serban|multimodal_variational_encoderdecoders", "keywords": ["Deep learning", "Structured prediction", "Natural language processing"], "conflicts": ["umontreal.ca", "psu.edu", "cs.mcgill.ca"], "authors": ["Iulian V. Serban", "Alexander G. Ororbia II", "Joelle Pineau", "Aaron Courville"], "authorids": ["julianserban@gmail.com", "ago109@psu.edu", "jpineau@cs.mcgill.ca", "aaron.courville@umontreal.ca"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1481932799000, "tmdate": 1482512664757, "id": "ICLR.cc/2017/conference/-/paper204/official/review", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/conference/paper204/reviewers"], "noninvitees": ["ICLR.cc/2017/conference/paper204/AnonReviewer1", "ICLR.cc/2017/conference/paper204/AnonReviewer3", "ICLR.cc/2017/conference/paper204/AnonReviewer4"], "reply": {"forum": "BJ9fZNqle", "replyto": "BJ9fZNqle", "writers": {"values-regex": "ICLR.cc/2017/conference/paper204/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/conference/paper204/AnonReviewer[0-9]+"}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "value-regex": "[\\S\\s]{1,20000}"}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1489708799000, "cdate": 1482512664757}}}, {"tddate": null, "replyto": null, "ddate": null, "tmdate": 1481452371944, "tcdate": 1478275345664, "number": 204, "id": "BJ9fZNqle", "invitation": "ICLR.cc/2017/conference/-/submission", "forum": "BJ9fZNqle", "signatures": ["~Iulian_Serban1"], "readers": ["everyone"], "content": {"title": "Multi-modal Variational Encoder-Decoders", "abstract": "Recent advances in neural variational inference have facilitated efficient training of powerful directed graphical models with continuous latent variables, such as variational autoencoders. However, these models usually assume simple, uni-modal priors \u2014 such as the multivariate Gaussian distribution \u2014 yet many real-world data distributions are highly complex and multi-modal. Examples of complex and multi-modal distributions range from topics in newswire text to conversational dialogue responses. When such latent variable models are applied to these domains, the restriction of the simple, uni-modal prior hinders the overall expressivity of the learned model as it cannot possibly capture more complex aspects of the data distribution. To overcome this critical restriction, we propose a flexible, simple prior distribution which can be learned efficiently and potentially capture an exponential number of modes of a target distribution. We develop the multi-modal variational encoder-decoder framework and investigate the effectiveness of the proposed prior in several natural language processing modeling tasks, including document modeling and dialogue modeling.", "pdf": "/pdf/071718de067f86d033a26cee3d6f7bd1e96215db.pdf", "TL;DR": "Learning continuous multimodal latent variables in the variational auto-encoder framework for text processing applications.", "paperhash": "serban|multimodal_variational_encoderdecoders", "keywords": ["Deep learning", "Structured prediction", "Natural language processing"], "conflicts": ["umontreal.ca", "psu.edu", "cs.mcgill.ca"], "authors": ["Iulian V. Serban", "Alexander G. Ororbia II", "Joelle Pineau", "Aaron Courville"], "authorids": ["julianserban@gmail.com", "ago109@psu.edu", "jpineau@cs.mcgill.ca", "aaron.courville@umontreal.ca"]}, "writers": [], "nonreaders": [], "details": {"replyCount": 27, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1475686800000, "tmdate": 1478287705855, "id": "ICLR.cc/2017/conference/-/submission", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/pcs"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": null, "replyto": null, "writers": {"values-regex": "~.*"}, "signatures": {"values-regex": "~.*", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"pdf": {"required": true, "order": 5, "description": "Either upload a PDF file or provide a direct link to your PDF on ArXiv (link must begin with http(s) and end with .pdf)", "value-regex": "upload|(http|https):\\/\\/.+\\.pdf"}, "title": {"required": true, "order": 1, "description": "Title of paper.", "value-regex": ".{1,250}"}, "abstract": {"required": true, "order": 4, "description": "Abstract of paper.", "value-regex": "[\\S\\s]{1,5000}"}, "authors": {"required": true, "order": 2, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of author names, as they appear in the paper."}, "conflicts": {"required": true, "order": 100, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of email domains of people who would have a conflict of interest in reviewing this paper, (e.g., cs.umass.edu;google.com, etc.)."}, "keywords": {"order": 6, "description": "Comma separated list of keywords.", "values-dropdown": ["Theory", "Computer vision", "Speech", "Natural language processing", "Deep learning", "Unsupervised Learning", "Supervised Learning", "Semi-Supervised Learning", "Reinforcement Learning", "Transfer Learning", "Multi-modal learning", "Applications", "Optimization", "Structured prediction", "Games"]}, "TL;DR": {"required": false, "order": 3, "description": "\"Too Long; Didn't Read\": a short sentence describing your paper", "value-regex": "[^\\n]{0,250}"}, "authorids": {"required": true, "order": 3, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of author email addresses, in the same order as above."}}}, "nonreaders": [], "noninvitees": [], "expdate": 1483462800000, "cdate": 1478287705855}}}, {"tddate": null, "tmdate": 1480784570073, "tcdate": 1480747830919, "number": 14, "id": "ryySs1gml", "invitation": "ICLR.cc/2017/conference/-/paper204/public/comment", "forum": "BJ9fZNqle", "replyto": "Sk23pFyQl", "signatures": ["~Alexander_G_Ororbia_II1"], "readers": ["everyone"], "writers": ["~Alexander_G_Ororbia_II1"], "content": {"title": "RE: Word query similarity test", "comment": "Hello,\n\nThe focus of the paper is to show that the proposed piecewise variables can benefit neural variational encoder-decoder architectures, such as the NVDM and the VHRED. As such (and to also avoid further clutter/yet more space for our manuscript) we focused on comparing the models with piecewise variables against the improved baseline, the G-NVDM (which encompasses the NVDM -- our target was to beat out the improved competition/baseline, the G-NVDM). The work of Miao et al. (2015) already showed that the NVDM, or rather, neural variational inference in general, was a better approach to document modeling than docNade and the Replicated Softmax model (reinforcing the initial results of Mnih & Gregor (2014)), so we felt that investigation along this line would have been redundant and chose to focus on the effect that using different latent variables had.  We chose to analyze the decoder matrix because in the document models (unlike the VHRED models, where the decoder is not directly connected to the latents), the direct input to the decoder is the generated latent variable state (when conditioned on a given document). As such, examining the synaptic connections connecting latent variables to word/output units can lend some insight towards the \"impact\" the latents have on the outputs in general (this is different than what is learned in the weights connecting the input units to the first hidden layer of the inference network, which would effectively be the word-embeddings). More importantly, we went beyond analyzing only the decoder matrix (since this is still, admittedly, a bit too indirect when measuring impact) and provided an approximate posterior analysis, found in the appendix, to confirm if the piecewise variables themselves were picking up different aspects of the data much as the dialogue encoder-decoder models appeared to.\n\nHowever, we do recognize that yet even further analysis of the piecewise variables learned by our proposed architectures is desirable (on perhaps even lesser-explored document data-sets in order to see what might be uncovered), and as such we will update the manuscript to reflect AnonReviewer3's comment, mentioning that a complementary, focused investigation is the subject of future work. In addition, we will modify the statement that AnonReviewer3 quoted such that it is less severe in its claim.\n\nThanks,\n\nAlex And Iulian"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Multi-modal Variational Encoder-Decoders", "abstract": "Recent advances in neural variational inference have facilitated efficient training of powerful directed graphical models with continuous latent variables, such as variational autoencoders. However, these models usually assume simple, uni-modal priors \u2014 such as the multivariate Gaussian distribution \u2014 yet many real-world data distributions are highly complex and multi-modal. Examples of complex and multi-modal distributions range from topics in newswire text to conversational dialogue responses. When such latent variable models are applied to these domains, the restriction of the simple, uni-modal prior hinders the overall expressivity of the learned model as it cannot possibly capture more complex aspects of the data distribution. To overcome this critical restriction, we propose a flexible, simple prior distribution which can be learned efficiently and potentially capture an exponential number of modes of a target distribution. We develop the multi-modal variational encoder-decoder framework and investigate the effectiveness of the proposed prior in several natural language processing modeling tasks, including document modeling and dialogue modeling.", "pdf": "/pdf/071718de067f86d033a26cee3d6f7bd1e96215db.pdf", "TL;DR": "Learning continuous multimodal latent variables in the variational auto-encoder framework for text processing applications.", "paperhash": "serban|multimodal_variational_encoderdecoders", "keywords": ["Deep learning", "Structured prediction", "Natural language processing"], "conflicts": ["umontreal.ca", "psu.edu", "cs.mcgill.ca"], "authors": ["Iulian V. Serban", "Alexander G. Ororbia II", "Joelle Pineau", "Aaron Courville"], "authorids": ["julianserban@gmail.com", "ago109@psu.edu", "jpineau@cs.mcgill.ca", "aaron.courville@umontreal.ca"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287686689, "id": "ICLR.cc/2017/conference/-/paper204/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "BJ9fZNqle", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper204/reviewers", "ICLR.cc/2017/conference/paper204/areachairs"], "cdate": 1485287686689}}}, {"tddate": null, "tmdate": 1480723892055, "tcdate": 1480723892051, "number": 2, "id": "Sk23pFyQl", "invitation": "ICLR.cc/2017/conference/-/paper204/pre-review/question", "forum": "BJ9fZNqle", "replyto": "BJ9fZNqle", "signatures": ["ICLR.cc/2017/conference/paper204/AnonReviewer3"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/conference/paper204/AnonReviewer3"], "content": {"title": "Word query similarity test", "question": "Why there is no comparison between your models and the baseline momdels (e.g. NVDM, docNADE or Replicated Softmax) in the word query similarity test? The argument \"It is clear that the piecewise variables affect what is uncovered by the model with respect to the data, as each model returns different, but relevant results with respect to the query word\" does not seem to stand. The latent variable represents the document level semantics which is multi-modal, but the evaluation is carried out by only using the decoder parameter matrix which is fixed. Basically, the words are tied to fixed embeddings. How is the multi-modality of the document semantics related to this?"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Multi-modal Variational Encoder-Decoders", "abstract": "Recent advances in neural variational inference have facilitated efficient training of powerful directed graphical models with continuous latent variables, such as variational autoencoders. However, these models usually assume simple, uni-modal priors \u2014 such as the multivariate Gaussian distribution \u2014 yet many real-world data distributions are highly complex and multi-modal. Examples of complex and multi-modal distributions range from topics in newswire text to conversational dialogue responses. When such latent variable models are applied to these domains, the restriction of the simple, uni-modal prior hinders the overall expressivity of the learned model as it cannot possibly capture more complex aspects of the data distribution. To overcome this critical restriction, we propose a flexible, simple prior distribution which can be learned efficiently and potentially capture an exponential number of modes of a target distribution. We develop the multi-modal variational encoder-decoder framework and investigate the effectiveness of the proposed prior in several natural language processing modeling tasks, including document modeling and dialogue modeling.", "pdf": "/pdf/071718de067f86d033a26cee3d6f7bd1e96215db.pdf", "TL;DR": "Learning continuous multimodal latent variables in the variational auto-encoder framework for text processing applications.", "paperhash": "serban|multimodal_variational_encoderdecoders", "keywords": ["Deep learning", "Structured prediction", "Natural language processing"], "conflicts": ["umontreal.ca", "psu.edu", "cs.mcgill.ca"], "authors": ["Iulian V. Serban", "Alexander G. Ororbia II", "Joelle Pineau", "Aaron Courville"], "authorids": ["julianserban@gmail.com", "ago109@psu.edu", "jpineau@cs.mcgill.ca", "aaron.courville@umontreal.ca"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1480741199000, "tmdate": 1480959407981, "id": "ICLR.cc/2017/conference/-/paper204/pre-review/question", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/conference/paper204/reviewers"], "noninvitees": ["ICLR.cc/2017/conference/paper204/AnonReviewer4", "ICLR.cc/2017/conference/paper204/AnonReviewer3"], "reply": {"forum": "BJ9fZNqle", "replyto": "BJ9fZNqle", "writers": {"values-regex": "ICLR.cc/2017/conference/paper204/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/conference/paper204/AnonReviewer[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your question.", "value-regex": ".{1,500}"}, "question": {"order": 2, "description": "Your question", "value-regex": "[\\S\\s]{1,5000}"}}}, "nonreaders": [], "expdate": 1488517199000, "cdate": 1480959407981}}}, {"tddate": null, "tmdate": 1480715475516, "tcdate": 1480715475511, "number": 13, "id": "SkiAnw1Qg", "invitation": "ICLR.cc/2017/conference/-/paper204/public/comment", "forum": "BJ9fZNqle", "replyto": "rktRfIJXx", "signatures": ["~Alexander_G_Ororbia_II1"], "readers": ["everyone"], "writers": ["~Alexander_G_Ororbia_II1"], "content": {"title": "RE: AnonReviewer4 Question", "comment": "Hello,\n\nThe main difference between the G-NVDM and NVDM is that: 1) the prior mean and variance parameters are learned (by taking the derivative of the variational lower bound with respect to each), and 2) the posterior is calculated as an interpolation (or gating) of both the generated prior and posterior parameters.\n\nOur choice for the above design decisions, for both the document models and dialogue models, is largely experimental as we empirically found that this led to better performance on the data-sets used. We interpret our choice for learning the prior as simply updating the model's general beliefs about the data (especially in the case of document models, where the prior is not conditioned on any context information like the dialogue models) since it might find that a standard Gaussian space is, perhaps, a less-than-reasonable prior. Since calculating the gradients with respect to the prior is rather cheap in a fully-differentiable architecture, we saw no reason not to try updating the prior in an effort to see if the baseline performance could be further improved. However, the interpolation mechanism led to the greatest improvement in performance.\n\nThanks,\n\nAlex And Iulian"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Multi-modal Variational Encoder-Decoders", "abstract": "Recent advances in neural variational inference have facilitated efficient training of powerful directed graphical models with continuous latent variables, such as variational autoencoders. However, these models usually assume simple, uni-modal priors \u2014 such as the multivariate Gaussian distribution \u2014 yet many real-world data distributions are highly complex and multi-modal. Examples of complex and multi-modal distributions range from topics in newswire text to conversational dialogue responses. When such latent variable models are applied to these domains, the restriction of the simple, uni-modal prior hinders the overall expressivity of the learned model as it cannot possibly capture more complex aspects of the data distribution. To overcome this critical restriction, we propose a flexible, simple prior distribution which can be learned efficiently and potentially capture an exponential number of modes of a target distribution. We develop the multi-modal variational encoder-decoder framework and investigate the effectiveness of the proposed prior in several natural language processing modeling tasks, including document modeling and dialogue modeling.", "pdf": "/pdf/071718de067f86d033a26cee3d6f7bd1e96215db.pdf", "TL;DR": "Learning continuous multimodal latent variables in the variational auto-encoder framework for text processing applications.", "paperhash": "serban|multimodal_variational_encoderdecoders", "keywords": ["Deep learning", "Structured prediction", "Natural language processing"], "conflicts": ["umontreal.ca", "psu.edu", "cs.mcgill.ca"], "authors": ["Iulian V. Serban", "Alexander G. Ororbia II", "Joelle Pineau", "Aaron Courville"], "authorids": ["julianserban@gmail.com", "ago109@psu.edu", "jpineau@cs.mcgill.ca", "aaron.courville@umontreal.ca"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287686689, "id": "ICLR.cc/2017/conference/-/paper204/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "BJ9fZNqle", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper204/reviewers", "ICLR.cc/2017/conference/paper204/areachairs"], "cdate": 1485287686689}}}, {"tddate": null, "tmdate": 1480708816624, "tcdate": 1480708816618, "number": 1, "id": "rktRfIJXx", "invitation": "ICLR.cc/2017/conference/-/paper204/pre-review/question", "forum": "BJ9fZNqle", "replyto": "BJ9fZNqle", "signatures": ["ICLR.cc/2017/conference/paper204/AnonReviewer4"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/conference/paper204/AnonReviewer4"], "content": {"title": "Question", "question": "Since it gives such dramatically better results on 20-NG, what is the exact difference between G-NVDM and NVDM? Is it the interpolation/gating between prior and posterior? Or is it the learned prior? Why does learning a variance and mean for the Gaussian prior help, when the latent space is already transformed by an affine transformation by the decoder and encoder networks? It seems that a standard Gaussian prior should have the same expressive capabilities since the posterior should be able to learn to transform itself into the \"whitened\" prior space. "}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Multi-modal Variational Encoder-Decoders", "abstract": "Recent advances in neural variational inference have facilitated efficient training of powerful directed graphical models with continuous latent variables, such as variational autoencoders. However, these models usually assume simple, uni-modal priors \u2014 such as the multivariate Gaussian distribution \u2014 yet many real-world data distributions are highly complex and multi-modal. Examples of complex and multi-modal distributions range from topics in newswire text to conversational dialogue responses. When such latent variable models are applied to these domains, the restriction of the simple, uni-modal prior hinders the overall expressivity of the learned model as it cannot possibly capture more complex aspects of the data distribution. To overcome this critical restriction, we propose a flexible, simple prior distribution which can be learned efficiently and potentially capture an exponential number of modes of a target distribution. We develop the multi-modal variational encoder-decoder framework and investigate the effectiveness of the proposed prior in several natural language processing modeling tasks, including document modeling and dialogue modeling.", "pdf": "/pdf/071718de067f86d033a26cee3d6f7bd1e96215db.pdf", "TL;DR": "Learning continuous multimodal latent variables in the variational auto-encoder framework for text processing applications.", "paperhash": "serban|multimodal_variational_encoderdecoders", "keywords": ["Deep learning", "Structured prediction", "Natural language processing"], "conflicts": ["umontreal.ca", "psu.edu", "cs.mcgill.ca"], "authors": ["Iulian V. Serban", "Alexander G. Ororbia II", "Joelle Pineau", "Aaron Courville"], "authorids": ["julianserban@gmail.com", "ago109@psu.edu", "jpineau@cs.mcgill.ca", "aaron.courville@umontreal.ca"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1480741199000, "tmdate": 1480959407981, "id": "ICLR.cc/2017/conference/-/paper204/pre-review/question", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/conference/paper204/reviewers"], "noninvitees": ["ICLR.cc/2017/conference/paper204/AnonReviewer4", "ICLR.cc/2017/conference/paper204/AnonReviewer3"], "reply": {"forum": "BJ9fZNqle", "replyto": "BJ9fZNqle", "writers": {"values-regex": "ICLR.cc/2017/conference/paper204/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/conference/paper204/AnonReviewer[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your question.", "value-regex": ".{1,500}"}, "question": {"order": 2, "description": "Your question", "value-regex": "[\\S\\s]{1,5000}"}}}, "nonreaders": [], "expdate": 1488517199000, "cdate": 1480959407981}}}, {"tddate": null, "tmdate": 1478739835168, "tcdate": 1478739835093, "number": 12, "id": "Hk-KPr-Wx", "invitation": "ICLR.cc/2017/conference/-/paper204/public/comment", "forum": "BJ9fZNqle", "replyto": "B1NoL21-l", "signatures": ["~Iulian_Serban1"], "readers": ["everyone"], "writers": ["~Iulian_Serban1"], "content": {"title": "Uni-modal Prior", "comment": "Hi Christian,\n\nYes, certainly deep latent Gaussian models (and other deep latent variable models) can model multi-modality when we consider their marginal latent variable representations. However, our approach is orthogonal to such models, because we explicitly model multi-modality in a single latent variable (both in the prior and posterior).\n\nIn practice, which model works better is going to be task-dependent. Still, the piecewise latent variables are different because:\n1) they explicitly represent the multi-modality within each latent variable,\n2) they can potentially represent an exponential number of modes (it's not clear that any deep model with continuous variables can do this), and\n3) they only require sampling one layer of latent variables (which reduces the gradient estimate variances, thus making it easier to learn complex latent variable distributions and scale up to larger tasks compared to deeper models).\n\nAlso, thanks for your comments! We really appreciate them, and we are updating our paper based on them!\n\nCheers,\n\nIulian"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Multi-modal Variational Encoder-Decoders", "abstract": "Recent advances in neural variational inference have facilitated efficient training of powerful directed graphical models with continuous latent variables, such as variational autoencoders. However, these models usually assume simple, uni-modal priors \u2014 such as the multivariate Gaussian distribution \u2014 yet many real-world data distributions are highly complex and multi-modal. Examples of complex and multi-modal distributions range from topics in newswire text to conversational dialogue responses. When such latent variable models are applied to these domains, the restriction of the simple, uni-modal prior hinders the overall expressivity of the learned model as it cannot possibly capture more complex aspects of the data distribution. To overcome this critical restriction, we propose a flexible, simple prior distribution which can be learned efficiently and potentially capture an exponential number of modes of a target distribution. We develop the multi-modal variational encoder-decoder framework and investigate the effectiveness of the proposed prior in several natural language processing modeling tasks, including document modeling and dialogue modeling.", "pdf": "/pdf/071718de067f86d033a26cee3d6f7bd1e96215db.pdf", "TL;DR": "Learning continuous multimodal latent variables in the variational auto-encoder framework for text processing applications.", "paperhash": "serban|multimodal_variational_encoderdecoders", "keywords": ["Deep learning", "Structured prediction", "Natural language processing"], "conflicts": ["umontreal.ca", "psu.edu", "cs.mcgill.ca"], "authors": ["Iulian V. Serban", "Alexander G. Ororbia II", "Joelle Pineau", "Aaron Courville"], "authorids": ["julianserban@gmail.com", "ago109@psu.edu", "jpineau@cs.mcgill.ca", "aaron.courville@umontreal.ca"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287686689, "id": "ICLR.cc/2017/conference/-/paper204/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "BJ9fZNqle", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper204/reviewers", "ICLR.cc/2017/conference/paper204/areachairs"], "cdate": 1485287686689}}}, {"tddate": null, "tmdate": 1478637267544, "tcdate": 1478637212499, "number": 11, "id": "B1NoL21-l", "invitation": "ICLR.cc/2017/conference/-/paper204/public/comment", "forum": "BJ9fZNqle", "replyto": "SkZoCOyZx", "signatures": ["~Christian_A_Naesseth1"], "readers": ["everyone"], "writers": ["~Christian_A_Naesseth1"], "content": {"title": "Uni-modal Prior", "comment": "Wouldn't a VAE typically use more than one layer of latent variables (\"deep latent Gaussian models\")? Although each conditional distribution is a unimodal (diagonal) Gaussian, the marginals (and joints) of later latent layers are not. I am just trying to understand the motivation behind the idea of using the piece-wise constant density, which is very interesting!\n\nCheers,\nChristian"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Multi-modal Variational Encoder-Decoders", "abstract": "Recent advances in neural variational inference have facilitated efficient training of powerful directed graphical models with continuous latent variables, such as variational autoencoders. However, these models usually assume simple, uni-modal priors \u2014 such as the multivariate Gaussian distribution \u2014 yet many real-world data distributions are highly complex and multi-modal. Examples of complex and multi-modal distributions range from topics in newswire text to conversational dialogue responses. When such latent variable models are applied to these domains, the restriction of the simple, uni-modal prior hinders the overall expressivity of the learned model as it cannot possibly capture more complex aspects of the data distribution. To overcome this critical restriction, we propose a flexible, simple prior distribution which can be learned efficiently and potentially capture an exponential number of modes of a target distribution. We develop the multi-modal variational encoder-decoder framework and investigate the effectiveness of the proposed prior in several natural language processing modeling tasks, including document modeling and dialogue modeling.", "pdf": "/pdf/071718de067f86d033a26cee3d6f7bd1e96215db.pdf", "TL;DR": "Learning continuous multimodal latent variables in the variational auto-encoder framework for text processing applications.", "paperhash": "serban|multimodal_variational_encoderdecoders", "keywords": ["Deep learning", "Structured prediction", "Natural language processing"], "conflicts": ["umontreal.ca", "psu.edu", "cs.mcgill.ca"], "authors": ["Iulian V. Serban", "Alexander G. Ororbia II", "Joelle Pineau", "Aaron Courville"], "authorids": ["julianserban@gmail.com", "ago109@psu.edu", "jpineau@cs.mcgill.ca", "aaron.courville@umontreal.ca"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287686689, "id": "ICLR.cc/2017/conference/-/paper204/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "BJ9fZNqle", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper204/reviewers", "ICLR.cc/2017/conference/paper204/areachairs"], "cdate": 1485287686689}}}, {"tddate": null, "tmdate": 1478636919010, "tcdate": 1478636873786, "number": 10, "id": "SkGLBnkWx", "invitation": "ICLR.cc/2017/conference/-/paper204/public/comment", "forum": "BJ9fZNqle", "replyto": "B1ONh_yWe", "signatures": ["~Christian_A_Naesseth1"], "readers": ["everyone"], "writers": ["~Christian_A_Naesseth1"], "content": {"title": "Differentiability of indicators", "comment": "The formalization using distribution theory will (I think) lead to something that is non-zero. So the gradient you obtain by making this approximation will be biased and it is unclear what effect this will have on the results. However, the variational bound is unaffected as you mention.\n\nBest regards,\nChristian"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Multi-modal Variational Encoder-Decoders", "abstract": "Recent advances in neural variational inference have facilitated efficient training of powerful directed graphical models with continuous latent variables, such as variational autoencoders. However, these models usually assume simple, uni-modal priors \u2014 such as the multivariate Gaussian distribution \u2014 yet many real-world data distributions are highly complex and multi-modal. Examples of complex and multi-modal distributions range from topics in newswire text to conversational dialogue responses. When such latent variable models are applied to these domains, the restriction of the simple, uni-modal prior hinders the overall expressivity of the learned model as it cannot possibly capture more complex aspects of the data distribution. To overcome this critical restriction, we propose a flexible, simple prior distribution which can be learned efficiently and potentially capture an exponential number of modes of a target distribution. We develop the multi-modal variational encoder-decoder framework and investigate the effectiveness of the proposed prior in several natural language processing modeling tasks, including document modeling and dialogue modeling.", "pdf": "/pdf/071718de067f86d033a26cee3d6f7bd1e96215db.pdf", "TL;DR": "Learning continuous multimodal latent variables in the variational auto-encoder framework for text processing applications.", "paperhash": "serban|multimodal_variational_encoderdecoders", "keywords": ["Deep learning", "Structured prediction", "Natural language processing"], "conflicts": ["umontreal.ca", "psu.edu", "cs.mcgill.ca"], "authors": ["Iulian V. Serban", "Alexander G. Ororbia II", "Joelle Pineau", "Aaron Courville"], "authorids": ["julianserban@gmail.com", "ago109@psu.edu", "jpineau@cs.mcgill.ca", "aaron.courville@umontreal.ca"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287686689, "id": "ICLR.cc/2017/conference/-/paper204/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "BJ9fZNqle", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper204/reviewers", "ICLR.cc/2017/conference/paper204/areachairs"], "cdate": 1485287686689}}}, {"tddate": null, "tmdate": 1478622872774, "tcdate": 1478622872768, "number": 9, "id": "SkZoCOyZx", "invitation": "ICLR.cc/2017/conference/-/paper204/public/comment", "forum": "BJ9fZNqle", "replyto": "SJlipLJZe", "signatures": ["~Iulian_Serban1"], "readers": ["everyone"], "writers": ["~Iulian_Serban1"], "content": {"title": "Uni-modal Prior", "comment": "Hi Christian,\n\n> Also, it is unclear if the paper is actually arguing that VAE learns unimodal generative distributions? The generative distribution that is learnt using a VAE is typically not unimodal, even though the prior p(z) is.\n\nWhen we discuss multi-modality, we are referring to the latent variable space. For example, when a model uses a Gaussian as prior distribution p(z), then the latent variable distribution is uni-modal. In this case, multi-modality can only be represented by the decoder model generating the data x: p(x|z).\n\nCheers,\n\nIulian"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Multi-modal Variational Encoder-Decoders", "abstract": "Recent advances in neural variational inference have facilitated efficient training of powerful directed graphical models with continuous latent variables, such as variational autoencoders. However, these models usually assume simple, uni-modal priors \u2014 such as the multivariate Gaussian distribution \u2014 yet many real-world data distributions are highly complex and multi-modal. Examples of complex and multi-modal distributions range from topics in newswire text to conversational dialogue responses. When such latent variable models are applied to these domains, the restriction of the simple, uni-modal prior hinders the overall expressivity of the learned model as it cannot possibly capture more complex aspects of the data distribution. To overcome this critical restriction, we propose a flexible, simple prior distribution which can be learned efficiently and potentially capture an exponential number of modes of a target distribution. We develop the multi-modal variational encoder-decoder framework and investigate the effectiveness of the proposed prior in several natural language processing modeling tasks, including document modeling and dialogue modeling.", "pdf": "/pdf/071718de067f86d033a26cee3d6f7bd1e96215db.pdf", "TL;DR": "Learning continuous multimodal latent variables in the variational auto-encoder framework for text processing applications.", "paperhash": "serban|multimodal_variational_encoderdecoders", "keywords": ["Deep learning", "Structured prediction", "Natural language processing"], "conflicts": ["umontreal.ca", "psu.edu", "cs.mcgill.ca"], "authors": ["Iulian V. Serban", "Alexander G. Ororbia II", "Joelle Pineau", "Aaron Courville"], "authorids": ["julianserban@gmail.com", "ago109@psu.edu", "jpineau@cs.mcgill.ca", "aaron.courville@umontreal.ca"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287686689, "id": "ICLR.cc/2017/conference/-/paper204/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "BJ9fZNqle", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper204/reviewers", "ICLR.cc/2017/conference/paper204/areachairs"], "cdate": 1485287686689}}}, {"tddate": null, "tmdate": 1478622256083, "tcdate": 1478622256078, "number": 8, "id": "B1ONh_yWe", "invitation": "ICLR.cc/2017/conference/-/paper204/public/comment", "forum": "BJ9fZNqle", "replyto": "SJlipLJZe", "signatures": ["~Iulian_Serban1"], "readers": ["everyone"], "writers": ["~Iulian_Serban1"], "content": {"title": "Differentiability of indicators", "comment": "Dear Christian,\n\nI think I understand now. My assumption that the indicator functions in eq. (8) were almost everywhere differentiable was incorrect. As such, we cannot take the derivative outside the expectation in eq. (1) in my last post.\n\nThere might be a mathematically more rigorous argument justifying this, for example using the distribution theorem you mentioned or perhaps by considering the indicator function a limit of a continuous and differentiable function. However, for the sake of this paper I think we can simply consider it an approximation. Whenever we sample one of the two boundary points --- f_1(x) = \\epsilon or f_2(x) = \\epsilon ---  we set the derivative to zero. Still, as I pointed out before, this happens with zero probability.\n\nAlso note this does not affect the validation and testing procedure. The gradients are not required for computing the variational bound itself, hence this is exact.\n\n"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Multi-modal Variational Encoder-Decoders", "abstract": "Recent advances in neural variational inference have facilitated efficient training of powerful directed graphical models with continuous latent variables, such as variational autoencoders. However, these models usually assume simple, uni-modal priors \u2014 such as the multivariate Gaussian distribution \u2014 yet many real-world data distributions are highly complex and multi-modal. Examples of complex and multi-modal distributions range from topics in newswire text to conversational dialogue responses. When such latent variable models are applied to these domains, the restriction of the simple, uni-modal prior hinders the overall expressivity of the learned model as it cannot possibly capture more complex aspects of the data distribution. To overcome this critical restriction, we propose a flexible, simple prior distribution which can be learned efficiently and potentially capture an exponential number of modes of a target distribution. We develop the multi-modal variational encoder-decoder framework and investigate the effectiveness of the proposed prior in several natural language processing modeling tasks, including document modeling and dialogue modeling.", "pdf": "/pdf/071718de067f86d033a26cee3d6f7bd1e96215db.pdf", "TL;DR": "Learning continuous multimodal latent variables in the variational auto-encoder framework for text processing applications.", "paperhash": "serban|multimodal_variational_encoderdecoders", "keywords": ["Deep learning", "Structured prediction", "Natural language processing"], "conflicts": ["umontreal.ca", "psu.edu", "cs.mcgill.ca"], "authors": ["Iulian V. Serban", "Alexander G. Ororbia II", "Joelle Pineau", "Aaron Courville"], "authorids": ["julianserban@gmail.com", "ago109@psu.edu", "jpineau@cs.mcgill.ca", "aaron.courville@umontreal.ca"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287686689, "id": "ICLR.cc/2017/conference/-/paper204/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "BJ9fZNqle", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper204/reviewers", "ICLR.cc/2017/conference/paper204/areachairs"], "cdate": 1485287686689}}}, {"tddate": null, "tmdate": 1478614424216, "tcdate": 1478614424207, "number": 7, "id": "SJlipLJZe", "invitation": "ICLR.cc/2017/conference/-/paper204/public/comment", "forum": "BJ9fZNqle", "replyto": "B1WUcqAlg", "signatures": ["~Christian_A_Naesseth1"], "readers": ["everyone"], "writers": ["~Christian_A_Naesseth1"], "content": {"title": "Differentiability of indicators", "comment": "Hi Iulian,\n\nThanks for your input! The point I am trying to make is that changing the order of expectation and derivative is not a straightforward operation in this case. Typically to interchange the order we have to make some assumptions to show that it is valid, http://planetmath.org/differentiationundertheintegralsign explains several common options. Adapted to your problem omega=epsilon and x is your parameters. Normally Thm 2 or 3 is enough to guarantee that this is a valid thing to do. However, as I have shown above the sufficient conditions for Thm 1-3 are not satisfied in your case, the partial derivative of your function f is not even differentiable a.e. with respect to the parameters. It might be possible to salvage the problem by considering distribution theory like in Thm 4, but it is unclear what would fall out and requires further derivation.\n\nNote that my first example above makes use of the fact that f_i(x) = f_i(cx) for all positive scalars c.\n\nAlso, it is unclear if the paper is actually arguing that VAE learns unimodal generative distributions? The generative distribution that is learnt using a VAE is typically not unimodal, even though the prior p(z) is.\n\nBest regards,\nChristian"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Multi-modal Variational Encoder-Decoders", "abstract": "Recent advances in neural variational inference have facilitated efficient training of powerful directed graphical models with continuous latent variables, such as variational autoencoders. However, these models usually assume simple, uni-modal priors \u2014 such as the multivariate Gaussian distribution \u2014 yet many real-world data distributions are highly complex and multi-modal. Examples of complex and multi-modal distributions range from topics in newswire text to conversational dialogue responses. When such latent variable models are applied to these domains, the restriction of the simple, uni-modal prior hinders the overall expressivity of the learned model as it cannot possibly capture more complex aspects of the data distribution. To overcome this critical restriction, we propose a flexible, simple prior distribution which can be learned efficiently and potentially capture an exponential number of modes of a target distribution. We develop the multi-modal variational encoder-decoder framework and investigate the effectiveness of the proposed prior in several natural language processing modeling tasks, including document modeling and dialogue modeling.", "pdf": "/pdf/071718de067f86d033a26cee3d6f7bd1e96215db.pdf", "TL;DR": "Learning continuous multimodal latent variables in the variational auto-encoder framework for text processing applications.", "paperhash": "serban|multimodal_variational_encoderdecoders", "keywords": ["Deep learning", "Structured prediction", "Natural language processing"], "conflicts": ["umontreal.ca", "psu.edu", "cs.mcgill.ca"], "authors": ["Iulian V. Serban", "Alexander G. Ororbia II", "Joelle Pineau", "Aaron Courville"], "authorids": ["julianserban@gmail.com", "ago109@psu.edu", "jpineau@cs.mcgill.ca", "aaron.courville@umontreal.ca"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287686689, "id": "ICLR.cc/2017/conference/-/paper204/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "BJ9fZNqle", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper204/reviewers", "ICLR.cc/2017/conference/paper204/areachairs"], "cdate": 1485287686689}}}, {"tddate": null, "tmdate": 1478564425186, "tcdate": 1478564425180, "number": 6, "id": "B1WUcqAlg", "invitation": "ICLR.cc/2017/conference/-/paper204/public/comment", "forum": "BJ9fZNqle", "replyto": "Hk4Ayc0xx", "signatures": ["~Iulian_Serban1"], "readers": ["everyone"], "writers": ["~Iulian_Serban1"], "content": {"title": "Differentiability of indicators", "comment": "Dear Christian,\n\n> Even if we define the derivative of the indicator functions to be zero everywhere but at the point where a change occurs (where it would be undefined), the points where a change occurs in your setup is not measure zero. Assume that the point a is such a point, then any c*a where c > 0, i.e. a positive constant, is also such a point. This basically means we can characterize these as rays which are not measure zero sets.\n\nI believe this argument is incorrect. You are assuming that any point c*a, for c > 0, is a non-differentiable point. This may be true for certain indicator functions (Dirac delta functions), but it is not true for eq. (8).\n\nHere is a more detailed explanation. The indicator functions in eq. (8) have the form:\n\n    1_{f_1(x) \\lt \\epsilon \\lt f_2(x)}\n\nwhere f_1 and f_2 are functions of the parameter x, and where we assume f_1(x) < f_2(x).\n\nOur claim is that almost everywhere this derivative is zero:\n\n    E_{\\epsilon}[d/dx 1_{f_1(x) \\lt \\epsilon \\lt f_2(x)}] = 0,         where \\epsilon is a random variable (1)\n\nWe need to consider three cases before taking the expectation:\n\nCase #1: When the indicator is on:\n\n    f_1(x) < \\epsilon < f_2(x)\n\nIn this case, given any infinitesimal change to f_1(x) or f_2(x), the indicator function is one. Hence, the derivative is exactly zero in expectation.\n\nCase #2: When the indicator is off:\n\n    \\epsilon < f_1(x) < f_2(x) or f_1(x) < f_2(x) < \\epsilon\n\nIn this case, given any infinitesimal change to f_1(x) or f_2(x), the indicator function is zero. Hence, the derivative is exactly zero in expectation.\n\nCase #3: When the indicator is changing:\n\n    f_1(x) = \\epsilon < f_2(x) or f_1(x) < \\epsilon = f_2(x)\n\nIn this case, the derivative is indeed undefined. However, this point has zero probability:\n\n    P(f_1(x) = \\epsilon) = P(f_2(x) = \\epsilon) = 0\n\nThe reason is that \\epsilon is continuous random variable; the point probability of any continuous random variable with a continuous PDF is zero (such as a Gaussian or uniform random variable). So we can safely fix this derivative to zero without affecting the expectation in my equation (1) above. Hope this clarifies things!\n\nCheers,\n\nIulian"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Multi-modal Variational Encoder-Decoders", "abstract": "Recent advances in neural variational inference have facilitated efficient training of powerful directed graphical models with continuous latent variables, such as variational autoencoders. However, these models usually assume simple, uni-modal priors \u2014 such as the multivariate Gaussian distribution \u2014 yet many real-world data distributions are highly complex and multi-modal. Examples of complex and multi-modal distributions range from topics in newswire text to conversational dialogue responses. When such latent variable models are applied to these domains, the restriction of the simple, uni-modal prior hinders the overall expressivity of the learned model as it cannot possibly capture more complex aspects of the data distribution. To overcome this critical restriction, we propose a flexible, simple prior distribution which can be learned efficiently and potentially capture an exponential number of modes of a target distribution. We develop the multi-modal variational encoder-decoder framework and investigate the effectiveness of the proposed prior in several natural language processing modeling tasks, including document modeling and dialogue modeling.", "pdf": "/pdf/071718de067f86d033a26cee3d6f7bd1e96215db.pdf", "TL;DR": "Learning continuous multimodal latent variables in the variational auto-encoder framework for text processing applications.", "paperhash": "serban|multimodal_variational_encoderdecoders", "keywords": ["Deep learning", "Structured prediction", "Natural language processing"], "conflicts": ["umontreal.ca", "psu.edu", "cs.mcgill.ca"], "authors": ["Iulian V. Serban", "Alexander G. Ororbia II", "Joelle Pineau", "Aaron Courville"], "authorids": ["julianserban@gmail.com", "ago109@psu.edu", "jpineau@cs.mcgill.ca", "aaron.courville@umontreal.ca"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287686689, "id": "ICLR.cc/2017/conference/-/paper204/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "BJ9fZNqle", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper204/reviewers", "ICLR.cc/2017/conference/paper204/areachairs"], "cdate": 1485287686689}}}, {"tddate": null, "tmdate": 1478561740610, "tcdate": 1478561740604, "number": 5, "id": "Hk4Ayc0xx", "invitation": "ICLR.cc/2017/conference/-/paper204/public/comment", "forum": "BJ9fZNqle", "replyto": "SkJldK0gx", "signatures": ["~Christian_A_Naesseth1"], "readers": ["everyone"], "writers": ["~Christian_A_Naesseth1"], "content": {"title": "Differentiability of indicators", "comment": "Hi Iulian and Alex,\n\nEven if we define the derivative of the indicator functions to be zero everywhere but at the point where a change occurs (where it would be undefined), the points where a change occurs in your setup is not measure zero. Assume that the point a is such a point, then any c*a where c > 0, i.e. a positive constant, is also such a point. This basically means we can characterize these as rays which are not measure zero sets. Removing this scenario by constraining \\sum_i a_i = 1 we can take another example: For a fix epsilon we can find a value a_1 such that we end up on the boundary between e.g. i=1 and 2. Now because a_i for i>1 can be arbitrary values between 0 and 1 that sums to one, we again have a set that is not measure zero.\n\nBest regards,\nChristian"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Multi-modal Variational Encoder-Decoders", "abstract": "Recent advances in neural variational inference have facilitated efficient training of powerful directed graphical models with continuous latent variables, such as variational autoencoders. However, these models usually assume simple, uni-modal priors \u2014 such as the multivariate Gaussian distribution \u2014 yet many real-world data distributions are highly complex and multi-modal. Examples of complex and multi-modal distributions range from topics in newswire text to conversational dialogue responses. When such latent variable models are applied to these domains, the restriction of the simple, uni-modal prior hinders the overall expressivity of the learned model as it cannot possibly capture more complex aspects of the data distribution. To overcome this critical restriction, we propose a flexible, simple prior distribution which can be learned efficiently and potentially capture an exponential number of modes of a target distribution. We develop the multi-modal variational encoder-decoder framework and investigate the effectiveness of the proposed prior in several natural language processing modeling tasks, including document modeling and dialogue modeling.", "pdf": "/pdf/071718de067f86d033a26cee3d6f7bd1e96215db.pdf", "TL;DR": "Learning continuous multimodal latent variables in the variational auto-encoder framework for text processing applications.", "paperhash": "serban|multimodal_variational_encoderdecoders", "keywords": ["Deep learning", "Structured prediction", "Natural language processing"], "conflicts": ["umontreal.ca", "psu.edu", "cs.mcgill.ca"], "authors": ["Iulian V. Serban", "Alexander G. Ororbia II", "Joelle Pineau", "Aaron Courville"], "authorids": ["julianserban@gmail.com", "ago109@psu.edu", "jpineau@cs.mcgill.ca", "aaron.courville@umontreal.ca"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287686689, "id": "ICLR.cc/2017/conference/-/paper204/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "BJ9fZNqle", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper204/reviewers", "ICLR.cc/2017/conference/paper204/areachairs"], "cdate": 1485287686689}}}, {"tddate": null, "tmdate": 1478559719513, "tcdate": 1478559719506, "number": 4, "id": "SkJldK0gx", "invitation": "ICLR.cc/2017/conference/-/paper204/public/comment", "forum": "BJ9fZNqle", "replyto": "Sk7DiL0ex", "signatures": ["~Alexander_G_Ororbia_II1"], "readers": ["everyone"], "writers": ["~Alexander_G_Ororbia_II1"], "content": {"title": "RE: Differentiability of the reparameterization", "comment": "Hello,\n\nThe Dirac delta functions are differentiable almost everywhere. The only non-differentiable point is the switch from 0 to 1. However, this happens with zero probability, or rather, the probability of sampling that exact point is zero. In implementation, we set the gradients at these switching points to zero. So in expectation our gradients are correct.\n\nThanks,\nIulian And Alex"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Multi-modal Variational Encoder-Decoders", "abstract": "Recent advances in neural variational inference have facilitated efficient training of powerful directed graphical models with continuous latent variables, such as variational autoencoders. However, these models usually assume simple, uni-modal priors \u2014 such as the multivariate Gaussian distribution \u2014 yet many real-world data distributions are highly complex and multi-modal. Examples of complex and multi-modal distributions range from topics in newswire text to conversational dialogue responses. When such latent variable models are applied to these domains, the restriction of the simple, uni-modal prior hinders the overall expressivity of the learned model as it cannot possibly capture more complex aspects of the data distribution. To overcome this critical restriction, we propose a flexible, simple prior distribution which can be learned efficiently and potentially capture an exponential number of modes of a target distribution. We develop the multi-modal variational encoder-decoder framework and investigate the effectiveness of the proposed prior in several natural language processing modeling tasks, including document modeling and dialogue modeling.", "pdf": "/pdf/071718de067f86d033a26cee3d6f7bd1e96215db.pdf", "TL;DR": "Learning continuous multimodal latent variables in the variational auto-encoder framework for text processing applications.", "paperhash": "serban|multimodal_variational_encoderdecoders", "keywords": ["Deep learning", "Structured prediction", "Natural language processing"], "conflicts": ["umontreal.ca", "psu.edu", "cs.mcgill.ca"], "authors": ["Iulian V. Serban", "Alexander G. Ororbia II", "Joelle Pineau", "Aaron Courville"], "authorids": ["julianserban@gmail.com", "ago109@psu.edu", "jpineau@cs.mcgill.ca", "aaron.courville@umontreal.ca"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287686689, "id": "ICLR.cc/2017/conference/-/paper204/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "BJ9fZNqle", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper204/reviewers", "ICLR.cc/2017/conference/paper204/areachairs"], "cdate": 1485287686689}}}, {"tddate": null, "tmdate": 1478548314635, "tcdate": 1478548314627, "number": 3, "id": "Sk7DiL0ex", "invitation": "ICLR.cc/2017/conference/-/paper204/public/comment", "forum": "BJ9fZNqle", "replyto": "BJ9fZNqle", "signatures": ["~Christian_A_Naesseth1"], "readers": ["everyone"], "writers": ["~Christian_A_Naesseth1"], "content": {"title": "Differentiability of the reparameterization", "comment": "The reparameterization does not seem to be differentiable? I.e. eq. (8) consists of indicator functions of the parameters you are optimizing with respect to."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Multi-modal Variational Encoder-Decoders", "abstract": "Recent advances in neural variational inference have facilitated efficient training of powerful directed graphical models with continuous latent variables, such as variational autoencoders. However, these models usually assume simple, uni-modal priors \u2014 such as the multivariate Gaussian distribution \u2014 yet many real-world data distributions are highly complex and multi-modal. Examples of complex and multi-modal distributions range from topics in newswire text to conversational dialogue responses. When such latent variable models are applied to these domains, the restriction of the simple, uni-modal prior hinders the overall expressivity of the learned model as it cannot possibly capture more complex aspects of the data distribution. To overcome this critical restriction, we propose a flexible, simple prior distribution which can be learned efficiently and potentially capture an exponential number of modes of a target distribution. We develop the multi-modal variational encoder-decoder framework and investigate the effectiveness of the proposed prior in several natural language processing modeling tasks, including document modeling and dialogue modeling.", "pdf": "/pdf/071718de067f86d033a26cee3d6f7bd1e96215db.pdf", "TL;DR": "Learning continuous multimodal latent variables in the variational auto-encoder framework for text processing applications.", "paperhash": "serban|multimodal_variational_encoderdecoders", "keywords": ["Deep learning", "Structured prediction", "Natural language processing"], "conflicts": ["umontreal.ca", "psu.edu", "cs.mcgill.ca"], "authors": ["Iulian V. Serban", "Alexander G. Ororbia II", "Joelle Pineau", "Aaron Courville"], "authorids": ["julianserban@gmail.com", "ago109@psu.edu", "jpineau@cs.mcgill.ca", "aaron.courville@umontreal.ca"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287686689, "id": "ICLR.cc/2017/conference/-/paper204/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "BJ9fZNqle", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper204/reviewers", "ICLR.cc/2017/conference/paper204/areachairs"], "cdate": 1485287686689}}}, {"tddate": null, "tmdate": 1478532674895, "tcdate": 1478532674885, "number": 2, "id": "HJoHAzRge", "invitation": "ICLR.cc/2017/conference/-/paper204/public/comment", "forum": "BJ9fZNqle", "replyto": "r1j28MRex", "signatures": ["~Iulian_Serban1"], "readers": ["everyone"], "writers": ["~Iulian_Serban1"], "content": {"title": "RE: Is is ok to submit an incomplete paper?", "comment": "Hello there, \n\nWe understand you may feel it is unfair to submit a paper without the final results.\n\nThe reason our results tables are still incomplete is because we found problems in our experiments a few weeks ago. We have been working hard to fix them since then. The tasks we are working on are computationally expensive. For example, on the Twitter task discussed in the paper, it takes over two weeks to train up our model and baselines on a TitanX GPU (compare this to the MNIST or sequential MNIST tasks, which other ideas related to VAEs are typically evaluated on). Since ICLR explicitly encourages updates/revisions of papers and since the majority of the work has already been done (the paper has been written and revised already, experiments are almost complete), we believe it is acceptable to upload the remaining results past the deadline within a short period of time.\n\nCheers,\n\nIulian And Alex"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Multi-modal Variational Encoder-Decoders", "abstract": "Recent advances in neural variational inference have facilitated efficient training of powerful directed graphical models with continuous latent variables, such as variational autoencoders. However, these models usually assume simple, uni-modal priors \u2014 such as the multivariate Gaussian distribution \u2014 yet many real-world data distributions are highly complex and multi-modal. Examples of complex and multi-modal distributions range from topics in newswire text to conversational dialogue responses. When such latent variable models are applied to these domains, the restriction of the simple, uni-modal prior hinders the overall expressivity of the learned model as it cannot possibly capture more complex aspects of the data distribution. To overcome this critical restriction, we propose a flexible, simple prior distribution which can be learned efficiently and potentially capture an exponential number of modes of a target distribution. We develop the multi-modal variational encoder-decoder framework and investigate the effectiveness of the proposed prior in several natural language processing modeling tasks, including document modeling and dialogue modeling.", "pdf": "/pdf/071718de067f86d033a26cee3d6f7bd1e96215db.pdf", "TL;DR": "Learning continuous multimodal latent variables in the variational auto-encoder framework for text processing applications.", "paperhash": "serban|multimodal_variational_encoderdecoders", "keywords": ["Deep learning", "Structured prediction", "Natural language processing"], "conflicts": ["umontreal.ca", "psu.edu", "cs.mcgill.ca"], "authors": ["Iulian V. Serban", "Alexander G. Ororbia II", "Joelle Pineau", "Aaron Courville"], "authorids": ["julianserban@gmail.com", "ago109@psu.edu", "jpineau@cs.mcgill.ca", "aaron.courville@umontreal.ca"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287686689, "id": "ICLR.cc/2017/conference/-/paper204/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "BJ9fZNqle", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper204/reviewers", "ICLR.cc/2017/conference/paper204/areachairs"], "cdate": 1485287686689}}}, {"tddate": null, "tmdate": 1478530739314, "tcdate": 1478530739298, "number": 1, "id": "r1j28MRex", "invitation": "ICLR.cc/2017/conference/-/paper204/public/comment", "forum": "BJ9fZNqle", "replyto": "BJ9fZNqle", "signatures": ["(anonymous)"], "readers": ["everyone"], "writers": ["(anonymous)"], "content": {"title": "Is is ok to submit an incomplete paper?", "comment": "This paper is incomplete. Most of results are blank.  What is the meaning of \"table XXXX\"? \nSuch strategy seems unfair....\n\nHowever, I agree that methods are good.  This paper should be submitted to ICML or workshop in ICLR.\n\nIf this type of method is allowed, I would wonder the credibility of papers in this conference. \n\n"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Multi-modal Variational Encoder-Decoders", "abstract": "Recent advances in neural variational inference have facilitated efficient training of powerful directed graphical models with continuous latent variables, such as variational autoencoders. However, these models usually assume simple, uni-modal priors \u2014 such as the multivariate Gaussian distribution \u2014 yet many real-world data distributions are highly complex and multi-modal. Examples of complex and multi-modal distributions range from topics in newswire text to conversational dialogue responses. When such latent variable models are applied to these domains, the restriction of the simple, uni-modal prior hinders the overall expressivity of the learned model as it cannot possibly capture more complex aspects of the data distribution. To overcome this critical restriction, we propose a flexible, simple prior distribution which can be learned efficiently and potentially capture an exponential number of modes of a target distribution. We develop the multi-modal variational encoder-decoder framework and investigate the effectiveness of the proposed prior in several natural language processing modeling tasks, including document modeling and dialogue modeling.", "pdf": "/pdf/071718de067f86d033a26cee3d6f7bd1e96215db.pdf", "TL;DR": "Learning continuous multimodal latent variables in the variational auto-encoder framework for text processing applications.", "paperhash": "serban|multimodal_variational_encoderdecoders", "keywords": ["Deep learning", "Structured prediction", "Natural language processing"], "conflicts": ["umontreal.ca", "psu.edu", "cs.mcgill.ca"], "authors": ["Iulian V. Serban", "Alexander G. Ororbia II", "Joelle Pineau", "Aaron Courville"], "authorids": ["julianserban@gmail.com", "ago109@psu.edu", "jpineau@cs.mcgill.ca", "aaron.courville@umontreal.ca"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287686689, "id": "ICLR.cc/2017/conference/-/paper204/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "BJ9fZNqle", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper204/reviewers", "ICLR.cc/2017/conference/paper204/areachairs"], "cdate": 1485287686689}}}], "count": 28}