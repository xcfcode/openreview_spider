{"notes": [{"id": "rkgFXR4KPr", "original": "SygYworODS", "number": 1046, "cdate": 1569439265153, "ddate": null, "tcdate": 1569439265153, "tmdate": 1577168223832, "tddate": null, "forum": "rkgFXR4KPr", "replyto": null, "invitation": "ICLR.cc/2020/Conference/-/Blind_Submission", "content": {"authorids": ["shuaitang93@ucsd.edu", "paul.smolensky@gmail.com", "desa@ucsd.edu"], "title": "A Simple Recurrent Unit with Reduced Tensor Product Representations", "authors": ["Shuai Tang", "Paul Smolensky", "Virginia R. de Sa"], "pdf": "/pdf/293e9e4eea0f8016f36d647d52237fbed21214e5.pdf", "abstract": "Widely used recurrent units, including Long-short Term Memory (LSTM) and Gated Recurrent Unit (GRU), perform well on natural language tasks, but their ability to learn structured representations is still questionable. Exploiting reduced Tensor Product Representations (TPRs) --- distributed representations of symbolic structure in which vector-embedded symbols are bound to vector-embedded structural positions --- we propose the TPRU, a simple recurrent unit that, at each time step, explicitly executes structural-role binding and unbinding operations to incorporate structural information into learning. The gradient analysis of our proposed TPRU is conducted to support our model design, and its performance on multiple datasets shows the effectiveness of it. Furthermore, observations on linguistically grounded study demonstrate the interpretability of our TPRU.", "keywords": ["RNNs", "TPRs"], "paperhash": "tang|a_simple_recurrent_unit_with_reduced_tensor_product_representations", "original_pdf": "/attachment/d56abd7f4a3ca9dd7a1afec27a73374261922ea5.pdf", "_bibtex": "@misc{\ntang2020a,\ntitle={A Simple Recurrent Unit with Reduced Tensor Product Representations},\nauthor={Shuai Tang and Paul Smolensky and Virginia R. de Sa},\nyear={2020},\nurl={https://openreview.net/forum?id=rkgFXR4KPr}\n}"}, "signatures": ["ICLR.cc/2020/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference"], "details": {"replyCount": 5, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"reply": {"readers": {"values-regex": ".*"}, "writers": {"values": ["ICLR.cc/2020/Conference"]}, "signatures": {"values": ["ICLR.cc/2020/Conference"]}, "content": {"spotlight_video": {"value-regex": ".*"}, "full_presentation_video": {"value-regex": ".*"}, "original_pdf": {"required": false, "description": "Upload a PDF file that ends with .pdf", "value-regex": ".*"}, "appendix": {"value-regex": ".*"}, "authorids": {"values-regex": ".*"}, "poster": {"value-regex": ".*"}, "authors": {"values": ["Anonymous"]}, "slides": {"value-regex": ".*"}}}, "final": [], "signatures": ["ICLR.cc/2020/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference"], "noninvitees": [], "tcdate": 1569271260237, "tmdate": 1593459412141, "id": "ICLR.cc/2020/Conference/-/Blind_Submission"}}, "tauthor": "OpenReview.net"}, {"id": "S1royhTc6", "original": null, "number": 1, "cdate": 1576798713141, "ddate": null, "tcdate": 1576798713141, "tmdate": 1576800923294, "tddate": null, "forum": "rkgFXR4KPr", "replyto": "rkgFXR4KPr", "invitation": "ICLR.cc/2020/Conference/Paper1046/-/Decision", "content": {"decision": "Reject", "comment": "This paper has been reviewed by three reviewers and received scores such as 3/3/6. The reviewers took into account the rebuttal in their final verdict. The major criticism concerned the somewhat ad-hoc notion of interpretability, the analysis of vanishing/exploding gradients in  TPRU is experimental lacking theory. Finally,  all reviewers noted the paper is difficult to read and contains grammar issues etc. which does not help. On balance, we regret that this paper cannot be accepted to ICLR2020.\n\n", "title": "Paper Decision"}, "signatures": ["ICLR.cc/2020/Conference/Program_Chairs"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Program_Chairs"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["shuaitang93@ucsd.edu", "paul.smolensky@gmail.com", "desa@ucsd.edu"], "title": "A Simple Recurrent Unit with Reduced Tensor Product Representations", "authors": ["Shuai Tang", "Paul Smolensky", "Virginia R. de Sa"], "pdf": "/pdf/293e9e4eea0f8016f36d647d52237fbed21214e5.pdf", "abstract": "Widely used recurrent units, including Long-short Term Memory (LSTM) and Gated Recurrent Unit (GRU), perform well on natural language tasks, but their ability to learn structured representations is still questionable. Exploiting reduced Tensor Product Representations (TPRs) --- distributed representations of symbolic structure in which vector-embedded symbols are bound to vector-embedded structural positions --- we propose the TPRU, a simple recurrent unit that, at each time step, explicitly executes structural-role binding and unbinding operations to incorporate structural information into learning. The gradient analysis of our proposed TPRU is conducted to support our model design, and its performance on multiple datasets shows the effectiveness of it. Furthermore, observations on linguistically grounded study demonstrate the interpretability of our TPRU.", "keywords": ["RNNs", "TPRs"], "paperhash": "tang|a_simple_recurrent_unit_with_reduced_tensor_product_representations", "original_pdf": "/attachment/d56abd7f4a3ca9dd7a1afec27a73374261922ea5.pdf", "_bibtex": "@misc{\ntang2020a,\ntitle={A Simple Recurrent Unit with Reduced Tensor Product Representations},\nauthor={Shuai Tang and Paul Smolensky and Virginia R. de Sa},\nyear={2020},\nurl={https://openreview.net/forum?id=rkgFXR4KPr}\n}"}, "tags": [], "invitation": {"reply": {"writers": {"description": "How your identity will be displayed.", "values-regex": ["ICLR.cc/2020/Conference/Program_Chairs"]}, "signatures": {"values": ["ICLR.cc/2020/Conference/Program_Chairs"], "description": "How your identity will be displayed."}, "content": {"decision": {"value-radio": ["Accept (Spotlight)", "Accept (Talk)", "Accept (Poster)", "Reject"], "description": "Decision", "required": true, "order": 2}, "title": {"value": "Paper Decision", "required": true, "order": 1}, "comment": {"value-regex": "[\\S\\s]{0,5000}", "description": "", "required": false, "order": 3}}, "forum": "rkgFXR4KPr", "replyto": "rkgFXR4KPr", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}}, "expdate": 1576854540000, "duedate": 1576853940000, "multiReply": false, "readers": ["everyone"], "invitees": ["ICLR.cc/2020/Conference/Program_Chairs"], "tcdate": 1576795703459, "tmdate": 1576800250833, "super": "ICLR.cc/2020/Conference/-/Decision", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper1046/-/Decision"}}}, {"id": "Bklsv1j2oS", "original": null, "number": 1, "cdate": 1573855075064, "ddate": null, "tcdate": 1573855075064, "tmdate": 1573855075064, "tddate": null, "forum": "rkgFXR4KPr", "replyto": "rkgFXR4KPr", "invitation": "ICLR.cc/2020/Conference/Paper1046/-/Official_Comment", "content": {"title": "A new version is available. Thanks for the comments.", "comment": "Thanks sincerely for the comments and we have a new version uploaded. "}, "signatures": ["ICLR.cc/2020/Conference/Paper1046/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1046/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["shuaitang93@ucsd.edu", "paul.smolensky@gmail.com", "desa@ucsd.edu"], "title": "A Simple Recurrent Unit with Reduced Tensor Product Representations", "authors": ["Shuai Tang", "Paul Smolensky", "Virginia R. de Sa"], "pdf": "/pdf/293e9e4eea0f8016f36d647d52237fbed21214e5.pdf", "abstract": "Widely used recurrent units, including Long-short Term Memory (LSTM) and Gated Recurrent Unit (GRU), perform well on natural language tasks, but their ability to learn structured representations is still questionable. Exploiting reduced Tensor Product Representations (TPRs) --- distributed representations of symbolic structure in which vector-embedded symbols are bound to vector-embedded structural positions --- we propose the TPRU, a simple recurrent unit that, at each time step, explicitly executes structural-role binding and unbinding operations to incorporate structural information into learning. The gradient analysis of our proposed TPRU is conducted to support our model design, and its performance on multiple datasets shows the effectiveness of it. Furthermore, observations on linguistically grounded study demonstrate the interpretability of our TPRU.", "keywords": ["RNNs", "TPRs"], "paperhash": "tang|a_simple_recurrent_unit_with_reduced_tensor_product_representations", "original_pdf": "/attachment/d56abd7f4a3ca9dd7a1afec27a73374261922ea5.pdf", "_bibtex": "@misc{\ntang2020a,\ntitle={A Simple Recurrent Unit with Reduced Tensor Product Representations},\nauthor={Shuai Tang and Paul Smolensky and Virginia R. de Sa},\nyear={2020},\nurl={https://openreview.net/forum?id=rkgFXR4KPr}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "rkgFXR4KPr", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper1046/Authors", "ICLR.cc/2020/Conference/Paper1046/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper1046/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper1046/Reviewers", "ICLR.cc/2020/Conference/Paper1046/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper1046/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper1046/Authors|ICLR.cc/2020/Conference/Paper1046/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504162090, "tmdate": 1576860557687, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper1046/Authors", "ICLR.cc/2020/Conference/Paper1046/Reviewers", "ICLR.cc/2020/Conference/Paper1046/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper1046/-/Official_Comment"}}}, {"id": "SJxro8sodH", "original": null, "number": 1, "cdate": 1570645660863, "ddate": null, "tcdate": 1570645660863, "tmdate": 1572972519330, "tddate": null, "forum": "rkgFXR4KPr", "replyto": "rkgFXR4KPr", "invitation": "ICLR.cc/2020/Conference/Paper1046/-/Official_Review", "content": {"rating": "6: Weak Accept", "experience_assessment": "I do not know much about this area.", "review_assessment:_checking_correctness_of_derivations_and_theory": "I did not assess the derivations or theory.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #3", "review_assessment:_thoroughness_in_paper_reading": "I made a quick assessment of this paper.", "review": "This paper proposes a new recurrent unit with a simplified dynamics during training leading to more stable training algorithms and better performance. The paper is difficult to read because it assumes the reader is an expert on Tensor Product Representations. Many important terms are not clearly defined, which makes difficult to follow. For example, the terms \u201croles\u201d and \u201cfiller\u201d are not defined. I think a quick introduction to the field with a clarifying figure would be greatly appreciated by general readers. However, I think the contribution of the paper is important and presented experimental results, comparing the method against classical LSTM and GRU architectures, seem to be relevant for the field.\n\n\n\n\n\n"}, "signatures": ["ICLR.cc/2020/Conference/Paper1046/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1046/AnonReviewer3"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["shuaitang93@ucsd.edu", "paul.smolensky@gmail.com", "desa@ucsd.edu"], "title": "A Simple Recurrent Unit with Reduced Tensor Product Representations", "authors": ["Shuai Tang", "Paul Smolensky", "Virginia R. de Sa"], "pdf": "/pdf/293e9e4eea0f8016f36d647d52237fbed21214e5.pdf", "abstract": "Widely used recurrent units, including Long-short Term Memory (LSTM) and Gated Recurrent Unit (GRU), perform well on natural language tasks, but their ability to learn structured representations is still questionable. Exploiting reduced Tensor Product Representations (TPRs) --- distributed representations of symbolic structure in which vector-embedded symbols are bound to vector-embedded structural positions --- we propose the TPRU, a simple recurrent unit that, at each time step, explicitly executes structural-role binding and unbinding operations to incorporate structural information into learning. The gradient analysis of our proposed TPRU is conducted to support our model design, and its performance on multiple datasets shows the effectiveness of it. Furthermore, observations on linguistically grounded study demonstrate the interpretability of our TPRU.", "keywords": ["RNNs", "TPRs"], "paperhash": "tang|a_simple_recurrent_unit_with_reduced_tensor_product_representations", "original_pdf": "/attachment/d56abd7f4a3ca9dd7a1afec27a73374261922ea5.pdf", "_bibtex": "@misc{\ntang2020a,\ntitle={A Simple Recurrent Unit with Reduced Tensor Product Representations},\nauthor={Shuai Tang and Paul Smolensky and Virginia R. de Sa},\nyear={2020},\nurl={https://openreview.net/forum?id=rkgFXR4KPr}\n}"}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "rkgFXR4KPr", "replyto": "rkgFXR4KPr", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper1046/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper1046/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1575637445527, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper1046/Reviewers"], "noninvitees": [], "tcdate": 1570237743188, "tmdate": 1575637445540, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper1046/-/Official_Review"}}}, {"id": "ByeJA1orFr", "original": null, "number": 2, "cdate": 1571299271110, "ddate": null, "tcdate": 1571299271110, "tmdate": 1572972519294, "tddate": null, "forum": "rkgFXR4KPr", "replyto": "rkgFXR4KPr", "invitation": "ICLR.cc/2020/Conference/Paper1046/-/Official_Review", "content": {"rating": "3: Weak Reject", "experience_assessment": "I do not know much about this area.", "review_assessment:_checking_correctness_of_derivations_and_theory": "N/A", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #2", "review_assessment:_thoroughness_in_paper_reading": "N/A", "review": "In this paper, a new unit based on the outer product called TPRU is proposed for recurrent neural networks. The performance of TPRU is validated with several NLP tasks such as POS tagging. \n\nWhile my knowledge about RNNs is limited, I feel the paper has room for improvement and I vote for rejection this time. The main reasons are: 1. the paper is not well written, and 2. the way of analysis is not enough.\n\n1. From the viewpoint of an RNN non-expert (i.e., me), the paper somehow fails to introduce the background. For example, tensor product representation (TPR) is introduced in the second paragraph of Introduction. While TPR is an elemental idea of this study, it is introduced with neither motivation (why and when TPR is useful, etc) nor appropriate references, which makes non-experts difficult to catch up with the main body of this study. So the paper is not self-contained enough. \n\n2-1. The paper tries to explain why TPRU is better in terms of gradient vanishing/explosion in Section 4. However, the analysis is mainly performed in a qualitative way, and there is no quantitative analysis of it. For example, I expect something like the evaluation of the magnitude of the gradient, e.g., how much degree the gradient scale is reduced from normal gate to the TPRU gate. Or, at least there should be the numerical experiments for the comparison. Otherwise, it is hard to judge whether the gradient is actually stabilized.\n\n2-2. The paper says one of the advantages of using TPRU is in its interpretability. However, the term \"interpretability\" is very vague and it is not properly defined in this paper. The paper should discuss what is the metric of interpretability here. More specifically, the paper claims TPRU's interpretability by Table 5. It looks, however, improper because there is no baseline and we cannot conclude that TPRU has better interpretability than others."}, "signatures": ["ICLR.cc/2020/Conference/Paper1046/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1046/AnonReviewer2"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["shuaitang93@ucsd.edu", "paul.smolensky@gmail.com", "desa@ucsd.edu"], "title": "A Simple Recurrent Unit with Reduced Tensor Product Representations", "authors": ["Shuai Tang", "Paul Smolensky", "Virginia R. de Sa"], "pdf": "/pdf/293e9e4eea0f8016f36d647d52237fbed21214e5.pdf", "abstract": "Widely used recurrent units, including Long-short Term Memory (LSTM) and Gated Recurrent Unit (GRU), perform well on natural language tasks, but their ability to learn structured representations is still questionable. Exploiting reduced Tensor Product Representations (TPRs) --- distributed representations of symbolic structure in which vector-embedded symbols are bound to vector-embedded structural positions --- we propose the TPRU, a simple recurrent unit that, at each time step, explicitly executes structural-role binding and unbinding operations to incorporate structural information into learning. The gradient analysis of our proposed TPRU is conducted to support our model design, and its performance on multiple datasets shows the effectiveness of it. Furthermore, observations on linguistically grounded study demonstrate the interpretability of our TPRU.", "keywords": ["RNNs", "TPRs"], "paperhash": "tang|a_simple_recurrent_unit_with_reduced_tensor_product_representations", "original_pdf": "/attachment/d56abd7f4a3ca9dd7a1afec27a73374261922ea5.pdf", "_bibtex": "@misc{\ntang2020a,\ntitle={A Simple Recurrent Unit with Reduced Tensor Product Representations},\nauthor={Shuai Tang and Paul Smolensky and Virginia R. de Sa},\nyear={2020},\nurl={https://openreview.net/forum?id=rkgFXR4KPr}\n}"}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "rkgFXR4KPr", "replyto": "rkgFXR4KPr", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper1046/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper1046/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1575637445527, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper1046/Reviewers"], "noninvitees": [], "tcdate": 1570237743188, "tmdate": 1575637445540, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper1046/-/Official_Review"}}}, {"id": "HklyTuFRFB", "original": null, "number": 3, "cdate": 1571883191129, "ddate": null, "tcdate": 1571883191129, "tmdate": 1572972519259, "tddate": null, "forum": "rkgFXR4KPr", "replyto": "rkgFXR4KPr", "invitation": "ICLR.cc/2020/Conference/Paper1046/-/Official_Review", "content": {"experience_assessment": "I have read many papers in this area.", "rating": "3: Weak Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #1", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "This paper proposes a novel model of recurrent unit for RNNs which is inspired from tensor product representation (TPR) introduced by Smolensky et al. in 1990. The authors claim that this allows one to better incorporate structural information into learning and easier interpretability for the learned representations. The proposed approach is motivated by a theoretical analysis showing that using TPR in this context acts as a sort of pre-conditioner and stabilizes learning. Experiments on entailment tasks (given two statement, decide whether the first implies the second) are provided to validate the approach. \n\nI find the paper not easy to follow, with a non-negligible amount of typos in the notations and results. The advantage in terms of accuracy of the proposed approach seems marginal in the experiment, and the analysis of the interpretability of the learned representations could be improved: loosely speaking, particular examples of interpretability are given but sometimes without contexts or baselines to compare to (see the two last comments below). I know \"interpretability\" is a difficult property to assess but I think there may be more principled ways to showcase the approach.\n\nI think this paper is not yet ready for publication: the proposed model is interesting and relevant but its validity could be better assessed and the paper needs some thorough proof-reading. \n\n\n* Questions / Comments *\n\n- page 1: the authors write U^TR = I, but I believe this is only possible if the TPR dimension d is bigger than the number of roles N. Is this always the case? This should be clarified.\n- related to the previous point:  if U^TR = I then shouldn't U^Tb_{t-1} simply be f_{t-1} in Eq. 1?\n- before Eq.1, f should be from R^d\\times R^d' to R^d, not from R^d \\times R^d\n- In Eq. 1, b_{t-1} and x_t are not of the same dimension, so the cannot be multiplied by the same matrix U (this is why the matrices V_x and V_b are introduced later on).\n- there seems to be a problem with Eq. (7): db_t/d_{b_{t-1}} appears on both sides of the equality...\n- Modification 1: what is \\tilde{vb_t}? I don't remember seeing this notation introduced before.\n- Table 1: constants should not be included in big O notation! To compare constants, one should give the exact number of operations needed for inference.\n- POS tagging: Aren't there many other reasons that could lead to this correlation (beside the informal argument that \"TPR captures structured information\")? Maybe the authors should compare with something else, for example the PMI between values of hidden neurons in a learned RNN and POS tags. Out of context, the numbers in Table 5 are not informative.\n- Polysemy: Only a very specific cherry picked example is given here. A more principled or in depth analysis of this phenomenon is needed to make a stronger case.\n\n* Typos *\n\n- \" The number of parameter matrices *is* the same as that of...\"\n- page 4 \"stables\" -> \"stabilizes\" (but rephrasing the sentence altogether would be better).\n- page 5: BiDAF misses the capital letters (\"bidaf\").\n- \"dev set\" -> \"validation set\" or \"development set\".\n- page 8: \"provides research*ers with* an intuitive...\"?\n"}, "signatures": ["ICLR.cc/2020/Conference/Paper1046/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1046/AnonReviewer1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["shuaitang93@ucsd.edu", "paul.smolensky@gmail.com", "desa@ucsd.edu"], "title": "A Simple Recurrent Unit with Reduced Tensor Product Representations", "authors": ["Shuai Tang", "Paul Smolensky", "Virginia R. de Sa"], "pdf": "/pdf/293e9e4eea0f8016f36d647d52237fbed21214e5.pdf", "abstract": "Widely used recurrent units, including Long-short Term Memory (LSTM) and Gated Recurrent Unit (GRU), perform well on natural language tasks, but their ability to learn structured representations is still questionable. Exploiting reduced Tensor Product Representations (TPRs) --- distributed representations of symbolic structure in which vector-embedded symbols are bound to vector-embedded structural positions --- we propose the TPRU, a simple recurrent unit that, at each time step, explicitly executes structural-role binding and unbinding operations to incorporate structural information into learning. The gradient analysis of our proposed TPRU is conducted to support our model design, and its performance on multiple datasets shows the effectiveness of it. Furthermore, observations on linguistically grounded study demonstrate the interpretability of our TPRU.", "keywords": ["RNNs", "TPRs"], "paperhash": "tang|a_simple_recurrent_unit_with_reduced_tensor_product_representations", "original_pdf": "/attachment/d56abd7f4a3ca9dd7a1afec27a73374261922ea5.pdf", "_bibtex": "@misc{\ntang2020a,\ntitle={A Simple Recurrent Unit with Reduced Tensor Product Representations},\nauthor={Shuai Tang and Paul Smolensky and Virginia R. de Sa},\nyear={2020},\nurl={https://openreview.net/forum?id=rkgFXR4KPr}\n}"}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "rkgFXR4KPr", "replyto": "rkgFXR4KPr", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper1046/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper1046/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1575637445527, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper1046/Reviewers"], "noninvitees": [], "tcdate": 1570237743188, "tmdate": 1575637445540, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper1046/-/Official_Review"}}}], "count": 6}