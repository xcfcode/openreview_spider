{"notes": [{"tddate": null, "number": null, "ddate": null, "cdate": null, "tmdate": 1458232806512, "tcdate": 1458232806512, "id": "k80JOkDAKsOYKX7ji4NV", "invitation": "ICLR.cc/2016/workshop/-/paper/137/comment", "forum": "p8jp5lzPWSnQVOGWfpDD", "replyto": "p8jp5lzPWSnQVOGWfpDD", "signatures": ["~Marc_Masana_Castrillo1"], "readers": ["everyone"], "writers": ["~Marc_Masana_Castrillo1"], "content": {"title": "Response to reviews", "comment": "Thanks everyone for your reviews.\n\nThe reviewers are right to point out that much of the computation is shared in the recent Faster-RCNN proposal (our detector follows exactly this Fast RCNN architecture). However, the fully connected layers (fc6, fc7 and fc8) must still be evaluated for all bounding box proposals, and these are the layers (fc6 and fc8) for which we show results. Even if their computational load in the original network is less than that of the convolutional layers, the fact that their evaluation must be repeated for each bounding box makes reduction of their computation very relevant. For small problems, fc8 reduction is irrelevant, but becomes relevant for problems with very many class problems.\n\nAlso in more modern architectures like Deep Residual Learning (He et al. arXiv 2015) where the fully connected layers are replaced by convolutional layers, the idea of our proposal could be applied. In the Deep Residual Network paper the first 91 convolutional layers are shared, but for every bounding box proposal the 9 remaining fully convolutional layers (conv5-) are computed. On these layers a pruning technique similar to the one we propose could be applied to prune filters resulting in feature maps with insignificant response (near zero)."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"CMT_id": "", "title": "On-the-fly Network Pruning for Object Detection", "abstract": "Object detection with deep neural networks is often performed by passing a few thousand candidate bounding boxes through a deep neural network for each image. These bounding boxes are highly correlated since they originate from the same image. In this paper we investigate how to exploit feature  occurrence at the image scale to prune the neural network which is subsequently applied to all bounding boxes. We show that removing units which have near-zero activation in the image allows us to significantly reduce the number of parameters in the network. Results on the PASCAL 2007 Object Detection Challenge demonstrate that up to 40% of units in some fully-connected layers can be entirely eliminated with little change in the detection result.", "pdf": "/pdf/p8jp5lzPWSnQVOGWfpDD.pdf", "paperhash": "masana|onthefly_network_pruning_for_object_detection", "conflicts": ["cvc.uab.cat", "cvc.uab.es", "unifi.it"], "authors": ["Marc Masana", "Joost van de Weijer", "Andrew D. Bagdanov"], "authorids": ["mmasana@cvc.uab.cat", "joost@cvc.uab.cat", "bagdanov@cvc.uab.cat"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "tmdate": null, "cdate": 1455827155240, "ddate": null, "super": null, "final": null, "tcdate": 1455827155240, "id": "ICLR.cc/2016/workshop/-/paper/137/comment", "writers": ["ICLR.cc/2016/workshop"], "signatures": ["ICLR.cc/2016/workshop"], "readers": ["everyone"], "invitees": ["~"], "reply": {"pdf": null, "replyto": null, "writers": {"values-regex": "~.*"}, "forum": "p8jp5lzPWSnQVOGWfpDD", "signatures": {"values-regex": "~.*", "description": "Your displayed identity associated with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,5000}"}}}, "nonreaders": [], "noninvitees": []}}}, {"tddate": null, "number": null, "ddate": null, "cdate": null, "tmdate": 1457746036006, "tcdate": 1457746036006, "id": "L7VQ0qN3niRNGwArs4go", "invitation": "ICLR.cc/2016/workshop/-/paper/132/review/11", "forum": "p8jp5lzPWSnQVOGWfpDD", "replyto": "p8jp5lzPWSnQVOGWfpDD", "signatures": ["~Jeff_Donahue1"], "readers": ["everyone"], "writers": ["~Jeff_Donahue1"], "content": {"title": "Review of On-the-fly Network Pruning for Object Detection", "rating": "6: Marginally above acceptance threshold", "review": "The paper presents two methods of reducing the number of parameters in a ReLU-based convnet based on pruning weights that result in a high proportion of inactive (activation 0) units.\n\nPros:\n-The method is simple, well-motivated, and well-described\n-Computation is reduced significantly while sacrificing little to no accuracy\n-Method is applicable to any convnet with relu activations, and could be trivially generalized from fully-connected to convolutional layers\n\nCons:\nThe experiments are somewhat limited in that the pruning trick is evaluated on just two layers of one network for one problem, and the more recent detection approaches (Fast(er) R-CNN) do not have the same degree of issues with evaluating many proposals that R-CNN did, due to the ROI Pooling layer (first proposed in SPP)\n\nThough the evaluation is limited and addresses a problem that isn't as big of an issue now as it once was, the method is general enough to be worth readers' time for the short paper.  Furthermore, my expectations for evaluation aren't as high for a workshop paper than in other venues, so I don't see the evaluation as being too much of a drawback for this work", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"CMT_id": "", "title": "On-the-fly Network Pruning for Object Detection", "abstract": "Object detection with deep neural networks is often performed by passing a few thousand candidate bounding boxes through a deep neural network for each image. These bounding boxes are highly correlated since they originate from the same image. In this paper we investigate how to exploit feature  occurrence at the image scale to prune the neural network which is subsequently applied to all bounding boxes. We show that removing units which have near-zero activation in the image allows us to significantly reduce the number of parameters in the network. Results on the PASCAL 2007 Object Detection Challenge demonstrate that up to 40% of units in some fully-connected layers can be entirely eliminated with little change in the detection result.", "pdf": "/pdf/p8jp5lzPWSnQVOGWfpDD.pdf", "paperhash": "masana|onthefly_network_pruning_for_object_detection", "conflicts": ["cvc.uab.cat", "cvc.uab.es", "unifi.it"], "authors": ["Marc Masana", "Joost van de Weijer", "Andrew D. Bagdanov"], "authorids": ["mmasana@cvc.uab.cat", "joost@cvc.uab.cat", "bagdanov@cvc.uab.cat"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "tmdate": null, "cdate": 1456580016543, "ddate": null, "super": null, "final": null, "duedate": 1460725200000, "tcdate": 1456580016543, "id": "ICLR.cc/2016/workshop/-/paper/132/review/11", "writers": ["ICLR.cc/2016/workshop"], "signatures": ["ICLR.cc/2016/workshop"], "reply": {"pdf": null, "forum": "p8jp5lzPWSnQVOGWfpDD", "replyto": "p8jp5lzPWSnQVOGWfpDD", "writers": {"values-regex": "(~.*)|ICLR.cc/2016/workshop/paper/[0-9]+/reviewer/[0-9]+)"}, "signatures": {"values-regex": "(~.*)|ICLR.cc/2016/workshop/paper/[0-9]+/reviewer/[0-9]+)", "description": "Your displayed identity associated with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "value-regex": "[\\S\\s]{1,5000}"}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "invitees": [], "nonreaders": [], "noninvitees": [], "readers": ["everyone", "ICLR.cc/2016/workshop/paper/132/reviewer/11", "ICLR.cc/2016/workshop"], "expdate": 1468501200000}}}, {"tddate": null, "number": null, "ddate": null, "cdate": null, "tmdate": 1457161668257, "tcdate": 1457161668257, "id": "vlpGAEnXZi7OYLG5inzJ", "invitation": "ICLR.cc/2016/workshop/-/paper/132/review/10", "forum": "p8jp5lzPWSnQVOGWfpDD", "replyto": "p8jp5lzPWSnQVOGWfpDD", "signatures": ["ICLR.cc/2016/workshop/paper/132/reviewer/10"], "readers": ["everyone"], "writers": ["ICLR.cc/2016/workshop/paper/132/reviewer/10"], "content": {"title": "Review_10: On-the-fly Network Pruning for Object Detection", "rating": "4: Ok but not good enough - rejection", "review": "The paper presents methods to reduce the number of parameters of network for proposal based object detector (e.g., R-CNN), which can potentially accelerate the inference. The proposed method prune the network based on the network activation of each image, and then a smaller network can be applied to all different object proposals in an image. It is based on the assumption that network units with zero activation on the whole image cannot have nonzero activation on any object proposal in the image. Backward and forward pruning methods are proposed to prune the unit with zero or near zero activation. Experiments are done on the PASCAL 2007 to show that the pruning does not degrade the performance significantly.\n\nPros:\n- Proposed methods are simple and well described.\n\nCons:\n- The key assumption does not have theoretical proof, or experimental support.\n- There is no baseline comparisons in the experiments. It is not clear if a random pruning will be as effective as the proposed methods.\n- The proposed methods are designed for detectors that evaluates each proposals independently, but it is based on the fast R-CNN, which obsoletes this routine (see the RoI pooling layer). The computation of all the convolutional layers are shared in fast R-CNN. This makes it less interesting to apply the proposed methods on the convolutional layers. \n- Actually, only the experiments on the full connected layers are shown.\n", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"CMT_id": "", "title": "On-the-fly Network Pruning for Object Detection", "abstract": "Object detection with deep neural networks is often performed by passing a few thousand candidate bounding boxes through a deep neural network for each image. These bounding boxes are highly correlated since they originate from the same image. In this paper we investigate how to exploit feature  occurrence at the image scale to prune the neural network which is subsequently applied to all bounding boxes. We show that removing units which have near-zero activation in the image allows us to significantly reduce the number of parameters in the network. Results on the PASCAL 2007 Object Detection Challenge demonstrate that up to 40% of units in some fully-connected layers can be entirely eliminated with little change in the detection result.", "pdf": "/pdf/p8jp5lzPWSnQVOGWfpDD.pdf", "paperhash": "masana|onthefly_network_pruning_for_object_detection", "conflicts": ["cvc.uab.cat", "cvc.uab.es", "unifi.it"], "authors": ["Marc Masana", "Joost van de Weijer", "Andrew D. Bagdanov"], "authorids": ["mmasana@cvc.uab.cat", "joost@cvc.uab.cat", "bagdanov@cvc.uab.cat"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "tmdate": null, "cdate": 1456580017055, "ddate": null, "super": null, "final": null, "duedate": 1460725200000, "tcdate": 1456580017055, "id": "ICLR.cc/2016/workshop/-/paper/132/review/10", "writers": ["ICLR.cc/2016/workshop"], "signatures": ["ICLR.cc/2016/workshop"], "reply": {"pdf": null, "forum": "p8jp5lzPWSnQVOGWfpDD", "replyto": "p8jp5lzPWSnQVOGWfpDD", "writers": {"values-regex": "(~.*)|ICLR.cc/2016/workshop/paper/[0-9]+/reviewer/[0-9]+)"}, "signatures": {"values-regex": "(~.*)|ICLR.cc/2016/workshop/paper/[0-9]+/reviewer/[0-9]+)", "description": "Your displayed identity associated with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "value-regex": "[\\S\\s]{1,5000}"}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "invitees": [], "nonreaders": [], "noninvitees": [], "readers": ["everyone", "ICLR.cc/2016/workshop/paper/132/reviewer/10", "ICLR.cc/2016/workshop"], "expdate": 1468501200000}}}, {"tddate": null, "number": null, "ddate": null, "cdate": null, "tmdate": 1456956474346, "tcdate": 1456956474346, "id": "ZY9jnY4GWu5Pk8ELfEKQ", "invitation": "ICLR.cc/2016/workshop/-/paper/132/unofficial_review", "forum": "p8jp5lzPWSnQVOGWfpDD", "replyto": "p8jp5lzPWSnQVOGWfpDD", "signatures": ["~Christian_Szegedy1"], "readers": ["everyone"], "writers": ["~Christian_Szegedy1"], "content": {"title": "Review of On-the-fly Network Pruning for Object Detection", "rating": "4: Ok but not good enough - rejection", "review": "This extended abstract proposes pruning methodology for the weights of an already trained deep neural network for object detection. This particular method applies to R-CNN style object detection approach, where the same network is applied to a lot of proposals. The paper hypothesizes that if the post-classifier network yields zero values for some activations on the whole image, then the same unit will never give non-zero values when network is applied on any of the proposals. This suggests a recursive algorithm to prune the network weight matrices based on the activations of the network on the whole image. The paper presents two pruning strategies, the first one guarantees equivalent activation output on the whole image. The second one is an approximate version that might change the output of the network. The various pruning methodologies are then evaluated on the VOC detection benchmark and demonstrated to be able to prune up to 60% of the weight matrices without effecting the overall quality of the output on the proposals significantly.\n\nThe positive:\n- The idea is sound and is relatively easy to implement for the R-CNN setup.\n\nThe negative:\n- The idea is based on an assumption that is not justified theoretically. The practical evidence for the activation is not presented in the abstract, but assumed silently.\n- The traditional R-CNN method performs poorly already on the small objects. The expected failure mode of this method is also on the small objects, so the comparison graphs do not have the potenetial to measure this failure mode easily. \n- The traditional R-CNN method of applying the post-classifier in separation has been obsoleted by applying SPP in the Faster R-CNN setup. The gains theoretically achievable by this algorithm are not very relevant in the big picture since SPP pools features from the globally applied network activations anyways.\n- The idea is very specific to a special type of (already obsolete) detection procedure and is not likely to generalize to settings other than this.", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"CMT_id": "", "title": "On-the-fly Network Pruning for Object Detection", "abstract": "Object detection with deep neural networks is often performed by passing a few thousand candidate bounding boxes through a deep neural network for each image. These bounding boxes are highly correlated since they originate from the same image. In this paper we investigate how to exploit feature  occurrence at the image scale to prune the neural network which is subsequently applied to all bounding boxes. We show that removing units which have near-zero activation in the image allows us to significantly reduce the number of parameters in the network. Results on the PASCAL 2007 Object Detection Challenge demonstrate that up to 40% of units in some fully-connected layers can be entirely eliminated with little change in the detection result.", "pdf": "/pdf/p8jp5lzPWSnQVOGWfpDD.pdf", "paperhash": "masana|onthefly_network_pruning_for_object_detection", "conflicts": ["cvc.uab.cat", "cvc.uab.es", "unifi.it"], "authors": ["Marc Masana", "Joost van de Weijer", "Andrew D. Bagdanov"], "authorids": ["mmasana@cvc.uab.cat", "joost@cvc.uab.cat", "bagdanov@cvc.uab.cat"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "tmdate": null, "cdate": 1455826095680, "ddate": null, "super": null, "final": null, "tcdate": 1455826095680, "id": "ICLR.cc/2016/workshop/-/paper/132/unofficial_review", "writers": ["ICLR.cc/2016/workshop"], "signatures": ["ICLR.cc/2016/workshop"], "readers": ["everyone"], "invitees": ["~"], "reply": {"pdf": null, "writers": {"values-regex": "~.*"}, "forum": "p8jp5lzPWSnQVOGWfpDD", "replyto": "p8jp5lzPWSnQVOGWfpDD", "signatures": {"values-regex": "~.*", "description": "Your displayed identity associated with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "value-regex": "[\\S\\s]{1,5000}"}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "noninvitees": ["mmasana@cvc.uab.cat", "bagdanov@cvc.uab.cat", "joost@cvc.uab.cat"]}}}, {"tddate": null, "number": null, "replyto": null, "ddate": null, "cdate": null, "tmdate": 1455826094518, "tcdate": 1455826094518, "id": "p8jp5lzPWSnQVOGWfpDD", "invitation": "ICLR.cc/2016/workshop/-/submission", "forum": "p8jp5lzPWSnQVOGWfpDD", "signatures": ["~Marc_Masana_Castrillo1"], "readers": ["everyone"], "writers": ["~Marc_Masana_Castrillo1"], "content": {"CMT_id": "", "title": "On-the-fly Network Pruning for Object Detection", "abstract": "Object detection with deep neural networks is often performed by passing a few thousand candidate bounding boxes through a deep neural network for each image. These bounding boxes are highly correlated since they originate from the same image. In this paper we investigate how to exploit feature  occurrence at the image scale to prune the neural network which is subsequently applied to all bounding boxes. We show that removing units which have near-zero activation in the image allows us to significantly reduce the number of parameters in the network. Results on the PASCAL 2007 Object Detection Challenge demonstrate that up to 40% of units in some fully-connected layers can be entirely eliminated with little change in the detection result.", "pdf": "/pdf/p8jp5lzPWSnQVOGWfpDD.pdf", "paperhash": "masana|onthefly_network_pruning_for_object_detection", "conflicts": ["cvc.uab.cat", "cvc.uab.es", "unifi.it"], "authors": ["Marc Masana", "Joost van de Weijer", "Andrew D. Bagdanov"], "authorids": ["mmasana@cvc.uab.cat", "joost@cvc.uab.cat", "bagdanov@cvc.uab.cat"]}, "nonreaders": [], "details": {"replyCount": 4, "writable": false, "overwriting": [], "revisions": false, "tags": [], "invitation": {"rdate": null, "tddate": null, "tmdate": null, "cdate": 1454464564200, "ddate": null, "super": null, "final": null, "duedate": 1455833700000, "tcdate": 1454464564200, "id": "ICLR.cc/2016/workshop/-/submission", "writers": ["ICLR.cc/2016/workshop"], "signatures": ["ICLR.cc/2016/workshop"], "readers": ["everyone"], "reply": {"pdf": null, "forum": null, "replyto": null, "writers": {"values-regex": "~.*"}, "signatures": {"values-regex": "~.*", "description": "Your displayed identity associated with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"pdf": {"order": 4, "description": "Either upload a PDF file or provide a direct link to your PDF on ArXiv.", "value-regex": "upload|http://arxiv.org/pdf/.+"}, "title": {"order": 3, "description": "Title of paper.", "value-regex": ".{0,500}"}, "abstract": {"order": 4, "description": "Abstract of paper.", "value-regex": "[\\S\\s]{1,5000}"}, "authors": {"order": 1, "description": "Comma separated list of author names, as they appear in the paper.", "value-regex": "[^,\\n]+(,[^,\\n]+)*"}, "author_emails": {"order": 2, "description": "Comma separated list of author email addresses, in the same order as above.", "value-regex": "[^,\\n]+(,[^,\\n]+)*"}, "conflicts": {"order": 100, "description": "Semi-colon separated list of email domains of people who would have a conflict of interest in reviewing this paper, (e.g., cs.umass.edu;google.com, etc.).", "value-regex": "^([a-zA-Z0-9][a-zA-Z0-9-_]{0,61}[a-zA-Z0-9]{0,1}\\.([a-zA-Z]{1,6}|[a-zA-Z0-9-]{1,30}\\.[a-zA-Z]{2,3}))+(;[a-zA-Z0-9][a-zA-Z0-9-_]{0,61}[a-zA-Z0-9]{0,1}\\.([a-zA-Z]{1,6}|[a-zA-Z0-9-]{1,30}\\.[a-zA-Z]{2,3}))*$"}, "CMT_id": {"order": 5, "value-regex": ".*", "description": "If the paper is a resubmission from the ICLR 2016 Conference Track, enter its CMT ID; otherwise, leave blank."}}}, "invitees": [], "nonreaders": [], "noninvitees": [], "expdate": 1463609700000}}}], "count": 5}