{"notes": [{"id": "HJedho0qFX", "original": "H1xd8JF9FX", "number": 727, "cdate": 1538087856421, "ddate": null, "tcdate": 1538087856421, "tmdate": 1545355389802, "tddate": null, "forum": "HJedho0qFX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Using Word Embeddings to Explore the Learned Representations of Convolutional Neural Networks", "abstract": "As deep neural net architectures minimize loss, they build up information in a hierarchy of learned representations that ultimately serve their final goal.  Different architectures tackle this problem in slightly different ways, but all models aim to  create representational spaces that accumulate information through the depth of the network.  Here we build on previous work that indicated that two very different model classes trained on two very different tasks actually build knowledge representations that have similar underlying representations.  Namely, we compare word embeddings from SkipGram (trained to predict co-occurring words) to several CNN architectures (trained for image classification) in order to understand how this accumulation of knowledge behaves in CNNs.  We improve upon previous work by including 5 times more ImageNet classes in our experiments, and further expand the scope of the analyses to include a network trained on CIFAR-100.  We  characterize network behavior in pretrained models, and also during training, misclassification, and adversarial attack.  Our work illustrates the power of using one model to explore another, gives new insights for CNN models, and provides a framework for others to perform similar analyses when developing new architectures.", "keywords": ["Distributional Semantics", "word embeddings", "cnns", "interpretability"], "authorids": ["dhanush987@gmail.com", "chris.james.foster@gmail.com", "alona@ualberta.ca"], "authors": ["Dhanush Dharmaretnam", "Chris Foster", "Alona Fyshe"], "TL;DR": "A simple technique using word embeddings provides multiple insights into the function and performance of CNNs, both during and after training, and for misclassified and adversarial examples.", "pdf": "/pdf/87fe821bddead5d4fde633700a3fc89b33b52c29.pdf", "paperhash": "dharmaretnam|using_word_embeddings_to_explore_the_learned_representations_of_convolutional_neural_networks", "_bibtex": "@misc{\ndharmaretnam2019using,\ntitle={Using Word Embeddings to Explore the Learned Representations of Convolutional Neural Networks},\nauthor={Dhanush Dharmaretnam and Chris Foster and Alona Fyshe},\nyear={2019},\nurl={https://openreview.net/forum?id=HJedho0qFX},\n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"replyCount": 4, "writable": false, "overwriting": [], "revisions": false, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Blind_Submission", "rdate": null, "ddate": null, "expdate": null, "duedate": 1538085600000, "tmdate": 1538142958393, "tddate": null, "super": null, "final": null, "reply": {"signatures": {"values": ["ICLR.cc/2019/Conference"]}, "forum": null, "readers": {"values": ["everyone"]}, "replyto": null, "content": {"authorids": {"values-regex": ".*"}, "authors": {"values": ["Anonymous"]}}, "writers": {"values": ["ICLR.cc/2019/Conference"]}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["~"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": null, "taskCompletionCount": null, "transform": null, "cdate": 1538142958393}}, "tauthor": "OpenReview.net"}, {"id": "SkghMQAee4", "original": null, "number": 1, "cdate": 1544770323537, "ddate": null, "tcdate": 1544770323537, "tmdate": 1545354521101, "tddate": null, "forum": "HJedho0qFX", "replyto": "HJedho0qFX", "invitation": "ICLR.cc/2019/Conference/-/Paper727/Meta_Review", "content": {"metareview": "The paper aims to study what is learned in the word representations by comparing SkipGram embeddings trained from a text corpus and CNNs trained from ImageNet.\n\nPros:\nThe paper tries to be comprehensive, including analysis of text representations and image representations, and the cases of misclassification and adversarial examples. \n\nCons:\nThe clarity of the paper is a major concern, as noted by all reviwers, and the authors did not come back with rebuttal to address reviewers' quetions. Also, as R1 and R2 pointed out the novelty over recent relevant papers such as (Dharmaretnam & Fyshe, 2018) is not clear.\n\nVerdict:\nReject due to weak novelty and major clarity issues.", "confidence": "5: The area chair is absolutely certain", "recommendation": "Reject", "title": "weak novelty and major clarity issues"}, "signatures": ["ICLR.cc/2019/Conference/Paper727/Area_Chair1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference/Paper727/Area_Chair1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Using Word Embeddings to Explore the Learned Representations of Convolutional Neural Networks", "abstract": "As deep neural net architectures minimize loss, they build up information in a hierarchy of learned representations that ultimately serve their final goal.  Different architectures tackle this problem in slightly different ways, but all models aim to  create representational spaces that accumulate information through the depth of the network.  Here we build on previous work that indicated that two very different model classes trained on two very different tasks actually build knowledge representations that have similar underlying representations.  Namely, we compare word embeddings from SkipGram (trained to predict co-occurring words) to several CNN architectures (trained for image classification) in order to understand how this accumulation of knowledge behaves in CNNs.  We improve upon previous work by including 5 times more ImageNet classes in our experiments, and further expand the scope of the analyses to include a network trained on CIFAR-100.  We  characterize network behavior in pretrained models, and also during training, misclassification, and adversarial attack.  Our work illustrates the power of using one model to explore another, gives new insights for CNN models, and provides a framework for others to perform similar analyses when developing new architectures.", "keywords": ["Distributional Semantics", "word embeddings", "cnns", "interpretability"], "authorids": ["dhanush987@gmail.com", "chris.james.foster@gmail.com", "alona@ualberta.ca"], "authors": ["Dhanush Dharmaretnam", "Chris Foster", "Alona Fyshe"], "TL;DR": "A simple technique using word embeddings provides multiple insights into the function and performance of CNNs, both during and after training, and for misclassified and adversarial examples.", "pdf": "/pdf/87fe821bddead5d4fde633700a3fc89b33b52c29.pdf", "paperhash": "dharmaretnam|using_word_embeddings_to_explore_the_learned_representations_of_convolutional_neural_networks", "_bibtex": "@misc{\ndharmaretnam2019using,\ntitle={Using Word Embeddings to Explore the Learned Representations of Convolutional Neural Networks},\nauthor={Dhanush Dharmaretnam and Chris Foster and Alona Fyshe},\nyear={2019},\nurl={https://openreview.net/forum?id=HJedho0qFX},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper727/Meta_Review", "rdate": null, "ddate": null, "expdate": null, "duedate": 1541548800000, "tmdate": 1545353107216, "tddate": null, "super": null, "final": null, "reply": {"forum": "HJedho0qFX", "replyto": "HJedho0qFX", "readers": {"description": "Select all user groups that should be able to read this comment. Selecting 'All Users' will allow paper authors, reviewers, area chairs, and program chairs to view this comment.", "values": ["everyone"]}, "signatures": {"description": "How your identity will be displayed with the above content.", "values-regex": "ICLR.cc/2019/Conference/Paper727/Area_Chair[0-9]+"}, "writers": {"description": "Users that may modify this record.", "values-regex": "ICLR.cc/2019/Conference/Paper727/Area_Chair[0-9]+"}, "content": {"title": {"order": 1, "value-regex": ".{1,500}", "description": "Brief summary of your review.", "required": true}, "metareview": {"order": 2, "value-regex": "[\\S\\s]{1,5000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "required": true}, "recommendation": {"order": 3, "value-dropdown": ["Accept (Oral)", "Accept (Poster)", "Reject"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The area chair is absolutely certain", "4: The area chair is confident but not absolutely certain", "3: The area chair is somewhat confident", "2: The area chair is not sure", "1: The area chair's evaluation is an educated guess"], "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper727/Area_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": false, "taskCompletionCount": null, "transform": null, "cdate": 1545353107216}}}, {"id": "Ske922ec3m", "original": null, "number": 2, "cdate": 1541176498162, "ddate": null, "tcdate": 1541176498162, "tmdate": 1541533737902, "tddate": null, "forum": "HJedho0qFX", "replyto": "HJedho0qFX", "invitation": "ICLR.cc/2019/Conference/-/Paper727/Official_Review", "content": {"title": "Too incremental", "review": "The authors apply an existing method (mainly 2 vs 2 test) to explore the representations learned by CNNs both during/after training. \n\n## Strength\n\nThe analysis of misclassification and adversarial examples is interesting. The authors also propose potential ways of improving the robustness of DNNs for adversarial examples. \n\n\n## Weakness\n1. It seems to me that the methodological novelty is limited, which mainly follows [The Emergence of Semantics in Neural Network Representations of Visual Information](http://aclweb.org/anthology/N18-2122). For example this paper extensively applies 2 vs. 2 test which was established in previous works. \nFurthermore, the first claimed contribution of 5 times more concepts than previous work does not result in any significant difference from the previous approaches. \n\n2. The analysis presented in this work does not really give new insights. For example, isn\u2019t \u201ca network fitting to noise does not learn semantics\u201d obvious to the community?\n\nSome of the subsection titles are misleading. For example in Section 5, the claim of \u201cCNNs Learn Semantics from Images\u201d is mainly proposed in a previous work, but the way of presentation sounds like this is a contribution of this work. \n", "rating": "4: Ok but not good enough - rejection", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["ICLR.cc/2019/Conference/Paper727/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Using Word Embeddings to Explore the Learned Representations of Convolutional Neural Networks", "abstract": "As deep neural net architectures minimize loss, they build up information in a hierarchy of learned representations that ultimately serve their final goal.  Different architectures tackle this problem in slightly different ways, but all models aim to  create representational spaces that accumulate information through the depth of the network.  Here we build on previous work that indicated that two very different model classes trained on two very different tasks actually build knowledge representations that have similar underlying representations.  Namely, we compare word embeddings from SkipGram (trained to predict co-occurring words) to several CNN architectures (trained for image classification) in order to understand how this accumulation of knowledge behaves in CNNs.  We improve upon previous work by including 5 times more ImageNet classes in our experiments, and further expand the scope of the analyses to include a network trained on CIFAR-100.  We  characterize network behavior in pretrained models, and also during training, misclassification, and adversarial attack.  Our work illustrates the power of using one model to explore another, gives new insights for CNN models, and provides a framework for others to perform similar analyses when developing new architectures.", "keywords": ["Distributional Semantics", "word embeddings", "cnns", "interpretability"], "authorids": ["dhanush987@gmail.com", "chris.james.foster@gmail.com", "alona@ualberta.ca"], "authors": ["Dhanush Dharmaretnam", "Chris Foster", "Alona Fyshe"], "TL;DR": "A simple technique using word embeddings provides multiple insights into the function and performance of CNNs, both during and after training, and for misclassified and adversarial examples.", "pdf": "/pdf/87fe821bddead5d4fde633700a3fc89b33b52c29.pdf", "paperhash": "dharmaretnam|using_word_embeddings_to_explore_the_learned_representations_of_convolutional_neural_networks", "_bibtex": "@misc{\ndharmaretnam2019using,\ntitle={Using Word Embeddings to Explore the Learned Representations of Convolutional Neural Networks},\nauthor={Dhanush Dharmaretnam and Chris Foster and Alona Fyshe},\nyear={2019},\nurl={https://openreview.net/forum?id=HJedho0qFX},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper727/Official_Review", "cdate": 1542234390355, "expdate": 1552335264000, "duedate": 1541196000000, "reply": {"forum": "HJedho0qFX", "replyto": "HJedho0qFX", "readers": {"description": "The users who will be allowed to read the reply content.", "values": ["everyone"]}, "nonreaders": {"values": []}, "signatures": {"description": "How your identity will be displayed with the above content.", "values-regex": "ICLR.cc/2019/Conference/Paper727/AnonReviewer[0-9]+"}, "writers": {"description": "Users that may modify this record.", "values": ["ICLR.cc/2019/Conference"]}, "content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "required": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}}, "multiReply": false, "tcdate": 1552335789778, "tmdate": 1552335789778, "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "invitees": ["ICLR.cc/2019/Conference/Paper727/Reviewers"], "noninvitees": [], "signatures": ["ICLR.cc/2019/Conference"]}}}, {"id": "ryeMJgOpnm", "original": null, "number": 3, "cdate": 1541402585951, "ddate": null, "tcdate": 1541402585951, "tmdate": 1541533737668, "tddate": null, "forum": "HJedho0qFX", "replyto": "HJedho0qFX", "invitation": "ICLR.cc/2019/Conference/-/Paper727/Official_Review", "content": {"title": "Rough idea. The proposed relationship is not properly confirmed.", "review": "The authors propose a new method of measuring a knowledge within the learned CNN: the representations of CNN layers and word2vec embeddings and compared, and the similarity between them are calculate. The authors claim that the similarity score increases with learning time, and the higher layers of CNN have more similarity to word2vec embeddings than the lower layers..\n\nCNN and word2vec use different datasets. CNN uses the vision pixels and word2vec uses the words in the sentences. A certain amount of representation patterns can be expected to be shared, but surely the extent is limited (correlation 0.9 in Fig. 1). Because of this limitation, the proposed similarity measure must not be claimed as the measure of knowledge accumulation in CNN. \n\nIn addition, the authors have to be precise in defining the measure and provide the information captured by the measure. In the literature, I can see \u201csomething\u201d is shared by the two algorithms but do not know what is this \u201csomething.\u201d The authors claim that \u201csemantics\u201d are shared, but replacing \u201csemantics\u201d to \u201csomething\u201d does not make any difference in this manuscript. Further investigations and confirmations are needed to report which information is actually similar to each other.\n\nMinor: the 1 vs. 2 accuracy measure is not defined.\n\nIn summary, the proposed measure may capture some information but the explanation about this information is unclear. The information seems to be a rough similar pattern of concept representations. Further rigorous investigation of the proposed measure is necessary to confirm which information is captured. The current version is not sufficient for acceptance.\n", "rating": "3: Clear rejection", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["ICLR.cc/2019/Conference/Paper727/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Using Word Embeddings to Explore the Learned Representations of Convolutional Neural Networks", "abstract": "As deep neural net architectures minimize loss, they build up information in a hierarchy of learned representations that ultimately serve their final goal.  Different architectures tackle this problem in slightly different ways, but all models aim to  create representational spaces that accumulate information through the depth of the network.  Here we build on previous work that indicated that two very different model classes trained on two very different tasks actually build knowledge representations that have similar underlying representations.  Namely, we compare word embeddings from SkipGram (trained to predict co-occurring words) to several CNN architectures (trained for image classification) in order to understand how this accumulation of knowledge behaves in CNNs.  We improve upon previous work by including 5 times more ImageNet classes in our experiments, and further expand the scope of the analyses to include a network trained on CIFAR-100.  We  characterize network behavior in pretrained models, and also during training, misclassification, and adversarial attack.  Our work illustrates the power of using one model to explore another, gives new insights for CNN models, and provides a framework for others to perform similar analyses when developing new architectures.", "keywords": ["Distributional Semantics", "word embeddings", "cnns", "interpretability"], "authorids": ["dhanush987@gmail.com", "chris.james.foster@gmail.com", "alona@ualberta.ca"], "authors": ["Dhanush Dharmaretnam", "Chris Foster", "Alona Fyshe"], "TL;DR": "A simple technique using word embeddings provides multiple insights into the function and performance of CNNs, both during and after training, and for misclassified and adversarial examples.", "pdf": "/pdf/87fe821bddead5d4fde633700a3fc89b33b52c29.pdf", "paperhash": "dharmaretnam|using_word_embeddings_to_explore_the_learned_representations_of_convolutional_neural_networks", "_bibtex": "@misc{\ndharmaretnam2019using,\ntitle={Using Word Embeddings to Explore the Learned Representations of Convolutional Neural Networks},\nauthor={Dhanush Dharmaretnam and Chris Foster and Alona Fyshe},\nyear={2019},\nurl={https://openreview.net/forum?id=HJedho0qFX},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper727/Official_Review", "cdate": 1542234390355, "expdate": 1552335264000, "duedate": 1541196000000, "reply": {"forum": "HJedho0qFX", "replyto": "HJedho0qFX", "readers": {"description": "The users who will be allowed to read the reply content.", "values": ["everyone"]}, "nonreaders": {"values": []}, "signatures": {"description": "How your identity will be displayed with the above content.", "values-regex": "ICLR.cc/2019/Conference/Paper727/AnonReviewer[0-9]+"}, "writers": {"description": "Users that may modify this record.", "values": ["ICLR.cc/2019/Conference"]}, "content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "required": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}}, "multiReply": false, "tcdate": 1552335789778, "tmdate": 1552335789778, "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "invitees": ["ICLR.cc/2019/Conference/Paper727/Reviewers"], "noninvitees": [], "signatures": ["ICLR.cc/2019/Conference"]}}}, {"id": "H1g9GJoN37", "original": null, "number": 1, "cdate": 1540824850400, "ddate": null, "tcdate": 1540824850400, "tmdate": 1541533737446, "tddate": null, "forum": "HJedho0qFX", "replyto": "HJedho0qFX", "invitation": "ICLR.cc/2019/Conference/-/Paper727/Official_Review", "content": {"title": "Limited contribution. In addition, it's hard to identify the contribution of this paper.", "review": "This paper extends the previous work (Dharmaretnam & Fyshe, 2018), which provided a analytic tool for understanding CNNs through word embeddings of class labels. By analyzing correlations between each CNN layers and class labels, enables to investigates how each layer of CNNs work, how much it performed well, or how to improve the performance.\n\nI felt it is little hard to read this paper. Although the short summary of contributions of this paper in the Introduction, I could not easily distinguish contributions of this paper from the ones of the previous work. It's better to explicitly explain which part is the contributions of this paper in detail. For example, \"additional explorations of the behavior of the hidden layers during training\" is not clear to me because this expression only explain what this paper do briefly, not what this paper is actually different from the previous work, and how this difference is important and crucial.\n\nSimilarly, I could not understand why adding concepts, architectures (FractalNet), datasets (CIFAR-100) is so important. Although this paper states these changes are one of the contributions, it is unclear whether these changes lead to significant insights and findings which the previous work could not find, and whether these findings are so important as contributions of this paper. Again, I think it is better to describe what main contributions of this paper are in more detail.", "rating": "4: Ok but not good enough - rejection", "confidence": "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper"}, "signatures": ["ICLR.cc/2019/Conference/Paper727/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Using Word Embeddings to Explore the Learned Representations of Convolutional Neural Networks", "abstract": "As deep neural net architectures minimize loss, they build up information in a hierarchy of learned representations that ultimately serve their final goal.  Different architectures tackle this problem in slightly different ways, but all models aim to  create representational spaces that accumulate information through the depth of the network.  Here we build on previous work that indicated that two very different model classes trained on two very different tasks actually build knowledge representations that have similar underlying representations.  Namely, we compare word embeddings from SkipGram (trained to predict co-occurring words) to several CNN architectures (trained for image classification) in order to understand how this accumulation of knowledge behaves in CNNs.  We improve upon previous work by including 5 times more ImageNet classes in our experiments, and further expand the scope of the analyses to include a network trained on CIFAR-100.  We  characterize network behavior in pretrained models, and also during training, misclassification, and adversarial attack.  Our work illustrates the power of using one model to explore another, gives new insights for CNN models, and provides a framework for others to perform similar analyses when developing new architectures.", "keywords": ["Distributional Semantics", "word embeddings", "cnns", "interpretability"], "authorids": ["dhanush987@gmail.com", "chris.james.foster@gmail.com", "alona@ualberta.ca"], "authors": ["Dhanush Dharmaretnam", "Chris Foster", "Alona Fyshe"], "TL;DR": "A simple technique using word embeddings provides multiple insights into the function and performance of CNNs, both during and after training, and for misclassified and adversarial examples.", "pdf": "/pdf/87fe821bddead5d4fde633700a3fc89b33b52c29.pdf", "paperhash": "dharmaretnam|using_word_embeddings_to_explore_the_learned_representations_of_convolutional_neural_networks", "_bibtex": "@misc{\ndharmaretnam2019using,\ntitle={Using Word Embeddings to Explore the Learned Representations of Convolutional Neural Networks},\nauthor={Dhanush Dharmaretnam and Chris Foster and Alona Fyshe},\nyear={2019},\nurl={https://openreview.net/forum?id=HJedho0qFX},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper727/Official_Review", "cdate": 1542234390355, "expdate": 1552335264000, "duedate": 1541196000000, "reply": {"forum": "HJedho0qFX", "replyto": "HJedho0qFX", "readers": {"description": "The users who will be allowed to read the reply content.", "values": ["everyone"]}, "nonreaders": {"values": []}, "signatures": {"description": "How your identity will be displayed with the above content.", "values-regex": "ICLR.cc/2019/Conference/Paper727/AnonReviewer[0-9]+"}, "writers": {"description": "Users that may modify this record.", "values": ["ICLR.cc/2019/Conference"]}, "content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "required": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}}, "multiReply": false, "tcdate": 1552335789778, "tmdate": 1552335789778, "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "invitees": ["ICLR.cc/2019/Conference/Paper727/Reviewers"], "noninvitees": [], "signatures": ["ICLR.cc/2019/Conference"]}}}], "count": 5}