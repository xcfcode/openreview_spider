{"notes": [{"id": "HklaEUUtON", "original": "HygP7zMdON", "number": 36, "cdate": 1553716788586, "ddate": null, "tcdate": 1553716788586, "tmdate": 1562083046240, "tddate": null, "forum": "HklaEUUtON", "replyto": null, "invitation": "ICLR.cc/2019/Workshop/DeepGenStruct/-/Blind_Submission", "content": {"title": "DISENTANGLED STATE SPACE MODELS: UNSUPERVISED LEARNING OF DYNAMICS ACROSS HETEROGENEOUS ENVIRONMENTS", "authors": ["\u00d0or\u0111e Miladinovi\u0107", "Waleed Gondal", "Bernhard Sch\u00f6lkopf", "Joachim M. Buhmann", "Stefan Bauer"], "authorids": ["djordjem@ethz.ch", "waleed.gondal@tuebingen.mpg.de", "bs@tuebingen.mpg.de", "jbuhmann@ethz.ch", "bauers@ethz.ch"], "keywords": ["State Space Models", "Sequential Data", "Bayesian Filtering", "Amortized Variational Inference", "Disentangled Representations", "Video Analysis"], "TL;DR": "DISENTANGLED STATE SPACE MODELS", "abstract": "Sequential data often originates from diverse environments. Across them exist both shared regularities and environment specifics. To learn robust cross-environment descriptions of sequences we introduce disentangled state space models (DSSM). In the latent space of DSSM environment-invariant state dynamics is explicitly disentangled from environment-specific information governing that dynamics. We empirically show that such separation enables robust prediction, sequence manipulation and environment characterization. We also propose an unsupervised VAE-based training procedure to learn DSSM as Bayesian filters. In our experiments, we demonstrate state-of-the-art performance in controlled generation and prediction of bouncing ball video sequences across varying gravitational influences.", "pdf": "/pdf/ae39ecbeab8ad13383ad885683e9bd836c882a67.pdf", "paperhash": "miladinovi|disentangled_state_space_models_unsupervised_learning_of_dynamics_across_heterogeneous_environments"}, "signatures": ["ICLR.cc/2019/Workshop/DeepGenStruct"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Workshop/DeepGenStruct"], "details": {"replyCount": 2, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"id": "ICLR.cc/2019/Workshop/DeepGenStruct/-/Blind_Submission", "cdate": 1547567085825, "reply": {"forum": null, "replyto": null, "readers": {"values-regex": [".*"]}, "writers": {"values": ["ICLR.cc/2019/Workshop/DeepGenStruct"]}, "signatures": {"values": ["ICLR.cc/2019/Workshop/DeepGenStruct"]}, "content": {"authors": {"values": ["Anonymous"]}, "authorids": {"values-regex": ".*"}}}, "tcdate": 1547567085825, "tmdate": 1555704438520, "readers": ["everyone"], "writers": ["ICLR.cc/2019/Workshop/DeepGenStruct"], "invitees": ["~"], "signatures": ["ICLR.cc/2019/Workshop/DeepGenStruct"]}}, "tauthor": "OpenReview.net"}, {"id": "SyxdSjqLF4", "original": null, "number": 1, "cdate": 1554586431800, "ddate": null, "tcdate": 1554586431800, "tmdate": 1556906136695, "tddate": null, "forum": "HklaEUUtON", "replyto": "HklaEUUtON", "invitation": "ICLR.cc/2019/Workshop/DeepGenStruct/-/Paper36/Official_Review", "content": {"title": "Weak evaluation, but reasonable for workshop", "review": "This paper presents a disentangled generative state space model. By using a global latent variable E the model captures environment-specific information and aims to be disentangled from the rest of the state information of the state space. In a single setting of 2D images of a bouncing ball in a varying gravity settings, this method seems to be yielding reasonable results.\n\nI like the ideas in this paper, and despite a weak evaluation, it is at a reasonable state for a workshop paper.\n\n* Fig 6a suggests that E captures well the direction of the gravity but there seems to be additional information (the variation within Fig6a). Have the authors explored what is the information that creeps in E? And, thus, is the model truly disentagled?\n\n* The video manipulation experiment is great, but seems to be of qualitative nature. It would be nice to see some quantitative results. For example, the same factors could be changed in the fully simulated environment and the output of the video manipulation experiments compared with the ground truth from the simulation.\n\n* Finally, it would have been nice to see more evaluation results on different settings beyond the bouncing ball experiment, both in simulated and real environments. Additionally, a deeper evaluation of the extent to which disentangling happens would be quite useful.\n\n\n\nMinor: \"This enhances robustness and ability to extrapolate\" -> \"... the ability\"", "rating": "3: Marginally above acceptance threshold", "confidence": "2: The reviewer is fairly confident that the evaluation is correct"}, "signatures": ["ICLR.cc/2019/Workshop/DeepGenStruct/Paper36/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Workshop/DeepGenStruct/Paper36/AnonReviewer2"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "DISENTANGLED STATE SPACE MODELS: UNSUPERVISED LEARNING OF DYNAMICS ACROSS HETEROGENEOUS ENVIRONMENTS", "authors": ["\u00d0or\u0111e Miladinovi\u0107", "Waleed Gondal", "Bernhard Sch\u00f6lkopf", "Joachim M. Buhmann", "Stefan Bauer"], "authorids": ["djordjem@ethz.ch", "waleed.gondal@tuebingen.mpg.de", "bs@tuebingen.mpg.de", "jbuhmann@ethz.ch", "bauers@ethz.ch"], "keywords": ["State Space Models", "Sequential Data", "Bayesian Filtering", "Amortized Variational Inference", "Disentangled Representations", "Video Analysis"], "TL;DR": "DISENTANGLED STATE SPACE MODELS", "abstract": "Sequential data often originates from diverse environments. Across them exist both shared regularities and environment specifics. To learn robust cross-environment descriptions of sequences we introduce disentangled state space models (DSSM). In the latent space of DSSM environment-invariant state dynamics is explicitly disentangled from environment-specific information governing that dynamics. We empirically show that such separation enables robust prediction, sequence manipulation and environment characterization. We also propose an unsupervised VAE-based training procedure to learn DSSM as Bayesian filters. In our experiments, we demonstrate state-of-the-art performance in controlled generation and prediction of bouncing ball video sequences across varying gravitational influences.", "pdf": "/pdf/ae39ecbeab8ad13383ad885683e9bd836c882a67.pdf", "paperhash": "miladinovi|disentangled_state_space_models_unsupervised_learning_of_dynamics_across_heterogeneous_environments"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Workshop/DeepGenStruct/-/Paper36/Official_Review", "cdate": 1554234173293, "reply": {"forum": "HklaEUUtON", "replyto": "HklaEUUtON", "readers": [".*"], "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2019/Workshop/DeepGenStruct/Paper36/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2019/Workshop/DeepGenStruct/Paper36/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "required": true}, "rating": {"order": 3, "value-dropdown": ["5: Top 15% of accepted papers, strong accept", "4: Top 50% of accepted papers, clear accept", "3: Marginally above acceptance threshold", "2: Marginally below acceptance threshold", "1: Strong rejection"], "required": true}, "confidence": {"order": 4, "value-radio": ["3: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "2: The reviewer is fairly confident that the evaluation is correct", "1: The reviewer's evaluation is an educated guess"], "required": true}}}, "tcdate": 1554234173293, "tmdate": 1556906091063, "readers": ["everyone"], "writers": ["ICLR.cc/2019/Workshop/DeepGenStruct"], "invitees": ["ICLR.cc/2019/Workshop/DeepGenStruct/Paper36/Reviewers"], "signatures": ["ICLR.cc/2019/Workshop/DeepGenStruct"], "details": {"writable": true}}}}, {"id": "S1e2zNOw94", "original": null, "number": 1, "cdate": 1555690516051, "ddate": null, "tcdate": 1555690516051, "tmdate": 1556906136479, "tddate": null, "forum": "HklaEUUtON", "replyto": "HklaEUUtON", "invitation": "ICLR.cc/2019/Workshop/DeepGenStruct/-/Paper36/Decision", "content": {"title": "Acceptance Decision", "decision": "Accept", "comment": "Accepted"}, "signatures": ["ICLR.cc/2019/Workshop/DeepGenStruct/Program_Chairs"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Workshop/DeepGenStruct/Program_Chairs"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "DISENTANGLED STATE SPACE MODELS: UNSUPERVISED LEARNING OF DYNAMICS ACROSS HETEROGENEOUS ENVIRONMENTS", "authors": ["\u00d0or\u0111e Miladinovi\u0107", "Waleed Gondal", "Bernhard Sch\u00f6lkopf", "Joachim M. Buhmann", "Stefan Bauer"], "authorids": ["djordjem@ethz.ch", "waleed.gondal@tuebingen.mpg.de", "bs@tuebingen.mpg.de", "jbuhmann@ethz.ch", "bauers@ethz.ch"], "keywords": ["State Space Models", "Sequential Data", "Bayesian Filtering", "Amortized Variational Inference", "Disentangled Representations", "Video Analysis"], "TL;DR": "DISENTANGLED STATE SPACE MODELS", "abstract": "Sequential data often originates from diverse environments. Across them exist both shared regularities and environment specifics. To learn robust cross-environment descriptions of sequences we introduce disentangled state space models (DSSM). In the latent space of DSSM environment-invariant state dynamics is explicitly disentangled from environment-specific information governing that dynamics. We empirically show that such separation enables robust prediction, sequence manipulation and environment characterization. We also propose an unsupervised VAE-based training procedure to learn DSSM as Bayesian filters. In our experiments, we demonstrate state-of-the-art performance in controlled generation and prediction of bouncing ball video sequences across varying gravitational influences.", "pdf": "/pdf/ae39ecbeab8ad13383ad885683e9bd836c882a67.pdf", "paperhash": "miladinovi|disentangled_state_space_models_unsupervised_learning_of_dynamics_across_heterogeneous_environments"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Workshop/DeepGenStruct/-/Paper36/Decision", "cdate": 1554814604278, "reply": {"forum": "HklaEUUtON", "replyto": "HklaEUUtON", "readers": [".*"], "nonreaders": {"values": []}, "writers": {"values-regex": ["ICLR.cc/2019/Workshop/DeepGenStruct/Program_Chairs"], "description": "How your identity will be displayed."}, "signatures": {"values": ["ICLR.cc/2019/Workshop/DeepGenStruct/Program_Chairs"], "description": "How your identity will be displayed."}, "content": {"title": {"order": 1, "required": true, "value": "Acceptance Decision"}, "decision": {"order": 2, "required": true, "value-radio": ["Accept", "Reject"], "description": "Acceptance decision"}, "comment": {"order": 3, "required": false, "value-regex": "[\\S\\s]{0,5000}", "description": ""}}}, "tcdate": 1554814604278, "tmdate": 1556906100920, "readers": ["everyone"], "writers": ["ICLR.cc/2019/Workshop/DeepGenStruct"], "invitees": ["ICLR.cc/2019/Workshop/DeepGenStruct/Program_Chairs"], "signatures": ["ICLR.cc/2019/Workshop/DeepGenStruct"], "details": {"writable": true}}}}], "count": 3}