{"notes": [{"id": "S1gEFkrtvH", "original": "SkgUKNRuDS", "number": 1837, "cdate": 1569439611924, "ddate": null, "tcdate": 1569439611924, "tmdate": 1577168220510, "tddate": null, "forum": "S1gEFkrtvH", "replyto": null, "invitation": "ICLR.cc/2020/Conference/-/Blind_Submission", "content": {"title": "BasisVAE: Orthogonal Latent Space for Deep Disentangled Representation", "authors": ["Jin-Young  Kim", "Sung-Bae Cho"], "authorids": ["seago0828@yonsei.ac.kr", "sbcho@yonsei.ac.kr"], "keywords": ["variational autoencoder", "latent space", "basis", "disentangled representation"], "TL;DR": "Construct orthogonal latent space for deep disentangled representation based on a basis in the linear algebra", "abstract": "The variational autoencoder, one of the generative models, defines the latent space for the data representation, and uses variational inference to infer the posterior probability. Several methods have been devised to disentangle the latent space for controlling the generative model easily. However, due to the excessive constraints, the more disentangled the latent space is, the lower quality the generative model has. A disentangled generative model would allocate a single feature of the generated data to the only single latent variable. In this paper, we propose a method to decompose the latent space into basis, and reconstruct it by linear combination of the latent bases. The proposed model called BasisVAE consists of the encoder that extracts the features of data and estimates the coefficients for linear combination of the latent bases, and the decoder that reconstructs the data with the combined latent bases. In this method, a single latent basis is subject to change in a single generative factor, and relatively invariant to the changes in other factors. It maintains the performance while relaxing the constraint for disentanglement on a basis, as we no longer need to decompose latent space on a standard basis. Experiments on the well-known benchmark datasets of MNIST, 3DFaces and CelebA demonstrate the efficacy of the proposed method, compared to other state-of-the-art methods. The proposed model not only defines the latent space to be separated by the generative factors, but also shows the better quality of the generated and reconstructed images. The disentangled representation is verified with the generated images and the simple classifier trained on the output of the encoder.", "pdf": "/pdf/079b41d419bb116ebe66ee31cbc020649feb676e.pdf", "paperhash": "kim|basisvae_orthogonal_latent_space_for_deep_disentangled_representation", "original_pdf": "/attachment/b49a377060eed4e3d3a1d7585dd7f810f24ec39e.pdf", "_bibtex": "@misc{\nkim2020basisvae,\ntitle={Basis{\\{}VAE{\\}}: Orthogonal Latent Space for Deep Disentangled Representation},\nauthor={Jin-Young  Kim and Sung-Bae Cho},\nyear={2020},\nurl={https://openreview.net/forum?id=S1gEFkrtvH}\n}"}, "signatures": ["ICLR.cc/2020/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference"], "details": {"replyCount": 25, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"reply": {"readers": {"values-regex": ".*"}, "writers": {"values": ["ICLR.cc/2020/Conference"]}, "signatures": {"values": ["ICLR.cc/2020/Conference"]}, "content": {"spotlight_video": {"value-regex": ".*"}, "full_presentation_video": {"value-regex": ".*"}, "original_pdf": {"required": false, "description": "Upload a PDF file that ends with .pdf", "value-regex": ".*"}, "appendix": {"value-regex": ".*"}, "authorids": {"values-regex": ".*"}, "poster": {"value-regex": ".*"}, "authors": {"values": ["Anonymous"]}, "slides": {"value-regex": ".*"}}}, "final": [], "signatures": ["ICLR.cc/2020/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference"], "noninvitees": [], "tcdate": 1569271260237, "tmdate": 1593459412141, "id": "ICLR.cc/2020/Conference/-/Blind_Submission"}}, "tauthor": "OpenReview.net"}, {"id": "H7_03fz3S", "original": null, "number": 1, "cdate": 1576798733732, "ddate": null, "tcdate": 1576798733732, "tmdate": 1576800902692, "tddate": null, "forum": "S1gEFkrtvH", "replyto": "S1gEFkrtvH", "invitation": "ICLR.cc/2020/Conference/Paper1837/-/Decision", "content": {"decision": "Reject", "comment": "The paper proposes a new way to learn a disentangled representation by embedding the latent representation z into an explicit learnt orthogonal basis M. While the paper proposes an interesting new approach to disentangling, the reviewers agreed that it would benefit from further work in order to be accepted. In particular, after an extensive discussion it was still not clear whether the assumptions of Theorem 1 applied to VAEs, and whether Theorem 1 was necessary at all. In terms of experimental results, the discussions revealed that the method used supervision during training, while the baselines in the paper are all unsupervised. The authors are encouraged to add supervised baselines in the next iteration of the manuscript. For these reasons I recommend rejection.", "title": "Paper Decision"}, "signatures": ["ICLR.cc/2020/Conference/Program_Chairs"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Program_Chairs"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "BasisVAE: Orthogonal Latent Space for Deep Disentangled Representation", "authors": ["Jin-Young  Kim", "Sung-Bae Cho"], "authorids": ["seago0828@yonsei.ac.kr", "sbcho@yonsei.ac.kr"], "keywords": ["variational autoencoder", "latent space", "basis", "disentangled representation"], "TL;DR": "Construct orthogonal latent space for deep disentangled representation based on a basis in the linear algebra", "abstract": "The variational autoencoder, one of the generative models, defines the latent space for the data representation, and uses variational inference to infer the posterior probability. Several methods have been devised to disentangle the latent space for controlling the generative model easily. However, due to the excessive constraints, the more disentangled the latent space is, the lower quality the generative model has. A disentangled generative model would allocate a single feature of the generated data to the only single latent variable. In this paper, we propose a method to decompose the latent space into basis, and reconstruct it by linear combination of the latent bases. The proposed model called BasisVAE consists of the encoder that extracts the features of data and estimates the coefficients for linear combination of the latent bases, and the decoder that reconstructs the data with the combined latent bases. In this method, a single latent basis is subject to change in a single generative factor, and relatively invariant to the changes in other factors. It maintains the performance while relaxing the constraint for disentanglement on a basis, as we no longer need to decompose latent space on a standard basis. Experiments on the well-known benchmark datasets of MNIST, 3DFaces and CelebA demonstrate the efficacy of the proposed method, compared to other state-of-the-art methods. The proposed model not only defines the latent space to be separated by the generative factors, but also shows the better quality of the generated and reconstructed images. The disentangled representation is verified with the generated images and the simple classifier trained on the output of the encoder.", "pdf": "/pdf/079b41d419bb116ebe66ee31cbc020649feb676e.pdf", "paperhash": "kim|basisvae_orthogonal_latent_space_for_deep_disentangled_representation", "original_pdf": "/attachment/b49a377060eed4e3d3a1d7585dd7f810f24ec39e.pdf", "_bibtex": "@misc{\nkim2020basisvae,\ntitle={Basis{\\{}VAE{\\}}: Orthogonal Latent Space for Deep Disentangled Representation},\nauthor={Jin-Young  Kim and Sung-Bae Cho},\nyear={2020},\nurl={https://openreview.net/forum?id=S1gEFkrtvH}\n}"}, "tags": [], "invitation": {"reply": {"writers": {"description": "How your identity will be displayed.", "values-regex": ["ICLR.cc/2020/Conference/Program_Chairs"]}, "signatures": {"values": ["ICLR.cc/2020/Conference/Program_Chairs"], "description": "How your identity will be displayed."}, "content": {"decision": {"value-radio": ["Accept (Spotlight)", "Accept (Talk)", "Accept (Poster)", "Reject"], "description": "Decision", "required": true, "order": 2}, "title": {"value": "Paper Decision", "required": true, "order": 1}, "comment": {"value-regex": "[\\S\\s]{0,5000}", "description": "", "required": false, "order": 3}}, "forum": "S1gEFkrtvH", "replyto": "S1gEFkrtvH", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}}, "expdate": 1576854540000, "duedate": 1576853940000, "multiReply": false, "readers": ["everyone"], "invitees": ["ICLR.cc/2020/Conference/Program_Chairs"], "tcdate": 1576795721691, "tmdate": 1576800272832, "super": "ICLR.cc/2020/Conference/-/Decision", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper1837/-/Decision"}}}, {"id": "B1xdl-vCFB", "original": null, "number": 2, "cdate": 1571873007637, "ddate": null, "tcdate": 1571873007637, "tmdate": 1573744175406, "tddate": null, "forum": "S1gEFkrtvH", "replyto": "S1gEFkrtvH", "invitation": "ICLR.cc/2020/Conference/Paper1837/-/Official_Review", "content": {"experience_assessment": "I have published in this field for several years.", "rating": "1: Reject", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "title": "Official Blind Review #1", "review": "[updated rating due to supervision of $c_i$, which was not made clear enough and would require other baseline models]\n\nThis paper proposes a modification of the usual parameterization of the encoder in VAEs, to more allow representing an embedding $z$ through an explicit basis $M_B$, which will be pushed to be orthogonal (and hence could correspond to a fully factorised disentangled representation). It is however possible for different samples $x$ to use different dimensions in the basis if that is beneficial (i.e. x is mapped to $z = f(x) \\cdot M_B$, where f(x) = (c_1, ... , c_n) which sums to 1.). This stretches the usual definition of what a \u201cdisentangled representation\u201d means, as this disentanglement is usually assumed to be globally consistent, but this is a fair extension.\nThey show that this formulation can be expressed as a different ELBO which can be maximized as for usual VAEs.\n\nI found this paper interesting, but I have one clarification that may modify my assessment quite strongly (hence I am tentatively putting it on the accept side). Some implementation details seem missing as well. Otherwise the presentation is fair, there are several results on different datasets which demonstrate the model's behaviour appropriately.\n\n1.\tThe main question I have, which may be rather trivial, is \u201care the c_i supervised in any way?\u201d.\u2028When I first read the paper, and looking at the losses in equations 9-11, I thought that this wasn\u2019t the case (also considering this paper is about unsupervised representation learning), but some sentences and figures make this quite unclear:\n\ta.\tIn Section 3.2, you say \u201cWe train the encoder so that c_i = 1 and c_j = 0 if the input data has i-feature and no j-feature\u201d. Do you?\n\tb.\tHow are the features in Figure 6 attached to each b_i?\u2028I.e. how was \u201c5_o_clock_shadow\u201d attached to that particular image at the top-left?\n\tIf the c_i are supervised, this paper is about a completely different type of generative modeling than what it compares against (it would be more comparable to VQ-VAE or other nearest-neighbor conditional density models).\n2.\tThere is not enough details about the architecture, hyperparameter and baselines in the current version of the paper.\n\ta.\tWhat n_x (i.e. dimensionality of the basis) do you use? How does this affect the results?\n\tb.\tHow exactly are f(x), \\Sigma_f(x) parametrized? They mention the architecture of the \u201cencoder\u201d in Section 4.1, but this could be much clearer.\n\tc.\tHow do you train M_B? I assume they are just a fixed set of embeddings that are back-propagated through?\n\td.\tWhat are the details about the architecture of the baselines, and their hyperparameters? E.g. what is the beta you used for Beta-VAE?\n3.\tThe reconstructions seem only partially related to their target inputs (e.g. see Figure 4). This seems to indicate that instead of really reconstructing x, the model chooses to reconstruct \u201ca close-by related \\tilde{x}\u201d, or even perhaps a b_i. This would make it behave closer to VQ-VAE, which explicitly does that. How related are reconstructions/samples to the b_i?\n4.\tCould you show the distribution of c_i that the model learns, and how much they vary for several example images? \u2028How \u201cpeaky\u201d is this distribution for a given image (this feeds into to the previous question as well)?\u2028The promise of the proposed model is that different images pick and choose different combinations of b_i, which hopefully one should see reflected in the distributions of c_i per sample, across clusters, or across the whole dataset.\n5.\tWhat happens when L_B is removed? I.e. what is the effect of removing the constraint on M_B being a basis, and instead allow it to be anything? This seems to make it closer to a continuous approximation to VQ-VAE?\n6.\tIs Equation 10 correct? Should the KL use N(f(x) \\cdot M_B, \\Sigma_f(x)), as in equation 9 above?\n7.\tSimilarly, in Section 4.2.3, did you mean \u201cc_i = 1 and c_j = 0 for i != j\u201d?\n\nIf the model happens to be fully unsupervised, I think that these results are quite interesting, and provide a good modification to the usual VAE framework, I find that having access to the M_B basis explicitly could be very valuable.\n\nThere is still an interesting philosophical discussion to be had about when one would like to obtain a \u201cglobal basis\u201d for the latent space (i.e. Figure 3 (b)), or when one would prefer more local ones. I can see clear advantages for a non-local basis, in terms of generalisation and compositionality, which your choice (i.e. Figure 3 (c) ) would prohibit.\n\nReferences:\n[1] VQ-VAE: Aaron van den Oord, Oriol Vinyals, Koray Kavukcuoglu, \u201cNeural Discrete Representation Learning\u201d, https://arxiv.org/abs/1711.00937", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory."}, "signatures": ["ICLR.cc/2020/Conference/Paper1837/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1837/AnonReviewer1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "BasisVAE: Orthogonal Latent Space for Deep Disentangled Representation", "authors": ["Jin-Young  Kim", "Sung-Bae Cho"], "authorids": ["seago0828@yonsei.ac.kr", "sbcho@yonsei.ac.kr"], "keywords": ["variational autoencoder", "latent space", "basis", "disentangled representation"], "TL;DR": "Construct orthogonal latent space for deep disentangled representation based on a basis in the linear algebra", "abstract": "The variational autoencoder, one of the generative models, defines the latent space for the data representation, and uses variational inference to infer the posterior probability. Several methods have been devised to disentangle the latent space for controlling the generative model easily. However, due to the excessive constraints, the more disentangled the latent space is, the lower quality the generative model has. A disentangled generative model would allocate a single feature of the generated data to the only single latent variable. In this paper, we propose a method to decompose the latent space into basis, and reconstruct it by linear combination of the latent bases. The proposed model called BasisVAE consists of the encoder that extracts the features of data and estimates the coefficients for linear combination of the latent bases, and the decoder that reconstructs the data with the combined latent bases. In this method, a single latent basis is subject to change in a single generative factor, and relatively invariant to the changes in other factors. It maintains the performance while relaxing the constraint for disentanglement on a basis, as we no longer need to decompose latent space on a standard basis. Experiments on the well-known benchmark datasets of MNIST, 3DFaces and CelebA demonstrate the efficacy of the proposed method, compared to other state-of-the-art methods. The proposed model not only defines the latent space to be separated by the generative factors, but also shows the better quality of the generated and reconstructed images. The disentangled representation is verified with the generated images and the simple classifier trained on the output of the encoder.", "pdf": "/pdf/079b41d419bb116ebe66ee31cbc020649feb676e.pdf", "paperhash": "kim|basisvae_orthogonal_latent_space_for_deep_disentangled_representation", "original_pdf": "/attachment/b49a377060eed4e3d3a1d7585dd7f810f24ec39e.pdf", "_bibtex": "@misc{\nkim2020basisvae,\ntitle={Basis{\\{}VAE{\\}}: Orthogonal Latent Space for Deep Disentangled Representation},\nauthor={Jin-Young  Kim and Sung-Bae Cho},\nyear={2020},\nurl={https://openreview.net/forum?id=S1gEFkrtvH}\n}"}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "S1gEFkrtvH", "replyto": "S1gEFkrtvH", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper1837/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper1837/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1575369535297, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper1837/Reviewers"], "noninvitees": [], "tcdate": 1570237731588, "tmdate": 1575369535310, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper1837/-/Official_Review"}}}, {"id": "rkeK3Tkijr", "original": null, "number": 24, "cdate": 1573744049513, "ddate": null, "tcdate": 1573744049513, "tmdate": 1573744049513, "tddate": null, "forum": "S1gEFkrtvH", "replyto": "HJgjySaUjH", "invitation": "ICLR.cc/2020/Conference/Paper1837/-/Official_Comment", "content": {"title": "Response to authors", "comment": "Thank you for the thorough rebuttal and for adding the comparison to VQ-VAE, very helpful.\n\n1. Thanks for making this clear. Unfortunately, I actually feel that the fact that you supervise $c_i $ but do not make this clear is rather problematic. \nAll baselines you compare against, and the history of the field of disentanglement learning is addressing the issue of *unsupervised* representation learning. Checking again, I see that you do not mention \"unsupervised\" or \"supervised\" anywhere in the paper, so this is more of an assumption on my side, but I feel you should have make that more explicit, or report unsupervised results in the Appendix.\n\nIt also puts you in competition with a plethora of other works which actually leverage supervision (fully supervised or semi-supervised). For example the Multimodal VAE literature has been doing this for a while [1-7], which are missing from the Related work.\n\nUnfortunately, due to this issue, I do not feel comfortable with approving the manuscript in this state, as this would require quite a rewrite and change of baselines.\n\nReferences:\n[1] For a good minimal extension of the VAE framework to introduce supervision, and their Related work section: https://arxiv.org/abs/1906.01044\n[2] Siddarth et al 2017, https://arxiv.org/abs/1706.00400\n[3] DC-IGN: https://arxiv.org/abs/1503.03167\n[4] JMVAE: https://arxiv.org/abs/1611.01891\n[5] BiVCCA: https://arxiv.org/abs/1610.03454\n[6] TELBO: https://arxiv.org/abs/1705.10762\n[7] MVAE: https://arxiv.org/abs/1802.05335 \n[8] Beta-TCVAE: https://arxiv.org/abs/1802.04942\n\n\n-- \nOther points:\n\n4. Thanks for the added plot. It was particularly informative to indicate specific sets of c_i that switch their behaviour. It would be good to see this for a single image, as currently this makes it hard to know what all the other c_i end up doing. Are they just capturing variability around a canonical c_j (which would be like the prototype / mean vector like in VQ-VAE)?\n\n5. I understood what the term does, I was wondering if you observed this lack of disentanglement happening *in practice*?\n\n--\n\nAs a point towards addressing the issue that the other reviewers have with the ELBO formulation:\n\nThe proposed ELBO derivation is not helpful in practice, because looking at the loss terms 9-11, none of them assume the fully factorised form shown in equation 8.\nInstead, BasisVAE simply forces the encoder to have a specific parametrisation (a linear combination of K vectors: z = \\sum_i c_i m_i), but this is never strictly enforced (even the basis assumption of $M_B$, which would be required for Equation 8 to be really used, is only a regularisation term...).\nThis choice of parametrisation may be unable to capture some distributions p(x), which is a trade-off to decide for the user.\n\nHence personally I would remove Theorem 1 as it does not help and is confusing at best for people that expect a VAE to capture any distribution p(x)."}, "signatures": ["ICLR.cc/2020/Conference/Paper1837/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1837/AnonReviewer1", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "BasisVAE: Orthogonal Latent Space for Deep Disentangled Representation", "authors": ["Jin-Young  Kim", "Sung-Bae Cho"], "authorids": ["seago0828@yonsei.ac.kr", "sbcho@yonsei.ac.kr"], "keywords": ["variational autoencoder", "latent space", "basis", "disentangled representation"], "TL;DR": "Construct orthogonal latent space for deep disentangled representation based on a basis in the linear algebra", "abstract": "The variational autoencoder, one of the generative models, defines the latent space for the data representation, and uses variational inference to infer the posterior probability. Several methods have been devised to disentangle the latent space for controlling the generative model easily. However, due to the excessive constraints, the more disentangled the latent space is, the lower quality the generative model has. A disentangled generative model would allocate a single feature of the generated data to the only single latent variable. In this paper, we propose a method to decompose the latent space into basis, and reconstruct it by linear combination of the latent bases. The proposed model called BasisVAE consists of the encoder that extracts the features of data and estimates the coefficients for linear combination of the latent bases, and the decoder that reconstructs the data with the combined latent bases. In this method, a single latent basis is subject to change in a single generative factor, and relatively invariant to the changes in other factors. It maintains the performance while relaxing the constraint for disentanglement on a basis, as we no longer need to decompose latent space on a standard basis. Experiments on the well-known benchmark datasets of MNIST, 3DFaces and CelebA demonstrate the efficacy of the proposed method, compared to other state-of-the-art methods. The proposed model not only defines the latent space to be separated by the generative factors, but also shows the better quality of the generated and reconstructed images. The disentangled representation is verified with the generated images and the simple classifier trained on the output of the encoder.", "pdf": "/pdf/079b41d419bb116ebe66ee31cbc020649feb676e.pdf", "paperhash": "kim|basisvae_orthogonal_latent_space_for_deep_disentangled_representation", "original_pdf": "/attachment/b49a377060eed4e3d3a1d7585dd7f810f24ec39e.pdf", "_bibtex": "@misc{\nkim2020basisvae,\ntitle={Basis{\\{}VAE{\\}}: Orthogonal Latent Space for Deep Disentangled Representation},\nauthor={Jin-Young  Kim and Sung-Bae Cho},\nyear={2020},\nurl={https://openreview.net/forum?id=S1gEFkrtvH}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "S1gEFkrtvH", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper1837/Authors", "ICLR.cc/2020/Conference/Paper1837/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper1837/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper1837/Reviewers", "ICLR.cc/2020/Conference/Paper1837/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper1837/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper1837/Authors|ICLR.cc/2020/Conference/Paper1837/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504150180, "tmdate": 1576860558951, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper1837/Authors", "ICLR.cc/2020/Conference/Paper1837/Reviewers", "ICLR.cc/2020/Conference/Paper1837/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper1837/-/Official_Comment"}}}, {"id": "r1g81ERqsH", "original": null, "number": 23, "cdate": 1573737437827, "ddate": null, "tcdate": 1573737437827, "tmdate": 1573737437827, "tddate": null, "forum": "S1gEFkrtvH", "replyto": "B1g_Pk6ciB", "invitation": "ICLR.cc/2020/Conference/Paper1837/-/Official_Comment", "content": {"title": "Answers to Reviewer #3 ", "comment": "We considered conditional independence in this paper in relation to disentanglement. That is, with $x$ and corresponding $z=\\Sigma c_i z_i$, the feature changed by $z_1$ and the feature changed by $z_2$ are not related to each other. Therefore, when conditional by $x$, the probability that the property represented by $z_1$ and $z_2$ $p(z_1 , z_2|x)$ is expressed as the probability that the property represented by z_2 multiplied by the probability that the property represented by z_1 is expressed $p(z_1 |x)p(z_2 |x)$.\n\nTherefore, the decoder needs to get $z_i$ from one of the encoder's outputs, $c_i$, and generate $x$ from it, and then this process is proceeded and the loss is calculated for all $i$. But, for the convenience, decoder generates $x$ from the linear combination $z=\\Sigma c_i z_i$."}, "signatures": ["ICLR.cc/2020/Conference/Paper1837/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1837/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "BasisVAE: Orthogonal Latent Space for Deep Disentangled Representation", "authors": ["Jin-Young  Kim", "Sung-Bae Cho"], "authorids": ["seago0828@yonsei.ac.kr", "sbcho@yonsei.ac.kr"], "keywords": ["variational autoencoder", "latent space", "basis", "disentangled representation"], "TL;DR": "Construct orthogonal latent space for deep disentangled representation based on a basis in the linear algebra", "abstract": "The variational autoencoder, one of the generative models, defines the latent space for the data representation, and uses variational inference to infer the posterior probability. Several methods have been devised to disentangle the latent space for controlling the generative model easily. However, due to the excessive constraints, the more disentangled the latent space is, the lower quality the generative model has. A disentangled generative model would allocate a single feature of the generated data to the only single latent variable. In this paper, we propose a method to decompose the latent space into basis, and reconstruct it by linear combination of the latent bases. The proposed model called BasisVAE consists of the encoder that extracts the features of data and estimates the coefficients for linear combination of the latent bases, and the decoder that reconstructs the data with the combined latent bases. In this method, a single latent basis is subject to change in a single generative factor, and relatively invariant to the changes in other factors. It maintains the performance while relaxing the constraint for disentanglement on a basis, as we no longer need to decompose latent space on a standard basis. Experiments on the well-known benchmark datasets of MNIST, 3DFaces and CelebA demonstrate the efficacy of the proposed method, compared to other state-of-the-art methods. The proposed model not only defines the latent space to be separated by the generative factors, but also shows the better quality of the generated and reconstructed images. The disentangled representation is verified with the generated images and the simple classifier trained on the output of the encoder.", "pdf": "/pdf/079b41d419bb116ebe66ee31cbc020649feb676e.pdf", "paperhash": "kim|basisvae_orthogonal_latent_space_for_deep_disentangled_representation", "original_pdf": "/attachment/b49a377060eed4e3d3a1d7585dd7f810f24ec39e.pdf", "_bibtex": "@misc{\nkim2020basisvae,\ntitle={Basis{\\{}VAE{\\}}: Orthogonal Latent Space for Deep Disentangled Representation},\nauthor={Jin-Young  Kim and Sung-Bae Cho},\nyear={2020},\nurl={https://openreview.net/forum?id=S1gEFkrtvH}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "S1gEFkrtvH", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper1837/Authors", "ICLR.cc/2020/Conference/Paper1837/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper1837/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper1837/Reviewers", "ICLR.cc/2020/Conference/Paper1837/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper1837/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper1837/Authors|ICLR.cc/2020/Conference/Paper1837/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504150180, "tmdate": 1576860558951, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper1837/Authors", "ICLR.cc/2020/Conference/Paper1837/Reviewers", "ICLR.cc/2020/Conference/Paper1837/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper1837/-/Official_Comment"}}}, {"id": "B1g_Pk6ciB", "original": null, "number": 22, "cdate": 1573732192495, "ddate": null, "tcdate": 1573732192495, "tmdate": 1573732192495, "tddate": null, "forum": "S1gEFkrtvH", "replyto": "B1gMzgvqoB", "invitation": "ICLR.cc/2020/Conference/Paper1837/-/Official_Comment", "content": {"title": "Encoder does not assure the assumption", "comment": "The conditional independence $p(z_1, z_2|x)=p(z_1|x)p(z_2|x)$ should be derived from the configurations of the prior $p(z)$ and decoder $p_\\theta(x|z)$. \nHow you sample $z$ from the encoder (or your variational distribution) is irrelevant of the conditional independence of the *true* posterior.\n\nThis is why I indicate that the decoder (or maybe the prior) needs a special structure."}, "signatures": ["ICLR.cc/2020/Conference/Paper1837/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1837/AnonReviewer3", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "BasisVAE: Orthogonal Latent Space for Deep Disentangled Representation", "authors": ["Jin-Young  Kim", "Sung-Bae Cho"], "authorids": ["seago0828@yonsei.ac.kr", "sbcho@yonsei.ac.kr"], "keywords": ["variational autoencoder", "latent space", "basis", "disentangled representation"], "TL;DR": "Construct orthogonal latent space for deep disentangled representation based on a basis in the linear algebra", "abstract": "The variational autoencoder, one of the generative models, defines the latent space for the data representation, and uses variational inference to infer the posterior probability. Several methods have been devised to disentangle the latent space for controlling the generative model easily. However, due to the excessive constraints, the more disentangled the latent space is, the lower quality the generative model has. A disentangled generative model would allocate a single feature of the generated data to the only single latent variable. In this paper, we propose a method to decompose the latent space into basis, and reconstruct it by linear combination of the latent bases. The proposed model called BasisVAE consists of the encoder that extracts the features of data and estimates the coefficients for linear combination of the latent bases, and the decoder that reconstructs the data with the combined latent bases. In this method, a single latent basis is subject to change in a single generative factor, and relatively invariant to the changes in other factors. It maintains the performance while relaxing the constraint for disentanglement on a basis, as we no longer need to decompose latent space on a standard basis. Experiments on the well-known benchmark datasets of MNIST, 3DFaces and CelebA demonstrate the efficacy of the proposed method, compared to other state-of-the-art methods. The proposed model not only defines the latent space to be separated by the generative factors, but also shows the better quality of the generated and reconstructed images. The disentangled representation is verified with the generated images and the simple classifier trained on the output of the encoder.", "pdf": "/pdf/079b41d419bb116ebe66ee31cbc020649feb676e.pdf", "paperhash": "kim|basisvae_orthogonal_latent_space_for_deep_disentangled_representation", "original_pdf": "/attachment/b49a377060eed4e3d3a1d7585dd7f810f24ec39e.pdf", "_bibtex": "@misc{\nkim2020basisvae,\ntitle={Basis{\\{}VAE{\\}}: Orthogonal Latent Space for Deep Disentangled Representation},\nauthor={Jin-Young  Kim and Sung-Bae Cho},\nyear={2020},\nurl={https://openreview.net/forum?id=S1gEFkrtvH}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "S1gEFkrtvH", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper1837/Authors", "ICLR.cc/2020/Conference/Paper1837/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper1837/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper1837/Reviewers", "ICLR.cc/2020/Conference/Paper1837/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper1837/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper1837/Authors|ICLR.cc/2020/Conference/Paper1837/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504150180, "tmdate": 1576860558951, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper1837/Authors", "ICLR.cc/2020/Conference/Paper1837/Reviewers", "ICLR.cc/2020/Conference/Paper1837/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper1837/-/Official_Comment"}}}, {"id": "B1gMzgvqoB", "original": null, "number": 21, "cdate": 1573707785853, "ddate": null, "tcdate": 1573707785853, "tmdate": 1573707879260, "tddate": null, "forum": "S1gEFkrtvH", "replyto": "HJgw2OGcjH", "invitation": "ICLR.cc/2020/Conference/Paper1837/-/Official_Comment", "content": {"title": "Answers to Reviewer #3", "comment": "Thank you for your respond!\n\n1.  We can derive $p(z_1, z_2 | x)=p(z_1 |z_2 , x)p(z_2 | x)$ with a conditional probability. In the assumption that the $z_i$ are independent conditioned by $x$, since $p(z_1 | z_2 , x) =p(z_1 |x)$, $p(z_1 , z_2 |x)$ can be factorized into $p(z_1 |x)p(z_2 |x)$. The $z$ in the line 9 of Algorithm 1 is sampled from $N(M_B \\cdot c^T,\\Sigma_{f(x)})$. In this process, we intended that the encoder outputs coefficient $c_i$ for independent $z_i$, and the decoder generates data by inputting $z$ which is a linear combination of $c_i$ and $z_i$. Therefore, decoder takes $z$ which is a linear combination of all components of $z$.\n\n2. Thank you for your comments. To avoid the confusion, we'll correct that word."}, "signatures": ["ICLR.cc/2020/Conference/Paper1837/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1837/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "BasisVAE: Orthogonal Latent Space for Deep Disentangled Representation", "authors": ["Jin-Young  Kim", "Sung-Bae Cho"], "authorids": ["seago0828@yonsei.ac.kr", "sbcho@yonsei.ac.kr"], "keywords": ["variational autoencoder", "latent space", "basis", "disentangled representation"], "TL;DR": "Construct orthogonal latent space for deep disentangled representation based on a basis in the linear algebra", "abstract": "The variational autoencoder, one of the generative models, defines the latent space for the data representation, and uses variational inference to infer the posterior probability. Several methods have been devised to disentangle the latent space for controlling the generative model easily. However, due to the excessive constraints, the more disentangled the latent space is, the lower quality the generative model has. A disentangled generative model would allocate a single feature of the generated data to the only single latent variable. In this paper, we propose a method to decompose the latent space into basis, and reconstruct it by linear combination of the latent bases. The proposed model called BasisVAE consists of the encoder that extracts the features of data and estimates the coefficients for linear combination of the latent bases, and the decoder that reconstructs the data with the combined latent bases. In this method, a single latent basis is subject to change in a single generative factor, and relatively invariant to the changes in other factors. It maintains the performance while relaxing the constraint for disentanglement on a basis, as we no longer need to decompose latent space on a standard basis. Experiments on the well-known benchmark datasets of MNIST, 3DFaces and CelebA demonstrate the efficacy of the proposed method, compared to other state-of-the-art methods. The proposed model not only defines the latent space to be separated by the generative factors, but also shows the better quality of the generated and reconstructed images. The disentangled representation is verified with the generated images and the simple classifier trained on the output of the encoder.", "pdf": "/pdf/079b41d419bb116ebe66ee31cbc020649feb676e.pdf", "paperhash": "kim|basisvae_orthogonal_latent_space_for_deep_disentangled_representation", "original_pdf": "/attachment/b49a377060eed4e3d3a1d7585dd7f810f24ec39e.pdf", "_bibtex": "@misc{\nkim2020basisvae,\ntitle={Basis{\\{}VAE{\\}}: Orthogonal Latent Space for Deep Disentangled Representation},\nauthor={Jin-Young  Kim and Sung-Bae Cho},\nyear={2020},\nurl={https://openreview.net/forum?id=S1gEFkrtvH}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "S1gEFkrtvH", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper1837/Authors", "ICLR.cc/2020/Conference/Paper1837/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper1837/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper1837/Reviewers", "ICLR.cc/2020/Conference/Paper1837/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper1837/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper1837/Authors|ICLR.cc/2020/Conference/Paper1837/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504150180, "tmdate": 1576860558951, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper1837/Authors", "ICLR.cc/2020/Conference/Paper1837/Reviewers", "ICLR.cc/2020/Conference/Paper1837/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper1837/-/Official_Comment"}}}, {"id": "HJgw2OGcjH", "original": null, "number": 20, "cdate": 1573689518734, "ddate": null, "tcdate": 1573689518734, "tmdate": 1573689518734, "tddate": null, "forum": "S1gEFkrtvH", "replyto": "HyghbSTIsr", "invitation": "ICLR.cc/2020/Conference/Paper1837/-/Official_Comment", "content": {"title": "Point 1. (Issue 1 of Reviewer #2)", "comment": "Thank you for the response. \n\nAs in the discussion with Reviewer #2, I am not yet convinced that p(z_1, z_2 | x) factorizes into p(z_1|x)p(z_2|x). \nThe generative model uses decoder $x \\sim p_\\theta(\\cdot | z)$ (line 9 of Algorithm 1) where the decoder network takes all components of $z$ as its input. \nIn this case, the conditional independence $p(z_1|x)p(z_2|x)$ should be carefully justified. (I think the decoder needs some special structure.)\n\nRegarding point 3: I interpreted the binary function as a function that returns a binary value {0,1}. \nSimply calling \"negative log likelihood\" or \"reconstruction function\" can avoid the possible confusion."}, "signatures": ["ICLR.cc/2020/Conference/Paper1837/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1837/AnonReviewer3", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "BasisVAE: Orthogonal Latent Space for Deep Disentangled Representation", "authors": ["Jin-Young  Kim", "Sung-Bae Cho"], "authorids": ["seago0828@yonsei.ac.kr", "sbcho@yonsei.ac.kr"], "keywords": ["variational autoencoder", "latent space", "basis", "disentangled representation"], "TL;DR": "Construct orthogonal latent space for deep disentangled representation based on a basis in the linear algebra", "abstract": "The variational autoencoder, one of the generative models, defines the latent space for the data representation, and uses variational inference to infer the posterior probability. Several methods have been devised to disentangle the latent space for controlling the generative model easily. However, due to the excessive constraints, the more disentangled the latent space is, the lower quality the generative model has. A disentangled generative model would allocate a single feature of the generated data to the only single latent variable. In this paper, we propose a method to decompose the latent space into basis, and reconstruct it by linear combination of the latent bases. The proposed model called BasisVAE consists of the encoder that extracts the features of data and estimates the coefficients for linear combination of the latent bases, and the decoder that reconstructs the data with the combined latent bases. In this method, a single latent basis is subject to change in a single generative factor, and relatively invariant to the changes in other factors. It maintains the performance while relaxing the constraint for disentanglement on a basis, as we no longer need to decompose latent space on a standard basis. Experiments on the well-known benchmark datasets of MNIST, 3DFaces and CelebA demonstrate the efficacy of the proposed method, compared to other state-of-the-art methods. The proposed model not only defines the latent space to be separated by the generative factors, but also shows the better quality of the generated and reconstructed images. The disentangled representation is verified with the generated images and the simple classifier trained on the output of the encoder.", "pdf": "/pdf/079b41d419bb116ebe66ee31cbc020649feb676e.pdf", "paperhash": "kim|basisvae_orthogonal_latent_space_for_deep_disentangled_representation", "original_pdf": "/attachment/b49a377060eed4e3d3a1d7585dd7f810f24ec39e.pdf", "_bibtex": "@misc{\nkim2020basisvae,\ntitle={Basis{\\{}VAE{\\}}: Orthogonal Latent Space for Deep Disentangled Representation},\nauthor={Jin-Young  Kim and Sung-Bae Cho},\nyear={2020},\nurl={https://openreview.net/forum?id=S1gEFkrtvH}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "S1gEFkrtvH", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper1837/Authors", "ICLR.cc/2020/Conference/Paper1837/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper1837/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper1837/Reviewers", "ICLR.cc/2020/Conference/Paper1837/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper1837/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper1837/Authors|ICLR.cc/2020/Conference/Paper1837/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504150180, "tmdate": 1576860558951, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper1837/Authors", "ICLR.cc/2020/Conference/Paper1837/Reviewers", "ICLR.cc/2020/Conference/Paper1837/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper1837/-/Official_Comment"}}}, {"id": "B1lk1AaDor", "original": null, "number": 18, "cdate": 1573539287103, "ddate": null, "tcdate": 1573539287103, "tmdate": 1573539287103, "tddate": null, "forum": "S1gEFkrtvH", "replyto": "SygFi36wir", "invitation": "ICLR.cc/2020/Conference/Paper1837/-/Official_Comment", "content": {"title": "Answers to Reviewer #2", "comment": "Thank you for your consecutive reviews!\n\nAs we mentioned, by definition, in that space, a latent variable covers only one generative factor and does not affect each other and we interpreted it as independence. \n\nIn many existing disentangled representations, it is confirmed that even for the same data x, different z_i changes individual characteristics (e.g. background color, gender, etc.) that do not affect each other."}, "signatures": ["ICLR.cc/2020/Conference/Paper1837/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1837/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "BasisVAE: Orthogonal Latent Space for Deep Disentangled Representation", "authors": ["Jin-Young  Kim", "Sung-Bae Cho"], "authorids": ["seago0828@yonsei.ac.kr", "sbcho@yonsei.ac.kr"], "keywords": ["variational autoencoder", "latent space", "basis", "disentangled representation"], "TL;DR": "Construct orthogonal latent space for deep disentangled representation based on a basis in the linear algebra", "abstract": "The variational autoencoder, one of the generative models, defines the latent space for the data representation, and uses variational inference to infer the posterior probability. Several methods have been devised to disentangle the latent space for controlling the generative model easily. However, due to the excessive constraints, the more disentangled the latent space is, the lower quality the generative model has. A disentangled generative model would allocate a single feature of the generated data to the only single latent variable. In this paper, we propose a method to decompose the latent space into basis, and reconstruct it by linear combination of the latent bases. The proposed model called BasisVAE consists of the encoder that extracts the features of data and estimates the coefficients for linear combination of the latent bases, and the decoder that reconstructs the data with the combined latent bases. In this method, a single latent basis is subject to change in a single generative factor, and relatively invariant to the changes in other factors. It maintains the performance while relaxing the constraint for disentanglement on a basis, as we no longer need to decompose latent space on a standard basis. Experiments on the well-known benchmark datasets of MNIST, 3DFaces and CelebA demonstrate the efficacy of the proposed method, compared to other state-of-the-art methods. The proposed model not only defines the latent space to be separated by the generative factors, but also shows the better quality of the generated and reconstructed images. The disentangled representation is verified with the generated images and the simple classifier trained on the output of the encoder.", "pdf": "/pdf/079b41d419bb116ebe66ee31cbc020649feb676e.pdf", "paperhash": "kim|basisvae_orthogonal_latent_space_for_deep_disentangled_representation", "original_pdf": "/attachment/b49a377060eed4e3d3a1d7585dd7f810f24ec39e.pdf", "_bibtex": "@misc{\nkim2020basisvae,\ntitle={Basis{\\{}VAE{\\}}: Orthogonal Latent Space for Deep Disentangled Representation},\nauthor={Jin-Young  Kim and Sung-Bae Cho},\nyear={2020},\nurl={https://openreview.net/forum?id=S1gEFkrtvH}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "S1gEFkrtvH", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper1837/Authors", "ICLR.cc/2020/Conference/Paper1837/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper1837/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper1837/Reviewers", "ICLR.cc/2020/Conference/Paper1837/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper1837/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper1837/Authors|ICLR.cc/2020/Conference/Paper1837/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504150180, "tmdate": 1576860558951, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper1837/Authors", "ICLR.cc/2020/Conference/Paper1837/Reviewers", "ICLR.cc/2020/Conference/Paper1837/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper1837/-/Official_Comment"}}}, {"id": "SygFi36wir", "original": null, "number": 17, "cdate": 1573538977464, "ddate": null, "tcdate": 1573538977464, "tmdate": 1573538977464, "tddate": null, "forum": "S1gEFkrtvH", "replyto": "HJlaLopwsr", "invitation": "ICLR.cc/2020/Conference/Paper1837/-/Official_Comment", "content": {"title": "Potentially false premise", "comment": "The statement \"Theorem 1 shows that the existing ELBO can be separated into independent z_i's.\" is only true if we believe Theorem 1's premise that \"z_i are independent conditioned by x\" is true for VAEs. Can you explain why \"z_i are independent conditioned by x\" is true for VAEs?"}, "signatures": ["ICLR.cc/2020/Conference/Paper1837/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1837/AnonReviewer2", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "BasisVAE: Orthogonal Latent Space for Deep Disentangled Representation", "authors": ["Jin-Young  Kim", "Sung-Bae Cho"], "authorids": ["seago0828@yonsei.ac.kr", "sbcho@yonsei.ac.kr"], "keywords": ["variational autoencoder", "latent space", "basis", "disentangled representation"], "TL;DR": "Construct orthogonal latent space for deep disentangled representation based on a basis in the linear algebra", "abstract": "The variational autoencoder, one of the generative models, defines the latent space for the data representation, and uses variational inference to infer the posterior probability. Several methods have been devised to disentangle the latent space for controlling the generative model easily. However, due to the excessive constraints, the more disentangled the latent space is, the lower quality the generative model has. A disentangled generative model would allocate a single feature of the generated data to the only single latent variable. In this paper, we propose a method to decompose the latent space into basis, and reconstruct it by linear combination of the latent bases. The proposed model called BasisVAE consists of the encoder that extracts the features of data and estimates the coefficients for linear combination of the latent bases, and the decoder that reconstructs the data with the combined latent bases. In this method, a single latent basis is subject to change in a single generative factor, and relatively invariant to the changes in other factors. It maintains the performance while relaxing the constraint for disentanglement on a basis, as we no longer need to decompose latent space on a standard basis. Experiments on the well-known benchmark datasets of MNIST, 3DFaces and CelebA demonstrate the efficacy of the proposed method, compared to other state-of-the-art methods. The proposed model not only defines the latent space to be separated by the generative factors, but also shows the better quality of the generated and reconstructed images. The disentangled representation is verified with the generated images and the simple classifier trained on the output of the encoder.", "pdf": "/pdf/079b41d419bb116ebe66ee31cbc020649feb676e.pdf", "paperhash": "kim|basisvae_orthogonal_latent_space_for_deep_disentangled_representation", "original_pdf": "/attachment/b49a377060eed4e3d3a1d7585dd7f810f24ec39e.pdf", "_bibtex": "@misc{\nkim2020basisvae,\ntitle={Basis{\\{}VAE{\\}}: Orthogonal Latent Space for Deep Disentangled Representation},\nauthor={Jin-Young  Kim and Sung-Bae Cho},\nyear={2020},\nurl={https://openreview.net/forum?id=S1gEFkrtvH}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "S1gEFkrtvH", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper1837/Authors", "ICLR.cc/2020/Conference/Paper1837/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper1837/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper1837/Reviewers", "ICLR.cc/2020/Conference/Paper1837/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper1837/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper1837/Authors|ICLR.cc/2020/Conference/Paper1837/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504150180, "tmdate": 1576860558951, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper1837/Authors", "ICLR.cc/2020/Conference/Paper1837/Reviewers", "ICLR.cc/2020/Conference/Paper1837/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper1837/-/Official_Comment"}}}, {"id": "HJlaLopwsr", "original": null, "number": 16, "cdate": 1573538645079, "ddate": null, "tcdate": 1573538645079, "tmdate": 1573538645079, "tddate": null, "forum": "S1gEFkrtvH", "replyto": "BJg9KSpwoS", "invitation": "ICLR.cc/2020/Conference/Paper1837/-/Official_Comment", "content": {"title": "Answers to Reviewer #2", "comment": "Theorem 1 shows that the existing ELBO can be separated into independent z_i's. \nBased on these observations, we set the output of the encoder to coefficient c_i for independent z_i instead of one integrated z, as in normal VAE, even though this actually violated to VAE. \nBy setting the loss as equations (9) ~ (11), we have trained the data representation to separate the z_i from each other (ie, to satisfy the disentanglement)."}, "signatures": ["ICLR.cc/2020/Conference/Paper1837/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1837/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "BasisVAE: Orthogonal Latent Space for Deep Disentangled Representation", "authors": ["Jin-Young  Kim", "Sung-Bae Cho"], "authorids": ["seago0828@yonsei.ac.kr", "sbcho@yonsei.ac.kr"], "keywords": ["variational autoencoder", "latent space", "basis", "disentangled representation"], "TL;DR": "Construct orthogonal latent space for deep disentangled representation based on a basis in the linear algebra", "abstract": "The variational autoencoder, one of the generative models, defines the latent space for the data representation, and uses variational inference to infer the posterior probability. Several methods have been devised to disentangle the latent space for controlling the generative model easily. However, due to the excessive constraints, the more disentangled the latent space is, the lower quality the generative model has. A disentangled generative model would allocate a single feature of the generated data to the only single latent variable. In this paper, we propose a method to decompose the latent space into basis, and reconstruct it by linear combination of the latent bases. The proposed model called BasisVAE consists of the encoder that extracts the features of data and estimates the coefficients for linear combination of the latent bases, and the decoder that reconstructs the data with the combined latent bases. In this method, a single latent basis is subject to change in a single generative factor, and relatively invariant to the changes in other factors. It maintains the performance while relaxing the constraint for disentanglement on a basis, as we no longer need to decompose latent space on a standard basis. Experiments on the well-known benchmark datasets of MNIST, 3DFaces and CelebA demonstrate the efficacy of the proposed method, compared to other state-of-the-art methods. The proposed model not only defines the latent space to be separated by the generative factors, but also shows the better quality of the generated and reconstructed images. The disentangled representation is verified with the generated images and the simple classifier trained on the output of the encoder.", "pdf": "/pdf/079b41d419bb116ebe66ee31cbc020649feb676e.pdf", "paperhash": "kim|basisvae_orthogonal_latent_space_for_deep_disentangled_representation", "original_pdf": "/attachment/b49a377060eed4e3d3a1d7585dd7f810f24ec39e.pdf", "_bibtex": "@misc{\nkim2020basisvae,\ntitle={Basis{\\{}VAE{\\}}: Orthogonal Latent Space for Deep Disentangled Representation},\nauthor={Jin-Young  Kim and Sung-Bae Cho},\nyear={2020},\nurl={https://openreview.net/forum?id=S1gEFkrtvH}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "S1gEFkrtvH", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper1837/Authors", "ICLR.cc/2020/Conference/Paper1837/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper1837/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper1837/Reviewers", "ICLR.cc/2020/Conference/Paper1837/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper1837/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper1837/Authors|ICLR.cc/2020/Conference/Paper1837/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504150180, "tmdate": 1576860558951, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper1837/Authors", "ICLR.cc/2020/Conference/Paper1837/Reviewers", "ICLR.cc/2020/Conference/Paper1837/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper1837/-/Official_Comment"}}}, {"id": "BJg9KSpwoS", "original": null, "number": 15, "cdate": 1573537154492, "ddate": null, "tcdate": 1573537154492, "tmdate": 1573537154492, "tddate": null, "forum": "S1gEFkrtvH", "replyto": "ryxC77nvsr", "invitation": "ICLR.cc/2020/Conference/Paper1837/-/Official_Comment", "content": {"title": "What is the significance of Theorem 1?", "comment": "Does this mean that \"z_i are independent conditioned by x\" is an explicit assumption in the premise of Theorem 1? If so, OK, I accept that Theorem 1 is correct.\n\nBut what, then, is the significance of Theorem 1? Since the premise for Theorem 1 is violated in a VAE, then Theorem 1 can't be applied to a VAE."}, "signatures": ["ICLR.cc/2020/Conference/Paper1837/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1837/AnonReviewer2", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "BasisVAE: Orthogonal Latent Space for Deep Disentangled Representation", "authors": ["Jin-Young  Kim", "Sung-Bae Cho"], "authorids": ["seago0828@yonsei.ac.kr", "sbcho@yonsei.ac.kr"], "keywords": ["variational autoencoder", "latent space", "basis", "disentangled representation"], "TL;DR": "Construct orthogonal latent space for deep disentangled representation based on a basis in the linear algebra", "abstract": "The variational autoencoder, one of the generative models, defines the latent space for the data representation, and uses variational inference to infer the posterior probability. Several methods have been devised to disentangle the latent space for controlling the generative model easily. However, due to the excessive constraints, the more disentangled the latent space is, the lower quality the generative model has. A disentangled generative model would allocate a single feature of the generated data to the only single latent variable. In this paper, we propose a method to decompose the latent space into basis, and reconstruct it by linear combination of the latent bases. The proposed model called BasisVAE consists of the encoder that extracts the features of data and estimates the coefficients for linear combination of the latent bases, and the decoder that reconstructs the data with the combined latent bases. In this method, a single latent basis is subject to change in a single generative factor, and relatively invariant to the changes in other factors. It maintains the performance while relaxing the constraint for disentanglement on a basis, as we no longer need to decompose latent space on a standard basis. Experiments on the well-known benchmark datasets of MNIST, 3DFaces and CelebA demonstrate the efficacy of the proposed method, compared to other state-of-the-art methods. The proposed model not only defines the latent space to be separated by the generative factors, but also shows the better quality of the generated and reconstructed images. The disentangled representation is verified with the generated images and the simple classifier trained on the output of the encoder.", "pdf": "/pdf/079b41d419bb116ebe66ee31cbc020649feb676e.pdf", "paperhash": "kim|basisvae_orthogonal_latent_space_for_deep_disentangled_representation", "original_pdf": "/attachment/b49a377060eed4e3d3a1d7585dd7f810f24ec39e.pdf", "_bibtex": "@misc{\nkim2020basisvae,\ntitle={Basis{\\{}VAE{\\}}: Orthogonal Latent Space for Deep Disentangled Representation},\nauthor={Jin-Young  Kim and Sung-Bae Cho},\nyear={2020},\nurl={https://openreview.net/forum?id=S1gEFkrtvH}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "S1gEFkrtvH", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper1837/Authors", "ICLR.cc/2020/Conference/Paper1837/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper1837/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper1837/Reviewers", "ICLR.cc/2020/Conference/Paper1837/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper1837/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper1837/Authors|ICLR.cc/2020/Conference/Paper1837/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504150180, "tmdate": 1576860558951, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper1837/Authors", "ICLR.cc/2020/Conference/Paper1837/Reviewers", "ICLR.cc/2020/Conference/Paper1837/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper1837/-/Official_Comment"}}}, {"id": "ryxC77nvsr", "original": null, "number": 14, "cdate": 1573532453583, "ddate": null, "tcdate": 1573532453583, "tmdate": 1573532453583, "tddate": null, "forum": "S1gEFkrtvH", "replyto": "HJloCRuPsH", "invitation": "ICLR.cc/2020/Conference/Paper1837/-/Official_Comment", "content": {"title": "Answers to Reviewer #2", "comment": "Theorem 1 is true if z_i are independent conditioned by x.\n\nWe found that in Figure 1, only one feature changes with z in the normal VAE. This is represented by z = c1z1 + c2z2 in a two-dimensional representation, meaning that only one feature is adjusted according to c, and z1 and z2 are disentangled, but not on a standard basis. \nWe proceed on the assumption that z_i are independent when disentangled. I apologize that this has made you very confused. We will add detailed and in-depth assumptions and content about what you pointed out.\n\nThanks again for the good point."}, "signatures": ["ICLR.cc/2020/Conference/Paper1837/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1837/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "BasisVAE: Orthogonal Latent Space for Deep Disentangled Representation", "authors": ["Jin-Young  Kim", "Sung-Bae Cho"], "authorids": ["seago0828@yonsei.ac.kr", "sbcho@yonsei.ac.kr"], "keywords": ["variational autoencoder", "latent space", "basis", "disentangled representation"], "TL;DR": "Construct orthogonal latent space for deep disentangled representation based on a basis in the linear algebra", "abstract": "The variational autoencoder, one of the generative models, defines the latent space for the data representation, and uses variational inference to infer the posterior probability. Several methods have been devised to disentangle the latent space for controlling the generative model easily. However, due to the excessive constraints, the more disentangled the latent space is, the lower quality the generative model has. A disentangled generative model would allocate a single feature of the generated data to the only single latent variable. In this paper, we propose a method to decompose the latent space into basis, and reconstruct it by linear combination of the latent bases. The proposed model called BasisVAE consists of the encoder that extracts the features of data and estimates the coefficients for linear combination of the latent bases, and the decoder that reconstructs the data with the combined latent bases. In this method, a single latent basis is subject to change in a single generative factor, and relatively invariant to the changes in other factors. It maintains the performance while relaxing the constraint for disentanglement on a basis, as we no longer need to decompose latent space on a standard basis. Experiments on the well-known benchmark datasets of MNIST, 3DFaces and CelebA demonstrate the efficacy of the proposed method, compared to other state-of-the-art methods. The proposed model not only defines the latent space to be separated by the generative factors, but also shows the better quality of the generated and reconstructed images. The disentangled representation is verified with the generated images and the simple classifier trained on the output of the encoder.", "pdf": "/pdf/079b41d419bb116ebe66ee31cbc020649feb676e.pdf", "paperhash": "kim|basisvae_orthogonal_latent_space_for_deep_disentangled_representation", "original_pdf": "/attachment/b49a377060eed4e3d3a1d7585dd7f810f24ec39e.pdf", "_bibtex": "@misc{\nkim2020basisvae,\ntitle={Basis{\\{}VAE{\\}}: Orthogonal Latent Space for Deep Disentangled Representation},\nauthor={Jin-Young  Kim and Sung-Bae Cho},\nyear={2020},\nurl={https://openreview.net/forum?id=S1gEFkrtvH}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "S1gEFkrtvH", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper1837/Authors", "ICLR.cc/2020/Conference/Paper1837/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper1837/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper1837/Reviewers", "ICLR.cc/2020/Conference/Paper1837/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper1837/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper1837/Authors|ICLR.cc/2020/Conference/Paper1837/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504150180, "tmdate": 1576860558951, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper1837/Authors", "ICLR.cc/2020/Conference/Paper1837/Reviewers", "ICLR.cc/2020/Conference/Paper1837/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper1837/-/Official_Comment"}}}, {"id": "HJloCRuPsH", "original": null, "number": 13, "cdate": 1573519059230, "ddate": null, "tcdate": 1573519059230, "tmdate": 1573519059230, "tddate": null, "forum": "S1gEFkrtvH", "replyto": "SkxON3_Pir", "invitation": "ICLR.cc/2020/Conference/Paper1837/-/Official_Comment", "content": {"title": "Please Rewrite Theorem 1", "comment": "It looks like we're not on the same page. I believe this confusion is arising from our disagreement over how to read Theorem 1. All I can say with confidence at the moment is that, in the standard VAE setup, the jump from Eq 5 to 6 is wrong.\n\nIf you wish to convince me otherwise, please restate Theorem 1 and its proof as rigorously as possible. "}, "signatures": ["ICLR.cc/2020/Conference/Paper1837/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1837/AnonReviewer2", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "BasisVAE: Orthogonal Latent Space for Deep Disentangled Representation", "authors": ["Jin-Young  Kim", "Sung-Bae Cho"], "authorids": ["seago0828@yonsei.ac.kr", "sbcho@yonsei.ac.kr"], "keywords": ["variational autoencoder", "latent space", "basis", "disentangled representation"], "TL;DR": "Construct orthogonal latent space for deep disentangled representation based on a basis in the linear algebra", "abstract": "The variational autoencoder, one of the generative models, defines the latent space for the data representation, and uses variational inference to infer the posterior probability. Several methods have been devised to disentangle the latent space for controlling the generative model easily. However, due to the excessive constraints, the more disentangled the latent space is, the lower quality the generative model has. A disentangled generative model would allocate a single feature of the generated data to the only single latent variable. In this paper, we propose a method to decompose the latent space into basis, and reconstruct it by linear combination of the latent bases. The proposed model called BasisVAE consists of the encoder that extracts the features of data and estimates the coefficients for linear combination of the latent bases, and the decoder that reconstructs the data with the combined latent bases. In this method, a single latent basis is subject to change in a single generative factor, and relatively invariant to the changes in other factors. It maintains the performance while relaxing the constraint for disentanglement on a basis, as we no longer need to decompose latent space on a standard basis. Experiments on the well-known benchmark datasets of MNIST, 3DFaces and CelebA demonstrate the efficacy of the proposed method, compared to other state-of-the-art methods. The proposed model not only defines the latent space to be separated by the generative factors, but also shows the better quality of the generated and reconstructed images. The disentangled representation is verified with the generated images and the simple classifier trained on the output of the encoder.", "pdf": "/pdf/079b41d419bb116ebe66ee31cbc020649feb676e.pdf", "paperhash": "kim|basisvae_orthogonal_latent_space_for_deep_disentangled_representation", "original_pdf": "/attachment/b49a377060eed4e3d3a1d7585dd7f810f24ec39e.pdf", "_bibtex": "@misc{\nkim2020basisvae,\ntitle={Basis{\\{}VAE{\\}}: Orthogonal Latent Space for Deep Disentangled Representation},\nauthor={Jin-Young  Kim and Sung-Bae Cho},\nyear={2020},\nurl={https://openreview.net/forum?id=S1gEFkrtvH}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "S1gEFkrtvH", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper1837/Authors", "ICLR.cc/2020/Conference/Paper1837/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper1837/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper1837/Reviewers", "ICLR.cc/2020/Conference/Paper1837/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper1837/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper1837/Authors|ICLR.cc/2020/Conference/Paper1837/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504150180, "tmdate": 1576860558951, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper1837/Authors", "ICLR.cc/2020/Conference/Paper1837/Reviewers", "ICLR.cc/2020/Conference/Paper1837/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper1837/-/Official_Comment"}}}, {"id": "SkxON3_Pir", "original": null, "number": 12, "cdate": 1573518384479, "ddate": null, "tcdate": 1573518384479, "tmdate": 1573518384479, "tddate": null, "forum": "S1gEFkrtvH", "replyto": "rJxBtFuDjH", "invitation": "ICLR.cc/2020/Conference/Paper1837/-/Official_Comment", "content": {"title": "Answers to Reviewer #2 ", "comment": "I'm sorry for using confusion expression. We mean \"Multiple levels\" that the \"multiple disentangled latent vector\".\nBasically, the proposed model is related to the disentanglement representation. By definition, in that space, a latent variable covers only one generative factor and does not affect each other [1, 2], which can be interpreted as independence. We put the latent space disentangled in Theorem 1 and each factor at that time is z_1, ..., z_n. (This is evidenced by experiments with only one latent variable changed in many disentanglement representation studies [3, 4].)\n\n[1] Y. Bengio, A. Courville, and P. Vincent. Representation learning: A review and new perspectives.\nIEEE Trans. on Pattern Analysis and Machine Intelligence, 35(8):1798\u20131828, 2013.\n[2] K. Ridgeway. A survey of inductive biases for factorial representation-learning. arXiv preprint\narXiv:1612.05299, 2016.\n[3] Higgins, I., Matthey, L., Pal, A., Burgess, C., Glorot, X., Botvinick, M., ... & Lerchner, A. (2017). beta-VAE: Learning Basic Visual Concepts with a Constrained Variational Framework. ICLR, 2(5), 6.\n[4] Chen, X., Duan, Y., Houthooft, R., Schulman, J., Sutskever, I., & Abbeel, P. (2016). Infogan: Interpretable representation learning by information maximizing generative adversarial nets. In Advances in neural information processing systems (pp. 2172-2180)."}, "signatures": ["ICLR.cc/2020/Conference/Paper1837/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1837/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "BasisVAE: Orthogonal Latent Space for Deep Disentangled Representation", "authors": ["Jin-Young  Kim", "Sung-Bae Cho"], "authorids": ["seago0828@yonsei.ac.kr", "sbcho@yonsei.ac.kr"], "keywords": ["variational autoencoder", "latent space", "basis", "disentangled representation"], "TL;DR": "Construct orthogonal latent space for deep disentangled representation based on a basis in the linear algebra", "abstract": "The variational autoencoder, one of the generative models, defines the latent space for the data representation, and uses variational inference to infer the posterior probability. Several methods have been devised to disentangle the latent space for controlling the generative model easily. However, due to the excessive constraints, the more disentangled the latent space is, the lower quality the generative model has. A disentangled generative model would allocate a single feature of the generated data to the only single latent variable. In this paper, we propose a method to decompose the latent space into basis, and reconstruct it by linear combination of the latent bases. The proposed model called BasisVAE consists of the encoder that extracts the features of data and estimates the coefficients for linear combination of the latent bases, and the decoder that reconstructs the data with the combined latent bases. In this method, a single latent basis is subject to change in a single generative factor, and relatively invariant to the changes in other factors. It maintains the performance while relaxing the constraint for disentanglement on a basis, as we no longer need to decompose latent space on a standard basis. Experiments on the well-known benchmark datasets of MNIST, 3DFaces and CelebA demonstrate the efficacy of the proposed method, compared to other state-of-the-art methods. The proposed model not only defines the latent space to be separated by the generative factors, but also shows the better quality of the generated and reconstructed images. The disentangled representation is verified with the generated images and the simple classifier trained on the output of the encoder.", "pdf": "/pdf/079b41d419bb116ebe66ee31cbc020649feb676e.pdf", "paperhash": "kim|basisvae_orthogonal_latent_space_for_deep_disentangled_representation", "original_pdf": "/attachment/b49a377060eed4e3d3a1d7585dd7f810f24ec39e.pdf", "_bibtex": "@misc{\nkim2020basisvae,\ntitle={Basis{\\{}VAE{\\}}: Orthogonal Latent Space for Deep Disentangled Representation},\nauthor={Jin-Young  Kim and Sung-Bae Cho},\nyear={2020},\nurl={https://openreview.net/forum?id=S1gEFkrtvH}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "S1gEFkrtvH", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper1837/Authors", "ICLR.cc/2020/Conference/Paper1837/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper1837/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper1837/Reviewers", "ICLR.cc/2020/Conference/Paper1837/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper1837/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper1837/Authors|ICLR.cc/2020/Conference/Paper1837/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504150180, "tmdate": 1576860558951, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper1837/Authors", "ICLR.cc/2020/Conference/Paper1837/Reviewers", "ICLR.cc/2020/Conference/Paper1837/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper1837/-/Official_Comment"}}}, {"id": "rJxBtFuDjH", "original": null, "number": 11, "cdate": 1573517692999, "ddate": null, "tcdate": 1573517692999, "tmdate": 1573517917408, "tddate": null, "forum": "S1gEFkrtvH", "replyto": "HylrrLuDsr", "invitation": "ICLR.cc/2020/Conference/Paper1837/-/Official_Comment", "content": {"title": "Response", "comment": "It is true that for hierarchical VAEs whose PGM is $z_1 \\to z_2 \\to \\cdots \\to x$, that $p(z_i \\mid x, z_j) = p(z_i \\mid z_j)$ when $i < j$.\n\nHowever, your model, from what I can tell, is not a hierarchical VAE. So I don't quite understand your claim that your \"latent variables are split into multiple levels z_1, ..., z_n\". \n\nFurthermore, this is still not the same as your claim that $p(z_i, z_j \\mid x) = p(z_i \\mid x)p(z_j \\mid x)$.\n\nAnd regarding the PixelVAE paper, the assumption that $q(z \\mid x)$ is factorized is an explicit assumption on the variational inference model, which is not the same object as the true posterior $p(z \\mid x)$ of the generative model in the VAE.\n\nCan you clarify what you meant?"}, "signatures": ["ICLR.cc/2020/Conference/Paper1837/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1837/AnonReviewer2", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "BasisVAE: Orthogonal Latent Space for Deep Disentangled Representation", "authors": ["Jin-Young  Kim", "Sung-Bae Cho"], "authorids": ["seago0828@yonsei.ac.kr", "sbcho@yonsei.ac.kr"], "keywords": ["variational autoencoder", "latent space", "basis", "disentangled representation"], "TL;DR": "Construct orthogonal latent space for deep disentangled representation based on a basis in the linear algebra", "abstract": "The variational autoencoder, one of the generative models, defines the latent space for the data representation, and uses variational inference to infer the posterior probability. Several methods have been devised to disentangle the latent space for controlling the generative model easily. However, due to the excessive constraints, the more disentangled the latent space is, the lower quality the generative model has. A disentangled generative model would allocate a single feature of the generated data to the only single latent variable. In this paper, we propose a method to decompose the latent space into basis, and reconstruct it by linear combination of the latent bases. The proposed model called BasisVAE consists of the encoder that extracts the features of data and estimates the coefficients for linear combination of the latent bases, and the decoder that reconstructs the data with the combined latent bases. In this method, a single latent basis is subject to change in a single generative factor, and relatively invariant to the changes in other factors. It maintains the performance while relaxing the constraint for disentanglement on a basis, as we no longer need to decompose latent space on a standard basis. Experiments on the well-known benchmark datasets of MNIST, 3DFaces and CelebA demonstrate the efficacy of the proposed method, compared to other state-of-the-art methods. The proposed model not only defines the latent space to be separated by the generative factors, but also shows the better quality of the generated and reconstructed images. The disentangled representation is verified with the generated images and the simple classifier trained on the output of the encoder.", "pdf": "/pdf/079b41d419bb116ebe66ee31cbc020649feb676e.pdf", "paperhash": "kim|basisvae_orthogonal_latent_space_for_deep_disentangled_representation", "original_pdf": "/attachment/b49a377060eed4e3d3a1d7585dd7f810f24ec39e.pdf", "_bibtex": "@misc{\nkim2020basisvae,\ntitle={Basis{\\{}VAE{\\}}: Orthogonal Latent Space for Deep Disentangled Representation},\nauthor={Jin-Young  Kim and Sung-Bae Cho},\nyear={2020},\nurl={https://openreview.net/forum?id=S1gEFkrtvH}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "S1gEFkrtvH", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper1837/Authors", "ICLR.cc/2020/Conference/Paper1837/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper1837/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper1837/Reviewers", "ICLR.cc/2020/Conference/Paper1837/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper1837/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper1837/Authors|ICLR.cc/2020/Conference/Paper1837/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504150180, "tmdate": 1576860558951, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper1837/Authors", "ICLR.cc/2020/Conference/Paper1837/Reviewers", "ICLR.cc/2020/Conference/Paper1837/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper1837/-/Official_Comment"}}}, {"id": "HylrrLuDsr", "original": null, "number": 10, "cdate": 1573516860577, "ddate": null, "tcdate": 1573516860577, "tmdate": 1573516860577, "tddate": null, "forum": "S1gEFkrtvH", "replyto": "SygjGNOvor", "invitation": "ICLR.cc/2020/Conference/Paper1837/-/Official_Comment", "content": {"title": "Answers to Reviewer #2", "comment": "Thank you for your quick response!\nI am pleased to be able to conduct this constructive discussion with you.\n\nOur latent variables are split into multiple levels z_1, ..., z_n. The joint posterior over all of these is a simple fully factorized Gaussian (e.g. conditioned on x, z_2 is independent of z_1), unlike normalizing flows which are used to make the posterior distribution more flexible. \n\nBesides, as in [1], if you look at the equation associated with -L (x, q, p) on page 4, you can see that the same assumption is used when moving from the first expression to the second.\n\n[1] Gulrajani, I., Kumar, K., Ahmed, F., Taiga, A. A., Visin, F., Vazquez, D., & Courville, A. (2016). Pixelvae: A latent variable model for natural images. International Conference on Learning Representation."}, "signatures": ["ICLR.cc/2020/Conference/Paper1837/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1837/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "BasisVAE: Orthogonal Latent Space for Deep Disentangled Representation", "authors": ["Jin-Young  Kim", "Sung-Bae Cho"], "authorids": ["seago0828@yonsei.ac.kr", "sbcho@yonsei.ac.kr"], "keywords": ["variational autoencoder", "latent space", "basis", "disentangled representation"], "TL;DR": "Construct orthogonal latent space for deep disentangled representation based on a basis in the linear algebra", "abstract": "The variational autoencoder, one of the generative models, defines the latent space for the data representation, and uses variational inference to infer the posterior probability. Several methods have been devised to disentangle the latent space for controlling the generative model easily. However, due to the excessive constraints, the more disentangled the latent space is, the lower quality the generative model has. A disentangled generative model would allocate a single feature of the generated data to the only single latent variable. In this paper, we propose a method to decompose the latent space into basis, and reconstruct it by linear combination of the latent bases. The proposed model called BasisVAE consists of the encoder that extracts the features of data and estimates the coefficients for linear combination of the latent bases, and the decoder that reconstructs the data with the combined latent bases. In this method, a single latent basis is subject to change in a single generative factor, and relatively invariant to the changes in other factors. It maintains the performance while relaxing the constraint for disentanglement on a basis, as we no longer need to decompose latent space on a standard basis. Experiments on the well-known benchmark datasets of MNIST, 3DFaces and CelebA demonstrate the efficacy of the proposed method, compared to other state-of-the-art methods. The proposed model not only defines the latent space to be separated by the generative factors, but also shows the better quality of the generated and reconstructed images. The disentangled representation is verified with the generated images and the simple classifier trained on the output of the encoder.", "pdf": "/pdf/079b41d419bb116ebe66ee31cbc020649feb676e.pdf", "paperhash": "kim|basisvae_orthogonal_latent_space_for_deep_disentangled_representation", "original_pdf": "/attachment/b49a377060eed4e3d3a1d7585dd7f810f24ec39e.pdf", "_bibtex": "@misc{\nkim2020basisvae,\ntitle={Basis{\\{}VAE{\\}}: Orthogonal Latent Space for Deep Disentangled Representation},\nauthor={Jin-Young  Kim and Sung-Bae Cho},\nyear={2020},\nurl={https://openreview.net/forum?id=S1gEFkrtvH}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "S1gEFkrtvH", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper1837/Authors", "ICLR.cc/2020/Conference/Paper1837/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper1837/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper1837/Reviewers", "ICLR.cc/2020/Conference/Paper1837/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper1837/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper1837/Authors|ICLR.cc/2020/Conference/Paper1837/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504150180, "tmdate": 1576860558951, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper1837/Authors", "ICLR.cc/2020/Conference/Paper1837/Reviewers", "ICLR.cc/2020/Conference/Paper1837/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper1837/-/Official_Comment"}}}, {"id": "SygjGNOvor", "original": null, "number": 9, "cdate": 1573516307499, "ddate": null, "tcdate": 1573516307499, "tmdate": 1573516307499, "tddate": null, "forum": "S1gEFkrtvH", "replyto": "H1gu7TPPir", "invitation": "ICLR.cc/2020/Conference/Paper1837/-/Official_Comment", "content": {"title": "Potential misuse of Naive Bayes assumption", "comment": "Assuming that all the latent variables are statistically independent conditional on the data is a very big assumption.\n\nIn the standard Naive Bayes setup, this assumption is fundamentally baked into the model class (by virtue of the PGM, every model within the Naive Bayes model class provably satisfies the Naive Bayes assumption: whereby the observed features are assumed to be independent when conditioned on the underlying class). \n\nIn contrast, your proof assumes that p(z_{1:k} | x) = prod_i p(z_i | x) within a VAE model class, which is not something that's actually guaranteed by the VAE model class. \n\nI am therefore quite uncomfortable with the analysis in Section 3.1. As of the moment, I am strongly inclined to believe that Theorem 1 is wrong. Please let me know what you think."}, "signatures": ["ICLR.cc/2020/Conference/Paper1837/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1837/AnonReviewer2", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "BasisVAE: Orthogonal Latent Space for Deep Disentangled Representation", "authors": ["Jin-Young  Kim", "Sung-Bae Cho"], "authorids": ["seago0828@yonsei.ac.kr", "sbcho@yonsei.ac.kr"], "keywords": ["variational autoencoder", "latent space", "basis", "disentangled representation"], "TL;DR": "Construct orthogonal latent space for deep disentangled representation based on a basis in the linear algebra", "abstract": "The variational autoencoder, one of the generative models, defines the latent space for the data representation, and uses variational inference to infer the posterior probability. Several methods have been devised to disentangle the latent space for controlling the generative model easily. However, due to the excessive constraints, the more disentangled the latent space is, the lower quality the generative model has. A disentangled generative model would allocate a single feature of the generated data to the only single latent variable. In this paper, we propose a method to decompose the latent space into basis, and reconstruct it by linear combination of the latent bases. The proposed model called BasisVAE consists of the encoder that extracts the features of data and estimates the coefficients for linear combination of the latent bases, and the decoder that reconstructs the data with the combined latent bases. In this method, a single latent basis is subject to change in a single generative factor, and relatively invariant to the changes in other factors. It maintains the performance while relaxing the constraint for disentanglement on a basis, as we no longer need to decompose latent space on a standard basis. Experiments on the well-known benchmark datasets of MNIST, 3DFaces and CelebA demonstrate the efficacy of the proposed method, compared to other state-of-the-art methods. The proposed model not only defines the latent space to be separated by the generative factors, but also shows the better quality of the generated and reconstructed images. The disentangled representation is verified with the generated images and the simple classifier trained on the output of the encoder.", "pdf": "/pdf/079b41d419bb116ebe66ee31cbc020649feb676e.pdf", "paperhash": "kim|basisvae_orthogonal_latent_space_for_deep_disentangled_representation", "original_pdf": "/attachment/b49a377060eed4e3d3a1d7585dd7f810f24ec39e.pdf", "_bibtex": "@misc{\nkim2020basisvae,\ntitle={Basis{\\{}VAE{\\}}: Orthogonal Latent Space for Deep Disentangled Representation},\nauthor={Jin-Young  Kim and Sung-Bae Cho},\nyear={2020},\nurl={https://openreview.net/forum?id=S1gEFkrtvH}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "S1gEFkrtvH", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper1837/Authors", "ICLR.cc/2020/Conference/Paper1837/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper1837/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper1837/Reviewers", "ICLR.cc/2020/Conference/Paper1837/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper1837/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper1837/Authors|ICLR.cc/2020/Conference/Paper1837/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504150180, "tmdate": 1576860558951, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper1837/Authors", "ICLR.cc/2020/Conference/Paper1837/Reviewers", "ICLR.cc/2020/Conference/Paper1837/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper1837/-/Official_Comment"}}}, {"id": "H1gu7TPPir", "original": null, "number": 8, "cdate": 1573514527972, "ddate": null, "tcdate": 1573514527972, "tmdate": 1573514570936, "tddate": null, "forum": "S1gEFkrtvH", "replyto": "r1llLeEDir", "invitation": "ICLR.cc/2020/Conference/Paper1837/-/Official_Comment", "content": {"title": "Answers to Reviewer #2 ", "comment": "Thank you for your respond!\n\nWe can check the equation in the derivation of the naive Bayes classifier [1-3].\nThe \"naive\" conditional independence assumptions in the naive Bayes classifier come into play on our derivation: assume that all latent variables in \\mathbf{z} are mutually independent, conditional on the data \\mathbf{x}. Under this assumption,\np(z_i|z_{i+1},...,z_n,x) = p(z_i|x)\n\n[1] Ceci, M., Appice, A., & Malerba, D. (2003). Mr-SBC: a multi-relational naive bayes classifier. In European conference on principles of data mining and knowledge discovery, 95-106.\n[2] Hilden, J. (1984). Statistical diagnosis based on conditional independence does not require it. Computers in biology and medicine, 14(4), 429-435.\n[3] Domingos, P., & Pazzani, M. (1997). On the optimality of the simple Bayesian classifier under zero-one loss. Machine learning, 29(2-3), 103-130."}, "signatures": ["ICLR.cc/2020/Conference/Paper1837/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1837/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "BasisVAE: Orthogonal Latent Space for Deep Disentangled Representation", "authors": ["Jin-Young  Kim", "Sung-Bae Cho"], "authorids": ["seago0828@yonsei.ac.kr", "sbcho@yonsei.ac.kr"], "keywords": ["variational autoencoder", "latent space", "basis", "disentangled representation"], "TL;DR": "Construct orthogonal latent space for deep disentangled representation based on a basis in the linear algebra", "abstract": "The variational autoencoder, one of the generative models, defines the latent space for the data representation, and uses variational inference to infer the posterior probability. Several methods have been devised to disentangle the latent space for controlling the generative model easily. However, due to the excessive constraints, the more disentangled the latent space is, the lower quality the generative model has. A disentangled generative model would allocate a single feature of the generated data to the only single latent variable. In this paper, we propose a method to decompose the latent space into basis, and reconstruct it by linear combination of the latent bases. The proposed model called BasisVAE consists of the encoder that extracts the features of data and estimates the coefficients for linear combination of the latent bases, and the decoder that reconstructs the data with the combined latent bases. In this method, a single latent basis is subject to change in a single generative factor, and relatively invariant to the changes in other factors. It maintains the performance while relaxing the constraint for disentanglement on a basis, as we no longer need to decompose latent space on a standard basis. Experiments on the well-known benchmark datasets of MNIST, 3DFaces and CelebA demonstrate the efficacy of the proposed method, compared to other state-of-the-art methods. The proposed model not only defines the latent space to be separated by the generative factors, but also shows the better quality of the generated and reconstructed images. The disentangled representation is verified with the generated images and the simple classifier trained on the output of the encoder.", "pdf": "/pdf/079b41d419bb116ebe66ee31cbc020649feb676e.pdf", "paperhash": "kim|basisvae_orthogonal_latent_space_for_deep_disentangled_representation", "original_pdf": "/attachment/b49a377060eed4e3d3a1d7585dd7f810f24ec39e.pdf", "_bibtex": "@misc{\nkim2020basisvae,\ntitle={Basis{\\{}VAE{\\}}: Orthogonal Latent Space for Deep Disentangled Representation},\nauthor={Jin-Young  Kim and Sung-Bae Cho},\nyear={2020},\nurl={https://openreview.net/forum?id=S1gEFkrtvH}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "S1gEFkrtvH", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper1837/Authors", "ICLR.cc/2020/Conference/Paper1837/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper1837/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper1837/Reviewers", "ICLR.cc/2020/Conference/Paper1837/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper1837/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper1837/Authors|ICLR.cc/2020/Conference/Paper1837/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504150180, "tmdate": 1576860558951, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper1837/Authors", "ICLR.cc/2020/Conference/Paper1837/Reviewers", "ICLR.cc/2020/Conference/Paper1837/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper1837/-/Official_Comment"}}}, {"id": "r1llLeEDir", "original": null, "number": 7, "cdate": 1573498951749, "ddate": null, "tcdate": 1573498951749, "tmdate": 1573498951749, "tddate": null, "forum": "S1gEFkrtvH", "replyto": "ryxnaET8or", "invitation": "ICLR.cc/2020/Conference/Paper1837/-/Official_Comment", "content": {"title": "Response to Issue 1", "comment": "Thanks for the response. I'd like to address Issue 1 first. \n\nI checked your Appendix C and noticed the following claim:\n\n$p(z_2 | x, z_1)  = p(z_2 | x)$\n\nI don't think this claim is correct in general (see \"explaining away\" effect in v-structures). Can the authors clarify this step?"}, "signatures": ["ICLR.cc/2020/Conference/Paper1837/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1837/AnonReviewer2", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "BasisVAE: Orthogonal Latent Space for Deep Disentangled Representation", "authors": ["Jin-Young  Kim", "Sung-Bae Cho"], "authorids": ["seago0828@yonsei.ac.kr", "sbcho@yonsei.ac.kr"], "keywords": ["variational autoencoder", "latent space", "basis", "disentangled representation"], "TL;DR": "Construct orthogonal latent space for deep disentangled representation based on a basis in the linear algebra", "abstract": "The variational autoencoder, one of the generative models, defines the latent space for the data representation, and uses variational inference to infer the posterior probability. Several methods have been devised to disentangle the latent space for controlling the generative model easily. However, due to the excessive constraints, the more disentangled the latent space is, the lower quality the generative model has. A disentangled generative model would allocate a single feature of the generated data to the only single latent variable. In this paper, we propose a method to decompose the latent space into basis, and reconstruct it by linear combination of the latent bases. The proposed model called BasisVAE consists of the encoder that extracts the features of data and estimates the coefficients for linear combination of the latent bases, and the decoder that reconstructs the data with the combined latent bases. In this method, a single latent basis is subject to change in a single generative factor, and relatively invariant to the changes in other factors. It maintains the performance while relaxing the constraint for disentanglement on a basis, as we no longer need to decompose latent space on a standard basis. Experiments on the well-known benchmark datasets of MNIST, 3DFaces and CelebA demonstrate the efficacy of the proposed method, compared to other state-of-the-art methods. The proposed model not only defines the latent space to be separated by the generative factors, but also shows the better quality of the generated and reconstructed images. The disentangled representation is verified with the generated images and the simple classifier trained on the output of the encoder.", "pdf": "/pdf/079b41d419bb116ebe66ee31cbc020649feb676e.pdf", "paperhash": "kim|basisvae_orthogonal_latent_space_for_deep_disentangled_representation", "original_pdf": "/attachment/b49a377060eed4e3d3a1d7585dd7f810f24ec39e.pdf", "_bibtex": "@misc{\nkim2020basisvae,\ntitle={Basis{\\{}VAE{\\}}: Orthogonal Latent Space for Deep Disentangled Representation},\nauthor={Jin-Young  Kim and Sung-Bae Cho},\nyear={2020},\nurl={https://openreview.net/forum?id=S1gEFkrtvH}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "S1gEFkrtvH", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper1837/Authors", "ICLR.cc/2020/Conference/Paper1837/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper1837/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper1837/Reviewers", "ICLR.cc/2020/Conference/Paper1837/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper1837/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper1837/Authors|ICLR.cc/2020/Conference/Paper1837/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504150180, "tmdate": 1576860558951, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper1837/Authors", "ICLR.cc/2020/Conference/Paper1837/Reviewers", "ICLR.cc/2020/Conference/Paper1837/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper1837/-/Official_Comment"}}}, {"id": "HyghbSTIsr", "original": null, "number": 6, "cdate": 1573471491874, "ddate": null, "tcdate": 1573471491874, "tmdate": 1573471491874, "tddate": null, "forum": "S1gEFkrtvH", "replyto": "H1gCgZOrKB", "invitation": "ICLR.cc/2020/Conference/Paper1837/-/Official_Comment", "content": {"title": "Answers to Reviewer #3", "comment": "Thank you for your comments. They are very helpful for us to conduct more finished works. According to the reviewer\u2019s comments, we have addressed them as follows.\n\t1. It is enough to show p(x\u2502z_1,z_2 )=(p(x\u2502z_1 )p(x\u2502z_2 ))/(p(x)) for derivation from (5) to (6). We have added it in Appendix C.\n\t2. We derive from Equation 8 that a latent variable z can be decomposed into several independent variables z_i, generating the same data x from them with the encoder, and constructing an ELBO. In the BasisVAE, z_i corresponds to the basis element b_i, and it is adjusted by the coefficient c_i output of the encoder.\n\t3. A binary function is a function that takes two arguments and becomes cross-entropy as in VAE or weighted l1 error Laplacian Pyramid as in Bojanowski et al.\n\t4. Sorry for the typos. N(f(x),\\Sigma_f(x)) should be replaced with N(M_B*f(x),\\Sigma_f(x)). We have corrected it.\n\t5. Fig. 6 shows the result when only one c is 1 and the others are 0. It is shown that the basis elements have one distinct characteristic and only one characteristic changes in Fig. 8 when changing the strength of the basis element (i.e., c). More examples are shown in Figure 11. These results are seen in MNIST and 3DFace datasets as well as CelebA datasets in Figures 5 and 7. In addition, we also demonstrate the performance by showing the quantitative evaluation of disentanglement in Table 3.\n"}, "signatures": ["ICLR.cc/2020/Conference/Paper1837/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1837/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "BasisVAE: Orthogonal Latent Space for Deep Disentangled Representation", "authors": ["Jin-Young  Kim", "Sung-Bae Cho"], "authorids": ["seago0828@yonsei.ac.kr", "sbcho@yonsei.ac.kr"], "keywords": ["variational autoencoder", "latent space", "basis", "disentangled representation"], "TL;DR": "Construct orthogonal latent space for deep disentangled representation based on a basis in the linear algebra", "abstract": "The variational autoencoder, one of the generative models, defines the latent space for the data representation, and uses variational inference to infer the posterior probability. Several methods have been devised to disentangle the latent space for controlling the generative model easily. However, due to the excessive constraints, the more disentangled the latent space is, the lower quality the generative model has. A disentangled generative model would allocate a single feature of the generated data to the only single latent variable. In this paper, we propose a method to decompose the latent space into basis, and reconstruct it by linear combination of the latent bases. The proposed model called BasisVAE consists of the encoder that extracts the features of data and estimates the coefficients for linear combination of the latent bases, and the decoder that reconstructs the data with the combined latent bases. In this method, a single latent basis is subject to change in a single generative factor, and relatively invariant to the changes in other factors. It maintains the performance while relaxing the constraint for disentanglement on a basis, as we no longer need to decompose latent space on a standard basis. Experiments on the well-known benchmark datasets of MNIST, 3DFaces and CelebA demonstrate the efficacy of the proposed method, compared to other state-of-the-art methods. The proposed model not only defines the latent space to be separated by the generative factors, but also shows the better quality of the generated and reconstructed images. The disentangled representation is verified with the generated images and the simple classifier trained on the output of the encoder.", "pdf": "/pdf/079b41d419bb116ebe66ee31cbc020649feb676e.pdf", "paperhash": "kim|basisvae_orthogonal_latent_space_for_deep_disentangled_representation", "original_pdf": "/attachment/b49a377060eed4e3d3a1d7585dd7f810f24ec39e.pdf", "_bibtex": "@misc{\nkim2020basisvae,\ntitle={Basis{\\{}VAE{\\}}: Orthogonal Latent Space for Deep Disentangled Representation},\nauthor={Jin-Young  Kim and Sung-Bae Cho},\nyear={2020},\nurl={https://openreview.net/forum?id=S1gEFkrtvH}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "S1gEFkrtvH", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper1837/Authors", "ICLR.cc/2020/Conference/Paper1837/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper1837/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper1837/Reviewers", "ICLR.cc/2020/Conference/Paper1837/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper1837/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper1837/Authors|ICLR.cc/2020/Conference/Paper1837/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504150180, "tmdate": 1576860558951, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper1837/Authors", "ICLR.cc/2020/Conference/Paper1837/Reviewers", "ICLR.cc/2020/Conference/Paper1837/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper1837/-/Official_Comment"}}}, {"id": "HJgjySaUjH", "original": null, "number": 5, "cdate": 1573471458877, "ddate": null, "tcdate": 1573471458877, "tmdate": 1573471458877, "tddate": null, "forum": "S1gEFkrtvH", "replyto": "B1xdl-vCFB", "invitation": "ICLR.cc/2020/Conference/Paper1837/-/Official_Comment", "content": {"title": "Answers to Reviewer #1", "comment": "Thank you for your comments. They are very helpful for us to conduct more finished works. According to the reviewer\u2019s comments, we have addressed them as follows.\n1.\tWe conducted the experiments with supervised learning, but we have obtained similar results when repeating all the experiments with unsupervised learning. In response to the reviewer's comment, we have also added a comparison with the VQ-VAE model.\nFigure 6 can be verified according to the relationship between the distribution of coefficient c and the characteristics of the input image.\n2.\tWe set n_x to 40 according to our previous work. For larger n_x values, there was no significant difference, but in small cases, more than two generative factors appear on one basis element.\nAs shown in Figure 2, f(x)=(c,\\sigma), i.e., encoder outputs the coefficient and \\sigma simultaneously as in VAE. Besides, the basis matrix B can be trained with equation (11) as in VQ-VAE.\nAs mentioned in Section 4.2, The layer structure of the model is almost similar, and sampling z is performed using encoder f(x) and \\sigma with no basis compared to the proposed model. In betaVAE, beta is set to 100 times the coefficient of the reconstruction error.\n3.\tThank you for the good comment. We already quantitatively assessed the reconstruction performance and listed it in Table 1 and confirmed that it showed the best performance. In fact, our model puts forward the theory of decomposing the latent space and built the basis to perform it, and makes the main contribution to the advantages (especially on disentanglement) that can be obtained by constructing the latent variable from the linear combination of the bases.\n4.\t Thank you for the good comment. We describe in appendix D the results of investigating differences in c_i distributions for \"blonde women\", \"black-haired women\" and \"black-haired men\". We will continue to add the comparisons of distribution for the various samples. \n5.\tBy removing L_B, the basis elements are not orthonormal to each other, so the Cartesian coordinate system is not set by default with that kind of basis. Thus, there will be more relationships between the basis elements, and the disentanglement will disappear.\n6.\tSorry for the typos. N(f(x),\\Sigma_f(x)) should be replaced with N(M_B*f(x),\\Sigma_f(x)). We have corrected it.\n7.\tTo avoid the confusion, we have corrected it. Thank you for your comments.\n"}, "signatures": ["ICLR.cc/2020/Conference/Paper1837/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1837/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "BasisVAE: Orthogonal Latent Space for Deep Disentangled Representation", "authors": ["Jin-Young  Kim", "Sung-Bae Cho"], "authorids": ["seago0828@yonsei.ac.kr", "sbcho@yonsei.ac.kr"], "keywords": ["variational autoencoder", "latent space", "basis", "disentangled representation"], "TL;DR": "Construct orthogonal latent space for deep disentangled representation based on a basis in the linear algebra", "abstract": "The variational autoencoder, one of the generative models, defines the latent space for the data representation, and uses variational inference to infer the posterior probability. Several methods have been devised to disentangle the latent space for controlling the generative model easily. However, due to the excessive constraints, the more disentangled the latent space is, the lower quality the generative model has. A disentangled generative model would allocate a single feature of the generated data to the only single latent variable. In this paper, we propose a method to decompose the latent space into basis, and reconstruct it by linear combination of the latent bases. The proposed model called BasisVAE consists of the encoder that extracts the features of data and estimates the coefficients for linear combination of the latent bases, and the decoder that reconstructs the data with the combined latent bases. In this method, a single latent basis is subject to change in a single generative factor, and relatively invariant to the changes in other factors. It maintains the performance while relaxing the constraint for disentanglement on a basis, as we no longer need to decompose latent space on a standard basis. Experiments on the well-known benchmark datasets of MNIST, 3DFaces and CelebA demonstrate the efficacy of the proposed method, compared to other state-of-the-art methods. The proposed model not only defines the latent space to be separated by the generative factors, but also shows the better quality of the generated and reconstructed images. The disentangled representation is verified with the generated images and the simple classifier trained on the output of the encoder.", "pdf": "/pdf/079b41d419bb116ebe66ee31cbc020649feb676e.pdf", "paperhash": "kim|basisvae_orthogonal_latent_space_for_deep_disentangled_representation", "original_pdf": "/attachment/b49a377060eed4e3d3a1d7585dd7f810f24ec39e.pdf", "_bibtex": "@misc{\nkim2020basisvae,\ntitle={Basis{\\{}VAE{\\}}: Orthogonal Latent Space for Deep Disentangled Representation},\nauthor={Jin-Young  Kim and Sung-Bae Cho},\nyear={2020},\nurl={https://openreview.net/forum?id=S1gEFkrtvH}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "S1gEFkrtvH", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper1837/Authors", "ICLR.cc/2020/Conference/Paper1837/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper1837/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper1837/Reviewers", "ICLR.cc/2020/Conference/Paper1837/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper1837/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper1837/Authors|ICLR.cc/2020/Conference/Paper1837/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504150180, "tmdate": 1576860558951, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper1837/Authors", "ICLR.cc/2020/Conference/Paper1837/Reviewers", "ICLR.cc/2020/Conference/Paper1837/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper1837/-/Official_Comment"}}}, {"id": "ryxnaET8or", "original": null, "number": 4, "cdate": 1573471427900, "ddate": null, "tcdate": 1573471427900, "tmdate": 1573471427900, "tddate": null, "forum": "S1gEFkrtvH", "replyto": "HkgnZixS9S", "invitation": "ICLR.cc/2020/Conference/Paper1837/-/Official_Comment", "content": {"title": "Answers to Reviewer #2", "comment": "Thank you for your comments. They are very helpful for us to conduct more finished works. According to the reviewer\u2019s comments, we have addressed them as follows.\nIssue 1\n\t1. It is enough to show p(x\u2502z_1,z_2 )=(p(x\u2502z_1 )p(x\u2502z_2 ))/(p(x)) for derivation from (5) to (6). We have added it in Appendix C.\n\t2. We derive from Equation 8 that a latent variable z can be decomposed into several independent variables z_i, generating the same data x from them with the encoder, and constructing an ELBO. In the BasisVAE, z_i corresponds to the basis element b_i, and it is adjusted by the coefficient c_i output of the encoder.\n\nIssue 2\n\t1. The output of the encoder is coefficient c_i, which is multiplied by the basis matrix and added to \\epsilon * \\sigma to produce a latent variable z. We have shown that latent space can be decomposed in Thm 1, which shows that latent variable z can be represented as a linear combination of several basis elements. It can be done with less constrains than conventional disentanglement representation, resulting in more effective method.\n\t2. M satisfying M.T * M = I may have many cases besides identity matrix I. In the case of the conventional disentanglement representation method, M = I is made so that a single latent unit is associated with a single generative factor. However, in the proposed method, a single basis element is associated with a single generative factor, which is free from the second constraint mentioned in Section 1.\n\nIssue 3\n\t1. We have slightly simplified the disentanglement-specific metric used in betaVAE as the performance of the simplest logistic regression (LR) using the coefficient c (or latent variable z) extracted through the encoder. As mentioned by the reviewer, rotation is applied. Nevertheless, the results show that the proposed model has the simplest design of latent space, which makes it easier to distinguish generative factors.\n\t2. Sorry for the confusion. In the first original, average was in %???. We have made the appropriate modifications to avoid the confusion.\n\nAccording to the comments, we have made up the lack of explanation in main contents and added more stuffs such as the results of VQ-VAE for comparison and the distribution of coefficient c_i at the appendix.\n"}, "signatures": ["ICLR.cc/2020/Conference/Paper1837/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1837/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "BasisVAE: Orthogonal Latent Space for Deep Disentangled Representation", "authors": ["Jin-Young  Kim", "Sung-Bae Cho"], "authorids": ["seago0828@yonsei.ac.kr", "sbcho@yonsei.ac.kr"], "keywords": ["variational autoencoder", "latent space", "basis", "disentangled representation"], "TL;DR": "Construct orthogonal latent space for deep disentangled representation based on a basis in the linear algebra", "abstract": "The variational autoencoder, one of the generative models, defines the latent space for the data representation, and uses variational inference to infer the posterior probability. Several methods have been devised to disentangle the latent space for controlling the generative model easily. However, due to the excessive constraints, the more disentangled the latent space is, the lower quality the generative model has. A disentangled generative model would allocate a single feature of the generated data to the only single latent variable. In this paper, we propose a method to decompose the latent space into basis, and reconstruct it by linear combination of the latent bases. The proposed model called BasisVAE consists of the encoder that extracts the features of data and estimates the coefficients for linear combination of the latent bases, and the decoder that reconstructs the data with the combined latent bases. In this method, a single latent basis is subject to change in a single generative factor, and relatively invariant to the changes in other factors. It maintains the performance while relaxing the constraint for disentanglement on a basis, as we no longer need to decompose latent space on a standard basis. Experiments on the well-known benchmark datasets of MNIST, 3DFaces and CelebA demonstrate the efficacy of the proposed method, compared to other state-of-the-art methods. The proposed model not only defines the latent space to be separated by the generative factors, but also shows the better quality of the generated and reconstructed images. The disentangled representation is verified with the generated images and the simple classifier trained on the output of the encoder.", "pdf": "/pdf/079b41d419bb116ebe66ee31cbc020649feb676e.pdf", "paperhash": "kim|basisvae_orthogonal_latent_space_for_deep_disentangled_representation", "original_pdf": "/attachment/b49a377060eed4e3d3a1d7585dd7f810f24ec39e.pdf", "_bibtex": "@misc{\nkim2020basisvae,\ntitle={Basis{\\{}VAE{\\}}: Orthogonal Latent Space for Deep Disentangled Representation},\nauthor={Jin-Young  Kim and Sung-Bae Cho},\nyear={2020},\nurl={https://openreview.net/forum?id=S1gEFkrtvH}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "S1gEFkrtvH", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper1837/Authors", "ICLR.cc/2020/Conference/Paper1837/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper1837/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper1837/Reviewers", "ICLR.cc/2020/Conference/Paper1837/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper1837/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper1837/Authors|ICLR.cc/2020/Conference/Paper1837/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504150180, "tmdate": 1576860558951, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper1837/Authors", "ICLR.cc/2020/Conference/Paper1837/Reviewers", "ICLR.cc/2020/Conference/Paper1837/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper1837/-/Official_Comment"}}}, {"id": "H1gCgZOrKB", "original": null, "number": 1, "cdate": 1571287285707, "ddate": null, "tcdate": 1571287285707, "tmdate": 1572972417252, "tddate": null, "forum": "S1gEFkrtvH", "replyto": "S1gEFkrtvH", "invitation": "ICLR.cc/2020/Conference/Paper1837/-/Official_Review", "content": {"rating": "1: Reject", "experience_assessment": "I have read many papers in this area.", "review_assessment:_checking_correctness_of_derivations_and_theory": "I carefully checked the derivations and theory.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #3", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review": "This paper proposes BasisVAE for acquiring a disentangled representation of VAE. \nThough the topic is much of interest for this conference, I cannot support its acceptance because the paper leaves many aspects unexplained in the model design. \n\nIn particular, the following points need justified and clarified.\n1) Theorem 1 is difficult to follow. \nThe claim of the theorem is unclear. \nI suppose it says ELBO can be written as a sum with respect to z_i given p(z)=\\prod_i p(z_i), but the statement is not clear enough from the text. \nProof of Lemma 1 is logically incomplete. Discuss the cases n>2.\nDerivation of equation (6) from (5) seems erroneous: p(x|z_1, ..., z_n) = \\prod_{i=1}^n p(x|z_i) / p^{n-1}(x) does not hold in general even if z_i's are independent p(z_1, ..., z_n)=\\prod_{i=1}^n p(z_i).\n\n2) Connection between the objective function and Theorem 1 is unclear. \nBasisVAE uses a linear combination of Eqs. (9,10,11) as its objective function. \nHow Theorem 1 motivates this formulation?\n\n3) Reconstruction error (9). \nThe text says \\ell of Eq. (9) is the binary function and configured as in (Bojanowski et al. 2017). \nHowever, Bojanowski et al. used a weighted l1 error Laplacian Pyramid representation. \nFurthermore, the original VAE formulation uses a conditional log-likelihood log p(x|z) for the reconstruction term. \nHow is binary function \\ell related the likelihood?\n\n4) KL regularization term (10).\nFor computing this term, the output of encoder c=f(x) should be converted into z. \nNotation of N(f(x), \\Sigma) is confusing. \n\n5) Figure 6 shows diversity in many factors. \nFigure 6 is not as impressive for disentangled images since many factors change by varying a single basis. \nIs this an expected result?"}, "signatures": ["ICLR.cc/2020/Conference/Paper1837/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1837/AnonReviewer3"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "BasisVAE: Orthogonal Latent Space for Deep Disentangled Representation", "authors": ["Jin-Young  Kim", "Sung-Bae Cho"], "authorids": ["seago0828@yonsei.ac.kr", "sbcho@yonsei.ac.kr"], "keywords": ["variational autoencoder", "latent space", "basis", "disentangled representation"], "TL;DR": "Construct orthogonal latent space for deep disentangled representation based on a basis in the linear algebra", "abstract": "The variational autoencoder, one of the generative models, defines the latent space for the data representation, and uses variational inference to infer the posterior probability. Several methods have been devised to disentangle the latent space for controlling the generative model easily. However, due to the excessive constraints, the more disentangled the latent space is, the lower quality the generative model has. A disentangled generative model would allocate a single feature of the generated data to the only single latent variable. In this paper, we propose a method to decompose the latent space into basis, and reconstruct it by linear combination of the latent bases. The proposed model called BasisVAE consists of the encoder that extracts the features of data and estimates the coefficients for linear combination of the latent bases, and the decoder that reconstructs the data with the combined latent bases. In this method, a single latent basis is subject to change in a single generative factor, and relatively invariant to the changes in other factors. It maintains the performance while relaxing the constraint for disentanglement on a basis, as we no longer need to decompose latent space on a standard basis. Experiments on the well-known benchmark datasets of MNIST, 3DFaces and CelebA demonstrate the efficacy of the proposed method, compared to other state-of-the-art methods. The proposed model not only defines the latent space to be separated by the generative factors, but also shows the better quality of the generated and reconstructed images. The disentangled representation is verified with the generated images and the simple classifier trained on the output of the encoder.", "pdf": "/pdf/079b41d419bb116ebe66ee31cbc020649feb676e.pdf", "paperhash": "kim|basisvae_orthogonal_latent_space_for_deep_disentangled_representation", "original_pdf": "/attachment/b49a377060eed4e3d3a1d7585dd7f810f24ec39e.pdf", "_bibtex": "@misc{\nkim2020basisvae,\ntitle={Basis{\\{}VAE{\\}}: Orthogonal Latent Space for Deep Disentangled Representation},\nauthor={Jin-Young  Kim and Sung-Bae Cho},\nyear={2020},\nurl={https://openreview.net/forum?id=S1gEFkrtvH}\n}"}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "S1gEFkrtvH", "replyto": "S1gEFkrtvH", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper1837/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper1837/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1575369535297, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper1837/Reviewers"], "noninvitees": [], "tcdate": 1570237731588, "tmdate": 1575369535310, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper1837/-/Official_Review"}}}, {"id": "HkgnZixS9S", "original": null, "number": 3, "cdate": 1572305668188, "ddate": null, "tcdate": 1572305668188, "tmdate": 1572972417174, "tddate": null, "forum": "S1gEFkrtvH", "replyto": "S1gEFkrtvH", "invitation": "ICLR.cc/2020/Conference/Paper1837/-/Official_Review", "content": {"experience_assessment": "I have published one or two papers in this area.", "rating": "1: Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #2", "review_assessment:_checking_correctness_of_derivations_and_theory": "I carefully checked the derivations and theory.", "review": "Summary:\nThis paper claims to achieve disentanglement by encouraging an orthogonal latent space.\n\nDecision: Reject. I found the paper difficult to read and the theoretical claims problematic. \n\nIssue 1: The Theorem\nCan the authors explain how they got from Eq 5 to Eq 6? It seems that the authors claim that:\np(x | z1 z2 \u2026 zn) = p(x | z1) \u2026 p(x | zn) / p(x)**(n - 1)\nI have difficulty understanding why this is true. It would suggest that\np(x | a b) = p(x | a) p(x | b) / p(x). \nSuppose a and b are fair coin flips and x = a XOR b. Then\np(x=1 | a=1 b=1) = 0\np(x=1 | a=1) = 0.5\np(x=1 | b=1) = 0.5\np(x=1) = 0.5\nCan the authors please address this issue?\n\nEven if Equation 8 is somehow correct, can the authors explain why BasisVAE provably maximizes the RHS expression in Eq 8? In particular the object p(x | z_i) is the integral of p(x, z_not_i | z_i) d z_not_i, which is quite non-trivial. \n\nIssue 2: The Model\nThe notation is a bit confusing, but it looks like the proposed model is basically a standard VAE, but where the last layer of the mean-encoder is an orthogonal matrix. I do not think the authors provided a sufficient justification for how this model relates back to Theorem 1. \n\nFurthermore, it is unclear to me why an orthogonal last-layer is of any significance theoretically. Suppose f is a highly expressive encoder. Let f(x) = M.T g(x) where g is itself a highly expressive neural network. Then M f(x) = g(x), which reduces to training a beta-VAE (if using Eq 12). From a theoretical standpoint, it is difficult to assess what last-layer orthogonality is really contributing.\n\nIssue 3: The Experiments\nExperimentally, the main question is whether the authors convincingly demonstrate that BasisVAE achieves better disentanglement (independent of whether BasisVAE is theoretically well-understood). \n\nThe only experiment that explicitly compares BasisVAE with previous models is Table 3. What strikes me as curious about the table is the standard deviation results. They are surprisingly small. Did the authors do multiple runs for each model? Furthermore, the classification result is not equivalent to measuring disentanglement. There exists examples of perfectly entangled representation spaces can still achieve perfect performance on the classification task (any rotation applied to the space is enough to break disentanglement if disentanglement is defined as each dimension corresponding to a single factor of variation)."}, "signatures": ["ICLR.cc/2020/Conference/Paper1837/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1837/AnonReviewer2"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "BasisVAE: Orthogonal Latent Space for Deep Disentangled Representation", "authors": ["Jin-Young  Kim", "Sung-Bae Cho"], "authorids": ["seago0828@yonsei.ac.kr", "sbcho@yonsei.ac.kr"], "keywords": ["variational autoencoder", "latent space", "basis", "disentangled representation"], "TL;DR": "Construct orthogonal latent space for deep disentangled representation based on a basis in the linear algebra", "abstract": "The variational autoencoder, one of the generative models, defines the latent space for the data representation, and uses variational inference to infer the posterior probability. Several methods have been devised to disentangle the latent space for controlling the generative model easily. However, due to the excessive constraints, the more disentangled the latent space is, the lower quality the generative model has. A disentangled generative model would allocate a single feature of the generated data to the only single latent variable. In this paper, we propose a method to decompose the latent space into basis, and reconstruct it by linear combination of the latent bases. The proposed model called BasisVAE consists of the encoder that extracts the features of data and estimates the coefficients for linear combination of the latent bases, and the decoder that reconstructs the data with the combined latent bases. In this method, a single latent basis is subject to change in a single generative factor, and relatively invariant to the changes in other factors. It maintains the performance while relaxing the constraint for disentanglement on a basis, as we no longer need to decompose latent space on a standard basis. Experiments on the well-known benchmark datasets of MNIST, 3DFaces and CelebA demonstrate the efficacy of the proposed method, compared to other state-of-the-art methods. The proposed model not only defines the latent space to be separated by the generative factors, but also shows the better quality of the generated and reconstructed images. The disentangled representation is verified with the generated images and the simple classifier trained on the output of the encoder.", "pdf": "/pdf/079b41d419bb116ebe66ee31cbc020649feb676e.pdf", "paperhash": "kim|basisvae_orthogonal_latent_space_for_deep_disentangled_representation", "original_pdf": "/attachment/b49a377060eed4e3d3a1d7585dd7f810f24ec39e.pdf", "_bibtex": "@misc{\nkim2020basisvae,\ntitle={Basis{\\{}VAE{\\}}: Orthogonal Latent Space for Deep Disentangled Representation},\nauthor={Jin-Young  Kim and Sung-Bae Cho},\nyear={2020},\nurl={https://openreview.net/forum?id=S1gEFkrtvH}\n}"}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "S1gEFkrtvH", "replyto": "S1gEFkrtvH", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper1837/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper1837/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1575369535297, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper1837/Reviewers"], "noninvitees": [], "tcdate": 1570237731588, "tmdate": 1575369535310, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper1837/-/Official_Review"}}}, {"id": "rJxFoqfsPS", "original": null, "number": 1, "cdate": 1569561248839, "ddate": null, "tcdate": 1569561248839, "tmdate": 1569561268959, "tddate": null, "forum": "S1gEFkrtvH", "replyto": "S1gEFkrtvH", "invitation": "ICLR.cc/2020/Conference/Paper1837/-/Official_Comment", "content": {"comment": "Apologies to the readers - we identified a formatting error in the first paragraph of Section 3.1. Theorem 1 and Lemma 1 have been not written separately, but together in the main text.", "title": "Formatting error causing inconvenience to read"}, "signatures": ["ICLR.cc/2020/Conference/Paper1837/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1837/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "BasisVAE: Orthogonal Latent Space for Deep Disentangled Representation", "authors": ["Jin-Young  Kim", "Sung-Bae Cho"], "authorids": ["seago0828@yonsei.ac.kr", "sbcho@yonsei.ac.kr"], "keywords": ["variational autoencoder", "latent space", "basis", "disentangled representation"], "TL;DR": "Construct orthogonal latent space for deep disentangled representation based on a basis in the linear algebra", "abstract": "The variational autoencoder, one of the generative models, defines the latent space for the data representation, and uses variational inference to infer the posterior probability. Several methods have been devised to disentangle the latent space for controlling the generative model easily. However, due to the excessive constraints, the more disentangled the latent space is, the lower quality the generative model has. A disentangled generative model would allocate a single feature of the generated data to the only single latent variable. In this paper, we propose a method to decompose the latent space into basis, and reconstruct it by linear combination of the latent bases. The proposed model called BasisVAE consists of the encoder that extracts the features of data and estimates the coefficients for linear combination of the latent bases, and the decoder that reconstructs the data with the combined latent bases. In this method, a single latent basis is subject to change in a single generative factor, and relatively invariant to the changes in other factors. It maintains the performance while relaxing the constraint for disentanglement on a basis, as we no longer need to decompose latent space on a standard basis. Experiments on the well-known benchmark datasets of MNIST, 3DFaces and CelebA demonstrate the efficacy of the proposed method, compared to other state-of-the-art methods. The proposed model not only defines the latent space to be separated by the generative factors, but also shows the better quality of the generated and reconstructed images. The disentangled representation is verified with the generated images and the simple classifier trained on the output of the encoder.", "pdf": "/pdf/079b41d419bb116ebe66ee31cbc020649feb676e.pdf", "paperhash": "kim|basisvae_orthogonal_latent_space_for_deep_disentangled_representation", "original_pdf": "/attachment/b49a377060eed4e3d3a1d7585dd7f810f24ec39e.pdf", "_bibtex": "@misc{\nkim2020basisvae,\ntitle={Basis{\\{}VAE{\\}}: Orthogonal Latent Space for Deep Disentangled Representation},\nauthor={Jin-Young  Kim and Sung-Bae Cho},\nyear={2020},\nurl={https://openreview.net/forum?id=S1gEFkrtvH}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "S1gEFkrtvH", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper1837/Authors", "ICLR.cc/2020/Conference/Paper1837/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper1837/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper1837/Reviewers", "ICLR.cc/2020/Conference/Paper1837/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper1837/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper1837/Authors|ICLR.cc/2020/Conference/Paper1837/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504150180, "tmdate": 1576860558951, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper1837/Authors", "ICLR.cc/2020/Conference/Paper1837/Reviewers", "ICLR.cc/2020/Conference/Paper1837/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper1837/-/Official_Comment"}}}], "count": 26}