{"notes": [{"ddate": null, "legacy_migration": true, "tmdate": 1392757800000, "tcdate": 1392757800000, "number": 7, "id": "GG90xWdBQuxkg", "invitation": "ICLR.cc/2014/-/submission/conference/review", "forum": "kziQtP-nGqzDb", "replyto": "kziQtP-nGqzDb", "signatures": ["Arjun Jain"], "readers": ["everyone"], "writers": ["anonymous"], "content": {"title": "", "review": "Thank you for your detailed review of our paper.  To address your concern regarding the impact of our spatial model on the final results, we would like to emphasise that the spatial model was designed as a post-processing step to reduce false positive detections for difficult joint locations.  While the impact was not great on the shoulder and elbow joints, the spatial model does help improve wrist location accuracy, which is by far the most difficult task owing to large amounts of occlusion, deformation and variation in pose.  For future work we would like to incorporate these spatial priors into the neural network and increase their complexity (by incorporating low level image features into the spatial prior), which we believe should improve the efficacy of the pose prior. \r\n\r\n\u201cI find it surprising, that this makes much of a difference, because I would have thought that the peak response of the sliding window conv net be pretty much at the same location, with or without a lot of spatial pooling\u201d\r\n\r\nIt is true that the peak response (or location of the heat map\u2019s maximal lobe) should be approximately the same when using larger amounts of spatial pooling.  However, we have found experimentally that large pooling factors produce an overly smooth response, which makes accurate detection of small image features difficult for the second stage of our detection pipeline (e.g. our spatial prior).  For future work we would like to investigate the use of other pooling strategies, such as overlapped pooling and other recent techniques.\r\n\r\n\u201cUsing sliding windows with a conv net sounds like it will be slow. Could you say something about the efficiency as compared to the other models?\u201d\r\n\r\nWe have included a discussion about relative efficiency of our model in our latest paper revision.  It should be noted that at test time we can speed up computation by running the first 3 convolutional layers over the entire image to reduce redundant computation of image features. Then only the fully connected stage need be run as a sliding window over the input image. This approach is actually very similar to the recent work by Sermanet et al., OverFeat: Integrated Recognition, Localization and Detection using Convolutional Networks (http://arxiv.org/abs/1312.6229), where they use 1x1 convolution kernels to describe the fully connected stages so that they can share the fully connected network weigths over the full detection output.\r\n\r\nWe also added timing measurements to the latest version of the paper as:\r\nTheano training takes: 1.9ms per patch (for FPROP and BPROP) = 41min total\r\nTheano testing (parallelized on cpu cluster) takes: 0.49sec per image (0.94x scale) = 2.8min total\r\nNMS and spatial model takes very little time (not really worth profiling)"}, "nonreaders": [], "details": {"replyCount": 0, "overwriting": [], "revisions": false, "forumContent": {"title": "Learning Human Pose Estimation Features with Convolutional Networks", "decision": "submitted, no decision", "abstract": "This paper introduces a new architecture for human pose estimation using a multi- layer convolutional network architecture and a modified learning technique that learns low-level features and higher-level weak spatial models. Unconstrained human pose estimation is one of the hardest problems in computer vision, and our new architecture and learning schema shows significant improvement over the current state-of-the-art results. The main contribution of this paper is showing, for the first time, that a specific variation of deep learning is able to outperform all existing traditional architectures on this task. The paper also discusses several lessons learned while researching alternatives, most notably, that it is possible to learn strong low-level feature detectors on features that might even just cover a few pixels in the image. Higher-level spatial models improve somewhat the overall result, but to a much lesser extent then expected. Many researchers previously argued that the kinematic structure and top-down information is crucial for this domain, but with our purely bottom up, and weak spatial model, we could improve other more complicated architectures that currently produce the best results. This mirrors what many other researchers, like those in the speech recognition, object recognition, and other domains have experienced.", "pdf": "https://arxiv.org/abs/1312.7302", "paperhash": "jain|learning_human_pose_estimation_features_with_convolutional_networks", "keywords": [], "conflicts": [], "authors": ["Ajrun Jain", "Jonathan Tompson", "Mykhaylo Andriluka", "Graham Taylor", "Christoph Bregler"], "authorids": ["ajain@nyu.edu", "jonathantompson@gmail.com", "andriluka@mpi-inf.mpg.de", "gwtaylor@gmail.com", "chris.bregler@gmail.com"]}, "tags": [], "invitation": {}}}, {"ddate": null, "legacy_migration": true, "tmdate": 1392757740000, "tcdate": 1392757740000, "number": 1, "id": "pzXqzYTC2nzdD", "invitation": "ICLR.cc/2014/-/submission/conference/reply", "forum": "kziQtP-nGqzDb", "replyto": "IBlASQ-hAuGJz", "signatures": ["Arjun Jain"], "readers": ["everyone"], "writers": ["anonymous"], "content": {"title": "", "reply": "Thank you for your comments and suggestions and we appreciate your recognition of the difficulty of the human body pose detection problem.  Given the challenge of this problem we hope that the implementation details in our paper will help others apply convolutional networks to this problem domain.\r\n\r\n\u201cI think the presentation of the spatial model in Figure 3 could be a little cleaner and clearer.\u201d\r\n\r\nSince receiving the reviewers\u2019 feedback, we have worked to address any confusion surrounding our implementation of the spatial prior and provide a more in-depth discussion of the theoretical framework. In particular, we believe that the current version of the paper now better links our implementation with that of standard sum-product belief propagation and explains the choices we made when formulating this prior.  Please see our above response to reviewer \u201cAnonymous 8a35\u201d for further clarification.\r\n\r\n\u201cThe part that seems like it doesn\u2019t quite match up is the fact that the prior is encoded within the conditionals of the discrete distributions of the Bayesian network while the likelihood is actually the result of the CNNs prediction for a set of binary decisions arising from the sliding window setup.\u201d\r\n\r\nRather than giving the prior or likelihood designation, we think the easiest way to interpret the chain-structured spatial model is that of the convnet providing the unary term and the training set statistics providing the pairwise term."}, "nonreaders": [], "details": {"replyCount": 0, "overwriting": [], "revisions": false, "forumContent": {"title": "Learning Human Pose Estimation Features with Convolutional Networks", "decision": "submitted, no decision", "abstract": "This paper introduces a new architecture for human pose estimation using a multi- layer convolutional network architecture and a modified learning technique that learns low-level features and higher-level weak spatial models. Unconstrained human pose estimation is one of the hardest problems in computer vision, and our new architecture and learning schema shows significant improvement over the current state-of-the-art results. The main contribution of this paper is showing, for the first time, that a specific variation of deep learning is able to outperform all existing traditional architectures on this task. The paper also discusses several lessons learned while researching alternatives, most notably, that it is possible to learn strong low-level feature detectors on features that might even just cover a few pixels in the image. Higher-level spatial models improve somewhat the overall result, but to a much lesser extent then expected. Many researchers previously argued that the kinematic structure and top-down information is crucial for this domain, but with our purely bottom up, and weak spatial model, we could improve other more complicated architectures that currently produce the best results. This mirrors what many other researchers, like those in the speech recognition, object recognition, and other domains have experienced.", "pdf": "https://arxiv.org/abs/1312.7302", "paperhash": "jain|learning_human_pose_estimation_features_with_convolutional_networks", "keywords": [], "conflicts": [], "authors": ["Ajrun Jain", "Jonathan Tompson", "Mykhaylo Andriluka", "Graham Taylor", "Christoph Bregler"], "authorids": ["ajain@nyu.edu", "jonathantompson@gmail.com", "andriluka@mpi-inf.mpg.de", "gwtaylor@gmail.com", "chris.bregler@gmail.com"]}, "tags": [], "invitation": {}}}, {"ddate": null, "legacy_migration": true, "tmdate": 1392757620000, "tcdate": 1392757620000, "number": 1, "id": "6auq8WBXjUEHY", "invitation": "ICLR.cc/2014/-/submission/conference/reply", "forum": "kziQtP-nGqzDb", "replyto": "qvnm_NL480_sI", "signatures": ["Arjun Jain"], "readers": ["everyone"], "writers": ["anonymous"], "content": {"title": "", "reply": "Firstly, thank you for your thoughtful insights and detailed comments.  At a high level, we have made the explanation about the experimental setup and the spatial prior model clearer following your advice.  In particular, we have added a discussion of the choices we made regarding experiments using the FLIC dataset and elaborated on the fairness of our evaluation criteria.\r\n\r\nIn response to your specific concerns:\r\n\r\n\u201cShakhnarovich et al. [37] do not use HOG [12] features. Note that [37] predates HOG [12] by a few years. \u201c\r\n\r\nSorry for this oversight.  We have corrected this in the latest draft.\r\n\r\n\u201cPlease be more specific about the form of LCN used.\u201d\r\n\r\nThe LCN normalization was based on standard techniques described by Jarrett et al. (What is the best multi-stage architecture for object recognition?).  Our LCN is a 2 layer module comprised of a local subtractive normalization followed by a local divisive normalization.  The local subtractive normalization stage subtracts the local mean value (calculated by convolving the input with a 9x9 Gaussian kernel) from each input pixel.  Likewise, the local divisive normalization divides each pixel by the standard deviation of the local 9x9 pixel window.  A divisive threshold of 1e-4 was used to prevent over-emphasis of input noise and division by zero.  We have added these details to the latest version on Arxiv.\r\n\r\n\u201cUnnumbered equation bottom of page 5: I might be confused by the notation and terse explanation, but I think this should be (p_u|i=0 * p_u).\u201d\r\n\r\nSorry for our overly terse explanation.  We have added a more thorough discussion in the latest version.\r\n\r\nThe equation describes standard sum-product belief propagation, however perhaps our notation made this confusing.  The biggest difference from standard literature is that we don't assume a Gaussian distribution for the pairwise terms, but have more flexible non-parametric representation based on the histograms of relative position occurrences in the training data.  Furthermore, we formulate these terms as convolutional priors, which avoid having to learn a distribution for every pixel location.  As indicated in figure 3, we do incorporate message terms from adjacent nodes in the graph (where the likelihood term from the shoulder to face nodes being a notable exception).  For example, when calculating the marginal for the shoulder term, the wrist location is accounted for in the elbow message.\r\n\r\n\u201cSec. 4: \u201cFollowing the methodology of Felzenszwalb et al. [16]...\u201d Felzenszwalb et al. does not deal with pose estimation or propose a methodology for this dataset. There is some confusion here. \u201d\r\n\r\nSorry for the confusion.  This was actually an typographic error and has been rectified in the latest draft.  We actually follow the methodology of Sapp et al. [36], not Felzenszwalb et al as stated.  In particular we used their error metric, evaluation code and their test-set.  We deviate from their methodology in one important way: we use a 351 image subset of the test set.  This subset contains the images that only contain a single person.  The motivation for doing so follows the fact that our detector will give a positive detection for all persons in the image, while the ground-truth labels exist for only a single person in the image (chosen arbitrarily).\r\n\r\n\u201cIf only 351 images were used (instead of 1016) how did you compare with MODEC? Eyeballing the plots, they appear to be the same as in the MODEC CVPR 2013 paper, which from what I can tell used all 1016 test images. Is this an apples-to-apples comparison?\u201d\r\n\r\nWe use the same 351 image subset when evaluating all models, including MODEC, and we have made this clear in the latest paper revision.  While the MODEC results appear similar to the CVPR 2013 paper when inspecting the plots, they are actually slightly different.\r\n\r\n\u201cIn Figure 6, how is the DPM baseline implemented? DPM [16] was not designed to do pose estimation, so how did you modify it to estimate pose in this work? What data was it trained on?\u201d\r\n\r\nAs you correctly pointed out, DPM is designed for detection and so we apply it to detect key-points in the skeleton (the same keypoints used to train our convnet based detector). Furthermore, DPM is trained on exactly same training data as our convnet (3987x2 images) and tested on the same test set; as such we believe that we have directly and fairly compared both keypoint-based detectors. The use of DPM in this manner is similar to the ICCV\u201913 paper of Pishchulin et al. (Strong Appearance and Expressive Spatial Models for Human Pose Estimation), which uses DPM as a unary likelihood model for keypoint detection."}, "nonreaders": [], "details": {"replyCount": 0, "overwriting": [], "revisions": false, "forumContent": {"title": "Learning Human Pose Estimation Features with Convolutional Networks", "decision": "submitted, no decision", "abstract": "This paper introduces a new architecture for human pose estimation using a multi- layer convolutional network architecture and a modified learning technique that learns low-level features and higher-level weak spatial models. Unconstrained human pose estimation is one of the hardest problems in computer vision, and our new architecture and learning schema shows significant improvement over the current state-of-the-art results. The main contribution of this paper is showing, for the first time, that a specific variation of deep learning is able to outperform all existing traditional architectures on this task. The paper also discusses several lessons learned while researching alternatives, most notably, that it is possible to learn strong low-level feature detectors on features that might even just cover a few pixels in the image. Higher-level spatial models improve somewhat the overall result, but to a much lesser extent then expected. Many researchers previously argued that the kinematic structure and top-down information is crucial for this domain, but with our purely bottom up, and weak spatial model, we could improve other more complicated architectures that currently produce the best results. This mirrors what many other researchers, like those in the speech recognition, object recognition, and other domains have experienced.", "pdf": "https://arxiv.org/abs/1312.7302", "paperhash": "jain|learning_human_pose_estimation_features_with_convolutional_networks", "keywords": [], "conflicts": [], "authors": ["Ajrun Jain", "Jonathan Tompson", "Mykhaylo Andriluka", "Graham Taylor", "Christoph Bregler"], "authorids": ["ajain@nyu.edu", "jonathantompson@gmail.com", "andriluka@mpi-inf.mpg.de", "gwtaylor@gmail.com", "chris.bregler@gmail.com"]}, "tags": [], "invitation": {}}}, {"ddate": null, "legacy_migration": true, "tmdate": 1391830620000, "tcdate": 1391830620000, "number": 6, "id": "vHcovKyYMR3lw", "invitation": "ICLR.cc/2014/-/submission/conference/review", "forum": "kziQtP-nGqzDb", "replyto": "kziQtP-nGqzDb", "signatures": ["anonymous reviewer ae8c"], "readers": ["everyone"], "writers": ["anonymous"], "content": {"title": "review of Learning Human Pose Estimation Features with Convolutional Networks", "review": "The paper proposes an architecture that takes as input an image and outputs the locations of human body parts (face, shoulder, elbow, wrist). The architecture consists of two parts, of which the second part, however, does not contribute much to classification accuracy (on the data on which the model was tested). \r\n\r\nThe first part is a sliding window detector using a binary-output convolutional network. The networks uses smaller pooling regions than what is conventional, in order to retain a high degree of spatial precision, and is otherwise not different from commonly used networks. I find it surprising, that this makes much of a difference, because I would have thought that the peak response of the sliding window conv net be pretty much at the same location, with or without a lot of spatial pooling (especially since you use non-maximum suppression). \r\n\r\nThe second part of the architecture is a graphical model (Markov chain) that represents a prior over relative spatial location of the different body parts. It is used to clean up the conv net detections. Unfortunately (but this is also an interesting finding) it does not help much. \r\n\r\nI find the first sentence in section 3.2 strange. Why do you care about false-positives? Or put another way, why don't you increase the detection threshold? It seems like you should really only care about the complete ROC curve. But then, as you show later, the prior you propose here doesn't help much to fix it. \r\n\r\nUsing sliding windows with a conv net sounds like it will be slow. Could you say something about the efficiency as compared to the other models? Sapp et al., for example, seem to show that MODEC is not only fairly accurate but also fast (well, as compared to DPM). Apologies, in case this is discussed somewhere and I overlooked it. \r\n\r\nIn Section 4.1 the references to the Figures are wrong. \r\n\r\nThis is yet another paper showing that conv nets work well in tasks previously dominated by more complicated vision architectures. The paper has some minor issues as pointed out, but overall I enjoyed reading it."}, "nonreaders": [], "details": {"replyCount": 0, "overwriting": [], "revisions": false, "forumContent": {"title": "Learning Human Pose Estimation Features with Convolutional Networks", "decision": "submitted, no decision", "abstract": "This paper introduces a new architecture for human pose estimation using a multi- layer convolutional network architecture and a modified learning technique that learns low-level features and higher-level weak spatial models. Unconstrained human pose estimation is one of the hardest problems in computer vision, and our new architecture and learning schema shows significant improvement over the current state-of-the-art results. The main contribution of this paper is showing, for the first time, that a specific variation of deep learning is able to outperform all existing traditional architectures on this task. The paper also discusses several lessons learned while researching alternatives, most notably, that it is possible to learn strong low-level feature detectors on features that might even just cover a few pixels in the image. Higher-level spatial models improve somewhat the overall result, but to a much lesser extent then expected. Many researchers previously argued that the kinematic structure and top-down information is crucial for this domain, but with our purely bottom up, and weak spatial model, we could improve other more complicated architectures that currently produce the best results. This mirrors what many other researchers, like those in the speech recognition, object recognition, and other domains have experienced.", "pdf": "https://arxiv.org/abs/1312.7302", "paperhash": "jain|learning_human_pose_estimation_features_with_convolutional_networks", "keywords": [], "conflicts": [], "authors": ["Ajrun Jain", "Jonathan Tompson", "Mykhaylo Andriluka", "Graham Taylor", "Christoph Bregler"], "authorids": ["ajain@nyu.edu", "jonathantompson@gmail.com", "andriluka@mpi-inf.mpg.de", "gwtaylor@gmail.com", "chris.bregler@gmail.com"]}, "tags": [], "invitation": {}}}, {"ddate": null, "legacy_migration": true, "tmdate": 1391483700000, "tcdate": 1391483700000, "number": 5, "id": "IBlASQ-hAuGJz", "invitation": "ICLR.cc/2014/-/submission/conference/review", "forum": "kziQtP-nGqzDb", "replyto": "kziQtP-nGqzDb", "signatures": ["anonymous reviewer 41e4"], "readers": ["everyone"], "writers": ["anonymous"], "content": {"title": "review of Learning Human Pose Estimation Features with Convolutional Networks", "review": "This paper examines a way to use convolutional neural networks to estimate human pose features. As many people in the community know, convolutional neural networks have had a major impact in the ImageNet object recognition evaluations. This paper looks at using them for a restricted setting of the challenging problem of human pose estimation. This is clearly an interesting direction to explore, and the details of how one does so are important - as noted by the authors. \r\n\r\nAt a high level it seems the main idea and contribution here involves the use of a simple chain structured model to capture spatial relationships between some key parts, namely: faces, shoulders, elbows and wrists. I think the presentation of the spatial model in Figure 3 could be a little cleaner and clearer. Basically it seems like the paper is coming up against the classic problem of how to combine local activity maps with some form of spatial prior or spatial model for how parts fit together. This type of issue has come up a lot in vision in many contexts and a number of approaches have been proposed on how to address the issue within a common theoretical framework, ex CRFs. Here it seems the approach has been to treat the output of the binary predictions for part locations from the CNN as a form of likelihood term that interacts with a prior that has been encoded through the discrete distributions of what seems to be essentially a linear chain Bayesian Network structure. The part that seems like it doesn\u2019t quite match up is the fact that the prior is encoded within the conditionals of the discrete distributions of the Bayesian network while the likelihood is actually the result of the CNNs prediction for a set of binary decisions arising from the sliding window setup.\r\n\r\nIn general the paper presents some promising results, I think the theoretical framework could be cleaned up a little, but the ideas and results are going in a good direction."}, "nonreaders": [], "details": {"replyCount": 0, "overwriting": [], "revisions": false, "forumContent": {"title": "Learning Human Pose Estimation Features with Convolutional Networks", "decision": "submitted, no decision", "abstract": "This paper introduces a new architecture for human pose estimation using a multi- layer convolutional network architecture and a modified learning technique that learns low-level features and higher-level weak spatial models. Unconstrained human pose estimation is one of the hardest problems in computer vision, and our new architecture and learning schema shows significant improvement over the current state-of-the-art results. The main contribution of this paper is showing, for the first time, that a specific variation of deep learning is able to outperform all existing traditional architectures on this task. The paper also discusses several lessons learned while researching alternatives, most notably, that it is possible to learn strong low-level feature detectors on features that might even just cover a few pixels in the image. Higher-level spatial models improve somewhat the overall result, but to a much lesser extent then expected. Many researchers previously argued that the kinematic structure and top-down information is crucial for this domain, but with our purely bottom up, and weak spatial model, we could improve other more complicated architectures that currently produce the best results. This mirrors what many other researchers, like those in the speech recognition, object recognition, and other domains have experienced.", "pdf": "https://arxiv.org/abs/1312.7302", "paperhash": "jain|learning_human_pose_estimation_features_with_convolutional_networks", "keywords": [], "conflicts": [], "authors": ["Ajrun Jain", "Jonathan Tompson", "Mykhaylo Andriluka", "Graham Taylor", "Christoph Bregler"], "authorids": ["ajain@nyu.edu", "jonathantompson@gmail.com", "andriluka@mpi-inf.mpg.de", "gwtaylor@gmail.com", "chris.bregler@gmail.com"]}, "tags": [], "invitation": {}}}, {"ddate": null, "legacy_migration": true, "tmdate": 1391422440000, "tcdate": 1391422440000, "number": 4, "id": "qvnm_NL480_sI", "invitation": "ICLR.cc/2014/-/submission/conference/review", "forum": "kziQtP-nGqzDb", "replyto": "kziQtP-nGqzDb", "signatures": ["anonymous reviewer 8a35"], "readers": ["everyone"], "writers": ["anonymous"], "content": {"title": "review of Learning Human Pose Estimation Features with Convolutional Networks", "review": "My review refers to the most recent arXiv revision (#3) at the time I downloaded papers for review.\r\n\r\nSummary\r\n\r\nThis paper applies convolutional neural networks to the task of predicting upper-body keypoints (face, shoulder, elbow, wrist) in static RGB images. The approach trains one ConvNet per keypoint (all with the same architecture) for the task of deciding if the center pixel of an image window is the location of the target keypoint. A spatial model (a simple chain connecting face-shoulder-elbow-wrist) is estimated to provide a prior between locations of adjacent keypoints. At test-time, the ConvNets are run in a multi-scale, sliding-window fashion over the test image. The \u201cunaries\u201d from the ConvNet keypoint detectors are then filtered using the prior.\r\n\r\nMuch recent work on pose estimation in static RGB images has focused on combining HOG-based part detectors via a spatial model. These models are often enriched with local mixture models. Yang & Ramanan and Sapp & Taskar are popular recent examples. This is one of the first papers that uses ConvNets within this \u201cparts and springs\u201d paradigm. A paper similar in spirit was posted to arXiv slightly before this paper was submitted (\u201cDeepPose\u201d by Toshev and Szegedy http://arxiv.org/pdf/1312.4659v1.pdf). While too new to require a comparison, I list it here for completeness.\r\n\r\nNovelty and Quality\r\n\r\nWhile ConvNets have been used for pose estimation in previous work (as properly referenced in this paper), the current generation of ConvNets (following from Krizhevsky et al.\u2019s work) have not been tried on the current generation of human pose datasets (e.g., FLIC). While the technique is not very novel, the proposal and investigation are good to see. The paper is well written. However, the experimental evaluation is confusing (unclear baseline methods, unclear if the subsets of images used are the same across methods) and computation employed for spatial modeling seems odd (more specific comments follow).\r\n\r\nPros\r\n\r\n+ It\u2019s good to see an investigation of ConvNets into pose estimation on modern datasets like FLIC.\r\n+ The paper is well written and easy to follow.\r\n+ The proposed architecture is similar to existing ones based on HOG, but with HOG filters replaced with ConvNets, making for an interesting comparison.\r\n\r\nCons\r\n\r\n- I found details of the experimental comparison on FLIC lacking (I\u2019ll be specific below).\r\n- The abstract and intro lead one to believe that the results on FLIC are going to much, much better than prior work, yet they only look marginally better.\r\n- The DPM baseline on FLIC doesn\u2019t make sense (details below).\r\n- The choices made in the spatial model needs to be explained more.\r\n\r\nDetails questions and comments\r\n\r\nSec. 2: Shakhnarovich et al. [37] do not use HOG [12] features. Note that [37] predates HOG [12] by a few years.\r\n\r\nSec. 3.1: Please be more specific about the form of LCN used.\r\n\r\nFootnote 1: \u201cthe the\u201d typo\r\n\r\nUnnumbered equation bottom of page 5: I might be confused by the notation and terse explanation, but I think this should be (p_u|i=0 * p_u). More generally, the computation needs to be explained/justified more. Given a chain like this, one would typically compute the marginal likelihood of a keypoint at each location using dynamic programming (same as sum-product on a tree/chain). Here, it seems that when computing the \u201cmarginal\u201d for the shoulder, the wrist is completely ignored. This seems very strange and ad hoc--given all of the literature on pictorial structure models, why implement this odd variant?\r\n\r\nExperimental setup / DPM comparison:\r\n\r\nSec. 4: \u201cFollowing the methodology of Felzenszwalb et al. [16]...\u201d Felzenszwalb et al. does not deal with pose estimation or propose a methodology for this dataset. There is some confusion here. \r\n\r\nIf only 351 images were used (instead of 1016) how did you compare with MODEC? Eyeballing the plots, they appear to be the same as in the MODEC CVPR 2013 paper, which from what I can tell used all 1016 test images. Is this an apples-to-apples comparison?\r\n\r\nIn Figure 6, how is the DPM baseline implemented? DPM [16] was not designed to do pose estimation, so how did you modify it to estimate pose in this work? What data was it trained on?"}, "nonreaders": [], "details": {"replyCount": 0, "overwriting": [], "revisions": false, "forumContent": {"title": "Learning Human Pose Estimation Features with Convolutional Networks", "decision": "submitted, no decision", "abstract": "This paper introduces a new architecture for human pose estimation using a multi- layer convolutional network architecture and a modified learning technique that learns low-level features and higher-level weak spatial models. Unconstrained human pose estimation is one of the hardest problems in computer vision, and our new architecture and learning schema shows significant improvement over the current state-of-the-art results. The main contribution of this paper is showing, for the first time, that a specific variation of deep learning is able to outperform all existing traditional architectures on this task. The paper also discusses several lessons learned while researching alternatives, most notably, that it is possible to learn strong low-level feature detectors on features that might even just cover a few pixels in the image. Higher-level spatial models improve somewhat the overall result, but to a much lesser extent then expected. Many researchers previously argued that the kinematic structure and top-down information is crucial for this domain, but with our purely bottom up, and weak spatial model, we could improve other more complicated architectures that currently produce the best results. This mirrors what many other researchers, like those in the speech recognition, object recognition, and other domains have experienced.", "pdf": "https://arxiv.org/abs/1312.7302", "paperhash": "jain|learning_human_pose_estimation_features_with_convolutional_networks", "keywords": [], "conflicts": [], "authors": ["Ajrun Jain", "Jonathan Tompson", "Mykhaylo Andriluka", "Graham Taylor", "Christoph Bregler"], "authorids": ["ajain@nyu.edu", "jonathantompson@gmail.com", "andriluka@mpi-inf.mpg.de", "gwtaylor@gmail.com", "chris.bregler@gmail.com"]}, "tags": [], "invitation": {}}}, {"ddate": null, "legacy_migration": true, "tmdate": 1390243320000, "tcdate": 1390243320000, "number": 1, "id": "YGNn9-ftL60CE", "invitation": "ICLR.cc/2014/-/submission/conference/review", "forum": "kziQtP-nGqzDb", "replyto": "kziQtP-nGqzDb", "signatures": ["\u6c88\u6770"], "readers": ["everyone"], "writers": ["anonymous"], "content": {"title": "", "review": "looks interesting!"}, "nonreaders": [], "details": {"replyCount": 0, "overwriting": [], "revisions": false, "forumContent": {"title": "Learning Human Pose Estimation Features with Convolutional Networks", "decision": "submitted, no decision", "abstract": "This paper introduces a new architecture for human pose estimation using a multi- layer convolutional network architecture and a modified learning technique that learns low-level features and higher-level weak spatial models. Unconstrained human pose estimation is one of the hardest problems in computer vision, and our new architecture and learning schema shows significant improvement over the current state-of-the-art results. The main contribution of this paper is showing, for the first time, that a specific variation of deep learning is able to outperform all existing traditional architectures on this task. The paper also discusses several lessons learned while researching alternatives, most notably, that it is possible to learn strong low-level feature detectors on features that might even just cover a few pixels in the image. Higher-level spatial models improve somewhat the overall result, but to a much lesser extent then expected. Many researchers previously argued that the kinematic structure and top-down information is crucial for this domain, but with our purely bottom up, and weak spatial model, we could improve other more complicated architectures that currently produce the best results. This mirrors what many other researchers, like those in the speech recognition, object recognition, and other domains have experienced.", "pdf": "https://arxiv.org/abs/1312.7302", "paperhash": "jain|learning_human_pose_estimation_features_with_convolutional_networks", "keywords": [], "conflicts": [], "authors": ["Ajrun Jain", "Jonathan Tompson", "Mykhaylo Andriluka", "Graham Taylor", "Christoph Bregler"], "authorids": ["ajain@nyu.edu", "jonathantompson@gmail.com", "andriluka@mpi-inf.mpg.de", "gwtaylor@gmail.com", "chris.bregler@gmail.com"]}, "tags": [], "invitation": {}}}, {"ddate": null, "legacy_migration": true, "tmdate": 1390243320000, "tcdate": 1390243320000, "number": 3, "id": "ksrLsy6nSDtBq", "invitation": "ICLR.cc/2014/-/submission/conference/review", "forum": "kziQtP-nGqzDb", "replyto": "kziQtP-nGqzDb", "signatures": ["\u6c88\u6770"], "readers": ["everyone"], "writers": ["anonymous"], "content": {"title": "", "review": "looks interesting!"}, "nonreaders": [], "details": {"replyCount": 0, "overwriting": [], "revisions": false, "forumContent": {"title": "Learning Human Pose Estimation Features with Convolutional Networks", "decision": "submitted, no decision", "abstract": "This paper introduces a new architecture for human pose estimation using a multi- layer convolutional network architecture and a modified learning technique that learns low-level features and higher-level weak spatial models. Unconstrained human pose estimation is one of the hardest problems in computer vision, and our new architecture and learning schema shows significant improvement over the current state-of-the-art results. The main contribution of this paper is showing, for the first time, that a specific variation of deep learning is able to outperform all existing traditional architectures on this task. The paper also discusses several lessons learned while researching alternatives, most notably, that it is possible to learn strong low-level feature detectors on features that might even just cover a few pixels in the image. Higher-level spatial models improve somewhat the overall result, but to a much lesser extent then expected. Many researchers previously argued that the kinematic structure and top-down information is crucial for this domain, but with our purely bottom up, and weak spatial model, we could improve other more complicated architectures that currently produce the best results. This mirrors what many other researchers, like those in the speech recognition, object recognition, and other domains have experienced.", "pdf": "https://arxiv.org/abs/1312.7302", "paperhash": "jain|learning_human_pose_estimation_features_with_convolutional_networks", "keywords": [], "conflicts": [], "authors": ["Ajrun Jain", "Jonathan Tompson", "Mykhaylo Andriluka", "Graham Taylor", "Christoph Bregler"], "authorids": ["ajain@nyu.edu", "jonathantompson@gmail.com", "andriluka@mpi-inf.mpg.de", "gwtaylor@gmail.com", "chris.bregler@gmail.com"]}, "tags": [], "invitation": {}}}, {"ddate": null, "legacy_migration": true, "tmdate": 1390243320000, "tcdate": 1390243320000, "number": 2, "id": "-kMX-SbGYskJh", "invitation": "ICLR.cc/2014/-/submission/conference/review", "forum": "kziQtP-nGqzDb", "replyto": "kziQtP-nGqzDb", "signatures": ["\u6c88\u6770"], "readers": ["everyone"], "writers": ["anonymous"], "content": {"title": "", "review": "looks interesting!"}, "nonreaders": [], "details": {"replyCount": 0, "overwriting": [], "revisions": false, "forumContent": {"title": "Learning Human Pose Estimation Features with Convolutional Networks", "decision": "submitted, no decision", "abstract": "This paper introduces a new architecture for human pose estimation using a multi- layer convolutional network architecture and a modified learning technique that learns low-level features and higher-level weak spatial models. Unconstrained human pose estimation is one of the hardest problems in computer vision, and our new architecture and learning schema shows significant improvement over the current state-of-the-art results. The main contribution of this paper is showing, for the first time, that a specific variation of deep learning is able to outperform all existing traditional architectures on this task. The paper also discusses several lessons learned while researching alternatives, most notably, that it is possible to learn strong low-level feature detectors on features that might even just cover a few pixels in the image. Higher-level spatial models improve somewhat the overall result, but to a much lesser extent then expected. Many researchers previously argued that the kinematic structure and top-down information is crucial for this domain, but with our purely bottom up, and weak spatial model, we could improve other more complicated architectures that currently produce the best results. This mirrors what many other researchers, like those in the speech recognition, object recognition, and other domains have experienced.", "pdf": "https://arxiv.org/abs/1312.7302", "paperhash": "jain|learning_human_pose_estimation_features_with_convolutional_networks", "keywords": [], "conflicts": [], "authors": ["Ajrun Jain", "Jonathan Tompson", "Mykhaylo Andriluka", "Graham Taylor", "Christoph Bregler"], "authorids": ["ajain@nyu.edu", "jonathantompson@gmail.com", "andriluka@mpi-inf.mpg.de", "gwtaylor@gmail.com", "chris.bregler@gmail.com"]}, "tags": [], "invitation": {}}}, {"replyto": null, "ddate": null, "legacy_migration": true, "tmdate": 1388384460000, "tcdate": 1388384460000, "number": 65, "id": "kziQtP-nGqzDb", "invitation": "ICLR.cc/2014/conference/-/submission", "forum": "kziQtP-nGqzDb", "signatures": ["ajain@nyu.edu"], "readers": ["everyone"], "content": {"title": "Learning Human Pose Estimation Features with Convolutional Networks", "decision": "submitted, no decision", "abstract": "This paper introduces a new architecture for human pose estimation using a multi- layer convolutional network architecture and a modified learning technique that learns low-level features and higher-level weak spatial models. Unconstrained human pose estimation is one of the hardest problems in computer vision, and our new architecture and learning schema shows significant improvement over the current state-of-the-art results. The main contribution of this paper is showing, for the first time, that a specific variation of deep learning is able to outperform all existing traditional architectures on this task. The paper also discusses several lessons learned while researching alternatives, most notably, that it is possible to learn strong low-level feature detectors on features that might even just cover a few pixels in the image. Higher-level spatial models improve somewhat the overall result, but to a much lesser extent then expected. Many researchers previously argued that the kinematic structure and top-down information is crucial for this domain, but with our purely bottom up, and weak spatial model, we could improve other more complicated architectures that currently produce the best results. This mirrors what many other researchers, like those in the speech recognition, object recognition, and other domains have experienced.", "pdf": "https://arxiv.org/abs/1312.7302", "paperhash": "jain|learning_human_pose_estimation_features_with_convolutional_networks", "keywords": [], "conflicts": [], "authors": ["Ajrun Jain", "Jonathan Tompson", "Mykhaylo Andriluka", "Graham Taylor", "Christoph Bregler"], "authorids": ["ajain@nyu.edu", "jonathantompson@gmail.com", "andriluka@mpi-inf.mpg.de", "gwtaylor@gmail.com", "chris.bregler@gmail.com"]}, "writers": [], "details": {"replyCount": 9, "writable": false, "overwriting": [], "revisions": false, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1369422751717, "tmdate": 1496674357195, "id": "ICLR.cc/2014/conference/-/submission", "writers": ["ICLR.cc/2014"], "signatures": ["OpenReview.net"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": null, "replyto": null, "writers": {"values-regex": "~.*"}, "signatures": {"values-regex": "~.*", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"pdf": {"required": true, "order": 5, "description": "Either upload a PDF file or provide a direct link to your PDF on ArXiv (link must begin with http(s) and end with .pdf)", "value-regex": "upload|(http|https):\\/\\/.+\\.pdf"}, "title": {"required": true, "order": 1, "description": "Title of paper.", "value-regex": ".{1,250}"}, "abstract": {"required": true, "order": 4, "description": "Abstract of paper.", "value-regex": "[\\S\\s]{1,5000}"}, "authors": {"required": true, "order": 2, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of author names, as they appear in the paper."}, "conflicts": {"required": true, "order": 100, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of email domains of people who would have a conflict of interest in reviewing this paper, (e.g., cs.umass.edu;google.com, etc.)."}, "keywords": {"order": 6, "description": "Comma separated list of keywords.", "values-dropdown": []}, "authorids": {"required": true, "order": 3, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of author email addresses, in the same order as above."}}}, "nonreaders": [], "noninvitees": [], "expdate": 1377198751717, "cdate": 1496674357195}}}], "count": 10}