{"notes": [{"id": "SOeY2AQR9", "original": "GGh8Fhyj1W", "number": 12, "cdate": 1582750152548, "ddate": null, "tcdate": 1582750152548, "tmdate": 1587925108735, "tddate": null, "forum": "SOeY2AQR9", "replyto": null, "invitation": "ICLR.cc/2020/Workshop/DeepDiffEq/-/Blind_Submission", "content": {"title": "How Chaotic Are Recurrent Neural Networks?", "authors": ["Pourya Vakilipourtakalou", "Lili Mou"], "authorids": ["vakilipo@ualberta.ca", "doublepower.mou@gmail.com"], "keywords": ["RNN", "Chaos", "NLP", "Text Generation"], "TL;DR": "We analyze the chaotic behavior of Recurrent Neural Networks (RNN) and find that in real-world applications, e.g., text generation, RNNs do not perform chaotic behavior.", "abstract": "Recurrent neural networks (RNNs) are non-linear dynamic systems. Previous\nwork believes that RNN may suffer from the phenomenon of chaos, where the\nsystem is sensitive to initial states and unpredictable in the long run. In this paper,\nhowever, we perform a systematic empirical analysis, showing that a vanilla or\nlong short term memory (LSTM) RNN does not exhibit chaotic behavior along\nthe training process in real applications such as text generation. Our findings suggest\nthat future work in this direction should address the other side of non-linear\ndynamics for RNN.", "pdf": "/pdf/0d45fdadf60875189e36aef7e350869e33407c6d.pdf", "paperhash": "vakilipourtakalou|how_chaotic_are_recurrent_neural_networks", "_bibtex": "@inproceedings{\nvakilipourtakalou2020how,\ntitle={How Chaotic Are Recurrent Neural Networks?},\nauthor={Pourya Vakilipourtakalou and Lili Mou},\nbooktitle={ICLR 2020 Workshop on Integration of Deep Neural Models and Differential Equations},\nyear={2020},\nurl={https://openreview.net/forum?id=SOeY2AQR9}\n}"}, "signatures": ["ICLR.cc/2020/Workshop/DeepDiffEq"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Workshop/DeepDiffEq"], "details": {"replyCount": 1, "writable": false, "overwriting": [], "revisions": false, "tags": [], "invitation": {"reply": {"readers": {"values-regex": ".*"}, "writers": {"values": ["ICLR.cc/2020/Workshop/DeepDiffEq"]}, "signatures": {"values": ["ICLR.cc/2020/Workshop/DeepDiffEq"]}, "content": {"authors": {"values": ["Anonymous"]}, "authorids": {"values-regex": ".*"}}}, "signatures": ["ICLR.cc/2020/Workshop/DeepDiffEq"], "readers": ["everyone"], "writers": ["ICLR.cc/2020/Workshop/DeepDiffEq"], "invitees": ["~"], "tcdate": 1582750147213, "tmdate": 1587924718420, "id": "ICLR.cc/2020/Workshop/DeepDiffEq/-/Blind_Submission"}}, "tauthor": "OpenReview.net"}, {"id": "BOXRk7yHS0", "original": null, "number": 1, "cdate": 1582774846271, "ddate": null, "tcdate": 1582774846271, "tmdate": 1582774846271, "tddate": null, "forum": "SOeY2AQR9", "replyto": "SOeY2AQR9", "invitation": "ICLR.cc/2020/Workshop/DeepDiffEq/Paper12/-/Decision", "content": {"decision": "Accept (Poster)", "title": "Paper Decision"}, "signatures": ["ICLR.cc/2020/Workshop/DeepDiffEq/Program_Chairs"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Workshop/DeepDiffEq/Program_Chairs"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "How Chaotic Are Recurrent Neural Networks?", "authors": ["Pourya Vakilipourtakalou", "Lili Mou"], "authorids": ["vakilipo@ualberta.ca", "doublepower.mou@gmail.com"], "keywords": ["RNN", "Chaos", "NLP", "Text Generation"], "TL;DR": "We analyze the chaotic behavior of Recurrent Neural Networks (RNN) and find that in real-world applications, e.g., text generation, RNNs do not perform chaotic behavior.", "abstract": "Recurrent neural networks (RNNs) are non-linear dynamic systems. Previous\nwork believes that RNN may suffer from the phenomenon of chaos, where the\nsystem is sensitive to initial states and unpredictable in the long run. In this paper,\nhowever, we perform a systematic empirical analysis, showing that a vanilla or\nlong short term memory (LSTM) RNN does not exhibit chaotic behavior along\nthe training process in real applications such as text generation. Our findings suggest\nthat future work in this direction should address the other side of non-linear\ndynamics for RNN.", "pdf": "/pdf/0d45fdadf60875189e36aef7e350869e33407c6d.pdf", "paperhash": "vakilipourtakalou|how_chaotic_are_recurrent_neural_networks", "_bibtex": "@inproceedings{\nvakilipourtakalou2020how,\ntitle={How Chaotic Are Recurrent Neural Networks?},\nauthor={Pourya Vakilipourtakalou and Lili Mou},\nbooktitle={ICLR 2020 Workshop on Integration of Deep Neural Models and Differential Equations},\nyear={2020},\nurl={https://openreview.net/forum?id=SOeY2AQR9}\n}"}, "tags": [], "invitation": {"reply": {"writers": {"values": ["ICLR.cc/2020/Workshop/DeepDiffEq/Program_Chairs"], "description": "How your identity will be displayed."}, "signatures": {"values": ["ICLR.cc/2020/Workshop/DeepDiffEq/Program_Chairs"], "description": "How your identity will be displayed."}, "content": {"title": {"order": 1, "required": true, "value": "Paper Decision"}, "decision": {"order": 2, "required": true, "value-radio": ["Accept (Oral)", "Accept (Poster)", "Reject"], "description": "Decision"}, "comment": {"order": 3, "required": false, "value-regex": "[\\S\\s]{0,5000}", "description": ""}}, "forum": "SOeY2AQR9", "replyto": "SOeY2AQR9", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}}, "cdate": 1582156800000, "expdate": 1589155200000, "duedate": 1588291200000, "multiReply": false, "readers": ["everyone"], "invitees": ["ICLR.cc/2020/Workshop/DeepDiffEq/Program_Chairs"], "tcdate": 1582771074650, "tmdate": 1587925015437, "super": "ICLR.cc/2020/Workshop/DeepDiffEq/-/Decision", "signatures": ["ICLR.cc/2020/Workshop/DeepDiffEq"], "writers": ["ICLR.cc/2020/Workshop/DeepDiffEq"], "id": "ICLR.cc/2020/Workshop/DeepDiffEq/Paper12/-/Decision"}}}], "count": 2}