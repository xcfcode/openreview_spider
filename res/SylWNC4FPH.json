{"notes": [{"id": "SylWNC4FPH", "original": "ryemzM8_wS", "number": 1065, "cdate": 1569439273213, "ddate": null, "tcdate": 1569439273213, "tmdate": 1577168251938, "tddate": null, "forum": "SylWNC4FPH", "replyto": null, "invitation": "ICLR.cc/2020/Conference/-/Blind_Submission", "content": {"authorids": ["liyang@google.com", "jamelot@google.com", "zhouxin@google.com", "bengio@google.com", "sisidaisy@google.com"], "title": "Auto Completion of User Interface Layout Design Using Transformer-Based Tree Decoders", "authors": ["Yang Li", "Julien Amelot", "Xin Zhou", "Samy Bengio", "Si Si"], "pdf": "/pdf/c519dc2e6822402832559e72df741b99036ea998.pdf", "TL;DR": "The paper investigates several Transformer-based decoder models for predicting a complete layout given a partial layout tree.", "abstract": "It has been of increasing interest in the field to develop automatic machineries to facilitate the design process. In this paper, we focus on assisting graphical user interface (UI) layout design, a crucial task in app development. Given a partial layout, which a designer has entered, our model learns to complete the layout by predicting the remaining UI elements with a correct position and dimension as well as the hierarchical structures. Such automation will significantly ease the effort of UI designers and developers. While we focus on interface layout prediction, our model can be generally applicable for other layout prediction problems that involve tree structures and 2-dimensional placements. Particularly, we design two versions of Transformer-based tree decoders: Pointer and Recursive Transformer, and experiment with these models on a public dataset. We also propose several metrics for measuring the accuracy of tree prediction and ground these metrics in the domain of user experience. These contribute a new task and methods to deep learning research.", "keywords": ["Transformer", "decoder", "user interface", "layout design"], "paperhash": "li|auto_completion_of_user_interface_layout_design_using_transformerbased_tree_decoders", "original_pdf": "/attachment/e12710117527c1c613e8dad7f3f54a98cdbe3498.pdf", "_bibtex": "@misc{\nli2020auto,\ntitle={Auto Completion of User Interface Layout Design Using Transformer-Based Tree Decoders},\nauthor={Yang Li and Julien Amelot and Xin Zhou and Samy Bengio and Si Si},\nyear={2020},\nurl={https://openreview.net/forum?id=SylWNC4FPH}\n}"}, "signatures": ["ICLR.cc/2020/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference"], "details": {"replyCount": 7, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"reply": {"readers": {"values-regex": ".*"}, "writers": {"values": ["ICLR.cc/2020/Conference"]}, "signatures": {"values": ["ICLR.cc/2020/Conference"]}, "content": {"spotlight_video": {"value-regex": ".*"}, "full_presentation_video": {"value-regex": ".*"}, "original_pdf": {"required": false, "description": "Upload a PDF file that ends with .pdf", "value-regex": ".*"}, "appendix": {"value-regex": ".*"}, "authorids": {"values-regex": ".*"}, "poster": {"value-regex": ".*"}, "authors": {"values": ["Anonymous"]}, "slides": {"value-regex": ".*"}}}, "final": [], "signatures": ["ICLR.cc/2020/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference"], "noninvitees": [], "tcdate": 1569271260237, "tmdate": 1593459412141, "id": "ICLR.cc/2020/Conference/-/Blind_Submission"}}, "tauthor": "OpenReview.net"}, {"id": "tVq1bBESvl", "original": null, "number": 1, "cdate": 1576798713651, "ddate": null, "tcdate": 1576798713651, "tmdate": 1576800922823, "tddate": null, "forum": "SylWNC4FPH", "replyto": "SylWNC4FPH", "invitation": "ICLR.cc/2020/Conference/Paper1065/-/Decision", "content": {"decision": "Reject", "comment": "The paper introduces an interesting application of GNNs, but the reviewers find that the contribution is too limited and the motivation is too weak.", "title": "Paper Decision"}, "signatures": ["ICLR.cc/2020/Conference/Program_Chairs"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Program_Chairs"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["liyang@google.com", "jamelot@google.com", "zhouxin@google.com", "bengio@google.com", "sisidaisy@google.com"], "title": "Auto Completion of User Interface Layout Design Using Transformer-Based Tree Decoders", "authors": ["Yang Li", "Julien Amelot", "Xin Zhou", "Samy Bengio", "Si Si"], "pdf": "/pdf/c519dc2e6822402832559e72df741b99036ea998.pdf", "TL;DR": "The paper investigates several Transformer-based decoder models for predicting a complete layout given a partial layout tree.", "abstract": "It has been of increasing interest in the field to develop automatic machineries to facilitate the design process. In this paper, we focus on assisting graphical user interface (UI) layout design, a crucial task in app development. Given a partial layout, which a designer has entered, our model learns to complete the layout by predicting the remaining UI elements with a correct position and dimension as well as the hierarchical structures. Such automation will significantly ease the effort of UI designers and developers. While we focus on interface layout prediction, our model can be generally applicable for other layout prediction problems that involve tree structures and 2-dimensional placements. Particularly, we design two versions of Transformer-based tree decoders: Pointer and Recursive Transformer, and experiment with these models on a public dataset. We also propose several metrics for measuring the accuracy of tree prediction and ground these metrics in the domain of user experience. These contribute a new task and methods to deep learning research.", "keywords": ["Transformer", "decoder", "user interface", "layout design"], "paperhash": "li|auto_completion_of_user_interface_layout_design_using_transformerbased_tree_decoders", "original_pdf": "/attachment/e12710117527c1c613e8dad7f3f54a98cdbe3498.pdf", "_bibtex": "@misc{\nli2020auto,\ntitle={Auto Completion of User Interface Layout Design Using Transformer-Based Tree Decoders},\nauthor={Yang Li and Julien Amelot and Xin Zhou and Samy Bengio and Si Si},\nyear={2020},\nurl={https://openreview.net/forum?id=SylWNC4FPH}\n}"}, "tags": [], "invitation": {"reply": {"writers": {"description": "How your identity will be displayed.", "values-regex": ["ICLR.cc/2020/Conference/Program_Chairs"]}, "signatures": {"values": ["ICLR.cc/2020/Conference/Program_Chairs"], "description": "How your identity will be displayed."}, "content": {"decision": {"value-radio": ["Accept (Spotlight)", "Accept (Talk)", "Accept (Poster)", "Reject"], "description": "Decision", "required": true, "order": 2}, "title": {"value": "Paper Decision", "required": true, "order": 1}, "comment": {"value-regex": "[\\S\\s]{0,5000}", "description": "", "required": false, "order": 3}}, "forum": "SylWNC4FPH", "replyto": "SylWNC4FPH", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}}, "expdate": 1576854540000, "duedate": 1576853940000, "multiReply": false, "readers": ["everyone"], "invitees": ["ICLR.cc/2020/Conference/Program_Chairs"], "tcdate": 1576795702819, "tmdate": 1576800250037, "super": "ICLR.cc/2020/Conference/-/Decision", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper1065/-/Decision"}}}, {"id": "BJxCz0ihsr", "original": null, "number": 3, "cdate": 1573858838128, "ddate": null, "tcdate": 1573858838128, "tmdate": 1573858838128, "tddate": null, "forum": "SylWNC4FPH", "replyto": "r1edRi1-9r", "invitation": "ICLR.cc/2020/Conference/Paper1065/-/Official_Comment", "content": {"title": "Re: Contribution, Reproducible and Technical Details", "comment": "Thank you for your comments. We have revised the paper to address the issues you brought up.\n\n- Contribution\nWe developed our approach based on Transformer models. We agree with the reviewer that the model novelty is relatively incremental. However, the focus of the paper is to contribute a new prediction problem and adapts and applies the Transformer model for this problem to establish a benchmark for future exploration, which we believe has values.\n\n- Benchmark & Reproducible\nThe data that our experiments used is an open dataset:\nhttps://storage.cloud.google.com/crowdstf-rico-uiuc-4540/rico_dataset_v0.1/semantic_annotations.zip\nWe will release our data preprocessing, and model code, including all the eval metrics to ensure the work is reproducible.\n\n- Technical details\nThanks for pointing out the issues with our presentations. We agree much detail on embeddings can be condensed or moved to Appendix. We included embedding details in the paper because a reviewer from the venue we previously submitted to requested these details to be in the paper. We revised the notations in the paper to make formulation clearer. In addition, we added more details about the data as you suggested. Given a partial tree, there can be more than one way to complete the layout. Given a 10%, 50% and 80% BFS partial layout, the mean number of completions of the layout is 2.97, 1.23 and 1.17 respectively. Given a 10%, 50% and 80% DFS partial layout, the mean number of completions is 3.63, 1.24, and 1.17 respectively. "}, "signatures": ["ICLR.cc/2020/Conference/Paper1065/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1065/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["liyang@google.com", "jamelot@google.com", "zhouxin@google.com", "bengio@google.com", "sisidaisy@google.com"], "title": "Auto Completion of User Interface Layout Design Using Transformer-Based Tree Decoders", "authors": ["Yang Li", "Julien Amelot", "Xin Zhou", "Samy Bengio", "Si Si"], "pdf": "/pdf/c519dc2e6822402832559e72df741b99036ea998.pdf", "TL;DR": "The paper investigates several Transformer-based decoder models for predicting a complete layout given a partial layout tree.", "abstract": "It has been of increasing interest in the field to develop automatic machineries to facilitate the design process. In this paper, we focus on assisting graphical user interface (UI) layout design, a crucial task in app development. Given a partial layout, which a designer has entered, our model learns to complete the layout by predicting the remaining UI elements with a correct position and dimension as well as the hierarchical structures. Such automation will significantly ease the effort of UI designers and developers. While we focus on interface layout prediction, our model can be generally applicable for other layout prediction problems that involve tree structures and 2-dimensional placements. Particularly, we design two versions of Transformer-based tree decoders: Pointer and Recursive Transformer, and experiment with these models on a public dataset. We also propose several metrics for measuring the accuracy of tree prediction and ground these metrics in the domain of user experience. These contribute a new task and methods to deep learning research.", "keywords": ["Transformer", "decoder", "user interface", "layout design"], "paperhash": "li|auto_completion_of_user_interface_layout_design_using_transformerbased_tree_decoders", "original_pdf": "/attachment/e12710117527c1c613e8dad7f3f54a98cdbe3498.pdf", "_bibtex": "@misc{\nli2020auto,\ntitle={Auto Completion of User Interface Layout Design Using Transformer-Based Tree Decoders},\nauthor={Yang Li and Julien Amelot and Xin Zhou and Samy Bengio and Si Si},\nyear={2020},\nurl={https://openreview.net/forum?id=SylWNC4FPH}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "SylWNC4FPH", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper1065/Authors", "ICLR.cc/2020/Conference/Paper1065/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper1065/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper1065/Reviewers", "ICLR.cc/2020/Conference/Paper1065/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper1065/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper1065/Authors|ICLR.cc/2020/Conference/Paper1065/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504161797, "tmdate": 1576860546574, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper1065/Authors", "ICLR.cc/2020/Conference/Paper1065/Reviewers", "ICLR.cc/2020/Conference/Paper1065/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper1065/-/Official_Comment"}}}, {"id": "BJeNDds2iH", "original": null, "number": 2, "cdate": 1573857371668, "ddate": null, "tcdate": 1573857371668, "tmdate": 1573857371668, "tddate": null, "forum": "SylWNC4FPH", "replyto": "H1g05tby5H", "invitation": "ICLR.cc/2020/Conference/Paper1065/-/Official_Comment", "content": {"title": "LSTM and Eval Metrics", "comment": "Thank you for your comments. \n\n- LSTM\nLSTMs are indeed a strong model for tree prediction on previous tasks. To allow the model to access ancestry nodes during decoding, one way is to concatenate the parent node latent representation with the input of each step for decoding children, and then feed the concatenated vector to LSTM (e.g., Dong & Lapata ACL 2016). However, since the ancestry has a variable-number of nodes (as decoding proceeds), to directly access these nodes during decoding, attentional mechanisms would be an efficient way, which is one of our motivations to use Transformer models that are attention-based. Of course, LSTM equipped with Attention would achieve the same benefit. In addition, positional encoding in Transformer also allows us to easily model spatial locations of UI elements. Our early experiments with LSTM did not yield good results on this spatial layout problem. That said, we agree it is worth investigating the performance of LSTM on this problem further. Since this is the first paper on this topic, we chose to focus on introducing the problem and providing Transformer-based approaches as a baseline for future work.\n\n- Eval metrics\nWe agree the IR-based metrics have limitations. This is why we provided multiple eval metrics including edit distances and next-N accuracy. The Edit Distance metric was designed by taking into account human factors in interaction tasks based on the key-stroke level GOMS models. We can clarify this further in the revision."}, "signatures": ["ICLR.cc/2020/Conference/Paper1065/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1065/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["liyang@google.com", "jamelot@google.com", "zhouxin@google.com", "bengio@google.com", "sisidaisy@google.com"], "title": "Auto Completion of User Interface Layout Design Using Transformer-Based Tree Decoders", "authors": ["Yang Li", "Julien Amelot", "Xin Zhou", "Samy Bengio", "Si Si"], "pdf": "/pdf/c519dc2e6822402832559e72df741b99036ea998.pdf", "TL;DR": "The paper investigates several Transformer-based decoder models for predicting a complete layout given a partial layout tree.", "abstract": "It has been of increasing interest in the field to develop automatic machineries to facilitate the design process. In this paper, we focus on assisting graphical user interface (UI) layout design, a crucial task in app development. Given a partial layout, which a designer has entered, our model learns to complete the layout by predicting the remaining UI elements with a correct position and dimension as well as the hierarchical structures. Such automation will significantly ease the effort of UI designers and developers. While we focus on interface layout prediction, our model can be generally applicable for other layout prediction problems that involve tree structures and 2-dimensional placements. Particularly, we design two versions of Transformer-based tree decoders: Pointer and Recursive Transformer, and experiment with these models on a public dataset. We also propose several metrics for measuring the accuracy of tree prediction and ground these metrics in the domain of user experience. These contribute a new task and methods to deep learning research.", "keywords": ["Transformer", "decoder", "user interface", "layout design"], "paperhash": "li|auto_completion_of_user_interface_layout_design_using_transformerbased_tree_decoders", "original_pdf": "/attachment/e12710117527c1c613e8dad7f3f54a98cdbe3498.pdf", "_bibtex": "@misc{\nli2020auto,\ntitle={Auto Completion of User Interface Layout Design Using Transformer-Based Tree Decoders},\nauthor={Yang Li and Julien Amelot and Xin Zhou and Samy Bengio and Si Si},\nyear={2020},\nurl={https://openreview.net/forum?id=SylWNC4FPH}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "SylWNC4FPH", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper1065/Authors", "ICLR.cc/2020/Conference/Paper1065/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper1065/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper1065/Reviewers", "ICLR.cc/2020/Conference/Paper1065/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper1065/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper1065/Authors|ICLR.cc/2020/Conference/Paper1065/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504161797, "tmdate": 1576860546574, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper1065/Authors", "ICLR.cc/2020/Conference/Paper1065/Reviewers", "ICLR.cc/2020/Conference/Paper1065/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper1065/-/Official_Comment"}}}, {"id": "HylnnWjhor", "original": null, "number": 1, "cdate": 1573855667689, "ddate": null, "tcdate": 1573855667689, "tmdate": 1573855667689, "tddate": null, "forum": "SylWNC4FPH", "replyto": "rygHqoLsKB", "invitation": "ICLR.cc/2020/Conference/Paper1065/-/Official_Comment", "content": {"title": "Comparison with Jenatton, Rodolphe, et al.'s work", "comment": "Thanks for your comments. We missed this previous work. Jenatton et al. proposed an approach to predict tree structures by using Bayesian optimization to combine independent Gaussian Processes with a linear model that encodes a tree-based structure. We have cited and discussed the work in the revision. The focus of our work is to propose a new tree prediction problem (layout completion) and introduce Transformer-based approaches for addressing the problem. It would be future work to investigate other tree-based models for this problem."}, "signatures": ["ICLR.cc/2020/Conference/Paper1065/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1065/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["liyang@google.com", "jamelot@google.com", "zhouxin@google.com", "bengio@google.com", "sisidaisy@google.com"], "title": "Auto Completion of User Interface Layout Design Using Transformer-Based Tree Decoders", "authors": ["Yang Li", "Julien Amelot", "Xin Zhou", "Samy Bengio", "Si Si"], "pdf": "/pdf/c519dc2e6822402832559e72df741b99036ea998.pdf", "TL;DR": "The paper investigates several Transformer-based decoder models for predicting a complete layout given a partial layout tree.", "abstract": "It has been of increasing interest in the field to develop automatic machineries to facilitate the design process. In this paper, we focus on assisting graphical user interface (UI) layout design, a crucial task in app development. Given a partial layout, which a designer has entered, our model learns to complete the layout by predicting the remaining UI elements with a correct position and dimension as well as the hierarchical structures. Such automation will significantly ease the effort of UI designers and developers. While we focus on interface layout prediction, our model can be generally applicable for other layout prediction problems that involve tree structures and 2-dimensional placements. Particularly, we design two versions of Transformer-based tree decoders: Pointer and Recursive Transformer, and experiment with these models on a public dataset. We also propose several metrics for measuring the accuracy of tree prediction and ground these metrics in the domain of user experience. These contribute a new task and methods to deep learning research.", "keywords": ["Transformer", "decoder", "user interface", "layout design"], "paperhash": "li|auto_completion_of_user_interface_layout_design_using_transformerbased_tree_decoders", "original_pdf": "/attachment/e12710117527c1c613e8dad7f3f54a98cdbe3498.pdf", "_bibtex": "@misc{\nli2020auto,\ntitle={Auto Completion of User Interface Layout Design Using Transformer-Based Tree Decoders},\nauthor={Yang Li and Julien Amelot and Xin Zhou and Samy Bengio and Si Si},\nyear={2020},\nurl={https://openreview.net/forum?id=SylWNC4FPH}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "SylWNC4FPH", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper1065/Authors", "ICLR.cc/2020/Conference/Paper1065/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper1065/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper1065/Reviewers", "ICLR.cc/2020/Conference/Paper1065/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper1065/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper1065/Authors|ICLR.cc/2020/Conference/Paper1065/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504161797, "tmdate": 1576860546574, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper1065/Authors", "ICLR.cc/2020/Conference/Paper1065/Reviewers", "ICLR.cc/2020/Conference/Paper1065/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper1065/-/Official_Comment"}}}, {"id": "rygHqoLsKB", "original": null, "number": 1, "cdate": 1571675020692, "ddate": null, "tcdate": 1571675020692, "tmdate": 1572972517194, "tddate": null, "forum": "SylWNC4FPH", "replyto": "SylWNC4FPH", "invitation": "ICLR.cc/2020/Conference/Paper1065/-/Official_Review", "content": {"rating": "3: Weak Reject", "experience_assessment": "I have read many papers in this area.", "review_assessment:_checking_correctness_of_derivations_and_theory": "I did not assess the derivations or theory.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #3", "review_assessment:_thoroughness_in_paper_reading": "I made a quick assessment of this paper.", "review": "The paper presents an auto completion for UI layout design. The authors formulate the problem as partial tree completion, and investigate a range of variations of layout decoders based on Transformer.\n\nThe paper proposes two models: Pointer and Recursive Transformer. The paper designs three sets of metrics to measure the quality of layout prediction based on the literature and the domain specifics of user interface interaction.\n\nThe writing quality is readable. The presentation is nice. The task of auto completion for UI layout design is relatively new.\n\nThe paper misses the key baseline in Bayesian optimisation using tree structure [1] which can perform the prediction under the tree-structure dependencies.\n\n[1] Jenatton, Rodolphe, et al. \"Bayesian optimization with tree-structured dependencies.\" Proceedings of the 34th International Conference on Machine Learning-Volume 70. JMLR. org, 2017.\n\nNB: the reviewer has low confidence in evaluating this paper.\n\n"}, "signatures": ["ICLR.cc/2020/Conference/Paper1065/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1065/AnonReviewer3"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["liyang@google.com", "jamelot@google.com", "zhouxin@google.com", "bengio@google.com", "sisidaisy@google.com"], "title": "Auto Completion of User Interface Layout Design Using Transformer-Based Tree Decoders", "authors": ["Yang Li", "Julien Amelot", "Xin Zhou", "Samy Bengio", "Si Si"], "pdf": "/pdf/c519dc2e6822402832559e72df741b99036ea998.pdf", "TL;DR": "The paper investigates several Transformer-based decoder models for predicting a complete layout given a partial layout tree.", "abstract": "It has been of increasing interest in the field to develop automatic machineries to facilitate the design process. In this paper, we focus on assisting graphical user interface (UI) layout design, a crucial task in app development. Given a partial layout, which a designer has entered, our model learns to complete the layout by predicting the remaining UI elements with a correct position and dimension as well as the hierarchical structures. Such automation will significantly ease the effort of UI designers and developers. While we focus on interface layout prediction, our model can be generally applicable for other layout prediction problems that involve tree structures and 2-dimensional placements. Particularly, we design two versions of Transformer-based tree decoders: Pointer and Recursive Transformer, and experiment with these models on a public dataset. We also propose several metrics for measuring the accuracy of tree prediction and ground these metrics in the domain of user experience. These contribute a new task and methods to deep learning research.", "keywords": ["Transformer", "decoder", "user interface", "layout design"], "paperhash": "li|auto_completion_of_user_interface_layout_design_using_transformerbased_tree_decoders", "original_pdf": "/attachment/e12710117527c1c613e8dad7f3f54a98cdbe3498.pdf", "_bibtex": "@misc{\nli2020auto,\ntitle={Auto Completion of User Interface Layout Design Using Transformer-Based Tree Decoders},\nauthor={Yang Li and Julien Amelot and Xin Zhou and Samy Bengio and Si Si},\nyear={2020},\nurl={https://openreview.net/forum?id=SylWNC4FPH}\n}"}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "SylWNC4FPH", "replyto": "SylWNC4FPH", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper1065/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper1065/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1574937091207, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper1065/Reviewers"], "noninvitees": [], "tcdate": 1570237742872, "tmdate": 1574937091218, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper1065/-/Official_Review"}}}, {"id": "H1g05tby5H", "original": null, "number": 2, "cdate": 1571916182417, "ddate": null, "tcdate": 1571916182417, "tmdate": 1572972517160, "tddate": null, "forum": "SylWNC4FPH", "replyto": "SylWNC4FPH", "invitation": "ICLR.cc/2020/Conference/Paper1065/-/Official_Review", "content": {"experience_assessment": "I have read many papers in this area.", "rating": "1: Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #1", "review_assessment:_checking_correctness_of_derivations_and_theory": "I carefully checked the derivations and theory.", "review": "This paper proposes an autocompletion model for UI layout based on adaptations of Transformers for tree structures and evaluates the models based on a few metrics on a public UI dataset.\n\nI like the area of research the authors are looking into and I think it's an important application. However, the paper doesn't answer key questions about both the application and the models:\n\n1) There is no clear rationale on why we need a new model based on Transformers for this task. What was wrong with LSTMs/GRUs as they've been used extensively for recursive problems including operations on trees? Similarly, I'd have expected baselines that included those models in the evaluation section showing the differences in performance between the newly proposed Transformer model for trees and previously used methods.\n\n2) The evaluation metrics used while borrowed from the language or IR fields doesn't seem to translate to UI design. UI layout is about visual and functional representation of an application so if one is seeking to evaluate different models, they need to relate to those."}, "signatures": ["ICLR.cc/2020/Conference/Paper1065/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1065/AnonReviewer1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["liyang@google.com", "jamelot@google.com", "zhouxin@google.com", "bengio@google.com", "sisidaisy@google.com"], "title": "Auto Completion of User Interface Layout Design Using Transformer-Based Tree Decoders", "authors": ["Yang Li", "Julien Amelot", "Xin Zhou", "Samy Bengio", "Si Si"], "pdf": "/pdf/c519dc2e6822402832559e72df741b99036ea998.pdf", "TL;DR": "The paper investigates several Transformer-based decoder models for predicting a complete layout given a partial layout tree.", "abstract": "It has been of increasing interest in the field to develop automatic machineries to facilitate the design process. In this paper, we focus on assisting graphical user interface (UI) layout design, a crucial task in app development. Given a partial layout, which a designer has entered, our model learns to complete the layout by predicting the remaining UI elements with a correct position and dimension as well as the hierarchical structures. Such automation will significantly ease the effort of UI designers and developers. While we focus on interface layout prediction, our model can be generally applicable for other layout prediction problems that involve tree structures and 2-dimensional placements. Particularly, we design two versions of Transformer-based tree decoders: Pointer and Recursive Transformer, and experiment with these models on a public dataset. We also propose several metrics for measuring the accuracy of tree prediction and ground these metrics in the domain of user experience. These contribute a new task and methods to deep learning research.", "keywords": ["Transformer", "decoder", "user interface", "layout design"], "paperhash": "li|auto_completion_of_user_interface_layout_design_using_transformerbased_tree_decoders", "original_pdf": "/attachment/e12710117527c1c613e8dad7f3f54a98cdbe3498.pdf", "_bibtex": "@misc{\nli2020auto,\ntitle={Auto Completion of User Interface Layout Design Using Transformer-Based Tree Decoders},\nauthor={Yang Li and Julien Amelot and Xin Zhou and Samy Bengio and Si Si},\nyear={2020},\nurl={https://openreview.net/forum?id=SylWNC4FPH}\n}"}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "SylWNC4FPH", "replyto": "SylWNC4FPH", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper1065/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper1065/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1574937091207, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper1065/Reviewers"], "noninvitees": [], "tcdate": 1570237742872, "tmdate": 1574937091218, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper1065/-/Official_Review"}}}, {"id": "r1edRi1-9r", "original": null, "number": 3, "cdate": 1572039631719, "ddate": null, "tcdate": 1572039631719, "tmdate": 1572972517115, "tddate": null, "forum": "SylWNC4FPH", "replyto": "SylWNC4FPH", "invitation": "ICLR.cc/2020/Conference/Paper1065/-/Official_Review", "content": {"experience_assessment": "I have read many papers in this area.", "rating": "3: Weak Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #2", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "Summary: This paper introduces the task of using deep learning for auto-completion in UI design. The basic idea is that given a partially completed tree (representing the design state of the UI), the goal is to predict or \"autocomplete\" the final tree. The authors propose a transformer-based solution to the task, considering three variants: a vanilla approach where the tree is flattened to a sequence, a pointer-network style approach, and a recursive transformer. Preliminary experiments indicate that the recursive model performs best and that the task is reasonable difficulty.\n\nAssessment: Overall, this is a borderline paper, as the task is interesting and novel, but the presentation is lacking in technical detail and there is a lack of novelty on the modeling side.\n\nIn particular, the authors spend a bulk of the paper describing the three different baselines they implement. However, despite the fact that most of the paper is dedicated to the explanation of these baselines. There is not sufficient detail to reproduce the models based on the paper alone. Indeed, without referencing the original Pointer Network and (and especially the) Transformer papers, it would not be possible to understand this paper at all. Further technical background and detail would drastically improve the paper. Moreover, it seems strange that significant space was used to give equations describing simple embedding lookups (i.e., matrix multiplications with one-hot vectors), but the basic technical foundations of Transformers were not adequately explained.  In addition, only the transformer baselines were considered, and it would seem natural to consider LSTM-based baselines, or some other related techniques.  In general, the space that was used to explain the Transformer baselines---which are essentially straightforward ways to adapt transformers to this task---could have been used to give more detail on the dataset. For example, one question is how often a single partial tree has multiple possible completions in the data. \n\nA major issue---mainly due to the lack of technical details and the lack of promise to provide code/data (unless I missed this)---is that the paper does not appear to be reproducible. Given the intent to have this be a new benchmark, ensuring reproducibility seems critical.\n\nReasons to accept:\n- Interesting new application of GNNs\n\nReasons to reject:\n- Incremental modeling contribution\n- Lack of sufficient technical detail on models and dataset\n- Does not appear to be reproducible \n\n"}, "signatures": ["ICLR.cc/2020/Conference/Paper1065/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1065/AnonReviewer2"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["liyang@google.com", "jamelot@google.com", "zhouxin@google.com", "bengio@google.com", "sisidaisy@google.com"], "title": "Auto Completion of User Interface Layout Design Using Transformer-Based Tree Decoders", "authors": ["Yang Li", "Julien Amelot", "Xin Zhou", "Samy Bengio", "Si Si"], "pdf": "/pdf/c519dc2e6822402832559e72df741b99036ea998.pdf", "TL;DR": "The paper investigates several Transformer-based decoder models for predicting a complete layout given a partial layout tree.", "abstract": "It has been of increasing interest in the field to develop automatic machineries to facilitate the design process. In this paper, we focus on assisting graphical user interface (UI) layout design, a crucial task in app development. Given a partial layout, which a designer has entered, our model learns to complete the layout by predicting the remaining UI elements with a correct position and dimension as well as the hierarchical structures. Such automation will significantly ease the effort of UI designers and developers. While we focus on interface layout prediction, our model can be generally applicable for other layout prediction problems that involve tree structures and 2-dimensional placements. Particularly, we design two versions of Transformer-based tree decoders: Pointer and Recursive Transformer, and experiment with these models on a public dataset. We also propose several metrics for measuring the accuracy of tree prediction and ground these metrics in the domain of user experience. These contribute a new task and methods to deep learning research.", "keywords": ["Transformer", "decoder", "user interface", "layout design"], "paperhash": "li|auto_completion_of_user_interface_layout_design_using_transformerbased_tree_decoders", "original_pdf": "/attachment/e12710117527c1c613e8dad7f3f54a98cdbe3498.pdf", "_bibtex": "@misc{\nli2020auto,\ntitle={Auto Completion of User Interface Layout Design Using Transformer-Based Tree Decoders},\nauthor={Yang Li and Julien Amelot and Xin Zhou and Samy Bengio and Si Si},\nyear={2020},\nurl={https://openreview.net/forum?id=SylWNC4FPH}\n}"}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "SylWNC4FPH", "replyto": "SylWNC4FPH", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper1065/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper1065/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1574937091207, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper1065/Reviewers"], "noninvitees": [], "tcdate": 1570237742872, "tmdate": 1574937091218, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper1065/-/Official_Review"}}}], "count": 8}