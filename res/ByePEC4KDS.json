{"notes": [{"id": "ByePEC4KDS", "original": "HygvD4LdPH", "number": 1078, "cdate": 1569439278896, "ddate": null, "tcdate": 1569439278896, "tmdate": 1577168282936, "tddate": null, "forum": "ByePEC4KDS", "replyto": null, "invitation": "ICLR.cc/2020/Conference/-/Blind_Submission", "content": {"title": "Situating Sentence Embedders with Nearest Neighbor Overlap", "authors": ["Lucy H. Lin", "Noah A. Smith"], "authorids": ["lucylin@cs.washington.edu", "nasmith@cs.washington.edu"], "keywords": ["sentence embeddings", "nearest neighbors", "semantic similarity"], "TL;DR": "We propose nearest neighbor overlap, a procedure which quantifies similarity between embedders in a task-agnostic manner, and use it to compare 21 sentence embedders.", "abstract": "As distributed approaches to natural language semantics have developed and diversified, embedders for linguistic units larger than words (e.g., sentences) have come to play an increasingly important role.  To date, such embedders have been evaluated using benchmark tasks (e.g., GLUE) and linguistic probes.  We propose a comparative approach, nearest neighbor overlap (N2O), that quantifies similarity between embedders in a task-agnostic manner.  N2O requires only a collection of examples and is simple to understand: two embedders are more similar if, for the same set of inputs, there is greater overlap between the inputs' nearest neighbors.  We use N2O to compare 21 sentence embedders and show the effects of different design choices and architectures.", "pdf": "/pdf/74799ce8c0253ae859d56cb64466b7a70d599771.pdf", "paperhash": "lin|situating_sentence_embedders_with_nearest_neighbor_overlap", "original_pdf": "/attachment/74799ce8c0253ae859d56cb64466b7a70d599771.pdf", "_bibtex": "@misc{\nlin2020situating,\ntitle={Situating Sentence Embedders with Nearest Neighbor Overlap},\nauthor={Lucy H. Lin and Noah A. Smith},\nyear={2020},\nurl={https://openreview.net/forum?id=ByePEC4KDS}\n}"}, "signatures": ["ICLR.cc/2020/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference"], "details": {"replyCount": 6, "writable": false, "overwriting": [], "revisions": false, "tags": [], "invitation": {"reply": {"readers": {"values-regex": ".*"}, "writers": {"values": ["ICLR.cc/2020/Conference"]}, "signatures": {"values": ["ICLR.cc/2020/Conference"]}, "content": {"spotlight_video": {"value-regex": ".*"}, "full_presentation_video": {"value-regex": ".*"}, "original_pdf": {"required": false, "description": "Upload a PDF file that ends with .pdf", "value-regex": ".*"}, "appendix": {"value-regex": ".*"}, "authorids": {"values-regex": ".*"}, "poster": {"value-regex": ".*"}, "authors": {"values": ["Anonymous"]}, "slides": {"value-regex": ".*"}}}, "final": [], "signatures": ["ICLR.cc/2020/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference"], "noninvitees": [], "tcdate": 1569271260237, "tmdate": 1593459412141, "id": "ICLR.cc/2020/Conference/-/Blind_Submission"}}, "tauthor": "OpenReview.net"}, {"id": "_o8AzJts-O", "original": null, "number": 1, "cdate": 1576798713953, "ddate": null, "tcdate": 1576798713953, "tmdate": 1576800922527, "tddate": null, "forum": "ByePEC4KDS", "replyto": "ByePEC4KDS", "invitation": "ICLR.cc/2020/Conference/Paper1078/-/Decision", "content": {"decision": "Reject", "comment": "This paper proposes to analyze the space of known sentence-to-vector functions by comparing the ways in which they induce nearest neighbor lists in a text corpus.\n\nThe primary results of the study are somewhat unclear, and the reviewers do not find the method to be novel enough\u2014or sufficiently well motivated a priori\u2014to warrant publication in spite of these results.", "title": "Paper Decision"}, "signatures": ["ICLR.cc/2020/Conference/Program_Chairs"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Program_Chairs"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Situating Sentence Embedders with Nearest Neighbor Overlap", "authors": ["Lucy H. Lin", "Noah A. Smith"], "authorids": ["lucylin@cs.washington.edu", "nasmith@cs.washington.edu"], "keywords": ["sentence embeddings", "nearest neighbors", "semantic similarity"], "TL;DR": "We propose nearest neighbor overlap, a procedure which quantifies similarity between embedders in a task-agnostic manner, and use it to compare 21 sentence embedders.", "abstract": "As distributed approaches to natural language semantics have developed and diversified, embedders for linguistic units larger than words (e.g., sentences) have come to play an increasingly important role.  To date, such embedders have been evaluated using benchmark tasks (e.g., GLUE) and linguistic probes.  We propose a comparative approach, nearest neighbor overlap (N2O), that quantifies similarity between embedders in a task-agnostic manner.  N2O requires only a collection of examples and is simple to understand: two embedders are more similar if, for the same set of inputs, there is greater overlap between the inputs' nearest neighbors.  We use N2O to compare 21 sentence embedders and show the effects of different design choices and architectures.", "pdf": "/pdf/74799ce8c0253ae859d56cb64466b7a70d599771.pdf", "paperhash": "lin|situating_sentence_embedders_with_nearest_neighbor_overlap", "original_pdf": "/attachment/74799ce8c0253ae859d56cb64466b7a70d599771.pdf", "_bibtex": "@misc{\nlin2020situating,\ntitle={Situating Sentence Embedders with Nearest Neighbor Overlap},\nauthor={Lucy H. Lin and Noah A. Smith},\nyear={2020},\nurl={https://openreview.net/forum?id=ByePEC4KDS}\n}"}, "tags": [], "invitation": {"reply": {"writers": {"description": "How your identity will be displayed.", "values-regex": ["ICLR.cc/2020/Conference/Program_Chairs"]}, "signatures": {"values": ["ICLR.cc/2020/Conference/Program_Chairs"], "description": "How your identity will be displayed."}, "content": {"decision": {"value-radio": ["Accept (Spotlight)", "Accept (Talk)", "Accept (Poster)", "Reject"], "description": "Decision", "required": true, "order": 2}, "title": {"value": "Paper Decision", "required": true, "order": 1}, "comment": {"value-regex": "[\\S\\s]{0,5000}", "description": "", "required": false, "order": 3}}, "forum": "ByePEC4KDS", "replyto": "ByePEC4KDS", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}}, "expdate": 1576854540000, "duedate": 1576853940000, "multiReply": false, "readers": ["everyone"], "invitees": ["ICLR.cc/2020/Conference/Program_Chairs"], "tcdate": 1576795727765, "tmdate": 1576800280062, "super": "ICLR.cc/2020/Conference/-/Decision", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper1078/-/Decision"}}}, {"id": "SkxzoaQniS", "original": null, "number": 2, "cdate": 1573825945905, "ddate": null, "tcdate": 1573825945905, "tmdate": 1573825945905, "tddate": null, "forum": "ByePEC4KDS", "replyto": "HyglRomisr", "invitation": "ICLR.cc/2020/Conference/Paper1078/-/Official_Comment", "content": {"title": "Does a high N2O scores really lead to similar downstream behavior?", "comment": "Thanks a lot for your reply!\n\nI think a key point here is the statement: \"N2O can identify when two embedders are functionally similar and therefore not worth both exploring.\", which also summarizes the main claim/purpose of the paper.\n\nThis statement is not substantiated by the experiments in the paper, because embeddings are usually used as input for a (potentially non-linear) layer/network. Hence, a high cosine similarity between two embedders A and B does not necessarily indicate that A and B will behave similarly in a downstream task. It would be great if you add an analysis to the paper to which extent a high cosine similarity (i.e. a high N2O score) indicates similar behavior in downstream tasks."}, "signatures": ["ICLR.cc/2020/Conference/Paper1078/AnonReviewer4"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1078/AnonReviewer4", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Situating Sentence Embedders with Nearest Neighbor Overlap", "authors": ["Lucy H. Lin", "Noah A. Smith"], "authorids": ["lucylin@cs.washington.edu", "nasmith@cs.washington.edu"], "keywords": ["sentence embeddings", "nearest neighbors", "semantic similarity"], "TL;DR": "We propose nearest neighbor overlap, a procedure which quantifies similarity between embedders in a task-agnostic manner, and use it to compare 21 sentence embedders.", "abstract": "As distributed approaches to natural language semantics have developed and diversified, embedders for linguistic units larger than words (e.g., sentences) have come to play an increasingly important role.  To date, such embedders have been evaluated using benchmark tasks (e.g., GLUE) and linguistic probes.  We propose a comparative approach, nearest neighbor overlap (N2O), that quantifies similarity between embedders in a task-agnostic manner.  N2O requires only a collection of examples and is simple to understand: two embedders are more similar if, for the same set of inputs, there is greater overlap between the inputs' nearest neighbors.  We use N2O to compare 21 sentence embedders and show the effects of different design choices and architectures.", "pdf": "/pdf/74799ce8c0253ae859d56cb64466b7a70d599771.pdf", "paperhash": "lin|situating_sentence_embedders_with_nearest_neighbor_overlap", "original_pdf": "/attachment/74799ce8c0253ae859d56cb64466b7a70d599771.pdf", "_bibtex": "@misc{\nlin2020situating,\ntitle={Situating Sentence Embedders with Nearest Neighbor Overlap},\nauthor={Lucy H. Lin and Noah A. Smith},\nyear={2020},\nurl={https://openreview.net/forum?id=ByePEC4KDS}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "ByePEC4KDS", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper1078/Authors", "ICLR.cc/2020/Conference/Paper1078/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper1078/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper1078/Reviewers", "ICLR.cc/2020/Conference/Paper1078/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper1078/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper1078/Authors|ICLR.cc/2020/Conference/Paper1078/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504161601, "tmdate": 1576860534287, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper1078/Authors", "ICLR.cc/2020/Conference/Paper1078/Reviewers", "ICLR.cc/2020/Conference/Paper1078/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper1078/-/Official_Comment"}}}, {"id": "HyglRomisr", "original": null, "number": 1, "cdate": 1573759943686, "ddate": null, "tcdate": 1573759943686, "tmdate": 1573759943686, "tddate": null, "forum": "ByePEC4KDS", "replyto": "ByePEC4KDS", "invitation": "ICLR.cc/2020/Conference/Paper1078/-/Official_Comment", "content": {"title": "Author response", "comment": "Thank you all for your feedback! Some general comments:\n\n* Correlation with downstream performance: Because embeddings are used in a wide variety of downstream tasks, we don\u2019t expect (or want to impose) a single notion of \u201cquality.\u201d Taking a comparative approach like N2O helps us understand to what extent embedders are behaving similarly in the context of a target corpus; this is helpful, for example, in checking whether a new method is comparable to existing ones (high N2O).  More concretely, one could use N2O to decide which (small) subset out of the many different sentence embedders are worth comparing in a more expensive human evaluation or expensive search among methods.  N2O can identify when two embedders are functionally similar and therefore not worth both exploring.\n\n* Use of cosine similarity: There are certainly other distance metrics we could try. We use cosine in this paper because it is the most frequently used in practice (it is the default in spacy and gensim, among other libraries).\n\n    We agree that many embedders are not trained on similarity objectives, but nonetheless a common *expectation* of sentence embeddings is that distance is meaningful and semantic similarity <=> nearness in vector space. (See, for example, frequent questions on this matter in the BERT github issues.)  Direct comparison between sentence embeddings is useful in its own right for tasks like open-domain question answering, IE, and IR (e.g., for quickly identifying candidate spans), and has also seen increased use in computational social science analyses.\n\n* Other ranking schemes: In general, we minimized the number of N2O hyperparameters where possible (e.g., weighting scheme by sentence rank or distance-based thresholding) to avoid premature assumptions about the embedding spaces & distortion of the results -- we view simplicity as a strength here. "}, "signatures": ["ICLR.cc/2020/Conference/Paper1078/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1078/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Situating Sentence Embedders with Nearest Neighbor Overlap", "authors": ["Lucy H. Lin", "Noah A. Smith"], "authorids": ["lucylin@cs.washington.edu", "nasmith@cs.washington.edu"], "keywords": ["sentence embeddings", "nearest neighbors", "semantic similarity"], "TL;DR": "We propose nearest neighbor overlap, a procedure which quantifies similarity between embedders in a task-agnostic manner, and use it to compare 21 sentence embedders.", "abstract": "As distributed approaches to natural language semantics have developed and diversified, embedders for linguistic units larger than words (e.g., sentences) have come to play an increasingly important role.  To date, such embedders have been evaluated using benchmark tasks (e.g., GLUE) and linguistic probes.  We propose a comparative approach, nearest neighbor overlap (N2O), that quantifies similarity between embedders in a task-agnostic manner.  N2O requires only a collection of examples and is simple to understand: two embedders are more similar if, for the same set of inputs, there is greater overlap between the inputs' nearest neighbors.  We use N2O to compare 21 sentence embedders and show the effects of different design choices and architectures.", "pdf": "/pdf/74799ce8c0253ae859d56cb64466b7a70d599771.pdf", "paperhash": "lin|situating_sentence_embedders_with_nearest_neighbor_overlap", "original_pdf": "/attachment/74799ce8c0253ae859d56cb64466b7a70d599771.pdf", "_bibtex": "@misc{\nlin2020situating,\ntitle={Situating Sentence Embedders with Nearest Neighbor Overlap},\nauthor={Lucy H. Lin and Noah A. Smith},\nyear={2020},\nurl={https://openreview.net/forum?id=ByePEC4KDS}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "ByePEC4KDS", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper1078/Authors", "ICLR.cc/2020/Conference/Paper1078/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper1078/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper1078/Reviewers", "ICLR.cc/2020/Conference/Paper1078/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper1078/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper1078/Authors|ICLR.cc/2020/Conference/Paper1078/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504161601, "tmdate": 1576860534287, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper1078/Authors", "ICLR.cc/2020/Conference/Paper1078/Reviewers", "ICLR.cc/2020/Conference/Paper1078/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper1078/-/Official_Comment"}}}, {"id": "SyeEdLChFS", "original": null, "number": 1, "cdate": 1571772012258, "ddate": null, "tcdate": 1571772012258, "tmdate": 1572972515491, "tddate": null, "forum": "ByePEC4KDS", "replyto": "ByePEC4KDS", "invitation": "ICLR.cc/2020/Conference/Paper1078/-/Official_Review", "content": {"experience_assessment": "I have read many papers in this area.", "rating": "3: Weak Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #3", "review_assessment:_checking_correctness_of_derivations_and_theory": "I carefully checked the derivations and theory.", "review": "\nThe paper proposes N2O, a tool for probing the similarity among sentence embedders. Given two sentence embedders, N2O measures the amount of overlap of the k-nearest neighbor sets reported by the two embedders, averaged over a sample of probing queries. Cosine similarity is used as the similarity metric. The paper computes all-pair N2O scores for common sentence embedders and analyzes the results.\n\nOverall, while the idea of probing similarity between embedders is interesting, the paper has the following weaknesses:\n\n- The use of neighbor overlap to compare embedders has precedence in the context of word embeddings [https://www.aclweb.org/anthology/C16-1262/ | https://hal.archives-ouvertes.fr/hal-01806468/ | https://www.aclweb.org/anthology/Q18-1008/]. The methods in these works are mostly identical to N2O with some minor variations (e.g., using Jaccard distance).\n\n- Using an existing method is justified if it provides new insights for the new setting. However, the results do not offer a lot of new insights. The fact that static embeddings, ELMo, and BERT give different neighbors is unsurprising. (The paper even admitted this.) Moreover, since sentence embedders are usually used as features when fine-tuned on downstream tasks, the importance of observations based on the pre-fine-tuned models is unclear. Contrast this with the work on word embedding similarity. Since some research areas (e.g., social science) directly use the similarity of word embeddings to conclude findings, the insights of how different word embeddings behave are more directly applicable.\n\n- The paper does address some design choices, such as the number of neighbors and the number of probing queries, showing that different choices have little effects on the scores. However, the use of cosine similarity is problematic. As noted in the paper, some embedders such as ELMo were not trained on similarity objectives. BERT does have the next-sentence task, but the sparse attention-based architecture does not necessarily push similar sentences to have low cosine similarity.\n\nAdditional comments and questions:\n\n- Instead of using the amount of overlap for a fixed k, it would be nice to have a metric that captures the whole distribution. For instance, maybe two embedders disagree on the first 20 neighbors, but end up retrieving the same set when considering 50 neighbors. The current overlap-based metric cannot capture such a phenomenon.\n\n- Page 2: The method is technically not task-agnostic --- the task is sentence similarity with respect to a specific corpus.\n\n- The paper tests variants of the same embedders by training on different corpora, with the conclusion that mismatched corpora give lower N2O scores. What is the N2O between two embedders of the same type trained on the same corpora but with different seeds?"}, "signatures": ["ICLR.cc/2020/Conference/Paper1078/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1078/AnonReviewer3"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Situating Sentence Embedders with Nearest Neighbor Overlap", "authors": ["Lucy H. Lin", "Noah A. Smith"], "authorids": ["lucylin@cs.washington.edu", "nasmith@cs.washington.edu"], "keywords": ["sentence embeddings", "nearest neighbors", "semantic similarity"], "TL;DR": "We propose nearest neighbor overlap, a procedure which quantifies similarity between embedders in a task-agnostic manner, and use it to compare 21 sentence embedders.", "abstract": "As distributed approaches to natural language semantics have developed and diversified, embedders for linguistic units larger than words (e.g., sentences) have come to play an increasingly important role.  To date, such embedders have been evaluated using benchmark tasks (e.g., GLUE) and linguistic probes.  We propose a comparative approach, nearest neighbor overlap (N2O), that quantifies similarity between embedders in a task-agnostic manner.  N2O requires only a collection of examples and is simple to understand: two embedders are more similar if, for the same set of inputs, there is greater overlap between the inputs' nearest neighbors.  We use N2O to compare 21 sentence embedders and show the effects of different design choices and architectures.", "pdf": "/pdf/74799ce8c0253ae859d56cb64466b7a70d599771.pdf", "paperhash": "lin|situating_sentence_embedders_with_nearest_neighbor_overlap", "original_pdf": "/attachment/74799ce8c0253ae859d56cb64466b7a70d599771.pdf", "_bibtex": "@misc{\nlin2020situating,\ntitle={Situating Sentence Embedders with Nearest Neighbor Overlap},\nauthor={Lucy H. Lin and Noah A. Smith},\nyear={2020},\nurl={https://openreview.net/forum?id=ByePEC4KDS}\n}"}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "ByePEC4KDS", "replyto": "ByePEC4KDS", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper1078/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper1078/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1575059584177, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper1078/Reviewers"], "noninvitees": [], "tcdate": 1570237742682, "tmdate": 1575059584189, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper1078/-/Official_Review"}}}, {"id": "r1xgsDq6KB", "original": null, "number": 2, "cdate": 1571821463669, "ddate": null, "tcdate": 1571821463669, "tmdate": 1572972515449, "tddate": null, "forum": "ByePEC4KDS", "replyto": "ByePEC4KDS", "invitation": "ICLR.cc/2020/Conference/Paper1078/-/Official_Review", "content": {"experience_assessment": "I have published in this field for several years.", "rating": "1: Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #1", "review_assessment:_checking_correctness_of_derivations_and_theory": "I carefully checked the derivations and theory.", "review": "The paper provides a method/metric for comparing sentence embedders, based on a nearest neighbor analysis. The method is straightforward: sample a sentence, embed the sentence and lots of sentences from a corpus, find the k nearest neighbors in the corpus to the sampled sentence, do the same for another embedder, calculate the overlap of the two sets of nearest neighbors.\n\nThe paper is commendably clear and easy to read.\n\nThe main problems I have with the paper are twofold: 1) it's not clear this is enough of a contribution for a top-tier ML conference; and 2) it's not clear what I do with the results.\n\nI think the idea of analysing embedders in this way is potentially interesting, but it feels like the paper needs more. This analysis could be a great section in another paper (e.g. one which proposes another embedding method); or perhaps it could be extended in some way, so that the current content only takes up 1/2 the space, and then there's 1/2 the paper showing how useful this analysis is, for e.g. building better embedders for particular tasks.\n\nThe abstract starts by talking about how embedders have been evaluated using various benchmarks, and hints at the idea that this new comparative approach could be an alternative. But the new method can't really be used for evaluation: I don't come away from the paper knowing whether embedding method A is better than method B, only that A is more like B than C.\n\nI think the problem with the paper as it stands is neatly summed up in the conclusion of the paper, which isn't a conclusion at all: it's just a mini-abstract. I'd like to know what readers should take away from the results, so that they can potentially build better embedders.\n\nI've given the paper a 1. rating only because I really don't think it's ready for a full ICLR paper, not because I think the method is uninteresting or useless. On the contrary, with some more work and thought about how the analysis could be used, this could be a potentially useful tool."}, "signatures": ["ICLR.cc/2020/Conference/Paper1078/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1078/AnonReviewer1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Situating Sentence Embedders with Nearest Neighbor Overlap", "authors": ["Lucy H. Lin", "Noah A. Smith"], "authorids": ["lucylin@cs.washington.edu", "nasmith@cs.washington.edu"], "keywords": ["sentence embeddings", "nearest neighbors", "semantic similarity"], "TL;DR": "We propose nearest neighbor overlap, a procedure which quantifies similarity between embedders in a task-agnostic manner, and use it to compare 21 sentence embedders.", "abstract": "As distributed approaches to natural language semantics have developed and diversified, embedders for linguistic units larger than words (e.g., sentences) have come to play an increasingly important role.  To date, such embedders have been evaluated using benchmark tasks (e.g., GLUE) and linguistic probes.  We propose a comparative approach, nearest neighbor overlap (N2O), that quantifies similarity between embedders in a task-agnostic manner.  N2O requires only a collection of examples and is simple to understand: two embedders are more similar if, for the same set of inputs, there is greater overlap between the inputs' nearest neighbors.  We use N2O to compare 21 sentence embedders and show the effects of different design choices and architectures.", "pdf": "/pdf/74799ce8c0253ae859d56cb64466b7a70d599771.pdf", "paperhash": "lin|situating_sentence_embedders_with_nearest_neighbor_overlap", "original_pdf": "/attachment/74799ce8c0253ae859d56cb64466b7a70d599771.pdf", "_bibtex": "@misc{\nlin2020situating,\ntitle={Situating Sentence Embedders with Nearest Neighbor Overlap},\nauthor={Lucy H. Lin and Noah A. Smith},\nyear={2020},\nurl={https://openreview.net/forum?id=ByePEC4KDS}\n}"}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "ByePEC4KDS", "replyto": "ByePEC4KDS", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper1078/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper1078/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1575059584177, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper1078/Reviewers"], "noninvitees": [], "tcdate": 1570237742682, "tmdate": 1575059584189, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper1078/-/Official_Review"}}}, {"id": "S1eHKnBw5r", "original": null, "number": 3, "cdate": 1572457596983, "ddate": null, "tcdate": 1572457596983, "tmdate": 1572972515407, "tddate": null, "forum": "ByePEC4KDS", "replyto": "ByePEC4KDS", "invitation": "ICLR.cc/2020/Conference/Paper1078/-/Official_Review", "content": {"experience_assessment": "I have read many papers in this area.", "rating": "1: Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #4", "review_assessment:_checking_correctness_of_derivations_and_theory": "N/A", "review": "The paper proposes a method to estimate the similarity of sentence embedders called N2O with the goal to better inform embedder choice in downstream applications. For two embedders A and B, N2O samples sentences called queries from a corpus, uses A and B to compute embeddings for each sentence, determines the k nearest neighbors (= other sentences from the corpus) for each sentence, and computes the overlap of the resulting sets of neighbors. Nearest neighbors are computed with Cosine similarity.\n\nThe paper should be rejected, mainly because the proposed method is not appropriate to inform embedder choices as claimed by the paper.\n\nI doubt that the results from this paper can be used to make better embedder choices. The paper measures which embedders are similar in a specific way, but this does not tell us much about the performance in downstream tasks. Only based on the N2O measure, no informed decision can be made which embedder will perform well on a given task. Hence, the approach is not well motivated. Evaluation metrics such as the GLUE benchmark or SentEval provide much more information what we can expect from specific embedders. Hence, I think the results in the paper are only interesting to very few readers. Furthermore, the paper uses Cosine similarity to compute the similarity between embedders. However, embeddings are often not used directly, but used as input for a model (e.g. a neural network), which learns to predict something based on the embeddings. Hence, two embedders which are similar according to N2O may perform differently in downstream tasks.\n\nTo improve the paper, I recommend to test whether the N2O similarity correlates well with downstream performance. Concretely, the paper should clearly answer the question whether we can predict the downstream performance of an embedder A given its N2O similarity to an embedder B and the downstream performance of B. Furthermore, I recommend to also use other metrics to compute the distances between embeddings, and not only Cosine similarity. Th robustness and relevance of the findings is much higher if the findings are consistent across many different metrics. Instead of computing the overlap of the neighbors for different values of k, the paper could also use ranking measures to estimate the similarity of embedders. Furthermore, I think this paper fits much better to a conference focused on natural language processing. \n\nQuestions:\n1. The paper claims that N2O can be used to inform embedder choices. Based on the main results in Figure 3, how can this help to decide which embedder to use for my task at hand?"}, "signatures": ["ICLR.cc/2020/Conference/Paper1078/AnonReviewer4"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1078/AnonReviewer4"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Situating Sentence Embedders with Nearest Neighbor Overlap", "authors": ["Lucy H. Lin", "Noah A. Smith"], "authorids": ["lucylin@cs.washington.edu", "nasmith@cs.washington.edu"], "keywords": ["sentence embeddings", "nearest neighbors", "semantic similarity"], "TL;DR": "We propose nearest neighbor overlap, a procedure which quantifies similarity between embedders in a task-agnostic manner, and use it to compare 21 sentence embedders.", "abstract": "As distributed approaches to natural language semantics have developed and diversified, embedders for linguistic units larger than words (e.g., sentences) have come to play an increasingly important role.  To date, such embedders have been evaluated using benchmark tasks (e.g., GLUE) and linguistic probes.  We propose a comparative approach, nearest neighbor overlap (N2O), that quantifies similarity between embedders in a task-agnostic manner.  N2O requires only a collection of examples and is simple to understand: two embedders are more similar if, for the same set of inputs, there is greater overlap between the inputs' nearest neighbors.  We use N2O to compare 21 sentence embedders and show the effects of different design choices and architectures.", "pdf": "/pdf/74799ce8c0253ae859d56cb64466b7a70d599771.pdf", "paperhash": "lin|situating_sentence_embedders_with_nearest_neighbor_overlap", "original_pdf": "/attachment/74799ce8c0253ae859d56cb64466b7a70d599771.pdf", "_bibtex": "@misc{\nlin2020situating,\ntitle={Situating Sentence Embedders with Nearest Neighbor Overlap},\nauthor={Lucy H. Lin and Noah A. Smith},\nyear={2020},\nurl={https://openreview.net/forum?id=ByePEC4KDS}\n}"}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "ByePEC4KDS", "replyto": "ByePEC4KDS", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper1078/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper1078/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1575059584177, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper1078/Reviewers"], "noninvitees": [], "tcdate": 1570237742682, "tmdate": 1575059584189, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper1078/-/Official_Review"}}}], "count": 7}