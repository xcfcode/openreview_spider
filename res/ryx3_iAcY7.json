{"notes": [{"id": "ryx3_iAcY7", "original": "S1xXrCoOF7", "number": 390, "cdate": 1538087795953, "ddate": null, "tcdate": 1538087795953, "tmdate": 1545355397664, "tddate": null, "forum": "ryx3_iAcY7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Contextualized Role Interaction for Neural Machine Translation", "abstract": "Word inputs tend to be represented as single continuous vectors in deep neural networks. It is left to the subsequent layers of the network to extract relevant aspects of a word's meaning based on the context in which it appears. In this paper, we investigate whether word representations can be improved by explicitly incorporating the idea of latent roles. That is, we propose a role interaction layer (RIL) that consists of context-dependent (latent) role assignments and role-specific transformations. We evaluate the RIL on machine translation using two language pairs (En-De and En-Fi) and three datasets of varying size. We find that the proposed mechanism improves translation quality over strong baselines with limited amounts of data, but that the improvement diminishes as the size of data grows, indicating that powerful neural MT systems are capable of implicitly modeling role-word interaction by themselves. Our qualitative analysis reveals that the RIL extracts meaningful context-dependent roles and that it allows us to inspect more deeply the internal mechanisms of state-of-the-art neural machine translation systems.", "keywords": ["Neural Machine Translation", "Natural Language Processing"], "authorids": ["dirk.weissenborn@gmail.com", "dkiela@fb.com", "jase@fb.com", "kyunghyun.cho@nyu.edu"], "authors": ["Dirk Weissenborn", "Douwe Kiela", "Jason Weston", "Kyunghyun Cho"], "TL;DR": "We propose a role interaction layer that explicitly models the modulation of token representations by contextualized roles.", "pdf": "/pdf/6b6b523e7619e51cc0ba56eab35e7ab9853dcfc7.pdf", "paperhash": "weissenborn|contextualized_role_interaction_for_neural_machine_translation", "_bibtex": "@misc{\nweissenborn2019contextualized,\ntitle={Contextualized Role Interaction for Neural Machine Translation},\nauthor={Dirk Weissenborn and Douwe Kiela and Jason Weston and Kyunghyun Cho},\nyear={2019},\nurl={https://openreview.net/forum?id=ryx3_iAcY7},\n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"replyCount": 9, "writable": false, "overwriting": [], "revisions": false, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Blind_Submission", "rdate": null, "ddate": null, "expdate": null, "duedate": 1538085600000, "tmdate": 1538142958393, "tddate": null, "super": null, "final": null, "reply": {"signatures": {"values": ["ICLR.cc/2019/Conference"]}, "forum": null, "readers": {"values": ["everyone"]}, "replyto": null, "content": {"authorids": {"values-regex": ".*"}, "authors": {"values": ["Anonymous"]}}, "writers": {"values": ["ICLR.cc/2019/Conference"]}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["~"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": null, "taskCompletionCount": null, "transform": null, "cdate": 1538142958393}}, "tauthor": "OpenReview.net"}, {"id": "ryg-jRIleN", "original": null, "number": 1, "cdate": 1544740504733, "ddate": null, "tcdate": 1544740504733, "tmdate": 1545354514228, "tddate": null, "forum": "ryx3_iAcY7", "replyto": "ryx3_iAcY7", "invitation": "ICLR.cc/2019/Conference/-/Paper390/Meta_Review", "content": {"metareview": "This paper proposes to improve MT with a specialized encoder component that models roles. It shows some improvements in low-resource scenarios.\n\nOverall, reviewers felt there were two issues with the paper: clarity of description of the contribution, and also the fact that the method itself was not seeing large empirical gains. On top of this, the method adds some additional complexity on top of the original model.\n\nGiven that no reviewer was strongly in favor of the paper, I am not going to recommend acceptance at this time.", "confidence": "4: The area chair is confident but not absolutely certain", "recommendation": "Reject", "title": "Some clarity issues, and improvements underwhelming"}, "signatures": ["ICLR.cc/2019/Conference/Paper390/Area_Chair1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference/Paper390/Area_Chair1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Contextualized Role Interaction for Neural Machine Translation", "abstract": "Word inputs tend to be represented as single continuous vectors in deep neural networks. It is left to the subsequent layers of the network to extract relevant aspects of a word's meaning based on the context in which it appears. In this paper, we investigate whether word representations can be improved by explicitly incorporating the idea of latent roles. That is, we propose a role interaction layer (RIL) that consists of context-dependent (latent) role assignments and role-specific transformations. We evaluate the RIL on machine translation using two language pairs (En-De and En-Fi) and three datasets of varying size. We find that the proposed mechanism improves translation quality over strong baselines with limited amounts of data, but that the improvement diminishes as the size of data grows, indicating that powerful neural MT systems are capable of implicitly modeling role-word interaction by themselves. Our qualitative analysis reveals that the RIL extracts meaningful context-dependent roles and that it allows us to inspect more deeply the internal mechanisms of state-of-the-art neural machine translation systems.", "keywords": ["Neural Machine Translation", "Natural Language Processing"], "authorids": ["dirk.weissenborn@gmail.com", "dkiela@fb.com", "jase@fb.com", "kyunghyun.cho@nyu.edu"], "authors": ["Dirk Weissenborn", "Douwe Kiela", "Jason Weston", "Kyunghyun Cho"], "TL;DR": "We propose a role interaction layer that explicitly models the modulation of token representations by contextualized roles.", "pdf": "/pdf/6b6b523e7619e51cc0ba56eab35e7ab9853dcfc7.pdf", "paperhash": "weissenborn|contextualized_role_interaction_for_neural_machine_translation", "_bibtex": "@misc{\nweissenborn2019contextualized,\ntitle={Contextualized Role Interaction for Neural Machine Translation},\nauthor={Dirk Weissenborn and Douwe Kiela and Jason Weston and Kyunghyun Cho},\nyear={2019},\nurl={https://openreview.net/forum?id=ryx3_iAcY7},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper390/Meta_Review", "rdate": null, "ddate": null, "expdate": null, "duedate": 1541548800000, "tmdate": 1545353233508, "tddate": null, "super": null, "final": null, "reply": {"forum": "ryx3_iAcY7", "replyto": "ryx3_iAcY7", "readers": {"description": "Select all user groups that should be able to read this comment. Selecting 'All Users' will allow paper authors, reviewers, area chairs, and program chairs to view this comment.", "values": ["everyone"]}, "signatures": {"description": "How your identity will be displayed with the above content.", "values-regex": "ICLR.cc/2019/Conference/Paper390/Area_Chair[0-9]+"}, "writers": {"description": "Users that may modify this record.", "values-regex": "ICLR.cc/2019/Conference/Paper390/Area_Chair[0-9]+"}, "content": {"title": {"order": 1, "value-regex": ".{1,500}", "description": "Brief summary of your review.", "required": true}, "metareview": {"order": 2, "value-regex": "[\\S\\s]{1,5000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "required": true}, "recommendation": {"order": 3, "value-dropdown": ["Accept (Oral)", "Accept (Poster)", "Reject"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The area chair is absolutely certain", "4: The area chair is confident but not absolutely certain", "3: The area chair is somewhat confident", "2: The area chair is not sure", "1: The area chair's evaluation is an educated guess"], "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper390/Area_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": false, "taskCompletionCount": null, "transform": null, "cdate": 1545353233508}}}, {"id": "rJeEvtKFAQ", "original": null, "number": 6, "cdate": 1543244123732, "ddate": null, "tcdate": 1543244123732, "tmdate": 1543244123732, "tddate": null, "forum": "ryx3_iAcY7", "replyto": "r1x3n_uZam", "invitation": "ICLR.cc/2019/Conference/-/Paper390/Official_Comment", "content": {"title": "Response to the rebuttal", "comment": "Thank you for the response.\n\nAccording to the authours' response,  now I understand that the proposed method is mainly for the \"low-data regime.\"\nHowever, we cannot find this kind of descriptions in the submitted version.\nI believe that this paper should be re-organized to clarify the primal goal (or motivation) of the proposed method as I wrote in the first review.\n\nThere is no additional information that I should consider to improve the overall recommendation score.\nTherefore, I decided to keep my score unchanged.\n"}, "signatures": ["ICLR.cc/2019/Conference/Paper390/AnonReviewer1"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper390/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper390/AnonReviewer1", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Contextualized Role Interaction for Neural Machine Translation", "abstract": "Word inputs tend to be represented as single continuous vectors in deep neural networks. It is left to the subsequent layers of the network to extract relevant aspects of a word's meaning based on the context in which it appears. In this paper, we investigate whether word representations can be improved by explicitly incorporating the idea of latent roles. That is, we propose a role interaction layer (RIL) that consists of context-dependent (latent) role assignments and role-specific transformations. We evaluate the RIL on machine translation using two language pairs (En-De and En-Fi) and three datasets of varying size. We find that the proposed mechanism improves translation quality over strong baselines with limited amounts of data, but that the improvement diminishes as the size of data grows, indicating that powerful neural MT systems are capable of implicitly modeling role-word interaction by themselves. Our qualitative analysis reveals that the RIL extracts meaningful context-dependent roles and that it allows us to inspect more deeply the internal mechanisms of state-of-the-art neural machine translation systems.", "keywords": ["Neural Machine Translation", "Natural Language Processing"], "authorids": ["dirk.weissenborn@gmail.com", "dkiela@fb.com", "jase@fb.com", "kyunghyun.cho@nyu.edu"], "authors": ["Dirk Weissenborn", "Douwe Kiela", "Jason Weston", "Kyunghyun Cho"], "TL;DR": "We propose a role interaction layer that explicitly models the modulation of token representations by contextualized roles.", "pdf": "/pdf/6b6b523e7619e51cc0ba56eab35e7ab9853dcfc7.pdf", "paperhash": "weissenborn|contextualized_role_interaction_for_neural_machine_translation", "_bibtex": "@misc{\nweissenborn2019contextualized,\ntitle={Contextualized Role Interaction for Neural Machine Translation},\nauthor={Dirk Weissenborn and Douwe Kiela and Jason Weston and Kyunghyun Cho},\nyear={2019},\nurl={https://openreview.net/forum?id=ryx3_iAcY7},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper390/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621623176, "tddate": null, "super": null, "final": null, "reply": {"forum": "ryx3_iAcY7", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper390/Authors", "ICLR.cc/2019/Conference/Paper390/Reviewers", "ICLR.cc/2019/Conference/Paper390/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper390/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper390/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper390/Authors|ICLR.cc/2019/Conference/Paper390/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper390/Reviewers", "ICLR.cc/2019/Conference/Paper390/Authors", "ICLR.cc/2019/Conference/Paper390/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621623176}}}, {"id": "HJexH879hX", "original": null, "number": 3, "cdate": 1541187127927, "ddate": null, "tcdate": 1541187127927, "tmdate": 1543239730539, "tddate": null, "forum": "ryx3_iAcY7", "replyto": "ryx3_iAcY7", "invitation": "ICLR.cc/2019/Conference/-/Paper390/Official_Review", "content": {"title": "The motivation and goal of this paper are unclear", "review": "\n\n[Summary]\nThis paper proposes a \u201crole interaction layer\u201d (RIL) to capture the context-dependent (latent) role for each token.\n\n\n[clarity]\nThe writing is basically clear.\nHowever, It is hard for me to get the motivation and goal of this paper.\nIs the main purpose of the proposed method \u201cimproving the performance\u201d or \u201cinterpretability\u201d?\n\n\n[originality]\nIt seems that the proposed method consists of several known methods.\nMoreover, even though the purpose differs, technically the proposed method is closely related to the method proposed in [Shu+,2018].\nTherefore, the technical novelty of the proposed method is limited.\n\n[Shu+,2018] Raphael Shu, Hideki Nakayama, \u201cCompressing Word Embeddings via Deep Compositional Code Learning\u201d, ICLR-2018.\n\n\n[significance]\nThe contribution of this paper is not very clear.\nThe improvements from the baseline method (Matched) is less than 1 point BLEU as shown in Table 1 and 2, which is not a significant improvement.\n\n\n\nOverall, this paper is basically well written. However, this paper seems a technical report rather than a conference paper.\n\n", "rating": "4: Ok but not good enough - rejection", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}, "signatures": ["ICLR.cc/2019/Conference/Paper390/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": true, "forumContent": {"title": "Contextualized Role Interaction for Neural Machine Translation", "abstract": "Word inputs tend to be represented as single continuous vectors in deep neural networks. It is left to the subsequent layers of the network to extract relevant aspects of a word's meaning based on the context in which it appears. In this paper, we investigate whether word representations can be improved by explicitly incorporating the idea of latent roles. That is, we propose a role interaction layer (RIL) that consists of context-dependent (latent) role assignments and role-specific transformations. We evaluate the RIL on machine translation using two language pairs (En-De and En-Fi) and three datasets of varying size. We find that the proposed mechanism improves translation quality over strong baselines with limited amounts of data, but that the improvement diminishes as the size of data grows, indicating that powerful neural MT systems are capable of implicitly modeling role-word interaction by themselves. Our qualitative analysis reveals that the RIL extracts meaningful context-dependent roles and that it allows us to inspect more deeply the internal mechanisms of state-of-the-art neural machine translation systems.", "keywords": ["Neural Machine Translation", "Natural Language Processing"], "authorids": ["dirk.weissenborn@gmail.com", "dkiela@fb.com", "jase@fb.com", "kyunghyun.cho@nyu.edu"], "authors": ["Dirk Weissenborn", "Douwe Kiela", "Jason Weston", "Kyunghyun Cho"], "TL;DR": "We propose a role interaction layer that explicitly models the modulation of token representations by contextualized roles.", "pdf": "/pdf/6b6b523e7619e51cc0ba56eab35e7ab9853dcfc7.pdf", "paperhash": "weissenborn|contextualized_role_interaction_for_neural_machine_translation", "_bibtex": "@misc{\nweissenborn2019contextualized,\ntitle={Contextualized Role Interaction for Neural Machine Translation},\nauthor={Dirk Weissenborn and Douwe Kiela and Jason Weston and Kyunghyun Cho},\nyear={2019},\nurl={https://openreview.net/forum?id=ryx3_iAcY7},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper390/Official_Review", "cdate": 1542234472396, "expdate": 1552335264000, "duedate": 1541196000000, "reply": {"forum": "ryx3_iAcY7", "replyto": "ryx3_iAcY7", "readers": {"description": "The users who will be allowed to read the reply content.", "values": ["everyone"]}, "nonreaders": {"values": []}, "signatures": {"description": "How your identity will be displayed with the above content.", "values-regex": "ICLR.cc/2019/Conference/Paper390/AnonReviewer[0-9]+"}, "writers": {"description": "Users that may modify this record.", "values": ["ICLR.cc/2019/Conference"]}, "content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "required": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}}, "multiReply": false, "tcdate": 1552335713296, "tmdate": 1552335713296, "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "invitees": ["ICLR.cc/2019/Conference/Paper390/Reviewers"], "noninvitees": [], "signatures": ["ICLR.cc/2019/Conference"]}}}, {"id": "B1lVhyY7R7", "original": null, "number": 5, "cdate": 1542848428316, "ddate": null, "tcdate": 1542848428316, "tmdate": 1542848428316, "tddate": null, "forum": "ryx3_iAcY7", "replyto": "HJgD1tOZTX", "invitation": "ICLR.cc/2019/Conference/-/Paper390/Official_Comment", "content": {"title": "Reply to the rebuttal", "comment": "Thanks for your response.\n\n1.\tThe improvement is not significant on large datasets. It seems that you agree with this point in your rebuttal. AnonReviewer1 also points it out in his/her ``[significant] comments\u2019\u2019. Therefore, this is still a concern for this paper. You should try to make it work before the revision deadline.\n\n2.\tI did not find the detailed analysis of \u201cimplicitly modeling role-word interaction\u201d. It seems that no revised paper is uploaded until now. I am still confused about your explanation: (a) What is the \u201cinductive bias\u201d ? (b) You mentioned that \u201cwe conjecture that a neural translation system does not exhibit an appropriate inductive bias that encourages it to capture role interaction and cannot learn to do so when only a small amount of data is available.\u201d Any statistics/visualization to support this claim? From my point of view, this explain is weak.\n\n\n3.\tYou have not implemented the baseline with an additional layer, i.e., the second point in my \u201c[Cons & Details]\u201d comments. Any results ? \n"}, "signatures": ["ICLR.cc/2019/Conference/Paper390/AnonReviewer2"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper390/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper390/AnonReviewer2", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Contextualized Role Interaction for Neural Machine Translation", "abstract": "Word inputs tend to be represented as single continuous vectors in deep neural networks. It is left to the subsequent layers of the network to extract relevant aspects of a word's meaning based on the context in which it appears. In this paper, we investigate whether word representations can be improved by explicitly incorporating the idea of latent roles. That is, we propose a role interaction layer (RIL) that consists of context-dependent (latent) role assignments and role-specific transformations. We evaluate the RIL on machine translation using two language pairs (En-De and En-Fi) and three datasets of varying size. We find that the proposed mechanism improves translation quality over strong baselines with limited amounts of data, but that the improvement diminishes as the size of data grows, indicating that powerful neural MT systems are capable of implicitly modeling role-word interaction by themselves. Our qualitative analysis reveals that the RIL extracts meaningful context-dependent roles and that it allows us to inspect more deeply the internal mechanisms of state-of-the-art neural machine translation systems.", "keywords": ["Neural Machine Translation", "Natural Language Processing"], "authorids": ["dirk.weissenborn@gmail.com", "dkiela@fb.com", "jase@fb.com", "kyunghyun.cho@nyu.edu"], "authors": ["Dirk Weissenborn", "Douwe Kiela", "Jason Weston", "Kyunghyun Cho"], "TL;DR": "We propose a role interaction layer that explicitly models the modulation of token representations by contextualized roles.", "pdf": "/pdf/6b6b523e7619e51cc0ba56eab35e7ab9853dcfc7.pdf", "paperhash": "weissenborn|contextualized_role_interaction_for_neural_machine_translation", "_bibtex": "@misc{\nweissenborn2019contextualized,\ntitle={Contextualized Role Interaction for Neural Machine Translation},\nauthor={Dirk Weissenborn and Douwe Kiela and Jason Weston and Kyunghyun Cho},\nyear={2019},\nurl={https://openreview.net/forum?id=ryx3_iAcY7},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper390/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621623176, "tddate": null, "super": null, "final": null, "reply": {"forum": "ryx3_iAcY7", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper390/Authors", "ICLR.cc/2019/Conference/Paper390/Reviewers", "ICLR.cc/2019/Conference/Paper390/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper390/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper390/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper390/Authors|ICLR.cc/2019/Conference/Paper390/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper390/Reviewers", "ICLR.cc/2019/Conference/Paper390/Authors", "ICLR.cc/2019/Conference/Paper390/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621623176}}}, {"id": "BJlGWKO-pX", "original": null, "number": 3, "cdate": 1541667066479, "ddate": null, "tcdate": 1541667066479, "tmdate": 1541667066479, "tddate": null, "forum": "ryx3_iAcY7", "replyto": "rkxeKKs_h7", "invitation": "ICLR.cc/2019/Conference/-/Paper390/Official_Comment", "content": {"title": "Rebuttal", "comment": "We thank you for your review. \n\nWe believe that creating and analysing network variations for the sole purpose of improving some rather artificial scores on some benchmarks is limiting the kind of research we can conduct. By designing and carefully evaluating meaningful model extensions we can learn a lot about both the model extensions and the baseline. For instance, in our case we find that the RIL exhibits its intended behavior and improves the translation quality when there is a limited amount of data (which is an important use case for machine translation), although there is no visible improvement on larger datasets. We thus draw an interesting conclusion from this observation that the baseline can/must learn something similar implicitly *if* enough data is available.\n"}, "signatures": ["ICLR.cc/2019/Conference/Paper390/Authors"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper390/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper390/Authors", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Contextualized Role Interaction for Neural Machine Translation", "abstract": "Word inputs tend to be represented as single continuous vectors in deep neural networks. It is left to the subsequent layers of the network to extract relevant aspects of a word's meaning based on the context in which it appears. In this paper, we investigate whether word representations can be improved by explicitly incorporating the idea of latent roles. That is, we propose a role interaction layer (RIL) that consists of context-dependent (latent) role assignments and role-specific transformations. We evaluate the RIL on machine translation using two language pairs (En-De and En-Fi) and three datasets of varying size. We find that the proposed mechanism improves translation quality over strong baselines with limited amounts of data, but that the improvement diminishes as the size of data grows, indicating that powerful neural MT systems are capable of implicitly modeling role-word interaction by themselves. Our qualitative analysis reveals that the RIL extracts meaningful context-dependent roles and that it allows us to inspect more deeply the internal mechanisms of state-of-the-art neural machine translation systems.", "keywords": ["Neural Machine Translation", "Natural Language Processing"], "authorids": ["dirk.weissenborn@gmail.com", "dkiela@fb.com", "jase@fb.com", "kyunghyun.cho@nyu.edu"], "authors": ["Dirk Weissenborn", "Douwe Kiela", "Jason Weston", "Kyunghyun Cho"], "TL;DR": "We propose a role interaction layer that explicitly models the modulation of token representations by contextualized roles.", "pdf": "/pdf/6b6b523e7619e51cc0ba56eab35e7ab9853dcfc7.pdf", "paperhash": "weissenborn|contextualized_role_interaction_for_neural_machine_translation", "_bibtex": "@misc{\nweissenborn2019contextualized,\ntitle={Contextualized Role Interaction for Neural Machine Translation},\nauthor={Dirk Weissenborn and Douwe Kiela and Jason Weston and Kyunghyun Cho},\nyear={2019},\nurl={https://openreview.net/forum?id=ryx3_iAcY7},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper390/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621623176, "tddate": null, "super": null, "final": null, "reply": {"forum": "ryx3_iAcY7", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper390/Authors", "ICLR.cc/2019/Conference/Paper390/Reviewers", "ICLR.cc/2019/Conference/Paper390/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper390/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper390/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper390/Authors|ICLR.cc/2019/Conference/Paper390/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper390/Reviewers", "ICLR.cc/2019/Conference/Paper390/Authors", "ICLR.cc/2019/Conference/Paper390/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621623176}}}, {"id": "HJgD1tOZTX", "original": null, "number": 2, "cdate": 1541667039134, "ddate": null, "tcdate": 1541667039134, "tmdate": 1541667039134, "tddate": null, "forum": "ryx3_iAcY7", "replyto": "Hkxk2bKt2X", "invitation": "ICLR.cc/2019/Conference/-/Paper390/Official_Comment", "content": {"title": "Rebuttal", "comment": "We thank you for your thorough review. \n\n\u201cwe cannot say that the proposed algorithm is better than the baseline.\u201d\n\nWe agree that we cannot say that our addition is better than the baseline on the larger datasets we considered.\n\n\u201cWhy the NMT systems trained on large dataset can \u201cimplicitly modeling role-word interaction\u201d, while small dataset cannot?\u201d\n\nWe conjecture that a neural translation system does not exhibit an appropriate inductive bias that encourages it to capture role interaction and cannot learn to do so when only a small amount of data is available. The proposed approach equips the neural translation model with the appropriate inductive bias that allows it to exploit role interaction to do better. However, with a large enough data, our observation suggests that this explicit inductive bias is unnecessary as the neural translation system can learn this role interaction property on its own from data.\n"}, "signatures": ["ICLR.cc/2019/Conference/Paper390/Authors"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper390/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper390/Authors", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Contextualized Role Interaction for Neural Machine Translation", "abstract": "Word inputs tend to be represented as single continuous vectors in deep neural networks. It is left to the subsequent layers of the network to extract relevant aspects of a word's meaning based on the context in which it appears. In this paper, we investigate whether word representations can be improved by explicitly incorporating the idea of latent roles. That is, we propose a role interaction layer (RIL) that consists of context-dependent (latent) role assignments and role-specific transformations. We evaluate the RIL on machine translation using two language pairs (En-De and En-Fi) and three datasets of varying size. We find that the proposed mechanism improves translation quality over strong baselines with limited amounts of data, but that the improvement diminishes as the size of data grows, indicating that powerful neural MT systems are capable of implicitly modeling role-word interaction by themselves. Our qualitative analysis reveals that the RIL extracts meaningful context-dependent roles and that it allows us to inspect more deeply the internal mechanisms of state-of-the-art neural machine translation systems.", "keywords": ["Neural Machine Translation", "Natural Language Processing"], "authorids": ["dirk.weissenborn@gmail.com", "dkiela@fb.com", "jase@fb.com", "kyunghyun.cho@nyu.edu"], "authors": ["Dirk Weissenborn", "Douwe Kiela", "Jason Weston", "Kyunghyun Cho"], "TL;DR": "We propose a role interaction layer that explicitly models the modulation of token representations by contextualized roles.", "pdf": "/pdf/6b6b523e7619e51cc0ba56eab35e7ab9853dcfc7.pdf", "paperhash": "weissenborn|contextualized_role_interaction_for_neural_machine_translation", "_bibtex": "@misc{\nweissenborn2019contextualized,\ntitle={Contextualized Role Interaction for Neural Machine Translation},\nauthor={Dirk Weissenborn and Douwe Kiela and Jason Weston and Kyunghyun Cho},\nyear={2019},\nurl={https://openreview.net/forum?id=ryx3_iAcY7},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper390/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621623176, "tddate": null, "super": null, "final": null, "reply": {"forum": "ryx3_iAcY7", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper390/Authors", "ICLR.cc/2019/Conference/Paper390/Reviewers", "ICLR.cc/2019/Conference/Paper390/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper390/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper390/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper390/Authors|ICLR.cc/2019/Conference/Paper390/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper390/Reviewers", "ICLR.cc/2019/Conference/Paper390/Authors", "ICLR.cc/2019/Conference/Paper390/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621623176}}}, {"id": "r1x3n_uZam", "original": null, "number": 1, "cdate": 1541666996362, "ddate": null, "tcdate": 1541666996362, "tmdate": 1541666996362, "tddate": null, "forum": "ryx3_iAcY7", "replyto": "HJexH879hX", "invitation": "ICLR.cc/2019/Conference/-/Paper390/Official_Comment", "content": {"title": "Rebuttal", "comment": "We thank you for your thorough review. \n\n\u201cIs the main purpose of the proposed method \u201cimproving the performance\u201d or \u201cinterpretability\u201d?\u201d\n\u201cThe contribution of this paper is not very clear.\u201d\n\u201cThe improvements from baseline method (Matched) is less than 1 point BLEU as shown in Table 1 and 2, which is not a significant improvement.\u201d\n\nThe purpose of this work was to give existing architectures a better inductive bias. The results of such an effort can be either or both better performance or/and better interpretability.  A stronger inductive bias typically leads to better generalization, which is often more necessary in the low-data regime, and our experiments clearly show that the proposed approach indeed improves the translation quality (better performance) when the amount of data is limited. Even when it does not offer better performance due to the availability of large data, the proposed RIL facilitates the interpretation of a model, which provides us with a deeper understanding of what these neural translation models are learning.\n\n\u201ctechnically the proposed method is closely related to the method proposed in [Shu+,2018].\u201d\n\nThe method proposed by Shu et al. [2018] is indeed related to our proposal. Our role assignments are however learned end-to-end with the downstream task while Shu et al. learn the codes of pre-trained embedding matrices. Furthermore, using discrete codes is just one possible formulation of the proposed approach in addition to other possibilities we explore in our work.\n"}, "signatures": ["ICLR.cc/2019/Conference/Paper390/Authors"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper390/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper390/Authors", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Contextualized Role Interaction for Neural Machine Translation", "abstract": "Word inputs tend to be represented as single continuous vectors in deep neural networks. It is left to the subsequent layers of the network to extract relevant aspects of a word's meaning based on the context in which it appears. In this paper, we investigate whether word representations can be improved by explicitly incorporating the idea of latent roles. That is, we propose a role interaction layer (RIL) that consists of context-dependent (latent) role assignments and role-specific transformations. We evaluate the RIL on machine translation using two language pairs (En-De and En-Fi) and three datasets of varying size. We find that the proposed mechanism improves translation quality over strong baselines with limited amounts of data, but that the improvement diminishes as the size of data grows, indicating that powerful neural MT systems are capable of implicitly modeling role-word interaction by themselves. Our qualitative analysis reveals that the RIL extracts meaningful context-dependent roles and that it allows us to inspect more deeply the internal mechanisms of state-of-the-art neural machine translation systems.", "keywords": ["Neural Machine Translation", "Natural Language Processing"], "authorids": ["dirk.weissenborn@gmail.com", "dkiela@fb.com", "jase@fb.com", "kyunghyun.cho@nyu.edu"], "authors": ["Dirk Weissenborn", "Douwe Kiela", "Jason Weston", "Kyunghyun Cho"], "TL;DR": "We propose a role interaction layer that explicitly models the modulation of token representations by contextualized roles.", "pdf": "/pdf/6b6b523e7619e51cc0ba56eab35e7ab9853dcfc7.pdf", "paperhash": "weissenborn|contextualized_role_interaction_for_neural_machine_translation", "_bibtex": "@misc{\nweissenborn2019contextualized,\ntitle={Contextualized Role Interaction for Neural Machine Translation},\nauthor={Dirk Weissenborn and Douwe Kiela and Jason Weston and Kyunghyun Cho},\nyear={2019},\nurl={https://openreview.net/forum?id=ryx3_iAcY7},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper390/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621623176, "tddate": null, "super": null, "final": null, "reply": {"forum": "ryx3_iAcY7", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper390/Authors", "ICLR.cc/2019/Conference/Paper390/Reviewers", "ICLR.cc/2019/Conference/Paper390/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper390/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper390/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper390/Authors|ICLR.cc/2019/Conference/Paper390/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper390/Reviewers", "ICLR.cc/2019/Conference/Paper390/Authors", "ICLR.cc/2019/Conference/Paper390/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621623176}}}, {"id": "Hkxk2bKt2X", "original": null, "number": 2, "cdate": 1541144999118, "ddate": null, "tcdate": 1541144999118, "tmdate": 1541534035923, "tddate": null, "forum": "ryx3_iAcY7", "replyto": "ryx3_iAcY7", "invitation": "ICLR.cc/2019/Conference/-/Paper390/Official_Review", "content": {"title": "Interesting idea, but the improvement over the baseline is not significant.", "review": "\n[Summary]\nThis paper proposes \u201ca role interaction layer\u201d (briefly, RIL) that consists of context-dependent (latent) role assignments and role-specific transformations: Given an RIL layer, different dimensions of an embedding vector are \u201cinteracted\u201d based on Eqn. (5), Eqn. (7), etc. The authors work on IWSLT De->En and WMT En->De, En->Fi to verify their proposed algorithm with case study included. \n\n[Pros]\n(+) I think the idea/thought of using a \u201crole interaction layer\u201d is interesting.  The case study in Section 5.3 demonstrates different \u201croles\u201d. Also, different RIL architectures are designed.\n(+) The paper is easy to follow.\n\n[Cons & Details]\n(1) As stated in the abstract, \u201c\u2026, but that the improvement diminishes as the size of data grows, indicating that powerful neural MT systems are capable of implicitly modeling role-word interaction by themselves\u2026\u201d (1) The main concern is that, considering RIL does not obtain significant gain on large datasets, then we cannot say that the proposed algorithm is better than the baseline. (2) Why the NMT systems trained on large dataset can \u201cimplicitly modeling role-word interaction\u201d, while small dataset cannot? Any analysis?\n\n(2) For the \u201cmatched baseline\u201d, page 5, you increase the dimensionality of the models. But an RIL is an additional layer, which makes the network deeper. Therefore, a baseline with an additional layer should be implemented. \n", "rating": "5: Marginally below acceptance threshold", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["ICLR.cc/2019/Conference/Paper390/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Contextualized Role Interaction for Neural Machine Translation", "abstract": "Word inputs tend to be represented as single continuous vectors in deep neural networks. It is left to the subsequent layers of the network to extract relevant aspects of a word's meaning based on the context in which it appears. In this paper, we investigate whether word representations can be improved by explicitly incorporating the idea of latent roles. That is, we propose a role interaction layer (RIL) that consists of context-dependent (latent) role assignments and role-specific transformations. We evaluate the RIL on machine translation using two language pairs (En-De and En-Fi) and three datasets of varying size. We find that the proposed mechanism improves translation quality over strong baselines with limited amounts of data, but that the improvement diminishes as the size of data grows, indicating that powerful neural MT systems are capable of implicitly modeling role-word interaction by themselves. Our qualitative analysis reveals that the RIL extracts meaningful context-dependent roles and that it allows us to inspect more deeply the internal mechanisms of state-of-the-art neural machine translation systems.", "keywords": ["Neural Machine Translation", "Natural Language Processing"], "authorids": ["dirk.weissenborn@gmail.com", "dkiela@fb.com", "jase@fb.com", "kyunghyun.cho@nyu.edu"], "authors": ["Dirk Weissenborn", "Douwe Kiela", "Jason Weston", "Kyunghyun Cho"], "TL;DR": "We propose a role interaction layer that explicitly models the modulation of token representations by contextualized roles.", "pdf": "/pdf/6b6b523e7619e51cc0ba56eab35e7ab9853dcfc7.pdf", "paperhash": "weissenborn|contextualized_role_interaction_for_neural_machine_translation", "_bibtex": "@misc{\nweissenborn2019contextualized,\ntitle={Contextualized Role Interaction for Neural Machine Translation},\nauthor={Dirk Weissenborn and Douwe Kiela and Jason Weston and Kyunghyun Cho},\nyear={2019},\nurl={https://openreview.net/forum?id=ryx3_iAcY7},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper390/Official_Review", "cdate": 1542234472396, "expdate": 1552335264000, "duedate": 1541196000000, "reply": {"forum": "ryx3_iAcY7", "replyto": "ryx3_iAcY7", "readers": {"description": "The users who will be allowed to read the reply content.", "values": ["everyone"]}, "nonreaders": {"values": []}, "signatures": {"description": "How your identity will be displayed with the above content.", "values-regex": "ICLR.cc/2019/Conference/Paper390/AnonReviewer[0-9]+"}, "writers": {"description": "Users that may modify this record.", "values": ["ICLR.cc/2019/Conference"]}, "content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "required": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}}, "multiReply": false, "tcdate": 1552335713296, "tmdate": 1552335713296, "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "invitees": ["ICLR.cc/2019/Conference/Paper390/Reviewers"], "noninvitees": [], "signatures": ["ICLR.cc/2019/Conference"]}}}, {"id": "rkxeKKs_h7", "original": null, "number": 1, "cdate": 1541089655719, "ddate": null, "tcdate": 1541089655719, "tmdate": 1541534035713, "tddate": null, "forum": "ryx3_iAcY7", "replyto": "ryx3_iAcY7", "invitation": "ICLR.cc/2019/Conference/-/Paper390/Official_Review", "content": {"title": "The improvement seems not enough", "review": "The paper proposes contextual role representation which is an interesting point. \nThe writing is clear and the idea is original.\nEven with the interesting point, however, the performance improvement seems not enough compared to the baseline. The baseline might be carefully tuned as the authors said, but the proposed representation is supposed to improve the performance on top of the baseline.\nThe interpretation of the role representation is pros of the proposed model. However, it is somehow arguable, since it is subjective. \n\n- minor issues: \nThere are typos in the notations right before Eq. (8). \n", "rating": "4: Ok but not good enough - rejection", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["ICLR.cc/2019/Conference/Paper390/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Contextualized Role Interaction for Neural Machine Translation", "abstract": "Word inputs tend to be represented as single continuous vectors in deep neural networks. It is left to the subsequent layers of the network to extract relevant aspects of a word's meaning based on the context in which it appears. In this paper, we investigate whether word representations can be improved by explicitly incorporating the idea of latent roles. That is, we propose a role interaction layer (RIL) that consists of context-dependent (latent) role assignments and role-specific transformations. We evaluate the RIL on machine translation using two language pairs (En-De and En-Fi) and three datasets of varying size. We find that the proposed mechanism improves translation quality over strong baselines with limited amounts of data, but that the improvement diminishes as the size of data grows, indicating that powerful neural MT systems are capable of implicitly modeling role-word interaction by themselves. Our qualitative analysis reveals that the RIL extracts meaningful context-dependent roles and that it allows us to inspect more deeply the internal mechanisms of state-of-the-art neural machine translation systems.", "keywords": ["Neural Machine Translation", "Natural Language Processing"], "authorids": ["dirk.weissenborn@gmail.com", "dkiela@fb.com", "jase@fb.com", "kyunghyun.cho@nyu.edu"], "authors": ["Dirk Weissenborn", "Douwe Kiela", "Jason Weston", "Kyunghyun Cho"], "TL;DR": "We propose a role interaction layer that explicitly models the modulation of token representations by contextualized roles.", "pdf": "/pdf/6b6b523e7619e51cc0ba56eab35e7ab9853dcfc7.pdf", "paperhash": "weissenborn|contextualized_role_interaction_for_neural_machine_translation", "_bibtex": "@misc{\nweissenborn2019contextualized,\ntitle={Contextualized Role Interaction for Neural Machine Translation},\nauthor={Dirk Weissenborn and Douwe Kiela and Jason Weston and Kyunghyun Cho},\nyear={2019},\nurl={https://openreview.net/forum?id=ryx3_iAcY7},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper390/Official_Review", "cdate": 1542234472396, "expdate": 1552335264000, "duedate": 1541196000000, "reply": {"forum": "ryx3_iAcY7", "replyto": "ryx3_iAcY7", "readers": {"description": "The users who will be allowed to read the reply content.", "values": ["everyone"]}, "nonreaders": {"values": []}, "signatures": {"description": "How your identity will be displayed with the above content.", "values-regex": "ICLR.cc/2019/Conference/Paper390/AnonReviewer[0-9]+"}, "writers": {"description": "Users that may modify this record.", "values": ["ICLR.cc/2019/Conference"]}, "content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "required": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}}, "multiReply": false, "tcdate": 1552335713296, "tmdate": 1552335713296, "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "invitees": ["ICLR.cc/2019/Conference/Paper390/Reviewers"], "noninvitees": [], "signatures": ["ICLR.cc/2019/Conference"]}}}], "count": 10}